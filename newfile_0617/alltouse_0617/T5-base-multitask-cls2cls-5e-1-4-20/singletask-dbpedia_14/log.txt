05/17/2022 18:17:55 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-multitask-cls2cls-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
05/17/2022 18:17:55 - INFO - __main__ - models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14
05/17/2022 18:17:55 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-multitask-cls2cls-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
05/17/2022 18:17:55 - INFO - __main__ - models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14
05/17/2022 18:17:57 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/17/2022 18:17:57 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/17/2022 18:17:57 - INFO - __main__ - args.device: cuda:0
05/17/2022 18:17:57 - INFO - __main__ - args.device: cuda:1
05/17/2022 18:17:57 - INFO - __main__ - Using 2 gpus
05/17/2022 18:17:57 - INFO - __main__ - Using 2 gpus
05/17/2022 18:17:57 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/17/2022 18:17:57 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/17/2022 18:18:01 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/17/2022 18:18:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:18:02 - INFO - __main__ - Printing 3 examples
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:18:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:18:02 - INFO - __main__ - Printing 3 examples
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:18:02 - INFO - __main__ - ['Animal']
05/17/2022 18:18:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:18:02 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:18:02 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:18:03 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:18:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:18:03 - INFO - __main__ - Printing 3 examples
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:18:03 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:18:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:18:03 - INFO - __main__ - Printing 3 examples
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:18:03 - INFO - __main__ - ['Animal']
05/17/2022 18:18:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:18:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:18:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:18:03 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:18:03 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:18:09 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:18:09 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:18:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:18:09 - INFO - __main__ - Starting training!
05/17/2022 18:18:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:18:15 - INFO - __main__ - Starting training!
05/17/2022 18:18:18 - INFO - __main__ - Step 10 Global step 10 Train loss 7.28 on epoch=0
05/17/2022 18:18:20 - INFO - __main__ - Step 20 Global step 20 Train loss 6.86 on epoch=1
05/17/2022 18:18:21 - INFO - __main__ - Step 30 Global step 30 Train loss 6.21 on epoch=2
05/17/2022 18:18:22 - INFO - __main__ - Step 40 Global step 40 Train loss 5.46 on epoch=2
05/17/2022 18:18:24 - INFO - __main__ - Step 50 Global step 50 Train loss 5.23 on epoch=3
05/17/2022 18:18:27 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=3
05/17/2022 18:18:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 18:18:28 - INFO - __main__ - Step 60 Global step 60 Train loss 4.86 on epoch=4
05/17/2022 18:18:29 - INFO - __main__ - Step 70 Global step 70 Train loss 4.31 on epoch=4
05/17/2022 18:18:31 - INFO - __main__ - Step 80 Global step 80 Train loss 4.33 on epoch=5
05/17/2022 18:18:32 - INFO - __main__ - Step 90 Global step 90 Train loss 3.68 on epoch=6
05/17/2022 18:18:33 - INFO - __main__ - Step 100 Global step 100 Train loss 3.79 on epoch=7
05/17/2022 18:18:37 - INFO - __main__ - Global step 100 Train loss 4.19 Classification-F1 0.0 on epoch=7
05/17/2022 18:18:38 - INFO - __main__ - Step 110 Global step 110 Train loss 3.37 on epoch=7
05/17/2022 18:18:39 - INFO - __main__ - Step 120 Global step 120 Train loss 3.39 on epoch=8
05/17/2022 18:18:41 - INFO - __main__ - Step 130 Global step 130 Train loss 3.10 on epoch=9
05/17/2022 18:18:42 - INFO - __main__ - Step 140 Global step 140 Train loss 3.03 on epoch=9
05/17/2022 18:18:43 - INFO - __main__ - Step 150 Global step 150 Train loss 2.97 on epoch=10
05/17/2022 18:18:45 - INFO - __main__ - Global step 150 Train loss 3.17 Classification-F1 0.009523809523809523 on epoch=10
05/17/2022 18:18:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809523 on epoch=10, global_step=150
05/17/2022 18:18:47 - INFO - __main__ - Step 160 Global step 160 Train loss 2.71 on epoch=11
05/17/2022 18:18:48 - INFO - __main__ - Step 170 Global step 170 Train loss 2.62 on epoch=12
05/17/2022 18:18:49 - INFO - __main__ - Step 180 Global step 180 Train loss 2.64 on epoch=12
05/17/2022 18:18:50 - INFO - __main__ - Step 190 Global step 190 Train loss 2.40 on epoch=13
05/17/2022 18:18:52 - INFO - __main__ - Step 200 Global step 200 Train loss 2.25 on epoch=14
05/17/2022 18:18:54 - INFO - __main__ - Global step 200 Train loss 2.53 Classification-F1 0.009523809523809523 on epoch=14
05/17/2022 18:18:55 - INFO - __main__ - Step 210 Global step 210 Train loss 2.34 on epoch=14
05/17/2022 18:18:56 - INFO - __main__ - Step 220 Global step 220 Train loss 2.12 on epoch=15
05/17/2022 18:18:57 - INFO - __main__ - Step 230 Global step 230 Train loss 2.11 on epoch=16
05/17/2022 18:18:59 - INFO - __main__ - Step 240 Global step 240 Train loss 2.10 on epoch=17
05/17/2022 18:19:00 - INFO - __main__ - Step 250 Global step 250 Train loss 1.97 on epoch=17
05/17/2022 18:19:02 - INFO - __main__ - Global step 250 Train loss 2.13 Classification-F1 0.009523809523809523 on epoch=17
05/17/2022 18:19:03 - INFO - __main__ - Step 260 Global step 260 Train loss 2.10 on epoch=18
05/17/2022 18:19:04 - INFO - __main__ - Step 270 Global step 270 Train loss 1.83 on epoch=19
05/17/2022 18:19:06 - INFO - __main__ - Step 280 Global step 280 Train loss 1.84 on epoch=19
05/17/2022 18:19:07 - INFO - __main__ - Step 290 Global step 290 Train loss 1.80 on epoch=20
05/17/2022 18:19:08 - INFO - __main__ - Step 300 Global step 300 Train loss 1.80 on epoch=21
05/17/2022 18:19:11 - INFO - __main__ - Global step 300 Train loss 1.87 Classification-F1 0.01728337236533958 on epoch=21
05/17/2022 18:19:11 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01728337236533958 on epoch=21, global_step=300
05/17/2022 18:19:12 - INFO - __main__ - Step 310 Global step 310 Train loss 1.67 on epoch=22
05/17/2022 18:19:13 - INFO - __main__ - Step 320 Global step 320 Train loss 1.66 on epoch=22
05/17/2022 18:19:14 - INFO - __main__ - Step 330 Global step 330 Train loss 1.63 on epoch=23
05/17/2022 18:19:16 - INFO - __main__ - Step 340 Global step 340 Train loss 1.54 on epoch=24
05/17/2022 18:19:17 - INFO - __main__ - Step 350 Global step 350 Train loss 1.55 on epoch=24
05/17/2022 18:19:20 - INFO - __main__ - Global step 350 Train loss 1.61 Classification-F1 0.03886910830946177 on epoch=24
05/17/2022 18:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.01728337236533958 -> 0.03886910830946177 on epoch=24, global_step=350
05/17/2022 18:19:21 - INFO - __main__ - Step 360 Global step 360 Train loss 1.54 on epoch=25
05/17/2022 18:19:22 - INFO - __main__ - Step 370 Global step 370 Train loss 1.48 on epoch=26
05/17/2022 18:19:24 - INFO - __main__ - Step 380 Global step 380 Train loss 1.50 on epoch=27
05/17/2022 18:19:25 - INFO - __main__ - Step 390 Global step 390 Train loss 1.43 on epoch=27
05/17/2022 18:19:26 - INFO - __main__ - Step 400 Global step 400 Train loss 1.41 on epoch=28
05/17/2022 18:19:28 - INFO - __main__ - Global step 400 Train loss 1.47 Classification-F1 0.03216419492132231 on epoch=28
05/17/2022 18:19:30 - INFO - __main__ - Step 410 Global step 410 Train loss 1.39 on epoch=29
05/17/2022 18:19:31 - INFO - __main__ - Step 420 Global step 420 Train loss 1.37 on epoch=29
05/17/2022 18:19:32 - INFO - __main__ - Step 430 Global step 430 Train loss 1.40 on epoch=30
05/17/2022 18:19:34 - INFO - __main__ - Step 440 Global step 440 Train loss 1.42 on epoch=31
05/17/2022 18:19:35 - INFO - __main__ - Step 450 Global step 450 Train loss 1.30 on epoch=32
05/17/2022 18:19:38 - INFO - __main__ - Global step 450 Train loss 1.38 Classification-F1 0.061876928790714936 on epoch=32
05/17/2022 18:19:38 - INFO - __main__ - Saving model with best Classification-F1: 0.03886910830946177 -> 0.061876928790714936 on epoch=32, global_step=450
05/17/2022 18:19:39 - INFO - __main__ - Step 460 Global step 460 Train loss 1.37 on epoch=32
05/17/2022 18:19:40 - INFO - __main__ - Step 470 Global step 470 Train loss 1.33 on epoch=33
05/17/2022 18:19:42 - INFO - __main__ - Step 480 Global step 480 Train loss 1.25 on epoch=34
05/17/2022 18:19:43 - INFO - __main__ - Step 490 Global step 490 Train loss 1.37 on epoch=34
05/17/2022 18:19:44 - INFO - __main__ - Step 500 Global step 500 Train loss 1.29 on epoch=35
05/17/2022 18:19:47 - INFO - __main__ - Global step 500 Train loss 1.32 Classification-F1 0.08144766775324959 on epoch=35
05/17/2022 18:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.061876928790714936 -> 0.08144766775324959 on epoch=35, global_step=500
05/17/2022 18:19:48 - INFO - __main__ - Step 510 Global step 510 Train loss 1.25 on epoch=36
05/17/2022 18:19:49 - INFO - __main__ - Step 520 Global step 520 Train loss 1.28 on epoch=37
05/17/2022 18:19:51 - INFO - __main__ - Step 530 Global step 530 Train loss 1.24 on epoch=37
05/17/2022 18:19:52 - INFO - __main__ - Step 540 Global step 540 Train loss 1.24 on epoch=38
05/17/2022 18:19:53 - INFO - __main__ - Step 550 Global step 550 Train loss 1.19 on epoch=39
05/17/2022 18:19:56 - INFO - __main__ - Global step 550 Train loss 1.24 Classification-F1 0.15418477854189722 on epoch=39
05/17/2022 18:19:56 - INFO - __main__ - Saving model with best Classification-F1: 0.08144766775324959 -> 0.15418477854189722 on epoch=39, global_step=550
05/17/2022 18:19:57 - INFO - __main__ - Step 560 Global step 560 Train loss 1.25 on epoch=39
05/17/2022 18:19:59 - INFO - __main__ - Step 570 Global step 570 Train loss 1.21 on epoch=40
05/17/2022 18:20:00 - INFO - __main__ - Step 580 Global step 580 Train loss 1.10 on epoch=41
05/17/2022 18:20:01 - INFO - __main__ - Step 590 Global step 590 Train loss 1.27 on epoch=42
05/17/2022 18:20:03 - INFO - __main__ - Step 600 Global step 600 Train loss 1.22 on epoch=42
05/17/2022 18:20:06 - INFO - __main__ - Global step 600 Train loss 1.21 Classification-F1 0.0996702189647789 on epoch=42
05/17/2022 18:20:07 - INFO - __main__ - Step 610 Global step 610 Train loss 1.21 on epoch=43
05/17/2022 18:20:08 - INFO - __main__ - Step 620 Global step 620 Train loss 1.17 on epoch=44
05/17/2022 18:20:09 - INFO - __main__ - Step 630 Global step 630 Train loss 1.27 on epoch=44
05/17/2022 18:20:11 - INFO - __main__ - Step 640 Global step 640 Train loss 1.11 on epoch=45
05/17/2022 18:20:12 - INFO - __main__ - Step 650 Global step 650 Train loss 1.20 on epoch=46
05/17/2022 18:20:15 - INFO - __main__ - Global step 650 Train loss 1.19 Classification-F1 0.09371274882764875 on epoch=46
05/17/2022 18:20:16 - INFO - __main__ - Step 660 Global step 660 Train loss 1.28 on epoch=47
05/17/2022 18:20:18 - INFO - __main__ - Step 670 Global step 670 Train loss 1.16 on epoch=47
05/17/2022 18:20:19 - INFO - __main__ - Step 680 Global step 680 Train loss 1.17 on epoch=48
05/17/2022 18:20:20 - INFO - __main__ - Step 690 Global step 690 Train loss 1.11 on epoch=49
05/17/2022 18:20:21 - INFO - __main__ - Step 700 Global step 700 Train loss 1.25 on epoch=49
05/17/2022 18:20:25 - INFO - __main__ - Global step 700 Train loss 1.19 Classification-F1 0.04073679222932954 on epoch=49
05/17/2022 18:20:26 - INFO - __main__ - Step 710 Global step 710 Train loss 1.11 on epoch=50
05/17/2022 18:20:27 - INFO - __main__ - Step 720 Global step 720 Train loss 1.17 on epoch=51
05/17/2022 18:20:28 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/17/2022 18:20:30 - INFO - __main__ - Step 740 Global step 740 Train loss 1.19 on epoch=52
05/17/2022 18:20:31 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/17/2022 18:20:34 - INFO - __main__ - Global step 750 Train loss 1.15 Classification-F1 0.07860756879500853 on epoch=53
05/17/2022 18:20:35 - INFO - __main__ - Step 760 Global step 760 Train loss 1.07 on epoch=54
05/17/2022 18:20:37 - INFO - __main__ - Step 770 Global step 770 Train loss 1.17 on epoch=54
05/17/2022 18:20:38 - INFO - __main__ - Step 780 Global step 780 Train loss 1.17 on epoch=55
05/17/2022 18:20:39 - INFO - __main__ - Step 790 Global step 790 Train loss 1.18 on epoch=56
05/17/2022 18:20:41 - INFO - __main__ - Step 800 Global step 800 Train loss 1.13 on epoch=57
05/17/2022 18:20:44 - INFO - __main__ - Global step 800 Train loss 1.14 Classification-F1 0.18043113784568243 on epoch=57
05/17/2022 18:20:44 - INFO - __main__ - Saving model with best Classification-F1: 0.15418477854189722 -> 0.18043113784568243 on epoch=57, global_step=800
05/17/2022 18:20:45 - INFO - __main__ - Step 810 Global step 810 Train loss 1.09 on epoch=57
05/17/2022 18:20:46 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=58
05/17/2022 18:20:47 - INFO - __main__ - Step 830 Global step 830 Train loss 1.01 on epoch=59
05/17/2022 18:20:49 - INFO - __main__ - Step 840 Global step 840 Train loss 1.04 on epoch=59
05/17/2022 18:20:50 - INFO - __main__ - Step 850 Global step 850 Train loss 1.06 on epoch=60
05/17/2022 18:20:53 - INFO - __main__ - Global step 850 Train loss 1.07 Classification-F1 0.29804622826647764 on epoch=60
05/17/2022 18:20:53 - INFO - __main__ - Saving model with best Classification-F1: 0.18043113784568243 -> 0.29804622826647764 on epoch=60, global_step=850
05/17/2022 18:20:55 - INFO - __main__ - Step 860 Global step 860 Train loss 1.14 on epoch=61
05/17/2022 18:20:56 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=62
05/17/2022 18:20:57 - INFO - __main__ - Step 880 Global step 880 Train loss 1.07 on epoch=62
05/17/2022 18:20:58 - INFO - __main__ - Step 890 Global step 890 Train loss 1.09 on epoch=63
05/17/2022 18:21:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.98 on epoch=64
05/17/2022 18:21:03 - INFO - __main__ - Global step 900 Train loss 1.09 Classification-F1 0.34361367156739214 on epoch=64
05/17/2022 18:21:03 - INFO - __main__ - Saving model with best Classification-F1: 0.29804622826647764 -> 0.34361367156739214 on epoch=64, global_step=900
05/17/2022 18:21:04 - INFO - __main__ - Step 910 Global step 910 Train loss 1.11 on epoch=64
05/17/2022 18:21:06 - INFO - __main__ - Step 920 Global step 920 Train loss 1.05 on epoch=65
05/17/2022 18:21:07 - INFO - __main__ - Step 930 Global step 930 Train loss 1.14 on epoch=66
05/17/2022 18:21:08 - INFO - __main__ - Step 940 Global step 940 Train loss 1.10 on epoch=67
05/17/2022 18:21:09 - INFO - __main__ - Step 950 Global step 950 Train loss 1.00 on epoch=67
05/17/2022 18:21:13 - INFO - __main__ - Global step 950 Train loss 1.08 Classification-F1 0.35467541863793733 on epoch=67
05/17/2022 18:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.34361367156739214 -> 0.35467541863793733 on epoch=67, global_step=950
05/17/2022 18:21:14 - INFO - __main__ - Step 960 Global step 960 Train loss 1.03 on epoch=68
05/17/2022 18:21:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.98 on epoch=69
05/17/2022 18:21:17 - INFO - __main__ - Step 980 Global step 980 Train loss 1.05 on epoch=69
05/17/2022 18:21:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.99 on epoch=70
05/17/2022 18:21:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.98 on epoch=71
05/17/2022 18:21:23 - INFO - __main__ - Global step 1000 Train loss 1.01 Classification-F1 0.41515727280869835 on epoch=71
05/17/2022 18:21:23 - INFO - __main__ - Saving model with best Classification-F1: 0.35467541863793733 -> 0.41515727280869835 on epoch=71, global_step=1000
05/17/2022 18:21:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/17/2022 18:21:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.99 on epoch=72
05/17/2022 18:21:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.01 on epoch=73
05/17/2022 18:21:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.96 on epoch=74
05/17/2022 18:21:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.97 on epoch=74
05/17/2022 18:21:33 - INFO - __main__ - Global step 1050 Train loss 0.99 Classification-F1 0.4906442202748969 on epoch=74
05/17/2022 18:21:33 - INFO - __main__ - Saving model with best Classification-F1: 0.41515727280869835 -> 0.4906442202748969 on epoch=74, global_step=1050
05/17/2022 18:21:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.06 on epoch=75
05/17/2022 18:21:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.04 on epoch=76
05/17/2022 18:21:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.01 on epoch=77
05/17/2022 18:21:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.02 on epoch=77
05/17/2022 18:21:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.00 on epoch=78
05/17/2022 18:21:43 - INFO - __main__ - Global step 1100 Train loss 1.02 Classification-F1 0.49409776660497573 on epoch=78
05/17/2022 18:21:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4906442202748969 -> 0.49409776660497573 on epoch=78, global_step=1100
05/17/2022 18:21:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.95 on epoch=79
05/17/2022 18:21:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/17/2022 18:21:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.91 on epoch=80
05/17/2022 18:21:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.95 on epoch=81
05/17/2022 18:21:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.00 on epoch=82
05/17/2022 18:21:53 - INFO - __main__ - Global step 1150 Train loss 0.95 Classification-F1 0.4647273301318002 on epoch=82
05/17/2022 18:21:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.83 on epoch=82
05/17/2022 18:21:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.85 on epoch=83
05/17/2022 18:21:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.85 on epoch=84
05/17/2022 18:21:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.84 on epoch=84
05/17/2022 18:21:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.85 on epoch=85
05/17/2022 18:22:03 - INFO - __main__ - Global step 1200 Train loss 0.84 Classification-F1 0.44596596604260846 on epoch=85
05/17/2022 18:22:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.82 on epoch=86
05/17/2022 18:22:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.82 on epoch=87
05/17/2022 18:22:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.81 on epoch=87
05/17/2022 18:22:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.85 on epoch=88
05/17/2022 18:22:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.79 on epoch=89
05/17/2022 18:22:13 - INFO - __main__ - Global step 1250 Train loss 0.82 Classification-F1 0.4157357352808112 on epoch=89
05/17/2022 18:22:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.90 on epoch=89
05/17/2022 18:22:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.86 on epoch=90
05/17/2022 18:22:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.79 on epoch=91
05/17/2022 18:22:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.81 on epoch=92
05/17/2022 18:22:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.83 on epoch=92
05/17/2022 18:22:23 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.4303783422080275 on epoch=92
05/17/2022 18:22:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.84 on epoch=93
05/17/2022 18:22:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.83 on epoch=94
05/17/2022 18:22:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.76 on epoch=94
05/17/2022 18:22:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.78 on epoch=95
05/17/2022 18:22:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.87 on epoch=96
05/17/2022 18:22:33 - INFO - __main__ - Global step 1350 Train loss 0.82 Classification-F1 0.42396406673620746 on epoch=96
05/17/2022 18:22:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.79 on epoch=97
05/17/2022 18:22:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.82 on epoch=97
05/17/2022 18:22:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.84 on epoch=98
05/17/2022 18:22:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.72 on epoch=99
05/17/2022 18:22:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.79 on epoch=99
05/17/2022 18:22:43 - INFO - __main__ - Global step 1400 Train loss 0.79 Classification-F1 0.39703179314276027 on epoch=99
05/17/2022 18:22:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/17/2022 18:22:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.85 on epoch=101
05/17/2022 18:22:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.74 on epoch=102
05/17/2022 18:22:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.78 on epoch=102
05/17/2022 18:22:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.81 on epoch=103
05/17/2022 18:22:53 - INFO - __main__ - Global step 1450 Train loss 0.79 Classification-F1 0.4088886866270234 on epoch=103
05/17/2022 18:22:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.74 on epoch=104
05/17/2022 18:22:56 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.79 on epoch=104
05/17/2022 18:22:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.66 on epoch=105
05/17/2022 18:22:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.79 on epoch=106
05/17/2022 18:23:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.74 on epoch=107
05/17/2022 18:23:03 - INFO - __main__ - Global step 1500 Train loss 0.74 Classification-F1 0.3813207016205517 on epoch=107
05/17/2022 18:23:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.75 on epoch=107
05/17/2022 18:23:06 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.78 on epoch=108
05/17/2022 18:23:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.79 on epoch=109
05/17/2022 18:23:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.70 on epoch=109
05/17/2022 18:23:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.77 on epoch=110
05/17/2022 18:23:14 - INFO - __main__ - Global step 1550 Train loss 0.76 Classification-F1 0.4055562518259034 on epoch=110
05/17/2022 18:23:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.69 on epoch=111
05/17/2022 18:23:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.70 on epoch=112
05/17/2022 18:23:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.68 on epoch=112
05/17/2022 18:23:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.73 on epoch=113
05/17/2022 18:23:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.67 on epoch=114
05/17/2022 18:23:24 - INFO - __main__ - Global step 1600 Train loss 0.70 Classification-F1 0.4397956662852786 on epoch=114
05/17/2022 18:23:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.78 on epoch=114
05/17/2022 18:23:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.73 on epoch=115
05/17/2022 18:23:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.66 on epoch=116
05/17/2022 18:23:29 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.81 on epoch=117
05/17/2022 18:23:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.57 on epoch=117
05/17/2022 18:23:34 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.5000456559314505 on epoch=117
05/17/2022 18:23:34 - INFO - __main__ - Saving model with best Classification-F1: 0.49409776660497573 -> 0.5000456559314505 on epoch=117, global_step=1650
05/17/2022 18:23:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.70 on epoch=118
05/17/2022 18:23:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.78 on epoch=119
05/17/2022 18:23:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.72 on epoch=119
05/17/2022 18:23:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.69 on epoch=120
05/17/2022 18:23:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.69 on epoch=121
05/17/2022 18:23:44 - INFO - __main__ - Global step 1700 Train loss 0.71 Classification-F1 0.4807801533850428 on epoch=121
05/17/2022 18:23:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.65 on epoch=122
05/17/2022 18:23:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.74 on epoch=122
05/17/2022 18:23:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.63 on epoch=123
05/17/2022 18:23:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.66 on epoch=124
05/17/2022 18:23:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.66 on epoch=124
05/17/2022 18:23:54 - INFO - __main__ - Global step 1750 Train loss 0.67 Classification-F1 0.49192001551749576 on epoch=124
05/17/2022 18:23:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.66 on epoch=125
05/17/2022 18:23:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.64 on epoch=126
05/17/2022 18:23:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.70 on epoch=127
05/17/2022 18:23:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.61 on epoch=127
05/17/2022 18:24:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.71 on epoch=128
05/17/2022 18:24:05 - INFO - __main__ - Global step 1800 Train loss 0.66 Classification-F1 0.49738870897331466 on epoch=128
05/17/2022 18:24:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.68 on epoch=129
05/17/2022 18:24:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.58 on epoch=129
05/17/2022 18:24:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.70 on epoch=130
05/17/2022 18:24:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.61 on epoch=131
05/17/2022 18:24:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.74 on epoch=132
05/17/2022 18:24:15 - INFO - __main__ - Global step 1850 Train loss 0.66 Classification-F1 0.5213543692622968 on epoch=132
05/17/2022 18:24:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5000456559314505 -> 0.5213543692622968 on epoch=132, global_step=1850
05/17/2022 18:24:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.57 on epoch=132
05/17/2022 18:24:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.60 on epoch=133
05/17/2022 18:24:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.64 on epoch=134
05/17/2022 18:24:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.65 on epoch=134
05/17/2022 18:24:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.70 on epoch=135
05/17/2022 18:24:25 - INFO - __main__ - Global step 1900 Train loss 0.63 Classification-F1 0.5604500882249385 on epoch=135
05/17/2022 18:24:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5213543692622968 -> 0.5604500882249385 on epoch=135, global_step=1900
05/17/2022 18:24:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.73 on epoch=136
05/17/2022 18:24:28 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.61 on epoch=137
05/17/2022 18:24:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.66 on epoch=137
05/17/2022 18:24:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.66 on epoch=138
05/17/2022 18:24:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.57 on epoch=139
05/17/2022 18:24:36 - INFO - __main__ - Global step 1950 Train loss 0.65 Classification-F1 0.5810103345855768 on epoch=139
05/17/2022 18:24:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5604500882249385 -> 0.5810103345855768 on epoch=139, global_step=1950
05/17/2022 18:24:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.62 on epoch=139
05/17/2022 18:24:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.60 on epoch=140
05/17/2022 18:24:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.66 on epoch=141
05/17/2022 18:24:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.72 on epoch=142
05/17/2022 18:24:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.60 on epoch=142
05/17/2022 18:24:46 - INFO - __main__ - Global step 2000 Train loss 0.64 Classification-F1 0.4721492983216242 on epoch=142
05/17/2022 18:24:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/17/2022 18:24:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.53 on epoch=144
05/17/2022 18:24:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.60 on epoch=144
05/17/2022 18:24:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.67 on epoch=145
05/17/2022 18:24:52 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/17/2022 18:24:56 - INFO - __main__ - Global step 2050 Train loss 0.62 Classification-F1 0.4613431389341754 on epoch=146
05/17/2022 18:24:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.67 on epoch=147
05/17/2022 18:24:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.68 on epoch=147
05/17/2022 18:25:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.54 on epoch=148
05/17/2022 18:25:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.60 on epoch=149
05/17/2022 18:25:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.57 on epoch=149
05/17/2022 18:25:06 - INFO - __main__ - Global step 2100 Train loss 0.61 Classification-F1 0.5011425157483176 on epoch=149
05/17/2022 18:25:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.57 on epoch=150
05/17/2022 18:25:09 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/17/2022 18:25:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.58 on epoch=152
05/17/2022 18:25:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.47 on epoch=152
05/17/2022 18:25:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.61 on epoch=153
05/17/2022 18:25:17 - INFO - __main__ - Global step 2150 Train loss 0.58 Classification-F1 0.5212033172741882 on epoch=153
05/17/2022 18:25:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.64 on epoch=154
05/17/2022 18:25:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.55 on epoch=154
05/17/2022 18:25:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.52 on epoch=155
05/17/2022 18:25:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.61 on epoch=156
05/17/2022 18:25:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.61 on epoch=157
05/17/2022 18:25:27 - INFO - __main__ - Global step 2200 Train loss 0.59 Classification-F1 0.5587170084863549 on epoch=157
05/17/2022 18:25:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.59 on epoch=157
05/17/2022 18:25:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.65 on epoch=158
05/17/2022 18:25:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.64 on epoch=159
05/17/2022 18:25:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.64 on epoch=159
05/17/2022 18:25:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.57 on epoch=160
05/17/2022 18:25:37 - INFO - __main__ - Global step 2250 Train loss 0.62 Classification-F1 0.5315857433050192 on epoch=160
05/17/2022 18:25:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.60 on epoch=161
05/17/2022 18:25:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.56 on epoch=162
05/17/2022 18:25:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.55 on epoch=162
05/17/2022 18:25:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.56 on epoch=163
05/17/2022 18:25:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.56 on epoch=164
05/17/2022 18:25:47 - INFO - __main__ - Global step 2300 Train loss 0.57 Classification-F1 0.5893967581245858 on epoch=164
05/17/2022 18:25:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5810103345855768 -> 0.5893967581245858 on epoch=164, global_step=2300
05/17/2022 18:25:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.49 on epoch=164
05/17/2022 18:25:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.54 on epoch=165
05/17/2022 18:25:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.58 on epoch=166
05/17/2022 18:25:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.63 on epoch=167
05/17/2022 18:25:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.61 on epoch=167
05/17/2022 18:25:57 - INFO - __main__ - Global step 2350 Train loss 0.57 Classification-F1 0.5502445599476751 on epoch=167
05/17/2022 18:25:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.54 on epoch=168
05/17/2022 18:26:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/17/2022 18:26:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.57 on epoch=169
05/17/2022 18:26:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.55 on epoch=170
05/17/2022 18:26:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.59 on epoch=171
05/17/2022 18:26:08 - INFO - __main__ - Global step 2400 Train loss 0.57 Classification-F1 0.5930741515106841 on epoch=171
05/17/2022 18:26:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5893967581245858 -> 0.5930741515106841 on epoch=171, global_step=2400
05/17/2022 18:26:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.63 on epoch=172
05/17/2022 18:26:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.53 on epoch=172
05/17/2022 18:26:11 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.52 on epoch=173
05/17/2022 18:26:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.52 on epoch=174
05/17/2022 18:26:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.64 on epoch=174
05/17/2022 18:26:18 - INFO - __main__ - Global step 2450 Train loss 0.57 Classification-F1 0.5441148301002042 on epoch=174
05/17/2022 18:26:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.63 on epoch=175
05/17/2022 18:26:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.50 on epoch=176
05/17/2022 18:26:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.60 on epoch=177
05/17/2022 18:26:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.48 on epoch=177
05/17/2022 18:26:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.61 on epoch=178
05/17/2022 18:26:28 - INFO - __main__ - Global step 2500 Train loss 0.56 Classification-F1 0.452659064310203 on epoch=178
05/17/2022 18:26:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.57 on epoch=179
05/17/2022 18:26:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.56 on epoch=179
05/17/2022 18:26:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.50 on epoch=180
05/17/2022 18:26:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.61 on epoch=181
05/17/2022 18:26:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.56 on epoch=182
05/17/2022 18:26:39 - INFO - __main__ - Global step 2550 Train loss 0.56 Classification-F1 0.5791584331718795 on epoch=182
05/17/2022 18:26:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.60 on epoch=182
05/17/2022 18:26:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.58 on epoch=183
05/17/2022 18:26:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.47 on epoch=184
05/17/2022 18:26:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/17/2022 18:26:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.53 on epoch=185
05/17/2022 18:26:49 - INFO - __main__ - Global step 2600 Train loss 0.56 Classification-F1 0.6664702370618898 on epoch=185
05/17/2022 18:26:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5930741515106841 -> 0.6664702370618898 on epoch=185, global_step=2600
05/17/2022 18:26:50 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.57 on epoch=186
05/17/2022 18:26:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.59 on epoch=187
05/17/2022 18:26:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.45 on epoch=187
05/17/2022 18:26:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.58 on epoch=188
05/17/2022 18:26:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.50 on epoch=189
05/17/2022 18:26:59 - INFO - __main__ - Global step 2650 Train loss 0.54 Classification-F1 0.5138024422824834 on epoch=189
05/17/2022 18:27:00 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.57 on epoch=189
05/17/2022 18:27:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.49 on epoch=190
05/17/2022 18:27:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.60 on epoch=191
05/17/2022 18:27:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.60 on epoch=192
05/17/2022 18:27:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.45 on epoch=192
05/17/2022 18:27:09 - INFO - __main__ - Global step 2700 Train loss 0.54 Classification-F1 0.5347081936633972 on epoch=192
05/17/2022 18:27:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.53 on epoch=193
05/17/2022 18:27:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.54 on epoch=194
05/17/2022 18:27:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.51 on epoch=194
05/17/2022 18:27:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.53 on epoch=195
05/17/2022 18:27:15 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.55 on epoch=196
05/17/2022 18:27:19 - INFO - __main__ - Global step 2750 Train loss 0.53 Classification-F1 0.5578858877171465 on epoch=196
05/17/2022 18:27:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.50 on epoch=197
05/17/2022 18:27:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.50 on epoch=197
05/17/2022 18:27:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.59 on epoch=198
05/17/2022 18:27:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.52 on epoch=199
05/17/2022 18:27:26 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.53 on epoch=199
05/17/2022 18:27:30 - INFO - __main__ - Global step 2800 Train loss 0.53 Classification-F1 0.5570213093246195 on epoch=199
05/17/2022 18:27:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.60 on epoch=200
05/17/2022 18:27:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.48 on epoch=201
05/17/2022 18:27:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.55 on epoch=202
05/17/2022 18:27:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.55 on epoch=202
05/17/2022 18:27:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.56 on epoch=203
05/17/2022 18:27:40 - INFO - __main__ - Global step 2850 Train loss 0.55 Classification-F1 0.5298437737394837 on epoch=203
05/17/2022 18:27:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.60 on epoch=204
05/17/2022 18:27:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.58 on epoch=204
05/17/2022 18:27:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.49 on epoch=205
05/17/2022 18:27:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.61 on epoch=206
05/17/2022 18:27:46 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.53 on epoch=207
05/17/2022 18:27:50 - INFO - __main__ - Global step 2900 Train loss 0.56 Classification-F1 0.5902234446180112 on epoch=207
05/17/2022 18:27:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.53 on epoch=207
05/17/2022 18:27:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.54 on epoch=208
05/17/2022 18:27:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.53 on epoch=209
05/17/2022 18:27:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.51 on epoch=209
05/17/2022 18:27:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.49 on epoch=210
05/17/2022 18:28:00 - INFO - __main__ - Global step 2950 Train loss 0.52 Classification-F1 0.5632930009797108 on epoch=210
05/17/2022 18:28:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.53 on epoch=211
05/17/2022 18:28:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/17/2022 18:28:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.52 on epoch=212
05/17/2022 18:28:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.54 on epoch=213
05/17/2022 18:28:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.51 on epoch=214
05/17/2022 18:28:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:28:08 - INFO - __main__ - Printing 3 examples
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:28:08 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:28:08 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:28:08 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:28:08 - INFO - __main__ - Printing 3 examples
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:28:08 - INFO - __main__ - ['Animal']
05/17/2022 18:28:08 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:28:08 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:28:08 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:28:11 - INFO - __main__ - Global step 3000 Train loss 0.54 Classification-F1 0.5956866760463084 on epoch=214
05/17/2022 18:28:11 - INFO - __main__ - save last model!
05/17/2022 18:28:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 18:28:11 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 18:28:11 - INFO - __main__ - Printing 3 examples
05/17/2022 18:28:11 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 18:28:11 - INFO - __main__ - ['Animal']
05/17/2022 18:28:11 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 18:28:11 - INFO - __main__ - ['Animal']
05/17/2022 18:28:11 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 18:28:11 - INFO - __main__ - ['Village']
05/17/2022 18:28:11 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:28:12 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:28:14 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:28:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:28:14 - INFO - __main__ - Starting training!
05/17/2022 18:28:16 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 18:29:27 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/17/2022 18:29:27 - INFO - __main__ - Classification-F1 on test data: 0.2895
05/17/2022 18:29:27 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.6664702370618898, test_performance=0.28952662875832763
05/17/2022 18:29:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/17/2022 18:29:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:29:28 - INFO - __main__ - Printing 3 examples
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:29:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:29:28 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:29:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:29:28 - INFO - __main__ - Printing 3 examples
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:29:28 - INFO - __main__ - ['Animal']
05/17/2022 18:29:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:29:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:29:29 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:29:35 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:29:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:29:35 - INFO - __main__ - Starting training!
05/17/2022 18:29:37 - INFO - __main__ - Step 10 Global step 10 Train loss 7.49 on epoch=0
05/17/2022 18:29:38 - INFO - __main__ - Step 20 Global step 20 Train loss 7.16 on epoch=1
05/17/2022 18:29:39 - INFO - __main__ - Step 30 Global step 30 Train loss 6.05 on epoch=2
05/17/2022 18:29:41 - INFO - __main__ - Step 40 Global step 40 Train loss 5.69 on epoch=2
05/17/2022 18:29:42 - INFO - __main__ - Step 50 Global step 50 Train loss 5.60 on epoch=3
05/17/2022 18:29:45 - INFO - __main__ - Global step 50 Train loss 6.40 Classification-F1 0.0 on epoch=3
05/17/2022 18:29:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 18:29:46 - INFO - __main__ - Step 60 Global step 60 Train loss 4.91 on epoch=4
05/17/2022 18:29:48 - INFO - __main__ - Step 70 Global step 70 Train loss 4.72 on epoch=4
05/17/2022 18:29:49 - INFO - __main__ - Step 80 Global step 80 Train loss 4.51 on epoch=5
05/17/2022 18:29:50 - INFO - __main__ - Step 90 Global step 90 Train loss 4.16 on epoch=6
05/17/2022 18:29:51 - INFO - __main__ - Step 100 Global step 100 Train loss 3.93 on epoch=7
05/17/2022 18:29:55 - INFO - __main__ - Global step 100 Train loss 4.45 Classification-F1 0.0 on epoch=7
05/17/2022 18:29:56 - INFO - __main__ - Step 110 Global step 110 Train loss 3.69 on epoch=7
05/17/2022 18:29:57 - INFO - __main__ - Step 120 Global step 120 Train loss 3.71 on epoch=8
05/17/2022 18:29:58 - INFO - __main__ - Step 130 Global step 130 Train loss 3.49 on epoch=9
05/17/2022 18:30:00 - INFO - __main__ - Step 140 Global step 140 Train loss 3.16 on epoch=9
05/17/2022 18:30:01 - INFO - __main__ - Step 150 Global step 150 Train loss 3.28 on epoch=10
05/17/2022 18:30:04 - INFO - __main__ - Global step 150 Train loss 3.47 Classification-F1 0.0 on epoch=10
05/17/2022 18:30:05 - INFO - __main__ - Step 160 Global step 160 Train loss 3.14 on epoch=11
05/17/2022 18:30:06 - INFO - __main__ - Step 170 Global step 170 Train loss 2.88 on epoch=12
05/17/2022 18:30:07 - INFO - __main__ - Step 180 Global step 180 Train loss 2.87 on epoch=12
05/17/2022 18:30:09 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=13
05/17/2022 18:30:10 - INFO - __main__ - Step 200 Global step 200 Train loss 2.57 on epoch=14
05/17/2022 18:30:12 - INFO - __main__ - Global step 200 Train loss 2.86 Classification-F1 0.009785932721712538 on epoch=14
05/17/2022 18:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009785932721712538 on epoch=14, global_step=200
05/17/2022 18:30:14 - INFO - __main__ - Step 210 Global step 210 Train loss 2.52 on epoch=14
05/17/2022 18:30:15 - INFO - __main__ - Step 220 Global step 220 Train loss 2.62 on epoch=15
05/17/2022 18:30:16 - INFO - __main__ - Step 230 Global step 230 Train loss 2.44 on epoch=16
05/17/2022 18:30:18 - INFO - __main__ - Step 240 Global step 240 Train loss 2.34 on epoch=17
05/17/2022 18:30:19 - INFO - __main__ - Step 250 Global step 250 Train loss 2.25 on epoch=17
05/17/2022 18:30:21 - INFO - __main__ - Global step 250 Train loss 2.43 Classification-F1 0.009523809523809523 on epoch=17
05/17/2022 18:30:22 - INFO - __main__ - Step 260 Global step 260 Train loss 2.28 on epoch=18
05/17/2022 18:30:23 - INFO - __main__ - Step 270 Global step 270 Train loss 2.15 on epoch=19
05/17/2022 18:30:25 - INFO - __main__ - Step 280 Global step 280 Train loss 2.10 on epoch=19
05/17/2022 18:30:26 - INFO - __main__ - Step 290 Global step 290 Train loss 2.06 on epoch=20
05/17/2022 18:30:27 - INFO - __main__ - Step 300 Global step 300 Train loss 1.97 on epoch=21
05/17/2022 18:30:29 - INFO - __main__ - Global step 300 Train loss 2.11 Classification-F1 0.014298055393945807 on epoch=21
05/17/2022 18:30:29 - INFO - __main__ - Saving model with best Classification-F1: 0.009785932721712538 -> 0.014298055393945807 on epoch=21, global_step=300
05/17/2022 18:30:30 - INFO - __main__ - Step 310 Global step 310 Train loss 1.85 on epoch=22
05/17/2022 18:30:32 - INFO - __main__ - Step 320 Global step 320 Train loss 1.86 on epoch=22
05/17/2022 18:30:33 - INFO - __main__ - Step 330 Global step 330 Train loss 1.89 on epoch=23
05/17/2022 18:30:34 - INFO - __main__ - Step 340 Global step 340 Train loss 1.78 on epoch=24
05/17/2022 18:30:35 - INFO - __main__ - Step 350 Global step 350 Train loss 1.83 on epoch=24
05/17/2022 18:30:37 - INFO - __main__ - Global step 350 Train loss 1.84 Classification-F1 0.04309644806539216 on epoch=24
05/17/2022 18:30:37 - INFO - __main__ - Saving model with best Classification-F1: 0.014298055393945807 -> 0.04309644806539216 on epoch=24, global_step=350
05/17/2022 18:30:39 - INFO - __main__ - Step 360 Global step 360 Train loss 1.85 on epoch=25
05/17/2022 18:30:40 - INFO - __main__ - Step 370 Global step 370 Train loss 1.76 on epoch=26
05/17/2022 18:30:41 - INFO - __main__ - Step 380 Global step 380 Train loss 1.66 on epoch=27
05/17/2022 18:30:43 - INFO - __main__ - Step 390 Global step 390 Train loss 1.68 on epoch=27
05/17/2022 18:30:44 - INFO - __main__ - Step 400 Global step 400 Train loss 1.66 on epoch=28
05/17/2022 18:30:46 - INFO - __main__ - Global step 400 Train loss 1.72 Classification-F1 0.034324530655254724 on epoch=28
05/17/2022 18:30:48 - INFO - __main__ - Step 410 Global step 410 Train loss 1.53 on epoch=29
05/17/2022 18:30:49 - INFO - __main__ - Step 420 Global step 420 Train loss 1.55 on epoch=29
05/17/2022 18:30:50 - INFO - __main__ - Step 430 Global step 430 Train loss 1.56 on epoch=30
05/17/2022 18:30:52 - INFO - __main__ - Step 440 Global step 440 Train loss 1.55 on epoch=31
05/17/2022 18:30:53 - INFO - __main__ - Step 450 Global step 450 Train loss 1.60 on epoch=32
05/17/2022 18:30:56 - INFO - __main__ - Global step 450 Train loss 1.56 Classification-F1 0.07826827617962007 on epoch=32
05/17/2022 18:30:56 - INFO - __main__ - Saving model with best Classification-F1: 0.04309644806539216 -> 0.07826827617962007 on epoch=32, global_step=450
05/17/2022 18:30:57 - INFO - __main__ - Step 460 Global step 460 Train loss 1.48 on epoch=32
05/17/2022 18:30:58 - INFO - __main__ - Step 470 Global step 470 Train loss 1.42 on epoch=33
05/17/2022 18:31:00 - INFO - __main__ - Step 480 Global step 480 Train loss 1.44 on epoch=34
05/17/2022 18:31:01 - INFO - __main__ - Step 490 Global step 490 Train loss 1.41 on epoch=34
05/17/2022 18:31:02 - INFO - __main__ - Step 500 Global step 500 Train loss 1.39 on epoch=35
05/17/2022 18:31:05 - INFO - __main__ - Global step 500 Train loss 1.43 Classification-F1 0.03487188872310663 on epoch=35
05/17/2022 18:31:07 - INFO - __main__ - Step 510 Global step 510 Train loss 1.45 on epoch=36
05/17/2022 18:31:08 - INFO - __main__ - Step 520 Global step 520 Train loss 1.40 on epoch=37
05/17/2022 18:31:09 - INFO - __main__ - Step 530 Global step 530 Train loss 1.42 on epoch=37
05/17/2022 18:31:10 - INFO - __main__ - Step 540 Global step 540 Train loss 1.35 on epoch=38
05/17/2022 18:31:12 - INFO - __main__ - Step 550 Global step 550 Train loss 1.22 on epoch=39
05/17/2022 18:31:15 - INFO - __main__ - Global step 550 Train loss 1.37 Classification-F1 0.061327336609948345 on epoch=39
05/17/2022 18:31:16 - INFO - __main__ - Step 560 Global step 560 Train loss 1.34 on epoch=39
05/17/2022 18:31:17 - INFO - __main__ - Step 570 Global step 570 Train loss 1.35 on epoch=40
05/17/2022 18:31:19 - INFO - __main__ - Step 580 Global step 580 Train loss 1.27 on epoch=41
05/17/2022 18:31:20 - INFO - __main__ - Step 590 Global step 590 Train loss 1.29 on epoch=42
05/17/2022 18:31:21 - INFO - __main__ - Step 600 Global step 600 Train loss 1.20 on epoch=42
05/17/2022 18:31:24 - INFO - __main__ - Global step 600 Train loss 1.29 Classification-F1 0.07899773584383592 on epoch=42
05/17/2022 18:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.07826827617962007 -> 0.07899773584383592 on epoch=42, global_step=600
05/17/2022 18:31:26 - INFO - __main__ - Step 610 Global step 610 Train loss 1.29 on epoch=43
05/17/2022 18:31:27 - INFO - __main__ - Step 620 Global step 620 Train loss 1.19 on epoch=44
05/17/2022 18:31:28 - INFO - __main__ - Step 630 Global step 630 Train loss 1.21 on epoch=44
05/17/2022 18:31:29 - INFO - __main__ - Step 640 Global step 640 Train loss 1.24 on epoch=45
05/17/2022 18:31:31 - INFO - __main__ - Step 650 Global step 650 Train loss 1.25 on epoch=46
05/17/2022 18:31:34 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.13331495319683048 on epoch=46
05/17/2022 18:31:34 - INFO - __main__ - Saving model with best Classification-F1: 0.07899773584383592 -> 0.13331495319683048 on epoch=46, global_step=650
05/17/2022 18:31:35 - INFO - __main__ - Step 660 Global step 660 Train loss 1.30 on epoch=47
05/17/2022 18:31:37 - INFO - __main__ - Step 670 Global step 670 Train loss 1.14 on epoch=47
05/17/2022 18:31:38 - INFO - __main__ - Step 680 Global step 680 Train loss 1.19 on epoch=48
05/17/2022 18:31:39 - INFO - __main__ - Step 690 Global step 690 Train loss 1.08 on epoch=49
05/17/2022 18:31:40 - INFO - __main__ - Step 700 Global step 700 Train loss 1.19 on epoch=49
05/17/2022 18:31:44 - INFO - __main__ - Global step 700 Train loss 1.18 Classification-F1 0.14212667799352308 on epoch=49
05/17/2022 18:31:44 - INFO - __main__ - Saving model with best Classification-F1: 0.13331495319683048 -> 0.14212667799352308 on epoch=49, global_step=700
05/17/2022 18:31:45 - INFO - __main__ - Step 710 Global step 710 Train loss 1.18 on epoch=50
05/17/2022 18:31:46 - INFO - __main__ - Step 720 Global step 720 Train loss 1.19 on epoch=51
05/17/2022 18:31:47 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/17/2022 18:31:49 - INFO - __main__ - Step 740 Global step 740 Train loss 1.17 on epoch=52
05/17/2022 18:31:50 - INFO - __main__ - Step 750 Global step 750 Train loss 1.21 on epoch=53
05/17/2022 18:31:53 - INFO - __main__ - Global step 750 Train loss 1.17 Classification-F1 0.16906558744591985 on epoch=53
05/17/2022 18:31:53 - INFO - __main__ - Saving model with best Classification-F1: 0.14212667799352308 -> 0.16906558744591985 on epoch=53, global_step=750
05/17/2022 18:31:55 - INFO - __main__ - Step 760 Global step 760 Train loss 1.07 on epoch=54
05/17/2022 18:31:56 - INFO - __main__ - Step 770 Global step 770 Train loss 1.17 on epoch=54
05/17/2022 18:31:57 - INFO - __main__ - Step 780 Global step 780 Train loss 1.20 on epoch=55
05/17/2022 18:31:58 - INFO - __main__ - Step 790 Global step 790 Train loss 1.16 on epoch=56
05/17/2022 18:32:00 - INFO - __main__ - Step 800 Global step 800 Train loss 1.06 on epoch=57
05/17/2022 18:32:03 - INFO - __main__ - Global step 800 Train loss 1.13 Classification-F1 0.24929134367264796 on epoch=57
05/17/2022 18:32:03 - INFO - __main__ - Saving model with best Classification-F1: 0.16906558744591985 -> 0.24929134367264796 on epoch=57, global_step=800
05/17/2022 18:32:04 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=57
05/17/2022 18:32:05 - INFO - __main__ - Step 820 Global step 820 Train loss 1.06 on epoch=58
05/17/2022 18:32:07 - INFO - __main__ - Step 830 Global step 830 Train loss 1.06 on epoch=59
05/17/2022 18:32:08 - INFO - __main__ - Step 840 Global step 840 Train loss 1.12 on epoch=59
05/17/2022 18:32:09 - INFO - __main__ - Step 850 Global step 850 Train loss 1.11 on epoch=60
05/17/2022 18:32:13 - INFO - __main__ - Global step 850 Train loss 1.09 Classification-F1 0.30456822002346423 on epoch=60
05/17/2022 18:32:13 - INFO - __main__ - Saving model with best Classification-F1: 0.24929134367264796 -> 0.30456822002346423 on epoch=60, global_step=850
05/17/2022 18:32:14 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=61
05/17/2022 18:32:16 - INFO - __main__ - Step 870 Global step 870 Train loss 1.09 on epoch=62
05/17/2022 18:32:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.96 on epoch=62
05/17/2022 18:32:18 - INFO - __main__ - Step 890 Global step 890 Train loss 1.11 on epoch=63
05/17/2022 18:32:19 - INFO - __main__ - Step 900 Global step 900 Train loss 1.06 on epoch=64
05/17/2022 18:32:23 - INFO - __main__ - Global step 900 Train loss 1.06 Classification-F1 0.35131702187264585 on epoch=64
05/17/2022 18:32:23 - INFO - __main__ - Saving model with best Classification-F1: 0.30456822002346423 -> 0.35131702187264585 on epoch=64, global_step=900
05/17/2022 18:32:24 - INFO - __main__ - Step 910 Global step 910 Train loss 1.06 on epoch=64
05/17/2022 18:32:26 - INFO - __main__ - Step 920 Global step 920 Train loss 1.00 on epoch=65
05/17/2022 18:32:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.98 on epoch=66
05/17/2022 18:32:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.98 on epoch=67
05/17/2022 18:32:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.95 on epoch=67
05/17/2022 18:32:33 - INFO - __main__ - Global step 950 Train loss 0.99 Classification-F1 0.4101250300979744 on epoch=67
05/17/2022 18:32:33 - INFO - __main__ - Saving model with best Classification-F1: 0.35131702187264585 -> 0.4101250300979744 on epoch=67, global_step=950
05/17/2022 18:32:35 - INFO - __main__ - Step 960 Global step 960 Train loss 1.01 on epoch=68
05/17/2022 18:32:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.95 on epoch=69
05/17/2022 18:32:37 - INFO - __main__ - Step 980 Global step 980 Train loss 0.97 on epoch=69
05/17/2022 18:32:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.89 on epoch=70
05/17/2022 18:32:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.03 on epoch=71
05/17/2022 18:32:44 - INFO - __main__ - Global step 1000 Train loss 0.97 Classification-F1 0.456588069954116 on epoch=71
05/17/2022 18:32:44 - INFO - __main__ - Saving model with best Classification-F1: 0.4101250300979744 -> 0.456588069954116 on epoch=71, global_step=1000
05/17/2022 18:32:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.02 on epoch=72
05/17/2022 18:32:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.92 on epoch=72
05/17/2022 18:32:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.93 on epoch=73
05/17/2022 18:32:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.94 on epoch=74
05/17/2022 18:32:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.95 on epoch=74
05/17/2022 18:32:55 - INFO - __main__ - Global step 1050 Train loss 0.95 Classification-F1 0.47919324019441867 on epoch=74
05/17/2022 18:32:55 - INFO - __main__ - Saving model with best Classification-F1: 0.456588069954116 -> 0.47919324019441867 on epoch=74, global_step=1050
05/17/2022 18:32:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.03 on epoch=75
05/17/2022 18:32:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.01 on epoch=76
05/17/2022 18:32:58 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.91 on epoch=77
05/17/2022 18:33:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.86 on epoch=77
05/17/2022 18:33:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.92 on epoch=78
05/17/2022 18:33:05 - INFO - __main__ - Global step 1100 Train loss 0.95 Classification-F1 0.47343967718990726 on epoch=78
05/17/2022 18:33:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.87 on epoch=79
05/17/2022 18:33:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/17/2022 18:33:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.90 on epoch=80
05/17/2022 18:33:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.93 on epoch=81
05/17/2022 18:33:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.88 on epoch=82
05/17/2022 18:33:15 - INFO - __main__ - Global step 1150 Train loss 0.91 Classification-F1 0.43130726106502343 on epoch=82
05/17/2022 18:33:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.89 on epoch=82
05/17/2022 18:33:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.93 on epoch=83
05/17/2022 18:33:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.84 on epoch=84
05/17/2022 18:33:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.86 on epoch=84
05/17/2022 18:33:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.92 on epoch=85
05/17/2022 18:33:25 - INFO - __main__ - Global step 1200 Train loss 0.89 Classification-F1 0.40266052258739754 on epoch=85
05/17/2022 18:33:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.97 on epoch=86
05/17/2022 18:33:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.86 on epoch=87
05/17/2022 18:33:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.75 on epoch=87
05/17/2022 18:33:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.79 on epoch=88
05/17/2022 18:33:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.89 on epoch=89
05/17/2022 18:33:36 - INFO - __main__ - Global step 1250 Train loss 0.85 Classification-F1 0.40548807376391255 on epoch=89
05/17/2022 18:33:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.93 on epoch=89
05/17/2022 18:33:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.89 on epoch=90
05/17/2022 18:33:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.84 on epoch=91
05/17/2022 18:33:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.80 on epoch=92
05/17/2022 18:33:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.75 on epoch=92
05/17/2022 18:33:46 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.366030039447711 on epoch=92
05/17/2022 18:33:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.80 on epoch=93
05/17/2022 18:33:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.74 on epoch=94
05/17/2022 18:33:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.87 on epoch=94
05/17/2022 18:33:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.84 on epoch=95
05/17/2022 18:33:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.77 on epoch=96
05/17/2022 18:33:56 - INFO - __main__ - Global step 1350 Train loss 0.80 Classification-F1 0.3681833528180866 on epoch=96
05/17/2022 18:33:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.80 on epoch=97
05/17/2022 18:33:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.76 on epoch=97
05/17/2022 18:34:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.87 on epoch=98
05/17/2022 18:34:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.77 on epoch=99
05/17/2022 18:34:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.82 on epoch=99
05/17/2022 18:34:06 - INFO - __main__ - Global step 1400 Train loss 0.80 Classification-F1 0.41386811779126775 on epoch=99
05/17/2022 18:34:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.84 on epoch=100
05/17/2022 18:34:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.88 on epoch=101
05/17/2022 18:34:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.82 on epoch=102
05/17/2022 18:34:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.73 on epoch=102
05/17/2022 18:34:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.79 on epoch=103
05/17/2022 18:34:16 - INFO - __main__ - Global step 1450 Train loss 0.81 Classification-F1 0.3839908109426604 on epoch=103
05/17/2022 18:34:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.75 on epoch=104
05/17/2022 18:34:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.79 on epoch=104
05/17/2022 18:34:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.84 on epoch=105
05/17/2022 18:34:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.80 on epoch=106
05/17/2022 18:34:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.78 on epoch=107
05/17/2022 18:34:26 - INFO - __main__ - Global step 1500 Train loss 0.79 Classification-F1 0.3912747357747128 on epoch=107
05/17/2022 18:34:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.75 on epoch=107
05/17/2022 18:34:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.80 on epoch=108
05/17/2022 18:34:30 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.82 on epoch=109
05/17/2022 18:34:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.67 on epoch=109
05/17/2022 18:34:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.70 on epoch=110
05/17/2022 18:34:36 - INFO - __main__ - Global step 1550 Train loss 0.75 Classification-F1 0.4246924225563416 on epoch=110
05/17/2022 18:34:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.82 on epoch=111
05/17/2022 18:34:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.75 on epoch=112
05/17/2022 18:34:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.69 on epoch=112
05/17/2022 18:34:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.74 on epoch=113
05/17/2022 18:34:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.76 on epoch=114
05/17/2022 18:34:46 - INFO - __main__ - Global step 1600 Train loss 0.75 Classification-F1 0.41851569066784816 on epoch=114
05/17/2022 18:34:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.78 on epoch=114
05/17/2022 18:34:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.78 on epoch=115
05/17/2022 18:34:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.82 on epoch=116
05/17/2022 18:34:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.80 on epoch=117
05/17/2022 18:34:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.65 on epoch=117
05/17/2022 18:34:56 - INFO - __main__ - Global step 1650 Train loss 0.77 Classification-F1 0.4055750832065744 on epoch=117
05/17/2022 18:34:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.83 on epoch=118
05/17/2022 18:34:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.72 on epoch=119
05/17/2022 18:35:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/17/2022 18:35:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.68 on epoch=120
05/17/2022 18:35:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.76 on epoch=121
05/17/2022 18:35:06 - INFO - __main__ - Global step 1700 Train loss 0.76 Classification-F1 0.3854818856418984 on epoch=121
05/17/2022 18:35:08 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.77 on epoch=122
05/17/2022 18:35:09 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.75 on epoch=122
05/17/2022 18:35:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.70 on epoch=123
05/17/2022 18:35:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.73 on epoch=124
05/17/2022 18:35:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.83 on epoch=124
05/17/2022 18:35:16 - INFO - __main__ - Global step 1750 Train loss 0.75 Classification-F1 0.37066543016420694 on epoch=124
05/17/2022 18:35:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/17/2022 18:35:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.74 on epoch=126
05/17/2022 18:35:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.71 on epoch=127
05/17/2022 18:35:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.68 on epoch=127
05/17/2022 18:35:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.69 on epoch=128
05/17/2022 18:35:26 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.43132548947766347 on epoch=128
05/17/2022 18:35:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.72 on epoch=129
05/17/2022 18:35:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.80 on epoch=129
05/17/2022 18:35:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.62 on epoch=130
05/17/2022 18:35:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.67 on epoch=131
05/17/2022 18:35:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.77 on epoch=132
05/17/2022 18:35:36 - INFO - __main__ - Global step 1850 Train loss 0.72 Classification-F1 0.39239213117090355 on epoch=132
05/17/2022 18:35:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/17/2022 18:35:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.75 on epoch=133
05/17/2022 18:35:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.71 on epoch=134
05/17/2022 18:35:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.73 on epoch=134
05/17/2022 18:35:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.68 on epoch=135
05/17/2022 18:35:46 - INFO - __main__ - Global step 1900 Train loss 0.70 Classification-F1 0.4241063681150352 on epoch=135
05/17/2022 18:35:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.67 on epoch=136
05/17/2022 18:35:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/17/2022 18:35:50 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.65 on epoch=137
05/17/2022 18:35:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.65 on epoch=138
05/17/2022 18:35:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.75 on epoch=139
05/17/2022 18:35:57 - INFO - __main__ - Global step 1950 Train loss 0.68 Classification-F1 0.4457470747661885 on epoch=139
05/17/2022 18:35:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.61 on epoch=139
05/17/2022 18:35:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.61 on epoch=140
05/17/2022 18:36:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.68 on epoch=141
05/17/2022 18:36:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.73 on epoch=142
05/17/2022 18:36:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.74 on epoch=142
05/17/2022 18:36:06 - INFO - __main__ - Global step 2000 Train loss 0.67 Classification-F1 0.4495267826237229 on epoch=142
05/17/2022 18:36:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.76 on epoch=143
05/17/2022 18:36:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.67 on epoch=144
05/17/2022 18:36:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.79 on epoch=144
05/17/2022 18:36:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.66 on epoch=145
05/17/2022 18:36:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.66 on epoch=146
05/17/2022 18:36:17 - INFO - __main__ - Global step 2050 Train loss 0.71 Classification-F1 0.4400233348279832 on epoch=146
05/17/2022 18:36:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.71 on epoch=147
05/17/2022 18:36:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.63 on epoch=147
05/17/2022 18:36:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.72 on epoch=148
05/17/2022 18:36:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.63 on epoch=149
05/17/2022 18:36:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.67 on epoch=149
05/17/2022 18:36:27 - INFO - __main__ - Global step 2100 Train loss 0.67 Classification-F1 0.4952540229869061 on epoch=149
05/17/2022 18:36:27 - INFO - __main__ - Saving model with best Classification-F1: 0.47919324019441867 -> 0.4952540229869061 on epoch=149, global_step=2100
05/17/2022 18:36:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.64 on epoch=150
05/17/2022 18:36:29 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/17/2022 18:36:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.63 on epoch=152
05/17/2022 18:36:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.60 on epoch=152
05/17/2022 18:36:33 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.67 on epoch=153
05/17/2022 18:36:37 - INFO - __main__ - Global step 2150 Train loss 0.64 Classification-F1 0.5393649860244972 on epoch=153
05/17/2022 18:36:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4952540229869061 -> 0.5393649860244972 on epoch=153, global_step=2150
05/17/2022 18:36:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.64 on epoch=154
05/17/2022 18:36:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.62 on epoch=154
05/17/2022 18:36:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.68 on epoch=155
05/17/2022 18:36:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.64 on epoch=156
05/17/2022 18:36:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.66 on epoch=157
05/17/2022 18:36:47 - INFO - __main__ - Global step 2200 Train loss 0.65 Classification-F1 0.4858707259698933 on epoch=157
05/17/2022 18:36:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.66 on epoch=157
05/17/2022 18:36:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.60 on epoch=158
05/17/2022 18:36:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.59 on epoch=159
05/17/2022 18:36:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.68 on epoch=159
05/17/2022 18:36:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.61 on epoch=160
05/17/2022 18:36:57 - INFO - __main__ - Global step 2250 Train loss 0.63 Classification-F1 0.5264624203052217 on epoch=160
05/17/2022 18:36:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.66 on epoch=161
05/17/2022 18:37:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.74 on epoch=162
05/17/2022 18:37:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.58 on epoch=162
05/17/2022 18:37:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.65 on epoch=163
05/17/2022 18:37:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.62 on epoch=164
05/17/2022 18:37:07 - INFO - __main__ - Global step 2300 Train loss 0.65 Classification-F1 0.5824887321991088 on epoch=164
05/17/2022 18:37:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5393649860244972 -> 0.5824887321991088 on epoch=164, global_step=2300
05/17/2022 18:37:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.60 on epoch=164
05/17/2022 18:37:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.66 on epoch=165
05/17/2022 18:37:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.61 on epoch=166
05/17/2022 18:37:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.62 on epoch=167
05/17/2022 18:37:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.66 on epoch=167
05/17/2022 18:37:17 - INFO - __main__ - Global step 2350 Train loss 0.63 Classification-F1 0.4958570029301608 on epoch=167
05/17/2022 18:37:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.62 on epoch=168
05/17/2022 18:37:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/17/2022 18:37:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.59 on epoch=169
05/17/2022 18:37:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.72 on epoch=170
05/17/2022 18:37:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.64 on epoch=171
05/17/2022 18:37:27 - INFO - __main__ - Global step 2400 Train loss 0.66 Classification-F1 0.5097427830917706 on epoch=171
05/17/2022 18:37:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.64 on epoch=172
05/17/2022 18:37:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.60 on epoch=172
05/17/2022 18:37:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.68 on epoch=173
05/17/2022 18:37:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.54 on epoch=174
05/17/2022 18:37:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.60 on epoch=174
05/17/2022 18:37:37 - INFO - __main__ - Global step 2450 Train loss 0.61 Classification-F1 0.5188916602411094 on epoch=174
05/17/2022 18:37:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.65 on epoch=175
05/17/2022 18:37:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.66 on epoch=176
05/17/2022 18:37:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.65 on epoch=177
05/17/2022 18:37:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.64 on epoch=177
05/17/2022 18:37:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.56 on epoch=178
05/17/2022 18:37:48 - INFO - __main__ - Global step 2500 Train loss 0.63 Classification-F1 0.5475319963698936 on epoch=178
05/17/2022 18:37:49 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.62 on epoch=179
05/17/2022 18:37:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.61 on epoch=179
05/17/2022 18:37:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.62 on epoch=180
05/17/2022 18:37:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.62 on epoch=181
05/17/2022 18:37:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.66 on epoch=182
05/17/2022 18:37:58 - INFO - __main__ - Global step 2550 Train loss 0.63 Classification-F1 0.5123070978560996 on epoch=182
05/17/2022 18:37:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.62 on epoch=182
05/17/2022 18:38:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.66 on epoch=183
05/17/2022 18:38:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.56 on epoch=184
05/17/2022 18:38:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.54 on epoch=184
05/17/2022 18:38:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.55 on epoch=185
05/17/2022 18:38:08 - INFO - __main__ - Global step 2600 Train loss 0.59 Classification-F1 0.49804322564971654 on epoch=185
05/17/2022 18:38:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.59 on epoch=186
05/17/2022 18:38:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.61 on epoch=187
05/17/2022 18:38:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.53 on epoch=187
05/17/2022 18:38:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.65 on epoch=188
05/17/2022 18:38:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.54 on epoch=189
05/17/2022 18:38:19 - INFO - __main__ - Global step 2650 Train loss 0.59 Classification-F1 0.5600636077664599 on epoch=189
05/17/2022 18:38:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.61 on epoch=189
05/17/2022 18:38:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.64 on epoch=190
05/17/2022 18:38:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.56 on epoch=191
05/17/2022 18:38:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.67 on epoch=192
05/17/2022 18:38:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.65 on epoch=192
05/17/2022 18:38:29 - INFO - __main__ - Global step 2700 Train loss 0.63 Classification-F1 0.5541726924343412 on epoch=192
05/17/2022 18:38:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.61 on epoch=193
05/17/2022 18:38:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.70 on epoch=194
05/17/2022 18:38:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.60 on epoch=194
05/17/2022 18:38:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.65 on epoch=195
05/17/2022 18:38:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.62 on epoch=196
05/17/2022 18:38:40 - INFO - __main__ - Global step 2750 Train loss 0.64 Classification-F1 0.5936413465228644 on epoch=196
05/17/2022 18:38:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5824887321991088 -> 0.5936413465228644 on epoch=196, global_step=2750
05/17/2022 18:38:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.72 on epoch=197
05/17/2022 18:38:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.60 on epoch=197
05/17/2022 18:38:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.62 on epoch=198
05/17/2022 18:38:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.55 on epoch=199
05/17/2022 18:38:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.59 on epoch=199
05/17/2022 18:38:50 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.6126826037831731 on epoch=199
05/17/2022 18:38:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5936413465228644 -> 0.6126826037831731 on epoch=199, global_step=2800
05/17/2022 18:38:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.57 on epoch=200
05/17/2022 18:38:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.66 on epoch=201
05/17/2022 18:38:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.63 on epoch=202
05/17/2022 18:38:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/17/2022 18:38:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.64 on epoch=203
05/17/2022 18:39:00 - INFO - __main__ - Global step 2850 Train loss 0.62 Classification-F1 0.6015875477335924 on epoch=203
05/17/2022 18:39:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.66 on epoch=204
05/17/2022 18:39:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/17/2022 18:39:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.56 on epoch=205
05/17/2022 18:39:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.61 on epoch=206
05/17/2022 18:39:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.65 on epoch=207
05/17/2022 18:39:11 - INFO - __main__ - Global step 2900 Train loss 0.62 Classification-F1 0.6037594944731524 on epoch=207
05/17/2022 18:39:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.58 on epoch=207
05/17/2022 18:39:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.64 on epoch=208
05/17/2022 18:39:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.60 on epoch=209
05/17/2022 18:39:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.55 on epoch=209
05/17/2022 18:39:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/17/2022 18:39:21 - INFO - __main__ - Global step 2950 Train loss 0.59 Classification-F1 0.6206961504867482 on epoch=210
05/17/2022 18:39:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6126826037831731 -> 0.6206961504867482 on epoch=210, global_step=2950
05/17/2022 18:39:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.64 on epoch=211
05/17/2022 18:39:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/17/2022 18:39:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.61 on epoch=212
05/17/2022 18:39:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.58 on epoch=213
05/17/2022 18:39:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.58 on epoch=214
05/17/2022 18:39:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:39:29 - INFO - __main__ - Printing 3 examples
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:39:29 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:39:29 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:39:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:39:29 - INFO - __main__ - Printing 3 examples
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:39:29 - INFO - __main__ - ['Animal']
05/17/2022 18:39:29 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:39:29 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:39:30 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:39:32 - INFO - __main__ - Global step 3000 Train loss 0.61 Classification-F1 0.5825785720986958 on epoch=214
05/17/2022 18:39:32 - INFO - __main__ - save last model!
05/17/2022 18:39:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 18:39:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 18:39:32 - INFO - __main__ - Printing 3 examples
05/17/2022 18:39:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 18:39:32 - INFO - __main__ - ['Animal']
05/17/2022 18:39:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 18:39:32 - INFO - __main__ - ['Animal']
05/17/2022 18:39:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 18:39:32 - INFO - __main__ - ['Village']
05/17/2022 18:39:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:39:34 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:39:35 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:39:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:39:35 - INFO - __main__ - Starting training!
05/17/2022 18:39:37 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 18:40:51 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/17/2022 18:40:51 - INFO - __main__ - Classification-F1 on test data: 0.2656
05/17/2022 18:40:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.6206961504867482, test_performance=0.2655662030944191
05/17/2022 18:40:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/17/2022 18:40:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:40:52 - INFO - __main__ - Printing 3 examples
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:40:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:40:52 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:40:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:40:52 - INFO - __main__ - Printing 3 examples
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:40:52 - INFO - __main__ - ['Animal']
05/17/2022 18:40:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:40:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:40:52 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:40:58 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:40:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:40:59 - INFO - __main__ - Starting training!
05/17/2022 18:41:00 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/17/2022 18:41:02 - INFO - __main__ - Step 20 Global step 20 Train loss 7.12 on epoch=1
05/17/2022 18:41:03 - INFO - __main__ - Step 30 Global step 30 Train loss 6.31 on epoch=2
05/17/2022 18:41:05 - INFO - __main__ - Step 40 Global step 40 Train loss 6.09 on epoch=2
05/17/2022 18:41:06 - INFO - __main__ - Step 50 Global step 50 Train loss 5.98 on epoch=3
05/17/2022 18:41:09 - INFO - __main__ - Global step 50 Train loss 6.62 Classification-F1 0.0 on epoch=3
05/17/2022 18:41:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 18:41:10 - INFO - __main__ - Step 60 Global step 60 Train loss 5.38 on epoch=4
05/17/2022 18:41:12 - INFO - __main__ - Step 70 Global step 70 Train loss 5.10 on epoch=4
05/17/2022 18:41:13 - INFO - __main__ - Step 80 Global step 80 Train loss 4.84 on epoch=5
05/17/2022 18:41:15 - INFO - __main__ - Step 90 Global step 90 Train loss 4.61 on epoch=6
05/17/2022 18:41:16 - INFO - __main__ - Step 100 Global step 100 Train loss 4.36 on epoch=7
05/17/2022 18:41:19 - INFO - __main__ - Global step 100 Train loss 4.86 Classification-F1 0.0 on epoch=7
05/17/2022 18:41:20 - INFO - __main__ - Step 110 Global step 110 Train loss 4.21 on epoch=7
05/17/2022 18:41:22 - INFO - __main__ - Step 120 Global step 120 Train loss 4.11 on epoch=8
05/17/2022 18:41:23 - INFO - __main__ - Step 130 Global step 130 Train loss 4.08 on epoch=9
05/17/2022 18:41:24 - INFO - __main__ - Step 140 Global step 140 Train loss 3.62 on epoch=9
05/17/2022 18:41:25 - INFO - __main__ - Step 150 Global step 150 Train loss 3.71 on epoch=10
05/17/2022 18:41:29 - INFO - __main__ - Global step 150 Train loss 3.95 Classification-F1 0.0 on epoch=10
05/17/2022 18:41:30 - INFO - __main__ - Step 160 Global step 160 Train loss 3.68 on epoch=11
05/17/2022 18:41:31 - INFO - __main__ - Step 170 Global step 170 Train loss 3.41 on epoch=12
05/17/2022 18:41:32 - INFO - __main__ - Step 180 Global step 180 Train loss 3.25 on epoch=12
05/17/2022 18:41:34 - INFO - __main__ - Step 190 Global step 190 Train loss 3.22 on epoch=13
05/17/2022 18:41:35 - INFO - __main__ - Step 200 Global step 200 Train loss 3.00 on epoch=14
05/17/2022 18:41:38 - INFO - __main__ - Global step 200 Train loss 3.31 Classification-F1 0.002588996763754045 on epoch=14
05/17/2022 18:41:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.002588996763754045 on epoch=14, global_step=200
05/17/2022 18:41:39 - INFO - __main__ - Step 210 Global step 210 Train loss 3.00 on epoch=14
05/17/2022 18:41:40 - INFO - __main__ - Step 220 Global step 220 Train loss 3.00 on epoch=15
05/17/2022 18:41:41 - INFO - __main__ - Step 230 Global step 230 Train loss 3.02 on epoch=16
05/17/2022 18:41:43 - INFO - __main__ - Step 240 Global step 240 Train loss 2.78 on epoch=17
05/17/2022 18:41:44 - INFO - __main__ - Step 250 Global step 250 Train loss 2.72 on epoch=17
05/17/2022 18:41:46 - INFO - __main__ - Global step 250 Train loss 2.90 Classification-F1 0.010509031198686371 on epoch=17
05/17/2022 18:41:46 - INFO - __main__ - Saving model with best Classification-F1: 0.002588996763754045 -> 0.010509031198686371 on epoch=17, global_step=250
05/17/2022 18:41:47 - INFO - __main__ - Step 260 Global step 260 Train loss 2.71 on epoch=18
05/17/2022 18:41:49 - INFO - __main__ - Step 270 Global step 270 Train loss 2.56 on epoch=19
05/17/2022 18:41:50 - INFO - __main__ - Step 280 Global step 280 Train loss 2.56 on epoch=19
05/17/2022 18:41:51 - INFO - __main__ - Step 290 Global step 290 Train loss 2.48 on epoch=20
05/17/2022 18:41:52 - INFO - __main__ - Step 300 Global step 300 Train loss 2.48 on epoch=21
05/17/2022 18:41:54 - INFO - __main__ - Global step 300 Train loss 2.56 Classification-F1 0.009523809523809523 on epoch=21
05/17/2022 18:41:55 - INFO - __main__ - Step 310 Global step 310 Train loss 2.30 on epoch=22
05/17/2022 18:41:57 - INFO - __main__ - Step 320 Global step 320 Train loss 2.29 on epoch=22
05/17/2022 18:41:58 - INFO - __main__ - Step 330 Global step 330 Train loss 2.36 on epoch=23
05/17/2022 18:41:59 - INFO - __main__ - Step 340 Global step 340 Train loss 2.22 on epoch=24
05/17/2022 18:42:00 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/17/2022 18:42:02 - INFO - __main__ - Global step 350 Train loss 2.27 Classification-F1 0.009523809523809523 on epoch=24
05/17/2022 18:42:03 - INFO - __main__ - Step 360 Global step 360 Train loss 2.16 on epoch=25
05/17/2022 18:42:05 - INFO - __main__ - Step 370 Global step 370 Train loss 2.11 on epoch=26
05/17/2022 18:42:06 - INFO - __main__ - Step 380 Global step 380 Train loss 2.01 on epoch=27
05/17/2022 18:42:07 - INFO - __main__ - Step 390 Global step 390 Train loss 1.99 on epoch=27
05/17/2022 18:42:08 - INFO - __main__ - Step 400 Global step 400 Train loss 2.11 on epoch=28
05/17/2022 18:42:10 - INFO - __main__ - Global step 400 Train loss 2.07 Classification-F1 0.016828087167070217 on epoch=28
05/17/2022 18:42:10 - INFO - __main__ - Saving model with best Classification-F1: 0.010509031198686371 -> 0.016828087167070217 on epoch=28, global_step=400
05/17/2022 18:42:11 - INFO - __main__ - Step 410 Global step 410 Train loss 1.94 on epoch=29
05/17/2022 18:42:12 - INFO - __main__ - Step 420 Global step 420 Train loss 1.90 on epoch=29
05/17/2022 18:42:14 - INFO - __main__ - Step 430 Global step 430 Train loss 1.91 on epoch=30
05/17/2022 18:42:15 - INFO - __main__ - Step 440 Global step 440 Train loss 1.86 on epoch=31
05/17/2022 18:42:16 - INFO - __main__ - Step 450 Global step 450 Train loss 1.79 on epoch=32
05/17/2022 18:42:19 - INFO - __main__ - Global step 450 Train loss 1.88 Classification-F1 0.020833637288463804 on epoch=32
05/17/2022 18:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.016828087167070217 -> 0.020833637288463804 on epoch=32, global_step=450
05/17/2022 18:42:20 - INFO - __main__ - Step 460 Global step 460 Train loss 1.71 on epoch=32
05/17/2022 18:42:21 - INFO - __main__ - Step 470 Global step 470 Train loss 1.89 on epoch=33
05/17/2022 18:42:22 - INFO - __main__ - Step 480 Global step 480 Train loss 1.68 on epoch=34
05/17/2022 18:42:23 - INFO - __main__ - Step 490 Global step 490 Train loss 1.59 on epoch=34
05/17/2022 18:42:25 - INFO - __main__ - Step 500 Global step 500 Train loss 1.74 on epoch=35
05/17/2022 18:42:27 - INFO - __main__ - Global step 500 Train loss 1.72 Classification-F1 0.01196719651716108 on epoch=35
05/17/2022 18:42:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.70 on epoch=36
05/17/2022 18:42:30 - INFO - __main__ - Step 520 Global step 520 Train loss 1.60 on epoch=37
05/17/2022 18:42:31 - INFO - __main__ - Step 530 Global step 530 Train loss 1.49 on epoch=37
05/17/2022 18:42:32 - INFO - __main__ - Step 540 Global step 540 Train loss 1.56 on epoch=38
05/17/2022 18:42:33 - INFO - __main__ - Step 550 Global step 550 Train loss 1.56 on epoch=39
05/17/2022 18:42:36 - INFO - __main__ - Global step 550 Train loss 1.58 Classification-F1 0.029890744176458463 on epoch=39
05/17/2022 18:42:36 - INFO - __main__ - Saving model with best Classification-F1: 0.020833637288463804 -> 0.029890744176458463 on epoch=39, global_step=550
05/17/2022 18:42:37 - INFO - __main__ - Step 560 Global step 560 Train loss 1.73 on epoch=39
05/17/2022 18:42:38 - INFO - __main__ - Step 570 Global step 570 Train loss 1.53 on epoch=40
05/17/2022 18:42:39 - INFO - __main__ - Step 580 Global step 580 Train loss 1.49 on epoch=41
05/17/2022 18:42:41 - INFO - __main__ - Step 590 Global step 590 Train loss 1.52 on epoch=42
05/17/2022 18:42:42 - INFO - __main__ - Step 600 Global step 600 Train loss 1.50 on epoch=42
05/17/2022 18:42:44 - INFO - __main__ - Global step 600 Train loss 1.55 Classification-F1 0.05003562755275028 on epoch=42
05/17/2022 18:42:44 - INFO - __main__ - Saving model with best Classification-F1: 0.029890744176458463 -> 0.05003562755275028 on epoch=42, global_step=600
05/17/2022 18:42:45 - INFO - __main__ - Step 610 Global step 610 Train loss 1.49 on epoch=43
05/17/2022 18:42:47 - INFO - __main__ - Step 620 Global step 620 Train loss 1.44 on epoch=44
05/17/2022 18:42:48 - INFO - __main__ - Step 630 Global step 630 Train loss 1.52 on epoch=44
05/17/2022 18:42:49 - INFO - __main__ - Step 640 Global step 640 Train loss 1.50 on epoch=45
05/17/2022 18:42:50 - INFO - __main__ - Step 650 Global step 650 Train loss 1.30 on epoch=46
05/17/2022 18:42:53 - INFO - __main__ - Global step 650 Train loss 1.45 Classification-F1 0.031858198096087705 on epoch=46
05/17/2022 18:42:54 - INFO - __main__ - Step 660 Global step 660 Train loss 1.36 on epoch=47
05/17/2022 18:42:55 - INFO - __main__ - Step 670 Global step 670 Train loss 1.41 on epoch=47
05/17/2022 18:42:56 - INFO - __main__ - Step 680 Global step 680 Train loss 1.36 on epoch=48
05/17/2022 18:42:57 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=49
05/17/2022 18:42:59 - INFO - __main__ - Step 700 Global step 700 Train loss 1.37 on epoch=49
05/17/2022 18:43:01 - INFO - __main__ - Global step 700 Train loss 1.35 Classification-F1 0.04600419487038839 on epoch=49
05/17/2022 18:43:02 - INFO - __main__ - Step 710 Global step 710 Train loss 1.27 on epoch=50
05/17/2022 18:43:04 - INFO - __main__ - Step 720 Global step 720 Train loss 1.38 on epoch=51
05/17/2022 18:43:05 - INFO - __main__ - Step 730 Global step 730 Train loss 1.35 on epoch=52
05/17/2022 18:43:06 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=52
05/17/2022 18:43:07 - INFO - __main__ - Step 750 Global step 750 Train loss 1.35 on epoch=53
05/17/2022 18:43:10 - INFO - __main__ - Global step 750 Train loss 1.33 Classification-F1 0.06833992338194018 on epoch=53
05/17/2022 18:43:10 - INFO - __main__ - Saving model with best Classification-F1: 0.05003562755275028 -> 0.06833992338194018 on epoch=53, global_step=750
05/17/2022 18:43:11 - INFO - __main__ - Step 760 Global step 760 Train loss 1.19 on epoch=54
05/17/2022 18:43:12 - INFO - __main__ - Step 770 Global step 770 Train loss 1.29 on epoch=54
05/17/2022 18:43:13 - INFO - __main__ - Step 780 Global step 780 Train loss 1.30 on epoch=55
05/17/2022 18:43:15 - INFO - __main__ - Step 790 Global step 790 Train loss 1.30 on epoch=56
05/17/2022 18:43:16 - INFO - __main__ - Step 800 Global step 800 Train loss 1.23 on epoch=57
05/17/2022 18:43:18 - INFO - __main__ - Global step 800 Train loss 1.26 Classification-F1 0.04716400798592579 on epoch=57
05/17/2022 18:43:19 - INFO - __main__ - Step 810 Global step 810 Train loss 1.24 on epoch=57
05/17/2022 18:43:21 - INFO - __main__ - Step 820 Global step 820 Train loss 1.36 on epoch=58
05/17/2022 18:43:22 - INFO - __main__ - Step 830 Global step 830 Train loss 1.24 on epoch=59
05/17/2022 18:43:23 - INFO - __main__ - Step 840 Global step 840 Train loss 1.34 on epoch=59
05/17/2022 18:43:24 - INFO - __main__ - Step 850 Global step 850 Train loss 1.17 on epoch=60
05/17/2022 18:43:27 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.10194360748807454 on epoch=60
05/17/2022 18:43:27 - INFO - __main__ - Saving model with best Classification-F1: 0.06833992338194018 -> 0.10194360748807454 on epoch=60, global_step=850
05/17/2022 18:43:28 - INFO - __main__ - Step 860 Global step 860 Train loss 1.26 on epoch=61
05/17/2022 18:43:29 - INFO - __main__ - Step 870 Global step 870 Train loss 1.21 on epoch=62
05/17/2022 18:43:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.28 on epoch=62
05/17/2022 18:43:32 - INFO - __main__ - Step 890 Global step 890 Train loss 1.25 on epoch=63
05/17/2022 18:43:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.18 on epoch=64
05/17/2022 18:43:36 - INFO - __main__ - Global step 900 Train loss 1.24 Classification-F1 0.15839783039112884 on epoch=64
05/17/2022 18:43:36 - INFO - __main__ - Saving model with best Classification-F1: 0.10194360748807454 -> 0.15839783039112884 on epoch=64, global_step=900
05/17/2022 18:43:37 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=64
05/17/2022 18:43:38 - INFO - __main__ - Step 920 Global step 920 Train loss 1.24 on epoch=65
05/17/2022 18:43:39 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=66
05/17/2022 18:43:40 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=67
05/17/2022 18:43:42 - INFO - __main__ - Step 950 Global step 950 Train loss 1.23 on epoch=67
05/17/2022 18:43:44 - INFO - __main__ - Global step 950 Train loss 1.23 Classification-F1 0.22510255958546163 on epoch=67
05/17/2022 18:43:44 - INFO - __main__ - Saving model with best Classification-F1: 0.15839783039112884 -> 0.22510255958546163 on epoch=67, global_step=950
05/17/2022 18:43:46 - INFO - __main__ - Step 960 Global step 960 Train loss 1.25 on epoch=68
05/17/2022 18:43:47 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=69
05/17/2022 18:43:48 - INFO - __main__ - Step 980 Global step 980 Train loss 1.16 on epoch=69
05/17/2022 18:43:49 - INFO - __main__ - Step 990 Global step 990 Train loss 1.19 on epoch=70
05/17/2022 18:43:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.22 on epoch=71
05/17/2022 18:43:53 - INFO - __main__ - Global step 1000 Train loss 1.20 Classification-F1 0.24081254093637186 on epoch=71
05/17/2022 18:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.22510255958546163 -> 0.24081254093637186 on epoch=71, global_step=1000
05/17/2022 18:43:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.22 on epoch=72
05/17/2022 18:43:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=72
05/17/2022 18:43:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.22 on epoch=73
05/17/2022 18:43:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.09 on epoch=74
05/17/2022 18:44:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.18 on epoch=74
05/17/2022 18:44:03 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.19794558253319655 on epoch=74
05/17/2022 18:44:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.24 on epoch=75
05/17/2022 18:44:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=76
05/17/2022 18:44:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.13 on epoch=77
05/17/2022 18:44:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.19 on epoch=77
05/17/2022 18:44:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=78
05/17/2022 18:44:12 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.28217891310906107 on epoch=78
05/17/2022 18:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.24081254093637186 -> 0.28217891310906107 on epoch=78, global_step=1100
05/17/2022 18:44:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.18 on epoch=79
05/17/2022 18:44:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.15 on epoch=79
05/17/2022 18:44:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.16 on epoch=80
05/17/2022 18:44:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=81
05/17/2022 18:44:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.13 on epoch=82
05/17/2022 18:44:21 - INFO - __main__ - Global step 1150 Train loss 1.17 Classification-F1 0.3084193599238327 on epoch=82
05/17/2022 18:44:21 - INFO - __main__ - Saving model with best Classification-F1: 0.28217891310906107 -> 0.3084193599238327 on epoch=82, global_step=1150
05/17/2022 18:44:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.10 on epoch=82
05/17/2022 18:44:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.13 on epoch=83
05/17/2022 18:44:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.18 on epoch=84
05/17/2022 18:44:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.19 on epoch=84
05/17/2022 18:44:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.08 on epoch=85
05/17/2022 18:44:30 - INFO - __main__ - Global step 1200 Train loss 1.13 Classification-F1 0.24772580040641495 on epoch=85
05/17/2022 18:44:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=86
05/17/2022 18:44:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.10 on epoch=87
05/17/2022 18:44:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.12 on epoch=87
05/17/2022 18:44:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.08 on epoch=88
05/17/2022 18:44:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.11 on epoch=89
05/17/2022 18:44:39 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.3244081058752295 on epoch=89
05/17/2022 18:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3084193599238327 -> 0.3244081058752295 on epoch=89, global_step=1250
05/17/2022 18:44:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.13 on epoch=89
05/17/2022 18:44:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.10 on epoch=90
05/17/2022 18:44:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=91
05/17/2022 18:44:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.05 on epoch=92
05/17/2022 18:44:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=92
05/17/2022 18:44:48 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.3026272734763301 on epoch=92
05/17/2022 18:44:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.10 on epoch=93
05/17/2022 18:44:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.02 on epoch=94
05/17/2022 18:44:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.04 on epoch=94
05/17/2022 18:44:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.11 on epoch=95
05/17/2022 18:44:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=96
05/17/2022 18:44:57 - INFO - __main__ - Global step 1350 Train loss 1.08 Classification-F1 0.38615900000016407 on epoch=96
05/17/2022 18:44:57 - INFO - __main__ - Saving model with best Classification-F1: 0.3244081058752295 -> 0.38615900000016407 on epoch=96, global_step=1350
05/17/2022 18:44:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=97
05/17/2022 18:45:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=97
05/17/2022 18:45:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=98
05/17/2022 18:45:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.02 on epoch=99
05/17/2022 18:45:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.10 on epoch=99
05/17/2022 18:45:07 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.2945966559374147 on epoch=99
05/17/2022 18:45:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=100
05/17/2022 18:45:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.06 on epoch=101
05/17/2022 18:45:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.04 on epoch=102
05/17/2022 18:45:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.04 on epoch=102
05/17/2022 18:45:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=103
05/17/2022 18:45:16 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.38536839055483113 on epoch=103
05/17/2022 18:45:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.99 on epoch=104
05/17/2022 18:45:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.13 on epoch=104
05/17/2022 18:45:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.07 on epoch=105
05/17/2022 18:45:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.02 on epoch=106
05/17/2022 18:45:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.09 on epoch=107
05/17/2022 18:45:25 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.4352167964825921 on epoch=107
05/17/2022 18:45:25 - INFO - __main__ - Saving model with best Classification-F1: 0.38615900000016407 -> 0.4352167964825921 on epoch=107, global_step=1500
05/17/2022 18:45:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.93 on epoch=107
05/17/2022 18:45:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=108
05/17/2022 18:45:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.96 on epoch=109
05/17/2022 18:45:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=109
05/17/2022 18:45:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.00 on epoch=110
05/17/2022 18:45:35 - INFO - __main__ - Global step 1550 Train loss 0.98 Classification-F1 0.45133714354923715 on epoch=110
05/17/2022 18:45:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4352167964825921 -> 0.45133714354923715 on epoch=110, global_step=1550
05/17/2022 18:45:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.06 on epoch=111
05/17/2022 18:45:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.98 on epoch=112
05/17/2022 18:45:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=112
05/17/2022 18:45:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.03 on epoch=113
05/17/2022 18:45:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.95 on epoch=114
05/17/2022 18:45:44 - INFO - __main__ - Global step 1600 Train loss 1.00 Classification-F1 0.44848765390932854 on epoch=114
05/17/2022 18:45:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=114
05/17/2022 18:45:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=115
05/17/2022 18:45:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.05 on epoch=116
05/17/2022 18:45:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.03 on epoch=117
05/17/2022 18:45:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.90 on epoch=117
05/17/2022 18:45:54 - INFO - __main__ - Global step 1650 Train loss 1.00 Classification-F1 0.4160904020440013 on epoch=117
05/17/2022 18:45:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.93 on epoch=118
05/17/2022 18:45:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.90 on epoch=119
05/17/2022 18:45:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=119
05/17/2022 18:45:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=120
05/17/2022 18:46:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=121
05/17/2022 18:46:04 - INFO - __main__ - Global step 1700 Train loss 0.97 Classification-F1 0.4321265194582038 on epoch=121
05/17/2022 18:46:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.99 on epoch=122
05/17/2022 18:46:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.93 on epoch=122
05/17/2022 18:46:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.95 on epoch=123
05/17/2022 18:46:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.91 on epoch=124
05/17/2022 18:46:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=124
05/17/2022 18:46:13 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.4693252731313539 on epoch=124
05/17/2022 18:46:13 - INFO - __main__ - Saving model with best Classification-F1: 0.45133714354923715 -> 0.4693252731313539 on epoch=124, global_step=1750
05/17/2022 18:46:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=125
05/17/2022 18:46:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=126
05/17/2022 18:46:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.93 on epoch=127
05/17/2022 18:46:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.90 on epoch=127
05/17/2022 18:46:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=128
05/17/2022 18:46:23 - INFO - __main__ - Global step 1800 Train loss 0.93 Classification-F1 0.40048573158326434 on epoch=128
05/17/2022 18:46:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.90 on epoch=129
05/17/2022 18:46:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=129
05/17/2022 18:46:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.90 on epoch=130
05/17/2022 18:46:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=131
05/17/2022 18:46:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.94 on epoch=132
05/17/2022 18:46:32 - INFO - __main__ - Global step 1850 Train loss 0.97 Classification-F1 0.42247431068467334 on epoch=132
05/17/2022 18:46:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=132
05/17/2022 18:46:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.95 on epoch=133
05/17/2022 18:46:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=134
05/17/2022 18:46:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.90 on epoch=134
05/17/2022 18:46:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.93 on epoch=135
05/17/2022 18:46:42 - INFO - __main__ - Global step 1900 Train loss 0.94 Classification-F1 0.4410405162256907 on epoch=135
05/17/2022 18:46:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=136
05/17/2022 18:46:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=137
05/17/2022 18:46:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.02 on epoch=137
05/17/2022 18:46:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.95 on epoch=138
05/17/2022 18:46:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.93 on epoch=139
05/17/2022 18:46:52 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.44553645385086593 on epoch=139
05/17/2022 18:46:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=139
05/17/2022 18:46:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=140
05/17/2022 18:46:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=141
05/17/2022 18:46:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.94 on epoch=142
05/17/2022 18:46:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.89 on epoch=142
05/17/2022 18:47:02 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.5234964749910304 on epoch=142
05/17/2022 18:47:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4693252731313539 -> 0.5234964749910304 on epoch=142, global_step=2000
05/17/2022 18:47:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.87 on epoch=143
05/17/2022 18:47:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=144
05/17/2022 18:47:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=144
05/17/2022 18:47:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.97 on epoch=145
05/17/2022 18:47:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.89 on epoch=146
05/17/2022 18:47:11 - INFO - __main__ - Global step 2050 Train loss 0.94 Classification-F1 0.4901172331380159 on epoch=146
05/17/2022 18:47:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=147
05/17/2022 18:47:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.84 on epoch=147
05/17/2022 18:47:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.92 on epoch=148
05/17/2022 18:47:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.93 on epoch=149
05/17/2022 18:47:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.95 on epoch=149
05/17/2022 18:47:21 - INFO - __main__ - Global step 2100 Train loss 0.93 Classification-F1 0.4284721152776708 on epoch=149
05/17/2022 18:47:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.89 on epoch=150
05/17/2022 18:47:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=151
05/17/2022 18:47:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=152
05/17/2022 18:47:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.81 on epoch=152
05/17/2022 18:47:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.98 on epoch=153
05/17/2022 18:47:30 - INFO - __main__ - Global step 2150 Train loss 0.92 Classification-F1 0.41954848706064235 on epoch=153
05/17/2022 18:47:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.85 on epoch=154
05/17/2022 18:47:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=154
05/17/2022 18:47:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.93 on epoch=155
05/17/2022 18:47:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=156
05/17/2022 18:47:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.91 on epoch=157
05/17/2022 18:47:40 - INFO - __main__ - Global step 2200 Train loss 0.92 Classification-F1 0.41453420664222285 on epoch=157
05/17/2022 18:47:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.76 on epoch=157
05/17/2022 18:47:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.84 on epoch=158
05/17/2022 18:47:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.93 on epoch=159
05/17/2022 18:47:45 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.92 on epoch=159
05/17/2022 18:47:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.81 on epoch=160
05/17/2022 18:47:50 - INFO - __main__ - Global step 2250 Train loss 0.85 Classification-F1 0.4034057190881158 on epoch=160
05/17/2022 18:47:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.92 on epoch=161
05/17/2022 18:47:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.90 on epoch=162
05/17/2022 18:47:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.89 on epoch=162
05/17/2022 18:47:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.88 on epoch=163
05/17/2022 18:47:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.83 on epoch=164
05/17/2022 18:48:00 - INFO - __main__ - Global step 2300 Train loss 0.88 Classification-F1 0.5161942724218016 on epoch=164
05/17/2022 18:48:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.86 on epoch=164
05/17/2022 18:48:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.85 on epoch=165
05/17/2022 18:48:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=166
05/17/2022 18:48:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.81 on epoch=167
05/17/2022 18:48:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.82 on epoch=167
05/17/2022 18:48:10 - INFO - __main__ - Global step 2350 Train loss 0.86 Classification-F1 0.44529019786648033 on epoch=167
05/17/2022 18:48:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.94 on epoch=168
05/17/2022 18:48:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.87 on epoch=169
05/17/2022 18:48:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=169
05/17/2022 18:48:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.91 on epoch=170
05/17/2022 18:48:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=171
05/17/2022 18:48:20 - INFO - __main__ - Global step 2400 Train loss 0.91 Classification-F1 0.4201725168324829 on epoch=171
05/17/2022 18:48:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.79 on epoch=172
05/17/2022 18:48:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.81 on epoch=172
05/17/2022 18:48:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.90 on epoch=173
05/17/2022 18:48:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.82 on epoch=174
05/17/2022 18:48:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.85 on epoch=174
05/17/2022 18:48:29 - INFO - __main__ - Global step 2450 Train loss 0.83 Classification-F1 0.4456636840639611 on epoch=174
05/17/2022 18:48:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.88 on epoch=175
05/17/2022 18:48:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=176
05/17/2022 18:48:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.83 on epoch=177
05/17/2022 18:48:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.82 on epoch=177
05/17/2022 18:48:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.88 on epoch=178
05/17/2022 18:48:39 - INFO - __main__ - Global step 2500 Train loss 0.85 Classification-F1 0.4104894813622855 on epoch=178
05/17/2022 18:48:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.86 on epoch=179
05/17/2022 18:48:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.78 on epoch=179
05/17/2022 18:48:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.90 on epoch=180
05/17/2022 18:48:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=181
05/17/2022 18:48:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.82 on epoch=182
05/17/2022 18:48:49 - INFO - __main__ - Global step 2550 Train loss 0.85 Classification-F1 0.3628275957452159 on epoch=182
05/17/2022 18:48:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.84 on epoch=182
05/17/2022 18:48:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.80 on epoch=183
05/17/2022 18:48:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.89 on epoch=184
05/17/2022 18:48:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.86 on epoch=184
05/17/2022 18:48:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.78 on epoch=185
05/17/2022 18:48:59 - INFO - __main__ - Global step 2600 Train loss 0.83 Classification-F1 0.4019924525118885 on epoch=185
05/17/2022 18:49:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.81 on epoch=186
05/17/2022 18:49:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.81 on epoch=187
05/17/2022 18:49:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.92 on epoch=187
05/17/2022 18:49:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.79 on epoch=188
05/17/2022 18:49:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.78 on epoch=189
05/17/2022 18:49:09 - INFO - __main__ - Global step 2650 Train loss 0.82 Classification-F1 0.4551111892182133 on epoch=189
05/17/2022 18:49:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.81 on epoch=189
05/17/2022 18:49:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.79 on epoch=190
05/17/2022 18:49:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.88 on epoch=191
05/17/2022 18:49:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=192
05/17/2022 18:49:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.83 on epoch=192
05/17/2022 18:49:20 - INFO - __main__ - Global step 2700 Train loss 0.85 Classification-F1 0.4713447887289862 on epoch=192
05/17/2022 18:49:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.80 on epoch=193
05/17/2022 18:49:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.84 on epoch=194
05/17/2022 18:49:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.80 on epoch=194
05/17/2022 18:49:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.75 on epoch=195
05/17/2022 18:49:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.83 on epoch=196
05/17/2022 18:49:30 - INFO - __main__ - Global step 2750 Train loss 0.81 Classification-F1 0.42151938633145164 on epoch=196
05/17/2022 18:49:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.77 on epoch=197
05/17/2022 18:49:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.84 on epoch=197
05/17/2022 18:49:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.82 on epoch=198
05/17/2022 18:49:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.83 on epoch=199
05/17/2022 18:49:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.82 on epoch=199
05/17/2022 18:49:40 - INFO - __main__ - Global step 2800 Train loss 0.82 Classification-F1 0.40111263432040023 on epoch=199
05/17/2022 18:49:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.85 on epoch=200
05/17/2022 18:49:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.85 on epoch=201
05/17/2022 18:49:43 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.85 on epoch=202
05/17/2022 18:49:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.83 on epoch=202
05/17/2022 18:49:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.84 on epoch=203
05/17/2022 18:49:50 - INFO - __main__ - Global step 2850 Train loss 0.84 Classification-F1 0.3784448726439597 on epoch=203
05/17/2022 18:49:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.85 on epoch=204
05/17/2022 18:49:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.84 on epoch=204
05/17/2022 18:49:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.81 on epoch=205
05/17/2022 18:49:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.82 on epoch=206
05/17/2022 18:49:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.78 on epoch=207
05/17/2022 18:50:00 - INFO - __main__ - Global step 2900 Train loss 0.82 Classification-F1 0.440980902802955 on epoch=207
05/17/2022 18:50:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.84 on epoch=207
05/17/2022 18:50:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.80 on epoch=208
05/17/2022 18:50:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.77 on epoch=209
05/17/2022 18:50:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.84 on epoch=209
05/17/2022 18:50:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.73 on epoch=210
05/17/2022 18:50:10 - INFO - __main__ - Global step 2950 Train loss 0.79 Classification-F1 0.4676090754963934 on epoch=210
05/17/2022 18:50:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.86 on epoch=211
05/17/2022 18:50:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.89 on epoch=212
05/17/2022 18:50:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.78 on epoch=212
05/17/2022 18:50:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.82 on epoch=213
05/17/2022 18:50:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.74 on epoch=214
05/17/2022 18:50:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:50:19 - INFO - __main__ - Printing 3 examples
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:50:19 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:50:19 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:50:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:50:19 - INFO - __main__ - Printing 3 examples
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:50:19 - INFO - __main__ - ['Animal']
05/17/2022 18:50:19 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:50:19 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:50:19 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:50:20 - INFO - __main__ - Global step 3000 Train loss 0.82 Classification-F1 0.4110119510104774 on epoch=214
05/17/2022 18:50:20 - INFO - __main__ - save last model!
05/17/2022 18:50:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 18:50:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 18:50:20 - INFO - __main__ - Printing 3 examples
05/17/2022 18:50:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 18:50:20 - INFO - __main__ - ['Animal']
05/17/2022 18:50:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 18:50:20 - INFO - __main__ - ['Animal']
05/17/2022 18:50:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 18:50:20 - INFO - __main__ - ['Village']
05/17/2022 18:50:20 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:50:22 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:50:25 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:50:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:50:25 - INFO - __main__ - Starting training!
05/17/2022 18:50:25 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 18:51:25 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/17/2022 18:51:25 - INFO - __main__ - Classification-F1 on test data: 0.1416
05/17/2022 18:51:25 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.5234964749910304, test_performance=0.14163478437566152
05/17/2022 18:51:25 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/17/2022 18:51:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:51:26 - INFO - __main__ - Printing 3 examples
05/17/2022 18:51:26 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/17/2022 18:51:26 - INFO - __main__ - ['Animal']
05/17/2022 18:51:26 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/17/2022 18:51:26 - INFO - __main__ - ['Animal']
05/17/2022 18:51:26 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/17/2022 18:51:26 - INFO - __main__ - ['Animal']
05/17/2022 18:51:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:51:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:51:27 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 18:51:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 18:51:27 - INFO - __main__ - Printing 3 examples
05/17/2022 18:51:27 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/17/2022 18:51:27 - INFO - __main__ - ['Animal']
05/17/2022 18:51:27 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/17/2022 18:51:27 - INFO - __main__ - ['Animal']
05/17/2022 18:51:27 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/17/2022 18:51:27 - INFO - __main__ - ['Animal']
05/17/2022 18:51:27 - INFO - __main__ - Tokenizing Input ...
05/17/2022 18:51:27 - INFO - __main__ - Tokenizing Output ...
05/17/2022 18:51:27 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 18:51:32 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 18:51:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 18:51:33 - INFO - __main__ - Starting training!
05/17/2022 18:51:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.55 on epoch=0
05/17/2022 18:51:36 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/17/2022 18:51:37 - INFO - __main__ - Step 30 Global step 30 Train loss 6.71 on epoch=2
05/17/2022 18:51:38 - INFO - __main__ - Step 40 Global step 40 Train loss 6.60 on epoch=2
05/17/2022 18:51:40 - INFO - __main__ - Step 50 Global step 50 Train loss 6.37 on epoch=3
05/17/2022 18:51:43 - INFO - __main__ - Global step 50 Train loss 6.87 Classification-F1 0.0 on epoch=3
05/17/2022 18:51:43 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 18:51:44 - INFO - __main__ - Step 60 Global step 60 Train loss 6.05 on epoch=4
05/17/2022 18:51:45 - INFO - __main__ - Step 70 Global step 70 Train loss 5.57 on epoch=4
05/17/2022 18:51:46 - INFO - __main__ - Step 80 Global step 80 Train loss 5.41 on epoch=5
05/17/2022 18:51:48 - INFO - __main__ - Step 90 Global step 90 Train loss 5.24 on epoch=6
05/17/2022 18:51:49 - INFO - __main__ - Step 100 Global step 100 Train loss 5.21 on epoch=7
05/17/2022 18:51:52 - INFO - __main__ - Global step 100 Train loss 5.50 Classification-F1 0.0 on epoch=7
05/17/2022 18:51:54 - INFO - __main__ - Step 110 Global step 110 Train loss 4.89 on epoch=7
05/17/2022 18:51:55 - INFO - __main__ - Step 120 Global step 120 Train loss 4.94 on epoch=8
05/17/2022 18:51:56 - INFO - __main__ - Step 130 Global step 130 Train loss 4.67 on epoch=9
05/17/2022 18:51:57 - INFO - __main__ - Step 140 Global step 140 Train loss 4.70 on epoch=9
05/17/2022 18:51:59 - INFO - __main__ - Step 150 Global step 150 Train loss 4.57 on epoch=10
05/17/2022 18:52:02 - INFO - __main__ - Global step 150 Train loss 4.75 Classification-F1 0.0 on epoch=10
05/17/2022 18:52:03 - INFO - __main__ - Step 160 Global step 160 Train loss 4.34 on epoch=11
05/17/2022 18:52:04 - INFO - __main__ - Step 170 Global step 170 Train loss 4.04 on epoch=12
05/17/2022 18:52:06 - INFO - __main__ - Step 180 Global step 180 Train loss 4.17 on epoch=12
05/17/2022 18:52:07 - INFO - __main__ - Step 190 Global step 190 Train loss 4.12 on epoch=13
05/17/2022 18:52:08 - INFO - __main__ - Step 200 Global step 200 Train loss 3.85 on epoch=14
05/17/2022 18:52:11 - INFO - __main__ - Global step 200 Train loss 4.10 Classification-F1 0.0 on epoch=14
05/17/2022 18:52:12 - INFO - __main__ - Step 210 Global step 210 Train loss 3.80 on epoch=14
05/17/2022 18:52:14 - INFO - __main__ - Step 220 Global step 220 Train loss 3.78 on epoch=15
05/17/2022 18:52:15 - INFO - __main__ - Step 230 Global step 230 Train loss 3.64 on epoch=16
05/17/2022 18:52:16 - INFO - __main__ - Step 240 Global step 240 Train loss 3.65 on epoch=17
05/17/2022 18:52:17 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/17/2022 18:52:20 - INFO - __main__ - Global step 250 Train loss 3.66 Classification-F1 0.0 on epoch=17
05/17/2022 18:52:21 - INFO - __main__ - Step 260 Global step 260 Train loss 3.49 on epoch=18
05/17/2022 18:52:22 - INFO - __main__ - Step 270 Global step 270 Train loss 3.32 on epoch=19
05/17/2022 18:52:24 - INFO - __main__ - Step 280 Global step 280 Train loss 3.43 on epoch=19
05/17/2022 18:52:25 - INFO - __main__ - Step 290 Global step 290 Train loss 3.35 on epoch=20
05/17/2022 18:52:26 - INFO - __main__ - Step 300 Global step 300 Train loss 3.02 on epoch=21
05/17/2022 18:52:29 - INFO - __main__ - Global step 300 Train loss 3.32 Classification-F1 0.006666666666666666 on epoch=21
05/17/2022 18:52:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.006666666666666666 on epoch=21, global_step=300
05/17/2022 18:52:30 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/17/2022 18:52:31 - INFO - __main__ - Step 320 Global step 320 Train loss 3.01 on epoch=22
05/17/2022 18:52:32 - INFO - __main__ - Step 330 Global step 330 Train loss 3.03 on epoch=23
05/17/2022 18:52:34 - INFO - __main__ - Step 340 Global step 340 Train loss 2.99 on epoch=24
05/17/2022 18:52:35 - INFO - __main__ - Step 350 Global step 350 Train loss 2.88 on epoch=24
05/17/2022 18:52:37 - INFO - __main__ - Global step 350 Train loss 2.99 Classification-F1 0.010136452241715398 on epoch=24
05/17/2022 18:52:37 - INFO - __main__ - Saving model with best Classification-F1: 0.006666666666666666 -> 0.010136452241715398 on epoch=24, global_step=350
05/17/2022 18:52:39 - INFO - __main__ - Step 360 Global step 360 Train loss 2.91 on epoch=25
05/17/2022 18:52:40 - INFO - __main__ - Step 370 Global step 370 Train loss 2.77 on epoch=26
05/17/2022 18:52:41 - INFO - __main__ - Step 380 Global step 380 Train loss 2.56 on epoch=27
05/17/2022 18:52:42 - INFO - __main__ - Step 390 Global step 390 Train loss 2.67 on epoch=27
05/17/2022 18:52:43 - INFO - __main__ - Step 400 Global step 400 Train loss 2.70 on epoch=28
05/17/2022 18:52:46 - INFO - __main__ - Global step 400 Train loss 2.72 Classification-F1 0.009315866084425035 on epoch=28
05/17/2022 18:52:47 - INFO - __main__ - Step 410 Global step 410 Train loss 2.46 on epoch=29
05/17/2022 18:52:48 - INFO - __main__ - Step 420 Global step 420 Train loss 2.56 on epoch=29
05/17/2022 18:52:50 - INFO - __main__ - Step 430 Global step 430 Train loss 2.50 on epoch=30
05/17/2022 18:52:51 - INFO - __main__ - Step 440 Global step 440 Train loss 2.47 on epoch=31
05/17/2022 18:52:52 - INFO - __main__ - Step 450 Global step 450 Train loss 2.38 on epoch=32
05/17/2022 18:52:54 - INFO - __main__ - Global step 450 Train loss 2.47 Classification-F1 0.009523809523809523 on epoch=32
05/17/2022 18:52:55 - INFO - __main__ - Step 460 Global step 460 Train loss 2.43 on epoch=32
05/17/2022 18:52:56 - INFO - __main__ - Step 470 Global step 470 Train loss 2.52 on epoch=33
05/17/2022 18:52:58 - INFO - __main__ - Step 480 Global step 480 Train loss 2.31 on epoch=34
05/17/2022 18:52:59 - INFO - __main__ - Step 490 Global step 490 Train loss 2.24 on epoch=34
05/17/2022 18:53:00 - INFO - __main__ - Step 500 Global step 500 Train loss 2.35 on epoch=35
05/17/2022 18:53:02 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.009523809523809523 on epoch=35
05/17/2022 18:53:03 - INFO - __main__ - Step 510 Global step 510 Train loss 2.21 on epoch=36
05/17/2022 18:53:04 - INFO - __main__ - Step 520 Global step 520 Train loss 2.20 on epoch=37
05/17/2022 18:53:06 - INFO - __main__ - Step 530 Global step 530 Train loss 2.09 on epoch=37
05/17/2022 18:53:07 - INFO - __main__ - Step 540 Global step 540 Train loss 2.23 on epoch=38
05/17/2022 18:53:08 - INFO - __main__ - Step 550 Global step 550 Train loss 1.99 on epoch=39
05/17/2022 18:53:10 - INFO - __main__ - Global step 550 Train loss 2.14 Classification-F1 0.009563658099222952 on epoch=39
05/17/2022 18:53:11 - INFO - __main__ - Step 560 Global step 560 Train loss 2.04 on epoch=39
05/17/2022 18:53:12 - INFO - __main__ - Step 570 Global step 570 Train loss 2.05 on epoch=40
05/17/2022 18:53:14 - INFO - __main__ - Step 580 Global step 580 Train loss 2.03 on epoch=41
05/17/2022 18:53:15 - INFO - __main__ - Step 590 Global step 590 Train loss 1.94 on epoch=42
05/17/2022 18:53:16 - INFO - __main__ - Step 600 Global step 600 Train loss 1.97 on epoch=42
05/17/2022 18:53:18 - INFO - __main__ - Global step 600 Train loss 2.01 Classification-F1 0.009603841536614645 on epoch=42
05/17/2022 18:53:19 - INFO - __main__ - Step 610 Global step 610 Train loss 1.94 on epoch=43
05/17/2022 18:53:21 - INFO - __main__ - Step 620 Global step 620 Train loss 2.01 on epoch=44
05/17/2022 18:53:22 - INFO - __main__ - Step 630 Global step 630 Train loss 1.82 on epoch=44
05/17/2022 18:53:23 - INFO - __main__ - Step 640 Global step 640 Train loss 1.89 on epoch=45
05/17/2022 18:53:25 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=46
05/17/2022 18:53:27 - INFO - __main__ - Global step 650 Train loss 1.89 Classification-F1 0.018224349907518225 on epoch=46
05/17/2022 18:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.010136452241715398 -> 0.018224349907518225 on epoch=46, global_step=650
05/17/2022 18:53:28 - INFO - __main__ - Step 660 Global step 660 Train loss 1.77 on epoch=47
05/17/2022 18:53:30 - INFO - __main__ - Step 670 Global step 670 Train loss 1.75 on epoch=47
05/17/2022 18:53:31 - INFO - __main__ - Step 680 Global step 680 Train loss 1.78 on epoch=48
05/17/2022 18:53:32 - INFO - __main__ - Step 690 Global step 690 Train loss 1.73 on epoch=49
05/17/2022 18:53:34 - INFO - __main__ - Step 700 Global step 700 Train loss 1.67 on epoch=49
05/17/2022 18:53:36 - INFO - __main__ - Global step 700 Train loss 1.74 Classification-F1 0.020874570564011558 on epoch=49
05/17/2022 18:53:36 - INFO - __main__ - Saving model with best Classification-F1: 0.018224349907518225 -> 0.020874570564011558 on epoch=49, global_step=700
05/17/2022 18:53:37 - INFO - __main__ - Step 710 Global step 710 Train loss 1.73 on epoch=50
05/17/2022 18:53:39 - INFO - __main__ - Step 720 Global step 720 Train loss 1.82 on epoch=51
05/17/2022 18:53:40 - INFO - __main__ - Step 730 Global step 730 Train loss 1.62 on epoch=52
05/17/2022 18:53:41 - INFO - __main__ - Step 740 Global step 740 Train loss 1.58 on epoch=52
05/17/2022 18:53:43 - INFO - __main__ - Step 750 Global step 750 Train loss 1.70 on epoch=53
05/17/2022 18:53:45 - INFO - __main__ - Global step 750 Train loss 1.69 Classification-F1 0.023928222315319086 on epoch=53
05/17/2022 18:53:45 - INFO - __main__ - Saving model with best Classification-F1: 0.020874570564011558 -> 0.023928222315319086 on epoch=53, global_step=750
05/17/2022 18:53:47 - INFO - __main__ - Step 760 Global step 760 Train loss 1.59 on epoch=54
05/17/2022 18:53:48 - INFO - __main__ - Step 770 Global step 770 Train loss 1.63 on epoch=54
05/17/2022 18:53:49 - INFO - __main__ - Step 780 Global step 780 Train loss 1.62 on epoch=55
05/17/2022 18:53:50 - INFO - __main__ - Step 790 Global step 790 Train loss 1.52 on epoch=56
05/17/2022 18:53:52 - INFO - __main__ - Step 800 Global step 800 Train loss 1.63 on epoch=57
05/17/2022 18:53:54 - INFO - __main__ - Global step 800 Train loss 1.60 Classification-F1 0.04258697812704781 on epoch=57
05/17/2022 18:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.023928222315319086 -> 0.04258697812704781 on epoch=57, global_step=800
05/17/2022 18:53:56 - INFO - __main__ - Step 810 Global step 810 Train loss 1.71 on epoch=57
05/17/2022 18:53:57 - INFO - __main__ - Step 820 Global step 820 Train loss 1.62 on epoch=58
05/17/2022 18:53:58 - INFO - __main__ - Step 830 Global step 830 Train loss 1.54 on epoch=59
05/17/2022 18:54:00 - INFO - __main__ - Step 840 Global step 840 Train loss 1.63 on epoch=59
05/17/2022 18:54:01 - INFO - __main__ - Step 850 Global step 850 Train loss 1.51 on epoch=60
05/17/2022 18:54:04 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.048646619797698576 on epoch=60
05/17/2022 18:54:04 - INFO - __main__ - Saving model with best Classification-F1: 0.04258697812704781 -> 0.048646619797698576 on epoch=60, global_step=850
05/17/2022 18:54:05 - INFO - __main__ - Step 860 Global step 860 Train loss 1.58 on epoch=61
05/17/2022 18:54:07 - INFO - __main__ - Step 870 Global step 870 Train loss 1.54 on epoch=62
05/17/2022 18:54:08 - INFO - __main__ - Step 880 Global step 880 Train loss 1.53 on epoch=62
05/17/2022 18:54:09 - INFO - __main__ - Step 890 Global step 890 Train loss 1.49 on epoch=63
05/17/2022 18:54:10 - INFO - __main__ - Step 900 Global step 900 Train loss 1.41 on epoch=64
05/17/2022 18:54:13 - INFO - __main__ - Global step 900 Train loss 1.51 Classification-F1 0.040875134696645 on epoch=64
05/17/2022 18:54:15 - INFO - __main__ - Step 910 Global step 910 Train loss 1.47 on epoch=64
05/17/2022 18:54:16 - INFO - __main__ - Step 920 Global step 920 Train loss 1.44 on epoch=65
05/17/2022 18:54:17 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=66
05/17/2022 18:54:19 - INFO - __main__ - Step 940 Global step 940 Train loss 1.50 on epoch=67
05/17/2022 18:54:20 - INFO - __main__ - Step 950 Global step 950 Train loss 1.33 on epoch=67
05/17/2022 18:54:23 - INFO - __main__ - Global step 950 Train loss 1.45 Classification-F1 0.05319937010668263 on epoch=67
05/17/2022 18:54:23 - INFO - __main__ - Saving model with best Classification-F1: 0.048646619797698576 -> 0.05319937010668263 on epoch=67, global_step=950
05/17/2022 18:54:24 - INFO - __main__ - Step 960 Global step 960 Train loss 1.40 on epoch=68
05/17/2022 18:54:26 - INFO - __main__ - Step 970 Global step 970 Train loss 1.41 on epoch=69
05/17/2022 18:54:27 - INFO - __main__ - Step 980 Global step 980 Train loss 1.46 on epoch=69
05/17/2022 18:54:28 - INFO - __main__ - Step 990 Global step 990 Train loss 1.51 on epoch=70
05/17/2022 18:54:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.34 on epoch=71
05/17/2022 18:54:33 - INFO - __main__ - Global step 1000 Train loss 1.42 Classification-F1 0.04023225451796881 on epoch=71
05/17/2022 18:54:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.35 on epoch=72
05/17/2022 18:54:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.40 on epoch=72
05/17/2022 18:54:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.37 on epoch=73
05/17/2022 18:54:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.40 on epoch=74
05/17/2022 18:54:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.37 on epoch=74
05/17/2022 18:54:42 - INFO - __main__ - Global step 1050 Train loss 1.38 Classification-F1 0.07086439125732572 on epoch=74
05/17/2022 18:54:42 - INFO - __main__ - Saving model with best Classification-F1: 0.05319937010668263 -> 0.07086439125732572 on epoch=74, global_step=1050
05/17/2022 18:54:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.38 on epoch=75
05/17/2022 18:54:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.44 on epoch=76
05/17/2022 18:54:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.34 on epoch=77
05/17/2022 18:54:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.26 on epoch=77
05/17/2022 18:54:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.40 on epoch=78
05/17/2022 18:54:52 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.07781640333275444 on epoch=78
05/17/2022 18:54:52 - INFO - __main__ - Saving model with best Classification-F1: 0.07086439125732572 -> 0.07781640333275444 on epoch=78, global_step=1100
05/17/2022 18:54:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.30 on epoch=79
05/17/2022 18:54:54 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.33 on epoch=79
05/17/2022 18:54:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.38 on epoch=80
05/17/2022 18:54:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.28 on epoch=81
05/17/2022 18:54:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.32 on epoch=82
05/17/2022 18:55:01 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.05736797924297925 on epoch=82
05/17/2022 18:55:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.22 on epoch=82
05/17/2022 18:55:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.29 on epoch=83
05/17/2022 18:55:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.30 on epoch=84
05/17/2022 18:55:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=84
05/17/2022 18:55:08 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.29 on epoch=85
05/17/2022 18:55:11 - INFO - __main__ - Global step 1200 Train loss 1.29 Classification-F1 0.0634405436207731 on epoch=85
05/17/2022 18:55:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.29 on epoch=86
05/17/2022 18:55:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.25 on epoch=87
05/17/2022 18:55:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.27 on epoch=87
05/17/2022 18:55:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.23 on epoch=88
05/17/2022 18:55:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=89
05/17/2022 18:55:20 - INFO - __main__ - Global step 1250 Train loss 1.25 Classification-F1 0.1364790602235259 on epoch=89
05/17/2022 18:55:20 - INFO - __main__ - Saving model with best Classification-F1: 0.07781640333275444 -> 0.1364790602235259 on epoch=89, global_step=1250
05/17/2022 18:55:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=89
05/17/2022 18:55:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.18 on epoch=90
05/17/2022 18:55:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.32 on epoch=91
05/17/2022 18:55:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.15 on epoch=92
05/17/2022 18:55:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.32 on epoch=92
05/17/2022 18:55:30 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.1281577070046249 on epoch=92
05/17/2022 18:55:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.25 on epoch=93
05/17/2022 18:55:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.22 on epoch=94
05/17/2022 18:55:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=94
05/17/2022 18:55:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.25 on epoch=95
05/17/2022 18:55:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=96
05/17/2022 18:55:39 - INFO - __main__ - Global step 1350 Train loss 1.24 Classification-F1 0.16371727787126897 on epoch=96
05/17/2022 18:55:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1364790602235259 -> 0.16371727787126897 on epoch=96, global_step=1350
05/17/2022 18:55:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.16 on epoch=97
05/17/2022 18:55:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.19 on epoch=97
05/17/2022 18:55:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=98
05/17/2022 18:55:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.17 on epoch=99
05/17/2022 18:55:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.26 on epoch=99
05/17/2022 18:55:48 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.12559956796079016 on epoch=99
05/17/2022 18:55:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.15 on epoch=100
05/17/2022 18:55:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.20 on epoch=101
05/17/2022 18:55:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.17 on epoch=102
05/17/2022 18:55:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=102
05/17/2022 18:55:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=103
05/17/2022 18:55:58 - INFO - __main__ - Global step 1450 Train loss 1.20 Classification-F1 0.16384565106732807 on epoch=103
05/17/2022 18:55:58 - INFO - __main__ - Saving model with best Classification-F1: 0.16371727787126897 -> 0.16384565106732807 on epoch=103, global_step=1450
05/17/2022 18:55:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=104
05/17/2022 18:56:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.23 on epoch=104
05/17/2022 18:56:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.20 on epoch=105
05/17/2022 18:56:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=106
05/17/2022 18:56:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=107
05/17/2022 18:56:07 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.15844320231025139 on epoch=107
05/17/2022 18:56:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.17 on epoch=107
05/17/2022 18:56:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.18 on epoch=108
05/17/2022 18:56:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/17/2022 18:56:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.18 on epoch=109
05/17/2022 18:56:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=110
05/17/2022 18:56:17 - INFO - __main__ - Global step 1550 Train loss 1.17 Classification-F1 0.1340554863494626 on epoch=110
05/17/2022 18:56:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=111
05/17/2022 18:56:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=112
05/17/2022 18:56:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.20 on epoch=112
05/17/2022 18:56:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.12 on epoch=113
05/17/2022 18:56:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=114
05/17/2022 18:56:26 - INFO - __main__ - Global step 1600 Train loss 1.16 Classification-F1 0.1908294723536181 on epoch=114
05/17/2022 18:56:26 - INFO - __main__ - Saving model with best Classification-F1: 0.16384565106732807 -> 0.1908294723536181 on epoch=114, global_step=1600
05/17/2022 18:56:28 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.22 on epoch=114
05/17/2022 18:56:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.21 on epoch=115
05/17/2022 18:56:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.11 on epoch=116
05/17/2022 18:56:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.17 on epoch=117
05/17/2022 18:56:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.12 on epoch=117
05/17/2022 18:56:36 - INFO - __main__ - Global step 1650 Train loss 1.16 Classification-F1 0.27573401512963097 on epoch=117
05/17/2022 18:56:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1908294723536181 -> 0.27573401512963097 on epoch=117, global_step=1650
05/17/2022 18:56:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.14 on epoch=118
05/17/2022 18:56:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=119
05/17/2022 18:56:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.16 on epoch=119
05/17/2022 18:56:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=120
05/17/2022 18:56:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.15 on epoch=121
05/17/2022 18:56:45 - INFO - __main__ - Global step 1700 Train loss 1.12 Classification-F1 0.27069685824947803 on epoch=121
05/17/2022 18:56:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.25 on epoch=122
05/17/2022 18:56:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=122
05/17/2022 18:56:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/17/2022 18:56:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.10 on epoch=124
05/17/2022 18:56:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=124
05/17/2022 18:56:55 - INFO - __main__ - Global step 1750 Train loss 1.17 Classification-F1 0.2173480933668585 on epoch=124
05/17/2022 18:56:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=125
05/17/2022 18:56:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=126
05/17/2022 18:56:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.17 on epoch=127
05/17/2022 18:57:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.05 on epoch=127
05/17/2022 18:57:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.18 on epoch=128
05/17/2022 18:57:05 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.181865040915349 on epoch=128
05/17/2022 18:57:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=129
05/17/2022 18:57:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=129
05/17/2022 18:57:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=130
05/17/2022 18:57:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/17/2022 18:57:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.24 on epoch=132
05/17/2022 18:57:14 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.257960577998172 on epoch=132
05/17/2022 18:57:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=132
05/17/2022 18:57:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.07 on epoch=133
05/17/2022 18:57:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.05 on epoch=134
05/17/2022 18:57:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=134
05/17/2022 18:57:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.20 on epoch=135
05/17/2022 18:57:24 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.19473692682919355 on epoch=135
05/17/2022 18:57:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=136
05/17/2022 18:57:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.11 on epoch=137
05/17/2022 18:57:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.03 on epoch=137
05/17/2022 18:57:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.10 on epoch=138
05/17/2022 18:57:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.99 on epoch=139
05/17/2022 18:57:33 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.2642080560836954 on epoch=139
05/17/2022 18:57:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=139
05/17/2022 18:57:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=140
05/17/2022 18:57:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=141
05/17/2022 18:57:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.11 on epoch=142
05/17/2022 18:57:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.04 on epoch=142
05/17/2022 18:57:43 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.25248283094714624 on epoch=142
05/17/2022 18:57:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=143
05/17/2022 18:57:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=144
05/17/2022 18:57:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=144
05/17/2022 18:57:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.18 on epoch=145
05/17/2022 18:57:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=146
05/17/2022 18:57:53 - INFO - __main__ - Global step 2050 Train loss 1.08 Classification-F1 0.2763105182437324 on epoch=146
05/17/2022 18:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.27573401512963097 -> 0.2763105182437324 on epoch=146, global_step=2050
05/17/2022 18:57:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=147
05/17/2022 18:57:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=147
05/17/2022 18:57:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.05 on epoch=148
05/17/2022 18:57:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.99 on epoch=149
05/17/2022 18:57:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.14 on epoch=149
05/17/2022 18:58:03 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.31450358106288767 on epoch=149
05/17/2022 18:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.2763105182437324 -> 0.31450358106288767 on epoch=149, global_step=2100
05/17/2022 18:58:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.02 on epoch=150
05/17/2022 18:58:05 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.02 on epoch=151
05/17/2022 18:58:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=152
05/17/2022 18:58:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=152
05/17/2022 18:58:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.94 on epoch=153
05/17/2022 18:58:13 - INFO - __main__ - Global step 2150 Train loss 1.01 Classification-F1 0.3666756543332173 on epoch=153
05/17/2022 18:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.31450358106288767 -> 0.3666756543332173 on epoch=153, global_step=2150
05/17/2022 18:58:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=154
05/17/2022 18:58:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.92 on epoch=154
05/17/2022 18:58:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=155
05/17/2022 18:58:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.11 on epoch=156
05/17/2022 18:58:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=157
05/17/2022 18:58:23 - INFO - __main__ - Global step 2200 Train loss 1.02 Classification-F1 0.3393428364195746 on epoch=157
05/17/2022 18:58:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=157
05/17/2022 18:58:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=158
05/17/2022 18:58:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.97 on epoch=159
05/17/2022 18:58:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.00 on epoch=159
05/17/2022 18:58:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.93 on epoch=160
05/17/2022 18:58:33 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.38058716827510003 on epoch=160
05/17/2022 18:58:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3666756543332173 -> 0.38058716827510003 on epoch=160, global_step=2250
05/17/2022 18:58:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=161
05/17/2022 18:58:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.88 on epoch=162
05/17/2022 18:58:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=162
05/17/2022 18:58:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=163
05/17/2022 18:58:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.99 on epoch=164
05/17/2022 18:58:43 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.36915953180392014 on epoch=164
05/17/2022 18:58:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.13 on epoch=164
05/17/2022 18:58:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=165
05/17/2022 18:58:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=166
05/17/2022 18:58:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.04 on epoch=167
05/17/2022 18:58:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=167
05/17/2022 18:58:53 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.37466226399371766 on epoch=167
05/17/2022 18:58:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.96 on epoch=168
05/17/2022 18:58:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=169
05/17/2022 18:58:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=169
05/17/2022 18:58:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=170
05/17/2022 18:58:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=171
05/17/2022 18:59:03 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.40388057773279457 on epoch=171
05/17/2022 18:59:03 - INFO - __main__ - Saving model with best Classification-F1: 0.38058716827510003 -> 0.40388057773279457 on epoch=171, global_step=2400
05/17/2022 18:59:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.94 on epoch=172
05/17/2022 18:59:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=172
05/17/2022 18:59:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=173
05/17/2022 18:59:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=174
05/17/2022 18:59:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=174
05/17/2022 18:59:13 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.3785887639002958 on epoch=174
05/17/2022 18:59:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.99 on epoch=175
05/17/2022 18:59:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.93 on epoch=176
05/17/2022 18:59:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=177
05/17/2022 18:59:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=177
05/17/2022 18:59:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.97 on epoch=178
05/17/2022 18:59:23 - INFO - __main__ - Global step 2500 Train loss 0.96 Classification-F1 0.45565598905917354 on epoch=178
05/17/2022 18:59:23 - INFO - __main__ - Saving model with best Classification-F1: 0.40388057773279457 -> 0.45565598905917354 on epoch=178, global_step=2500
05/17/2022 18:59:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.89 on epoch=179
05/17/2022 18:59:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=179
05/17/2022 18:59:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.96 on epoch=180
05/17/2022 18:59:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.99 on epoch=181
05/17/2022 18:59:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=182
05/17/2022 18:59:34 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.46606850338207034 on epoch=182
05/17/2022 18:59:34 - INFO - __main__ - Saving model with best Classification-F1: 0.45565598905917354 -> 0.46606850338207034 on epoch=182, global_step=2550
05/17/2022 18:59:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=182
05/17/2022 18:59:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=183
05/17/2022 18:59:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=184
05/17/2022 18:59:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.92 on epoch=184
05/17/2022 18:59:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=185
05/17/2022 18:59:45 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.473825980162187 on epoch=185
05/17/2022 18:59:45 - INFO - __main__ - Saving model with best Classification-F1: 0.46606850338207034 -> 0.473825980162187 on epoch=185, global_step=2600
05/17/2022 18:59:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.00 on epoch=186
05/17/2022 18:59:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=187
05/17/2022 18:59:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.96 on epoch=187
05/17/2022 18:59:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.92 on epoch=188
05/17/2022 18:59:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.98 on epoch=189
05/17/2022 18:59:55 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.40039965636270486 on epoch=189
05/17/2022 18:59:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.97 on epoch=189
05/17/2022 18:59:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.81 on epoch=190
05/17/2022 19:00:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.96 on epoch=191
05/17/2022 19:00:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.90 on epoch=192
05/17/2022 19:00:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=192
05/17/2022 19:00:06 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.4140104987289586 on epoch=192
05/17/2022 19:00:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.90 on epoch=193
05/17/2022 19:00:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.93 on epoch=194
05/17/2022 19:00:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.86 on epoch=194
05/17/2022 19:00:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.89 on epoch=195
05/17/2022 19:00:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.92 on epoch=196
05/17/2022 19:00:17 - INFO - __main__ - Global step 2750 Train loss 0.90 Classification-F1 0.4775948738486042 on epoch=196
05/17/2022 19:00:17 - INFO - __main__ - Saving model with best Classification-F1: 0.473825980162187 -> 0.4775948738486042 on epoch=196, global_step=2750
05/17/2022 19:00:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.92 on epoch=197
05/17/2022 19:00:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.87 on epoch=197
05/17/2022 19:00:21 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.84 on epoch=198
05/17/2022 19:00:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.85 on epoch=199
05/17/2022 19:00:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=199
05/17/2022 19:00:28 - INFO - __main__ - Global step 2800 Train loss 0.89 Classification-F1 0.49525713013674233 on epoch=199
05/17/2022 19:00:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4775948738486042 -> 0.49525713013674233 on epoch=199, global_step=2800
05/17/2022 19:00:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/17/2022 19:00:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=201
05/17/2022 19:00:32 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.91 on epoch=202
05/17/2022 19:00:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.82 on epoch=202
05/17/2022 19:00:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.01 on epoch=203
05/17/2022 19:00:38 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.5035235606567374 on epoch=203
05/17/2022 19:00:38 - INFO - __main__ - Saving model with best Classification-F1: 0.49525713013674233 -> 0.5035235606567374 on epoch=203, global_step=2850
05/17/2022 19:00:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.85 on epoch=204
05/17/2022 19:00:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.90 on epoch=204
05/17/2022 19:00:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.85 on epoch=205
05/17/2022 19:00:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.88 on epoch=206
05/17/2022 19:00:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.87 on epoch=207
05/17/2022 19:00:49 - INFO - __main__ - Global step 2900 Train loss 0.87 Classification-F1 0.4539915686299956 on epoch=207
05/17/2022 19:00:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.86 on epoch=207
05/17/2022 19:00:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.90 on epoch=208
05/17/2022 19:00:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.82 on epoch=209
05/17/2022 19:00:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/17/2022 19:00:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.84 on epoch=210
05/17/2022 19:00:59 - INFO - __main__ - Global step 2950 Train loss 0.84 Classification-F1 0.4499097976468869 on epoch=210
05/17/2022 19:01:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=211
05/17/2022 19:01:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.05 on epoch=212
05/17/2022 19:01:03 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.85 on epoch=212
05/17/2022 19:01:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.80 on epoch=213
05/17/2022 19:01:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.88 on epoch=214
05/17/2022 19:01:06 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:01:06 - INFO - __main__ - Printing 3 examples
05/17/2022 19:01:06 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:01:06 - INFO - __main__ - ['Animal']
05/17/2022 19:01:06 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:01:06 - INFO - __main__ - ['Animal']
05/17/2022 19:01:06 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:01:06 - INFO - __main__ - ['Animal']
05/17/2022 19:01:06 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:01:06 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:01:07 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:01:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:01:07 - INFO - __main__ - Printing 3 examples
05/17/2022 19:01:07 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:01:07 - INFO - __main__ - ['Animal']
05/17/2022 19:01:07 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:01:07 - INFO - __main__ - ['Animal']
05/17/2022 19:01:07 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:01:07 - INFO - __main__ - ['Animal']
05/17/2022 19:01:07 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:01:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:01:07 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:01:09 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.40907132777267635 on epoch=214
05/17/2022 19:01:09 - INFO - __main__ - save last model!
05/17/2022 19:01:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:01:09 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:01:09 - INFO - __main__ - Printing 3 examples
05/17/2022 19:01:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:01:09 - INFO - __main__ - ['Animal']
05/17/2022 19:01:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:01:09 - INFO - __main__ - ['Animal']
05/17/2022 19:01:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:01:09 - INFO - __main__ - ['Village']
05/17/2022 19:01:09 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:01:11 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:01:13 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:01:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:01:13 - INFO - __main__ - Starting training!
05/17/2022 19:01:14 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:02:14 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/17/2022 19:02:14 - INFO - __main__ - Classification-F1 on test data: 0.1417
05/17/2022 19:02:14 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.5035235606567374, test_performance=0.14166563649230043
05/17/2022 19:02:14 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/17/2022 19:02:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:02:15 - INFO - __main__ - Printing 3 examples
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:02:15 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:02:15 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:02:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:02:15 - INFO - __main__ - Printing 3 examples
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:02:15 - INFO - __main__ - ['Animal']
05/17/2022 19:02:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:02:15 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:02:16 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:02:21 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:02:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:02:22 - INFO - __main__ - Starting training!
05/17/2022 19:02:23 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/17/2022 19:02:24 - INFO - __main__ - Step 20 Global step 20 Train loss 6.91 on epoch=1
05/17/2022 19:02:26 - INFO - __main__ - Step 30 Global step 30 Train loss 5.95 on epoch=2
05/17/2022 19:02:27 - INFO - __main__ - Step 40 Global step 40 Train loss 5.32 on epoch=2
05/17/2022 19:02:28 - INFO - __main__ - Step 50 Global step 50 Train loss 5.08 on epoch=3
05/17/2022 19:02:32 - INFO - __main__ - Global step 50 Train loss 6.13 Classification-F1 0.0 on epoch=3
05/17/2022 19:02:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:02:33 - INFO - __main__ - Step 60 Global step 60 Train loss 4.89 on epoch=4
05/17/2022 19:02:34 - INFO - __main__ - Step 70 Global step 70 Train loss 4.55 on epoch=4
05/17/2022 19:02:35 - INFO - __main__ - Step 80 Global step 80 Train loss 4.21 on epoch=5
05/17/2022 19:02:37 - INFO - __main__ - Step 90 Global step 90 Train loss 3.86 on epoch=6
05/17/2022 19:02:38 - INFO - __main__ - Step 100 Global step 100 Train loss 3.60 on epoch=7
05/17/2022 19:02:41 - INFO - __main__ - Global step 100 Train loss 4.22 Classification-F1 0.0 on epoch=7
05/17/2022 19:02:42 - INFO - __main__ - Step 110 Global step 110 Train loss 3.35 on epoch=7
05/17/2022 19:02:44 - INFO - __main__ - Step 120 Global step 120 Train loss 3.31 on epoch=8
05/17/2022 19:02:45 - INFO - __main__ - Step 130 Global step 130 Train loss 3.33 on epoch=9
05/17/2022 19:02:46 - INFO - __main__ - Step 140 Global step 140 Train loss 3.12 on epoch=9
05/17/2022 19:02:47 - INFO - __main__ - Step 150 Global step 150 Train loss 2.85 on epoch=10
05/17/2022 19:02:50 - INFO - __main__ - Global step 150 Train loss 3.19 Classification-F1 0.008121827411167511 on epoch=10
05/17/2022 19:02:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.008121827411167511 on epoch=10, global_step=150
05/17/2022 19:02:51 - INFO - __main__ - Step 160 Global step 160 Train loss 2.82 on epoch=11
05/17/2022 19:02:52 - INFO - __main__ - Step 170 Global step 170 Train loss 2.57 on epoch=12
05/17/2022 19:02:53 - INFO - __main__ - Step 180 Global step 180 Train loss 2.49 on epoch=12
05/17/2022 19:02:55 - INFO - __main__ - Step 190 Global step 190 Train loss 2.42 on epoch=13
05/17/2022 19:02:56 - INFO - __main__ - Step 200 Global step 200 Train loss 2.40 on epoch=14
05/17/2022 19:02:58 - INFO - __main__ - Global step 200 Train loss 2.54 Classification-F1 0.009523809523809523 on epoch=14
05/17/2022 19:02:58 - INFO - __main__ - Saving model with best Classification-F1: 0.008121827411167511 -> 0.009523809523809523 on epoch=14, global_step=200
05/17/2022 19:02:59 - INFO - __main__ - Step 210 Global step 210 Train loss 2.35 on epoch=14
05/17/2022 19:03:00 - INFO - __main__ - Step 220 Global step 220 Train loss 2.22 on epoch=15
05/17/2022 19:03:02 - INFO - __main__ - Step 230 Global step 230 Train loss 2.22 on epoch=16
05/17/2022 19:03:03 - INFO - __main__ - Step 240 Global step 240 Train loss 2.06 on epoch=17
05/17/2022 19:03:04 - INFO - __main__ - Step 250 Global step 250 Train loss 1.94 on epoch=17
05/17/2022 19:03:06 - INFO - __main__ - Global step 250 Train loss 2.16 Classification-F1 0.018567737172388337 on epoch=17
05/17/2022 19:03:06 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.018567737172388337 on epoch=17, global_step=250
05/17/2022 19:03:07 - INFO - __main__ - Step 260 Global step 260 Train loss 1.86 on epoch=18
05/17/2022 19:03:09 - INFO - __main__ - Step 270 Global step 270 Train loss 2.02 on epoch=19
05/17/2022 19:03:10 - INFO - __main__ - Step 280 Global step 280 Train loss 1.85 on epoch=19
05/17/2022 19:03:11 - INFO - __main__ - Step 290 Global step 290 Train loss 1.74 on epoch=20
05/17/2022 19:03:12 - INFO - __main__ - Step 300 Global step 300 Train loss 1.83 on epoch=21
05/17/2022 19:03:15 - INFO - __main__ - Global step 300 Train loss 1.86 Classification-F1 0.0381820560391989 on epoch=21
05/17/2022 19:03:15 - INFO - __main__ - Saving model with best Classification-F1: 0.018567737172388337 -> 0.0381820560391989 on epoch=21, global_step=300
05/17/2022 19:03:17 - INFO - __main__ - Step 310 Global step 310 Train loss 1.72 on epoch=22
05/17/2022 19:03:18 - INFO - __main__ - Step 320 Global step 320 Train loss 1.68 on epoch=22
05/17/2022 19:03:19 - INFO - __main__ - Step 330 Global step 330 Train loss 1.60 on epoch=23
05/17/2022 19:03:21 - INFO - __main__ - Step 340 Global step 340 Train loss 1.66 on epoch=24
05/17/2022 19:03:22 - INFO - __main__ - Step 350 Global step 350 Train loss 1.57 on epoch=24
05/17/2022 19:03:25 - INFO - __main__ - Global step 350 Train loss 1.65 Classification-F1 0.04671846760682295 on epoch=24
05/17/2022 19:03:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0381820560391989 -> 0.04671846760682295 on epoch=24, global_step=350
05/17/2022 19:03:26 - INFO - __main__ - Step 360 Global step 360 Train loss 1.55 on epoch=25
05/17/2022 19:03:27 - INFO - __main__ - Step 370 Global step 370 Train loss 1.47 on epoch=26
05/17/2022 19:03:28 - INFO - __main__ - Step 380 Global step 380 Train loss 1.41 on epoch=27
05/17/2022 19:03:30 - INFO - __main__ - Step 390 Global step 390 Train loss 1.43 on epoch=27
05/17/2022 19:03:31 - INFO - __main__ - Step 400 Global step 400 Train loss 1.42 on epoch=28
05/17/2022 19:03:34 - INFO - __main__ - Global step 400 Train loss 1.46 Classification-F1 0.031160474980699703 on epoch=28
05/17/2022 19:03:35 - INFO - __main__ - Step 410 Global step 410 Train loss 1.36 on epoch=29
05/17/2022 19:03:37 - INFO - __main__ - Step 420 Global step 420 Train loss 1.41 on epoch=29
05/17/2022 19:03:38 - INFO - __main__ - Step 430 Global step 430 Train loss 1.25 on epoch=30
05/17/2022 19:03:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.36 on epoch=31
05/17/2022 19:03:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.44 on epoch=32
05/17/2022 19:03:43 - INFO - __main__ - Global step 450 Train loss 1.36 Classification-F1 0.06569257115412609 on epoch=32
05/17/2022 19:03:43 - INFO - __main__ - Saving model with best Classification-F1: 0.04671846760682295 -> 0.06569257115412609 on epoch=32, global_step=450
05/17/2022 19:03:44 - INFO - __main__ - Step 460 Global step 460 Train loss 1.31 on epoch=32
05/17/2022 19:03:46 - INFO - __main__ - Step 470 Global step 470 Train loss 1.26 on epoch=33
05/17/2022 19:03:47 - INFO - __main__ - Step 480 Global step 480 Train loss 1.30 on epoch=34
05/17/2022 19:03:48 - INFO - __main__ - Step 490 Global step 490 Train loss 1.39 on epoch=34
05/17/2022 19:03:49 - INFO - __main__ - Step 500 Global step 500 Train loss 1.24 on epoch=35
05/17/2022 19:03:52 - INFO - __main__ - Global step 500 Train loss 1.30 Classification-F1 0.02726742871061468 on epoch=35
05/17/2022 19:03:54 - INFO - __main__ - Step 510 Global step 510 Train loss 1.35 on epoch=36
05/17/2022 19:03:55 - INFO - __main__ - Step 520 Global step 520 Train loss 1.27 on epoch=37
05/17/2022 19:03:56 - INFO - __main__ - Step 530 Global step 530 Train loss 1.33 on epoch=37
05/17/2022 19:03:57 - INFO - __main__ - Step 540 Global step 540 Train loss 1.27 on epoch=38
05/17/2022 19:03:59 - INFO - __main__ - Step 550 Global step 550 Train loss 1.26 on epoch=39
05/17/2022 19:04:02 - INFO - __main__ - Global step 550 Train loss 1.30 Classification-F1 0.07825015486305809 on epoch=39
05/17/2022 19:04:02 - INFO - __main__ - Saving model with best Classification-F1: 0.06569257115412609 -> 0.07825015486305809 on epoch=39, global_step=550
05/17/2022 19:04:03 - INFO - __main__ - Step 560 Global step 560 Train loss 1.28 on epoch=39
05/17/2022 19:04:04 - INFO - __main__ - Step 570 Global step 570 Train loss 1.32 on epoch=40
05/17/2022 19:04:05 - INFO - __main__ - Step 580 Global step 580 Train loss 1.19 on epoch=41
05/17/2022 19:04:07 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/17/2022 19:04:08 - INFO - __main__ - Step 600 Global step 600 Train loss 1.26 on epoch=42
05/17/2022 19:04:11 - INFO - __main__ - Global step 600 Train loss 1.25 Classification-F1 0.049771254746958066 on epoch=42
05/17/2022 19:04:12 - INFO - __main__ - Step 610 Global step 610 Train loss 1.22 on epoch=43
05/17/2022 19:04:13 - INFO - __main__ - Step 620 Global step 620 Train loss 1.24 on epoch=44
05/17/2022 19:04:15 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=44
05/17/2022 19:04:16 - INFO - __main__ - Step 640 Global step 640 Train loss 1.22 on epoch=45
05/17/2022 19:04:17 - INFO - __main__ - Step 650 Global step 650 Train loss 1.23 on epoch=46
05/17/2022 19:04:20 - INFO - __main__ - Global step 650 Train loss 1.23 Classification-F1 0.09135531938851137 on epoch=46
05/17/2022 19:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.07825015486305809 -> 0.09135531938851137 on epoch=46, global_step=650
05/17/2022 19:04:22 - INFO - __main__ - Step 660 Global step 660 Train loss 1.22 on epoch=47
05/17/2022 19:04:23 - INFO - __main__ - Step 670 Global step 670 Train loss 1.24 on epoch=47
05/17/2022 19:04:24 - INFO - __main__ - Step 680 Global step 680 Train loss 1.14 on epoch=48
05/17/2022 19:04:26 - INFO - __main__ - Step 690 Global step 690 Train loss 1.31 on epoch=49
05/17/2022 19:04:27 - INFO - __main__ - Step 700 Global step 700 Train loss 1.16 on epoch=49
05/17/2022 19:04:30 - INFO - __main__ - Global step 700 Train loss 1.21 Classification-F1 0.08736098013890373 on epoch=49
05/17/2022 19:04:31 - INFO - __main__ - Step 710 Global step 710 Train loss 1.15 on epoch=50
05/17/2022 19:04:32 - INFO - __main__ - Step 720 Global step 720 Train loss 1.31 on epoch=51
05/17/2022 19:04:33 - INFO - __main__ - Step 730 Global step 730 Train loss 1.15 on epoch=52
05/17/2022 19:04:35 - INFO - __main__ - Step 740 Global step 740 Train loss 1.16 on epoch=52
05/17/2022 19:04:36 - INFO - __main__ - Step 750 Global step 750 Train loss 1.11 on epoch=53
05/17/2022 19:04:39 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.1426971915826405 on epoch=53
05/17/2022 19:04:39 - INFO - __main__ - Saving model with best Classification-F1: 0.09135531938851137 -> 0.1426971915826405 on epoch=53, global_step=750
05/17/2022 19:04:40 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=54
05/17/2022 19:04:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.15 on epoch=54
05/17/2022 19:04:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.12 on epoch=55
05/17/2022 19:04:44 - INFO - __main__ - Step 790 Global step 790 Train loss 1.18 on epoch=56
05/17/2022 19:04:45 - INFO - __main__ - Step 800 Global step 800 Train loss 1.11 on epoch=57
05/17/2022 19:04:48 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.14175972687584742 on epoch=57
05/17/2022 19:04:50 - INFO - __main__ - Step 810 Global step 810 Train loss 1.04 on epoch=57
05/17/2022 19:04:51 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=58
05/17/2022 19:04:52 - INFO - __main__ - Step 830 Global step 830 Train loss 1.12 on epoch=59
05/17/2022 19:04:54 - INFO - __main__ - Step 840 Global step 840 Train loss 1.12 on epoch=59
05/17/2022 19:04:55 - INFO - __main__ - Step 850 Global step 850 Train loss 1.09 on epoch=60
05/17/2022 19:04:58 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.296695194206715 on epoch=60
05/17/2022 19:04:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1426971915826405 -> 0.296695194206715 on epoch=60, global_step=850
05/17/2022 19:04:59 - INFO - __main__ - Step 860 Global step 860 Train loss 1.19 on epoch=61
05/17/2022 19:05:01 - INFO - __main__ - Step 870 Global step 870 Train loss 1.07 on epoch=62
05/17/2022 19:05:02 - INFO - __main__ - Step 880 Global step 880 Train loss 1.02 on epoch=62
05/17/2022 19:05:03 - INFO - __main__ - Step 890 Global step 890 Train loss 1.07 on epoch=63
05/17/2022 19:05:04 - INFO - __main__ - Step 900 Global step 900 Train loss 1.08 on epoch=64
05/17/2022 19:05:08 - INFO - __main__ - Global step 900 Train loss 1.08 Classification-F1 0.22397482234197003 on epoch=64
05/17/2022 19:05:09 - INFO - __main__ - Step 910 Global step 910 Train loss 1.01 on epoch=64
05/17/2022 19:05:10 - INFO - __main__ - Step 920 Global step 920 Train loss 1.05 on epoch=65
05/17/2022 19:05:11 - INFO - __main__ - Step 930 Global step 930 Train loss 1.04 on epoch=66
05/17/2022 19:05:13 - INFO - __main__ - Step 940 Global step 940 Train loss 1.00 on epoch=67
05/17/2022 19:05:14 - INFO - __main__ - Step 950 Global step 950 Train loss 1.00 on epoch=67
05/17/2022 19:05:17 - INFO - __main__ - Global step 950 Train loss 1.02 Classification-F1 0.3420675478242199 on epoch=67
05/17/2022 19:05:17 - INFO - __main__ - Saving model with best Classification-F1: 0.296695194206715 -> 0.3420675478242199 on epoch=67, global_step=950
05/17/2022 19:05:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.95 on epoch=68
05/17/2022 19:05:20 - INFO - __main__ - Step 970 Global step 970 Train loss 1.08 on epoch=69
05/17/2022 19:05:21 - INFO - __main__ - Step 980 Global step 980 Train loss 1.00 on epoch=69
05/17/2022 19:05:22 - INFO - __main__ - Step 990 Global step 990 Train loss 1.02 on epoch=70
05/17/2022 19:05:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.99 on epoch=71
05/17/2022 19:05:27 - INFO - __main__ - Global step 1000 Train loss 1.01 Classification-F1 0.29767263529375965 on epoch=71
05/17/2022 19:05:28 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/17/2022 19:05:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.96 on epoch=72
05/17/2022 19:05:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.94 on epoch=73
05/17/2022 19:05:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/17/2022 19:05:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.03 on epoch=74
05/17/2022 19:05:37 - INFO - __main__ - Global step 1050 Train loss 0.98 Classification-F1 0.3710029673812576 on epoch=74
05/17/2022 19:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3420675478242199 -> 0.3710029673812576 on epoch=74, global_step=1050
05/17/2022 19:05:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.93 on epoch=75
05/17/2022 19:05:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.10 on epoch=76
05/17/2022 19:05:40 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.89 on epoch=77
05/17/2022 19:05:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.95 on epoch=77
05/17/2022 19:05:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.86 on epoch=78
05/17/2022 19:05:46 - INFO - __main__ - Global step 1100 Train loss 0.95 Classification-F1 0.4156813020277727 on epoch=78
05/17/2022 19:05:46 - INFO - __main__ - Saving model with best Classification-F1: 0.3710029673812576 -> 0.4156813020277727 on epoch=78, global_step=1100
05/17/2022 19:05:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.97 on epoch=79
05/17/2022 19:05:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.90 on epoch=79
05/17/2022 19:05:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.88 on epoch=80
05/17/2022 19:05:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.86 on epoch=81
05/17/2022 19:05:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.91 on epoch=82
05/17/2022 19:05:56 - INFO - __main__ - Global step 1150 Train loss 0.91 Classification-F1 0.43352326937020275 on epoch=82
05/17/2022 19:05:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4156813020277727 -> 0.43352326937020275 on epoch=82, global_step=1150
05/17/2022 19:05:58 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.95 on epoch=82
05/17/2022 19:05:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.88 on epoch=83
05/17/2022 19:06:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.87 on epoch=84
05/17/2022 19:06:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.95 on epoch=84
05/17/2022 19:06:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.80 on epoch=85
05/17/2022 19:06:06 - INFO - __main__ - Global step 1200 Train loss 0.89 Classification-F1 0.4577580796556713 on epoch=85
05/17/2022 19:06:06 - INFO - __main__ - Saving model with best Classification-F1: 0.43352326937020275 -> 0.4577580796556713 on epoch=85, global_step=1200
05/17/2022 19:06:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.97 on epoch=86
05/17/2022 19:06:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.89 on epoch=87
05/17/2022 19:06:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.81 on epoch=87
05/17/2022 19:06:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.92 on epoch=88
05/17/2022 19:06:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.88 on epoch=89
05/17/2022 19:06:16 - INFO - __main__ - Global step 1250 Train loss 0.90 Classification-F1 0.47943398774760554 on epoch=89
05/17/2022 19:06:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4577580796556713 -> 0.47943398774760554 on epoch=89, global_step=1250
05/17/2022 19:06:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.81 on epoch=89
05/17/2022 19:06:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.92 on epoch=90
05/17/2022 19:06:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.82 on epoch=91
05/17/2022 19:06:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.84 on epoch=92
05/17/2022 19:06:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.81 on epoch=92
05/17/2022 19:06:26 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.48033639728824784 on epoch=92
05/17/2022 19:06:26 - INFO - __main__ - Saving model with best Classification-F1: 0.47943398774760554 -> 0.48033639728824784 on epoch=92, global_step=1300
05/17/2022 19:06:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.81 on epoch=93
05/17/2022 19:06:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.88 on epoch=94
05/17/2022 19:06:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.83 on epoch=94
05/17/2022 19:06:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.78 on epoch=95
05/17/2022 19:06:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.82 on epoch=96
05/17/2022 19:06:36 - INFO - __main__ - Global step 1350 Train loss 0.82 Classification-F1 0.5088131656176287 on epoch=96
05/17/2022 19:06:36 - INFO - __main__ - Saving model with best Classification-F1: 0.48033639728824784 -> 0.5088131656176287 on epoch=96, global_step=1350
05/17/2022 19:06:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.78 on epoch=97
05/17/2022 19:06:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.74 on epoch=97
05/17/2022 19:06:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.82 on epoch=98
05/17/2022 19:06:41 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.74 on epoch=99
05/17/2022 19:06:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.77 on epoch=99
05/17/2022 19:06:46 - INFO - __main__ - Global step 1400 Train loss 0.77 Classification-F1 0.49265165008692335 on epoch=99
05/17/2022 19:06:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.79 on epoch=100
05/17/2022 19:06:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.79 on epoch=101
05/17/2022 19:06:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.66 on epoch=102
05/17/2022 19:06:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.70 on epoch=102
05/17/2022 19:06:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.68 on epoch=103
05/17/2022 19:06:56 - INFO - __main__ - Global step 1450 Train loss 0.72 Classification-F1 0.5174556741085561 on epoch=103
05/17/2022 19:06:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5088131656176287 -> 0.5174556741085561 on epoch=103, global_step=1450
05/17/2022 19:06:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.89 on epoch=104
05/17/2022 19:06:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.77 on epoch=104
05/17/2022 19:07:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.69 on epoch=105
05/17/2022 19:07:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.72 on epoch=106
05/17/2022 19:07:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.77 on epoch=107
05/17/2022 19:07:06 - INFO - __main__ - Global step 1500 Train loss 0.77 Classification-F1 0.5256229339578652 on epoch=107
05/17/2022 19:07:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5174556741085561 -> 0.5256229339578652 on epoch=107, global_step=1500
05/17/2022 19:07:07 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.66 on epoch=107
05/17/2022 19:07:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.65 on epoch=108
05/17/2022 19:07:10 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.74 on epoch=109
05/17/2022 19:07:11 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.78 on epoch=109
05/17/2022 19:07:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.82 on epoch=110
05/17/2022 19:07:16 - INFO - __main__ - Global step 1550 Train loss 0.73 Classification-F1 0.5820198745481442 on epoch=110
05/17/2022 19:07:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5256229339578652 -> 0.5820198745481442 on epoch=110, global_step=1550
05/17/2022 19:07:17 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.82 on epoch=111
05/17/2022 19:07:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.71 on epoch=112
05/17/2022 19:07:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.60 on epoch=112
05/17/2022 19:07:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.65 on epoch=113
05/17/2022 19:07:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.85 on epoch=114
05/17/2022 19:07:26 - INFO - __main__ - Global step 1600 Train loss 0.73 Classification-F1 0.5848265517046514 on epoch=114
05/17/2022 19:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5820198745481442 -> 0.5848265517046514 on epoch=114, global_step=1600
05/17/2022 19:07:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.75 on epoch=114
05/17/2022 19:07:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.74 on epoch=115
05/17/2022 19:07:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.63 on epoch=116
05/17/2022 19:07:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.74 on epoch=117
05/17/2022 19:07:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.77 on epoch=117
05/17/2022 19:07:36 - INFO - __main__ - Global step 1650 Train loss 0.73 Classification-F1 0.5015725346814093 on epoch=117
05/17/2022 19:07:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.65 on epoch=118
05/17/2022 19:07:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.76 on epoch=119
05/17/2022 19:07:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.69 on epoch=119
05/17/2022 19:07:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.73 on epoch=120
05/17/2022 19:07:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.68 on epoch=121
05/17/2022 19:07:46 - INFO - __main__ - Global step 1700 Train loss 0.70 Classification-F1 0.5579131238908087 on epoch=121
05/17/2022 19:07:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.74 on epoch=122
05/17/2022 19:07:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.66 on epoch=122
05/17/2022 19:07:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.73 on epoch=123
05/17/2022 19:07:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.69 on epoch=124
05/17/2022 19:07:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.73 on epoch=124
05/17/2022 19:07:56 - INFO - __main__ - Global step 1750 Train loss 0.71 Classification-F1 0.5881912321422317 on epoch=124
05/17/2022 19:07:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5848265517046514 -> 0.5881912321422317 on epoch=124, global_step=1750
05/17/2022 19:07:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.66 on epoch=125
05/17/2022 19:07:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.74 on epoch=126
05/17/2022 19:08:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.77 on epoch=127
05/17/2022 19:08:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.65 on epoch=127
05/17/2022 19:08:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.65 on epoch=128
05/17/2022 19:08:07 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.6263649401606022 on epoch=128
05/17/2022 19:08:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5881912321422317 -> 0.6263649401606022 on epoch=128, global_step=1800
05/17/2022 19:08:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.63 on epoch=129
05/17/2022 19:08:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.67 on epoch=129
05/17/2022 19:08:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.72 on epoch=130
05/17/2022 19:08:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.64 on epoch=131
05/17/2022 19:08:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.71 on epoch=132
05/17/2022 19:08:17 - INFO - __main__ - Global step 1850 Train loss 0.67 Classification-F1 0.5660488061927783 on epoch=132
05/17/2022 19:08:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/17/2022 19:08:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.67 on epoch=133
05/17/2022 19:08:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.70 on epoch=134
05/17/2022 19:08:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.66 on epoch=134
05/17/2022 19:08:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.65 on epoch=135
05/17/2022 19:08:28 - INFO - __main__ - Global step 1900 Train loss 0.66 Classification-F1 0.5507182584378699 on epoch=135
05/17/2022 19:08:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.69 on epoch=136
05/17/2022 19:08:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/17/2022 19:08:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.63 on epoch=137
05/17/2022 19:08:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.58 on epoch=138
05/17/2022 19:08:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.65 on epoch=139
05/17/2022 19:08:38 - INFO - __main__ - Global step 1950 Train loss 0.64 Classification-F1 0.5508859426198135 on epoch=139
05/17/2022 19:08:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.62 on epoch=139
05/17/2022 19:08:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.66 on epoch=140
05/17/2022 19:08:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.63 on epoch=141
05/17/2022 19:08:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.68 on epoch=142
05/17/2022 19:08:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.68 on epoch=142
05/17/2022 19:08:48 - INFO - __main__ - Global step 2000 Train loss 0.65 Classification-F1 0.5078998378647774 on epoch=142
05/17/2022 19:08:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.55 on epoch=143
05/17/2022 19:08:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.65 on epoch=144
05/17/2022 19:08:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.63 on epoch=144
05/17/2022 19:08:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.67 on epoch=145
05/17/2022 19:08:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.66 on epoch=146
05/17/2022 19:08:59 - INFO - __main__ - Global step 2050 Train loss 0.63 Classification-F1 0.5370402955147103 on epoch=146
05/17/2022 19:09:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.65 on epoch=147
05/17/2022 19:09:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.66 on epoch=147
05/17/2022 19:09:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.64 on epoch=148
05/17/2022 19:09:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.62 on epoch=149
05/17/2022 19:09:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.64 on epoch=149
05/17/2022 19:09:09 - INFO - __main__ - Global step 2100 Train loss 0.64 Classification-F1 0.617303771989218 on epoch=149
05/17/2022 19:09:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.60 on epoch=150
05/17/2022 19:09:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.54 on epoch=151
05/17/2022 19:09:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.60 on epoch=152
05/17/2022 19:09:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.62 on epoch=152
05/17/2022 19:09:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.61 on epoch=153
05/17/2022 19:09:19 - INFO - __main__ - Global step 2150 Train loss 0.59 Classification-F1 0.6191714862454281 on epoch=153
05/17/2022 19:09:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.69 on epoch=154
05/17/2022 19:09:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.56 on epoch=154
05/17/2022 19:09:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.62 on epoch=155
05/17/2022 19:09:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.67 on epoch=156
05/17/2022 19:09:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.61 on epoch=157
05/17/2022 19:09:30 - INFO - __main__ - Global step 2200 Train loss 0.63 Classification-F1 0.6420258196022015 on epoch=157
05/17/2022 19:09:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6263649401606022 -> 0.6420258196022015 on epoch=157, global_step=2200
05/17/2022 19:09:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.58 on epoch=157
05/17/2022 19:09:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.59 on epoch=158
05/17/2022 19:09:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.73 on epoch=159
05/17/2022 19:09:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.64 on epoch=159
05/17/2022 19:09:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.62 on epoch=160
05/17/2022 19:09:40 - INFO - __main__ - Global step 2250 Train loss 0.63 Classification-F1 0.593803666524819 on epoch=160
05/17/2022 19:09:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.54 on epoch=161
05/17/2022 19:09:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.64 on epoch=162
05/17/2022 19:09:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.66 on epoch=162
05/17/2022 19:09:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.63 on epoch=163
05/17/2022 19:09:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.66 on epoch=164
05/17/2022 19:09:50 - INFO - __main__ - Global step 2300 Train loss 0.63 Classification-F1 0.6457658482431301 on epoch=164
05/17/2022 19:09:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6420258196022015 -> 0.6457658482431301 on epoch=164, global_step=2300
05/17/2022 19:09:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.57 on epoch=164
05/17/2022 19:09:53 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.64 on epoch=165
05/17/2022 19:09:54 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.59 on epoch=166
05/17/2022 19:09:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.59 on epoch=167
05/17/2022 19:09:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.59 on epoch=167
05/17/2022 19:10:00 - INFO - __main__ - Global step 2350 Train loss 0.60 Classification-F1 0.5928688434335039 on epoch=167
05/17/2022 19:10:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.46 on epoch=168
05/17/2022 19:10:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.65 on epoch=169
05/17/2022 19:10:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.63 on epoch=169
05/17/2022 19:10:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.56 on epoch=170
05/17/2022 19:10:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.54 on epoch=171
05/17/2022 19:10:11 - INFO - __main__ - Global step 2400 Train loss 0.57 Classification-F1 0.6467508631135759 on epoch=171
05/17/2022 19:10:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6457658482431301 -> 0.6467508631135759 on epoch=171, global_step=2400
05/17/2022 19:10:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.62 on epoch=172
05/17/2022 19:10:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.53 on epoch=172
05/17/2022 19:10:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.62 on epoch=173
05/17/2022 19:10:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.61 on epoch=174
05/17/2022 19:10:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.56 on epoch=174
05/17/2022 19:10:21 - INFO - __main__ - Global step 2450 Train loss 0.59 Classification-F1 0.5614129865403209 on epoch=174
05/17/2022 19:10:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.66 on epoch=175
05/17/2022 19:10:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.56 on epoch=176
05/17/2022 19:10:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.52 on epoch=177
05/17/2022 19:10:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.60 on epoch=177
05/17/2022 19:10:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.55 on epoch=178
05/17/2022 19:10:32 - INFO - __main__ - Global step 2500 Train loss 0.58 Classification-F1 0.6080456941743887 on epoch=178
05/17/2022 19:10:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.55 on epoch=179
05/17/2022 19:10:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.55 on epoch=179
05/17/2022 19:10:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.66 on epoch=180
05/17/2022 19:10:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.62 on epoch=181
05/17/2022 19:10:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.59 on epoch=182
05/17/2022 19:10:42 - INFO - __main__ - Global step 2550 Train loss 0.59 Classification-F1 0.6275411080786937 on epoch=182
05/17/2022 19:10:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.61 on epoch=182
05/17/2022 19:10:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.58 on epoch=183
05/17/2022 19:10:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.57 on epoch=184
05/17/2022 19:10:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/17/2022 19:10:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/17/2022 19:10:52 - INFO - __main__ - Global step 2600 Train loss 0.59 Classification-F1 0.5860984360984361 on epoch=185
05/17/2022 19:10:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.55 on epoch=186
05/17/2022 19:10:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.51 on epoch=187
05/17/2022 19:10:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.62 on epoch=187
05/17/2022 19:10:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.47 on epoch=188
05/17/2022 19:10:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.54 on epoch=189
05/17/2022 19:11:03 - INFO - __main__ - Global step 2650 Train loss 0.54 Classification-F1 0.6426412587754625 on epoch=189
05/17/2022 19:11:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.58 on epoch=189
05/17/2022 19:11:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.45 on epoch=190
05/17/2022 19:11:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.67 on epoch=191
05/17/2022 19:11:08 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.54 on epoch=192
05/17/2022 19:11:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/17/2022 19:11:13 - INFO - __main__ - Global step 2700 Train loss 0.56 Classification-F1 0.6017365219880997 on epoch=192
05/17/2022 19:11:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.55 on epoch=193
05/17/2022 19:11:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.54 on epoch=194
05/17/2022 19:11:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.57 on epoch=194
05/17/2022 19:11:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.63 on epoch=195
05/17/2022 19:11:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.50 on epoch=196
05/17/2022 19:11:23 - INFO - __main__ - Global step 2750 Train loss 0.56 Classification-F1 0.5971294340493688 on epoch=196
05/17/2022 19:11:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.47 on epoch=197
05/17/2022 19:11:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.53 on epoch=197
05/17/2022 19:11:27 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.51 on epoch=198
05/17/2022 19:11:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.54 on epoch=199
05/17/2022 19:11:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.48 on epoch=199
05/17/2022 19:11:34 - INFO - __main__ - Global step 2800 Train loss 0.51 Classification-F1 0.5333459741210591 on epoch=199
05/17/2022 19:11:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.48 on epoch=200
05/17/2022 19:11:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.50 on epoch=201
05/17/2022 19:11:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.53 on epoch=202
05/17/2022 19:11:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.48 on epoch=202
05/17/2022 19:11:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.53 on epoch=203
05/17/2022 19:11:44 - INFO - __main__ - Global step 2850 Train loss 0.51 Classification-F1 0.5839422757242092 on epoch=203
05/17/2022 19:11:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.53 on epoch=204
05/17/2022 19:11:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.50 on epoch=204
05/17/2022 19:11:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.52 on epoch=205
05/17/2022 19:11:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.56 on epoch=206
05/17/2022 19:11:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.56 on epoch=207
05/17/2022 19:11:54 - INFO - __main__ - Global step 2900 Train loss 0.54 Classification-F1 0.6164217444628414 on epoch=207
05/17/2022 19:11:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.48 on epoch=207
05/17/2022 19:11:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.49 on epoch=208
05/17/2022 19:11:58 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.47 on epoch=209
05/17/2022 19:11:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.53 on epoch=209
05/17/2022 19:12:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.56 on epoch=210
05/17/2022 19:12:05 - INFO - __main__ - Global step 2950 Train loss 0.51 Classification-F1 0.6304720769187915 on epoch=210
05/17/2022 19:12:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.50 on epoch=211
05/17/2022 19:12:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.58 on epoch=212
05/17/2022 19:12:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.57 on epoch=212
05/17/2022 19:12:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.47 on epoch=213
05/17/2022 19:12:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.62 on epoch=214
05/17/2022 19:12:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:12:12 - INFO - __main__ - Printing 3 examples
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:12:12 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:12:12 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:12:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:12:12 - INFO - __main__ - Printing 3 examples
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:12:12 - INFO - __main__ - ['Animal']
05/17/2022 19:12:12 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:12:12 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:12:13 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:12:15 - INFO - __main__ - Global step 3000 Train loss 0.55 Classification-F1 0.656294644427364 on epoch=214
05/17/2022 19:12:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6467508631135759 -> 0.656294644427364 on epoch=214, global_step=3000
05/17/2022 19:12:15 - INFO - __main__ - save last model!
05/17/2022 19:12:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:12:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:12:15 - INFO - __main__ - Printing 3 examples
05/17/2022 19:12:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:12:15 - INFO - __main__ - ['Animal']
05/17/2022 19:12:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:12:15 - INFO - __main__ - ['Animal']
05/17/2022 19:12:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:12:15 - INFO - __main__ - ['Village']
05/17/2022 19:12:15 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:12:17 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:12:18 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:12:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:12:18 - INFO - __main__ - Starting training!
05/17/2022 19:12:20 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:13:35 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/17/2022 19:13:35 - INFO - __main__ - Classification-F1 on test data: 0.3476
05/17/2022 19:13:35 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.656294644427364, test_performance=0.3475793006374498
05/17/2022 19:13:35 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/17/2022 19:13:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:13:36 - INFO - __main__ - Printing 3 examples
05/17/2022 19:13:36 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:13:36 - INFO - __main__ - ['Animal']
05/17/2022 19:13:36 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:13:36 - INFO - __main__ - ['Animal']
05/17/2022 19:13:36 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:13:36 - INFO - __main__ - ['Animal']
05/17/2022 19:13:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:13:37 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:13:37 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:13:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:13:37 - INFO - __main__ - Printing 3 examples
05/17/2022 19:13:37 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:13:37 - INFO - __main__ - ['Animal']
05/17/2022 19:13:37 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:13:37 - INFO - __main__ - ['Animal']
05/17/2022 19:13:37 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:13:37 - INFO - __main__ - ['Animal']
05/17/2022 19:13:37 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:13:37 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:13:37 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:13:43 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:13:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:13:43 - INFO - __main__ - Starting training!
05/17/2022 19:13:44 - INFO - __main__ - Step 10 Global step 10 Train loss 7.76 on epoch=0
05/17/2022 19:13:46 - INFO - __main__ - Step 20 Global step 20 Train loss 6.73 on epoch=1
05/17/2022 19:13:47 - INFO - __main__ - Step 30 Global step 30 Train loss 6.17 on epoch=2
05/17/2022 19:13:48 - INFO - __main__ - Step 40 Global step 40 Train loss 5.79 on epoch=2
05/17/2022 19:13:50 - INFO - __main__ - Step 50 Global step 50 Train loss 5.39 on epoch=3
05/17/2022 19:13:53 - INFO - __main__ - Global step 50 Train loss 6.37 Classification-F1 0.0 on epoch=3
05/17/2022 19:13:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:13:54 - INFO - __main__ - Step 60 Global step 60 Train loss 5.25 on epoch=4
05/17/2022 19:13:56 - INFO - __main__ - Step 70 Global step 70 Train loss 4.89 on epoch=4
05/17/2022 19:13:57 - INFO - __main__ - Step 80 Global step 80 Train loss 4.39 on epoch=5
05/17/2022 19:13:58 - INFO - __main__ - Step 90 Global step 90 Train loss 4.12 on epoch=6
05/17/2022 19:13:59 - INFO - __main__ - Step 100 Global step 100 Train loss 4.13 on epoch=7
05/17/2022 19:14:02 - INFO - __main__ - Global step 100 Train loss 4.55 Classification-F1 0.0 on epoch=7
05/17/2022 19:14:04 - INFO - __main__ - Step 110 Global step 110 Train loss 3.80 on epoch=7
05/17/2022 19:14:05 - INFO - __main__ - Step 120 Global step 120 Train loss 3.71 on epoch=8
05/17/2022 19:14:06 - INFO - __main__ - Step 130 Global step 130 Train loss 3.54 on epoch=9
05/17/2022 19:14:07 - INFO - __main__ - Step 140 Global step 140 Train loss 3.43 on epoch=9
05/17/2022 19:14:09 - INFO - __main__ - Step 150 Global step 150 Train loss 3.06 on epoch=10
05/17/2022 19:14:11 - INFO - __main__ - Global step 150 Train loss 3.51 Classification-F1 0.0035714285714285713 on epoch=10
05/17/2022 19:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0035714285714285713 on epoch=10, global_step=150
05/17/2022 19:14:12 - INFO - __main__ - Step 160 Global step 160 Train loss 3.16 on epoch=11
05/17/2022 19:14:14 - INFO - __main__ - Step 170 Global step 170 Train loss 2.94 on epoch=12
05/17/2022 19:14:15 - INFO - __main__ - Step 180 Global step 180 Train loss 2.88 on epoch=12
05/17/2022 19:14:16 - INFO - __main__ - Step 190 Global step 190 Train loss 2.72 on epoch=13
05/17/2022 19:14:18 - INFO - __main__ - Step 200 Global step 200 Train loss 2.72 on epoch=14
05/17/2022 19:14:20 - INFO - __main__ - Global step 200 Train loss 2.88 Classification-F1 0.009315866084425035 on epoch=14
05/17/2022 19:14:20 - INFO - __main__ - Saving model with best Classification-F1: 0.0035714285714285713 -> 0.009315866084425035 on epoch=14, global_step=200
05/17/2022 19:14:21 - INFO - __main__ - Step 210 Global step 210 Train loss 2.55 on epoch=14
05/17/2022 19:14:22 - INFO - __main__ - Step 220 Global step 220 Train loss 2.49 on epoch=15
05/17/2022 19:14:24 - INFO - __main__ - Step 230 Global step 230 Train loss 2.42 on epoch=16
05/17/2022 19:14:25 - INFO - __main__ - Step 240 Global step 240 Train loss 2.27 on epoch=17
05/17/2022 19:14:26 - INFO - __main__ - Step 250 Global step 250 Train loss 2.28 on epoch=17
05/17/2022 19:14:28 - INFO - __main__ - Global step 250 Train loss 2.40 Classification-F1 0.009523809523809523 on epoch=17
05/17/2022 19:14:28 - INFO - __main__ - Saving model with best Classification-F1: 0.009315866084425035 -> 0.009523809523809523 on epoch=17, global_step=250
05/17/2022 19:14:29 - INFO - __main__ - Step 260 Global step 260 Train loss 2.32 on epoch=18
05/17/2022 19:14:31 - INFO - __main__ - Step 270 Global step 270 Train loss 2.19 on epoch=19
05/17/2022 19:14:32 - INFO - __main__ - Step 280 Global step 280 Train loss 2.21 on epoch=19
05/17/2022 19:14:33 - INFO - __main__ - Step 290 Global step 290 Train loss 1.99 on epoch=20
05/17/2022 19:14:34 - INFO - __main__ - Step 300 Global step 300 Train loss 2.08 on epoch=21
05/17/2022 19:14:37 - INFO - __main__ - Global step 300 Train loss 2.16 Classification-F1 0.024535554131966692 on epoch=21
05/17/2022 19:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024535554131966692 on epoch=21, global_step=300
05/17/2022 19:14:38 - INFO - __main__ - Step 310 Global step 310 Train loss 1.88 on epoch=22
05/17/2022 19:14:39 - INFO - __main__ - Step 320 Global step 320 Train loss 1.82 on epoch=22
05/17/2022 19:14:41 - INFO - __main__ - Step 330 Global step 330 Train loss 1.89 on epoch=23
05/17/2022 19:14:42 - INFO - __main__ - Step 340 Global step 340 Train loss 1.82 on epoch=24
05/17/2022 19:14:43 - INFO - __main__ - Step 350 Global step 350 Train loss 1.74 on epoch=24
05/17/2022 19:14:46 - INFO - __main__ - Global step 350 Train loss 1.83 Classification-F1 0.029036288292428523 on epoch=24
05/17/2022 19:14:46 - INFO - __main__ - Saving model with best Classification-F1: 0.024535554131966692 -> 0.029036288292428523 on epoch=24, global_step=350
05/17/2022 19:14:47 - INFO - __main__ - Step 360 Global step 360 Train loss 1.67 on epoch=25
05/17/2022 19:14:48 - INFO - __main__ - Step 370 Global step 370 Train loss 1.74 on epoch=26
05/17/2022 19:14:50 - INFO - __main__ - Step 380 Global step 380 Train loss 1.65 on epoch=27
05/17/2022 19:14:51 - INFO - __main__ - Step 390 Global step 390 Train loss 1.72 on epoch=27
05/17/2022 19:14:52 - INFO - __main__ - Step 400 Global step 400 Train loss 1.60 on epoch=28
05/17/2022 19:14:55 - INFO - __main__ - Global step 400 Train loss 1.68 Classification-F1 0.04736231497903119 on epoch=28
05/17/2022 19:14:55 - INFO - __main__ - Saving model with best Classification-F1: 0.029036288292428523 -> 0.04736231497903119 on epoch=28, global_step=400
05/17/2022 19:14:56 - INFO - __main__ - Step 410 Global step 410 Train loss 1.63 on epoch=29
05/17/2022 19:14:57 - INFO - __main__ - Step 420 Global step 420 Train loss 1.59 on epoch=29
05/17/2022 19:14:58 - INFO - __main__ - Step 430 Global step 430 Train loss 1.58 on epoch=30
05/17/2022 19:15:00 - INFO - __main__ - Step 440 Global step 440 Train loss 1.59 on epoch=31
05/17/2022 19:15:01 - INFO - __main__ - Step 450 Global step 450 Train loss 1.47 on epoch=32
05/17/2022 19:15:04 - INFO - __main__ - Global step 450 Train loss 1.57 Classification-F1 0.03994744386048734 on epoch=32
05/17/2022 19:15:05 - INFO - __main__ - Step 460 Global step 460 Train loss 1.47 on epoch=32
05/17/2022 19:15:06 - INFO - __main__ - Step 470 Global step 470 Train loss 1.51 on epoch=33
05/17/2022 19:15:08 - INFO - __main__ - Step 480 Global step 480 Train loss 1.52 on epoch=34
05/17/2022 19:15:09 - INFO - __main__ - Step 490 Global step 490 Train loss 1.50 on epoch=34
05/17/2022 19:15:10 - INFO - __main__ - Step 500 Global step 500 Train loss 1.32 on epoch=35
05/17/2022 19:15:13 - INFO - __main__ - Global step 500 Train loss 1.46 Classification-F1 0.029159650789946038 on epoch=35
05/17/2022 19:15:14 - INFO - __main__ - Step 510 Global step 510 Train loss 1.46 on epoch=36
05/17/2022 19:15:15 - INFO - __main__ - Step 520 Global step 520 Train loss 1.20 on epoch=37
05/17/2022 19:15:17 - INFO - __main__ - Step 530 Global step 530 Train loss 1.43 on epoch=37
05/17/2022 19:15:18 - INFO - __main__ - Step 540 Global step 540 Train loss 1.48 on epoch=38
05/17/2022 19:15:19 - INFO - __main__ - Step 550 Global step 550 Train loss 1.49 on epoch=39
05/17/2022 19:15:22 - INFO - __main__ - Global step 550 Train loss 1.41 Classification-F1 0.04402436350924593 on epoch=39
05/17/2022 19:15:23 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=39
05/17/2022 19:15:25 - INFO - __main__ - Step 570 Global step 570 Train loss 1.26 on epoch=40
05/17/2022 19:15:26 - INFO - __main__ - Step 580 Global step 580 Train loss 1.29 on epoch=41
05/17/2022 19:15:27 - INFO - __main__ - Step 590 Global step 590 Train loss 1.30 on epoch=42
05/17/2022 19:15:28 - INFO - __main__ - Step 600 Global step 600 Train loss 1.30 on epoch=42
05/17/2022 19:15:31 - INFO - __main__ - Global step 600 Train loss 1.30 Classification-F1 0.07027649769585255 on epoch=42
05/17/2022 19:15:31 - INFO - __main__ - Saving model with best Classification-F1: 0.04736231497903119 -> 0.07027649769585255 on epoch=42, global_step=600
05/17/2022 19:15:33 - INFO - __main__ - Step 610 Global step 610 Train loss 1.25 on epoch=43
05/17/2022 19:15:34 - INFO - __main__ - Step 620 Global step 620 Train loss 1.27 on epoch=44
05/17/2022 19:15:35 - INFO - __main__ - Step 630 Global step 630 Train loss 1.25 on epoch=44
05/17/2022 19:15:36 - INFO - __main__ - Step 640 Global step 640 Train loss 1.18 on epoch=45
05/17/2022 19:15:38 - INFO - __main__ - Step 650 Global step 650 Train loss 1.24 on epoch=46
05/17/2022 19:15:41 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.15303232950001752 on epoch=46
05/17/2022 19:15:41 - INFO - __main__ - Saving model with best Classification-F1: 0.07027649769585255 -> 0.15303232950001752 on epoch=46, global_step=650
05/17/2022 19:15:42 - INFO - __main__ - Step 660 Global step 660 Train loss 1.26 on epoch=47
05/17/2022 19:15:43 - INFO - __main__ - Step 670 Global step 670 Train loss 1.20 on epoch=47
05/17/2022 19:15:44 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=48
05/17/2022 19:15:46 - INFO - __main__ - Step 690 Global step 690 Train loss 1.29 on epoch=49
05/17/2022 19:15:47 - INFO - __main__ - Step 700 Global step 700 Train loss 1.33 on epoch=49
05/17/2022 19:15:50 - INFO - __main__ - Global step 700 Train loss 1.27 Classification-F1 0.2371194384861121 on epoch=49
05/17/2022 19:15:50 - INFO - __main__ - Saving model with best Classification-F1: 0.15303232950001752 -> 0.2371194384861121 on epoch=49, global_step=700
05/17/2022 19:15:51 - INFO - __main__ - Step 710 Global step 710 Train loss 1.14 on epoch=50
05/17/2022 19:15:53 - INFO - __main__ - Step 720 Global step 720 Train loss 1.26 on epoch=51
05/17/2022 19:15:54 - INFO - __main__ - Step 730 Global step 730 Train loss 1.19 on epoch=52
05/17/2022 19:15:55 - INFO - __main__ - Step 740 Global step 740 Train loss 1.22 on epoch=52
05/17/2022 19:15:56 - INFO - __main__ - Step 750 Global step 750 Train loss 1.13 on epoch=53
05/17/2022 19:16:00 - INFO - __main__ - Global step 750 Train loss 1.19 Classification-F1 0.27584183695970516 on epoch=53
05/17/2022 19:16:00 - INFO - __main__ - Saving model with best Classification-F1: 0.2371194384861121 -> 0.27584183695970516 on epoch=53, global_step=750
05/17/2022 19:16:01 - INFO - __main__ - Step 760 Global step 760 Train loss 1.16 on epoch=54
05/17/2022 19:16:02 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=54
05/17/2022 19:16:04 - INFO - __main__ - Step 780 Global step 780 Train loss 1.13 on epoch=55
05/17/2022 19:16:05 - INFO - __main__ - Step 790 Global step 790 Train loss 1.11 on epoch=56
05/17/2022 19:16:06 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=57
05/17/2022 19:16:09 - INFO - __main__ - Global step 800 Train loss 1.15 Classification-F1 0.28699401324660384 on epoch=57
05/17/2022 19:16:09 - INFO - __main__ - Saving model with best Classification-F1: 0.27584183695970516 -> 0.28699401324660384 on epoch=57, global_step=800
05/17/2022 19:16:11 - INFO - __main__ - Step 810 Global step 810 Train loss 1.14 on epoch=57
05/17/2022 19:16:12 - INFO - __main__ - Step 820 Global step 820 Train loss 1.03 on epoch=58
05/17/2022 19:16:13 - INFO - __main__ - Step 830 Global step 830 Train loss 1.15 on epoch=59
05/17/2022 19:16:14 - INFO - __main__ - Step 840 Global step 840 Train loss 0.99 on epoch=59
05/17/2022 19:16:16 - INFO - __main__ - Step 850 Global step 850 Train loss 1.00 on epoch=60
05/17/2022 19:16:19 - INFO - __main__ - Global step 850 Train loss 1.06 Classification-F1 0.3613625120605195 on epoch=60
05/17/2022 19:16:19 - INFO - __main__ - Saving model with best Classification-F1: 0.28699401324660384 -> 0.3613625120605195 on epoch=60, global_step=850
05/17/2022 19:16:20 - INFO - __main__ - Step 860 Global step 860 Train loss 1.13 on epoch=61
05/17/2022 19:16:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.98 on epoch=62
05/17/2022 19:16:23 - INFO - __main__ - Step 880 Global step 880 Train loss 1.11 on epoch=62
05/17/2022 19:16:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.91 on epoch=63
05/17/2022 19:16:25 - INFO - __main__ - Step 900 Global step 900 Train loss 1.06 on epoch=64
05/17/2022 19:16:28 - INFO - __main__ - Global step 900 Train loss 1.04 Classification-F1 0.3770910367176884 on epoch=64
05/17/2022 19:16:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3613625120605195 -> 0.3770910367176884 on epoch=64, global_step=900
05/17/2022 19:16:30 - INFO - __main__ - Step 910 Global step 910 Train loss 0.96 on epoch=64
05/17/2022 19:16:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.86 on epoch=65
05/17/2022 19:16:32 - INFO - __main__ - Step 930 Global step 930 Train loss 1.03 on epoch=66
05/17/2022 19:16:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.93 on epoch=67
05/17/2022 19:16:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.97 on epoch=67
05/17/2022 19:16:38 - INFO - __main__ - Global step 950 Train loss 0.95 Classification-F1 0.32836793482567933 on epoch=67
05/17/2022 19:16:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.92 on epoch=68
05/17/2022 19:16:40 - INFO - __main__ - Step 970 Global step 970 Train loss 1.01 on epoch=69
05/17/2022 19:16:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.95 on epoch=69
05/17/2022 19:16:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.88 on epoch=70
05/17/2022 19:16:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.93 on epoch=71
05/17/2022 19:16:48 - INFO - __main__ - Global step 1000 Train loss 0.94 Classification-F1 0.38193952812537174 on epoch=71
05/17/2022 19:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.3770910367176884 -> 0.38193952812537174 on epoch=71, global_step=1000
05/17/2022 19:16:49 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.96 on epoch=72
05/17/2022 19:16:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.87 on epoch=72
05/17/2022 19:16:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.94 on epoch=73
05/17/2022 19:16:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.92 on epoch=74
05/17/2022 19:16:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.97 on epoch=74
05/17/2022 19:16:57 - INFO - __main__ - Global step 1050 Train loss 0.93 Classification-F1 0.4694736745788746 on epoch=74
05/17/2022 19:16:57 - INFO - __main__ - Saving model with best Classification-F1: 0.38193952812537174 -> 0.4694736745788746 on epoch=74, global_step=1050
05/17/2022 19:16:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.81 on epoch=75
05/17/2022 19:17:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.78 on epoch=76
05/17/2022 19:17:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.96 on epoch=77
05/17/2022 19:17:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.86 on epoch=77
05/17/2022 19:17:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.81 on epoch=78
05/17/2022 19:17:07 - INFO - __main__ - Global step 1100 Train loss 0.84 Classification-F1 0.4769979548918512 on epoch=78
05/17/2022 19:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4694736745788746 -> 0.4769979548918512 on epoch=78, global_step=1100
05/17/2022 19:17:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.93 on epoch=79
05/17/2022 19:17:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.87 on epoch=79
05/17/2022 19:17:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.86 on epoch=80
05/17/2022 19:17:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.78 on epoch=81
05/17/2022 19:17:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.85 on epoch=82
05/17/2022 19:17:17 - INFO - __main__ - Global step 1150 Train loss 0.86 Classification-F1 0.4305798004124109 on epoch=82
05/17/2022 19:17:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.80 on epoch=82
05/17/2022 19:17:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.79 on epoch=83
05/17/2022 19:17:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.89 on epoch=84
05/17/2022 19:17:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.89 on epoch=84
05/17/2022 19:17:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.78 on epoch=85
05/17/2022 19:17:26 - INFO - __main__ - Global step 1200 Train loss 0.83 Classification-F1 0.5371970798521823 on epoch=85
05/17/2022 19:17:26 - INFO - __main__ - Saving model with best Classification-F1: 0.4769979548918512 -> 0.5371970798521823 on epoch=85, global_step=1200
05/17/2022 19:17:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.77 on epoch=86
05/17/2022 19:17:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.83 on epoch=87
05/17/2022 19:17:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.88 on epoch=87
05/17/2022 19:17:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.69 on epoch=88
05/17/2022 19:17:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.84 on epoch=89
05/17/2022 19:17:36 - INFO - __main__ - Global step 1250 Train loss 0.80 Classification-F1 0.5593650014403917 on epoch=89
05/17/2022 19:17:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5371970798521823 -> 0.5593650014403917 on epoch=89, global_step=1250
05/17/2022 19:17:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.78 on epoch=89
05/17/2022 19:17:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.79 on epoch=90
05/17/2022 19:17:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.78 on epoch=91
05/17/2022 19:17:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.79 on epoch=92
05/17/2022 19:17:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.83 on epoch=92
05/17/2022 19:17:46 - INFO - __main__ - Global step 1300 Train loss 0.79 Classification-F1 0.46245018567333085 on epoch=92
05/17/2022 19:17:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.73 on epoch=93
05/17/2022 19:17:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.74 on epoch=94
05/17/2022 19:17:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.71 on epoch=94
05/17/2022 19:17:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.79 on epoch=95
05/17/2022 19:17:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.79 on epoch=96
05/17/2022 19:17:56 - INFO - __main__ - Global step 1350 Train loss 0.75 Classification-F1 0.514171196821693 on epoch=96
05/17/2022 19:17:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.81 on epoch=97
05/17/2022 19:17:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.78 on epoch=97
05/17/2022 19:18:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.77 on epoch=98
05/17/2022 19:18:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.85 on epoch=99
05/17/2022 19:18:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.82 on epoch=99
05/17/2022 19:18:06 - INFO - __main__ - Global step 1400 Train loss 0.81 Classification-F1 0.45885190522232133 on epoch=99
05/17/2022 19:18:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.74 on epoch=100
05/17/2022 19:18:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.83 on epoch=101
05/17/2022 19:18:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.80 on epoch=102
05/17/2022 19:18:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.69 on epoch=102
05/17/2022 19:18:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/17/2022 19:18:16 - INFO - __main__ - Global step 1450 Train loss 0.76 Classification-F1 0.4647919654626045 on epoch=103
05/17/2022 19:18:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.71 on epoch=104
05/17/2022 19:18:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.67 on epoch=104
05/17/2022 19:18:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.79 on epoch=105
05/17/2022 19:18:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.76 on epoch=106
05/17/2022 19:18:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.67 on epoch=107
05/17/2022 19:18:25 - INFO - __main__ - Global step 1500 Train loss 0.72 Classification-F1 0.5217045329109063 on epoch=107
05/17/2022 19:18:27 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.71 on epoch=107
05/17/2022 19:18:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.65 on epoch=108
05/17/2022 19:18:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.70 on epoch=109
05/17/2022 19:18:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.69 on epoch=109
05/17/2022 19:18:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.67 on epoch=110
05/17/2022 19:18:35 - INFO - __main__ - Global step 1550 Train loss 0.68 Classification-F1 0.6252889229109214 on epoch=110
05/17/2022 19:18:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5593650014403917 -> 0.6252889229109214 on epoch=110, global_step=1550
05/17/2022 19:18:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.75 on epoch=111
05/17/2022 19:18:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.74 on epoch=112
05/17/2022 19:18:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.77 on epoch=112
05/17/2022 19:18:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.68 on epoch=113
05/17/2022 19:18:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.68 on epoch=114
05/17/2022 19:18:45 - INFO - __main__ - Global step 1600 Train loss 0.73 Classification-F1 0.4436415620083209 on epoch=114
05/17/2022 19:18:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.75 on epoch=114
05/17/2022 19:18:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.69 on epoch=115
05/17/2022 19:18:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.66 on epoch=116
05/17/2022 19:18:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.78 on epoch=117
05/17/2022 19:18:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.65 on epoch=117
05/17/2022 19:18:55 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.5261308911788498 on epoch=117
05/17/2022 19:18:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.71 on epoch=118
05/17/2022 19:18:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.72 on epoch=119
05/17/2022 19:18:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.70 on epoch=119
05/17/2022 19:19:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.70 on epoch=120
05/17/2022 19:19:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.72 on epoch=121
05/17/2022 19:19:04 - INFO - __main__ - Global step 1700 Train loss 0.71 Classification-F1 0.5564639916088828 on epoch=121
05/17/2022 19:19:06 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.72 on epoch=122
05/17/2022 19:19:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.70 on epoch=122
05/17/2022 19:19:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.69 on epoch=123
05/17/2022 19:19:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.75 on epoch=124
05/17/2022 19:19:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.70 on epoch=124
05/17/2022 19:19:14 - INFO - __main__ - Global step 1750 Train loss 0.71 Classification-F1 0.5757153753161872 on epoch=124
05/17/2022 19:19:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.68 on epoch=125
05/17/2022 19:19:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.59 on epoch=126
05/17/2022 19:19:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.68 on epoch=127
05/17/2022 19:19:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.69 on epoch=127
05/17/2022 19:19:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.70 on epoch=128
05/17/2022 19:19:24 - INFO - __main__ - Global step 1800 Train loss 0.67 Classification-F1 0.5445356731173963 on epoch=128
05/17/2022 19:19:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.66 on epoch=129
05/17/2022 19:19:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.71 on epoch=129
05/17/2022 19:19:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.65 on epoch=130
05/17/2022 19:19:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.67 on epoch=131
05/17/2022 19:19:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.64 on epoch=132
05/17/2022 19:19:34 - INFO - __main__ - Global step 1850 Train loss 0.67 Classification-F1 0.54820611318046 on epoch=132
05/17/2022 19:19:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/17/2022 19:19:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.65 on epoch=133
05/17/2022 19:19:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.78 on epoch=134
05/17/2022 19:19:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.58 on epoch=134
05/17/2022 19:19:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.67 on epoch=135
05/17/2022 19:19:45 - INFO - __main__ - Global step 1900 Train loss 0.66 Classification-F1 0.6386547337414972 on epoch=135
05/17/2022 19:19:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6252889229109214 -> 0.6386547337414972 on epoch=135, global_step=1900
05/17/2022 19:19:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.71 on epoch=136
05/17/2022 19:19:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/17/2022 19:19:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.69 on epoch=137
05/17/2022 19:19:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.59 on epoch=138
05/17/2022 19:19:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.68 on epoch=139
05/17/2022 19:19:55 - INFO - __main__ - Global step 1950 Train loss 0.67 Classification-F1 0.5211593207481449 on epoch=139
05/17/2022 19:19:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.67 on epoch=139
05/17/2022 19:19:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.59 on epoch=140
05/17/2022 19:19:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.64 on epoch=141
05/17/2022 19:20:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.70 on epoch=142
05/17/2022 19:20:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.71 on epoch=142
05/17/2022 19:20:05 - INFO - __main__ - Global step 2000 Train loss 0.66 Classification-F1 0.5850281050730608 on epoch=142
05/17/2022 19:20:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/17/2022 19:20:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.73 on epoch=144
05/17/2022 19:20:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.71 on epoch=144
05/17/2022 19:20:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.64 on epoch=145
05/17/2022 19:20:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.69 on epoch=146
05/17/2022 19:20:15 - INFO - __main__ - Global step 2050 Train loss 0.69 Classification-F1 0.5373458421383714 on epoch=146
05/17/2022 19:20:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.61 on epoch=147
05/17/2022 19:20:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.60 on epoch=147
05/17/2022 19:20:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.65 on epoch=148
05/17/2022 19:20:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.67 on epoch=149
05/17/2022 19:20:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.64 on epoch=149
05/17/2022 19:20:25 - INFO - __main__ - Global step 2100 Train loss 0.63 Classification-F1 0.6005097757154294 on epoch=149
05/17/2022 19:20:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.61 on epoch=150
05/17/2022 19:20:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.67 on epoch=151
05/17/2022 19:20:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.71 on epoch=152
05/17/2022 19:20:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.57 on epoch=152
05/17/2022 19:20:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.53 on epoch=153
05/17/2022 19:20:35 - INFO - __main__ - Global step 2150 Train loss 0.62 Classification-F1 0.6792367523739249 on epoch=153
05/17/2022 19:20:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6386547337414972 -> 0.6792367523739249 on epoch=153, global_step=2150
05/17/2022 19:20:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.72 on epoch=154
05/17/2022 19:20:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.57 on epoch=154
05/17/2022 19:20:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.57 on epoch=155
05/17/2022 19:20:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.53 on epoch=156
05/17/2022 19:20:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.68 on epoch=157
05/17/2022 19:20:45 - INFO - __main__ - Global step 2200 Train loss 0.62 Classification-F1 0.6759610981256092 on epoch=157
05/17/2022 19:20:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.61 on epoch=157
05/17/2022 19:20:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.59 on epoch=158
05/17/2022 19:20:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.54 on epoch=159
05/17/2022 19:20:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.59 on epoch=159
05/17/2022 19:20:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.59 on epoch=160
05/17/2022 19:20:55 - INFO - __main__ - Global step 2250 Train loss 0.58 Classification-F1 0.6152329833956565 on epoch=160
05/17/2022 19:20:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.62 on epoch=161
05/17/2022 19:20:57 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.56 on epoch=162
05/17/2022 19:20:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.61 on epoch=162
05/17/2022 19:21:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.52 on epoch=163
05/17/2022 19:21:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.62 on epoch=164
05/17/2022 19:21:05 - INFO - __main__ - Global step 2300 Train loss 0.59 Classification-F1 0.6267403480995284 on epoch=164
05/17/2022 19:21:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.58 on epoch=164
05/17/2022 19:21:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.62 on epoch=165
05/17/2022 19:21:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.50 on epoch=166
05/17/2022 19:21:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.59 on epoch=167
05/17/2022 19:21:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.60 on epoch=167
05/17/2022 19:21:16 - INFO - __main__ - Global step 2350 Train loss 0.58 Classification-F1 0.6547887836728481 on epoch=167
05/17/2022 19:21:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.52 on epoch=168
05/17/2022 19:21:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.61 on epoch=169
05/17/2022 19:21:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.57 on epoch=169
05/17/2022 19:21:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.55 on epoch=170
05/17/2022 19:21:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.56 on epoch=171
05/17/2022 19:21:26 - INFO - __main__ - Global step 2400 Train loss 0.56 Classification-F1 0.6257600064274917 on epoch=171
05/17/2022 19:21:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.63 on epoch=172
05/17/2022 19:21:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.59 on epoch=172
05/17/2022 19:21:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.57 on epoch=173
05/17/2022 19:21:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.59 on epoch=174
05/17/2022 19:21:32 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.55 on epoch=174
05/17/2022 19:21:36 - INFO - __main__ - Global step 2450 Train loss 0.59 Classification-F1 0.6542722359638171 on epoch=174
05/17/2022 19:21:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.59 on epoch=175
05/17/2022 19:21:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.58 on epoch=176
05/17/2022 19:21:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.64 on epoch=177
05/17/2022 19:21:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.60 on epoch=177
05/17/2022 19:21:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.53 on epoch=178
05/17/2022 19:21:47 - INFO - __main__ - Global step 2500 Train loss 0.59 Classification-F1 0.6756890612974471 on epoch=178
05/17/2022 19:21:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.62 on epoch=179
05/17/2022 19:21:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.67 on epoch=179
05/17/2022 19:21:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.57 on epoch=180
05/17/2022 19:21:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.54 on epoch=181
05/17/2022 19:21:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.55 on epoch=182
05/17/2022 19:21:57 - INFO - __main__ - Global step 2550 Train loss 0.59 Classification-F1 0.6012919464450097 on epoch=182
05/17/2022 19:21:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.49 on epoch=182
05/17/2022 19:21:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.56 on epoch=183
05/17/2022 19:22:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.62 on epoch=184
05/17/2022 19:22:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/17/2022 19:22:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.58 on epoch=185
05/17/2022 19:22:07 - INFO - __main__ - Global step 2600 Train loss 0.57 Classification-F1 0.5842080153308914 on epoch=185
05/17/2022 19:22:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.52 on epoch=186
05/17/2022 19:22:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.51 on epoch=187
05/17/2022 19:22:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.57 on epoch=187
05/17/2022 19:22:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.46 on epoch=188
05/17/2022 19:22:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.59 on epoch=189
05/17/2022 19:22:17 - INFO - __main__ - Global step 2650 Train loss 0.53 Classification-F1 0.6525689705915226 on epoch=189
05/17/2022 19:22:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.60 on epoch=189
05/17/2022 19:22:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.47 on epoch=190
05/17/2022 19:22:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.61 on epoch=191
05/17/2022 19:22:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.64 on epoch=192
05/17/2022 19:22:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.44 on epoch=192
05/17/2022 19:22:27 - INFO - __main__ - Global step 2700 Train loss 0.55 Classification-F1 0.6877502583064932 on epoch=192
05/17/2022 19:22:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6792367523739249 -> 0.6877502583064932 on epoch=192, global_step=2700
05/17/2022 19:22:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.52 on epoch=193
05/17/2022 19:22:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.67 on epoch=194
05/17/2022 19:22:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.58 on epoch=194
05/17/2022 19:22:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.57 on epoch=195
05/17/2022 19:22:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.52 on epoch=196
05/17/2022 19:22:38 - INFO - __main__ - Global step 2750 Train loss 0.57 Classification-F1 0.6726047977560075 on epoch=196
05/17/2022 19:22:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.49 on epoch=197
05/17/2022 19:22:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.53 on epoch=197
05/17/2022 19:22:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.47 on epoch=198
05/17/2022 19:22:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.60 on epoch=199
05/17/2022 19:22:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.60 on epoch=199
05/17/2022 19:22:48 - INFO - __main__ - Global step 2800 Train loss 0.54 Classification-F1 0.5990672744968453 on epoch=199
05/17/2022 19:22:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.53 on epoch=200
05/17/2022 19:22:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.49 on epoch=201
05/17/2022 19:22:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.60 on epoch=202
05/17/2022 19:22:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.51 on epoch=202
05/17/2022 19:22:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.43 on epoch=203
05/17/2022 19:22:58 - INFO - __main__ - Global step 2850 Train loss 0.51 Classification-F1 0.6896904394230257 on epoch=203
05/17/2022 19:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6877502583064932 -> 0.6896904394230257 on epoch=203, global_step=2850
05/17/2022 19:22:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.55 on epoch=204
05/17/2022 19:23:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.51 on epoch=204
05/17/2022 19:23:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.53 on epoch=205
05/17/2022 19:23:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.49 on epoch=206
05/17/2022 19:23:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.54 on epoch=207
05/17/2022 19:23:08 - INFO - __main__ - Global step 2900 Train loss 0.52 Classification-F1 0.7572429597919794 on epoch=207
05/17/2022 19:23:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6896904394230257 -> 0.7572429597919794 on epoch=207, global_step=2900
05/17/2022 19:23:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.44 on epoch=207
05/17/2022 19:23:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.46 on epoch=208
05/17/2022 19:23:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.56 on epoch=209
05/17/2022 19:23:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.43 on epoch=209
05/17/2022 19:23:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/17/2022 19:23:18 - INFO - __main__ - Global step 2950 Train loss 0.49 Classification-F1 0.6595539474418737 on epoch=210
05/17/2022 19:23:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.44 on epoch=211
05/17/2022 19:23:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.46 on epoch=212
05/17/2022 19:23:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.52 on epoch=212
05/17/2022 19:23:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.51 on epoch=213
05/17/2022 19:23:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.53 on epoch=214
05/17/2022 19:23:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:23:26 - INFO - __main__ - Printing 3 examples
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:23:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:23:26 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:23:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:23:26 - INFO - __main__ - Printing 3 examples
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:23:26 - INFO - __main__ - ['Animal']
05/17/2022 19:23:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:23:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:23:27 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:23:29 - INFO - __main__ - Global step 3000 Train loss 0.49 Classification-F1 0.6517473383912353 on epoch=214
05/17/2022 19:23:29 - INFO - __main__ - save last model!
05/17/2022 19:23:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:23:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:23:29 - INFO - __main__ - Printing 3 examples
05/17/2022 19:23:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:23:29 - INFO - __main__ - ['Animal']
05/17/2022 19:23:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:23:29 - INFO - __main__ - ['Animal']
05/17/2022 19:23:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:23:29 - INFO - __main__ - ['Village']
05/17/2022 19:23:29 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:23:31 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:23:33 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:23:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:23:33 - INFO - __main__ - Starting training!
05/17/2022 19:23:34 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:24:44 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/17/2022 19:24:44 - INFO - __main__ - Classification-F1 on test data: 0.3095
05/17/2022 19:24:45 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.7572429597919794, test_performance=0.3094864968159179
05/17/2022 19:24:45 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/17/2022 19:24:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:24:46 - INFO - __main__ - Printing 3 examples
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:24:46 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:24:46 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:24:46 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:24:46 - INFO - __main__ - Printing 3 examples
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:24:46 - INFO - __main__ - ['Animal']
05/17/2022 19:24:46 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:24:46 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:24:46 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:24:52 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:24:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:24:52 - INFO - __main__ - Starting training!
05/17/2022 19:24:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.49 on epoch=0
05/17/2022 19:24:55 - INFO - __main__ - Step 20 Global step 20 Train loss 6.97 on epoch=1
05/17/2022 19:24:56 - INFO - __main__ - Step 30 Global step 30 Train loss 6.32 on epoch=2
05/17/2022 19:24:57 - INFO - __main__ - Step 40 Global step 40 Train loss 6.09 on epoch=2
05/17/2022 19:24:58 - INFO - __main__ - Step 50 Global step 50 Train loss 5.85 on epoch=3
05/17/2022 19:25:01 - INFO - __main__ - Global step 50 Train loss 6.54 Classification-F1 0.0 on epoch=3
05/17/2022 19:25:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:25:03 - INFO - __main__ - Step 60 Global step 60 Train loss 5.63 on epoch=4
05/17/2022 19:25:04 - INFO - __main__ - Step 70 Global step 70 Train loss 5.35 on epoch=4
05/17/2022 19:25:05 - INFO - __main__ - Step 80 Global step 80 Train loss 4.82 on epoch=5
05/17/2022 19:25:07 - INFO - __main__ - Step 90 Global step 90 Train loss 4.76 on epoch=6
05/17/2022 19:25:08 - INFO - __main__ - Step 100 Global step 100 Train loss 4.45 on epoch=7
05/17/2022 19:25:11 - INFO - __main__ - Global step 100 Train loss 5.00 Classification-F1 0.0 on epoch=7
05/17/2022 19:25:12 - INFO - __main__ - Step 110 Global step 110 Train loss 4.26 on epoch=7
05/17/2022 19:25:13 - INFO - __main__ - Step 120 Global step 120 Train loss 4.08 on epoch=8
05/17/2022 19:25:15 - INFO - __main__ - Step 130 Global step 130 Train loss 3.78 on epoch=9
05/17/2022 19:25:16 - INFO - __main__ - Step 140 Global step 140 Train loss 3.88 on epoch=9
05/17/2022 19:25:17 - INFO - __main__ - Step 150 Global step 150 Train loss 3.53 on epoch=10
05/17/2022 19:25:20 - INFO - __main__ - Global step 150 Train loss 3.91 Classification-F1 0.0 on epoch=10
05/17/2022 19:25:22 - INFO - __main__ - Step 160 Global step 160 Train loss 3.57 on epoch=11
05/17/2022 19:25:23 - INFO - __main__ - Step 170 Global step 170 Train loss 3.55 on epoch=12
05/17/2022 19:25:24 - INFO - __main__ - Step 180 Global step 180 Train loss 3.27 on epoch=12
05/17/2022 19:25:25 - INFO - __main__ - Step 190 Global step 190 Train loss 3.20 on epoch=13
05/17/2022 19:25:27 - INFO - __main__ - Step 200 Global step 200 Train loss 3.14 on epoch=14
05/17/2022 19:25:29 - INFO - __main__ - Global step 200 Train loss 3.35 Classification-F1 0.0024922118380062306 on epoch=14
05/17/2022 19:25:29 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0024922118380062306 on epoch=14, global_step=200
05/17/2022 19:25:31 - INFO - __main__ - Step 210 Global step 210 Train loss 3.15 on epoch=14
05/17/2022 19:25:32 - INFO - __main__ - Step 220 Global step 220 Train loss 2.87 on epoch=15
05/17/2022 19:25:33 - INFO - __main__ - Step 230 Global step 230 Train loss 2.89 on epoch=16
05/17/2022 19:25:34 - INFO - __main__ - Step 240 Global step 240 Train loss 2.86 on epoch=17
05/17/2022 19:25:36 - INFO - __main__ - Step 250 Global step 250 Train loss 2.70 on epoch=17
05/17/2022 19:25:38 - INFO - __main__ - Global step 250 Train loss 2.89 Classification-F1 0.008333333333333333 on epoch=17
05/17/2022 19:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0024922118380062306 -> 0.008333333333333333 on epoch=17, global_step=250
05/17/2022 19:25:39 - INFO - __main__ - Step 260 Global step 260 Train loss 2.51 on epoch=18
05/17/2022 19:25:40 - INFO - __main__ - Step 270 Global step 270 Train loss 2.61 on epoch=19
05/17/2022 19:25:42 - INFO - __main__ - Step 280 Global step 280 Train loss 2.60 on epoch=19
05/17/2022 19:25:43 - INFO - __main__ - Step 290 Global step 290 Train loss 2.40 on epoch=20
05/17/2022 19:25:44 - INFO - __main__ - Step 300 Global step 300 Train loss 2.50 on epoch=21
05/17/2022 19:25:46 - INFO - __main__ - Global step 300 Train loss 2.52 Classification-F1 0.00892608089260809 on epoch=21
05/17/2022 19:25:46 - INFO - __main__ - Saving model with best Classification-F1: 0.008333333333333333 -> 0.00892608089260809 on epoch=21, global_step=300
05/17/2022 19:25:47 - INFO - __main__ - Step 310 Global step 310 Train loss 2.32 on epoch=22
05/17/2022 19:25:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.28 on epoch=22
05/17/2022 19:25:50 - INFO - __main__ - Step 330 Global step 330 Train loss 2.17 on epoch=23
05/17/2022 19:25:51 - INFO - __main__ - Step 340 Global step 340 Train loss 2.19 on epoch=24
05/17/2022 19:25:53 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/17/2022 19:25:54 - INFO - __main__ - Global step 350 Train loss 2.22 Classification-F1 0.009001406469760902 on epoch=24
05/17/2022 19:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009001406469760902 on epoch=24, global_step=350
05/17/2022 19:25:56 - INFO - __main__ - Step 360 Global step 360 Train loss 2.12 on epoch=25
05/17/2022 19:25:57 - INFO - __main__ - Step 370 Global step 370 Train loss 2.03 on epoch=26
05/17/2022 19:25:58 - INFO - __main__ - Step 380 Global step 380 Train loss 2.07 on epoch=27
05/17/2022 19:26:00 - INFO - __main__ - Step 390 Global step 390 Train loss 2.01 on epoch=27
05/17/2022 19:26:01 - INFO - __main__ - Step 400 Global step 400 Train loss 1.93 on epoch=28
05/17/2022 19:26:03 - INFO - __main__ - Global step 400 Train loss 2.03 Classification-F1 0.023682036532754032 on epoch=28
05/17/2022 19:26:03 - INFO - __main__ - Saving model with best Classification-F1: 0.009001406469760902 -> 0.023682036532754032 on epoch=28, global_step=400
05/17/2022 19:26:04 - INFO - __main__ - Step 410 Global step 410 Train loss 2.03 on epoch=29
05/17/2022 19:26:05 - INFO - __main__ - Step 420 Global step 420 Train loss 1.91 on epoch=29
05/17/2022 19:26:06 - INFO - __main__ - Step 430 Global step 430 Train loss 1.90 on epoch=30
05/17/2022 19:26:08 - INFO - __main__ - Step 440 Global step 440 Train loss 1.86 on epoch=31
05/17/2022 19:26:09 - INFO - __main__ - Step 450 Global step 450 Train loss 1.80 on epoch=32
05/17/2022 19:26:11 - INFO - __main__ - Global step 450 Train loss 1.90 Classification-F1 0.02449537390713861 on epoch=32
05/17/2022 19:26:11 - INFO - __main__ - Saving model with best Classification-F1: 0.023682036532754032 -> 0.02449537390713861 on epoch=32, global_step=450
05/17/2022 19:26:12 - INFO - __main__ - Step 460 Global step 460 Train loss 1.80 on epoch=32
05/17/2022 19:26:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.71 on epoch=33
05/17/2022 19:26:15 - INFO - __main__ - Step 480 Global step 480 Train loss 1.66 on epoch=34
05/17/2022 19:26:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.82 on epoch=34
05/17/2022 19:26:17 - INFO - __main__ - Step 500 Global step 500 Train loss 1.50 on epoch=35
05/17/2022 19:26:19 - INFO - __main__ - Global step 500 Train loss 1.70 Classification-F1 0.030796980796980795 on epoch=35
05/17/2022 19:26:19 - INFO - __main__ - Saving model with best Classification-F1: 0.02449537390713861 -> 0.030796980796980795 on epoch=35, global_step=500
05/17/2022 19:26:21 - INFO - __main__ - Step 510 Global step 510 Train loss 1.72 on epoch=36
05/17/2022 19:26:22 - INFO - __main__ - Step 520 Global step 520 Train loss 1.64 on epoch=37
05/17/2022 19:26:23 - INFO - __main__ - Step 530 Global step 530 Train loss 1.60 on epoch=37
05/17/2022 19:26:25 - INFO - __main__ - Step 540 Global step 540 Train loss 1.57 on epoch=38
05/17/2022 19:26:26 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=39
05/17/2022 19:26:28 - INFO - __main__ - Global step 550 Train loss 1.61 Classification-F1 0.0362671384343211 on epoch=39
05/17/2022 19:26:28 - INFO - __main__ - Saving model with best Classification-F1: 0.030796980796980795 -> 0.0362671384343211 on epoch=39, global_step=550
05/17/2022 19:26:30 - INFO - __main__ - Step 560 Global step 560 Train loss 1.60 on epoch=39
05/17/2022 19:26:31 - INFO - __main__ - Step 570 Global step 570 Train loss 1.50 on epoch=40
05/17/2022 19:26:32 - INFO - __main__ - Step 580 Global step 580 Train loss 1.50 on epoch=41
05/17/2022 19:26:33 - INFO - __main__ - Step 590 Global step 590 Train loss 1.47 on epoch=42
05/17/2022 19:26:35 - INFO - __main__ - Step 600 Global step 600 Train loss 1.52 on epoch=42
05/17/2022 19:26:38 - INFO - __main__ - Global step 600 Train loss 1.52 Classification-F1 0.05157937596153971 on epoch=42
05/17/2022 19:26:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0362671384343211 -> 0.05157937596153971 on epoch=42, global_step=600
05/17/2022 19:26:39 - INFO - __main__ - Step 610 Global step 610 Train loss 1.46 on epoch=43
05/17/2022 19:26:40 - INFO - __main__ - Step 620 Global step 620 Train loss 1.51 on epoch=44
05/17/2022 19:26:41 - INFO - __main__ - Step 630 Global step 630 Train loss 1.45 on epoch=44
05/17/2022 19:26:43 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=45
05/17/2022 19:26:44 - INFO - __main__ - Step 650 Global step 650 Train loss 1.52 on epoch=46
05/17/2022 19:26:47 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.05001770972907253 on epoch=46
05/17/2022 19:26:48 - INFO - __main__ - Step 660 Global step 660 Train loss 1.38 on epoch=47
05/17/2022 19:26:50 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=47
05/17/2022 19:26:51 - INFO - __main__ - Step 680 Global step 680 Train loss 1.42 on epoch=48
05/17/2022 19:26:52 - INFO - __main__ - Step 690 Global step 690 Train loss 1.42 on epoch=49
05/17/2022 19:26:53 - INFO - __main__ - Step 700 Global step 700 Train loss 1.50 on epoch=49
05/17/2022 19:26:56 - INFO - __main__ - Global step 700 Train loss 1.44 Classification-F1 0.05177440805273735 on epoch=49
05/17/2022 19:26:56 - INFO - __main__ - Saving model with best Classification-F1: 0.05157937596153971 -> 0.05177440805273735 on epoch=49, global_step=700
05/17/2022 19:26:58 - INFO - __main__ - Step 710 Global step 710 Train loss 1.40 on epoch=50
05/17/2022 19:26:59 - INFO - __main__ - Step 720 Global step 720 Train loss 1.37 on epoch=51
05/17/2022 19:27:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.41 on epoch=52
05/17/2022 19:27:01 - INFO - __main__ - Step 740 Global step 740 Train loss 1.43 on epoch=52
05/17/2022 19:27:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.23 on epoch=53
05/17/2022 19:27:05 - INFO - __main__ - Global step 750 Train loss 1.37 Classification-F1 0.04950527059434245 on epoch=53
05/17/2022 19:27:07 - INFO - __main__ - Step 760 Global step 760 Train loss 1.29 on epoch=54
05/17/2022 19:27:08 - INFO - __main__ - Step 770 Global step 770 Train loss 1.40 on epoch=54
05/17/2022 19:27:09 - INFO - __main__ - Step 780 Global step 780 Train loss 1.34 on epoch=55
05/17/2022 19:27:10 - INFO - __main__ - Step 790 Global step 790 Train loss 1.39 on epoch=56
05/17/2022 19:27:12 - INFO - __main__ - Step 800 Global step 800 Train loss 1.39 on epoch=57
05/17/2022 19:27:14 - INFO - __main__ - Global step 800 Train loss 1.36 Classification-F1 0.0882849787512259 on epoch=57
05/17/2022 19:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.05177440805273735 -> 0.0882849787512259 on epoch=57, global_step=800
05/17/2022 19:27:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.34 on epoch=57
05/17/2022 19:27:17 - INFO - __main__ - Step 820 Global step 820 Train loss 1.27 on epoch=58
05/17/2022 19:27:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.34 on epoch=59
05/17/2022 19:27:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.33 on epoch=59
05/17/2022 19:27:20 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=60
05/17/2022 19:27:23 - INFO - __main__ - Global step 850 Train loss 1.30 Classification-F1 0.0679465394860987 on epoch=60
05/17/2022 19:27:24 - INFO - __main__ - Step 860 Global step 860 Train loss 1.32 on epoch=61
05/17/2022 19:27:26 - INFO - __main__ - Step 870 Global step 870 Train loss 1.27 on epoch=62
05/17/2022 19:27:27 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=62
05/17/2022 19:27:28 - INFO - __main__ - Step 890 Global step 890 Train loss 1.16 on epoch=63
05/17/2022 19:27:30 - INFO - __main__ - Step 900 Global step 900 Train loss 1.30 on epoch=64
05/17/2022 19:27:32 - INFO - __main__ - Global step 900 Train loss 1.26 Classification-F1 0.13070547198145605 on epoch=64
05/17/2022 19:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0882849787512259 -> 0.13070547198145605 on epoch=64, global_step=900
05/17/2022 19:27:34 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=64
05/17/2022 19:27:35 - INFO - __main__ - Step 920 Global step 920 Train loss 1.14 on epoch=65
05/17/2022 19:27:36 - INFO - __main__ - Step 930 Global step 930 Train loss 1.12 on epoch=66
05/17/2022 19:27:37 - INFO - __main__ - Step 940 Global step 940 Train loss 1.27 on epoch=67
05/17/2022 19:27:39 - INFO - __main__ - Step 950 Global step 950 Train loss 1.19 on epoch=67
05/17/2022 19:27:42 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.14456472535032905 on epoch=67
05/17/2022 19:27:42 - INFO - __main__ - Saving model with best Classification-F1: 0.13070547198145605 -> 0.14456472535032905 on epoch=67, global_step=950
05/17/2022 19:27:43 - INFO - __main__ - Step 960 Global step 960 Train loss 1.14 on epoch=68
05/17/2022 19:27:44 - INFO - __main__ - Step 970 Global step 970 Train loss 1.20 on epoch=69
05/17/2022 19:27:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.13 on epoch=69
05/17/2022 19:27:47 - INFO - __main__ - Step 990 Global step 990 Train loss 1.23 on epoch=70
05/17/2022 19:27:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.21 on epoch=71
05/17/2022 19:27:51 - INFO - __main__ - Global step 1000 Train loss 1.18 Classification-F1 0.16793494340091927 on epoch=71
05/17/2022 19:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.14456472535032905 -> 0.16793494340091927 on epoch=71, global_step=1000
05/17/2022 19:27:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.12 on epoch=72
05/17/2022 19:27:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.13 on epoch=72
05/17/2022 19:27:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.18 on epoch=73
05/17/2022 19:27:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.26 on epoch=74
05/17/2022 19:27:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=74
05/17/2022 19:28:00 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.24728569766536715 on epoch=74
05/17/2022 19:28:00 - INFO - __main__ - Saving model with best Classification-F1: 0.16793494340091927 -> 0.24728569766536715 on epoch=74, global_step=1050
05/17/2022 19:28:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=75
05/17/2022 19:28:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.24 on epoch=76
05/17/2022 19:28:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.08 on epoch=77
05/17/2022 19:28:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.31 on epoch=77
05/17/2022 19:28:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.01 on epoch=78
05/17/2022 19:28:10 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.3244508084266361 on epoch=78
05/17/2022 19:28:10 - INFO - __main__ - Saving model with best Classification-F1: 0.24728569766536715 -> 0.3244508084266361 on epoch=78, global_step=1100
05/17/2022 19:28:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=79
05/17/2022 19:28:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.19 on epoch=79
05/17/2022 19:28:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.12 on epoch=80
05/17/2022 19:28:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.10 on epoch=81
05/17/2022 19:28:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.00 on epoch=82
05/17/2022 19:28:20 - INFO - __main__ - Global step 1150 Train loss 1.13 Classification-F1 0.33462911378952453 on epoch=82
05/17/2022 19:28:20 - INFO - __main__ - Saving model with best Classification-F1: 0.3244508084266361 -> 0.33462911378952453 on epoch=82, global_step=1150
05/17/2022 19:28:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.08 on epoch=82
05/17/2022 19:28:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=83
05/17/2022 19:28:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=84
05/17/2022 19:28:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=84
05/17/2022 19:28:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.03 on epoch=85
05/17/2022 19:28:29 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.3499950377394849 on epoch=85
05/17/2022 19:28:29 - INFO - __main__ - Saving model with best Classification-F1: 0.33462911378952453 -> 0.3499950377394849 on epoch=85, global_step=1200
05/17/2022 19:28:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.96 on epoch=86
05/17/2022 19:28:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/17/2022 19:28:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.96 on epoch=87
05/17/2022 19:28:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.02 on epoch=88
05/17/2022 19:28:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=89
05/17/2022 19:28:39 - INFO - __main__ - Global step 1250 Train loss 1.02 Classification-F1 0.3811215708879141 on epoch=89
05/17/2022 19:28:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3499950377394849 -> 0.3811215708879141 on epoch=89, global_step=1250
05/17/2022 19:28:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.00 on epoch=89
05/17/2022 19:28:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.97 on epoch=90
05/17/2022 19:28:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.00 on epoch=91
05/17/2022 19:28:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.03 on epoch=92
05/17/2022 19:28:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.04 on epoch=92
05/17/2022 19:28:49 - INFO - __main__ - Global step 1300 Train loss 1.01 Classification-F1 0.34966306417270004 on epoch=92
05/17/2022 19:28:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.90 on epoch=93
05/17/2022 19:28:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.04 on epoch=94
05/17/2022 19:28:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.03 on epoch=94
05/17/2022 19:28:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.96 on epoch=95
05/17/2022 19:28:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.99 on epoch=96
05/17/2022 19:28:59 - INFO - __main__ - Global step 1350 Train loss 0.98 Classification-F1 0.39252550793041907 on epoch=96
05/17/2022 19:28:59 - INFO - __main__ - Saving model with best Classification-F1: 0.3811215708879141 -> 0.39252550793041907 on epoch=96, global_step=1350
05/17/2022 19:29:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.99 on epoch=97
05/17/2022 19:29:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.92 on epoch=97
05/17/2022 19:29:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.97 on epoch=98
05/17/2022 19:29:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.99 on epoch=99
05/17/2022 19:29:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.96 on epoch=99
05/17/2022 19:29:09 - INFO - __main__ - Global step 1400 Train loss 0.96 Classification-F1 0.4497458919869441 on epoch=99
05/17/2022 19:29:09 - INFO - __main__ - Saving model with best Classification-F1: 0.39252550793041907 -> 0.4497458919869441 on epoch=99, global_step=1400
05/17/2022 19:29:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.93 on epoch=100
05/17/2022 19:29:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.98 on epoch=101
05/17/2022 19:29:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.02 on epoch=102
05/17/2022 19:29:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.87 on epoch=102
05/17/2022 19:29:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.88 on epoch=103
05/17/2022 19:29:19 - INFO - __main__ - Global step 1450 Train loss 0.94 Classification-F1 0.41630367333307927 on epoch=103
05/17/2022 19:29:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.95 on epoch=104
05/17/2022 19:29:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.84 on epoch=104
05/17/2022 19:29:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.93 on epoch=105
05/17/2022 19:29:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.94 on epoch=106
05/17/2022 19:29:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.91 on epoch=107
05/17/2022 19:29:30 - INFO - __main__ - Global step 1500 Train loss 0.92 Classification-F1 0.46933153432715374 on epoch=107
05/17/2022 19:29:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4497458919869441 -> 0.46933153432715374 on epoch=107, global_step=1500
05/17/2022 19:29:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.96 on epoch=107
05/17/2022 19:29:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.94 on epoch=108
05/17/2022 19:29:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.95 on epoch=109
05/17/2022 19:29:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.93 on epoch=109
05/17/2022 19:29:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.83 on epoch=110
05/17/2022 19:29:41 - INFO - __main__ - Global step 1550 Train loss 0.92 Classification-F1 0.49318817290229383 on epoch=110
05/17/2022 19:29:41 - INFO - __main__ - Saving model with best Classification-F1: 0.46933153432715374 -> 0.49318817290229383 on epoch=110, global_step=1550
05/17/2022 19:29:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=111
05/17/2022 19:29:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.94 on epoch=112
05/17/2022 19:29:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.90 on epoch=112
05/17/2022 19:29:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.82 on epoch=113
05/17/2022 19:29:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.86 on epoch=114
05/17/2022 19:29:51 - INFO - __main__ - Global step 1600 Train loss 0.88 Classification-F1 0.42450281516158767 on epoch=114
05/17/2022 19:29:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.88 on epoch=114
05/17/2022 19:29:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.88 on epoch=115
05/17/2022 19:29:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.88 on epoch=116
05/17/2022 19:29:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.82 on epoch=117
05/17/2022 19:29:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.81 on epoch=117
05/17/2022 19:30:01 - INFO - __main__ - Global step 1650 Train loss 0.86 Classification-F1 0.4514951089616117 on epoch=117
05/17/2022 19:30:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.81 on epoch=118
05/17/2022 19:30:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.84 on epoch=119
05/17/2022 19:30:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/17/2022 19:30:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.79 on epoch=120
05/17/2022 19:30:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.88 on epoch=121
05/17/2022 19:30:12 - INFO - __main__ - Global step 1700 Train loss 0.82 Classification-F1 0.4319419459764785 on epoch=121
05/17/2022 19:30:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.89 on epoch=122
05/17/2022 19:30:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.75 on epoch=122
05/17/2022 19:30:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.77 on epoch=123
05/17/2022 19:30:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.84 on epoch=124
05/17/2022 19:30:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.84 on epoch=124
05/17/2022 19:30:23 - INFO - __main__ - Global step 1750 Train loss 0.82 Classification-F1 0.44668164012539724 on epoch=124
05/17/2022 19:30:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.88 on epoch=125
05/17/2022 19:30:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.76 on epoch=126
05/17/2022 19:30:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.83 on epoch=127
05/17/2022 19:30:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.80 on epoch=127
05/17/2022 19:30:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.80 on epoch=128
05/17/2022 19:30:33 - INFO - __main__ - Global step 1800 Train loss 0.81 Classification-F1 0.4773163201989948 on epoch=128
05/17/2022 19:30:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.73 on epoch=129
05/17/2022 19:30:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.77 on epoch=129
05/17/2022 19:30:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.80 on epoch=130
05/17/2022 19:30:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.73 on epoch=131
05/17/2022 19:30:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.70 on epoch=132
05/17/2022 19:30:44 - INFO - __main__ - Global step 1850 Train loss 0.75 Classification-F1 0.4906395921602844 on epoch=132
05/17/2022 19:30:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.75 on epoch=132
05/17/2022 19:30:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.72 on epoch=133
05/17/2022 19:30:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.82 on epoch=134
05/17/2022 19:30:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.73 on epoch=134
05/17/2022 19:30:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.82 on epoch=135
05/17/2022 19:30:54 - INFO - __main__ - Global step 1900 Train loss 0.77 Classification-F1 0.470824544450079 on epoch=135
05/17/2022 19:30:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.76 on epoch=136
05/17/2022 19:30:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.88 on epoch=137
05/17/2022 19:30:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/17/2022 19:31:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/17/2022 19:31:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.78 on epoch=139
05/17/2022 19:31:04 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.46654291136274834 on epoch=139
05/17/2022 19:31:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.72 on epoch=139
05/17/2022 19:31:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.82 on epoch=140
05/17/2022 19:31:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.78 on epoch=141
05/17/2022 19:31:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.84 on epoch=142
05/17/2022 19:31:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.74 on epoch=142
05/17/2022 19:31:14 - INFO - __main__ - Global step 2000 Train loss 0.78 Classification-F1 0.5063532676543112 on epoch=142
05/17/2022 19:31:14 - INFO - __main__ - Saving model with best Classification-F1: 0.49318817290229383 -> 0.5063532676543112 on epoch=142, global_step=2000
05/17/2022 19:31:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.68 on epoch=143
05/17/2022 19:31:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.86 on epoch=144
05/17/2022 19:31:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.69 on epoch=144
05/17/2022 19:31:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.74 on epoch=145
05/17/2022 19:31:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.79 on epoch=146
05/17/2022 19:31:24 - INFO - __main__ - Global step 2050 Train loss 0.75 Classification-F1 0.5245277129700868 on epoch=146
05/17/2022 19:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5063532676543112 -> 0.5245277129700868 on epoch=146, global_step=2050
05/17/2022 19:31:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.82 on epoch=147
05/17/2022 19:31:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.78 on epoch=147
05/17/2022 19:31:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.77 on epoch=148
05/17/2022 19:31:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.80 on epoch=149
05/17/2022 19:31:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.75 on epoch=149
05/17/2022 19:31:34 - INFO - __main__ - Global step 2100 Train loss 0.78 Classification-F1 0.5664838387116167 on epoch=149
05/17/2022 19:31:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5245277129700868 -> 0.5664838387116167 on epoch=149, global_step=2100
05/17/2022 19:31:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.70 on epoch=150
05/17/2022 19:31:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.74 on epoch=151
05/17/2022 19:31:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.80 on epoch=152
05/17/2022 19:31:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.77 on epoch=152
05/17/2022 19:31:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.71 on epoch=153
05/17/2022 19:31:44 - INFO - __main__ - Global step 2150 Train loss 0.74 Classification-F1 0.5412912509851706 on epoch=153
05/17/2022 19:31:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.78 on epoch=154
05/17/2022 19:31:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.76 on epoch=154
05/17/2022 19:31:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.74 on epoch=155
05/17/2022 19:31:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.69 on epoch=156
05/17/2022 19:31:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.80 on epoch=157
05/17/2022 19:31:54 - INFO - __main__ - Global step 2200 Train loss 0.76 Classification-F1 0.5114314623599602 on epoch=157
05/17/2022 19:31:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.80 on epoch=157
05/17/2022 19:31:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.64 on epoch=158
05/17/2022 19:31:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.77 on epoch=159
05/17/2022 19:32:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.73 on epoch=159
05/17/2022 19:32:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.64 on epoch=160
05/17/2022 19:32:04 - INFO - __main__ - Global step 2250 Train loss 0.72 Classification-F1 0.4745899658204248 on epoch=160
05/17/2022 19:32:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.68 on epoch=161
05/17/2022 19:32:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.82 on epoch=162
05/17/2022 19:32:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.67 on epoch=162
05/17/2022 19:32:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.60 on epoch=163
05/17/2022 19:32:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.70 on epoch=164
05/17/2022 19:32:15 - INFO - __main__ - Global step 2300 Train loss 0.69 Classification-F1 0.5205749157488563 on epoch=164
05/17/2022 19:32:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.69 on epoch=164
05/17/2022 19:32:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.72 on epoch=165
05/17/2022 19:32:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.65 on epoch=166
05/17/2022 19:32:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.64 on epoch=167
05/17/2022 19:32:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.63 on epoch=167
05/17/2022 19:32:25 - INFO - __main__ - Global step 2350 Train loss 0.66 Classification-F1 0.5071473033764607 on epoch=167
05/17/2022 19:32:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.61 on epoch=168
05/17/2022 19:32:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/17/2022 19:32:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.70 on epoch=169
05/17/2022 19:32:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.76 on epoch=170
05/17/2022 19:32:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.70 on epoch=171
05/17/2022 19:32:35 - INFO - __main__ - Global step 2400 Train loss 0.69 Classification-F1 0.4987281237999801 on epoch=171
05/17/2022 19:32:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.75 on epoch=172
05/17/2022 19:32:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.66 on epoch=172
05/17/2022 19:32:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.66 on epoch=173
05/17/2022 19:32:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.71 on epoch=174
05/17/2022 19:32:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.72 on epoch=174
05/17/2022 19:32:44 - INFO - __main__ - Global step 2450 Train loss 0.70 Classification-F1 0.5445179902841671 on epoch=174
05/17/2022 19:32:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.81 on epoch=175
05/17/2022 19:32:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.66 on epoch=176
05/17/2022 19:32:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.73 on epoch=177
05/17/2022 19:32:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.77 on epoch=177
05/17/2022 19:32:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.71 on epoch=178
05/17/2022 19:32:54 - INFO - __main__ - Global step 2500 Train loss 0.74 Classification-F1 0.487774540587213 on epoch=178
05/17/2022 19:32:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.64 on epoch=179
05/17/2022 19:32:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.76 on epoch=179
05/17/2022 19:32:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.69 on epoch=180
05/17/2022 19:32:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.69 on epoch=181
05/17/2022 19:33:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.64 on epoch=182
05/17/2022 19:33:04 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.5939992895987185 on epoch=182
05/17/2022 19:33:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5664838387116167 -> 0.5939992895987185 on epoch=182, global_step=2550
05/17/2022 19:33:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/17/2022 19:33:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.61 on epoch=183
05/17/2022 19:33:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/17/2022 19:33:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/17/2022 19:33:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.67 on epoch=185
05/17/2022 19:33:14 - INFO - __main__ - Global step 2600 Train loss 0.65 Classification-F1 0.524013833261686 on epoch=185
05/17/2022 19:33:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.71 on epoch=186
05/17/2022 19:33:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/17/2022 19:33:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.64 on epoch=187
05/17/2022 19:33:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.64 on epoch=188
05/17/2022 19:33:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.75 on epoch=189
05/17/2022 19:33:24 - INFO - __main__ - Global step 2650 Train loss 0.68 Classification-F1 0.47390262610063505 on epoch=189
05/17/2022 19:33:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.66 on epoch=189
05/17/2022 19:33:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.68 on epoch=190
05/17/2022 19:33:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.70 on epoch=191
05/17/2022 19:33:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.66 on epoch=192
05/17/2022 19:33:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.70 on epoch=192
05/17/2022 19:33:34 - INFO - __main__ - Global step 2700 Train loss 0.68 Classification-F1 0.46085450738617956 on epoch=192
05/17/2022 19:33:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.63 on epoch=193
05/17/2022 19:33:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.64 on epoch=194
05/17/2022 19:33:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/17/2022 19:33:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.68 on epoch=195
05/17/2022 19:33:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.63 on epoch=196
05/17/2022 19:33:44 - INFO - __main__ - Global step 2750 Train loss 0.66 Classification-F1 0.5085851663971163 on epoch=196
05/17/2022 19:33:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.73 on epoch=197
05/17/2022 19:33:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.70 on epoch=197
05/17/2022 19:33:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.67 on epoch=198
05/17/2022 19:33:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.75 on epoch=199
05/17/2022 19:33:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.69 on epoch=199
05/17/2022 19:33:54 - INFO - __main__ - Global step 2800 Train loss 0.71 Classification-F1 0.5663433183771196 on epoch=199
05/17/2022 19:33:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.61 on epoch=200
05/17/2022 19:33:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.72 on epoch=201
05/17/2022 19:33:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.73 on epoch=202
05/17/2022 19:33:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/17/2022 19:34:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.59 on epoch=203
05/17/2022 19:34:04 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.4675305015124251 on epoch=203
05/17/2022 19:34:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.69 on epoch=204
05/17/2022 19:34:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.65 on epoch=204
05/17/2022 19:34:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.58 on epoch=205
05/17/2022 19:34:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/17/2022 19:34:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.72 on epoch=207
05/17/2022 19:34:14 - INFO - __main__ - Global step 2900 Train loss 0.65 Classification-F1 0.6283857038623236 on epoch=207
05/17/2022 19:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5939992895987185 -> 0.6283857038623236 on epoch=207, global_step=2900
05/17/2022 19:34:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.71 on epoch=207
05/17/2022 19:34:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.61 on epoch=208
05/17/2022 19:34:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.67 on epoch=209
05/17/2022 19:34:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.74 on epoch=209
05/17/2022 19:34:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.70 on epoch=210
05/17/2022 19:34:25 - INFO - __main__ - Global step 2950 Train loss 0.69 Classification-F1 0.5959853034172045 on epoch=210
05/17/2022 19:34:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.59 on epoch=211
05/17/2022 19:34:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.70 on epoch=212
05/17/2022 19:34:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.69 on epoch=212
05/17/2022 19:34:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.62 on epoch=213
05/17/2022 19:34:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.53 on epoch=214
05/17/2022 19:34:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:34:32 - INFO - __main__ - Printing 3 examples
05/17/2022 19:34:32 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:34:32 - INFO - __main__ - ['Animal']
05/17/2022 19:34:32 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:34:32 - INFO - __main__ - ['Animal']
05/17/2022 19:34:32 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:34:32 - INFO - __main__ - ['Animal']
05/17/2022 19:34:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:34:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:34:33 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:34:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:34:33 - INFO - __main__ - Printing 3 examples
05/17/2022 19:34:33 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:34:33 - INFO - __main__ - ['Animal']
05/17/2022 19:34:33 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:34:33 - INFO - __main__ - ['Animal']
05/17/2022 19:34:33 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:34:33 - INFO - __main__ - ['Animal']
05/17/2022 19:34:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:34:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:34:33 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:34:35 - INFO - __main__ - Global step 3000 Train loss 0.63 Classification-F1 0.5543464184768533 on epoch=214
05/17/2022 19:34:35 - INFO - __main__ - save last model!
05/17/2022 19:34:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:34:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:34:35 - INFO - __main__ - Printing 3 examples
05/17/2022 19:34:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:34:35 - INFO - __main__ - ['Animal']
05/17/2022 19:34:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:34:35 - INFO - __main__ - ['Animal']
05/17/2022 19:34:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:34:35 - INFO - __main__ - ['Village']
05/17/2022 19:34:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:34:37 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:34:39 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:34:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:34:39 - INFO - __main__ - Starting training!
05/17/2022 19:34:40 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:35:48 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/17/2022 19:35:48 - INFO - __main__ - Classification-F1 on test data: 0.2268
05/17/2022 19:35:48 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.6283857038623236, test_performance=0.22678688553921758
05/17/2022 19:35:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/17/2022 19:35:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:35:49 - INFO - __main__ - Printing 3 examples
05/17/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/17/2022 19:35:49 - INFO - __main__ - ['Animal']
05/17/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/17/2022 19:35:49 - INFO - __main__ - ['Animal']
05/17/2022 19:35:49 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/17/2022 19:35:49 - INFO - __main__ - ['Animal']
05/17/2022 19:35:49 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:35:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:35:50 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:35:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:35:50 - INFO - __main__ - Printing 3 examples
05/17/2022 19:35:50 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/17/2022 19:35:50 - INFO - __main__ - ['Animal']
05/17/2022 19:35:50 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/17/2022 19:35:50 - INFO - __main__ - ['Animal']
05/17/2022 19:35:50 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/17/2022 19:35:50 - INFO - __main__ - ['Animal']
05/17/2022 19:35:50 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:35:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:35:50 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:35:56 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:35:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:35:56 - INFO - __main__ - Starting training!
05/17/2022 19:35:58 - INFO - __main__ - Step 10 Global step 10 Train loss 7.23 on epoch=0
05/17/2022 19:35:59 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/17/2022 19:36:00 - INFO - __main__ - Step 30 Global step 30 Train loss 6.75 on epoch=2
05/17/2022 19:36:02 - INFO - __main__ - Step 40 Global step 40 Train loss 6.38 on epoch=2
05/17/2022 19:36:03 - INFO - __main__ - Step 50 Global step 50 Train loss 6.28 on epoch=3
05/17/2022 19:36:06 - INFO - __main__ - Global step 50 Train loss 6.75 Classification-F1 0.0 on epoch=3
05/17/2022 19:36:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:36:07 - INFO - __main__ - Step 60 Global step 60 Train loss 5.84 on epoch=4
05/17/2022 19:36:09 - INFO - __main__ - Step 70 Global step 70 Train loss 5.82 on epoch=4
05/17/2022 19:36:10 - INFO - __main__ - Step 80 Global step 80 Train loss 5.51 on epoch=5
05/17/2022 19:36:12 - INFO - __main__ - Step 90 Global step 90 Train loss 5.35 on epoch=6
05/17/2022 19:36:13 - INFO - __main__ - Step 100 Global step 100 Train loss 5.13 on epoch=7
05/17/2022 19:36:16 - INFO - __main__ - Global step 100 Train loss 5.53 Classification-F1 0.0 on epoch=7
05/17/2022 19:36:17 - INFO - __main__ - Step 110 Global step 110 Train loss 4.96 on epoch=7
05/17/2022 19:36:18 - INFO - __main__ - Step 120 Global step 120 Train loss 4.82 on epoch=8
05/17/2022 19:36:20 - INFO - __main__ - Step 130 Global step 130 Train loss 5.01 on epoch=9
05/17/2022 19:36:21 - INFO - __main__ - Step 140 Global step 140 Train loss 4.65 on epoch=9
05/17/2022 19:36:22 - INFO - __main__ - Step 150 Global step 150 Train loss 4.41 on epoch=10
05/17/2022 19:36:25 - INFO - __main__ - Global step 150 Train loss 4.77 Classification-F1 0.0 on epoch=10
05/17/2022 19:36:27 - INFO - __main__ - Step 160 Global step 160 Train loss 4.29 on epoch=11
05/17/2022 19:36:28 - INFO - __main__ - Step 170 Global step 170 Train loss 4.24 on epoch=12
05/17/2022 19:36:29 - INFO - __main__ - Step 180 Global step 180 Train loss 4.11 on epoch=12
05/17/2022 19:36:31 - INFO - __main__ - Step 190 Global step 190 Train loss 4.05 on epoch=13
05/17/2022 19:36:32 - INFO - __main__ - Step 200 Global step 200 Train loss 3.96 on epoch=14
05/17/2022 19:36:35 - INFO - __main__ - Global step 200 Train loss 4.13 Classification-F1 0.0 on epoch=14
05/17/2022 19:36:37 - INFO - __main__ - Step 210 Global step 210 Train loss 3.97 on epoch=14
05/17/2022 19:36:38 - INFO - __main__ - Step 220 Global step 220 Train loss 3.66 on epoch=15
05/17/2022 19:36:39 - INFO - __main__ - Step 230 Global step 230 Train loss 3.77 on epoch=16
05/17/2022 19:36:40 - INFO - __main__ - Step 240 Global step 240 Train loss 3.59 on epoch=17
05/17/2022 19:36:42 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/17/2022 19:36:45 - INFO - __main__ - Global step 250 Train loss 3.69 Classification-F1 0.0 on epoch=17
05/17/2022 19:36:46 - INFO - __main__ - Step 260 Global step 260 Train loss 3.44 on epoch=18
05/17/2022 19:36:47 - INFO - __main__ - Step 270 Global step 270 Train loss 3.55 on epoch=19
05/17/2022 19:36:49 - INFO - __main__ - Step 280 Global step 280 Train loss 3.35 on epoch=19
05/17/2022 19:36:50 - INFO - __main__ - Step 290 Global step 290 Train loss 3.11 on epoch=20
05/17/2022 19:36:51 - INFO - __main__ - Step 300 Global step 300 Train loss 3.19 on epoch=21
05/17/2022 19:36:54 - INFO - __main__ - Global step 300 Train loss 3.33 Classification-F1 0.0025510204081632655 on epoch=21
05/17/2022 19:36:54 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0025510204081632655 on epoch=21, global_step=300
05/17/2022 19:36:55 - INFO - __main__ - Step 310 Global step 310 Train loss 3.14 on epoch=22
05/17/2022 19:36:57 - INFO - __main__ - Step 320 Global step 320 Train loss 3.12 on epoch=22
05/17/2022 19:36:58 - INFO - __main__ - Step 330 Global step 330 Train loss 3.06 on epoch=23
05/17/2022 19:36:59 - INFO - __main__ - Step 340 Global step 340 Train loss 2.96 on epoch=24
05/17/2022 19:37:01 - INFO - __main__ - Step 350 Global step 350 Train loss 2.86 on epoch=24
05/17/2022 19:37:03 - INFO - __main__ - Global step 350 Train loss 3.03 Classification-F1 0.00670391061452514 on epoch=24
05/17/2022 19:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0025510204081632655 -> 0.00670391061452514 on epoch=24, global_step=350
05/17/2022 19:37:04 - INFO - __main__ - Step 360 Global step 360 Train loss 2.88 on epoch=25
05/17/2022 19:37:06 - INFO - __main__ - Step 370 Global step 370 Train loss 2.78 on epoch=26
05/17/2022 19:37:07 - INFO - __main__ - Step 380 Global step 380 Train loss 2.71 on epoch=27
05/17/2022 19:37:08 - INFO - __main__ - Step 390 Global step 390 Train loss 2.62 on epoch=27
05/17/2022 19:37:10 - INFO - __main__ - Step 400 Global step 400 Train loss 2.58 on epoch=28
05/17/2022 19:37:12 - INFO - __main__ - Global step 400 Train loss 2.71 Classification-F1 0.00880503144654088 on epoch=28
05/17/2022 19:37:12 - INFO - __main__ - Saving model with best Classification-F1: 0.00670391061452514 -> 0.00880503144654088 on epoch=28, global_step=400
05/17/2022 19:37:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.62 on epoch=29
05/17/2022 19:37:14 - INFO - __main__ - Step 420 Global step 420 Train loss 2.60 on epoch=29
05/17/2022 19:37:16 - INFO - __main__ - Step 430 Global step 430 Train loss 2.47 on epoch=30
05/17/2022 19:37:17 - INFO - __main__ - Step 440 Global step 440 Train loss 2.43 on epoch=31
05/17/2022 19:37:18 - INFO - __main__ - Step 450 Global step 450 Train loss 2.40 on epoch=32
05/17/2022 19:37:20 - INFO - __main__ - Global step 450 Train loss 2.50 Classification-F1 0.009523809523809523 on epoch=32
05/17/2022 19:37:20 - INFO - __main__ - Saving model with best Classification-F1: 0.00880503144654088 -> 0.009523809523809523 on epoch=32, global_step=450
05/17/2022 19:37:22 - INFO - __main__ - Step 460 Global step 460 Train loss 2.37 on epoch=32
05/17/2022 19:37:23 - INFO - __main__ - Step 470 Global step 470 Train loss 2.34 on epoch=33
05/17/2022 19:37:24 - INFO - __main__ - Step 480 Global step 480 Train loss 2.39 on epoch=34
05/17/2022 19:37:25 - INFO - __main__ - Step 490 Global step 490 Train loss 2.30 on epoch=34
05/17/2022 19:37:27 - INFO - __main__ - Step 500 Global step 500 Train loss 2.05 on epoch=35
05/17/2022 19:37:29 - INFO - __main__ - Global step 500 Train loss 2.29 Classification-F1 0.009523809523809523 on epoch=35
05/17/2022 19:37:30 - INFO - __main__ - Step 510 Global step 510 Train loss 2.24 on epoch=36
05/17/2022 19:37:31 - INFO - __main__ - Step 520 Global step 520 Train loss 2.31 on epoch=37
05/17/2022 19:37:32 - INFO - __main__ - Step 530 Global step 530 Train loss 2.10 on epoch=37
05/17/2022 19:37:34 - INFO - __main__ - Step 540 Global step 540 Train loss 2.15 on epoch=38
05/17/2022 19:37:35 - INFO - __main__ - Step 550 Global step 550 Train loss 2.16 on epoch=39
05/17/2022 19:37:37 - INFO - __main__ - Global step 550 Train loss 2.19 Classification-F1 0.009644364074743823 on epoch=39
05/17/2022 19:37:37 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009644364074743823 on epoch=39, global_step=550
05/17/2022 19:37:39 - INFO - __main__ - Step 560 Global step 560 Train loss 2.13 on epoch=39
05/17/2022 19:37:40 - INFO - __main__ - Step 570 Global step 570 Train loss 2.09 on epoch=40
05/17/2022 19:37:41 - INFO - __main__ - Step 580 Global step 580 Train loss 2.15 on epoch=41
05/17/2022 19:37:42 - INFO - __main__ - Step 590 Global step 590 Train loss 1.96 on epoch=42
05/17/2022 19:37:44 - INFO - __main__ - Step 600 Global step 600 Train loss 2.03 on epoch=42
05/17/2022 19:37:46 - INFO - __main__ - Global step 600 Train loss 2.07 Classification-F1 0.009894867037724181 on epoch=42
05/17/2022 19:37:46 - INFO - __main__ - Saving model with best Classification-F1: 0.009644364074743823 -> 0.009894867037724181 on epoch=42, global_step=600
05/17/2022 19:37:47 - INFO - __main__ - Step 610 Global step 610 Train loss 1.96 on epoch=43
05/17/2022 19:37:48 - INFO - __main__ - Step 620 Global step 620 Train loss 1.93 on epoch=44
05/17/2022 19:37:50 - INFO - __main__ - Step 630 Global step 630 Train loss 1.94 on epoch=44
05/17/2022 19:37:51 - INFO - __main__ - Step 640 Global step 640 Train loss 1.73 on epoch=45
05/17/2022 19:37:52 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=46
05/17/2022 19:37:55 - INFO - __main__ - Global step 650 Train loss 1.90 Classification-F1 0.02328801902806262 on epoch=46
05/17/2022 19:37:55 - INFO - __main__ - Saving model with best Classification-F1: 0.009894867037724181 -> 0.02328801902806262 on epoch=46, global_step=650
05/17/2022 19:37:56 - INFO - __main__ - Step 660 Global step 660 Train loss 1.85 on epoch=47
05/17/2022 19:37:57 - INFO - __main__ - Step 670 Global step 670 Train loss 1.86 on epoch=47
05/17/2022 19:37:58 - INFO - __main__ - Step 680 Global step 680 Train loss 1.76 on epoch=48
05/17/2022 19:38:00 - INFO - __main__ - Step 690 Global step 690 Train loss 1.90 on epoch=49
05/17/2022 19:38:01 - INFO - __main__ - Step 700 Global step 700 Train loss 1.77 on epoch=49
05/17/2022 19:38:03 - INFO - __main__ - Global step 700 Train loss 1.83 Classification-F1 0.03189765172035549 on epoch=49
05/17/2022 19:38:03 - INFO - __main__ - Saving model with best Classification-F1: 0.02328801902806262 -> 0.03189765172035549 on epoch=49, global_step=700
05/17/2022 19:38:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.79 on epoch=50
05/17/2022 19:38:06 - INFO - __main__ - Step 720 Global step 720 Train loss 1.74 on epoch=51
05/17/2022 19:38:07 - INFO - __main__ - Step 730 Global step 730 Train loss 1.76 on epoch=52
05/17/2022 19:38:09 - INFO - __main__ - Step 740 Global step 740 Train loss 1.72 on epoch=52
05/17/2022 19:38:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.68 on epoch=53
05/17/2022 19:38:13 - INFO - __main__ - Global step 750 Train loss 1.74 Classification-F1 0.03432355190596949 on epoch=53
05/17/2022 19:38:13 - INFO - __main__ - Saving model with best Classification-F1: 0.03189765172035549 -> 0.03432355190596949 on epoch=53, global_step=750
05/17/2022 19:38:14 - INFO - __main__ - Step 760 Global step 760 Train loss 1.70 on epoch=54
05/17/2022 19:38:15 - INFO - __main__ - Step 770 Global step 770 Train loss 1.84 on epoch=54
05/17/2022 19:38:16 - INFO - __main__ - Step 780 Global step 780 Train loss 1.54 on epoch=55
05/17/2022 19:38:18 - INFO - __main__ - Step 790 Global step 790 Train loss 1.62 on epoch=56
05/17/2022 19:38:19 - INFO - __main__ - Step 800 Global step 800 Train loss 1.62 on epoch=57
05/17/2022 19:38:22 - INFO - __main__ - Global step 800 Train loss 1.67 Classification-F1 0.04788472365468425 on epoch=57
05/17/2022 19:38:22 - INFO - __main__ - Saving model with best Classification-F1: 0.03432355190596949 -> 0.04788472365468425 on epoch=57, global_step=800
05/17/2022 19:38:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.66 on epoch=57
05/17/2022 19:38:24 - INFO - __main__ - Step 820 Global step 820 Train loss 1.55 on epoch=58
05/17/2022 19:38:25 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=59
05/17/2022 19:38:27 - INFO - __main__ - Step 840 Global step 840 Train loss 1.55 on epoch=59
05/17/2022 19:38:28 - INFO - __main__ - Step 850 Global step 850 Train loss 1.58 on epoch=60
05/17/2022 19:38:31 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.06756831318640903 on epoch=60
05/17/2022 19:38:31 - INFO - __main__ - Saving model with best Classification-F1: 0.04788472365468425 -> 0.06756831318640903 on epoch=60, global_step=850
05/17/2022 19:38:32 - INFO - __main__ - Step 860 Global step 860 Train loss 1.47 on epoch=61
05/17/2022 19:38:33 - INFO - __main__ - Step 870 Global step 870 Train loss 1.58 on epoch=62
05/17/2022 19:38:35 - INFO - __main__ - Step 880 Global step 880 Train loss 1.55 on epoch=62
05/17/2022 19:38:36 - INFO - __main__ - Step 890 Global step 890 Train loss 1.44 on epoch=63
05/17/2022 19:38:37 - INFO - __main__ - Step 900 Global step 900 Train loss 1.58 on epoch=64
05/17/2022 19:38:40 - INFO - __main__ - Global step 900 Train loss 1.53 Classification-F1 0.03124522180783524 on epoch=64
05/17/2022 19:38:41 - INFO - __main__ - Step 910 Global step 910 Train loss 1.57 on epoch=64
05/17/2022 19:38:42 - INFO - __main__ - Step 920 Global step 920 Train loss 1.44 on epoch=65
05/17/2022 19:38:44 - INFO - __main__ - Step 930 Global step 930 Train loss 1.48 on epoch=66
05/17/2022 19:38:45 - INFO - __main__ - Step 940 Global step 940 Train loss 1.44 on epoch=67
05/17/2022 19:38:46 - INFO - __main__ - Step 950 Global step 950 Train loss 1.48 on epoch=67
05/17/2022 19:38:49 - INFO - __main__ - Global step 950 Train loss 1.48 Classification-F1 0.04890332582087136 on epoch=67
05/17/2022 19:38:50 - INFO - __main__ - Step 960 Global step 960 Train loss 1.46 on epoch=68
05/17/2022 19:38:52 - INFO - __main__ - Step 970 Global step 970 Train loss 1.47 on epoch=69
05/17/2022 19:38:53 - INFO - __main__ - Step 980 Global step 980 Train loss 1.44 on epoch=69
05/17/2022 19:38:54 - INFO - __main__ - Step 990 Global step 990 Train loss 1.36 on epoch=70
05/17/2022 19:38:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.40 on epoch=71
05/17/2022 19:38:58 - INFO - __main__ - Global step 1000 Train loss 1.43 Classification-F1 0.05979590826958037 on epoch=71
05/17/2022 19:39:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.39 on epoch=72
05/17/2022 19:39:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.48 on epoch=72
05/17/2022 19:39:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.41 on epoch=73
05/17/2022 19:39:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.41 on epoch=74
05/17/2022 19:39:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.39 on epoch=74
05/17/2022 19:39:07 - INFO - __main__ - Global step 1050 Train loss 1.42 Classification-F1 0.047322775263951726 on epoch=74
05/17/2022 19:39:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.31 on epoch=75
05/17/2022 19:39:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.31 on epoch=76
05/17/2022 19:39:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=77
05/17/2022 19:39:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.37 on epoch=77
05/17/2022 19:39:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.32 on epoch=78
05/17/2022 19:39:17 - INFO - __main__ - Global step 1100 Train loss 1.32 Classification-F1 0.0571118186658662 on epoch=78
05/17/2022 19:39:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.39 on epoch=79
05/17/2022 19:39:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.34 on epoch=79
05/17/2022 19:39:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=80
05/17/2022 19:39:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.33 on epoch=81
05/17/2022 19:39:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.29 on epoch=82
05/17/2022 19:39:26 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.06400942195059842 on epoch=82
05/17/2022 19:39:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.29 on epoch=82
05/17/2022 19:39:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.30 on epoch=83
05/17/2022 19:39:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.33 on epoch=84
05/17/2022 19:39:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.39 on epoch=84
05/17/2022 19:39:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.29 on epoch=85
05/17/2022 19:39:36 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.07487880319591952 on epoch=85
05/17/2022 19:39:36 - INFO - __main__ - Saving model with best Classification-F1: 0.06756831318640903 -> 0.07487880319591952 on epoch=85, global_step=1200
05/17/2022 19:39:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.37 on epoch=86
05/17/2022 19:39:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.29 on epoch=87
05/17/2022 19:39:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=87
05/17/2022 19:39:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.29 on epoch=88
05/17/2022 19:39:42 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.37 on epoch=89
05/17/2022 19:39:45 - INFO - __main__ - Global step 1250 Train loss 1.32 Classification-F1 0.13571681729576465 on epoch=89
05/17/2022 19:39:45 - INFO - __main__ - Saving model with best Classification-F1: 0.07487880319591952 -> 0.13571681729576465 on epoch=89, global_step=1250
05/17/2022 19:39:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.29 on epoch=89
05/17/2022 19:39:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=90
05/17/2022 19:39:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.35 on epoch=91
05/17/2022 19:39:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.23 on epoch=92
05/17/2022 19:39:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=92
05/17/2022 19:39:54 - INFO - __main__ - Global step 1300 Train loss 1.28 Classification-F1 0.15165816984761937 on epoch=92
05/17/2022 19:39:54 - INFO - __main__ - Saving model with best Classification-F1: 0.13571681729576465 -> 0.15165816984761937 on epoch=92, global_step=1300
05/17/2022 19:39:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.11 on epoch=93
05/17/2022 19:39:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=94
05/17/2022 19:39:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.24 on epoch=94
05/17/2022 19:39:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=95
05/17/2022 19:40:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=96
05/17/2022 19:40:04 - INFO - __main__ - Global step 1350 Train loss 1.23 Classification-F1 0.1574902292881518 on epoch=96
05/17/2022 19:40:04 - INFO - __main__ - Saving model with best Classification-F1: 0.15165816984761937 -> 0.1574902292881518 on epoch=96, global_step=1350
05/17/2022 19:40:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.23 on epoch=97
05/17/2022 19:40:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.20 on epoch=97
05/17/2022 19:40:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=98
05/17/2022 19:40:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.20 on epoch=99
05/17/2022 19:40:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=99
05/17/2022 19:40:13 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.16232871877118576 on epoch=99
05/17/2022 19:40:13 - INFO - __main__ - Saving model with best Classification-F1: 0.1574902292881518 -> 0.16232871877118576 on epoch=99, global_step=1400
05/17/2022 19:40:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.14 on epoch=100
05/17/2022 19:40:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.22 on epoch=101
05/17/2022 19:40:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=102
05/17/2022 19:40:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.26 on epoch=102
05/17/2022 19:40:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.19 on epoch=103
05/17/2022 19:40:23 - INFO - __main__ - Global step 1450 Train loss 1.19 Classification-F1 0.2142795195751142 on epoch=103
05/17/2022 19:40:23 - INFO - __main__ - Saving model with best Classification-F1: 0.16232871877118576 -> 0.2142795195751142 on epoch=103, global_step=1450
05/17/2022 19:40:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.15 on epoch=104
05/17/2022 19:40:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.25 on epoch=104
05/17/2022 19:40:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.14 on epoch=105
05/17/2022 19:40:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.12 on epoch=106
05/17/2022 19:40:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.11 on epoch=107
05/17/2022 19:40:32 - INFO - __main__ - Global step 1500 Train loss 1.15 Classification-F1 0.31443214423755345 on epoch=107
05/17/2022 19:40:32 - INFO - __main__ - Saving model with best Classification-F1: 0.2142795195751142 -> 0.31443214423755345 on epoch=107, global_step=1500
05/17/2022 19:40:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.29 on epoch=107
05/17/2022 19:40:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.15 on epoch=108
05/17/2022 19:40:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.13 on epoch=109
05/17/2022 19:40:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.19 on epoch=109
05/17/2022 19:40:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=110
05/17/2022 19:40:42 - INFO - __main__ - Global step 1550 Train loss 1.18 Classification-F1 0.34313132927220524 on epoch=110
05/17/2022 19:40:42 - INFO - __main__ - Saving model with best Classification-F1: 0.31443214423755345 -> 0.34313132927220524 on epoch=110, global_step=1550
05/17/2022 19:40:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.19 on epoch=111
05/17/2022 19:40:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=112
05/17/2022 19:40:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.13 on epoch=112
05/17/2022 19:40:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.12 on epoch=113
05/17/2022 19:40:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.14 on epoch=114
05/17/2022 19:40:51 - INFO - __main__ - Global step 1600 Train loss 1.15 Classification-F1 0.30428786275882225 on epoch=114
05/17/2022 19:40:53 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.12 on epoch=114
05/17/2022 19:40:54 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.05 on epoch=115
05/17/2022 19:40:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=116
05/17/2022 19:40:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=117
05/17/2022 19:40:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.05 on epoch=117
05/17/2022 19:41:01 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.32333790488294817 on epoch=117
05/17/2022 19:41:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.06 on epoch=118
05/17/2022 19:41:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=119
05/17/2022 19:41:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=119
05/17/2022 19:41:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.07 on epoch=120
05/17/2022 19:41:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=121
05/17/2022 19:41:10 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.32756463176333633 on epoch=121
05/17/2022 19:41:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=122
05/17/2022 19:41:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=122
05/17/2022 19:41:14 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.08 on epoch=123
05/17/2022 19:41:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.12 on epoch=124
05/17/2022 19:41:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=124
05/17/2022 19:41:20 - INFO - __main__ - Global step 1750 Train loss 1.07 Classification-F1 0.3664782154837658 on epoch=124
05/17/2022 19:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.34313132927220524 -> 0.3664782154837658 on epoch=124, global_step=1750
05/17/2022 19:41:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.97 on epoch=125
05/17/2022 19:41:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.08 on epoch=126
05/17/2022 19:41:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=127
05/17/2022 19:41:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=127
05/17/2022 19:41:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=128
05/17/2022 19:41:30 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.35711236990576317 on epoch=128
05/17/2022 19:41:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.08 on epoch=129
05/17/2022 19:41:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.04 on epoch=129
05/17/2022 19:41:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.04 on epoch=130
05/17/2022 19:41:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=131
05/17/2022 19:41:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.12 on epoch=132
05/17/2022 19:41:39 - INFO - __main__ - Global step 1850 Train loss 1.06 Classification-F1 0.407880574472203 on epoch=132
05/17/2022 19:41:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3664782154837658 -> 0.407880574472203 on epoch=132, global_step=1850
05/17/2022 19:41:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=132
05/17/2022 19:41:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=133
05/17/2022 19:41:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.01 on epoch=134
05/17/2022 19:41:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.13 on epoch=134
05/17/2022 19:41:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=135
05/17/2022 19:41:49 - INFO - __main__ - Global step 1900 Train loss 1.03 Classification-F1 0.42413357853871486 on epoch=135
05/17/2022 19:41:49 - INFO - __main__ - Saving model with best Classification-F1: 0.407880574472203 -> 0.42413357853871486 on epoch=135, global_step=1900
05/17/2022 19:41:50 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.04 on epoch=136
05/17/2022 19:41:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=137
05/17/2022 19:41:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=137
05/17/2022 19:41:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=138
05/17/2022 19:41:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.12 on epoch=139
05/17/2022 19:41:59 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.40211789341680154 on epoch=139
05/17/2022 19:42:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.12 on epoch=139
05/17/2022 19:42:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.07 on epoch=140
05/17/2022 19:42:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=141
05/17/2022 19:42:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.02 on epoch=142
05/17/2022 19:42:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.08 on epoch=142
05/17/2022 19:42:08 - INFO - __main__ - Global step 2000 Train loss 1.05 Classification-F1 0.4104689983672708 on epoch=142
05/17/2022 19:42:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.97 on epoch=143
05/17/2022 19:42:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.93 on epoch=144
05/17/2022 19:42:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.98 on epoch=144
05/17/2022 19:42:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.00 on epoch=145
05/17/2022 19:42:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.07 on epoch=146
05/17/2022 19:42:18 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.4102114730209184 on epoch=146
05/17/2022 19:42:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.99 on epoch=147
05/17/2022 19:42:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.03 on epoch=147
05/17/2022 19:42:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=148
05/17/2022 19:42:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=149
05/17/2022 19:42:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.16 on epoch=149
05/17/2022 19:42:28 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.4193092844655344 on epoch=149
05/17/2022 19:42:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.88 on epoch=150
05/17/2022 19:42:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.01 on epoch=151
05/17/2022 19:42:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.86 on epoch=152
05/17/2022 19:42:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=152
05/17/2022 19:42:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.96 on epoch=153
05/17/2022 19:42:38 - INFO - __main__ - Global step 2150 Train loss 0.95 Classification-F1 0.4373458279758817 on epoch=153
05/17/2022 19:42:38 - INFO - __main__ - Saving model with best Classification-F1: 0.42413357853871486 -> 0.4373458279758817 on epoch=153, global_step=2150
05/17/2022 19:42:40 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.04 on epoch=154
05/17/2022 19:42:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=154
05/17/2022 19:42:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.95 on epoch=155
05/17/2022 19:42:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=156
05/17/2022 19:42:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=157
05/17/2022 19:42:48 - INFO - __main__ - Global step 2200 Train loss 1.00 Classification-F1 0.46914545395802887 on epoch=157
05/17/2022 19:42:48 - INFO - __main__ - Saving model with best Classification-F1: 0.4373458279758817 -> 0.46914545395802887 on epoch=157, global_step=2200
05/17/2022 19:42:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.88 on epoch=157
05/17/2022 19:42:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.99 on epoch=158
05/17/2022 19:42:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=159
05/17/2022 19:42:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=159
05/17/2022 19:42:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.93 on epoch=160
05/17/2022 19:42:58 - INFO - __main__ - Global step 2250 Train loss 0.96 Classification-F1 0.36186512730373427 on epoch=160
05/17/2022 19:43:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.98 on epoch=161
05/17/2022 19:43:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=162
05/17/2022 19:43:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=162
05/17/2022 19:43:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.92 on epoch=163
05/17/2022 19:43:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.05 on epoch=164
05/17/2022 19:43:08 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.492250036106172 on epoch=164
05/17/2022 19:43:08 - INFO - __main__ - Saving model with best Classification-F1: 0.46914545395802887 -> 0.492250036106172 on epoch=164, global_step=2300
05/17/2022 19:43:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=164
05/17/2022 19:43:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.96 on epoch=165
05/17/2022 19:43:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=166
05/17/2022 19:43:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=167
05/17/2022 19:43:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.95 on epoch=167
05/17/2022 19:43:18 - INFO - __main__ - Global step 2350 Train loss 0.99 Classification-F1 0.497193331044547 on epoch=167
05/17/2022 19:43:18 - INFO - __main__ - Saving model with best Classification-F1: 0.492250036106172 -> 0.497193331044547 on epoch=167, global_step=2350
05/17/2022 19:43:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=168
05/17/2022 19:43:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.94 on epoch=169
05/17/2022 19:43:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=169
05/17/2022 19:43:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.90 on epoch=170
05/17/2022 19:43:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=171
05/17/2022 19:43:28 - INFO - __main__ - Global step 2400 Train loss 0.94 Classification-F1 0.47662941813856025 on epoch=171
05/17/2022 19:43:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.01 on epoch=172
05/17/2022 19:43:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.92 on epoch=172
05/17/2022 19:43:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.95 on epoch=173
05/17/2022 19:43:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=174
05/17/2022 19:43:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=174
05/17/2022 19:43:38 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.4870166209403959 on epoch=174
05/17/2022 19:43:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.91 on epoch=175
05/17/2022 19:43:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=176
05/17/2022 19:43:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.92 on epoch=177
05/17/2022 19:43:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.87 on epoch=177
05/17/2022 19:43:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.85 on epoch=178
05/17/2022 19:43:48 - INFO - __main__ - Global step 2500 Train loss 0.91 Classification-F1 0.4571216569907926 on epoch=178
05/17/2022 19:43:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=179
05/17/2022 19:43:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=179
05/17/2022 19:43:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.85 on epoch=180
05/17/2022 19:43:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.96 on epoch=181
05/17/2022 19:43:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.88 on epoch=182
05/17/2022 19:43:58 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.49724040344662623 on epoch=182
05/17/2022 19:43:58 - INFO - __main__ - Saving model with best Classification-F1: 0.497193331044547 -> 0.49724040344662623 on epoch=182, global_step=2550
05/17/2022 19:43:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=182
05/17/2022 19:44:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.87 on epoch=183
05/17/2022 19:44:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.87 on epoch=184
05/17/2022 19:44:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=184
05/17/2022 19:44:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.89 on epoch=185
05/17/2022 19:44:08 - INFO - __main__ - Global step 2600 Train loss 0.92 Classification-F1 0.5475490730996848 on epoch=185
05/17/2022 19:44:08 - INFO - __main__ - Saving model with best Classification-F1: 0.49724040344662623 -> 0.5475490730996848 on epoch=185, global_step=2600
05/17/2022 19:44:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.91 on epoch=186
05/17/2022 19:44:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=187
05/17/2022 19:44:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.84 on epoch=187
05/17/2022 19:44:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.81 on epoch=188
05/17/2022 19:44:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.90 on epoch=189
05/17/2022 19:44:18 - INFO - __main__ - Global step 2650 Train loss 0.87 Classification-F1 0.5348265149366306 on epoch=189
05/17/2022 19:44:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.83 on epoch=189
05/17/2022 19:44:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=190
05/17/2022 19:44:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.89 on epoch=191
05/17/2022 19:44:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=192
05/17/2022 19:44:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.93 on epoch=192
05/17/2022 19:44:28 - INFO - __main__ - Global step 2700 Train loss 0.90 Classification-F1 0.44645601641566895 on epoch=192
05/17/2022 19:44:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.96 on epoch=193
05/17/2022 19:44:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=194
05/17/2022 19:44:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.85 on epoch=194
05/17/2022 19:44:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=195
05/17/2022 19:44:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=196
05/17/2022 19:44:38 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.48783690611785957 on epoch=196
05/17/2022 19:44:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=197
05/17/2022 19:44:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.91 on epoch=197
05/17/2022 19:44:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.82 on epoch=198
05/17/2022 19:44:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.99 on epoch=199
05/17/2022 19:44:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=199
05/17/2022 19:44:48 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.48960719228332755 on epoch=199
05/17/2022 19:44:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.87 on epoch=200
05/17/2022 19:44:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.90 on epoch=201
05/17/2022 19:44:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.96 on epoch=202
05/17/2022 19:44:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.78 on epoch=202
05/17/2022 19:44:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.80 on epoch=203
05/17/2022 19:44:59 - INFO - __main__ - Global step 2850 Train loss 0.86 Classification-F1 0.5443174414488889 on epoch=203
05/17/2022 19:45:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.91 on epoch=204
05/17/2022 19:45:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.94 on epoch=204
05/17/2022 19:45:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.86 on epoch=205
05/17/2022 19:45:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.82 on epoch=206
05/17/2022 19:45:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.99 on epoch=207
05/17/2022 19:45:09 - INFO - __main__ - Global step 2900 Train loss 0.91 Classification-F1 0.5014152174358549 on epoch=207
05/17/2022 19:45:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=207
05/17/2022 19:45:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.78 on epoch=208
05/17/2022 19:45:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.94 on epoch=209
05/17/2022 19:45:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/17/2022 19:45:15 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.89 on epoch=210
05/17/2022 19:45:19 - INFO - __main__ - Global step 2950 Train loss 0.87 Classification-F1 0.5610991655183694 on epoch=210
05/17/2022 19:45:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5475490730996848 -> 0.5610991655183694 on epoch=210, global_step=2950
05/17/2022 19:45:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=211
05/17/2022 19:45:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.87 on epoch=212
05/17/2022 19:45:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.83 on epoch=212
05/17/2022 19:45:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.88 on epoch=213
05/17/2022 19:45:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.82 on epoch=214
05/17/2022 19:45:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:45:27 - INFO - __main__ - Printing 3 examples
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:45:27 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:45:27 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:45:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:45:27 - INFO - __main__ - Printing 3 examples
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 19:45:27 - INFO - __main__ - ['Plant']
05/17/2022 19:45:27 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:45:27 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:45:27 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:45:29 - INFO - __main__ - Global step 3000 Train loss 0.86 Classification-F1 0.5168053985098775 on epoch=214
05/17/2022 19:45:29 - INFO - __main__ - save last model!
05/17/2022 19:45:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:45:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:45:29 - INFO - __main__ - Printing 3 examples
05/17/2022 19:45:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:45:29 - INFO - __main__ - ['Animal']
05/17/2022 19:45:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:45:29 - INFO - __main__ - ['Animal']
05/17/2022 19:45:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:45:29 - INFO - __main__ - ['Village']
05/17/2022 19:45:29 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:45:31 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:45:33 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:45:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:45:33 - INFO - __main__ - Starting training!
05/17/2022 19:45:34 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:46:32 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/17/2022 19:46:32 - INFO - __main__ - Classification-F1 on test data: 0.1913
05/17/2022 19:46:32 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.5610991655183694, test_performance=0.19132566812166832
05/17/2022 19:46:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/17/2022 19:46:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:46:33 - INFO - __main__ - Printing 3 examples
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:46:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:46:33 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:46:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:46:33 - INFO - __main__ - Printing 3 examples
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 19:46:33 - INFO - __main__ - ['Plant']
05/17/2022 19:46:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:46:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:46:34 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:46:39 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:46:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:46:39 - INFO - __main__ - Starting training!
05/17/2022 19:46:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.73 on epoch=0
05/17/2022 19:46:42 - INFO - __main__ - Step 20 Global step 20 Train loss 6.75 on epoch=1
05/17/2022 19:46:43 - INFO - __main__ - Step 30 Global step 30 Train loss 5.96 on epoch=2
05/17/2022 19:46:45 - INFO - __main__ - Step 40 Global step 40 Train loss 5.53 on epoch=2
05/17/2022 19:46:46 - INFO - __main__ - Step 50 Global step 50 Train loss 5.10 on epoch=3
05/17/2022 19:46:49 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=3
05/17/2022 19:46:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:46:51 - INFO - __main__ - Step 60 Global step 60 Train loss 4.87 on epoch=4
05/17/2022 19:46:52 - INFO - __main__ - Step 70 Global step 70 Train loss 4.35 on epoch=4
05/17/2022 19:46:53 - INFO - __main__ - Step 80 Global step 80 Train loss 4.22 on epoch=5
05/17/2022 19:46:55 - INFO - __main__ - Step 90 Global step 90 Train loss 3.78 on epoch=6
05/17/2022 19:46:56 - INFO - __main__ - Step 100 Global step 100 Train loss 3.62 on epoch=7
05/17/2022 19:46:59 - INFO - __main__ - Global step 100 Train loss 4.17 Classification-F1 0.0 on epoch=7
05/17/2022 19:47:01 - INFO - __main__ - Step 110 Global step 110 Train loss 3.51 on epoch=7
05/17/2022 19:47:02 - INFO - __main__ - Step 120 Global step 120 Train loss 3.33 on epoch=8
05/17/2022 19:47:03 - INFO - __main__ - Step 130 Global step 130 Train loss 3.33 on epoch=9
05/17/2022 19:47:04 - INFO - __main__ - Step 140 Global step 140 Train loss 2.89 on epoch=9
05/17/2022 19:47:06 - INFO - __main__ - Step 150 Global step 150 Train loss 2.99 on epoch=10
05/17/2022 19:47:08 - INFO - __main__ - Global step 150 Train loss 3.21 Classification-F1 0.005893186003683242 on epoch=10
05/17/2022 19:47:08 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005893186003683242 on epoch=10, global_step=150
05/17/2022 19:47:09 - INFO - __main__ - Step 160 Global step 160 Train loss 2.74 on epoch=11
05/17/2022 19:47:10 - INFO - __main__ - Step 170 Global step 170 Train loss 2.69 on epoch=12
05/17/2022 19:47:12 - INFO - __main__ - Step 180 Global step 180 Train loss 2.57 on epoch=12
05/17/2022 19:47:13 - INFO - __main__ - Step 190 Global step 190 Train loss 2.49 on epoch=13
05/17/2022 19:47:14 - INFO - __main__ - Step 200 Global step 200 Train loss 2.41 on epoch=14
05/17/2022 19:47:16 - INFO - __main__ - Global step 200 Train loss 2.58 Classification-F1 0.009523809523809523 on epoch=14
05/17/2022 19:47:16 - INFO - __main__ - Saving model with best Classification-F1: 0.005893186003683242 -> 0.009523809523809523 on epoch=14, global_step=200
05/17/2022 19:47:17 - INFO - __main__ - Step 210 Global step 210 Train loss 2.31 on epoch=14
05/17/2022 19:47:19 - INFO - __main__ - Step 220 Global step 220 Train loss 2.25 on epoch=15
05/17/2022 19:47:20 - INFO - __main__ - Step 230 Global step 230 Train loss 2.10 on epoch=16
05/17/2022 19:47:21 - INFO - __main__ - Step 240 Global step 240 Train loss 2.16 on epoch=17
05/17/2022 19:47:22 - INFO - __main__ - Step 250 Global step 250 Train loss 2.02 on epoch=17
05/17/2022 19:47:24 - INFO - __main__ - Global step 250 Train loss 2.17 Classification-F1 0.03466486043255069 on epoch=17
05/17/2022 19:47:24 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.03466486043255069 on epoch=17, global_step=250
05/17/2022 19:47:26 - INFO - __main__ - Step 260 Global step 260 Train loss 1.96 on epoch=18
05/17/2022 19:47:27 - INFO - __main__ - Step 270 Global step 270 Train loss 1.89 on epoch=19
05/17/2022 19:47:28 - INFO - __main__ - Step 280 Global step 280 Train loss 1.76 on epoch=19
05/17/2022 19:47:29 - INFO - __main__ - Step 290 Global step 290 Train loss 1.80 on epoch=20
05/17/2022 19:47:31 - INFO - __main__ - Step 300 Global step 300 Train loss 1.77 on epoch=21
05/17/2022 19:47:33 - INFO - __main__ - Global step 300 Train loss 1.84 Classification-F1 0.029542102051052704 on epoch=21
05/17/2022 19:47:34 - INFO - __main__ - Step 310 Global step 310 Train loss 1.88 on epoch=22
05/17/2022 19:47:35 - INFO - __main__ - Step 320 Global step 320 Train loss 1.74 on epoch=22
05/17/2022 19:47:36 - INFO - __main__ - Step 330 Global step 330 Train loss 1.63 on epoch=23
05/17/2022 19:47:37 - INFO - __main__ - Step 340 Global step 340 Train loss 1.55 on epoch=24
05/17/2022 19:47:39 - INFO - __main__ - Step 350 Global step 350 Train loss 1.56 on epoch=24
05/17/2022 19:47:41 - INFO - __main__ - Global step 350 Train loss 1.67 Classification-F1 0.025014459224985543 on epoch=24
05/17/2022 19:47:42 - INFO - __main__ - Step 360 Global step 360 Train loss 1.58 on epoch=25
05/17/2022 19:47:44 - INFO - __main__ - Step 370 Global step 370 Train loss 1.50 on epoch=26
05/17/2022 19:47:45 - INFO - __main__ - Step 380 Global step 380 Train loss 1.53 on epoch=27
05/17/2022 19:47:46 - INFO - __main__ - Step 390 Global step 390 Train loss 1.59 on epoch=27
05/17/2022 19:47:47 - INFO - __main__ - Step 400 Global step 400 Train loss 1.40 on epoch=28
05/17/2022 19:47:50 - INFO - __main__ - Global step 400 Train loss 1.52 Classification-F1 0.0417027417027417 on epoch=28
05/17/2022 19:47:50 - INFO - __main__ - Saving model with best Classification-F1: 0.03466486043255069 -> 0.0417027417027417 on epoch=28, global_step=400
05/17/2022 19:47:51 - INFO - __main__ - Step 410 Global step 410 Train loss 1.35 on epoch=29
05/17/2022 19:47:52 - INFO - __main__ - Step 420 Global step 420 Train loss 1.40 on epoch=29
05/17/2022 19:47:53 - INFO - __main__ - Step 430 Global step 430 Train loss 1.39 on epoch=30
05/17/2022 19:47:55 - INFO - __main__ - Step 440 Global step 440 Train loss 1.33 on epoch=31
05/17/2022 19:47:56 - INFO - __main__ - Step 450 Global step 450 Train loss 1.37 on epoch=32
05/17/2022 19:47:59 - INFO - __main__ - Global step 450 Train loss 1.37 Classification-F1 0.06903634986747445 on epoch=32
05/17/2022 19:47:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0417027417027417 -> 0.06903634986747445 on epoch=32, global_step=450
05/17/2022 19:48:00 - INFO - __main__ - Step 460 Global step 460 Train loss 1.44 on epoch=32
05/17/2022 19:48:01 - INFO - __main__ - Step 470 Global step 470 Train loss 1.37 on epoch=33
05/17/2022 19:48:02 - INFO - __main__ - Step 480 Global step 480 Train loss 1.29 on epoch=34
05/17/2022 19:48:03 - INFO - __main__ - Step 490 Global step 490 Train loss 1.35 on epoch=34
05/17/2022 19:48:05 - INFO - __main__ - Step 500 Global step 500 Train loss 1.37 on epoch=35
05/17/2022 19:48:08 - INFO - __main__ - Global step 500 Train loss 1.36 Classification-F1 0.05584639652962635 on epoch=35
05/17/2022 19:48:09 - INFO - __main__ - Step 510 Global step 510 Train loss 1.28 on epoch=36
05/17/2022 19:48:10 - INFO - __main__ - Step 520 Global step 520 Train loss 1.34 on epoch=37
05/17/2022 19:48:12 - INFO - __main__ - Step 530 Global step 530 Train loss 1.36 on epoch=37
05/17/2022 19:48:13 - INFO - __main__ - Step 540 Global step 540 Train loss 1.24 on epoch=38
05/17/2022 19:48:14 - INFO - __main__ - Step 550 Global step 550 Train loss 1.44 on epoch=39
05/17/2022 19:48:16 - INFO - __main__ - Global step 550 Train loss 1.33 Classification-F1 0.09019348333018215 on epoch=39
05/17/2022 19:48:16 - INFO - __main__ - Saving model with best Classification-F1: 0.06903634986747445 -> 0.09019348333018215 on epoch=39, global_step=550
05/17/2022 19:48:18 - INFO - __main__ - Step 560 Global step 560 Train loss 1.32 on epoch=39
05/17/2022 19:48:19 - INFO - __main__ - Step 570 Global step 570 Train loss 1.42 on epoch=40
05/17/2022 19:48:20 - INFO - __main__ - Step 580 Global step 580 Train loss 1.19 on epoch=41
05/17/2022 19:48:21 - INFO - __main__ - Step 590 Global step 590 Train loss 1.18 on epoch=42
05/17/2022 19:48:23 - INFO - __main__ - Step 600 Global step 600 Train loss 1.27 on epoch=42
05/17/2022 19:48:25 - INFO - __main__ - Global step 600 Train loss 1.28 Classification-F1 0.12639005869099465 on epoch=42
05/17/2022 19:48:25 - INFO - __main__ - Saving model with best Classification-F1: 0.09019348333018215 -> 0.12639005869099465 on epoch=42, global_step=600
05/17/2022 19:48:26 - INFO - __main__ - Step 610 Global step 610 Train loss 1.30 on epoch=43
05/17/2022 19:48:28 - INFO - __main__ - Step 620 Global step 620 Train loss 1.32 on epoch=44
05/17/2022 19:48:29 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=44
05/17/2022 19:48:30 - INFO - __main__ - Step 640 Global step 640 Train loss 1.24 on epoch=45
05/17/2022 19:48:31 - INFO - __main__ - Step 650 Global step 650 Train loss 1.24 on epoch=46
05/17/2022 19:48:34 - INFO - __main__ - Global step 650 Train loss 1.26 Classification-F1 0.12436852486790807 on epoch=46
05/17/2022 19:48:36 - INFO - __main__ - Step 660 Global step 660 Train loss 1.23 on epoch=47
05/17/2022 19:48:37 - INFO - __main__ - Step 670 Global step 670 Train loss 1.21 on epoch=47
05/17/2022 19:48:38 - INFO - __main__ - Step 680 Global step 680 Train loss 1.20 on epoch=48
05/17/2022 19:48:39 - INFO - __main__ - Step 690 Global step 690 Train loss 1.18 on epoch=49
05/17/2022 19:48:41 - INFO - __main__ - Step 700 Global step 700 Train loss 1.14 on epoch=49
05/17/2022 19:48:44 - INFO - __main__ - Global step 700 Train loss 1.19 Classification-F1 0.20575474634298163 on epoch=49
05/17/2022 19:48:44 - INFO - __main__ - Saving model with best Classification-F1: 0.12639005869099465 -> 0.20575474634298163 on epoch=49, global_step=700
05/17/2022 19:48:45 - INFO - __main__ - Step 710 Global step 710 Train loss 1.21 on epoch=50
05/17/2022 19:48:46 - INFO - __main__ - Step 720 Global step 720 Train loss 1.09 on epoch=51
05/17/2022 19:48:47 - INFO - __main__ - Step 730 Global step 730 Train loss 1.20 on epoch=52
05/17/2022 19:48:49 - INFO - __main__ - Step 740 Global step 740 Train loss 1.26 on epoch=52
05/17/2022 19:48:50 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/17/2022 19:48:53 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.21818166880278683 on epoch=53
05/17/2022 19:48:53 - INFO - __main__ - Saving model with best Classification-F1: 0.20575474634298163 -> 0.21818166880278683 on epoch=53, global_step=750
05/17/2022 19:48:54 - INFO - __main__ - Step 760 Global step 760 Train loss 1.15 on epoch=54
05/17/2022 19:48:56 - INFO - __main__ - Step 770 Global step 770 Train loss 1.10 on epoch=54
05/17/2022 19:48:57 - INFO - __main__ - Step 780 Global step 780 Train loss 1.25 on epoch=55
05/17/2022 19:48:58 - INFO - __main__ - Step 790 Global step 790 Train loss 1.14 on epoch=56
05/17/2022 19:48:59 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=57
05/17/2022 19:49:03 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.2213537502234789 on epoch=57
05/17/2022 19:49:03 - INFO - __main__ - Saving model with best Classification-F1: 0.21818166880278683 -> 0.2213537502234789 on epoch=57, global_step=800
05/17/2022 19:49:04 - INFO - __main__ - Step 810 Global step 810 Train loss 1.16 on epoch=57
05/17/2022 19:49:05 - INFO - __main__ - Step 820 Global step 820 Train loss 1.09 on epoch=58
05/17/2022 19:49:06 - INFO - __main__ - Step 830 Global step 830 Train loss 1.11 on epoch=59
05/17/2022 19:49:08 - INFO - __main__ - Step 840 Global step 840 Train loss 1.06 on epoch=59
05/17/2022 19:49:09 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=60
05/17/2022 19:49:12 - INFO - __main__ - Global step 850 Train loss 1.12 Classification-F1 0.2686510861677969 on epoch=60
05/17/2022 19:49:12 - INFO - __main__ - Saving model with best Classification-F1: 0.2213537502234789 -> 0.2686510861677969 on epoch=60, global_step=850
05/17/2022 19:49:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.99 on epoch=61
05/17/2022 19:49:15 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=62
05/17/2022 19:49:16 - INFO - __main__ - Step 880 Global step 880 Train loss 1.10 on epoch=62
05/17/2022 19:49:17 - INFO - __main__ - Step 890 Global step 890 Train loss 1.09 on epoch=63
05/17/2022 19:49:18 - INFO - __main__ - Step 900 Global step 900 Train loss 1.07 on epoch=64
05/17/2022 19:49:22 - INFO - __main__ - Global step 900 Train loss 1.07 Classification-F1 0.3415945209243633 on epoch=64
05/17/2022 19:49:22 - INFO - __main__ - Saving model with best Classification-F1: 0.2686510861677969 -> 0.3415945209243633 on epoch=64, global_step=900
05/17/2022 19:49:23 - INFO - __main__ - Step 910 Global step 910 Train loss 1.05 on epoch=64
05/17/2022 19:49:25 - INFO - __main__ - Step 920 Global step 920 Train loss 1.02 on epoch=65
05/17/2022 19:49:26 - INFO - __main__ - Step 930 Global step 930 Train loss 1.04 on epoch=66
05/17/2022 19:49:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.96 on epoch=67
05/17/2022 19:49:28 - INFO - __main__ - Step 950 Global step 950 Train loss 1.03 on epoch=67
05/17/2022 19:49:32 - INFO - __main__ - Global step 950 Train loss 1.02 Classification-F1 0.35030232828005886 on epoch=67
05/17/2022 19:49:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3415945209243633 -> 0.35030232828005886 on epoch=67, global_step=950
05/17/2022 19:49:33 - INFO - __main__ - Step 960 Global step 960 Train loss 1.01 on epoch=68
05/17/2022 19:49:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.94 on epoch=69
05/17/2022 19:49:36 - INFO - __main__ - Step 980 Global step 980 Train loss 1.05 on epoch=69
05/17/2022 19:49:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.99 on epoch=70
05/17/2022 19:49:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.00 on epoch=71
05/17/2022 19:49:42 - INFO - __main__ - Global step 1000 Train loss 1.00 Classification-F1 0.419783329073688 on epoch=71
05/17/2022 19:49:42 - INFO - __main__ - Saving model with best Classification-F1: 0.35030232828005886 -> 0.419783329073688 on epoch=71, global_step=1000
05/17/2022 19:49:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/17/2022 19:49:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.07 on epoch=72
05/17/2022 19:49:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.00 on epoch=73
05/17/2022 19:49:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/17/2022 19:49:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.95 on epoch=74
05/17/2022 19:49:52 - INFO - __main__ - Global step 1050 Train loss 1.00 Classification-F1 0.421410562645707 on epoch=74
05/17/2022 19:49:52 - INFO - __main__ - Saving model with best Classification-F1: 0.419783329073688 -> 0.421410562645707 on epoch=74, global_step=1050
05/17/2022 19:49:53 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.00 on epoch=75
05/17/2022 19:49:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.88 on epoch=76
05/17/2022 19:49:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.01 on epoch=77
05/17/2022 19:49:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.05 on epoch=77
05/17/2022 19:49:58 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.00 on epoch=78
05/17/2022 19:50:02 - INFO - __main__ - Global step 1100 Train loss 0.99 Classification-F1 0.41006870775272275 on epoch=78
05/17/2022 19:50:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.88 on epoch=79
05/17/2022 19:50:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/17/2022 19:50:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.05 on epoch=80
05/17/2022 19:50:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.93 on epoch=81
05/17/2022 19:50:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.92 on epoch=82
05/17/2022 19:50:12 - INFO - __main__ - Global step 1150 Train loss 0.94 Classification-F1 0.474635812320912 on epoch=82
05/17/2022 19:50:12 - INFO - __main__ - Saving model with best Classification-F1: 0.421410562645707 -> 0.474635812320912 on epoch=82, global_step=1150
05/17/2022 19:50:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.99 on epoch=82
05/17/2022 19:50:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.83 on epoch=83
05/17/2022 19:50:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.96 on epoch=84
05/17/2022 19:50:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.89 on epoch=84
05/17/2022 19:50:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.91 on epoch=85
05/17/2022 19:50:22 - INFO - __main__ - Global step 1200 Train loss 0.91 Classification-F1 0.47827616344142804 on epoch=85
05/17/2022 19:50:22 - INFO - __main__ - Saving model with best Classification-F1: 0.474635812320912 -> 0.47827616344142804 on epoch=85, global_step=1200
05/17/2022 19:50:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.77 on epoch=86
05/17/2022 19:50:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.87 on epoch=87
05/17/2022 19:50:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.87 on epoch=87
05/17/2022 19:50:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.84 on epoch=88
05/17/2022 19:50:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.91 on epoch=89
05/17/2022 19:50:33 - INFO - __main__ - Global step 1250 Train loss 0.85 Classification-F1 0.44523899533611566 on epoch=89
05/17/2022 19:50:34 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.82 on epoch=89
05/17/2022 19:50:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.87 on epoch=90
05/17/2022 19:50:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.79 on epoch=91
05/17/2022 19:50:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.73 on epoch=92
05/17/2022 19:50:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.88 on epoch=92
05/17/2022 19:50:43 - INFO - __main__ - Global step 1300 Train loss 0.82 Classification-F1 0.39888438584915775 on epoch=92
05/17/2022 19:50:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.85 on epoch=93
05/17/2022 19:50:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.79 on epoch=94
05/17/2022 19:50:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.75 on epoch=94
05/17/2022 19:50:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.82 on epoch=95
05/17/2022 19:50:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.74 on epoch=96
05/17/2022 19:50:53 - INFO - __main__ - Global step 1350 Train loss 0.79 Classification-F1 0.3781056614084473 on epoch=96
05/17/2022 19:50:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.80 on epoch=97
05/17/2022 19:50:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.79 on epoch=97
05/17/2022 19:50:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.75 on epoch=98
05/17/2022 19:50:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.81 on epoch=99
05/17/2022 19:50:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.73 on epoch=99
05/17/2022 19:51:03 - INFO - __main__ - Global step 1400 Train loss 0.78 Classification-F1 0.4098662105435753 on epoch=99
05/17/2022 19:51:04 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.82 on epoch=100
05/17/2022 19:51:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.73 on epoch=101
05/17/2022 19:51:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.68 on epoch=102
05/17/2022 19:51:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.73 on epoch=102
05/17/2022 19:51:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/17/2022 19:51:13 - INFO - __main__ - Global step 1450 Train loss 0.74 Classification-F1 0.459368662313528 on epoch=103
05/17/2022 19:51:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.75 on epoch=104
05/17/2022 19:51:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.86 on epoch=104
05/17/2022 19:51:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.78 on epoch=105
05/17/2022 19:51:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.78 on epoch=106
05/17/2022 19:51:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.62 on epoch=107
05/17/2022 19:51:23 - INFO - __main__ - Global step 1500 Train loss 0.76 Classification-F1 0.4010885226148551 on epoch=107
05/17/2022 19:51:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.65 on epoch=107
05/17/2022 19:51:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.74 on epoch=108
05/17/2022 19:51:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.71 on epoch=109
05/17/2022 19:51:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.80 on epoch=109
05/17/2022 19:51:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.67 on epoch=110
05/17/2022 19:51:33 - INFO - __main__ - Global step 1550 Train loss 0.71 Classification-F1 0.41263511740784475 on epoch=110
05/17/2022 19:51:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.64 on epoch=111
05/17/2022 19:51:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.64 on epoch=112
05/17/2022 19:51:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.73 on epoch=112
05/17/2022 19:51:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.78 on epoch=113
05/17/2022 19:51:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.71 on epoch=114
05/17/2022 19:51:43 - INFO - __main__ - Global step 1600 Train loss 0.70 Classification-F1 0.44496651672735416 on epoch=114
05/17/2022 19:51:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.77 on epoch=114
05/17/2022 19:51:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.75 on epoch=115
05/17/2022 19:51:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.55 on epoch=116
05/17/2022 19:51:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.74 on epoch=117
05/17/2022 19:51:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.75 on epoch=117
05/17/2022 19:51:53 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.39997980805850797 on epoch=117
05/17/2022 19:51:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.79 on epoch=118
05/17/2022 19:51:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.67 on epoch=119
05/17/2022 19:51:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.65 on epoch=119
05/17/2022 19:51:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.64 on epoch=120
05/17/2022 19:51:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.63 on epoch=121
05/17/2022 19:52:03 - INFO - __main__ - Global step 1700 Train loss 0.68 Classification-F1 0.45450599532503705 on epoch=121
05/17/2022 19:52:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.69 on epoch=122
05/17/2022 19:52:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.70 on epoch=122
05/17/2022 19:52:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.58 on epoch=123
05/17/2022 19:52:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.60 on epoch=124
05/17/2022 19:52:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.63 on epoch=124
05/17/2022 19:52:13 - INFO - __main__ - Global step 1750 Train loss 0.64 Classification-F1 0.46922142612269313 on epoch=124
05/17/2022 19:52:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.61 on epoch=125
05/17/2022 19:52:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.59 on epoch=126
05/17/2022 19:52:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.64 on epoch=127
05/17/2022 19:52:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.67 on epoch=127
05/17/2022 19:52:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.52 on epoch=128
05/17/2022 19:52:23 - INFO - __main__ - Global step 1800 Train loss 0.61 Classification-F1 0.45894600381013434 on epoch=128
05/17/2022 19:52:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.65 on epoch=129
05/17/2022 19:52:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.73 on epoch=129
05/17/2022 19:52:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.74 on epoch=130
05/17/2022 19:52:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.60 on epoch=131
05/17/2022 19:52:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.66 on epoch=132
05/17/2022 19:52:34 - INFO - __main__ - Global step 1850 Train loss 0.68 Classification-F1 0.49048938633875117 on epoch=132
05/17/2022 19:52:34 - INFO - __main__ - Saving model with best Classification-F1: 0.47827616344142804 -> 0.49048938633875117 on epoch=132, global_step=1850
05/17/2022 19:52:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.65 on epoch=132
05/17/2022 19:52:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.59 on epoch=133
05/17/2022 19:52:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.61 on epoch=134
05/17/2022 19:52:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.62 on epoch=134
05/17/2022 19:52:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.55 on epoch=135
05/17/2022 19:52:44 - INFO - __main__ - Global step 1900 Train loss 0.60 Classification-F1 0.4462474635952298 on epoch=135
05/17/2022 19:52:45 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.60 on epoch=136
05/17/2022 19:52:47 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.54 on epoch=137
05/17/2022 19:52:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.57 on epoch=137
05/17/2022 19:52:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.63 on epoch=138
05/17/2022 19:52:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.59 on epoch=139
05/17/2022 19:52:54 - INFO - __main__ - Global step 1950 Train loss 0.59 Classification-F1 0.5194691271741799 on epoch=139
05/17/2022 19:52:54 - INFO - __main__ - Saving model with best Classification-F1: 0.49048938633875117 -> 0.5194691271741799 on epoch=139, global_step=1950
05/17/2022 19:52:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.54 on epoch=139
05/17/2022 19:52:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.61 on epoch=140
05/17/2022 19:52:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.55 on epoch=141
05/17/2022 19:52:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.58 on epoch=142
05/17/2022 19:53:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.51 on epoch=142
05/17/2022 19:53:05 - INFO - __main__ - Global step 2000 Train loss 0.56 Classification-F1 0.4638218208907028 on epoch=142
05/17/2022 19:53:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.56 on epoch=143
05/17/2022 19:53:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.63 on epoch=144
05/17/2022 19:53:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.56 on epoch=144
05/17/2022 19:53:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.60 on epoch=145
05/17/2022 19:53:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.53 on epoch=146
05/17/2022 19:53:15 - INFO - __main__ - Global step 2050 Train loss 0.58 Classification-F1 0.4757923062584945 on epoch=146
05/17/2022 19:53:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.58 on epoch=147
05/17/2022 19:53:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.51 on epoch=147
05/17/2022 19:53:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.56 on epoch=148
05/17/2022 19:53:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.60 on epoch=149
05/17/2022 19:53:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.55 on epoch=149
05/17/2022 19:53:25 - INFO - __main__ - Global step 2100 Train loss 0.56 Classification-F1 0.46934569956977645 on epoch=149
05/17/2022 19:53:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.57 on epoch=150
05/17/2022 19:53:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.50 on epoch=151
05/17/2022 19:53:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.48 on epoch=152
05/17/2022 19:53:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.53 on epoch=152
05/17/2022 19:53:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.59 on epoch=153
05/17/2022 19:53:35 - INFO - __main__ - Global step 2150 Train loss 0.53 Classification-F1 0.5102246728682145 on epoch=153
05/17/2022 19:53:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.53 on epoch=154
05/17/2022 19:53:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.55 on epoch=154
05/17/2022 19:53:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.49 on epoch=155
05/17/2022 19:53:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.44 on epoch=156
05/17/2022 19:53:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.50 on epoch=157
05/17/2022 19:53:46 - INFO - __main__ - Global step 2200 Train loss 0.50 Classification-F1 0.5401720452243565 on epoch=157
05/17/2022 19:53:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5194691271741799 -> 0.5401720452243565 on epoch=157, global_step=2200
05/17/2022 19:53:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.53 on epoch=157
05/17/2022 19:53:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.60 on epoch=158
05/17/2022 19:53:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.50 on epoch=159
05/17/2022 19:53:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.54 on epoch=159
05/17/2022 19:53:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.58 on epoch=160
05/17/2022 19:53:56 - INFO - __main__ - Global step 2250 Train loss 0.55 Classification-F1 0.5546702891001137 on epoch=160
05/17/2022 19:53:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5401720452243565 -> 0.5546702891001137 on epoch=160, global_step=2250
05/17/2022 19:53:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.51 on epoch=161
05/17/2022 19:53:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.55 on epoch=162
05/17/2022 19:54:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.50 on epoch=162
05/17/2022 19:54:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.48 on epoch=163
05/17/2022 19:54:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.57 on epoch=164
05/17/2022 19:54:06 - INFO - __main__ - Global step 2300 Train loss 0.52 Classification-F1 0.5895819500425334 on epoch=164
05/17/2022 19:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5546702891001137 -> 0.5895819500425334 on epoch=164, global_step=2300
05/17/2022 19:54:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.44 on epoch=164
05/17/2022 19:54:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.51 on epoch=165
05/17/2022 19:54:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.48 on epoch=166
05/17/2022 19:54:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.52 on epoch=167
05/17/2022 19:54:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.49 on epoch=167
05/17/2022 19:54:16 - INFO - __main__ - Global step 2350 Train loss 0.49 Classification-F1 0.5121021762894827 on epoch=167
05/17/2022 19:54:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.50 on epoch=168
05/17/2022 19:54:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.53 on epoch=169
05/17/2022 19:54:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.50 on epoch=169
05/17/2022 19:54:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.49 on epoch=170
05/17/2022 19:54:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.40 on epoch=171
05/17/2022 19:54:27 - INFO - __main__ - Global step 2400 Train loss 0.48 Classification-F1 0.5775754475035223 on epoch=171
05/17/2022 19:54:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.50 on epoch=172
05/17/2022 19:54:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.45 on epoch=172
05/17/2022 19:54:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.52 on epoch=173
05/17/2022 19:54:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.52 on epoch=174
05/17/2022 19:54:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.54 on epoch=174
05/17/2022 19:54:37 - INFO - __main__ - Global step 2450 Train loss 0.50 Classification-F1 0.5164688960746263 on epoch=174
05/17/2022 19:54:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.51 on epoch=175
05/17/2022 19:54:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.55 on epoch=176
05/17/2022 19:54:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.57 on epoch=177
05/17/2022 19:54:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.47 on epoch=177
05/17/2022 19:54:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.43 on epoch=178
05/17/2022 19:54:47 - INFO - __main__ - Global step 2500 Train loss 0.51 Classification-F1 0.5878894835537837 on epoch=178
05/17/2022 19:54:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.52 on epoch=179
05/17/2022 19:54:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.47 on epoch=179
05/17/2022 19:54:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.38 on epoch=180
05/17/2022 19:54:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.52 on epoch=181
05/17/2022 19:54:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.51 on epoch=182
05/17/2022 19:54:57 - INFO - __main__ - Global step 2550 Train loss 0.48 Classification-F1 0.622853140067673 on epoch=182
05/17/2022 19:54:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5895819500425334 -> 0.622853140067673 on epoch=182, global_step=2550
05/17/2022 19:54:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.43 on epoch=182
05/17/2022 19:55:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.44 on epoch=183
05/17/2022 19:55:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.44 on epoch=184
05/17/2022 19:55:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.48 on epoch=184
05/17/2022 19:55:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.52 on epoch=185
05/17/2022 19:55:08 - INFO - __main__ - Global step 2600 Train loss 0.46 Classification-F1 0.5711073942931766 on epoch=185
05/17/2022 19:55:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.44 on epoch=186
05/17/2022 19:55:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.39 on epoch=187
05/17/2022 19:55:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.46 on epoch=187
05/17/2022 19:55:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.55 on epoch=188
05/17/2022 19:55:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.49 on epoch=189
05/17/2022 19:55:18 - INFO - __main__ - Global step 2650 Train loss 0.47 Classification-F1 0.59442134214024 on epoch=189
05/17/2022 19:55:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.45 on epoch=189
05/17/2022 19:55:20 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.47 on epoch=190
05/17/2022 19:55:22 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.46 on epoch=191
05/17/2022 19:55:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.49 on epoch=192
05/17/2022 19:55:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.45 on epoch=192
05/17/2022 19:55:28 - INFO - __main__ - Global step 2700 Train loss 0.46 Classification-F1 0.6905446912156471 on epoch=192
05/17/2022 19:55:28 - INFO - __main__ - Saving model with best Classification-F1: 0.622853140067673 -> 0.6905446912156471 on epoch=192, global_step=2700
05/17/2022 19:55:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.46 on epoch=193
05/17/2022 19:55:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.49 on epoch=194
05/17/2022 19:55:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.47 on epoch=194
05/17/2022 19:55:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.44 on epoch=195
05/17/2022 19:55:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.37 on epoch=196
05/17/2022 19:55:39 - INFO - __main__ - Global step 2750 Train loss 0.45 Classification-F1 0.6484918126243961 on epoch=196
05/17/2022 19:55:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.46 on epoch=197
05/17/2022 19:55:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.52 on epoch=197
05/17/2022 19:55:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.56 on epoch=198
05/17/2022 19:55:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.42 on epoch=199
05/17/2022 19:55:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.49 on epoch=199
05/17/2022 19:55:49 - INFO - __main__ - Global step 2800 Train loss 0.49 Classification-F1 0.6705482373972107 on epoch=199
05/17/2022 19:55:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.44 on epoch=200
05/17/2022 19:55:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.44 on epoch=201
05/17/2022 19:55:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.43 on epoch=202
05/17/2022 19:55:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.43 on epoch=202
05/17/2022 19:55:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.37 on epoch=203
05/17/2022 19:55:59 - INFO - __main__ - Global step 2850 Train loss 0.42 Classification-F1 0.6821218186578614 on epoch=203
05/17/2022 19:56:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.39 on epoch=204
05/17/2022 19:56:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.40 on epoch=204
05/17/2022 19:56:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.43 on epoch=205
05/17/2022 19:56:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.42 on epoch=206
05/17/2022 19:56:05 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.44 on epoch=207
05/17/2022 19:56:09 - INFO - __main__ - Global step 2900 Train loss 0.42 Classification-F1 0.7125912269791526 on epoch=207
05/17/2022 19:56:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6905446912156471 -> 0.7125912269791526 on epoch=207, global_step=2900
05/17/2022 19:56:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.47 on epoch=207
05/17/2022 19:56:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.48 on epoch=208
05/17/2022 19:56:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.45 on epoch=209
05/17/2022 19:56:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.48 on epoch=209
05/17/2022 19:56:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.48 on epoch=210
05/17/2022 19:56:20 - INFO - __main__ - Global step 2950 Train loss 0.47 Classification-F1 0.7012383225941694 on epoch=210
05/17/2022 19:56:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.45 on epoch=211
05/17/2022 19:56:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.37 on epoch=212
05/17/2022 19:56:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.37 on epoch=212
05/17/2022 19:56:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.44 on epoch=213
05/17/2022 19:56:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.51 on epoch=214
05/17/2022 19:56:27 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:56:27 - INFO - __main__ - Printing 3 examples
05/17/2022 19:56:27 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 19:56:27 - INFO - __main__ - ['Plant']
05/17/2022 19:56:27 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 19:56:27 - INFO - __main__ - ['Plant']
05/17/2022 19:56:27 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 19:56:27 - INFO - __main__ - ['Plant']
05/17/2022 19:56:27 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:56:27 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:56:28 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:56:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:56:28 - INFO - __main__ - Printing 3 examples
05/17/2022 19:56:28 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 19:56:28 - INFO - __main__ - ['Plant']
05/17/2022 19:56:28 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 19:56:28 - INFO - __main__ - ['Plant']
05/17/2022 19:56:28 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 19:56:28 - INFO - __main__ - ['Plant']
05/17/2022 19:56:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:56:28 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:56:28 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:56:31 - INFO - __main__ - Global step 3000 Train loss 0.43 Classification-F1 0.6955418566939027 on epoch=214
05/17/2022 19:56:31 - INFO - __main__ - save last model!
05/17/2022 19:56:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 19:56:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 19:56:31 - INFO - __main__ - Printing 3 examples
05/17/2022 19:56:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 19:56:31 - INFO - __main__ - ['Animal']
05/17/2022 19:56:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 19:56:31 - INFO - __main__ - ['Animal']
05/17/2022 19:56:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 19:56:31 - INFO - __main__ - ['Village']
05/17/2022 19:56:31 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:56:32 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:56:34 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:56:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:56:34 - INFO - __main__ - Starting training!
05/17/2022 19:56:36 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 19:57:50 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/17/2022 19:57:50 - INFO - __main__ - Classification-F1 on test data: 0.2515
05/17/2022 19:57:50 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.7125912269791526, test_performance=0.251529457532102
05/17/2022 19:57:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/17/2022 19:57:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:57:51 - INFO - __main__ - Printing 3 examples
05/17/2022 19:57:51 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 19:57:51 - INFO - __main__ - ['Plant']
05/17/2022 19:57:51 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 19:57:51 - INFO - __main__ - ['Plant']
05/17/2022 19:57:51 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 19:57:51 - INFO - __main__ - ['Plant']
05/17/2022 19:57:51 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:57:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:57:52 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 19:57:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 19:57:52 - INFO - __main__ - Printing 3 examples
05/17/2022 19:57:52 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 19:57:52 - INFO - __main__ - ['Plant']
05/17/2022 19:57:52 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 19:57:52 - INFO - __main__ - ['Plant']
05/17/2022 19:57:52 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 19:57:52 - INFO - __main__ - ['Plant']
05/17/2022 19:57:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 19:57:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 19:57:52 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 19:57:58 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 19:57:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 19:57:58 - INFO - __main__ - Starting training!
05/17/2022 19:58:00 - INFO - __main__ - Step 10 Global step 10 Train loss 7.67 on epoch=0
05/17/2022 19:58:01 - INFO - __main__ - Step 20 Global step 20 Train loss 6.74 on epoch=1
05/17/2022 19:58:02 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=2
05/17/2022 19:58:04 - INFO - __main__ - Step 40 Global step 40 Train loss 5.85 on epoch=2
05/17/2022 19:58:05 - INFO - __main__ - Step 50 Global step 50 Train loss 5.42 on epoch=3
05/17/2022 19:58:08 - INFO - __main__ - Global step 50 Train loss 6.42 Classification-F1 0.0 on epoch=3
05/17/2022 19:58:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 19:58:09 - INFO - __main__ - Step 60 Global step 60 Train loss 5.18 on epoch=4
05/17/2022 19:58:11 - INFO - __main__ - Step 70 Global step 70 Train loss 4.58 on epoch=4
05/17/2022 19:58:12 - INFO - __main__ - Step 80 Global step 80 Train loss 4.46 on epoch=5
05/17/2022 19:58:13 - INFO - __main__ - Step 90 Global step 90 Train loss 4.09 on epoch=6
05/17/2022 19:58:14 - INFO - __main__ - Step 100 Global step 100 Train loss 3.99 on epoch=7
05/17/2022 19:58:17 - INFO - __main__ - Global step 100 Train loss 4.46 Classification-F1 0.0 on epoch=7
05/17/2022 19:58:19 - INFO - __main__ - Step 110 Global step 110 Train loss 3.80 on epoch=7
05/17/2022 19:58:20 - INFO - __main__ - Step 120 Global step 120 Train loss 3.69 on epoch=8
05/17/2022 19:58:21 - INFO - __main__ - Step 130 Global step 130 Train loss 3.42 on epoch=9
05/17/2022 19:58:23 - INFO - __main__ - Step 140 Global step 140 Train loss 3.24 on epoch=9
05/17/2022 19:58:24 - INFO - __main__ - Step 150 Global step 150 Train loss 3.19 on epoch=10
05/17/2022 19:58:26 - INFO - __main__ - Global step 150 Train loss 3.47 Classification-F1 0.005797101449275362 on epoch=10
05/17/2022 19:58:26 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005797101449275362 on epoch=10, global_step=150
05/17/2022 19:58:28 - INFO - __main__ - Step 160 Global step 160 Train loss 3.12 on epoch=11
05/17/2022 19:58:29 - INFO - __main__ - Step 170 Global step 170 Train loss 3.05 on epoch=12
05/17/2022 19:58:30 - INFO - __main__ - Step 180 Global step 180 Train loss 2.98 on epoch=12
05/17/2022 19:58:31 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=13
05/17/2022 19:58:33 - INFO - __main__ - Step 200 Global step 200 Train loss 2.76 on epoch=14
05/17/2022 19:58:35 - INFO - __main__ - Global step 200 Train loss 2.95 Classification-F1 0.0072607260726072625 on epoch=14
05/17/2022 19:58:35 - INFO - __main__ - Saving model with best Classification-F1: 0.005797101449275362 -> 0.0072607260726072625 on epoch=14, global_step=200
05/17/2022 19:58:36 - INFO - __main__ - Step 210 Global step 210 Train loss 2.56 on epoch=14
05/17/2022 19:58:38 - INFO - __main__ - Step 220 Global step 220 Train loss 2.62 on epoch=15
05/17/2022 19:58:39 - INFO - __main__ - Step 230 Global step 230 Train loss 2.42 on epoch=16
05/17/2022 19:58:40 - INFO - __main__ - Step 240 Global step 240 Train loss 2.53 on epoch=17
05/17/2022 19:58:42 - INFO - __main__ - Step 250 Global step 250 Train loss 2.40 on epoch=17
05/17/2022 19:58:43 - INFO - __main__ - Global step 250 Train loss 2.51 Classification-F1 0.008963585434173669 on epoch=17
05/17/2022 19:58:44 - INFO - __main__ - Saving model with best Classification-F1: 0.0072607260726072625 -> 0.008963585434173669 on epoch=17, global_step=250
05/17/2022 19:58:45 - INFO - __main__ - Step 260 Global step 260 Train loss 2.20 on epoch=18
05/17/2022 19:58:46 - INFO - __main__ - Step 270 Global step 270 Train loss 2.18 on epoch=19
05/17/2022 19:58:47 - INFO - __main__ - Step 280 Global step 280 Train loss 2.15 on epoch=19
05/17/2022 19:58:49 - INFO - __main__ - Step 290 Global step 290 Train loss 2.16 on epoch=20
05/17/2022 19:58:50 - INFO - __main__ - Step 300 Global step 300 Train loss 2.06 on epoch=21
05/17/2022 19:58:52 - INFO - __main__ - Global step 300 Train loss 2.15 Classification-F1 0.02866586391932014 on epoch=21
05/17/2022 19:58:52 - INFO - __main__ - Saving model with best Classification-F1: 0.008963585434173669 -> 0.02866586391932014 on epoch=21, global_step=300
05/17/2022 19:58:53 - INFO - __main__ - Step 310 Global step 310 Train loss 1.96 on epoch=22
05/17/2022 19:58:54 - INFO - __main__ - Step 320 Global step 320 Train loss 2.00 on epoch=22
05/17/2022 19:58:56 - INFO - __main__ - Step 330 Global step 330 Train loss 1.92 on epoch=23
05/17/2022 19:58:57 - INFO - __main__ - Step 340 Global step 340 Train loss 1.86 on epoch=24
05/17/2022 19:58:58 - INFO - __main__ - Step 350 Global step 350 Train loss 1.82 on epoch=24
05/17/2022 19:59:00 - INFO - __main__ - Global step 350 Train loss 1.91 Classification-F1 0.031997971602434075 on epoch=24
05/17/2022 19:59:00 - INFO - __main__ - Saving model with best Classification-F1: 0.02866586391932014 -> 0.031997971602434075 on epoch=24, global_step=350
05/17/2022 19:59:01 - INFO - __main__ - Step 360 Global step 360 Train loss 1.88 on epoch=25
05/17/2022 19:59:03 - INFO - __main__ - Step 370 Global step 370 Train loss 1.74 on epoch=26
05/17/2022 19:59:04 - INFO - __main__ - Step 380 Global step 380 Train loss 1.76 on epoch=27
05/17/2022 19:59:05 - INFO - __main__ - Step 390 Global step 390 Train loss 1.77 on epoch=27
05/17/2022 19:59:06 - INFO - __main__ - Step 400 Global step 400 Train loss 1.57 on epoch=28
05/17/2022 19:59:08 - INFO - __main__ - Global step 400 Train loss 1.74 Classification-F1 0.02652674706246135 on epoch=28
05/17/2022 19:59:10 - INFO - __main__ - Step 410 Global step 410 Train loss 1.68 on epoch=29
05/17/2022 19:59:11 - INFO - __main__ - Step 420 Global step 420 Train loss 1.64 on epoch=29
05/17/2022 19:59:12 - INFO - __main__ - Step 430 Global step 430 Train loss 1.65 on epoch=30
05/17/2022 19:59:14 - INFO - __main__ - Step 440 Global step 440 Train loss 1.56 on epoch=31
05/17/2022 19:59:15 - INFO - __main__ - Step 450 Global step 450 Train loss 1.58 on epoch=32
05/17/2022 19:59:17 - INFO - __main__ - Global step 450 Train loss 1.62 Classification-F1 0.041171997645211934 on epoch=32
05/17/2022 19:59:17 - INFO - __main__ - Saving model with best Classification-F1: 0.031997971602434075 -> 0.041171997645211934 on epoch=32, global_step=450
05/17/2022 19:59:19 - INFO - __main__ - Step 460 Global step 460 Train loss 1.71 on epoch=32
05/17/2022 19:59:20 - INFO - __main__ - Step 470 Global step 470 Train loss 1.53 on epoch=33
05/17/2022 19:59:21 - INFO - __main__ - Step 480 Global step 480 Train loss 1.49 on epoch=34
05/17/2022 19:59:23 - INFO - __main__ - Step 490 Global step 490 Train loss 1.59 on epoch=34
05/17/2022 19:59:24 - INFO - __main__ - Step 500 Global step 500 Train loss 1.53 on epoch=35
05/17/2022 19:59:27 - INFO - __main__ - Global step 500 Train loss 1.57 Classification-F1 0.05247357572011572 on epoch=35
05/17/2022 19:59:27 - INFO - __main__ - Saving model with best Classification-F1: 0.041171997645211934 -> 0.05247357572011572 on epoch=35, global_step=500
05/17/2022 19:59:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.48 on epoch=36
05/17/2022 19:59:30 - INFO - __main__ - Step 520 Global step 520 Train loss 1.36 on epoch=37
05/17/2022 19:59:31 - INFO - __main__ - Step 530 Global step 530 Train loss 1.44 on epoch=37
05/17/2022 19:59:32 - INFO - __main__ - Step 540 Global step 540 Train loss 1.44 on epoch=38
05/17/2022 19:59:33 - INFO - __main__ - Step 550 Global step 550 Train loss 1.48 on epoch=39
05/17/2022 19:59:36 - INFO - __main__ - Global step 550 Train loss 1.44 Classification-F1 0.05324532043419951 on epoch=39
05/17/2022 19:59:36 - INFO - __main__ - Saving model with best Classification-F1: 0.05247357572011572 -> 0.05324532043419951 on epoch=39, global_step=550
05/17/2022 19:59:37 - INFO - __main__ - Step 560 Global step 560 Train loss 1.37 on epoch=39
05/17/2022 19:59:39 - INFO - __main__ - Step 570 Global step 570 Train loss 1.40 on epoch=40
05/17/2022 19:59:40 - INFO - __main__ - Step 580 Global step 580 Train loss 1.42 on epoch=41
05/17/2022 19:59:41 - INFO - __main__ - Step 590 Global step 590 Train loss 1.42 on epoch=42
05/17/2022 19:59:42 - INFO - __main__ - Step 600 Global step 600 Train loss 1.41 on epoch=42
05/17/2022 19:59:45 - INFO - __main__ - Global step 600 Train loss 1.41 Classification-F1 0.05234340205915485 on epoch=42
05/17/2022 19:59:46 - INFO - __main__ - Step 610 Global step 610 Train loss 1.38 on epoch=43
05/17/2022 19:59:48 - INFO - __main__ - Step 620 Global step 620 Train loss 1.33 on epoch=44
05/17/2022 19:59:49 - INFO - __main__ - Step 630 Global step 630 Train loss 1.28 on epoch=44
05/17/2022 19:59:50 - INFO - __main__ - Step 640 Global step 640 Train loss 1.33 on epoch=45
05/17/2022 19:59:52 - INFO - __main__ - Step 650 Global step 650 Train loss 1.32 on epoch=46
05/17/2022 19:59:54 - INFO - __main__ - Global step 650 Train loss 1.33 Classification-F1 0.09314302212929959 on epoch=46
05/17/2022 19:59:54 - INFO - __main__ - Saving model with best Classification-F1: 0.05324532043419951 -> 0.09314302212929959 on epoch=46, global_step=650
05/17/2022 19:59:55 - INFO - __main__ - Step 660 Global step 660 Train loss 1.41 on epoch=47
05/17/2022 19:59:56 - INFO - __main__ - Step 670 Global step 670 Train loss 1.38 on epoch=47
05/17/2022 19:59:58 - INFO - __main__ - Step 680 Global step 680 Train loss 1.27 on epoch=48
05/17/2022 19:59:59 - INFO - __main__ - Step 690 Global step 690 Train loss 1.35 on epoch=49
05/17/2022 20:00:00 - INFO - __main__ - Step 700 Global step 700 Train loss 1.23 on epoch=49
05/17/2022 20:00:03 - INFO - __main__ - Global step 700 Train loss 1.33 Classification-F1 0.07513082155939299 on epoch=49
05/17/2022 20:00:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.27 on epoch=50
05/17/2022 20:00:06 - INFO - __main__ - Step 720 Global step 720 Train loss 1.27 on epoch=51
05/17/2022 20:00:07 - INFO - __main__ - Step 730 Global step 730 Train loss 1.27 on epoch=52
05/17/2022 20:00:08 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=52
05/17/2022 20:00:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.32 on epoch=53
05/17/2022 20:00:13 - INFO - __main__ - Global step 750 Train loss 1.30 Classification-F1 0.09220293192418626 on epoch=53
05/17/2022 20:00:14 - INFO - __main__ - Step 760 Global step 760 Train loss 1.34 on epoch=54
05/17/2022 20:00:15 - INFO - __main__ - Step 770 Global step 770 Train loss 1.23 on epoch=54
05/17/2022 20:00:17 - INFO - __main__ - Step 780 Global step 780 Train loss 1.30 on epoch=55
05/17/2022 20:00:18 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=56
05/17/2022 20:00:19 - INFO - __main__ - Step 800 Global step 800 Train loss 1.28 on epoch=57
05/17/2022 20:00:22 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.06905450799967804 on epoch=57
05/17/2022 20:00:24 - INFO - __main__ - Step 810 Global step 810 Train loss 1.21 on epoch=57
05/17/2022 20:00:25 - INFO - __main__ - Step 820 Global step 820 Train loss 1.15 on epoch=58
05/17/2022 20:00:26 - INFO - __main__ - Step 830 Global step 830 Train loss 1.21 on epoch=59
05/17/2022 20:00:28 - INFO - __main__ - Step 840 Global step 840 Train loss 1.19 on epoch=59
05/17/2022 20:00:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.26 on epoch=60
05/17/2022 20:00:32 - INFO - __main__ - Global step 850 Train loss 1.20 Classification-F1 0.10873378788650424 on epoch=60
05/17/2022 20:00:32 - INFO - __main__ - Saving model with best Classification-F1: 0.09314302212929959 -> 0.10873378788650424 on epoch=60, global_step=850
05/17/2022 20:00:33 - INFO - __main__ - Step 860 Global step 860 Train loss 1.20 on epoch=61
05/17/2022 20:00:35 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=62
05/17/2022 20:00:36 - INFO - __main__ - Step 880 Global step 880 Train loss 1.25 on epoch=62
05/17/2022 20:00:37 - INFO - __main__ - Step 890 Global step 890 Train loss 1.13 on epoch=63
05/17/2022 20:00:38 - INFO - __main__ - Step 900 Global step 900 Train loss 1.22 on epoch=64
05/17/2022 20:00:41 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.1596063650208572 on epoch=64
05/17/2022 20:00:41 - INFO - __main__ - Saving model with best Classification-F1: 0.10873378788650424 -> 0.1596063650208572 on epoch=64, global_step=900
05/17/2022 20:00:43 - INFO - __main__ - Step 910 Global step 910 Train loss 1.19 on epoch=64
05/17/2022 20:00:44 - INFO - __main__ - Step 920 Global step 920 Train loss 1.22 on epoch=65
05/17/2022 20:00:45 - INFO - __main__ - Step 930 Global step 930 Train loss 1.21 on epoch=66
05/17/2022 20:00:47 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=67
05/17/2022 20:00:48 - INFO - __main__ - Step 950 Global step 950 Train loss 1.20 on epoch=67
05/17/2022 20:00:51 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.2026036065329301 on epoch=67
05/17/2022 20:00:51 - INFO - __main__ - Saving model with best Classification-F1: 0.1596063650208572 -> 0.2026036065329301 on epoch=67, global_step=950
05/17/2022 20:00:52 - INFO - __main__ - Step 960 Global step 960 Train loss 1.13 on epoch=68
05/17/2022 20:00:54 - INFO - __main__ - Step 970 Global step 970 Train loss 1.21 on epoch=69
05/17/2022 20:00:55 - INFO - __main__ - Step 980 Global step 980 Train loss 1.10 on epoch=69
05/17/2022 20:00:56 - INFO - __main__ - Step 990 Global step 990 Train loss 1.08 on epoch=70
05/17/2022 20:00:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.20 on epoch=71
05/17/2022 20:01:01 - INFO - __main__ - Global step 1000 Train loss 1.14 Classification-F1 0.24822447914293694 on epoch=71
05/17/2022 20:01:01 - INFO - __main__ - Saving model with best Classification-F1: 0.2026036065329301 -> 0.24822447914293694 on epoch=71, global_step=1000
05/17/2022 20:01:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.14 on epoch=72
05/17/2022 20:01:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=72
05/17/2022 20:01:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.10 on epoch=73
05/17/2022 20:01:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=74
05/17/2022 20:01:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.13 on epoch=74
05/17/2022 20:01:10 - INFO - __main__ - Global step 1050 Train loss 1.13 Classification-F1 0.2727657735886707 on epoch=74
05/17/2022 20:01:10 - INFO - __main__ - Saving model with best Classification-F1: 0.24822447914293694 -> 0.2727657735886707 on epoch=74, global_step=1050
05/17/2022 20:01:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.13 on epoch=75
05/17/2022 20:01:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.15 on epoch=76
05/17/2022 20:01:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.11 on epoch=77
05/17/2022 20:01:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.12 on epoch=77
05/17/2022 20:01:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.01 on epoch=78
05/17/2022 20:01:20 - INFO - __main__ - Global step 1100 Train loss 1.10 Classification-F1 0.27167641830782246 on epoch=78
05/17/2022 20:01:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.11 on epoch=79
05/17/2022 20:01:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=79
05/17/2022 20:01:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.11 on epoch=80
05/17/2022 20:01:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.01 on epoch=81
05/17/2022 20:01:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.10 on epoch=82
05/17/2022 20:01:30 - INFO - __main__ - Global step 1150 Train loss 1.08 Classification-F1 0.300431811399176 on epoch=82
05/17/2022 20:01:30 - INFO - __main__ - Saving model with best Classification-F1: 0.2727657735886707 -> 0.300431811399176 on epoch=82, global_step=1150
05/17/2022 20:01:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.00 on epoch=82
05/17/2022 20:01:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=83
05/17/2022 20:01:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.01 on epoch=84
05/17/2022 20:01:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.02 on epoch=84
05/17/2022 20:01:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.10 on epoch=85
05/17/2022 20:01:40 - INFO - __main__ - Global step 1200 Train loss 1.04 Classification-F1 0.34806335312967424 on epoch=85
05/17/2022 20:01:40 - INFO - __main__ - Saving model with best Classification-F1: 0.300431811399176 -> 0.34806335312967424 on epoch=85, global_step=1200
05/17/2022 20:01:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.01 on epoch=86
05/17/2022 20:01:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/17/2022 20:01:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.11 on epoch=87
05/17/2022 20:01:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.02 on epoch=88
05/17/2022 20:01:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=89
05/17/2022 20:01:50 - INFO - __main__ - Global step 1250 Train loss 1.05 Classification-F1 0.38216840101473826 on epoch=89
05/17/2022 20:01:50 - INFO - __main__ - Saving model with best Classification-F1: 0.34806335312967424 -> 0.38216840101473826 on epoch=89, global_step=1250
05/17/2022 20:01:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.91 on epoch=89
05/17/2022 20:01:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.93 on epoch=90
05/17/2022 20:01:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.98 on epoch=91
05/17/2022 20:01:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.97 on epoch=92
05/17/2022 20:01:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=92
05/17/2022 20:02:00 - INFO - __main__ - Global step 1300 Train loss 0.98 Classification-F1 0.3875282221753237 on epoch=92
05/17/2022 20:02:00 - INFO - __main__ - Saving model with best Classification-F1: 0.38216840101473826 -> 0.3875282221753237 on epoch=92, global_step=1300
05/17/2022 20:02:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.98 on epoch=93
05/17/2022 20:02:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.08 on epoch=94
05/17/2022 20:02:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.91 on epoch=94
05/17/2022 20:02:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.96 on epoch=95
05/17/2022 20:02:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.94 on epoch=96
05/17/2022 20:02:10 - INFO - __main__ - Global step 1350 Train loss 0.97 Classification-F1 0.42243569823875426 on epoch=96
05/17/2022 20:02:10 - INFO - __main__ - Saving model with best Classification-F1: 0.3875282221753237 -> 0.42243569823875426 on epoch=96, global_step=1350
05/17/2022 20:02:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.96 on epoch=97
05/17/2022 20:02:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.00 on epoch=97
05/17/2022 20:02:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.92 on epoch=98
05/17/2022 20:02:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.94 on epoch=99
05/17/2022 20:02:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.92 on epoch=99
05/17/2022 20:02:21 - INFO - __main__ - Global step 1400 Train loss 0.95 Classification-F1 0.46936844209583717 on epoch=99
05/17/2022 20:02:21 - INFO - __main__ - Saving model with best Classification-F1: 0.42243569823875426 -> 0.46936844209583717 on epoch=99, global_step=1400
05/17/2022 20:02:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.94 on epoch=100
05/17/2022 20:02:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.93 on epoch=101
05/17/2022 20:02:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.02 on epoch=102
05/17/2022 20:02:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.95 on epoch=102
05/17/2022 20:02:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.02 on epoch=103
05/17/2022 20:02:32 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.4525355104665449 on epoch=103
05/17/2022 20:02:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.88 on epoch=104
05/17/2022 20:02:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.90 on epoch=104
05/17/2022 20:02:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.94 on epoch=105
05/17/2022 20:02:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.88 on epoch=106
05/17/2022 20:02:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.85 on epoch=107
05/17/2022 20:02:42 - INFO - __main__ - Global step 1500 Train loss 0.89 Classification-F1 0.4940221312176071 on epoch=107
05/17/2022 20:02:42 - INFO - __main__ - Saving model with best Classification-F1: 0.46936844209583717 -> 0.4940221312176071 on epoch=107, global_step=1500
05/17/2022 20:02:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.85 on epoch=107
05/17/2022 20:02:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.77 on epoch=108
05/17/2022 20:02:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.83 on epoch=109
05/17/2022 20:02:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.77 on epoch=109
05/17/2022 20:02:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.87 on epoch=110
05/17/2022 20:02:52 - INFO - __main__ - Global step 1550 Train loss 0.82 Classification-F1 0.5083913693625749 on epoch=110
05/17/2022 20:02:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4940221312176071 -> 0.5083913693625749 on epoch=110, global_step=1550
05/17/2022 20:02:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.87 on epoch=111
05/17/2022 20:02:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.90 on epoch=112
05/17/2022 20:02:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.70 on epoch=112
05/17/2022 20:02:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.78 on epoch=113
05/17/2022 20:02:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.83 on epoch=114
05/17/2022 20:03:02 - INFO - __main__ - Global step 1600 Train loss 0.82 Classification-F1 0.5174731922274491 on epoch=114
05/17/2022 20:03:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5083913693625749 -> 0.5174731922274491 on epoch=114, global_step=1600
05/17/2022 20:03:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.90 on epoch=114
05/17/2022 20:03:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.76 on epoch=115
05/17/2022 20:03:06 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.81 on epoch=116
05/17/2022 20:03:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.85 on epoch=117
05/17/2022 20:03:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.79 on epoch=117
05/17/2022 20:03:12 - INFO - __main__ - Global step 1650 Train loss 0.82 Classification-F1 0.5451205044093885 on epoch=117
05/17/2022 20:03:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5174731922274491 -> 0.5451205044093885 on epoch=117, global_step=1650
05/17/2022 20:03:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.77 on epoch=118
05/17/2022 20:03:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.81 on epoch=119
05/17/2022 20:03:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.78 on epoch=119
05/17/2022 20:03:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.81 on epoch=120
05/17/2022 20:03:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.67 on epoch=121
05/17/2022 20:03:22 - INFO - __main__ - Global step 1700 Train loss 0.77 Classification-F1 0.4919108200670532 on epoch=121
05/17/2022 20:03:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.70 on epoch=122
05/17/2022 20:03:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.78 on epoch=122
05/17/2022 20:03:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.73 on epoch=123
05/17/2022 20:03:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.71 on epoch=124
05/17/2022 20:03:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.82 on epoch=124
05/17/2022 20:03:32 - INFO - __main__ - Global step 1750 Train loss 0.75 Classification-F1 0.509559247238019 on epoch=124
05/17/2022 20:03:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/17/2022 20:03:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.75 on epoch=126
05/17/2022 20:03:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.67 on epoch=127
05/17/2022 20:03:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.71 on epoch=127
05/17/2022 20:03:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.67 on epoch=128
05/17/2022 20:03:42 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.5315294940748904 on epoch=128
05/17/2022 20:03:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.75 on epoch=129
05/17/2022 20:03:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.70 on epoch=129
05/17/2022 20:03:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.65 on epoch=130
05/17/2022 20:03:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.70 on epoch=131
05/17/2022 20:03:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.71 on epoch=132
05/17/2022 20:03:52 - INFO - __main__ - Global step 1850 Train loss 0.70 Classification-F1 0.5077311619829451 on epoch=132
05/17/2022 20:03:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.77 on epoch=132
05/17/2022 20:03:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.68 on epoch=133
05/17/2022 20:03:56 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.67 on epoch=134
05/17/2022 20:03:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.72 on epoch=134
05/17/2022 20:03:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.71 on epoch=135
05/17/2022 20:04:02 - INFO - __main__ - Global step 1900 Train loss 0.71 Classification-F1 0.5399268935940604 on epoch=135
05/17/2022 20:04:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.67 on epoch=136
05/17/2022 20:04:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.77 on epoch=137
05/17/2022 20:04:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.68 on epoch=137
05/17/2022 20:04:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/17/2022 20:04:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.62 on epoch=139
05/17/2022 20:04:12 - INFO - __main__ - Global step 1950 Train loss 0.70 Classification-F1 0.5391985936447581 on epoch=139
05/17/2022 20:04:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.70 on epoch=139
05/17/2022 20:04:15 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.63 on epoch=140
05/17/2022 20:04:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.66 on epoch=141
05/17/2022 20:04:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.60 on epoch=142
05/17/2022 20:04:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.64 on epoch=142
05/17/2022 20:04:22 - INFO - __main__ - Global step 2000 Train loss 0.65 Classification-F1 0.5059524267657879 on epoch=142
05/17/2022 20:04:24 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/17/2022 20:04:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.67 on epoch=144
05/17/2022 20:04:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.66 on epoch=144
05/17/2022 20:04:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.65 on epoch=145
05/17/2022 20:04:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/17/2022 20:04:33 - INFO - __main__ - Global step 2050 Train loss 0.66 Classification-F1 0.42088753418298863 on epoch=146
05/17/2022 20:04:34 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.77 on epoch=147
05/17/2022 20:04:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.67 on epoch=147
05/17/2022 20:04:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.65 on epoch=148
05/17/2022 20:04:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.69 on epoch=149
05/17/2022 20:04:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.75 on epoch=149
05/17/2022 20:04:43 - INFO - __main__ - Global step 2100 Train loss 0.71 Classification-F1 0.47938028846400726 on epoch=149
05/17/2022 20:04:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.68 on epoch=150
05/17/2022 20:04:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.61 on epoch=151
05/17/2022 20:04:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.58 on epoch=152
05/17/2022 20:04:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.71 on epoch=152
05/17/2022 20:04:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.63 on epoch=153
05/17/2022 20:04:53 - INFO - __main__ - Global step 2150 Train loss 0.64 Classification-F1 0.41135459603298846 on epoch=153
05/17/2022 20:04:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.66 on epoch=154
05/17/2022 20:04:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.66 on epoch=154
05/17/2022 20:04:57 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.71 on epoch=155
05/17/2022 20:04:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.62 on epoch=156
05/17/2022 20:04:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.68 on epoch=157
05/17/2022 20:05:03 - INFO - __main__ - Global step 2200 Train loss 0.67 Classification-F1 0.5283378605217686 on epoch=157
05/17/2022 20:05:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.68 on epoch=157
05/17/2022 20:05:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.66 on epoch=158
05/17/2022 20:05:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.61 on epoch=159
05/17/2022 20:05:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/17/2022 20:05:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/17/2022 20:05:13 - INFO - __main__ - Global step 2250 Train loss 0.68 Classification-F1 0.5290302982118624 on epoch=160
05/17/2022 20:05:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.56 on epoch=161
05/17/2022 20:05:16 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.66 on epoch=162
05/17/2022 20:05:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.61 on epoch=162
05/17/2022 20:05:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.70 on epoch=163
05/17/2022 20:05:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.57 on epoch=164
05/17/2022 20:05:23 - INFO - __main__ - Global step 2300 Train loss 0.62 Classification-F1 0.45205589272409546 on epoch=164
05/17/2022 20:05:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.67 on epoch=164
05/17/2022 20:05:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.70 on epoch=165
05/17/2022 20:05:27 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.62 on epoch=166
05/17/2022 20:05:28 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.68 on epoch=167
05/17/2022 20:05:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.66 on epoch=167
05/17/2022 20:05:34 - INFO - __main__ - Global step 2350 Train loss 0.66 Classification-F1 0.4622387271992328 on epoch=167
05/17/2022 20:05:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.63 on epoch=168
05/17/2022 20:05:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.66 on epoch=169
05/17/2022 20:05:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.58 on epoch=169
05/17/2022 20:05:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.62 on epoch=170
05/17/2022 20:05:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.65 on epoch=171
05/17/2022 20:05:44 - INFO - __main__ - Global step 2400 Train loss 0.63 Classification-F1 0.504928620456147 on epoch=171
05/17/2022 20:05:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.57 on epoch=172
05/17/2022 20:05:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.70 on epoch=172
05/17/2022 20:05:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.63 on epoch=173
05/17/2022 20:05:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.62 on epoch=174
05/17/2022 20:05:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.58 on epoch=174
05/17/2022 20:05:54 - INFO - __main__ - Global step 2450 Train loss 0.62 Classification-F1 0.45292572023328764 on epoch=174
05/17/2022 20:05:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.61 on epoch=175
05/17/2022 20:05:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.56 on epoch=176
05/17/2022 20:05:58 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.60 on epoch=177
05/17/2022 20:05:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.58 on epoch=177
05/17/2022 20:06:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.63 on epoch=178
05/17/2022 20:06:05 - INFO - __main__ - Global step 2500 Train loss 0.60 Classification-F1 0.4696354581058407 on epoch=178
05/17/2022 20:06:06 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.68 on epoch=179
05/17/2022 20:06:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.60 on epoch=179
05/17/2022 20:06:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.65 on epoch=180
05/17/2022 20:06:10 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.64 on epoch=181
05/17/2022 20:06:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.56 on epoch=182
05/17/2022 20:06:15 - INFO - __main__ - Global step 2550 Train loss 0.62 Classification-F1 0.46752012148416855 on epoch=182
05/17/2022 20:06:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/17/2022 20:06:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.60 on epoch=183
05/17/2022 20:06:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.67 on epoch=184
05/17/2022 20:06:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.53 on epoch=184
05/17/2022 20:06:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/17/2022 20:06:25 - INFO - __main__ - Global step 2600 Train loss 0.61 Classification-F1 0.502043806049571 on epoch=185
05/17/2022 20:06:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.54 on epoch=186
05/17/2022 20:06:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.69 on epoch=187
05/17/2022 20:06:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.63 on epoch=187
05/17/2022 20:06:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.66 on epoch=188
05/17/2022 20:06:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.64 on epoch=189
05/17/2022 20:06:35 - INFO - __main__ - Global step 2650 Train loss 0.63 Classification-F1 0.46489714715078917 on epoch=189
05/17/2022 20:06:36 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.60 on epoch=189
05/17/2022 20:06:38 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.69 on epoch=190
05/17/2022 20:06:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.53 on epoch=191
05/17/2022 20:06:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.62 on epoch=192
05/17/2022 20:06:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.72 on epoch=192
05/17/2022 20:06:45 - INFO - __main__ - Global step 2700 Train loss 0.63 Classification-F1 0.4486575016695601 on epoch=192
05/17/2022 20:06:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.58 on epoch=193
05/17/2022 20:06:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.53 on epoch=194
05/17/2022 20:06:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.69 on epoch=194
05/17/2022 20:06:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.53 on epoch=195
05/17/2022 20:06:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.58 on epoch=196
05/17/2022 20:06:56 - INFO - __main__ - Global step 2750 Train loss 0.58 Classification-F1 0.5028305654763484 on epoch=196
05/17/2022 20:06:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.63 on epoch=197
05/17/2022 20:06:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.59 on epoch=197
05/17/2022 20:06:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.71 on epoch=198
05/17/2022 20:07:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.66 on epoch=199
05/17/2022 20:07:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.53 on epoch=199
05/17/2022 20:07:06 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.5061377064972391 on epoch=199
05/17/2022 20:07:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.63 on epoch=200
05/17/2022 20:07:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.57 on epoch=201
05/17/2022 20:07:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.61 on epoch=202
05/17/2022 20:07:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.57 on epoch=202
05/17/2022 20:07:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.58 on epoch=203
05/17/2022 20:07:16 - INFO - __main__ - Global step 2850 Train loss 0.59 Classification-F1 0.5031510894281706 on epoch=203
05/17/2022 20:07:17 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.57 on epoch=204
05/17/2022 20:07:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.61 on epoch=204
05/17/2022 20:07:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.59 on epoch=205
05/17/2022 20:07:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/17/2022 20:07:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.52 on epoch=207
05/17/2022 20:07:26 - INFO - __main__ - Global step 2900 Train loss 0.58 Classification-F1 0.4526871050483903 on epoch=207
05/17/2022 20:07:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.66 on epoch=207
05/17/2022 20:07:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.60 on epoch=208
05/17/2022 20:07:30 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.61 on epoch=209
05/17/2022 20:07:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.56 on epoch=209
05/17/2022 20:07:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/17/2022 20:07:36 - INFO - __main__ - Global step 2950 Train loss 0.60 Classification-F1 0.4780956162273541 on epoch=210
05/17/2022 20:07:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.50 on epoch=211
05/17/2022 20:07:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.67 on epoch=212
05/17/2022 20:07:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.55 on epoch=212
05/17/2022 20:07:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.59 on epoch=213
05/17/2022 20:07:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.63 on epoch=214
05/17/2022 20:07:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:07:44 - INFO - __main__ - Printing 3 examples
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:07:44 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:07:44 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:07:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:07:44 - INFO - __main__ - Printing 3 examples
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 20:07:44 - INFO - __main__ - ['Plant']
05/17/2022 20:07:44 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:07:44 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:07:45 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:07:47 - INFO - __main__ - Global step 3000 Train loss 0.59 Classification-F1 0.4556341274369846 on epoch=214
05/17/2022 20:07:47 - INFO - __main__ - save last model!
05/17/2022 20:07:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 20:07:47 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 20:07:47 - INFO - __main__ - Printing 3 examples
05/17/2022 20:07:47 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 20:07:47 - INFO - __main__ - ['Animal']
05/17/2022 20:07:47 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 20:07:47 - INFO - __main__ - ['Animal']
05/17/2022 20:07:47 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 20:07:47 - INFO - __main__ - ['Village']
05/17/2022 20:07:47 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:07:49 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:07:50 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:07:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:07:50 - INFO - __main__ - Starting training!
05/17/2022 20:07:52 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 20:09:02 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/17/2022 20:09:02 - INFO - __main__ - Classification-F1 on test data: 0.1490
05/17/2022 20:09:02 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.5451205044093885, test_performance=0.1490095654550946
05/17/2022 20:09:02 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/17/2022 20:09:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:09:03 - INFO - __main__ - Printing 3 examples
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:09:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:09:03 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:09:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:09:03 - INFO - __main__ - Printing 3 examples
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 20:09:03 - INFO - __main__ - ['Plant']
05/17/2022 20:09:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:09:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:09:03 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:09:09 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:09:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:09:09 - INFO - __main__ - Starting training!
05/17/2022 20:09:11 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/17/2022 20:09:12 - INFO - __main__ - Step 20 Global step 20 Train loss 7.05 on epoch=1
05/17/2022 20:09:13 - INFO - __main__ - Step 30 Global step 30 Train loss 6.54 on epoch=2
05/17/2022 20:09:14 - INFO - __main__ - Step 40 Global step 40 Train loss 6.44 on epoch=2
05/17/2022 20:09:16 - INFO - __main__ - Step 50 Global step 50 Train loss 5.89 on epoch=3
05/17/2022 20:09:19 - INFO - __main__ - Global step 50 Train loss 6.70 Classification-F1 0.0 on epoch=3
05/17/2022 20:09:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 20:09:21 - INFO - __main__ - Step 60 Global step 60 Train loss 5.64 on epoch=4
05/17/2022 20:09:22 - INFO - __main__ - Step 70 Global step 70 Train loss 5.26 on epoch=4
05/17/2022 20:09:23 - INFO - __main__ - Step 80 Global step 80 Train loss 5.04 on epoch=5
05/17/2022 20:09:24 - INFO - __main__ - Step 90 Global step 90 Train loss 4.83 on epoch=6
05/17/2022 20:09:26 - INFO - __main__ - Step 100 Global step 100 Train loss 4.62 on epoch=7
05/17/2022 20:09:29 - INFO - __main__ - Global step 100 Train loss 5.08 Classification-F1 0.0 on epoch=7
05/17/2022 20:09:30 - INFO - __main__ - Step 110 Global step 110 Train loss 4.44 on epoch=7
05/17/2022 20:09:31 - INFO - __main__ - Step 120 Global step 120 Train loss 4.26 on epoch=8
05/17/2022 20:09:32 - INFO - __main__ - Step 130 Global step 130 Train loss 4.06 on epoch=9
05/17/2022 20:09:34 - INFO - __main__ - Step 140 Global step 140 Train loss 3.81 on epoch=9
05/17/2022 20:09:35 - INFO - __main__ - Step 150 Global step 150 Train loss 3.95 on epoch=10
05/17/2022 20:09:38 - INFO - __main__ - Global step 150 Train loss 4.10 Classification-F1 0.0 on epoch=10
05/17/2022 20:09:39 - INFO - __main__ - Step 160 Global step 160 Train loss 3.68 on epoch=11
05/17/2022 20:09:40 - INFO - __main__ - Step 170 Global step 170 Train loss 3.55 on epoch=12
05/17/2022 20:09:42 - INFO - __main__ - Step 180 Global step 180 Train loss 3.47 on epoch=12
05/17/2022 20:09:43 - INFO - __main__ - Step 190 Global step 190 Train loss 3.31 on epoch=13
05/17/2022 20:09:44 - INFO - __main__ - Step 200 Global step 200 Train loss 3.27 on epoch=14
05/17/2022 20:09:47 - INFO - __main__ - Global step 200 Train loss 3.45 Classification-F1 0.002530044275774826 on epoch=14
05/17/2022 20:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.002530044275774826 on epoch=14, global_step=200
05/17/2022 20:09:48 - INFO - __main__ - Step 210 Global step 210 Train loss 3.02 on epoch=14
05/17/2022 20:09:49 - INFO - __main__ - Step 220 Global step 220 Train loss 3.14 on epoch=15
05/17/2022 20:09:51 - INFO - __main__ - Step 230 Global step 230 Train loss 3.02 on epoch=16
05/17/2022 20:09:52 - INFO - __main__ - Step 240 Global step 240 Train loss 2.89 on epoch=17
05/17/2022 20:09:53 - INFO - __main__ - Step 250 Global step 250 Train loss 2.79 on epoch=17
05/17/2022 20:09:56 - INFO - __main__ - Global step 250 Train loss 2.97 Classification-F1 0.005490196078431373 on epoch=17
05/17/2022 20:09:56 - INFO - __main__ - Saving model with best Classification-F1: 0.002530044275774826 -> 0.005490196078431373 on epoch=17, global_step=250
05/17/2022 20:09:57 - INFO - __main__ - Step 260 Global step 260 Train loss 2.72 on epoch=18
05/17/2022 20:09:58 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/17/2022 20:09:59 - INFO - __main__ - Step 280 Global step 280 Train loss 2.53 on epoch=19
05/17/2022 20:10:01 - INFO - __main__ - Step 290 Global step 290 Train loss 2.59 on epoch=20
05/17/2022 20:10:02 - INFO - __main__ - Step 300 Global step 300 Train loss 2.40 on epoch=21
05/17/2022 20:10:04 - INFO - __main__ - Global step 300 Train loss 2.57 Classification-F1 0.00892608089260809 on epoch=21
05/17/2022 20:10:04 - INFO - __main__ - Saving model with best Classification-F1: 0.005490196078431373 -> 0.00892608089260809 on epoch=21, global_step=300
05/17/2022 20:10:05 - INFO - __main__ - Step 310 Global step 310 Train loss 2.43 on epoch=22
05/17/2022 20:10:06 - INFO - __main__ - Step 320 Global step 320 Train loss 2.37 on epoch=22
05/17/2022 20:10:08 - INFO - __main__ - Step 330 Global step 330 Train loss 2.36 on epoch=23
05/17/2022 20:10:09 - INFO - __main__ - Step 340 Global step 340 Train loss 2.31 on epoch=24
05/17/2022 20:10:10 - INFO - __main__ - Step 350 Global step 350 Train loss 2.25 on epoch=24
05/17/2022 20:10:12 - INFO - __main__ - Global step 350 Train loss 2.35 Classification-F1 0.009523809523809523 on epoch=24
05/17/2022 20:10:12 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=24, global_step=350
05/17/2022 20:10:13 - INFO - __main__ - Step 360 Global step 360 Train loss 2.28 on epoch=25
05/17/2022 20:10:15 - INFO - __main__ - Step 370 Global step 370 Train loss 2.12 on epoch=26
05/17/2022 20:10:16 - INFO - __main__ - Step 380 Global step 380 Train loss 2.20 on epoch=27
05/17/2022 20:10:17 - INFO - __main__ - Step 390 Global step 390 Train loss 2.19 on epoch=27
05/17/2022 20:10:18 - INFO - __main__ - Step 400 Global step 400 Train loss 2.13 on epoch=28
05/17/2022 20:10:20 - INFO - __main__ - Global step 400 Train loss 2.18 Classification-F1 0.01083276912660799 on epoch=28
05/17/2022 20:10:20 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01083276912660799 on epoch=28, global_step=400
05/17/2022 20:10:22 - INFO - __main__ - Step 410 Global step 410 Train loss 2.03 on epoch=29
05/17/2022 20:10:23 - INFO - __main__ - Step 420 Global step 420 Train loss 2.04 on epoch=29
05/17/2022 20:10:24 - INFO - __main__ - Step 430 Global step 430 Train loss 2.06 on epoch=30
05/17/2022 20:10:25 - INFO - __main__ - Step 440 Global step 440 Train loss 1.90 on epoch=31
05/17/2022 20:10:27 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=32
05/17/2022 20:10:29 - INFO - __main__ - Global step 450 Train loss 1.98 Classification-F1 0.034133420493967795 on epoch=32
05/17/2022 20:10:29 - INFO - __main__ - Saving model with best Classification-F1: 0.01083276912660799 -> 0.034133420493967795 on epoch=32, global_step=450
05/17/2022 20:10:30 - INFO - __main__ - Step 460 Global step 460 Train loss 1.88 on epoch=32
05/17/2022 20:10:31 - INFO - __main__ - Step 470 Global step 470 Train loss 1.84 on epoch=33
05/17/2022 20:10:32 - INFO - __main__ - Step 480 Global step 480 Train loss 1.83 on epoch=34
05/17/2022 20:10:34 - INFO - __main__ - Step 490 Global step 490 Train loss 1.78 on epoch=34
05/17/2022 20:10:35 - INFO - __main__ - Step 500 Global step 500 Train loss 1.85 on epoch=35
05/17/2022 20:10:37 - INFO - __main__ - Global step 500 Train loss 1.84 Classification-F1 0.026049068302589427 on epoch=35
05/17/2022 20:10:38 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=36
05/17/2022 20:10:39 - INFO - __main__ - Step 520 Global step 520 Train loss 1.71 on epoch=37
05/17/2022 20:10:40 - INFO - __main__ - Step 530 Global step 530 Train loss 1.72 on epoch=37
05/17/2022 20:10:42 - INFO - __main__ - Step 540 Global step 540 Train loss 1.70 on epoch=38
05/17/2022 20:10:43 - INFO - __main__ - Step 550 Global step 550 Train loss 1.63 on epoch=39
05/17/2022 20:10:45 - INFO - __main__ - Global step 550 Train loss 1.68 Classification-F1 0.03996362433862433 on epoch=39
05/17/2022 20:10:45 - INFO - __main__ - Saving model with best Classification-F1: 0.034133420493967795 -> 0.03996362433862433 on epoch=39, global_step=550
05/17/2022 20:10:46 - INFO - __main__ - Step 560 Global step 560 Train loss 1.58 on epoch=39
05/17/2022 20:10:47 - INFO - __main__ - Step 570 Global step 570 Train loss 1.58 on epoch=40
05/17/2022 20:10:49 - INFO - __main__ - Step 580 Global step 580 Train loss 1.56 on epoch=41
05/17/2022 20:10:50 - INFO - __main__ - Step 590 Global step 590 Train loss 1.58 on epoch=42
05/17/2022 20:10:51 - INFO - __main__ - Step 600 Global step 600 Train loss 1.62 on epoch=42
05/17/2022 20:10:53 - INFO - __main__ - Global step 600 Train loss 1.59 Classification-F1 0.060707955638831204 on epoch=42
05/17/2022 20:10:53 - INFO - __main__ - Saving model with best Classification-F1: 0.03996362433862433 -> 0.060707955638831204 on epoch=42, global_step=600
05/17/2022 20:10:55 - INFO - __main__ - Step 610 Global step 610 Train loss 1.45 on epoch=43
05/17/2022 20:10:56 - INFO - __main__ - Step 620 Global step 620 Train loss 1.53 on epoch=44
05/17/2022 20:10:57 - INFO - __main__ - Step 630 Global step 630 Train loss 1.50 on epoch=44
05/17/2022 20:10:58 - INFO - __main__ - Step 640 Global step 640 Train loss 1.49 on epoch=45
05/17/2022 20:11:00 - INFO - __main__ - Step 650 Global step 650 Train loss 1.40 on epoch=46
05/17/2022 20:11:02 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.0195970695970696 on epoch=46
05/17/2022 20:11:03 - INFO - __main__ - Step 660 Global step 660 Train loss 1.42 on epoch=47
05/17/2022 20:11:04 - INFO - __main__ - Step 670 Global step 670 Train loss 1.56 on epoch=47
05/17/2022 20:11:06 - INFO - __main__ - Step 680 Global step 680 Train loss 1.47 on epoch=48
05/17/2022 20:11:07 - INFO - __main__ - Step 690 Global step 690 Train loss 1.43 on epoch=49
05/17/2022 20:11:08 - INFO - __main__ - Step 700 Global step 700 Train loss 1.51 on epoch=49
05/17/2022 20:11:10 - INFO - __main__ - Global step 700 Train loss 1.48 Classification-F1 0.020545028741750054 on epoch=49
05/17/2022 20:11:11 - INFO - __main__ - Step 710 Global step 710 Train loss 1.50 on epoch=50
05/17/2022 20:11:13 - INFO - __main__ - Step 720 Global step 720 Train loss 1.32 on epoch=51
05/17/2022 20:11:14 - INFO - __main__ - Step 730 Global step 730 Train loss 1.49 on epoch=52
05/17/2022 20:11:15 - INFO - __main__ - Step 740 Global step 740 Train loss 1.33 on epoch=52
05/17/2022 20:11:16 - INFO - __main__ - Step 750 Global step 750 Train loss 1.36 on epoch=53
05/17/2022 20:11:18 - INFO - __main__ - Global step 750 Train loss 1.40 Classification-F1 0.050526777950217 on epoch=53
05/17/2022 20:11:20 - INFO - __main__ - Step 760 Global step 760 Train loss 1.45 on epoch=54
05/17/2022 20:11:21 - INFO - __main__ - Step 770 Global step 770 Train loss 1.32 on epoch=54
05/17/2022 20:11:22 - INFO - __main__ - Step 780 Global step 780 Train loss 1.28 on epoch=55
05/17/2022 20:11:23 - INFO - __main__ - Step 790 Global step 790 Train loss 1.29 on epoch=56
05/17/2022 20:11:25 - INFO - __main__ - Step 800 Global step 800 Train loss 1.32 on epoch=57
05/17/2022 20:11:28 - INFO - __main__ - Global step 800 Train loss 1.33 Classification-F1 0.06943822119138983 on epoch=57
05/17/2022 20:11:28 - INFO - __main__ - Saving model with best Classification-F1: 0.060707955638831204 -> 0.06943822119138983 on epoch=57, global_step=800
05/17/2022 20:11:29 - INFO - __main__ - Step 810 Global step 810 Train loss 1.47 on epoch=57
05/17/2022 20:11:30 - INFO - __main__ - Step 820 Global step 820 Train loss 1.36 on epoch=58
05/17/2022 20:11:32 - INFO - __main__ - Step 830 Global step 830 Train loss 1.42 on epoch=59
05/17/2022 20:11:33 - INFO - __main__ - Step 840 Global step 840 Train loss 1.28 on epoch=59
05/17/2022 20:11:34 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=60
05/17/2022 20:11:36 - INFO - __main__ - Global step 850 Train loss 1.39 Classification-F1 0.044114069190088374 on epoch=60
05/17/2022 20:11:37 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/17/2022 20:11:39 - INFO - __main__ - Step 870 Global step 870 Train loss 1.28 on epoch=62
05/17/2022 20:11:40 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=62
05/17/2022 20:11:41 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=63
05/17/2022 20:11:42 - INFO - __main__ - Step 900 Global step 900 Train loss 1.39 on epoch=64
05/17/2022 20:11:44 - INFO - __main__ - Global step 900 Train loss 1.33 Classification-F1 0.03970641613662208 on epoch=64
05/17/2022 20:11:46 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=64
05/17/2022 20:11:47 - INFO - __main__ - Step 920 Global step 920 Train loss 1.31 on epoch=65
05/17/2022 20:11:48 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=66
05/17/2022 20:11:49 - INFO - __main__ - Step 940 Global step 940 Train loss 1.36 on epoch=67
05/17/2022 20:11:51 - INFO - __main__ - Step 950 Global step 950 Train loss 1.35 on epoch=67
05/17/2022 20:11:53 - INFO - __main__ - Global step 950 Train loss 1.33 Classification-F1 0.11142225815602004 on epoch=67
05/17/2022 20:11:53 - INFO - __main__ - Saving model with best Classification-F1: 0.06943822119138983 -> 0.11142225815602004 on epoch=67, global_step=950
05/17/2022 20:11:54 - INFO - __main__ - Step 960 Global step 960 Train loss 1.26 on epoch=68
05/17/2022 20:11:56 - INFO - __main__ - Step 970 Global step 970 Train loss 1.22 on epoch=69
05/17/2022 20:11:57 - INFO - __main__ - Step 980 Global step 980 Train loss 1.26 on epoch=69
05/17/2022 20:11:58 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=70
05/17/2022 20:11:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.24 on epoch=71
05/17/2022 20:12:02 - INFO - __main__ - Global step 1000 Train loss 1.26 Classification-F1 0.16134746283508378 on epoch=71
05/17/2022 20:12:02 - INFO - __main__ - Saving model with best Classification-F1: 0.11142225815602004 -> 0.16134746283508378 on epoch=71, global_step=1000
05/17/2022 20:12:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.30 on epoch=72
05/17/2022 20:12:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.23 on epoch=72
05/17/2022 20:12:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=73
05/17/2022 20:12:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.21 on epoch=74
05/17/2022 20:12:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=74
05/17/2022 20:12:12 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.25977981476750467 on epoch=74
05/17/2022 20:12:12 - INFO - __main__ - Saving model with best Classification-F1: 0.16134746283508378 -> 0.25977981476750467 on epoch=74, global_step=1050
05/17/2022 20:12:13 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.27 on epoch=75
05/17/2022 20:12:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=76
05/17/2022 20:12:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.23 on epoch=77
05/17/2022 20:12:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.18 on epoch=77
05/17/2022 20:12:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.15 on epoch=78
05/17/2022 20:12:21 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.2554424553523898 on epoch=78
05/17/2022 20:12:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.09 on epoch=79
05/17/2022 20:12:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.11 on epoch=79
05/17/2022 20:12:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.21 on epoch=80
05/17/2022 20:12:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.11 on epoch=81
05/17/2022 20:12:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=82
05/17/2022 20:12:30 - INFO - __main__ - Global step 1150 Train loss 1.13 Classification-F1 0.31771979645600373 on epoch=82
05/17/2022 20:12:30 - INFO - __main__ - Saving model with best Classification-F1: 0.25977981476750467 -> 0.31771979645600373 on epoch=82, global_step=1150
05/17/2022 20:12:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.16 on epoch=82
05/17/2022 20:12:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.12 on epoch=83
05/17/2022 20:12:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.21 on epoch=84
05/17/2022 20:12:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=84
05/17/2022 20:12:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.06 on epoch=85
05/17/2022 20:12:40 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.3442867242670859 on epoch=85
05/17/2022 20:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.31771979645600373 -> 0.3442867242670859 on epoch=85, global_step=1200
05/17/2022 20:12:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.14 on epoch=86
05/17/2022 20:12:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.04 on epoch=87
05/17/2022 20:12:44 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=87
05/17/2022 20:12:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.12 on epoch=88
05/17/2022 20:12:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.05 on epoch=89
05/17/2022 20:12:49 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.4456553088342209 on epoch=89
05/17/2022 20:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.3442867242670859 -> 0.4456553088342209 on epoch=89, global_step=1250
05/17/2022 20:12:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.08 on epoch=89
05/17/2022 20:12:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.11 on epoch=90
05/17/2022 20:12:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.06 on epoch=91
05/17/2022 20:12:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.11 on epoch=92
05/17/2022 20:12:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=92
05/17/2022 20:12:59 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.4388525810890392 on epoch=92
05/17/2022 20:13:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.98 on epoch=93
05/17/2022 20:13:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.09 on epoch=94
05/17/2022 20:13:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.97 on epoch=94
05/17/2022 20:13:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.03 on epoch=95
05/17/2022 20:13:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.92 on epoch=96
05/17/2022 20:13:08 - INFO - __main__ - Global step 1350 Train loss 1.00 Classification-F1 0.42621259067053263 on epoch=96
05/17/2022 20:13:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.01 on epoch=97
05/17/2022 20:13:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=97
05/17/2022 20:13:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.00 on epoch=98
05/17/2022 20:13:14 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.00 on epoch=99
05/17/2022 20:13:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.01 on epoch=99
05/17/2022 20:13:18 - INFO - __main__ - Global step 1400 Train loss 1.02 Classification-F1 0.474250777363385 on epoch=99
05/17/2022 20:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.4456553088342209 -> 0.474250777363385 on epoch=99, global_step=1400
05/17/2022 20:13:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.93 on epoch=100
05/17/2022 20:13:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.99 on epoch=101
05/17/2022 20:13:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.00 on epoch=102
05/17/2022 20:13:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.01 on epoch=102
05/17/2022 20:13:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.91 on epoch=103
05/17/2022 20:13:28 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.4342149569980718 on epoch=103
05/17/2022 20:13:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.91 on epoch=104
05/17/2022 20:13:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.90 on epoch=104
05/17/2022 20:13:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.91 on epoch=105
05/17/2022 20:13:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.00 on epoch=106
05/17/2022 20:13:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.00 on epoch=107
05/17/2022 20:13:37 - INFO - __main__ - Global step 1500 Train loss 0.94 Classification-F1 0.4457592809389973 on epoch=107
05/17/2022 20:13:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.01 on epoch=107
05/17/2022 20:13:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.85 on epoch=108
05/17/2022 20:13:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.99 on epoch=109
05/17/2022 20:13:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.96 on epoch=109
05/17/2022 20:13:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.88 on epoch=110
05/17/2022 20:13:47 - INFO - __main__ - Global step 1550 Train loss 0.94 Classification-F1 0.4464614953989707 on epoch=110
05/17/2022 20:13:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.89 on epoch=111
05/17/2022 20:13:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.86 on epoch=112
05/17/2022 20:13:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.97 on epoch=112
05/17/2022 20:13:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=113
05/17/2022 20:13:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.82 on epoch=114
05/17/2022 20:13:57 - INFO - __main__ - Global step 1600 Train loss 0.89 Classification-F1 0.5185460927442817 on epoch=114
05/17/2022 20:13:57 - INFO - __main__ - Saving model with best Classification-F1: 0.474250777363385 -> 0.5185460927442817 on epoch=114, global_step=1600
05/17/2022 20:13:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.96 on epoch=114
05/17/2022 20:13:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.83 on epoch=115
05/17/2022 20:14:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.85 on epoch=116
05/17/2022 20:14:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.79 on epoch=117
05/17/2022 20:14:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.74 on epoch=117
05/17/2022 20:14:06 - INFO - __main__ - Global step 1650 Train loss 0.83 Classification-F1 0.45009135125995453 on epoch=117
05/17/2022 20:14:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.88 on epoch=118
05/17/2022 20:14:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.83 on epoch=119
05/17/2022 20:14:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.83 on epoch=119
05/17/2022 20:14:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.93 on epoch=120
05/17/2022 20:14:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.82 on epoch=121
05/17/2022 20:14:16 - INFO - __main__ - Global step 1700 Train loss 0.86 Classification-F1 0.49069730582644916 on epoch=121
05/17/2022 20:14:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.81 on epoch=122
05/17/2022 20:14:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=122
05/17/2022 20:14:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.84 on epoch=123
05/17/2022 20:14:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.85 on epoch=124
05/17/2022 20:14:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.80 on epoch=124
05/17/2022 20:14:26 - INFO - __main__ - Global step 1750 Train loss 0.85 Classification-F1 0.4850740572575491 on epoch=124
05/17/2022 20:14:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.76 on epoch=125
05/17/2022 20:14:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.83 on epoch=126
05/17/2022 20:14:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.85 on epoch=127
05/17/2022 20:14:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.83 on epoch=127
05/17/2022 20:14:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.88 on epoch=128
05/17/2022 20:14:36 - INFO - __main__ - Global step 1800 Train loss 0.83 Classification-F1 0.4155008599036395 on epoch=128
05/17/2022 20:14:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.84 on epoch=129
05/17/2022 20:14:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.88 on epoch=129
05/17/2022 20:14:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.75 on epoch=130
05/17/2022 20:14:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.82 on epoch=131
05/17/2022 20:14:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.86 on epoch=132
05/17/2022 20:14:46 - INFO - __main__ - Global step 1850 Train loss 0.83 Classification-F1 0.4638013882623782 on epoch=132
05/17/2022 20:14:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.85 on epoch=132
05/17/2022 20:14:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.83 on epoch=133
05/17/2022 20:14:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.79 on epoch=134
05/17/2022 20:14:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.99 on epoch=134
05/17/2022 20:14:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.87 on epoch=135
05/17/2022 20:14:55 - INFO - __main__ - Global step 1900 Train loss 0.86 Classification-F1 0.41182997628515194 on epoch=135
05/17/2022 20:14:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.71 on epoch=136
05/17/2022 20:14:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.81 on epoch=137
05/17/2022 20:14:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/17/2022 20:15:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/17/2022 20:15:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.73 on epoch=139
05/17/2022 20:15:05 - INFO - __main__ - Global step 1950 Train loss 0.76 Classification-F1 0.43181665859582796 on epoch=139
05/17/2022 20:15:07 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.69 on epoch=139
05/17/2022 20:15:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.68 on epoch=140
05/17/2022 20:15:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.77 on epoch=141
05/17/2022 20:15:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.75 on epoch=142
05/17/2022 20:15:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.77 on epoch=142
05/17/2022 20:15:15 - INFO - __main__ - Global step 2000 Train loss 0.73 Classification-F1 0.4544399551491709 on epoch=142
05/17/2022 20:15:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.81 on epoch=143
05/17/2022 20:15:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.82 on epoch=144
05/17/2022 20:15:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.78 on epoch=144
05/17/2022 20:15:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.81 on epoch=145
05/17/2022 20:15:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.73 on epoch=146
05/17/2022 20:15:25 - INFO - __main__ - Global step 2050 Train loss 0.79 Classification-F1 0.3853243129934757 on epoch=146
05/17/2022 20:15:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.75 on epoch=147
05/17/2022 20:15:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.73 on epoch=147
05/17/2022 20:15:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.72 on epoch=148
05/17/2022 20:15:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.73 on epoch=149
05/17/2022 20:15:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.74 on epoch=149
05/17/2022 20:15:35 - INFO - __main__ - Global step 2100 Train loss 0.73 Classification-F1 0.49391005923900655 on epoch=149
05/17/2022 20:15:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.74 on epoch=150
05/17/2022 20:15:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.78 on epoch=151
05/17/2022 20:15:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.67 on epoch=152
05/17/2022 20:15:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.73 on epoch=152
05/17/2022 20:15:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.70 on epoch=153
05/17/2022 20:15:45 - INFO - __main__ - Global step 2150 Train loss 0.73 Classification-F1 0.42771344563243857 on epoch=153
05/17/2022 20:15:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.74 on epoch=154
05/17/2022 20:15:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.79 on epoch=154
05/17/2022 20:15:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.81 on epoch=155
05/17/2022 20:15:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.75 on epoch=156
05/17/2022 20:15:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.80 on epoch=157
05/17/2022 20:15:55 - INFO - __main__ - Global step 2200 Train loss 0.78 Classification-F1 0.3922719280128331 on epoch=157
05/17/2022 20:15:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.78 on epoch=157
05/17/2022 20:15:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.74 on epoch=158
05/17/2022 20:15:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.77 on epoch=159
05/17/2022 20:16:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.75 on epoch=159
05/17/2022 20:16:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.86 on epoch=160
05/17/2022 20:16:04 - INFO - __main__ - Global step 2250 Train loss 0.78 Classification-F1 0.4405858438883079 on epoch=160
05/17/2022 20:16:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.78 on epoch=161
05/17/2022 20:16:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.75 on epoch=162
05/17/2022 20:16:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.81 on epoch=162
05/17/2022 20:16:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.78 on epoch=163
05/17/2022 20:16:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.80 on epoch=164
05/17/2022 20:16:14 - INFO - __main__ - Global step 2300 Train loss 0.78 Classification-F1 0.44904966092607185 on epoch=164
05/17/2022 20:16:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.84 on epoch=164
05/17/2022 20:16:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.78 on epoch=165
05/17/2022 20:16:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.78 on epoch=166
05/17/2022 20:16:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.78 on epoch=167
05/17/2022 20:16:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.82 on epoch=167
05/17/2022 20:16:24 - INFO - __main__ - Global step 2350 Train loss 0.80 Classification-F1 0.3845386778635046 on epoch=167
05/17/2022 20:16:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.74 on epoch=168
05/17/2022 20:16:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.82 on epoch=169
05/17/2022 20:16:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.77 on epoch=169
05/17/2022 20:16:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.70 on epoch=170
05/17/2022 20:16:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.69 on epoch=171
05/17/2022 20:16:34 - INFO - __main__ - Global step 2400 Train loss 0.74 Classification-F1 0.40877091022026135 on epoch=171
05/17/2022 20:16:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.80 on epoch=172
05/17/2022 20:16:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.72 on epoch=172
05/17/2022 20:16:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.79 on epoch=173
05/17/2022 20:16:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.78 on epoch=174
05/17/2022 20:16:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.86 on epoch=174
05/17/2022 20:16:44 - INFO - __main__ - Global step 2450 Train loss 0.79 Classification-F1 0.3875351177337717 on epoch=174
05/17/2022 20:16:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.86 on epoch=175
05/17/2022 20:16:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.82 on epoch=176
05/17/2022 20:16:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.87 on epoch=177
05/17/2022 20:16:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.76 on epoch=177
05/17/2022 20:16:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.66 on epoch=178
05/17/2022 20:16:53 - INFO - __main__ - Global step 2500 Train loss 0.79 Classification-F1 0.4368257148599654 on epoch=178
05/17/2022 20:16:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.69 on epoch=179
05/17/2022 20:16:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.65 on epoch=179
05/17/2022 20:16:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.76 on epoch=180
05/17/2022 20:16:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.71 on epoch=181
05/17/2022 20:17:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.62 on epoch=182
05/17/2022 20:17:03 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.4707824754818409 on epoch=182
05/17/2022 20:17:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.69 on epoch=182
05/17/2022 20:17:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.69 on epoch=183
05/17/2022 20:17:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.80 on epoch=184
05/17/2022 20:17:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/17/2022 20:17:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.70 on epoch=185
05/17/2022 20:17:13 - INFO - __main__ - Global step 2600 Train loss 0.72 Classification-F1 0.4466566312651423 on epoch=185
05/17/2022 20:17:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.68 on epoch=186
05/17/2022 20:17:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.74 on epoch=187
05/17/2022 20:17:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.70 on epoch=187
05/17/2022 20:17:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/17/2022 20:17:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.74 on epoch=189
05/17/2022 20:17:23 - INFO - __main__ - Global step 2650 Train loss 0.71 Classification-F1 0.38128984293697443 on epoch=189
05/17/2022 20:17:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.64 on epoch=189
05/17/2022 20:17:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.76 on epoch=190
05/17/2022 20:17:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.64 on epoch=191
05/17/2022 20:17:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.68 on epoch=192
05/17/2022 20:17:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.74 on epoch=192
05/17/2022 20:17:34 - INFO - __main__ - Global step 2700 Train loss 0.69 Classification-F1 0.4694359592947054 on epoch=192
05/17/2022 20:17:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.67 on epoch=193
05/17/2022 20:17:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.67 on epoch=194
05/17/2022 20:17:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/17/2022 20:17:39 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.75 on epoch=195
05/17/2022 20:17:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.62 on epoch=196
05/17/2022 20:17:43 - INFO - __main__ - Global step 2750 Train loss 0.68 Classification-F1 0.4905953124454761 on epoch=196
05/17/2022 20:17:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.74 on epoch=197
05/17/2022 20:17:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.65 on epoch=197
05/17/2022 20:17:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.66 on epoch=198
05/17/2022 20:17:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.73 on epoch=199
05/17/2022 20:17:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.67 on epoch=199
05/17/2022 20:17:53 - INFO - __main__ - Global step 2800 Train loss 0.69 Classification-F1 0.5005729849885869 on epoch=199
05/17/2022 20:17:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.65 on epoch=200
05/17/2022 20:17:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.76 on epoch=201
05/17/2022 20:17:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.68 on epoch=202
05/17/2022 20:17:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.64 on epoch=202
05/17/2022 20:17:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.73 on epoch=203
05/17/2022 20:18:03 - INFO - __main__ - Global step 2850 Train loss 0.69 Classification-F1 0.48186980686980685 on epoch=203
05/17/2022 20:18:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.63 on epoch=204
05/17/2022 20:18:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/17/2022 20:18:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.62 on epoch=205
05/17/2022 20:18:08 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.66 on epoch=206
05/17/2022 20:18:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.57 on epoch=207
05/17/2022 20:18:13 - INFO - __main__ - Global step 2900 Train loss 0.62 Classification-F1 0.40065539268381994 on epoch=207
05/17/2022 20:18:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.61 on epoch=207
05/17/2022 20:18:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.65 on epoch=208
05/17/2022 20:18:17 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.64 on epoch=209
05/17/2022 20:18:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.65 on epoch=209
05/17/2022 20:18:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.63 on epoch=210
05/17/2022 20:18:23 - INFO - __main__ - Global step 2950 Train loss 0.64 Classification-F1 0.44125545022067475 on epoch=210
05/17/2022 20:18:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.56 on epoch=211
05/17/2022 20:18:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/17/2022 20:18:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.65 on epoch=212
05/17/2022 20:18:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.62 on epoch=213
05/17/2022 20:18:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.63 on epoch=214
05/17/2022 20:18:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:18:30 - INFO - __main__ - Printing 3 examples
05/17/2022 20:18:30 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 20:18:30 - INFO - __main__ - ['Plant']
05/17/2022 20:18:30 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 20:18:30 - INFO - __main__ - ['Plant']
05/17/2022 20:18:30 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 20:18:30 - INFO - __main__ - ['Plant']
05/17/2022 20:18:30 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:18:30 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:18:31 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:18:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:18:31 - INFO - __main__ - Printing 3 examples
05/17/2022 20:18:31 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 20:18:31 - INFO - __main__ - ['Plant']
05/17/2022 20:18:31 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 20:18:31 - INFO - __main__ - ['Plant']
05/17/2022 20:18:31 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 20:18:31 - INFO - __main__ - ['Plant']
05/17/2022 20:18:31 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:18:31 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:18:31 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:18:33 - INFO - __main__ - Global step 3000 Train loss 0.62 Classification-F1 0.38930880757379566 on epoch=214
05/17/2022 20:18:33 - INFO - __main__ - save last model!
05/17/2022 20:18:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 20:18:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 20:18:33 - INFO - __main__ - Printing 3 examples
05/17/2022 20:18:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 20:18:33 - INFO - __main__ - ['Animal']
05/17/2022 20:18:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 20:18:33 - INFO - __main__ - ['Animal']
05/17/2022 20:18:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 20:18:33 - INFO - __main__ - ['Village']
05/17/2022 20:18:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:18:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:18:37 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:18:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:18:37 - INFO - __main__ - Starting training!
05/17/2022 20:18:38 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 20:19:43 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/17/2022 20:19:43 - INFO - __main__ - Classification-F1 on test data: 0.1897
05/17/2022 20:19:43 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.5185460927442817, test_performance=0.18968790860185245
05/17/2022 20:19:43 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/17/2022 20:19:44 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:19:44 - INFO - __main__ - Printing 3 examples
05/17/2022 20:19:44 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/17/2022 20:19:44 - INFO - __main__ - ['Plant']
05/17/2022 20:19:44 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/17/2022 20:19:44 - INFO - __main__ - ['Plant']
05/17/2022 20:19:44 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/17/2022 20:19:44 - INFO - __main__ - ['Plant']
05/17/2022 20:19:44 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:19:45 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:19:45 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:19:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:19:45 - INFO - __main__ - Printing 3 examples
05/17/2022 20:19:45 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/17/2022 20:19:45 - INFO - __main__ - ['Plant']
05/17/2022 20:19:45 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/17/2022 20:19:45 - INFO - __main__ - ['Plant']
05/17/2022 20:19:45 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/17/2022 20:19:45 - INFO - __main__ - ['Plant']
05/17/2022 20:19:45 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:19:45 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:19:45 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:19:50 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:19:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:19:51 - INFO - __main__ - Starting training!
05/17/2022 20:19:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.48 on epoch=0
05/17/2022 20:19:54 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/17/2022 20:19:55 - INFO - __main__ - Step 30 Global step 30 Train loss 6.73 on epoch=2
05/17/2022 20:19:57 - INFO - __main__ - Step 40 Global step 40 Train loss 6.74 on epoch=2
05/17/2022 20:19:58 - INFO - __main__ - Step 50 Global step 50 Train loss 6.31 on epoch=3
05/17/2022 20:20:01 - INFO - __main__ - Global step 50 Train loss 6.88 Classification-F1 0.0 on epoch=3
05/17/2022 20:20:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 20:20:02 - INFO - __main__ - Step 60 Global step 60 Train loss 5.85 on epoch=4
05/17/2022 20:20:04 - INFO - __main__ - Step 70 Global step 70 Train loss 5.75 on epoch=4
05/17/2022 20:20:05 - INFO - __main__ - Step 80 Global step 80 Train loss 5.76 on epoch=5
05/17/2022 20:20:06 - INFO - __main__ - Step 90 Global step 90 Train loss 5.46 on epoch=6
05/17/2022 20:20:08 - INFO - __main__ - Step 100 Global step 100 Train loss 5.31 on epoch=7
05/17/2022 20:20:11 - INFO - __main__ - Global step 100 Train loss 5.63 Classification-F1 0.0 on epoch=7
05/17/2022 20:20:12 - INFO - __main__ - Step 110 Global step 110 Train loss 5.16 on epoch=7
05/17/2022 20:20:13 - INFO - __main__ - Step 120 Global step 120 Train loss 5.03 on epoch=8
05/17/2022 20:20:14 - INFO - __main__ - Step 130 Global step 130 Train loss 5.02 on epoch=9
05/17/2022 20:20:16 - INFO - __main__ - Step 140 Global step 140 Train loss 4.60 on epoch=9
05/17/2022 20:20:17 - INFO - __main__ - Step 150 Global step 150 Train loss 4.63 on epoch=10
05/17/2022 20:20:20 - INFO - __main__ - Global step 150 Train loss 4.89 Classification-F1 0.0 on epoch=10
05/17/2022 20:20:22 - INFO - __main__ - Step 160 Global step 160 Train loss 4.37 on epoch=11
05/17/2022 20:20:23 - INFO - __main__ - Step 170 Global step 170 Train loss 4.36 on epoch=12
05/17/2022 20:20:24 - INFO - __main__ - Step 180 Global step 180 Train loss 4.24 on epoch=12
05/17/2022 20:20:25 - INFO - __main__ - Step 190 Global step 190 Train loss 4.06 on epoch=13
05/17/2022 20:20:27 - INFO - __main__ - Step 200 Global step 200 Train loss 4.06 on epoch=14
05/17/2022 20:20:30 - INFO - __main__ - Global step 200 Train loss 4.22 Classification-F1 0.0 on epoch=14
05/17/2022 20:20:32 - INFO - __main__ - Step 210 Global step 210 Train loss 3.74 on epoch=14
05/17/2022 20:20:33 - INFO - __main__ - Step 220 Global step 220 Train loss 3.70 on epoch=15
05/17/2022 20:20:34 - INFO - __main__ - Step 230 Global step 230 Train loss 3.69 on epoch=16
05/17/2022 20:20:35 - INFO - __main__ - Step 240 Global step 240 Train loss 3.49 on epoch=17
05/17/2022 20:20:37 - INFO - __main__ - Step 250 Global step 250 Train loss 3.50 on epoch=17
05/17/2022 20:20:40 - INFO - __main__ - Global step 250 Train loss 3.62 Classification-F1 0.0 on epoch=17
05/17/2022 20:20:41 - INFO - __main__ - Step 260 Global step 260 Train loss 3.40 on epoch=18
05/17/2022 20:20:43 - INFO - __main__ - Step 270 Global step 270 Train loss 3.39 on epoch=19
05/17/2022 20:20:44 - INFO - __main__ - Step 280 Global step 280 Train loss 3.25 on epoch=19
05/17/2022 20:20:45 - INFO - __main__ - Step 290 Global step 290 Train loss 3.31 on epoch=20
05/17/2022 20:20:46 - INFO - __main__ - Step 300 Global step 300 Train loss 3.05 on epoch=21
05/17/2022 20:20:50 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.0060331825037707384 on epoch=21
05/17/2022 20:20:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0060331825037707384 on epoch=21, global_step=300
05/17/2022 20:20:51 - INFO - __main__ - Step 310 Global step 310 Train loss 3.19 on epoch=22
05/17/2022 20:20:52 - INFO - __main__ - Step 320 Global step 320 Train loss 3.02 on epoch=22
05/17/2022 20:20:54 - INFO - __main__ - Step 330 Global step 330 Train loss 3.07 on epoch=23
05/17/2022 20:20:55 - INFO - __main__ - Step 340 Global step 340 Train loss 3.02 on epoch=24
05/17/2022 20:20:56 - INFO - __main__ - Step 350 Global step 350 Train loss 2.86 on epoch=24
05/17/2022 20:20:59 - INFO - __main__ - Global step 350 Train loss 3.03 Classification-F1 0.006436781609195402 on epoch=24
05/17/2022 20:20:59 - INFO - __main__ - Saving model with best Classification-F1: 0.0060331825037707384 -> 0.006436781609195402 on epoch=24, global_step=350
05/17/2022 20:21:00 - INFO - __main__ - Step 360 Global step 360 Train loss 2.92 on epoch=25
05/17/2022 20:21:01 - INFO - __main__ - Step 370 Global step 370 Train loss 2.70 on epoch=26
05/17/2022 20:21:03 - INFO - __main__ - Step 380 Global step 380 Train loss 2.72 on epoch=27
05/17/2022 20:21:04 - INFO - __main__ - Step 390 Global step 390 Train loss 2.67 on epoch=27
05/17/2022 20:21:05 - INFO - __main__ - Step 400 Global step 400 Train loss 2.67 on epoch=28
05/17/2022 20:21:07 - INFO - __main__ - Global step 400 Train loss 2.74 Classification-F1 0.008641975308641974 on epoch=28
05/17/2022 20:21:07 - INFO - __main__ - Saving model with best Classification-F1: 0.006436781609195402 -> 0.008641975308641974 on epoch=28, global_step=400
05/17/2022 20:21:09 - INFO - __main__ - Step 410 Global step 410 Train loss 2.66 on epoch=29
05/17/2022 20:21:10 - INFO - __main__ - Step 420 Global step 420 Train loss 2.49 on epoch=29
05/17/2022 20:21:11 - INFO - __main__ - Step 430 Global step 430 Train loss 2.67 on epoch=30
05/17/2022 20:21:12 - INFO - __main__ - Step 440 Global step 440 Train loss 2.42 on epoch=31
05/17/2022 20:21:14 - INFO - __main__ - Step 450 Global step 450 Train loss 2.45 on epoch=32
05/17/2022 20:21:16 - INFO - __main__ - Global step 450 Train loss 2.54 Classification-F1 0.007943262411347516 on epoch=32
05/17/2022 20:21:17 - INFO - __main__ - Step 460 Global step 460 Train loss 2.49 on epoch=32
05/17/2022 20:21:18 - INFO - __main__ - Step 470 Global step 470 Train loss 2.46 on epoch=33
05/17/2022 20:21:20 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=34
05/17/2022 20:21:21 - INFO - __main__ - Step 490 Global step 490 Train loss 2.31 on epoch=34
05/17/2022 20:21:22 - INFO - __main__ - Step 500 Global step 500 Train loss 2.46 on epoch=35
05/17/2022 20:21:24 - INFO - __main__ - Global step 500 Train loss 2.41 Classification-F1 0.009523809523809523 on epoch=35
05/17/2022 20:21:24 - INFO - __main__ - Saving model with best Classification-F1: 0.008641975308641974 -> 0.009523809523809523 on epoch=35, global_step=500
05/17/2022 20:21:25 - INFO - __main__ - Step 510 Global step 510 Train loss 2.34 on epoch=36
05/17/2022 20:21:27 - INFO - __main__ - Step 520 Global step 520 Train loss 2.29 on epoch=37
05/17/2022 20:21:28 - INFO - __main__ - Step 530 Global step 530 Train loss 2.26 on epoch=37
05/17/2022 20:21:29 - INFO - __main__ - Step 540 Global step 540 Train loss 2.32 on epoch=38
05/17/2022 20:21:30 - INFO - __main__ - Step 550 Global step 550 Train loss 2.12 on epoch=39
05/17/2022 20:21:32 - INFO - __main__ - Global step 550 Train loss 2.27 Classification-F1 0.02779503105590062 on epoch=39
05/17/2022 20:21:32 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02779503105590062 on epoch=39, global_step=550
05/17/2022 20:21:34 - INFO - __main__ - Step 560 Global step 560 Train loss 2.04 on epoch=39
05/17/2022 20:21:35 - INFO - __main__ - Step 570 Global step 570 Train loss 2.14 on epoch=40
05/17/2022 20:21:36 - INFO - __main__ - Step 580 Global step 580 Train loss 2.02 on epoch=41
05/17/2022 20:21:37 - INFO - __main__ - Step 590 Global step 590 Train loss 2.22 on epoch=42
05/17/2022 20:21:39 - INFO - __main__ - Step 600 Global step 600 Train loss 2.00 on epoch=42
05/17/2022 20:21:41 - INFO - __main__ - Global step 600 Train loss 2.08 Classification-F1 0.035080050111869286 on epoch=42
05/17/2022 20:21:41 - INFO - __main__ - Saving model with best Classification-F1: 0.02779503105590062 -> 0.035080050111869286 on epoch=42, global_step=600
05/17/2022 20:21:42 - INFO - __main__ - Step 610 Global step 610 Train loss 2.07 on epoch=43
05/17/2022 20:21:43 - INFO - __main__ - Step 620 Global step 620 Train loss 1.99 on epoch=44
05/17/2022 20:21:44 - INFO - __main__ - Step 630 Global step 630 Train loss 1.94 on epoch=44
05/17/2022 20:21:46 - INFO - __main__ - Step 640 Global step 640 Train loss 2.00 on epoch=45
05/17/2022 20:21:47 - INFO - __main__ - Step 650 Global step 650 Train loss 1.87 on epoch=46
05/17/2022 20:21:49 - INFO - __main__ - Global step 650 Train loss 1.97 Classification-F1 0.03837252585411643 on epoch=46
05/17/2022 20:21:49 - INFO - __main__ - Saving model with best Classification-F1: 0.035080050111869286 -> 0.03837252585411643 on epoch=46, global_step=650
05/17/2022 20:21:51 - INFO - __main__ - Step 660 Global step 660 Train loss 1.86 on epoch=47
05/17/2022 20:21:52 - INFO - __main__ - Step 670 Global step 670 Train loss 1.88 on epoch=47
05/17/2022 20:21:53 - INFO - __main__ - Step 680 Global step 680 Train loss 1.82 on epoch=48
05/17/2022 20:21:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.73 on epoch=49
05/17/2022 20:21:56 - INFO - __main__ - Step 700 Global step 700 Train loss 1.86 on epoch=49
05/17/2022 20:21:58 - INFO - __main__ - Global step 700 Train loss 1.83 Classification-F1 0.03678996610621815 on epoch=49
05/17/2022 20:21:59 - INFO - __main__ - Step 710 Global step 710 Train loss 1.83 on epoch=50
05/17/2022 20:22:00 - INFO - __main__ - Step 720 Global step 720 Train loss 1.74 on epoch=51
05/17/2022 20:22:02 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=52
05/17/2022 20:22:03 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=52
05/17/2022 20:22:04 - INFO - __main__ - Step 750 Global step 750 Train loss 1.73 on epoch=53
05/17/2022 20:22:06 - INFO - __main__ - Global step 750 Train loss 1.77 Classification-F1 0.03291641551135222 on epoch=53
05/17/2022 20:22:07 - INFO - __main__ - Step 760 Global step 760 Train loss 1.66 on epoch=54
05/17/2022 20:22:09 - INFO - __main__ - Step 770 Global step 770 Train loss 1.62 on epoch=54
05/17/2022 20:22:10 - INFO - __main__ - Step 780 Global step 780 Train loss 1.77 on epoch=55
05/17/2022 20:22:11 - INFO - __main__ - Step 790 Global step 790 Train loss 1.58 on epoch=56
05/17/2022 20:22:12 - INFO - __main__ - Step 800 Global step 800 Train loss 1.67 on epoch=57
05/17/2022 20:22:14 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.04233794125186992 on epoch=57
05/17/2022 20:22:14 - INFO - __main__ - Saving model with best Classification-F1: 0.03837252585411643 -> 0.04233794125186992 on epoch=57, global_step=800
05/17/2022 20:22:16 - INFO - __main__ - Step 810 Global step 810 Train loss 1.67 on epoch=57
05/17/2022 20:22:17 - INFO - __main__ - Step 820 Global step 820 Train loss 1.54 on epoch=58
05/17/2022 20:22:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.64 on epoch=59
05/17/2022 20:22:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.50 on epoch=59
05/17/2022 20:22:21 - INFO - __main__ - Step 850 Global step 850 Train loss 1.65 on epoch=60
05/17/2022 20:22:23 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.03842807263859895 on epoch=60
05/17/2022 20:22:24 - INFO - __main__ - Step 860 Global step 860 Train loss 1.54 on epoch=61
05/17/2022 20:22:25 - INFO - __main__ - Step 870 Global step 870 Train loss 1.68 on epoch=62
05/17/2022 20:22:26 - INFO - __main__ - Step 880 Global step 880 Train loss 1.59 on epoch=62
05/17/2022 20:22:28 - INFO - __main__ - Step 890 Global step 890 Train loss 1.50 on epoch=63
05/17/2022 20:22:29 - INFO - __main__ - Step 900 Global step 900 Train loss 1.57 on epoch=64
05/17/2022 20:22:31 - INFO - __main__ - Global step 900 Train loss 1.57 Classification-F1 0.033387989342078296 on epoch=64
05/17/2022 20:22:32 - INFO - __main__ - Step 910 Global step 910 Train loss 1.40 on epoch=64
05/17/2022 20:22:33 - INFO - __main__ - Step 920 Global step 920 Train loss 1.53 on epoch=65
05/17/2022 20:22:35 - INFO - __main__ - Step 930 Global step 930 Train loss 1.51 on epoch=66
05/17/2022 20:22:36 - INFO - __main__ - Step 940 Global step 940 Train loss 1.41 on epoch=67
05/17/2022 20:22:37 - INFO - __main__ - Step 950 Global step 950 Train loss 1.45 on epoch=67
05/17/2022 20:22:40 - INFO - __main__ - Global step 950 Train loss 1.46 Classification-F1 0.063718733107278 on epoch=67
05/17/2022 20:22:40 - INFO - __main__ - Saving model with best Classification-F1: 0.04233794125186992 -> 0.063718733107278 on epoch=67, global_step=950
05/17/2022 20:22:41 - INFO - __main__ - Step 960 Global step 960 Train loss 1.41 on epoch=68
05/17/2022 20:22:42 - INFO - __main__ - Step 970 Global step 970 Train loss 1.50 on epoch=69
05/17/2022 20:22:43 - INFO - __main__ - Step 980 Global step 980 Train loss 1.53 on epoch=69
05/17/2022 20:22:45 - INFO - __main__ - Step 990 Global step 990 Train loss 1.50 on epoch=70
05/17/2022 20:22:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.47 on epoch=71
05/17/2022 20:22:48 - INFO - __main__ - Global step 1000 Train loss 1.48 Classification-F1 0.07074884484667965 on epoch=71
05/17/2022 20:22:48 - INFO - __main__ - Saving model with best Classification-F1: 0.063718733107278 -> 0.07074884484667965 on epoch=71, global_step=1000
05/17/2022 20:22:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=72
05/17/2022 20:22:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.49 on epoch=72
05/17/2022 20:22:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.42 on epoch=73
05/17/2022 20:22:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.43 on epoch=74
05/17/2022 20:22:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.47 on epoch=74
05/17/2022 20:22:57 - INFO - __main__ - Global step 1050 Train loss 1.44 Classification-F1 0.033074113127965654 on epoch=74
05/17/2022 20:22:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.47 on epoch=75
05/17/2022 20:22:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.41 on epoch=76
05/17/2022 20:23:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.37 on epoch=77
05/17/2022 20:23:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.45 on epoch=77
05/17/2022 20:23:03 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.38 on epoch=78
05/17/2022 20:23:06 - INFO - __main__ - Global step 1100 Train loss 1.42 Classification-F1 0.035624625904719896 on epoch=78
05/17/2022 20:23:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.38 on epoch=79
05/17/2022 20:23:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.36 on epoch=79
05/17/2022 20:23:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.39 on epoch=80
05/17/2022 20:23:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.37 on epoch=81
05/17/2022 20:23:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.37 on epoch=82
05/17/2022 20:23:15 - INFO - __main__ - Global step 1150 Train loss 1.37 Classification-F1 0.05253305398719269 on epoch=82
05/17/2022 20:23:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.39 on epoch=82
05/17/2022 20:23:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.30 on epoch=83
05/17/2022 20:23:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=84
05/17/2022 20:23:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.38 on epoch=84
05/17/2022 20:23:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=85
05/17/2022 20:23:24 - INFO - __main__ - Global step 1200 Train loss 1.36 Classification-F1 0.0521799628942486 on epoch=85
05/17/2022 20:23:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.31 on epoch=86
05/17/2022 20:23:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.31 on epoch=87
05/17/2022 20:23:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.46 on epoch=87
05/17/2022 20:23:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.39 on epoch=88
05/17/2022 20:23:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.40 on epoch=89
05/17/2022 20:23:32 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.07507378794972779 on epoch=89
05/17/2022 20:23:32 - INFO - __main__ - Saving model with best Classification-F1: 0.07074884484667965 -> 0.07507378794972779 on epoch=89, global_step=1250
05/17/2022 20:23:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.21 on epoch=89
05/17/2022 20:23:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.30 on epoch=90
05/17/2022 20:23:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.38 on epoch=91
05/17/2022 20:23:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=92
05/17/2022 20:23:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.42 on epoch=92
05/17/2022 20:23:41 - INFO - __main__ - Global step 1300 Train loss 1.33 Classification-F1 0.07700710595447437 on epoch=92
05/17/2022 20:23:41 - INFO - __main__ - Saving model with best Classification-F1: 0.07507378794972779 -> 0.07700710595447437 on epoch=92, global_step=1300
05/17/2022 20:23:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.30 on epoch=93
05/17/2022 20:23:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=94
05/17/2022 20:23:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.29 on epoch=94
05/17/2022 20:23:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.41 on epoch=95
05/17/2022 20:23:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=96
05/17/2022 20:23:50 - INFO - __main__ - Global step 1350 Train loss 1.31 Classification-F1 0.1058599360086783 on epoch=96
05/17/2022 20:23:50 - INFO - __main__ - Saving model with best Classification-F1: 0.07700710595447437 -> 0.1058599360086783 on epoch=96, global_step=1350
05/17/2022 20:23:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.32 on epoch=97
05/17/2022 20:23:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.39 on epoch=97
05/17/2022 20:23:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.23 on epoch=98
05/17/2022 20:23:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.32 on epoch=99
05/17/2022 20:23:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.34 on epoch=99
05/17/2022 20:23:59 - INFO - __main__ - Global step 1400 Train loss 1.32 Classification-F1 0.07324306353284367 on epoch=99
05/17/2022 20:24:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.30 on epoch=100
05/17/2022 20:24:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=101
05/17/2022 20:24:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.23 on epoch=102
05/17/2022 20:24:04 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.31 on epoch=102
05/17/2022 20:24:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.16 on epoch=103
05/17/2022 20:24:08 - INFO - __main__ - Global step 1450 Train loss 1.25 Classification-F1 0.09630235705859218 on epoch=103
05/17/2022 20:24:09 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.24 on epoch=104
05/17/2022 20:24:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.32 on epoch=104
05/17/2022 20:24:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.31 on epoch=105
05/17/2022 20:24:13 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.27 on epoch=106
05/17/2022 20:24:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=107
05/17/2022 20:24:17 - INFO - __main__ - Global step 1500 Train loss 1.27 Classification-F1 0.08698789133571741 on epoch=107
05/17/2022 20:24:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.37 on epoch=107
05/17/2022 20:24:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=108
05/17/2022 20:24:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/17/2022 20:24:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=109
05/17/2022 20:24:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.26 on epoch=110
05/17/2022 20:24:26 - INFO - __main__ - Global step 1550 Train loss 1.27 Classification-F1 0.09281412018638295 on epoch=110
05/17/2022 20:24:27 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.32 on epoch=111
05/17/2022 20:24:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=112
05/17/2022 20:24:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=112
05/17/2022 20:24:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=113
05/17/2022 20:24:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.22 on epoch=114
05/17/2022 20:24:35 - INFO - __main__ - Global step 1600 Train loss 1.24 Classification-F1 0.1201514232935497 on epoch=114
05/17/2022 20:24:35 - INFO - __main__ - Saving model with best Classification-F1: 0.1058599360086783 -> 0.1201514232935497 on epoch=114, global_step=1600
05/17/2022 20:24:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.23 on epoch=114
05/17/2022 20:24:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.29 on epoch=115
05/17/2022 20:24:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.19 on epoch=116
05/17/2022 20:24:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.28 on epoch=117
05/17/2022 20:24:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.21 on epoch=117
05/17/2022 20:24:44 - INFO - __main__ - Global step 1650 Train loss 1.24 Classification-F1 0.11154888850289464 on epoch=117
05/17/2022 20:24:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.22 on epoch=118
05/17/2022 20:24:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.16 on epoch=119
05/17/2022 20:24:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.31 on epoch=119
05/17/2022 20:24:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.32 on epoch=120
05/17/2022 20:24:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.22 on epoch=121
05/17/2022 20:24:53 - INFO - __main__ - Global step 1700 Train loss 1.25 Classification-F1 0.15071644432747724 on epoch=121
05/17/2022 20:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1201514232935497 -> 0.15071644432747724 on epoch=121, global_step=1700
05/17/2022 20:24:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=122
05/17/2022 20:24:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.23 on epoch=122
05/17/2022 20:24:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/17/2022 20:24:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.22 on epoch=124
05/17/2022 20:24:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.21 on epoch=124
05/17/2022 20:25:02 - INFO - __main__ - Global step 1750 Train loss 1.21 Classification-F1 0.16705088219405015 on epoch=124
05/17/2022 20:25:02 - INFO - __main__ - Saving model with best Classification-F1: 0.15071644432747724 -> 0.16705088219405015 on epoch=124, global_step=1750
05/17/2022 20:25:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.29 on epoch=125
05/17/2022 20:25:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.20 on epoch=126
05/17/2022 20:25:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.20 on epoch=127
05/17/2022 20:25:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.30 on epoch=127
05/17/2022 20:25:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.23 on epoch=128
05/17/2022 20:25:12 - INFO - __main__ - Global step 1800 Train loss 1.24 Classification-F1 0.17544664640283036 on epoch=128
05/17/2022 20:25:12 - INFO - __main__ - Saving model with best Classification-F1: 0.16705088219405015 -> 0.17544664640283036 on epoch=128, global_step=1800
05/17/2022 20:25:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.21 on epoch=129
05/17/2022 20:25:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.25 on epoch=129
05/17/2022 20:25:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.32 on epoch=130
05/17/2022 20:25:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/17/2022 20:25:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=132
05/17/2022 20:25:22 - INFO - __main__ - Global step 1850 Train loss 1.23 Classification-F1 0.22221992773005234 on epoch=132
05/17/2022 20:25:22 - INFO - __main__ - Saving model with best Classification-F1: 0.17544664640283036 -> 0.22221992773005234 on epoch=132, global_step=1850
05/17/2022 20:25:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.19 on epoch=132
05/17/2022 20:25:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=133
05/17/2022 20:25:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.27 on epoch=134
05/17/2022 20:25:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=134
05/17/2022 20:25:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.21 on epoch=135
05/17/2022 20:25:31 - INFO - __main__ - Global step 1900 Train loss 1.19 Classification-F1 0.18159169470814723 on epoch=135
05/17/2022 20:25:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.16 on epoch=136
05/17/2022 20:25:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.11 on epoch=137
05/17/2022 20:25:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.18 on epoch=137
05/17/2022 20:25:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.17 on epoch=138
05/17/2022 20:25:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.21 on epoch=139
05/17/2022 20:25:41 - INFO - __main__ - Global step 1950 Train loss 1.17 Classification-F1 0.2506412634984063 on epoch=139
05/17/2022 20:25:41 - INFO - __main__ - Saving model with best Classification-F1: 0.22221992773005234 -> 0.2506412634984063 on epoch=139, global_step=1950
05/17/2022 20:25:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.16 on epoch=139
05/17/2022 20:25:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.17 on epoch=140
05/17/2022 20:25:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.13 on epoch=141
05/17/2022 20:25:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.22 on epoch=142
05/17/2022 20:25:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.21 on epoch=142
05/17/2022 20:25:50 - INFO - __main__ - Global step 2000 Train loss 1.18 Classification-F1 0.30080052368650856 on epoch=142
05/17/2022 20:25:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2506412634984063 -> 0.30080052368650856 on epoch=142, global_step=2000
05/17/2022 20:25:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.10 on epoch=143
05/17/2022 20:25:53 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.16 on epoch=144
05/17/2022 20:25:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.10 on epoch=144
05/17/2022 20:25:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.10 on epoch=145
05/17/2022 20:25:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.13 on epoch=146
05/17/2022 20:26:00 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.32803541285440746 on epoch=146
05/17/2022 20:26:00 - INFO - __main__ - Saving model with best Classification-F1: 0.30080052368650856 -> 0.32803541285440746 on epoch=146, global_step=2050
05/17/2022 20:26:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=147
05/17/2022 20:26:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=147
05/17/2022 20:26:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.09 on epoch=148
05/17/2022 20:26:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=149
05/17/2022 20:26:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/17/2022 20:26:10 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.30424961030994363 on epoch=149
05/17/2022 20:26:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.17 on epoch=150
05/17/2022 20:26:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.14 on epoch=151
05/17/2022 20:26:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=152
05/17/2022 20:26:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.04 on epoch=152
05/17/2022 20:26:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.07 on epoch=153
05/17/2022 20:26:19 - INFO - __main__ - Global step 2150 Train loss 1.11 Classification-F1 0.3824772151460708 on epoch=153
05/17/2022 20:26:19 - INFO - __main__ - Saving model with best Classification-F1: 0.32803541285440746 -> 0.3824772151460708 on epoch=153, global_step=2150
05/17/2022 20:26:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.08 on epoch=154
05/17/2022 20:26:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=154
05/17/2022 20:26:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.04 on epoch=155
05/17/2022 20:26:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.06 on epoch=156
05/17/2022 20:26:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=157
05/17/2022 20:26:29 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.3585204599524737 on epoch=157
05/17/2022 20:26:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.18 on epoch=157
05/17/2022 20:26:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=158
05/17/2022 20:26:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.02 on epoch=159
05/17/2022 20:26:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.11 on epoch=159
05/17/2022 20:26:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.07 on epoch=160
05/17/2022 20:26:39 - INFO - __main__ - Global step 2250 Train loss 1.09 Classification-F1 0.37779875333120116 on epoch=160
05/17/2022 20:26:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=161
05/17/2022 20:26:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.08 on epoch=162
05/17/2022 20:26:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=162
05/17/2022 20:26:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.09 on epoch=163
05/17/2022 20:26:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.02 on epoch=164
05/17/2022 20:26:48 - INFO - __main__ - Global step 2300 Train loss 1.07 Classification-F1 0.35963522992311886 on epoch=164
05/17/2022 20:26:50 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.98 on epoch=164
05/17/2022 20:26:51 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=165
05/17/2022 20:26:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.01 on epoch=166
05/17/2022 20:26:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.99 on epoch=167
05/17/2022 20:26:55 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.94 on epoch=167
05/17/2022 20:26:58 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.38558155284969187 on epoch=167
05/17/2022 20:26:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3824772151460708 -> 0.38558155284969187 on epoch=167, global_step=2350
05/17/2022 20:26:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.99 on epoch=168
05/17/2022 20:27:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.05 on epoch=169
05/17/2022 20:27:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.07 on epoch=169
05/17/2022 20:27:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=170
05/17/2022 20:27:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.95 on epoch=171
05/17/2022 20:27:08 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.35135670283378395 on epoch=171
05/17/2022 20:27:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=172
05/17/2022 20:27:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.07 on epoch=172
05/17/2022 20:27:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=173
05/17/2022 20:27:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=174
05/17/2022 20:27:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=174
05/17/2022 20:27:18 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.3938095700582353 on epoch=174
05/17/2022 20:27:18 - INFO - __main__ - Saving model with best Classification-F1: 0.38558155284969187 -> 0.3938095700582353 on epoch=174, global_step=2450
05/17/2022 20:27:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.05 on epoch=175
05/17/2022 20:27:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=176
05/17/2022 20:27:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=177
05/17/2022 20:27:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.04 on epoch=177
05/17/2022 20:27:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.96 on epoch=178
05/17/2022 20:27:27 - INFO - __main__ - Global step 2500 Train loss 1.01 Classification-F1 0.41167843562596523 on epoch=178
05/17/2022 20:27:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3938095700582353 -> 0.41167843562596523 on epoch=178, global_step=2500
05/17/2022 20:27:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.95 on epoch=179
05/17/2022 20:27:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=179
05/17/2022 20:27:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=180
05/17/2022 20:27:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.93 on epoch=181
05/17/2022 20:27:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=182
05/17/2022 20:27:37 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.4565433747000566 on epoch=182
05/17/2022 20:27:37 - INFO - __main__ - Saving model with best Classification-F1: 0.41167843562596523 -> 0.4565433747000566 on epoch=182, global_step=2550
05/17/2022 20:27:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=182
05/17/2022 20:27:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.99 on epoch=183
05/17/2022 20:27:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.97 on epoch=184
05/17/2022 20:27:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.04 on epoch=184
05/17/2022 20:27:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.05 on epoch=185
05/17/2022 20:27:47 - INFO - __main__ - Global step 2600 Train loss 1.00 Classification-F1 0.44056165949431725 on epoch=185
05/17/2022 20:27:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.92 on epoch=186
05/17/2022 20:27:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.97 on epoch=187
05/17/2022 20:27:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.00 on epoch=187
05/17/2022 20:27:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.97 on epoch=188
05/17/2022 20:27:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.91 on epoch=189
05/17/2022 20:27:57 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.4019290226750264 on epoch=189
05/17/2022 20:27:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.95 on epoch=189
05/17/2022 20:27:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.98 on epoch=190
05/17/2022 20:28:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=191
05/17/2022 20:28:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.03 on epoch=192
05/17/2022 20:28:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=192
05/17/2022 20:28:07 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.4722289573244759 on epoch=192
05/17/2022 20:28:07 - INFO - __main__ - Saving model with best Classification-F1: 0.4565433747000566 -> 0.4722289573244759 on epoch=192, global_step=2700
05/17/2022 20:28:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.83 on epoch=193
05/17/2022 20:28:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=194
05/17/2022 20:28:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.89 on epoch=194
05/17/2022 20:28:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=195
05/17/2022 20:28:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.95 on epoch=196
05/17/2022 20:28:16 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.38454704201844114 on epoch=196
05/17/2022 20:28:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=197
05/17/2022 20:28:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.94 on epoch=197
05/17/2022 20:28:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=198
05/17/2022 20:28:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=199
05/17/2022 20:28:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=199
05/17/2022 20:28:26 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.399421405594835 on epoch=199
05/17/2022 20:28:27 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/17/2022 20:28:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=201
05/17/2022 20:28:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=202
05/17/2022 20:28:31 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=202
05/17/2022 20:28:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=203
05/17/2022 20:28:36 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.3164567177078194 on epoch=203
05/17/2022 20:28:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.78 on epoch=204
05/17/2022 20:28:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.91 on epoch=204
05/17/2022 20:28:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.03 on epoch=205
05/17/2022 20:28:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.89 on epoch=206
05/17/2022 20:28:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.83 on epoch=207
05/17/2022 20:28:46 - INFO - __main__ - Global step 2900 Train loss 0.89 Classification-F1 0.43546896084126263 on epoch=207
05/17/2022 20:28:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.99 on epoch=207
05/17/2022 20:28:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.87 on epoch=208
05/17/2022 20:28:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.86 on epoch=209
05/17/2022 20:28:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.91 on epoch=209
05/17/2022 20:28:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.93 on epoch=210
05/17/2022 20:28:55 - INFO - __main__ - Global step 2950 Train loss 0.91 Classification-F1 0.37539250658524503 on epoch=210
05/17/2022 20:28:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.83 on epoch=211
05/17/2022 20:28:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.83 on epoch=212
05/17/2022 20:28:59 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=212
05/17/2022 20:29:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.81 on epoch=213
05/17/2022 20:29:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.89 on epoch=214
05/17/2022 20:29:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:29:03 - INFO - __main__ - Printing 3 examples
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:29:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:29:03 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:29:03 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:29:03 - INFO - __main__ - Printing 3 examples
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:29:03 - INFO - __main__ - ['Company']
05/17/2022 20:29:03 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:29:03 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:29:04 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:29:05 - INFO - __main__ - Global step 3000 Train loss 0.86 Classification-F1 0.35547057046280073 on epoch=214
05/17/2022 20:29:05 - INFO - __main__ - save last model!
05/17/2022 20:29:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 20:29:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 20:29:05 - INFO - __main__ - Printing 3 examples
05/17/2022 20:29:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 20:29:05 - INFO - __main__ - ['Animal']
05/17/2022 20:29:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 20:29:05 - INFO - __main__ - ['Animal']
05/17/2022 20:29:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 20:29:05 - INFO - __main__ - ['Village']
05/17/2022 20:29:05 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:29:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:29:09 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:29:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:29:09 - INFO - __main__ - Starting training!
05/17/2022 20:29:10 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 20:30:05 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/17/2022 20:30:06 - INFO - __main__ - Classification-F1 on test data: 0.1797
05/17/2022 20:30:06 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.4722289573244759, test_performance=0.17965025799953324
05/17/2022 20:30:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/17/2022 20:30:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:30:07 - INFO - __main__ - Printing 3 examples
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:30:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:30:07 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:30:07 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:30:07 - INFO - __main__ - Printing 3 examples
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:30:07 - INFO - __main__ - ['Company']
05/17/2022 20:30:07 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:30:07 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:30:07 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:30:13 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:30:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:30:13 - INFO - __main__ - Starting training!
05/17/2022 20:30:14 - INFO - __main__ - Step 10 Global step 10 Train loss 7.50 on epoch=0
05/17/2022 20:30:16 - INFO - __main__ - Step 20 Global step 20 Train loss 6.99 on epoch=1
05/17/2022 20:30:17 - INFO - __main__ - Step 30 Global step 30 Train loss 6.10 on epoch=2
05/17/2022 20:30:18 - INFO - __main__ - Step 40 Global step 40 Train loss 5.38 on epoch=2
05/17/2022 20:30:19 - INFO - __main__ - Step 50 Global step 50 Train loss 5.03 on epoch=3
05/17/2022 20:30:23 - INFO - __main__ - Global step 50 Train loss 6.20 Classification-F1 0.0 on epoch=3
05/17/2022 20:30:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 20:30:25 - INFO - __main__ - Step 60 Global step 60 Train loss 4.66 on epoch=4
05/17/2022 20:30:26 - INFO - __main__ - Step 70 Global step 70 Train loss 4.39 on epoch=4
05/17/2022 20:30:27 - INFO - __main__ - Step 80 Global step 80 Train loss 3.91 on epoch=5
05/17/2022 20:30:28 - INFO - __main__ - Step 90 Global step 90 Train loss 3.88 on epoch=6
05/17/2022 20:30:30 - INFO - __main__ - Step 100 Global step 100 Train loss 3.61 on epoch=7
05/17/2022 20:30:32 - INFO - __main__ - Global step 100 Train loss 4.09 Classification-F1 0.0 on epoch=7
05/17/2022 20:30:33 - INFO - __main__ - Step 110 Global step 110 Train loss 3.43 on epoch=7
05/17/2022 20:30:35 - INFO - __main__ - Step 120 Global step 120 Train loss 3.22 on epoch=8
05/17/2022 20:30:36 - INFO - __main__ - Step 130 Global step 130 Train loss 3.01 on epoch=9
05/17/2022 20:30:37 - INFO - __main__ - Step 140 Global step 140 Train loss 3.06 on epoch=9
05/17/2022 20:30:38 - INFO - __main__ - Step 150 Global step 150 Train loss 2.59 on epoch=10
05/17/2022 20:30:41 - INFO - __main__ - Global step 150 Train loss 3.06 Classification-F1 0.0077972709551656924 on epoch=10
05/17/2022 20:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0077972709551656924 on epoch=10, global_step=150
05/17/2022 20:30:42 - INFO - __main__ - Step 160 Global step 160 Train loss 2.77 on epoch=11
05/17/2022 20:30:43 - INFO - __main__ - Step 170 Global step 170 Train loss 2.57 on epoch=12
05/17/2022 20:30:45 - INFO - __main__ - Step 180 Global step 180 Train loss 2.37 on epoch=12
05/17/2022 20:30:46 - INFO - __main__ - Step 190 Global step 190 Train loss 2.36 on epoch=13
05/17/2022 20:30:47 - INFO - __main__ - Step 200 Global step 200 Train loss 2.32 on epoch=14
05/17/2022 20:30:50 - INFO - __main__ - Global step 200 Train loss 2.48 Classification-F1 0.009078014184397163 on epoch=14
05/17/2022 20:30:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0077972709551656924 -> 0.009078014184397163 on epoch=14, global_step=200
05/17/2022 20:30:51 - INFO - __main__ - Step 210 Global step 210 Train loss 2.30 on epoch=14
05/17/2022 20:30:52 - INFO - __main__ - Step 220 Global step 220 Train loss 2.00 on epoch=15
05/17/2022 20:30:54 - INFO - __main__ - Step 230 Global step 230 Train loss 2.12 on epoch=16
05/17/2022 20:30:55 - INFO - __main__ - Step 240 Global step 240 Train loss 2.02 on epoch=17
05/17/2022 20:30:56 - INFO - __main__ - Step 250 Global step 250 Train loss 1.81 on epoch=17
05/17/2022 20:30:58 - INFO - __main__ - Global step 250 Train loss 2.05 Classification-F1 0.0308350150294238 on epoch=17
05/17/2022 20:30:58 - INFO - __main__ - Saving model with best Classification-F1: 0.009078014184397163 -> 0.0308350150294238 on epoch=17, global_step=250
05/17/2022 20:30:59 - INFO - __main__ - Step 260 Global step 260 Train loss 1.90 on epoch=18
05/17/2022 20:31:01 - INFO - __main__ - Step 270 Global step 270 Train loss 1.93 on epoch=19
05/17/2022 20:31:02 - INFO - __main__ - Step 280 Global step 280 Train loss 1.76 on epoch=19
05/17/2022 20:31:03 - INFO - __main__ - Step 290 Global step 290 Train loss 1.77 on epoch=20
05/17/2022 20:31:04 - INFO - __main__ - Step 300 Global step 300 Train loss 1.78 on epoch=21
05/17/2022 20:31:06 - INFO - __main__ - Global step 300 Train loss 1.83 Classification-F1 0.03898509030477863 on epoch=21
05/17/2022 20:31:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0308350150294238 -> 0.03898509030477863 on epoch=21, global_step=300
05/17/2022 20:31:08 - INFO - __main__ - Step 310 Global step 310 Train loss 1.78 on epoch=22
05/17/2022 20:31:09 - INFO - __main__ - Step 320 Global step 320 Train loss 1.61 on epoch=22
05/17/2022 20:31:10 - INFO - __main__ - Step 330 Global step 330 Train loss 1.61 on epoch=23
05/17/2022 20:31:11 - INFO - __main__ - Step 340 Global step 340 Train loss 1.60 on epoch=24
05/17/2022 20:31:13 - INFO - __main__ - Step 350 Global step 350 Train loss 1.64 on epoch=24
05/17/2022 20:31:15 - INFO - __main__ - Global step 350 Train loss 1.65 Classification-F1 0.0630286147477859 on epoch=24
05/17/2022 20:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.03898509030477863 -> 0.0630286147477859 on epoch=24, global_step=350
05/17/2022 20:31:16 - INFO - __main__ - Step 360 Global step 360 Train loss 1.48 on epoch=25
05/17/2022 20:31:17 - INFO - __main__ - Step 370 Global step 370 Train loss 1.59 on epoch=26
05/17/2022 20:31:19 - INFO - __main__ - Step 380 Global step 380 Train loss 1.53 on epoch=27
05/17/2022 20:31:20 - INFO - __main__ - Step 390 Global step 390 Train loss 1.34 on epoch=27
05/17/2022 20:31:21 - INFO - __main__ - Step 400 Global step 400 Train loss 1.43 on epoch=28
05/17/2022 20:31:23 - INFO - __main__ - Global step 400 Train loss 1.47 Classification-F1 0.03799379898296264 on epoch=28
05/17/2022 20:31:25 - INFO - __main__ - Step 410 Global step 410 Train loss 1.43 on epoch=29
05/17/2022 20:31:26 - INFO - __main__ - Step 420 Global step 420 Train loss 1.45 on epoch=29
05/17/2022 20:31:27 - INFO - __main__ - Step 430 Global step 430 Train loss 1.40 on epoch=30
05/17/2022 20:31:28 - INFO - __main__ - Step 440 Global step 440 Train loss 1.52 on epoch=31
05/17/2022 20:31:30 - INFO - __main__ - Step 450 Global step 450 Train loss 1.39 on epoch=32
05/17/2022 20:31:32 - INFO - __main__ - Global step 450 Train loss 1.44 Classification-F1 0.06022126113059998 on epoch=32
05/17/2022 20:31:34 - INFO - __main__ - Step 460 Global step 460 Train loss 1.18 on epoch=32
05/17/2022 20:31:35 - INFO - __main__ - Step 470 Global step 470 Train loss 1.29 on epoch=33
05/17/2022 20:31:36 - INFO - __main__ - Step 480 Global step 480 Train loss 1.35 on epoch=34
05/17/2022 20:31:37 - INFO - __main__ - Step 490 Global step 490 Train loss 1.23 on epoch=34
05/17/2022 20:31:39 - INFO - __main__ - Step 500 Global step 500 Train loss 1.26 on epoch=35
05/17/2022 20:31:41 - INFO - __main__ - Global step 500 Train loss 1.26 Classification-F1 0.05104708550086702 on epoch=35
05/17/2022 20:31:42 - INFO - __main__ - Step 510 Global step 510 Train loss 1.29 on epoch=36
05/17/2022 20:31:43 - INFO - __main__ - Step 520 Global step 520 Train loss 1.33 on epoch=37
05/17/2022 20:31:45 - INFO - __main__ - Step 530 Global step 530 Train loss 1.22 on epoch=37
05/17/2022 20:31:46 - INFO - __main__ - Step 540 Global step 540 Train loss 1.25 on epoch=38
05/17/2022 20:31:47 - INFO - __main__ - Step 550 Global step 550 Train loss 1.32 on epoch=39
05/17/2022 20:31:50 - INFO - __main__ - Global step 550 Train loss 1.28 Classification-F1 0.13310542296631808 on epoch=39
05/17/2022 20:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0630286147477859 -> 0.13310542296631808 on epoch=39, global_step=550
05/17/2022 20:31:51 - INFO - __main__ - Step 560 Global step 560 Train loss 1.31 on epoch=39
05/17/2022 20:31:53 - INFO - __main__ - Step 570 Global step 570 Train loss 1.25 on epoch=40
05/17/2022 20:31:54 - INFO - __main__ - Step 580 Global step 580 Train loss 1.35 on epoch=41
05/17/2022 20:31:55 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/17/2022 20:31:57 - INFO - __main__ - Step 600 Global step 600 Train loss 1.10 on epoch=42
05/17/2022 20:31:59 - INFO - __main__ - Global step 600 Train loss 1.25 Classification-F1 0.14538533379578394 on epoch=42
05/17/2022 20:31:59 - INFO - __main__ - Saving model with best Classification-F1: 0.13310542296631808 -> 0.14538533379578394 on epoch=42, global_step=600
05/17/2022 20:32:01 - INFO - __main__ - Step 610 Global step 610 Train loss 1.27 on epoch=43
05/17/2022 20:32:02 - INFO - __main__ - Step 620 Global step 620 Train loss 1.36 on epoch=44
05/17/2022 20:32:03 - INFO - __main__ - Step 630 Global step 630 Train loss 1.20 on epoch=44
05/17/2022 20:32:05 - INFO - __main__ - Step 640 Global step 640 Train loss 1.16 on epoch=45
05/17/2022 20:32:06 - INFO - __main__ - Step 650 Global step 650 Train loss 1.20 on epoch=46
05/17/2022 20:32:09 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.13266304996445563 on epoch=46
05/17/2022 20:32:10 - INFO - __main__ - Step 660 Global step 660 Train loss 1.24 on epoch=47
05/17/2022 20:32:12 - INFO - __main__ - Step 670 Global step 670 Train loss 1.09 on epoch=47
05/17/2022 20:32:13 - INFO - __main__ - Step 680 Global step 680 Train loss 1.26 on epoch=48
05/17/2022 20:32:14 - INFO - __main__ - Step 690 Global step 690 Train loss 1.18 on epoch=49
05/17/2022 20:32:15 - INFO - __main__ - Step 700 Global step 700 Train loss 1.11 on epoch=49
05/17/2022 20:32:18 - INFO - __main__ - Global step 700 Train loss 1.18 Classification-F1 0.1782529250443686 on epoch=49
05/17/2022 20:32:18 - INFO - __main__ - Saving model with best Classification-F1: 0.14538533379578394 -> 0.1782529250443686 on epoch=49, global_step=700
05/17/2022 20:32:20 - INFO - __main__ - Step 710 Global step 710 Train loss 1.11 on epoch=50
05/17/2022 20:32:21 - INFO - __main__ - Step 720 Global step 720 Train loss 1.24 on epoch=51
05/17/2022 20:32:22 - INFO - __main__ - Step 730 Global step 730 Train loss 1.18 on epoch=52
05/17/2022 20:32:23 - INFO - __main__ - Step 740 Global step 740 Train loss 1.10 on epoch=52
05/17/2022 20:32:25 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/17/2022 20:32:28 - INFO - __main__ - Global step 750 Train loss 1.16 Classification-F1 0.21646305422840342 on epoch=53
05/17/2022 20:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.1782529250443686 -> 0.21646305422840342 on epoch=53, global_step=750
05/17/2022 20:32:29 - INFO - __main__ - Step 760 Global step 760 Train loss 1.20 on epoch=54
05/17/2022 20:32:31 - INFO - __main__ - Step 770 Global step 770 Train loss 1.23 on epoch=54
05/17/2022 20:32:32 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=55
05/17/2022 20:32:33 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=56
05/17/2022 20:32:34 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/17/2022 20:32:37 - INFO - __main__ - Global step 800 Train loss 1.20 Classification-F1 0.3100162140274763 on epoch=57
05/17/2022 20:32:37 - INFO - __main__ - Saving model with best Classification-F1: 0.21646305422840342 -> 0.3100162140274763 on epoch=57, global_step=800
05/17/2022 20:32:39 - INFO - __main__ - Step 810 Global step 810 Train loss 1.06 on epoch=57
05/17/2022 20:32:40 - INFO - __main__ - Step 820 Global step 820 Train loss 1.09 on epoch=58
05/17/2022 20:32:41 - INFO - __main__ - Step 830 Global step 830 Train loss 1.10 on epoch=59
05/17/2022 20:32:42 - INFO - __main__ - Step 840 Global step 840 Train loss 1.21 on epoch=59
05/17/2022 20:32:44 - INFO - __main__ - Step 850 Global step 850 Train loss 1.07 on epoch=60
05/17/2022 20:32:47 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.33943086003792666 on epoch=60
05/17/2022 20:32:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3100162140274763 -> 0.33943086003792666 on epoch=60, global_step=850
05/17/2022 20:32:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.16 on epoch=61
05/17/2022 20:32:50 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=62
05/17/2022 20:32:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.99 on epoch=62
05/17/2022 20:32:52 - INFO - __main__ - Step 890 Global step 890 Train loss 1.11 on epoch=63
05/17/2022 20:32:53 - INFO - __main__ - Step 900 Global step 900 Train loss 1.14 on epoch=64
05/17/2022 20:32:57 - INFO - __main__ - Global step 900 Train loss 1.11 Classification-F1 0.3251227380333354 on epoch=64
05/17/2022 20:32:58 - INFO - __main__ - Step 910 Global step 910 Train loss 1.15 on epoch=64
05/17/2022 20:32:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.98 on epoch=65
05/17/2022 20:33:00 - INFO - __main__ - Step 930 Global step 930 Train loss 1.08 on epoch=66
05/17/2022 20:33:02 - INFO - __main__ - Step 940 Global step 940 Train loss 1.08 on epoch=67
05/17/2022 20:33:03 - INFO - __main__ - Step 950 Global step 950 Train loss 1.05 on epoch=67
05/17/2022 20:33:06 - INFO - __main__ - Global step 950 Train loss 1.07 Classification-F1 0.3592671278106849 on epoch=67
05/17/2022 20:33:06 - INFO - __main__ - Saving model with best Classification-F1: 0.33943086003792666 -> 0.3592671278106849 on epoch=67, global_step=950
05/17/2022 20:33:07 - INFO - __main__ - Step 960 Global step 960 Train loss 1.12 on epoch=68
05/17/2022 20:33:09 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=69
05/17/2022 20:33:10 - INFO - __main__ - Step 980 Global step 980 Train loss 1.08 on epoch=69
05/17/2022 20:33:11 - INFO - __main__ - Step 990 Global step 990 Train loss 1.03 on epoch=70
05/17/2022 20:33:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.10 on epoch=71
05/17/2022 20:33:16 - INFO - __main__ - Global step 1000 Train loss 1.10 Classification-F1 0.3400494040446876 on epoch=71
05/17/2022 20:33:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.13 on epoch=72
05/17/2022 20:33:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.02 on epoch=72
05/17/2022 20:33:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.00 on epoch=73
05/17/2022 20:33:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/17/2022 20:33:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.02 on epoch=74
05/17/2022 20:33:25 - INFO - __main__ - Global step 1050 Train loss 1.03 Classification-F1 0.4177538126361656 on epoch=74
05/17/2022 20:33:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3592671278106849 -> 0.4177538126361656 on epoch=74, global_step=1050
05/17/2022 20:33:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.97 on epoch=75
05/17/2022 20:33:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=76
05/17/2022 20:33:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=77
05/17/2022 20:33:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.90 on epoch=77
05/17/2022 20:33:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.08 on epoch=78
05/17/2022 20:33:35 - INFO - __main__ - Global step 1100 Train loss 1.03 Classification-F1 0.41833994047487305 on epoch=78
05/17/2022 20:33:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4177538126361656 -> 0.41833994047487305 on epoch=78, global_step=1100
05/17/2022 20:33:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.04 on epoch=79
05/17/2022 20:33:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.00 on epoch=79
05/17/2022 20:33:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.95 on epoch=80
05/17/2022 20:33:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=81
05/17/2022 20:33:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.98 on epoch=82
05/17/2022 20:33:44 - INFO - __main__ - Global step 1150 Train loss 1.01 Classification-F1 0.48492477247681354 on epoch=82
05/17/2022 20:33:44 - INFO - __main__ - Saving model with best Classification-F1: 0.41833994047487305 -> 0.48492477247681354 on epoch=82, global_step=1150
05/17/2022 20:33:46 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.01 on epoch=82
05/17/2022 20:33:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.04 on epoch=83
05/17/2022 20:33:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.00 on epoch=84
05/17/2022 20:33:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.91 on epoch=84
05/17/2022 20:33:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.83 on epoch=85
05/17/2022 20:33:54 - INFO - __main__ - Global step 1200 Train loss 0.96 Classification-F1 0.43635901222902496 on epoch=85
05/17/2022 20:33:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.04 on epoch=86
05/17/2022 20:33:56 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.98 on epoch=87
05/17/2022 20:33:58 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.93 on epoch=87
05/17/2022 20:33:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.96 on epoch=88
05/17/2022 20:34:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.97 on epoch=89
05/17/2022 20:34:04 - INFO - __main__ - Global step 1250 Train loss 0.97 Classification-F1 0.4746489791316136 on epoch=89
05/17/2022 20:34:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=89
05/17/2022 20:34:06 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.88 on epoch=90
05/17/2022 20:34:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.97 on epoch=91
05/17/2022 20:34:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.96 on epoch=92
05/17/2022 20:34:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.94 on epoch=92
05/17/2022 20:34:14 - INFO - __main__ - Global step 1300 Train loss 0.96 Classification-F1 0.4108643677025864 on epoch=92
05/17/2022 20:34:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.92 on epoch=93
05/17/2022 20:34:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.91 on epoch=94
05/17/2022 20:34:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.88 on epoch=94
05/17/2022 20:34:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.80 on epoch=95
05/17/2022 20:34:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.87 on epoch=96
05/17/2022 20:34:23 - INFO - __main__ - Global step 1350 Train loss 0.88 Classification-F1 0.4329445401263793 on epoch=96
05/17/2022 20:34:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.92 on epoch=97
05/17/2022 20:34:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.84 on epoch=97
05/17/2022 20:34:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.88 on epoch=98
05/17/2022 20:34:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.88 on epoch=99
05/17/2022 20:34:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=99
05/17/2022 20:34:33 - INFO - __main__ - Global step 1400 Train loss 0.90 Classification-F1 0.4739033840244181 on epoch=99
05/17/2022 20:34:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.84 on epoch=100
05/17/2022 20:34:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.99 on epoch=101
05/17/2022 20:34:37 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=102
05/17/2022 20:34:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.79 on epoch=102
05/17/2022 20:34:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=103
05/17/2022 20:34:43 - INFO - __main__ - Global step 1450 Train loss 0.90 Classification-F1 0.3952154096666231 on epoch=103
05/17/2022 20:34:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.79 on epoch=104
05/17/2022 20:34:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.91 on epoch=104
05/17/2022 20:34:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.83 on epoch=105
05/17/2022 20:34:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.91 on epoch=106
05/17/2022 20:34:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.91 on epoch=107
05/17/2022 20:34:53 - INFO - __main__ - Global step 1500 Train loss 0.87 Classification-F1 0.4373502776701951 on epoch=107
05/17/2022 20:34:54 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.90 on epoch=107
05/17/2022 20:34:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.79 on epoch=108
05/17/2022 20:34:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.98 on epoch=109
05/17/2022 20:34:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=109
05/17/2022 20:34:59 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.84 on epoch=110
05/17/2022 20:35:03 - INFO - __main__ - Global step 1550 Train loss 0.90 Classification-F1 0.40330712399095575 on epoch=110
05/17/2022 20:35:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=111
05/17/2022 20:35:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.85 on epoch=112
05/17/2022 20:35:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.86 on epoch=112
05/17/2022 20:35:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.87 on epoch=113
05/17/2022 20:35:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.83 on epoch=114
05/17/2022 20:35:13 - INFO - __main__ - Global step 1600 Train loss 0.86 Classification-F1 0.41708146683921876 on epoch=114
05/17/2022 20:35:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.85 on epoch=114
05/17/2022 20:35:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.87 on epoch=115
05/17/2022 20:35:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.97 on epoch=116
05/17/2022 20:35:18 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.90 on epoch=117
05/17/2022 20:35:19 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.91 on epoch=117
05/17/2022 20:35:23 - INFO - __main__ - Global step 1650 Train loss 0.90 Classification-F1 0.35716845985819723 on epoch=117
05/17/2022 20:35:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.83 on epoch=118
05/17/2022 20:35:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.85 on epoch=119
05/17/2022 20:35:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.10 on epoch=119
05/17/2022 20:35:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.74 on epoch=120
05/17/2022 20:35:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.90 on epoch=121
05/17/2022 20:35:33 - INFO - __main__ - Global step 1700 Train loss 0.88 Classification-F1 0.3736332093988351 on epoch=121
05/17/2022 20:35:34 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.94 on epoch=122
05/17/2022 20:35:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.81 on epoch=122
05/17/2022 20:35:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.87 on epoch=123
05/17/2022 20:35:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.86 on epoch=124
05/17/2022 20:35:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.79 on epoch=124
05/17/2022 20:35:43 - INFO - __main__ - Global step 1750 Train loss 0.86 Classification-F1 0.3727163633176147 on epoch=124
05/17/2022 20:35:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.78 on epoch=125
05/17/2022 20:35:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.90 on epoch=126
05/17/2022 20:35:46 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.85 on epoch=127
05/17/2022 20:35:48 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.93 on epoch=127
05/17/2022 20:35:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.83 on epoch=128
05/17/2022 20:35:52 - INFO - __main__ - Global step 1800 Train loss 0.86 Classification-F1 0.4304162308929294 on epoch=128
05/17/2022 20:35:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.82 on epoch=129
05/17/2022 20:35:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.93 on epoch=129
05/17/2022 20:35:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.85 on epoch=130
05/17/2022 20:35:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.90 on epoch=131
05/17/2022 20:35:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.85 on epoch=132
05/17/2022 20:36:02 - INFO - __main__ - Global step 1850 Train loss 0.87 Classification-F1 0.4623991618423324 on epoch=132
05/17/2022 20:36:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.85 on epoch=132
05/17/2022 20:36:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.77 on epoch=133
05/17/2022 20:36:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.76 on epoch=134
05/17/2022 20:36:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.90 on epoch=134
05/17/2022 20:36:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.74 on epoch=135
05/17/2022 20:36:13 - INFO - __main__ - Global step 1900 Train loss 0.80 Classification-F1 0.4436138168874514 on epoch=135
05/17/2022 20:36:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.78 on epoch=136
05/17/2022 20:36:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.89 on epoch=137
05/17/2022 20:36:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/17/2022 20:36:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.77 on epoch=138
05/17/2022 20:36:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.81 on epoch=139
05/17/2022 20:36:22 - INFO - __main__ - Global step 1950 Train loss 0.81 Classification-F1 0.42787276712649647 on epoch=139
05/17/2022 20:36:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.86 on epoch=139
05/17/2022 20:36:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.71 on epoch=140
05/17/2022 20:36:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.85 on epoch=141
05/17/2022 20:36:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.90 on epoch=142
05/17/2022 20:36:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.76 on epoch=142
05/17/2022 20:36:32 - INFO - __main__ - Global step 2000 Train loss 0.82 Classification-F1 0.4385453812835994 on epoch=142
05/17/2022 20:36:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.79 on epoch=143
05/17/2022 20:36:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.83 on epoch=144
05/17/2022 20:36:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.95 on epoch=144
05/17/2022 20:36:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.72 on epoch=145
05/17/2022 20:36:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.81 on epoch=146
05/17/2022 20:36:42 - INFO - __main__ - Global step 2050 Train loss 0.82 Classification-F1 0.46395882373409864 on epoch=146
05/17/2022 20:36:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.78 on epoch=147
05/17/2022 20:36:45 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.84 on epoch=147
05/17/2022 20:36:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.80 on epoch=148
05/17/2022 20:36:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.88 on epoch=149
05/17/2022 20:36:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.79 on epoch=149
05/17/2022 20:36:52 - INFO - __main__ - Global step 2100 Train loss 0.82 Classification-F1 0.42404557595046066 on epoch=149
05/17/2022 20:36:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.83 on epoch=150
05/17/2022 20:36:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.85 on epoch=151
05/17/2022 20:36:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.87 on epoch=152
05/17/2022 20:36:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.85 on epoch=152
05/17/2022 20:36:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.75 on epoch=153
05/17/2022 20:37:02 - INFO - __main__ - Global step 2150 Train loss 0.83 Classification-F1 0.39032234008527106 on epoch=153
05/17/2022 20:37:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.84 on epoch=154
05/17/2022 20:37:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.81 on epoch=154
05/17/2022 20:37:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.72 on epoch=155
05/17/2022 20:37:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.82 on epoch=156
05/17/2022 20:37:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=157
05/17/2022 20:37:12 - INFO - __main__ - Global step 2200 Train loss 0.81 Classification-F1 0.48344509779627665 on epoch=157
05/17/2022 20:37:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.71 on epoch=157
05/17/2022 20:37:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.86 on epoch=158
05/17/2022 20:37:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.72 on epoch=159
05/17/2022 20:37:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.85 on epoch=159
05/17/2022 20:37:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/17/2022 20:37:22 - INFO - __main__ - Global step 2250 Train loss 0.77 Classification-F1 0.3770890103392523 on epoch=160
05/17/2022 20:37:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.79 on epoch=161
05/17/2022 20:37:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.79 on epoch=162
05/17/2022 20:37:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.81 on epoch=162
05/17/2022 20:37:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.76 on epoch=163
05/17/2022 20:37:28 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.82 on epoch=164
05/17/2022 20:37:32 - INFO - __main__ - Global step 2300 Train loss 0.79 Classification-F1 0.37133132629956583 on epoch=164
05/17/2022 20:37:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.84 on epoch=164
05/17/2022 20:37:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.65 on epoch=165
05/17/2022 20:37:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.81 on epoch=166
05/17/2022 20:37:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.71 on epoch=167
05/17/2022 20:37:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.77 on epoch=167
05/17/2022 20:37:42 - INFO - __main__ - Global step 2350 Train loss 0.75 Classification-F1 0.3817790774202439 on epoch=167
05/17/2022 20:37:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.82 on epoch=168
05/17/2022 20:37:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.84 on epoch=169
05/17/2022 20:37:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.73 on epoch=169
05/17/2022 20:37:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.72 on epoch=170
05/17/2022 20:37:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.72 on epoch=171
05/17/2022 20:37:52 - INFO - __main__ - Global step 2400 Train loss 0.77 Classification-F1 0.4012833977222862 on epoch=171
05/17/2022 20:37:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.86 on epoch=172
05/17/2022 20:37:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.78 on epoch=172
05/17/2022 20:37:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.67 on epoch=173
05/17/2022 20:37:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.75 on epoch=174
05/17/2022 20:37:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.80 on epoch=174
05/17/2022 20:38:02 - INFO - __main__ - Global step 2450 Train loss 0.77 Classification-F1 0.4042802324383157 on epoch=174
05/17/2022 20:38:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.70 on epoch=175
05/17/2022 20:38:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=176
05/17/2022 20:38:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.80 on epoch=177
05/17/2022 20:38:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.81 on epoch=177
05/17/2022 20:38:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.71 on epoch=178
05/17/2022 20:38:12 - INFO - __main__ - Global step 2500 Train loss 0.77 Classification-F1 0.39453271162975767 on epoch=178
05/17/2022 20:38:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.81 on epoch=179
05/17/2022 20:38:14 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.82 on epoch=179
05/17/2022 20:38:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.67 on epoch=180
05/17/2022 20:38:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.73 on epoch=181
05/17/2022 20:38:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.83 on epoch=182
05/17/2022 20:38:22 - INFO - __main__ - Global step 2550 Train loss 0.77 Classification-F1 0.3518740033362488 on epoch=182
05/17/2022 20:38:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.75 on epoch=182
05/17/2022 20:38:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.77 on epoch=183
05/17/2022 20:38:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.78 on epoch=184
05/17/2022 20:38:26 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.72 on epoch=184
05/17/2022 20:38:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.70 on epoch=185
05/17/2022 20:38:31 - INFO - __main__ - Global step 2600 Train loss 0.75 Classification-F1 0.31745212753394786 on epoch=185
05/17/2022 20:38:33 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.69 on epoch=186
05/17/2022 20:38:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.76 on epoch=187
05/17/2022 20:38:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.79 on epoch=187
05/17/2022 20:38:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.62 on epoch=188
05/17/2022 20:38:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.74 on epoch=189
05/17/2022 20:38:41 - INFO - __main__ - Global step 2650 Train loss 0.72 Classification-F1 0.40372174283738904 on epoch=189
05/17/2022 20:38:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.71 on epoch=189
05/17/2022 20:38:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.66 on epoch=190
05/17/2022 20:38:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.83 on epoch=191
05/17/2022 20:38:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.79 on epoch=192
05/17/2022 20:38:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.69 on epoch=192
05/17/2022 20:38:51 - INFO - __main__ - Global step 2700 Train loss 0.74 Classification-F1 0.4100883127046888 on epoch=192
05/17/2022 20:38:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.70 on epoch=193
05/17/2022 20:38:54 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.79 on epoch=194
05/17/2022 20:38:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.76 on epoch=194
05/17/2022 20:38:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.63 on epoch=195
05/17/2022 20:38:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.77 on epoch=196
05/17/2022 20:39:01 - INFO - __main__ - Global step 2750 Train loss 0.73 Classification-F1 0.3883938026508039 on epoch=196
05/17/2022 20:39:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.72 on epoch=197
05/17/2022 20:39:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.76 on epoch=197
05/17/2022 20:39:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.60 on epoch=198
05/17/2022 20:39:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.62 on epoch=199
05/17/2022 20:39:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.70 on epoch=199
05/17/2022 20:39:11 - INFO - __main__ - Global step 2800 Train loss 0.68 Classification-F1 0.3833147974452322 on epoch=199
05/17/2022 20:39:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.69 on epoch=200
05/17/2022 20:39:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.63 on epoch=201
05/17/2022 20:39:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.72 on epoch=202
05/17/2022 20:39:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/17/2022 20:39:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.66 on epoch=203
05/17/2022 20:39:21 - INFO - __main__ - Global step 2850 Train loss 0.68 Classification-F1 0.39932651326204033 on epoch=203
05/17/2022 20:39:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.62 on epoch=204
05/17/2022 20:39:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.72 on epoch=204
05/17/2022 20:39:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.74 on epoch=205
05/17/2022 20:39:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.74 on epoch=206
05/17/2022 20:39:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.71 on epoch=207
05/17/2022 20:39:31 - INFO - __main__ - Global step 2900 Train loss 0.71 Classification-F1 0.4870131073648216 on epoch=207
05/17/2022 20:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.48492477247681354 -> 0.4870131073648216 on epoch=207, global_step=2900
05/17/2022 20:39:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.62 on epoch=207
05/17/2022 20:39:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.64 on epoch=208
05/17/2022 20:39:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.69 on epoch=209
05/17/2022 20:39:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.79 on epoch=209
05/17/2022 20:39:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.71 on epoch=210
05/17/2022 20:39:42 - INFO - __main__ - Global step 2950 Train loss 0.69 Classification-F1 0.4705511760006969 on epoch=210
05/17/2022 20:39:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.78 on epoch=211
05/17/2022 20:39:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.75 on epoch=212
05/17/2022 20:39:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.64 on epoch=212
05/17/2022 20:39:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.60 on epoch=213
05/17/2022 20:39:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.80 on epoch=214
05/17/2022 20:39:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:39:50 - INFO - __main__ - Printing 3 examples
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:39:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:39:50 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:39:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:39:50 - INFO - __main__ - Printing 3 examples
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:39:50 - INFO - __main__ - ['Company']
05/17/2022 20:39:50 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:39:50 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:39:50 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:39:52 - INFO - __main__ - Global step 3000 Train loss 0.71 Classification-F1 0.41897897647316046 on epoch=214
05/17/2022 20:39:52 - INFO - __main__ - save last model!
05/17/2022 20:39:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 20:39:52 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 20:39:52 - INFO - __main__ - Printing 3 examples
05/17/2022 20:39:52 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 20:39:52 - INFO - __main__ - ['Animal']
05/17/2022 20:39:52 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 20:39:52 - INFO - __main__ - ['Animal']
05/17/2022 20:39:52 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 20:39:52 - INFO - __main__ - ['Village']
05/17/2022 20:39:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:39:54 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:39:57 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:39:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:39:57 - INFO - __main__ - Starting training!
05/17/2022 20:39:57 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 20:41:08 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/17/2022 20:41:08 - INFO - __main__ - Classification-F1 on test data: 0.2252
05/17/2022 20:41:08 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.4870131073648216, test_performance=0.22521467901078668
05/17/2022 20:41:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/17/2022 20:41:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:41:09 - INFO - __main__ - Printing 3 examples
05/17/2022 20:41:09 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:41:09 - INFO - __main__ - ['Company']
05/17/2022 20:41:09 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:41:09 - INFO - __main__ - ['Company']
05/17/2022 20:41:09 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:41:09 - INFO - __main__ - ['Company']
05/17/2022 20:41:09 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:41:09 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:41:10 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:41:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:41:10 - INFO - __main__ - Printing 3 examples
05/17/2022 20:41:10 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:41:10 - INFO - __main__ - ['Company']
05/17/2022 20:41:10 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:41:10 - INFO - __main__ - ['Company']
05/17/2022 20:41:10 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:41:10 - INFO - __main__ - ['Company']
05/17/2022 20:41:10 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:41:10 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:41:10 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:41:16 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:41:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:41:16 - INFO - __main__ - Starting training!
05/17/2022 20:41:20 - INFO - __main__ - Step 10 Global step 10 Train loss 7.75 on epoch=0
05/17/2022 20:41:22 - INFO - __main__ - Step 20 Global step 20 Train loss 6.92 on epoch=1
05/17/2022 20:41:23 - INFO - __main__ - Step 30 Global step 30 Train loss 6.28 on epoch=2
05/17/2022 20:41:25 - INFO - __main__ - Step 40 Global step 40 Train loss 5.64 on epoch=2
05/17/2022 20:41:26 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=3
05/17/2022 20:41:29 - INFO - __main__ - Global step 50 Train loss 6.43 Classification-F1 0.0 on epoch=3
05/17/2022 20:41:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 20:41:31 - INFO - __main__ - Step 60 Global step 60 Train loss 5.02 on epoch=4
05/17/2022 20:41:32 - INFO - __main__ - Step 70 Global step 70 Train loss 4.93 on epoch=4
05/17/2022 20:41:34 - INFO - __main__ - Step 80 Global step 80 Train loss 4.37 on epoch=5
05/17/2022 20:41:35 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=6
05/17/2022 20:41:36 - INFO - __main__ - Step 100 Global step 100 Train loss 4.05 on epoch=7
05/17/2022 20:41:40 - INFO - __main__ - Global step 100 Train loss 4.56 Classification-F1 0.0 on epoch=7
05/17/2022 20:41:41 - INFO - __main__ - Step 110 Global step 110 Train loss 3.62 on epoch=7
05/17/2022 20:41:43 - INFO - __main__ - Step 120 Global step 120 Train loss 3.78 on epoch=8
05/17/2022 20:41:44 - INFO - __main__ - Step 130 Global step 130 Train loss 3.55 on epoch=9
05/17/2022 20:41:46 - INFO - __main__ - Step 140 Global step 140 Train loss 3.51 on epoch=9
05/17/2022 20:41:47 - INFO - __main__ - Step 150 Global step 150 Train loss 3.11 on epoch=10
05/17/2022 20:41:50 - INFO - __main__ - Global step 150 Train loss 3.51 Classification-F1 0.007909604519774013 on epoch=10
05/17/2022 20:41:50 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007909604519774013 on epoch=10, global_step=150
05/17/2022 20:41:51 - INFO - __main__ - Step 160 Global step 160 Train loss 3.17 on epoch=11
05/17/2022 20:41:53 - INFO - __main__ - Step 170 Global step 170 Train loss 2.95 on epoch=12
05/17/2022 20:41:54 - INFO - __main__ - Step 180 Global step 180 Train loss 2.79 on epoch=12
05/17/2022 20:41:56 - INFO - __main__ - Step 190 Global step 190 Train loss 2.76 on epoch=13
05/17/2022 20:41:57 - INFO - __main__ - Step 200 Global step 200 Train loss 2.59 on epoch=14
05/17/2022 20:42:00 - INFO - __main__ - Global step 200 Train loss 2.85 Classification-F1 0.008849557522123895 on epoch=14
05/17/2022 20:42:00 - INFO - __main__ - Saving model with best Classification-F1: 0.007909604519774013 -> 0.008849557522123895 on epoch=14, global_step=200
05/17/2022 20:42:01 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=14
05/17/2022 20:42:02 - INFO - __main__ - Step 220 Global step 220 Train loss 2.36 on epoch=15
05/17/2022 20:42:04 - INFO - __main__ - Step 230 Global step 230 Train loss 2.51 on epoch=16
05/17/2022 20:42:05 - INFO - __main__ - Step 240 Global step 240 Train loss 2.44 on epoch=17
05/17/2022 20:42:07 - INFO - __main__ - Step 250 Global step 250 Train loss 2.19 on epoch=17
05/17/2022 20:42:08 - INFO - __main__ - Global step 250 Train loss 2.44 Classification-F1 0.009523809523809523 on epoch=17
05/17/2022 20:42:09 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=17, global_step=250
05/17/2022 20:42:10 - INFO - __main__ - Step 260 Global step 260 Train loss 2.33 on epoch=18
05/17/2022 20:42:11 - INFO - __main__ - Step 270 Global step 270 Train loss 2.23 on epoch=19
05/17/2022 20:42:13 - INFO - __main__ - Step 280 Global step 280 Train loss 2.16 on epoch=19
05/17/2022 20:42:14 - INFO - __main__ - Step 290 Global step 290 Train loss 1.94 on epoch=20
05/17/2022 20:42:15 - INFO - __main__ - Step 300 Global step 300 Train loss 1.99 on epoch=21
05/17/2022 20:42:17 - INFO - __main__ - Global step 300 Train loss 2.13 Classification-F1 0.009603841536614645 on epoch=21
05/17/2022 20:42:17 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009603841536614645 on epoch=21, global_step=300
05/17/2022 20:42:19 - INFO - __main__ - Step 310 Global step 310 Train loss 2.07 on epoch=22
05/17/2022 20:42:20 - INFO - __main__ - Step 320 Global step 320 Train loss 1.87 on epoch=22
05/17/2022 20:42:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.86 on epoch=23
05/17/2022 20:42:22 - INFO - __main__ - Step 340 Global step 340 Train loss 1.85 on epoch=24
05/17/2022 20:42:24 - INFO - __main__ - Step 350 Global step 350 Train loss 1.93 on epoch=24
05/17/2022 20:42:26 - INFO - __main__ - Global step 350 Train loss 1.91 Classification-F1 0.03281995365953387 on epoch=24
05/17/2022 20:42:26 - INFO - __main__ - Saving model with best Classification-F1: 0.009603841536614645 -> 0.03281995365953387 on epoch=24, global_step=350
05/17/2022 20:42:27 - INFO - __main__ - Step 360 Global step 360 Train loss 1.65 on epoch=25
05/17/2022 20:42:28 - INFO - __main__ - Step 370 Global step 370 Train loss 1.79 on epoch=26
05/17/2022 20:42:29 - INFO - __main__ - Step 380 Global step 380 Train loss 1.76 on epoch=27
05/17/2022 20:42:31 - INFO - __main__ - Step 390 Global step 390 Train loss 1.61 on epoch=27
05/17/2022 20:42:32 - INFO - __main__ - Step 400 Global step 400 Train loss 1.59 on epoch=28
05/17/2022 20:42:34 - INFO - __main__ - Global step 400 Train loss 1.68 Classification-F1 0.022251980169810243 on epoch=28
05/17/2022 20:42:35 - INFO - __main__ - Step 410 Global step 410 Train loss 1.57 on epoch=29
05/17/2022 20:42:36 - INFO - __main__ - Step 420 Global step 420 Train loss 1.61 on epoch=29
05/17/2022 20:42:38 - INFO - __main__ - Step 430 Global step 430 Train loss 1.48 on epoch=30
05/17/2022 20:42:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.59 on epoch=31
05/17/2022 20:42:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.56 on epoch=32
05/17/2022 20:42:42 - INFO - __main__ - Global step 450 Train loss 1.56 Classification-F1 0.0257512276917554 on epoch=32
05/17/2022 20:42:44 - INFO - __main__ - Step 460 Global step 460 Train loss 1.43 on epoch=32
05/17/2022 20:42:45 - INFO - __main__ - Step 470 Global step 470 Train loss 1.52 on epoch=33
05/17/2022 20:42:46 - INFO - __main__ - Step 480 Global step 480 Train loss 1.48 on epoch=34
05/17/2022 20:42:47 - INFO - __main__ - Step 490 Global step 490 Train loss 1.45 on epoch=34
05/17/2022 20:42:49 - INFO - __main__ - Step 500 Global step 500 Train loss 1.44 on epoch=35
05/17/2022 20:42:51 - INFO - __main__ - Global step 500 Train loss 1.47 Classification-F1 0.0268251128716245 on epoch=35
05/17/2022 20:42:52 - INFO - __main__ - Step 510 Global step 510 Train loss 1.37 on epoch=36
05/17/2022 20:42:54 - INFO - __main__ - Step 520 Global step 520 Train loss 1.47 on epoch=37
05/17/2022 20:42:55 - INFO - __main__ - Step 530 Global step 530 Train loss 1.33 on epoch=37
05/17/2022 20:42:56 - INFO - __main__ - Step 540 Global step 540 Train loss 1.32 on epoch=38
05/17/2022 20:42:57 - INFO - __main__ - Step 550 Global step 550 Train loss 1.38 on epoch=39
05/17/2022 20:43:00 - INFO - __main__ - Global step 550 Train loss 1.37 Classification-F1 0.023153331193325712 on epoch=39
05/17/2022 20:43:01 - INFO - __main__ - Step 560 Global step 560 Train loss 1.28 on epoch=39
05/17/2022 20:43:02 - INFO - __main__ - Step 570 Global step 570 Train loss 1.28 on epoch=40
05/17/2022 20:43:04 - INFO - __main__ - Step 580 Global step 580 Train loss 1.38 on epoch=41
05/17/2022 20:43:05 - INFO - __main__ - Step 590 Global step 590 Train loss 1.29 on epoch=42
05/17/2022 20:43:06 - INFO - __main__ - Step 600 Global step 600 Train loss 1.31 on epoch=42
05/17/2022 20:43:08 - INFO - __main__ - Global step 600 Train loss 1.31 Classification-F1 0.07989073342810764 on epoch=42
05/17/2022 20:43:08 - INFO - __main__ - Saving model with best Classification-F1: 0.03281995365953387 -> 0.07989073342810764 on epoch=42, global_step=600
05/17/2022 20:43:10 - INFO - __main__ - Step 610 Global step 610 Train loss 1.28 on epoch=43
05/17/2022 20:43:11 - INFO - __main__ - Step 620 Global step 620 Train loss 1.26 on epoch=44
05/17/2022 20:43:12 - INFO - __main__ - Step 630 Global step 630 Train loss 1.29 on epoch=44
05/17/2022 20:43:13 - INFO - __main__ - Step 640 Global step 640 Train loss 1.25 on epoch=45
05/17/2022 20:43:15 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=46
05/17/2022 20:43:17 - INFO - __main__ - Global step 650 Train loss 1.29 Classification-F1 0.0333884537714907 on epoch=46
05/17/2022 20:43:18 - INFO - __main__ - Step 660 Global step 660 Train loss 1.27 on epoch=47
05/17/2022 20:43:20 - INFO - __main__ - Step 670 Global step 670 Train loss 1.20 on epoch=47
05/17/2022 20:43:21 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=48
05/17/2022 20:43:22 - INFO - __main__ - Step 690 Global step 690 Train loss 1.33 on epoch=49
05/17/2022 20:43:23 - INFO - __main__ - Step 700 Global step 700 Train loss 1.32 on epoch=49
05/17/2022 20:43:26 - INFO - __main__ - Global step 700 Train loss 1.27 Classification-F1 0.06235792947315912 on epoch=49
05/17/2022 20:43:27 - INFO - __main__ - Step 710 Global step 710 Train loss 1.20 on epoch=50
05/17/2022 20:43:29 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=51
05/17/2022 20:43:30 - INFO - __main__ - Step 730 Global step 730 Train loss 1.23 on epoch=52
05/17/2022 20:43:31 - INFO - __main__ - Step 740 Global step 740 Train loss 1.10 on epoch=52
05/17/2022 20:43:32 - INFO - __main__ - Step 750 Global step 750 Train loss 1.20 on epoch=53
05/17/2022 20:43:35 - INFO - __main__ - Global step 750 Train loss 1.21 Classification-F1 0.03989622202212662 on epoch=53
05/17/2022 20:43:36 - INFO - __main__ - Step 760 Global step 760 Train loss 1.25 on epoch=54
05/17/2022 20:43:38 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=54
05/17/2022 20:43:39 - INFO - __main__ - Step 780 Global step 780 Train loss 1.15 on epoch=55
05/17/2022 20:43:40 - INFO - __main__ - Step 790 Global step 790 Train loss 1.24 on epoch=56
05/17/2022 20:43:41 - INFO - __main__ - Step 800 Global step 800 Train loss 1.23 on epoch=57
05/17/2022 20:43:44 - INFO - __main__ - Global step 800 Train loss 1.22 Classification-F1 0.17678883366948178 on epoch=57
05/17/2022 20:43:44 - INFO - __main__ - Saving model with best Classification-F1: 0.07989073342810764 -> 0.17678883366948178 on epoch=57, global_step=800
05/17/2022 20:43:45 - INFO - __main__ - Step 810 Global step 810 Train loss 1.18 on epoch=57
05/17/2022 20:43:46 - INFO - __main__ - Step 820 Global step 820 Train loss 1.20 on epoch=58
05/17/2022 20:43:48 - INFO - __main__ - Step 830 Global step 830 Train loss 1.22 on epoch=59
05/17/2022 20:43:49 - INFO - __main__ - Step 840 Global step 840 Train loss 1.16 on epoch=59
05/17/2022 20:43:50 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=60
05/17/2022 20:43:53 - INFO - __main__ - Global step 850 Train loss 1.19 Classification-F1 0.06428265786417263 on epoch=60
05/17/2022 20:43:55 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/17/2022 20:43:56 - INFO - __main__ - Step 870 Global step 870 Train loss 1.24 on epoch=62
05/17/2022 20:43:57 - INFO - __main__ - Step 880 Global step 880 Train loss 1.08 on epoch=62
05/17/2022 20:43:59 - INFO - __main__ - Step 890 Global step 890 Train loss 1.20 on epoch=63
05/17/2022 20:44:00 - INFO - __main__ - Step 900 Global step 900 Train loss 1.20 on epoch=64
05/17/2022 20:44:02 - INFO - __main__ - Global step 900 Train loss 1.20 Classification-F1 0.1396898040660333 on epoch=64
05/17/2022 20:44:04 - INFO - __main__ - Step 910 Global step 910 Train loss 1.14 on epoch=64
05/17/2022 20:44:05 - INFO - __main__ - Step 920 Global step 920 Train loss 1.03 on epoch=65
05/17/2022 20:44:06 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=66
05/17/2022 20:44:08 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=67
05/17/2022 20:44:09 - INFO - __main__ - Step 950 Global step 950 Train loss 1.09 on epoch=67
05/17/2022 20:44:12 - INFO - __main__ - Global step 950 Train loss 1.13 Classification-F1 0.2607884080056811 on epoch=67
05/17/2022 20:44:12 - INFO - __main__ - Saving model with best Classification-F1: 0.17678883366948178 -> 0.2607884080056811 on epoch=67, global_step=950
05/17/2022 20:44:13 - INFO - __main__ - Step 960 Global step 960 Train loss 1.19 on epoch=68
05/17/2022 20:44:15 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=69
05/17/2022 20:44:16 - INFO - __main__ - Step 980 Global step 980 Train loss 1.19 on epoch=69
05/17/2022 20:44:17 - INFO - __main__ - Step 990 Global step 990 Train loss 1.15 on epoch=70
05/17/2022 20:44:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.15 on epoch=71
05/17/2022 20:44:21 - INFO - __main__ - Global step 1000 Train loss 1.16 Classification-F1 0.208198847391394 on epoch=71
05/17/2022 20:44:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.13 on epoch=72
05/17/2022 20:44:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.00 on epoch=72
05/17/2022 20:44:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.11 on epoch=73
05/17/2022 20:44:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=74
05/17/2022 20:44:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=74
05/17/2022 20:44:31 - INFO - __main__ - Global step 1050 Train loss 1.09 Classification-F1 0.296853977886774 on epoch=74
05/17/2022 20:44:31 - INFO - __main__ - Saving model with best Classification-F1: 0.2607884080056811 -> 0.296853977886774 on epoch=74, global_step=1050
05/17/2022 20:44:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=75
05/17/2022 20:44:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.08 on epoch=76
05/17/2022 20:44:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.17 on epoch=77
05/17/2022 20:44:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.97 on epoch=77
05/17/2022 20:44:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.05 on epoch=78
05/17/2022 20:44:40 - INFO - __main__ - Global step 1100 Train loss 1.06 Classification-F1 0.2971531826107923 on epoch=78
05/17/2022 20:44:41 - INFO - __main__ - Saving model with best Classification-F1: 0.296853977886774 -> 0.2971531826107923 on epoch=78, global_step=1100
05/17/2022 20:44:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.11 on epoch=79
05/17/2022 20:44:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=79
05/17/2022 20:44:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.98 on epoch=80
05/17/2022 20:44:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.17 on epoch=81
05/17/2022 20:44:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.11 on epoch=82
05/17/2022 20:44:50 - INFO - __main__ - Global step 1150 Train loss 1.09 Classification-F1 0.3746964368208783 on epoch=82
05/17/2022 20:44:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2971531826107923 -> 0.3746964368208783 on epoch=82, global_step=1150
05/17/2022 20:44:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.04 on epoch=82
05/17/2022 20:44:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.08 on epoch=83
05/17/2022 20:44:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.10 on epoch=84
05/17/2022 20:44:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.03 on epoch=84
05/17/2022 20:44:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.15 on epoch=85
05/17/2022 20:45:00 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.37118110361533346 on epoch=85
05/17/2022 20:45:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.02 on epoch=86
05/17/2022 20:45:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/17/2022 20:45:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.04 on epoch=87
05/17/2022 20:45:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.07 on epoch=88
05/17/2022 20:45:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.00 on epoch=89
05/17/2022 20:45:10 - INFO - __main__ - Global step 1250 Train loss 1.04 Classification-F1 0.362679676992809 on epoch=89
05/17/2022 20:45:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.04 on epoch=89
05/17/2022 20:45:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.94 on epoch=90
05/17/2022 20:45:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.09 on epoch=91
05/17/2022 20:45:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.09 on epoch=92
05/17/2022 20:45:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.96 on epoch=92
05/17/2022 20:45:20 - INFO - __main__ - Global step 1300 Train loss 1.02 Classification-F1 0.3896652264780717 on epoch=92
05/17/2022 20:45:20 - INFO - __main__ - Saving model with best Classification-F1: 0.3746964368208783 -> 0.3896652264780717 on epoch=92, global_step=1300
05/17/2022 20:45:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.96 on epoch=93
05/17/2022 20:45:22 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.98 on epoch=94
05/17/2022 20:45:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.98 on epoch=94
05/17/2022 20:45:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.02 on epoch=95
05/17/2022 20:45:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.07 on epoch=96
05/17/2022 20:45:29 - INFO - __main__ - Global step 1350 Train loss 1.00 Classification-F1 0.3896999813761542 on epoch=96
05/17/2022 20:45:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3896652264780717 -> 0.3896999813761542 on epoch=96, global_step=1350
05/17/2022 20:45:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.93 on epoch=97
05/17/2022 20:45:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.99 on epoch=97
05/17/2022 20:45:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.01 on epoch=98
05/17/2022 20:45:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.96 on epoch=99
05/17/2022 20:45:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.93 on epoch=99
05/17/2022 20:45:39 - INFO - __main__ - Global step 1400 Train loss 0.96 Classification-F1 0.397766103351814 on epoch=99
05/17/2022 20:45:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3896999813761542 -> 0.397766103351814 on epoch=99, global_step=1400
05/17/2022 20:45:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.92 on epoch=100
05/17/2022 20:45:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.05 on epoch=101
05/17/2022 20:45:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.98 on epoch=102
05/17/2022 20:45:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=102
05/17/2022 20:45:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.91 on epoch=103
05/17/2022 20:45:49 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.44688606739496894 on epoch=103
05/17/2022 20:45:49 - INFO - __main__ - Saving model with best Classification-F1: 0.397766103351814 -> 0.44688606739496894 on epoch=103, global_step=1450
05/17/2022 20:45:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.92 on epoch=104
05/17/2022 20:45:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.00 on epoch=104
05/17/2022 20:45:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.86 on epoch=105
05/17/2022 20:45:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=106
05/17/2022 20:45:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.86 on epoch=107
05/17/2022 20:45:59 - INFO - __main__ - Global step 1500 Train loss 0.93 Classification-F1 0.4668924486250462 on epoch=107
05/17/2022 20:45:59 - INFO - __main__ - Saving model with best Classification-F1: 0.44688606739496894 -> 0.4668924486250462 on epoch=107, global_step=1500
05/17/2022 20:46:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.87 on epoch=107
05/17/2022 20:46:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.90 on epoch=108
05/17/2022 20:46:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.88 on epoch=109
05/17/2022 20:46:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.02 on epoch=109
05/17/2022 20:46:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.77 on epoch=110
05/17/2022 20:46:09 - INFO - __main__ - Global step 1550 Train loss 0.89 Classification-F1 0.45929679817693514 on epoch=110
05/17/2022 20:46:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.96 on epoch=111
05/17/2022 20:46:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.88 on epoch=112
05/17/2022 20:46:13 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.89 on epoch=112
05/17/2022 20:46:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.82 on epoch=113
05/17/2022 20:46:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.87 on epoch=114
05/17/2022 20:46:19 - INFO - __main__ - Global step 1600 Train loss 0.89 Classification-F1 0.46867252096240897 on epoch=114
05/17/2022 20:46:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4668924486250462 -> 0.46867252096240897 on epoch=114, global_step=1600
05/17/2022 20:46:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.94 on epoch=114
05/17/2022 20:46:22 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.76 on epoch=115
05/17/2022 20:46:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.82 on epoch=116
05/17/2022 20:46:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.88 on epoch=117
05/17/2022 20:46:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.89 on epoch=117
05/17/2022 20:46:29 - INFO - __main__ - Global step 1650 Train loss 0.86 Classification-F1 0.41486922134730125 on epoch=117
05/17/2022 20:46:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.89 on epoch=118
05/17/2022 20:46:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.82 on epoch=119
05/17/2022 20:46:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.83 on epoch=119
05/17/2022 20:46:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.90 on epoch=120
05/17/2022 20:46:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.87 on epoch=121
05/17/2022 20:46:39 - INFO - __main__ - Global step 1700 Train loss 0.86 Classification-F1 0.407162480865902 on epoch=121
05/17/2022 20:46:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.88 on epoch=122
05/17/2022 20:46:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.78 on epoch=122
05/17/2022 20:46:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.91 on epoch=123
05/17/2022 20:46:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.83 on epoch=124
05/17/2022 20:46:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.85 on epoch=124
05/17/2022 20:46:48 - INFO - __main__ - Global step 1750 Train loss 0.85 Classification-F1 0.4141797550425481 on epoch=124
05/17/2022 20:46:50 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.88 on epoch=125
05/17/2022 20:46:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.85 on epoch=126
05/17/2022 20:46:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=127
05/17/2022 20:46:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.80 on epoch=127
05/17/2022 20:46:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.76 on epoch=128
05/17/2022 20:46:59 - INFO - __main__ - Global step 1800 Train loss 0.85 Classification-F1 0.4869835940982847 on epoch=128
05/17/2022 20:46:59 - INFO - __main__ - Saving model with best Classification-F1: 0.46867252096240897 -> 0.4869835940982847 on epoch=128, global_step=1800
05/17/2022 20:47:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.81 on epoch=129
05/17/2022 20:47:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.85 on epoch=129
05/17/2022 20:47:02 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.87 on epoch=130
05/17/2022 20:47:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.89 on epoch=131
05/17/2022 20:47:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.89 on epoch=132
05/17/2022 20:47:08 - INFO - __main__ - Global step 1850 Train loss 0.86 Classification-F1 0.48301759213671386 on epoch=132
05/17/2022 20:47:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.75 on epoch=132
05/17/2022 20:47:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.69 on epoch=133
05/17/2022 20:47:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.79 on epoch=134
05/17/2022 20:47:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.82 on epoch=134
05/17/2022 20:47:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.79 on epoch=135
05/17/2022 20:47:18 - INFO - __main__ - Global step 1900 Train loss 0.77 Classification-F1 0.38612758447344914 on epoch=135
05/17/2022 20:47:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.82 on epoch=136
05/17/2022 20:47:21 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.84 on epoch=137
05/17/2022 20:47:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.74 on epoch=137
05/17/2022 20:47:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.79 on epoch=138
05/17/2022 20:47:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.78 on epoch=139
05/17/2022 20:47:29 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.45631396664893387 on epoch=139
05/17/2022 20:47:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.81 on epoch=139
05/17/2022 20:47:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.77 on epoch=140
05/17/2022 20:47:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.74 on epoch=141
05/17/2022 20:47:34 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.79 on epoch=142
05/17/2022 20:47:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.80 on epoch=142
05/17/2022 20:47:39 - INFO - __main__ - Global step 2000 Train loss 0.78 Classification-F1 0.473439897988087 on epoch=142
05/17/2022 20:47:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.75 on epoch=143
05/17/2022 20:47:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.77 on epoch=144
05/17/2022 20:47:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.72 on epoch=144
05/17/2022 20:47:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.72 on epoch=145
05/17/2022 20:47:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.86 on epoch=146
05/17/2022 20:47:49 - INFO - __main__ - Global step 2050 Train loss 0.76 Classification-F1 0.39693075524138 on epoch=146
05/17/2022 20:47:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.77 on epoch=147
05/17/2022 20:47:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.69 on epoch=147
05/17/2022 20:47:53 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.78 on epoch=148
05/17/2022 20:47:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.76 on epoch=149
05/17/2022 20:47:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.76 on epoch=149
05/17/2022 20:47:59 - INFO - __main__ - Global step 2100 Train loss 0.75 Classification-F1 0.363243387048246 on epoch=149
05/17/2022 20:48:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.65 on epoch=150
05/17/2022 20:48:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.75 on epoch=151
05/17/2022 20:48:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.79 on epoch=152
05/17/2022 20:48:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.73 on epoch=152
05/17/2022 20:48:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.71 on epoch=153
05/17/2022 20:48:10 - INFO - __main__ - Global step 2150 Train loss 0.73 Classification-F1 0.371111735372387 on epoch=153
05/17/2022 20:48:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.71 on epoch=154
05/17/2022 20:48:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.73 on epoch=154
05/17/2022 20:48:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.67 on epoch=155
05/17/2022 20:48:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.66 on epoch=156
05/17/2022 20:48:16 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.71 on epoch=157
05/17/2022 20:48:20 - INFO - __main__ - Global step 2200 Train loss 0.70 Classification-F1 0.3883600191804526 on epoch=157
05/17/2022 20:48:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.71 on epoch=157
05/17/2022 20:48:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.63 on epoch=158
05/17/2022 20:48:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.67 on epoch=159
05/17/2022 20:48:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/17/2022 20:48:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.59 on epoch=160
05/17/2022 20:48:30 - INFO - __main__ - Global step 2250 Train loss 0.66 Classification-F1 0.4039625981765836 on epoch=160
05/17/2022 20:48:31 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.74 on epoch=161
05/17/2022 20:48:32 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.70 on epoch=162
05/17/2022 20:48:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.60 on epoch=162
05/17/2022 20:48:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.75 on epoch=163
05/17/2022 20:48:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.66 on epoch=164
05/17/2022 20:48:40 - INFO - __main__ - Global step 2300 Train loss 0.69 Classification-F1 0.3713061408729262 on epoch=164
05/17/2022 20:48:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.74 on epoch=164
05/17/2022 20:48:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.63 on epoch=165
05/17/2022 20:48:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.67 on epoch=166
05/17/2022 20:48:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.74 on epoch=167
05/17/2022 20:48:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.69 on epoch=167
05/17/2022 20:48:50 - INFO - __main__ - Global step 2350 Train loss 0.69 Classification-F1 0.41441566576375116 on epoch=167
05/17/2022 20:48:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.72 on epoch=168
05/17/2022 20:48:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/17/2022 20:48:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.73 on epoch=169
05/17/2022 20:48:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.60 on epoch=170
05/17/2022 20:48:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.76 on epoch=171
05/17/2022 20:49:00 - INFO - __main__ - Global step 2400 Train loss 0.70 Classification-F1 0.4528631908331156 on epoch=171
05/17/2022 20:49:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.66 on epoch=172
05/17/2022 20:49:03 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.66 on epoch=172
05/17/2022 20:49:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.61 on epoch=173
05/17/2022 20:49:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.68 on epoch=174
05/17/2022 20:49:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.64 on epoch=174
05/17/2022 20:49:10 - INFO - __main__ - Global step 2450 Train loss 0.65 Classification-F1 0.44983506232721326 on epoch=174
05/17/2022 20:49:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.60 on epoch=175
05/17/2022 20:49:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.67 on epoch=176
05/17/2022 20:49:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.72 on epoch=177
05/17/2022 20:49:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.68 on epoch=177
05/17/2022 20:49:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.68 on epoch=178
05/17/2022 20:49:21 - INFO - __main__ - Global step 2500 Train loss 0.67 Classification-F1 0.4961425596654536 on epoch=178
05/17/2022 20:49:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4869835940982847 -> 0.4961425596654536 on epoch=178, global_step=2500
05/17/2022 20:49:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.66 on epoch=179
05/17/2022 20:49:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.76 on epoch=179
05/17/2022 20:49:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.54 on epoch=180
05/17/2022 20:49:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.64 on epoch=181
05/17/2022 20:49:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.69 on epoch=182
05/17/2022 20:49:31 - INFO - __main__ - Global step 2550 Train loss 0.66 Classification-F1 0.4380040061994949 on epoch=182
05/17/2022 20:49:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/17/2022 20:49:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.60 on epoch=183
05/17/2022 20:49:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.63 on epoch=184
05/17/2022 20:49:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.69 on epoch=184
05/17/2022 20:49:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/17/2022 20:49:41 - INFO - __main__ - Global step 2600 Train loss 0.63 Classification-F1 0.43946915881729876 on epoch=185
05/17/2022 20:49:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.65 on epoch=186
05/17/2022 20:49:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/17/2022 20:49:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.64 on epoch=187
05/17/2022 20:49:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/17/2022 20:49:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.71 on epoch=189
05/17/2022 20:49:51 - INFO - __main__ - Global step 2650 Train loss 0.66 Classification-F1 0.5118123463765093 on epoch=189
05/17/2022 20:49:51 - INFO - __main__ - Saving model with best Classification-F1: 0.4961425596654536 -> 0.5118123463765093 on epoch=189, global_step=2650
05/17/2022 20:49:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.68 on epoch=189
05/17/2022 20:49:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.48 on epoch=190
05/17/2022 20:49:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.66 on epoch=191
05/17/2022 20:49:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.62 on epoch=192
05/17/2022 20:49:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.65 on epoch=192
05/17/2022 20:50:01 - INFO - __main__ - Global step 2700 Train loss 0.62 Classification-F1 0.4512262285221224 on epoch=192
05/17/2022 20:50:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.62 on epoch=193
05/17/2022 20:50:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.69 on epoch=194
05/17/2022 20:50:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.62 on epoch=194
05/17/2022 20:50:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.56 on epoch=195
05/17/2022 20:50:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.69 on epoch=196
05/17/2022 20:50:12 - INFO - __main__ - Global step 2750 Train loss 0.64 Classification-F1 0.48441908506193476 on epoch=196
05/17/2022 20:50:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.70 on epoch=197
05/17/2022 20:50:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.63 on epoch=197
05/17/2022 20:50:15 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.59 on epoch=198
05/17/2022 20:50:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.55 on epoch=199
05/17/2022 20:50:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.64 on epoch=199
05/17/2022 20:50:22 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.5247447941080094 on epoch=199
05/17/2022 20:50:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5118123463765093 -> 0.5247447941080094 on epoch=199, global_step=2800
05/17/2022 20:50:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.62 on epoch=200
05/17/2022 20:50:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.58 on epoch=201
05/17/2022 20:50:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.67 on epoch=202
05/17/2022 20:50:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/17/2022 20:50:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.63 on epoch=203
05/17/2022 20:50:33 - INFO - __main__ - Global step 2850 Train loss 0.62 Classification-F1 0.4913647250859154 on epoch=203
05/17/2022 20:50:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.63 on epoch=204
05/17/2022 20:50:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/17/2022 20:50:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.55 on epoch=205
05/17/2022 20:50:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/17/2022 20:50:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.63 on epoch=207
05/17/2022 20:50:43 - INFO - __main__ - Global step 2900 Train loss 0.61 Classification-F1 0.4880918233240215 on epoch=207
05/17/2022 20:50:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.55 on epoch=207
05/17/2022 20:50:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.56 on epoch=208
05/17/2022 20:50:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.65 on epoch=209
05/17/2022 20:50:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.71 on epoch=209
05/17/2022 20:50:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.51 on epoch=210
05/17/2022 20:50:54 - INFO - __main__ - Global step 2950 Train loss 0.60 Classification-F1 0.4856148914289321 on epoch=210
05/17/2022 20:50:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.58 on epoch=211
05/17/2022 20:50:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.65 on epoch=212
05/17/2022 20:50:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.62 on epoch=212
05/17/2022 20:50:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.64 on epoch=213
05/17/2022 20:51:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.52 on epoch=214
05/17/2022 20:51:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:51:02 - INFO - __main__ - Printing 3 examples
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:51:02 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:51:02 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:51:02 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:51:02 - INFO - __main__ - Printing 3 examples
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:51:02 - INFO - __main__ - ['Company']
05/17/2022 20:51:02 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:51:02 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:51:02 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:51:04 - INFO - __main__ - Global step 3000 Train loss 0.60 Classification-F1 0.5410753259914368 on epoch=214
05/17/2022 20:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5247447941080094 -> 0.5410753259914368 on epoch=214, global_step=3000
05/17/2022 20:51:05 - INFO - __main__ - save last model!
05/17/2022 20:51:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 20:51:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 20:51:05 - INFO - __main__ - Printing 3 examples
05/17/2022 20:51:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 20:51:05 - INFO - __main__ - ['Animal']
05/17/2022 20:51:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 20:51:05 - INFO - __main__ - ['Animal']
05/17/2022 20:51:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 20:51:05 - INFO - __main__ - ['Village']
05/17/2022 20:51:05 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:51:06 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:51:09 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:51:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:51:09 - INFO - __main__ - Starting training!
05/17/2022 20:51:10 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 20:52:24 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/17/2022 20:52:24 - INFO - __main__ - Classification-F1 on test data: 0.2168
05/17/2022 20:52:24 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.5410753259914368, test_performance=0.2168230204016608
05/17/2022 20:52:24 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/17/2022 20:52:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:52:25 - INFO - __main__ - Printing 3 examples
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:52:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:52:25 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 20:52:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 20:52:25 - INFO - __main__ - Printing 3 examples
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 20:52:25 - INFO - __main__ - ['Company']
05/17/2022 20:52:25 - INFO - __main__ - Tokenizing Input ...
05/17/2022 20:52:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 20:52:26 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 20:52:32 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 20:52:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 20:52:32 - INFO - __main__ - Starting training!
05/17/2022 20:52:33 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/17/2022 20:52:35 - INFO - __main__ - Step 20 Global step 20 Train loss 7.32 on epoch=1
05/17/2022 20:52:36 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=2
05/17/2022 20:52:37 - INFO - __main__ - Step 40 Global step 40 Train loss 6.26 on epoch=2
05/17/2022 20:52:38 - INFO - __main__ - Step 50 Global step 50 Train loss 5.84 on epoch=3
05/17/2022 20:52:41 - INFO - __main__ - Global step 50 Train loss 6.66 Classification-F1 0.0 on epoch=3
05/17/2022 20:52:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 20:52:43 - INFO - __main__ - Step 60 Global step 60 Train loss 5.53 on epoch=4
05/17/2022 20:52:44 - INFO - __main__ - Step 70 Global step 70 Train loss 5.44 on epoch=4
05/17/2022 20:52:45 - INFO - __main__ - Step 80 Global step 80 Train loss 4.79 on epoch=5
05/17/2022 20:52:46 - INFO - __main__ - Step 90 Global step 90 Train loss 4.74 on epoch=6
05/17/2022 20:52:48 - INFO - __main__ - Step 100 Global step 100 Train loss 4.88 on epoch=7
05/17/2022 20:52:51 - INFO - __main__ - Global step 100 Train loss 5.08 Classification-F1 0.0 on epoch=7
05/17/2022 20:52:52 - INFO - __main__ - Step 110 Global step 110 Train loss 4.41 on epoch=7
05/17/2022 20:52:53 - INFO - __main__ - Step 120 Global step 120 Train loss 4.28 on epoch=8
05/17/2022 20:52:55 - INFO - __main__ - Step 130 Global step 130 Train loss 4.14 on epoch=9
05/17/2022 20:52:56 - INFO - __main__ - Step 140 Global step 140 Train loss 4.06 on epoch=9
05/17/2022 20:52:57 - INFO - __main__ - Step 150 Global step 150 Train loss 3.60 on epoch=10
05/17/2022 20:53:01 - INFO - __main__ - Global step 150 Train loss 4.10 Classification-F1 0.0 on epoch=10
05/17/2022 20:53:02 - INFO - __main__ - Step 160 Global step 160 Train loss 3.80 on epoch=11
05/17/2022 20:53:03 - INFO - __main__ - Step 170 Global step 170 Train loss 3.63 on epoch=12
05/17/2022 20:53:04 - INFO - __main__ - Step 180 Global step 180 Train loss 3.30 on epoch=12
05/17/2022 20:53:06 - INFO - __main__ - Step 190 Global step 190 Train loss 3.29 on epoch=13
05/17/2022 20:53:07 - INFO - __main__ - Step 200 Global step 200 Train loss 3.14 on epoch=14
05/17/2022 20:53:10 - INFO - __main__ - Global step 200 Train loss 3.43 Classification-F1 0.0056022408963585435 on epoch=14
05/17/2022 20:53:10 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0056022408963585435 on epoch=14, global_step=200
05/17/2022 20:53:11 - INFO - __main__ - Step 210 Global step 210 Train loss 3.18 on epoch=14
05/17/2022 20:53:13 - INFO - __main__ - Step 220 Global step 220 Train loss 2.85 on epoch=15
05/17/2022 20:53:14 - INFO - __main__ - Step 230 Global step 230 Train loss 3.04 on epoch=16
05/17/2022 20:53:15 - INFO - __main__ - Step 240 Global step 240 Train loss 2.97 on epoch=17
05/17/2022 20:53:16 - INFO - __main__ - Step 250 Global step 250 Train loss 2.66 on epoch=17
05/17/2022 20:53:19 - INFO - __main__ - Global step 250 Train loss 2.94 Classification-F1 0.008011444921316165 on epoch=17
05/17/2022 20:53:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0056022408963585435 -> 0.008011444921316165 on epoch=17, global_step=250
05/17/2022 20:53:20 - INFO - __main__ - Step 260 Global step 260 Train loss 2.79 on epoch=18
05/17/2022 20:53:21 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/17/2022 20:53:22 - INFO - __main__ - Step 280 Global step 280 Train loss 2.71 on epoch=19
05/17/2022 20:53:24 - INFO - __main__ - Step 290 Global step 290 Train loss 2.43 on epoch=20
05/17/2022 20:53:25 - INFO - __main__ - Step 300 Global step 300 Train loss 2.61 on epoch=21
05/17/2022 20:53:27 - INFO - __main__ - Global step 300 Train loss 2.63 Classification-F1 0.009523809523809523 on epoch=21
05/17/2022 20:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.008011444921316165 -> 0.009523809523809523 on epoch=21, global_step=300
05/17/2022 20:53:28 - INFO - __main__ - Step 310 Global step 310 Train loss 2.42 on epoch=22
05/17/2022 20:53:29 - INFO - __main__ - Step 320 Global step 320 Train loss 2.27 on epoch=22
05/17/2022 20:53:30 - INFO - __main__ - Step 330 Global step 330 Train loss 2.31 on epoch=23
05/17/2022 20:53:31 - INFO - __main__ - Step 340 Global step 340 Train loss 2.37 on epoch=24
05/17/2022 20:53:33 - INFO - __main__ - Step 350 Global step 350 Train loss 2.28 on epoch=24
05/17/2022 20:53:35 - INFO - __main__ - Global step 350 Train loss 2.33 Classification-F1 0.009523809523809523 on epoch=24
05/17/2022 20:53:36 - INFO - __main__ - Step 360 Global step 360 Train loss 2.05 on epoch=25
05/17/2022 20:53:37 - INFO - __main__ - Step 370 Global step 370 Train loss 2.11 on epoch=26
05/17/2022 20:53:38 - INFO - __main__ - Step 380 Global step 380 Train loss 2.07 on epoch=27
05/17/2022 20:53:39 - INFO - __main__ - Step 390 Global step 390 Train loss 1.91 on epoch=27
05/17/2022 20:53:41 - INFO - __main__ - Step 400 Global step 400 Train loss 2.06 on epoch=28
05/17/2022 20:53:43 - INFO - __main__ - Global step 400 Train loss 2.04 Classification-F1 0.009523809523809523 on epoch=28
05/17/2022 20:53:44 - INFO - __main__ - Step 410 Global step 410 Train loss 1.96 on epoch=29
05/17/2022 20:53:45 - INFO - __main__ - Step 420 Global step 420 Train loss 1.93 on epoch=29
05/17/2022 20:53:46 - INFO - __main__ - Step 430 Global step 430 Train loss 1.75 on epoch=30
05/17/2022 20:53:48 - INFO - __main__ - Step 440 Global step 440 Train loss 1.93 on epoch=31
05/17/2022 20:53:49 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=32
05/17/2022 20:53:51 - INFO - __main__ - Global step 450 Train loss 1.90 Classification-F1 0.027493106144791536 on epoch=32
05/17/2022 20:53:51 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.027493106144791536 on epoch=32, global_step=450
05/17/2022 20:53:52 - INFO - __main__ - Step 460 Global step 460 Train loss 1.73 on epoch=32
05/17/2022 20:53:53 - INFO - __main__ - Step 470 Global step 470 Train loss 1.74 on epoch=33
05/17/2022 20:53:54 - INFO - __main__ - Step 480 Global step 480 Train loss 1.72 on epoch=34
05/17/2022 20:53:56 - INFO - __main__ - Step 490 Global step 490 Train loss 1.68 on epoch=34
05/17/2022 20:53:57 - INFO - __main__ - Step 500 Global step 500 Train loss 1.56 on epoch=35
05/17/2022 20:53:59 - INFO - __main__ - Global step 500 Train loss 1.69 Classification-F1 0.022157666894508994 on epoch=35
05/17/2022 20:54:00 - INFO - __main__ - Step 510 Global step 510 Train loss 1.71 on epoch=36
05/17/2022 20:54:01 - INFO - __main__ - Step 520 Global step 520 Train loss 1.69 on epoch=37
05/17/2022 20:54:03 - INFO - __main__ - Step 530 Global step 530 Train loss 1.53 on epoch=37
05/17/2022 20:54:04 - INFO - __main__ - Step 540 Global step 540 Train loss 1.65 on epoch=38
05/17/2022 20:54:05 - INFO - __main__ - Step 550 Global step 550 Train loss 1.56 on epoch=39
05/17/2022 20:54:07 - INFO - __main__ - Global step 550 Train loss 1.63 Classification-F1 0.03300506249011232 on epoch=39
05/17/2022 20:54:07 - INFO - __main__ - Saving model with best Classification-F1: 0.027493106144791536 -> 0.03300506249011232 on epoch=39, global_step=550
05/17/2022 20:54:08 - INFO - __main__ - Step 560 Global step 560 Train loss 1.68 on epoch=39
05/17/2022 20:54:09 - INFO - __main__ - Step 570 Global step 570 Train loss 1.54 on epoch=40
05/17/2022 20:54:11 - INFO - __main__ - Step 580 Global step 580 Train loss 1.59 on epoch=41
05/17/2022 20:54:12 - INFO - __main__ - Step 590 Global step 590 Train loss 1.63 on epoch=42
05/17/2022 20:54:13 - INFO - __main__ - Step 600 Global step 600 Train loss 1.49 on epoch=42
05/17/2022 20:54:15 - INFO - __main__ - Global step 600 Train loss 1.58 Classification-F1 0.054354680728307105 on epoch=42
05/17/2022 20:54:15 - INFO - __main__ - Saving model with best Classification-F1: 0.03300506249011232 -> 0.054354680728307105 on epoch=42, global_step=600
05/17/2022 20:54:16 - INFO - __main__ - Step 610 Global step 610 Train loss 1.57 on epoch=43
05/17/2022 20:54:18 - INFO - __main__ - Step 620 Global step 620 Train loss 1.48 on epoch=44
05/17/2022 20:54:19 - INFO - __main__ - Step 630 Global step 630 Train loss 1.52 on epoch=44
05/17/2022 20:54:20 - INFO - __main__ - Step 640 Global step 640 Train loss 1.35 on epoch=45
05/17/2022 20:54:21 - INFO - __main__ - Step 650 Global step 650 Train loss 1.46 on epoch=46
05/17/2022 20:54:24 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.036130555281693996 on epoch=46
05/17/2022 20:54:25 - INFO - __main__ - Step 660 Global step 660 Train loss 1.38 on epoch=47
05/17/2022 20:54:26 - INFO - __main__ - Step 670 Global step 670 Train loss 1.37 on epoch=47
05/17/2022 20:54:27 - INFO - __main__ - Step 680 Global step 680 Train loss 1.40 on epoch=48
05/17/2022 20:54:29 - INFO - __main__ - Step 690 Global step 690 Train loss 1.31 on epoch=49
05/17/2022 20:54:30 - INFO - __main__ - Step 700 Global step 700 Train loss 1.41 on epoch=49
05/17/2022 20:54:32 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.02838988822761642 on epoch=49
05/17/2022 20:54:33 - INFO - __main__ - Step 710 Global step 710 Train loss 1.30 on epoch=50
05/17/2022 20:54:35 - INFO - __main__ - Step 720 Global step 720 Train loss 1.48 on epoch=51
05/17/2022 20:54:36 - INFO - __main__ - Step 730 Global step 730 Train loss 1.29 on epoch=52
05/17/2022 20:54:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.30 on epoch=52
05/17/2022 20:54:38 - INFO - __main__ - Step 750 Global step 750 Train loss 1.37 on epoch=53
05/17/2022 20:54:40 - INFO - __main__ - Global step 750 Train loss 1.35 Classification-F1 0.02770658651057322 on epoch=53
05/17/2022 20:54:41 - INFO - __main__ - Step 760 Global step 760 Train loss 1.31 on epoch=54
05/17/2022 20:54:42 - INFO - __main__ - Step 770 Global step 770 Train loss 1.37 on epoch=54
05/17/2022 20:54:44 - INFO - __main__ - Step 780 Global step 780 Train loss 1.23 on epoch=55
05/17/2022 20:54:45 - INFO - __main__ - Step 790 Global step 790 Train loss 1.36 on epoch=56
05/17/2022 20:54:46 - INFO - __main__ - Step 800 Global step 800 Train loss 1.35 on epoch=57
05/17/2022 20:54:48 - INFO - __main__ - Global step 800 Train loss 1.32 Classification-F1 0.06126147506499391 on epoch=57
05/17/2022 20:54:48 - INFO - __main__ - Saving model with best Classification-F1: 0.054354680728307105 -> 0.06126147506499391 on epoch=57, global_step=800
05/17/2022 20:54:49 - INFO - __main__ - Step 810 Global step 810 Train loss 1.23 on epoch=57
05/17/2022 20:54:50 - INFO - __main__ - Step 820 Global step 820 Train loss 1.29 on epoch=58
05/17/2022 20:54:52 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=59
05/17/2022 20:54:53 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=59
05/17/2022 20:54:54 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=60
05/17/2022 20:54:56 - INFO - __main__ - Global step 850 Train loss 1.26 Classification-F1 0.047836100847586015 on epoch=60
05/17/2022 20:54:57 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/17/2022 20:54:59 - INFO - __main__ - Step 870 Global step 870 Train loss 1.26 on epoch=62
05/17/2022 20:55:00 - INFO - __main__ - Step 880 Global step 880 Train loss 1.21 on epoch=62
05/17/2022 20:55:01 - INFO - __main__ - Step 890 Global step 890 Train loss 1.36 on epoch=63
05/17/2022 20:55:02 - INFO - __main__ - Step 900 Global step 900 Train loss 1.32 on epoch=64
05/17/2022 20:55:05 - INFO - __main__ - Global step 900 Train loss 1.29 Classification-F1 0.11557459638638222 on epoch=64
05/17/2022 20:55:05 - INFO - __main__ - Saving model with best Classification-F1: 0.06126147506499391 -> 0.11557459638638222 on epoch=64, global_step=900
05/17/2022 20:55:06 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=64
05/17/2022 20:55:07 - INFO - __main__ - Step 920 Global step 920 Train loss 1.23 on epoch=65
05/17/2022 20:55:08 - INFO - __main__ - Step 930 Global step 930 Train loss 1.39 on epoch=66
05/17/2022 20:55:10 - INFO - __main__ - Step 940 Global step 940 Train loss 1.31 on epoch=67
05/17/2022 20:55:11 - INFO - __main__ - Step 950 Global step 950 Train loss 1.21 on epoch=67
05/17/2022 20:55:14 - INFO - __main__ - Global step 950 Train loss 1.29 Classification-F1 0.06785377420460463 on epoch=67
05/17/2022 20:55:15 - INFO - __main__ - Step 960 Global step 960 Train loss 1.21 on epoch=68
05/17/2022 20:55:16 - INFO - __main__ - Step 970 Global step 970 Train loss 1.23 on epoch=69
05/17/2022 20:55:17 - INFO - __main__ - Step 980 Global step 980 Train loss 1.25 on epoch=69
05/17/2022 20:55:18 - INFO - __main__ - Step 990 Global step 990 Train loss 1.20 on epoch=70
05/17/2022 20:55:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.33 on epoch=71
05/17/2022 20:55:22 - INFO - __main__ - Global step 1000 Train loss 1.24 Classification-F1 0.06692553692300231 on epoch=71
05/17/2022 20:55:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.31 on epoch=72
05/17/2022 20:55:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.23 on epoch=72
05/17/2022 20:55:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.21 on epoch=73
05/17/2022 20:55:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.22 on epoch=74
05/17/2022 20:55:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.19 on epoch=74
05/17/2022 20:55:31 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.11813815806741963 on epoch=74
05/17/2022 20:55:31 - INFO - __main__ - Saving model with best Classification-F1: 0.11557459638638222 -> 0.11813815806741963 on epoch=74, global_step=1050
05/17/2022 20:55:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.21 on epoch=75
05/17/2022 20:55:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.15 on epoch=76
05/17/2022 20:55:35 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.23 on epoch=77
05/17/2022 20:55:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.17 on epoch=77
05/17/2022 20:55:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=78
05/17/2022 20:55:40 - INFO - __main__ - Global step 1100 Train loss 1.21 Classification-F1 0.07429862458719813 on epoch=78
05/17/2022 20:55:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=79
05/17/2022 20:55:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.18 on epoch=79
05/17/2022 20:55:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=80
05/17/2022 20:55:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.16 on epoch=81
05/17/2022 20:55:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.22 on epoch=82
05/17/2022 20:55:49 - INFO - __main__ - Global step 1150 Train loss 1.15 Classification-F1 0.14739075999517076 on epoch=82
05/17/2022 20:55:49 - INFO - __main__ - Saving model with best Classification-F1: 0.11813815806741963 -> 0.14739075999517076 on epoch=82, global_step=1150
05/17/2022 20:55:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.12 on epoch=82
05/17/2022 20:55:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.27 on epoch=83
05/17/2022 20:55:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.14 on epoch=84
05/17/2022 20:55:54 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.22 on epoch=84
05/17/2022 20:55:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.08 on epoch=85
05/17/2022 20:55:58 - INFO - __main__ - Global step 1200 Train loss 1.17 Classification-F1 0.10988781477503283 on epoch=85
05/17/2022 20:56:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.23 on epoch=86
05/17/2022 20:56:01 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=87
05/17/2022 20:56:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.15 on epoch=87
05/17/2022 20:56:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.23 on epoch=88
05/17/2022 20:56:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.16 on epoch=89
05/17/2022 20:56:08 - INFO - __main__ - Global step 1250 Train loss 1.19 Classification-F1 0.17702530555924315 on epoch=89
05/17/2022 20:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.14739075999517076 -> 0.17702530555924315 on epoch=89, global_step=1250
05/17/2022 20:56:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.15 on epoch=89
05/17/2022 20:56:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.20 on epoch=90
05/17/2022 20:56:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=91
05/17/2022 20:56:13 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.24 on epoch=92
05/17/2022 20:56:14 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.04 on epoch=92
05/17/2022 20:56:17 - INFO - __main__ - Global step 1300 Train loss 1.16 Classification-F1 0.222351411484978 on epoch=92
05/17/2022 20:56:17 - INFO - __main__ - Saving model with best Classification-F1: 0.17702530555924315 -> 0.222351411484978 on epoch=92, global_step=1300
05/17/2022 20:56:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.21 on epoch=93
05/17/2022 20:56:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.16 on epoch=94
05/17/2022 20:56:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=94
05/17/2022 20:56:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.05 on epoch=95
05/17/2022 20:56:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.15 on epoch=96
05/17/2022 20:56:27 - INFO - __main__ - Global step 1350 Train loss 1.15 Classification-F1 0.22686934578553866 on epoch=96
05/17/2022 20:56:27 - INFO - __main__ - Saving model with best Classification-F1: 0.222351411484978 -> 0.22686934578553866 on epoch=96, global_step=1350
05/17/2022 20:56:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=97
05/17/2022 20:56:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.99 on epoch=97
05/17/2022 20:56:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=98
05/17/2022 20:56:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=99
05/17/2022 20:56:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.16 on epoch=99
05/17/2022 20:56:37 - INFO - __main__ - Global step 1400 Train loss 1.11 Classification-F1 0.19625122903563574 on epoch=99
05/17/2022 20:56:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.04 on epoch=100
05/17/2022 20:56:39 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.15 on epoch=101
05/17/2022 20:56:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=102
05/17/2022 20:56:42 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.00 on epoch=102
05/17/2022 20:56:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.06 on epoch=103
05/17/2022 20:56:46 - INFO - __main__ - Global step 1450 Train loss 1.08 Classification-F1 0.2789831843937262 on epoch=103
05/17/2022 20:56:46 - INFO - __main__ - Saving model with best Classification-F1: 0.22686934578553866 -> 0.2789831843937262 on epoch=103, global_step=1450
05/17/2022 20:56:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.14 on epoch=104
05/17/2022 20:56:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.12 on epoch=104
05/17/2022 20:56:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.02 on epoch=105
05/17/2022 20:56:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.09 on epoch=106
05/17/2022 20:56:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=107
05/17/2022 20:56:56 - INFO - __main__ - Global step 1500 Train loss 1.08 Classification-F1 0.28943887063532603 on epoch=107
05/17/2022 20:56:56 - INFO - __main__ - Saving model with best Classification-F1: 0.2789831843937262 -> 0.28943887063532603 on epoch=107, global_step=1500
05/17/2022 20:56:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=107
05/17/2022 20:56:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.10 on epoch=108
05/17/2022 20:56:59 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.07 on epoch=109
05/17/2022 20:57:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.08 on epoch=109
05/17/2022 20:57:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.98 on epoch=110
05/17/2022 20:57:05 - INFO - __main__ - Global step 1550 Train loss 1.05 Classification-F1 0.23803130228099195 on epoch=110
05/17/2022 20:57:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.13 on epoch=111
05/17/2022 20:57:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=112
05/17/2022 20:57:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=112
05/17/2022 20:57:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=113
05/17/2022 20:57:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=114
05/17/2022 20:57:15 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.3365936002906512 on epoch=114
05/17/2022 20:57:15 - INFO - __main__ - Saving model with best Classification-F1: 0.28943887063532603 -> 0.3365936002906512 on epoch=114, global_step=1600
05/17/2022 20:57:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.03 on epoch=114
05/17/2022 20:57:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=115
05/17/2022 20:57:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.06 on epoch=116
05/17/2022 20:57:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.10 on epoch=117
05/17/2022 20:57:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.96 on epoch=117
05/17/2022 20:57:24 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.330305749372405 on epoch=117
05/17/2022 20:57:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=118
05/17/2022 20:57:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=119
05/17/2022 20:57:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.99 on epoch=119
05/17/2022 20:57:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.91 on epoch=120
05/17/2022 20:57:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=121
05/17/2022 20:57:34 - INFO - __main__ - Global step 1700 Train loss 1.01 Classification-F1 0.3156618269432915 on epoch=121
05/17/2022 20:57:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.01 on epoch=122
05/17/2022 20:57:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=122
05/17/2022 20:57:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.02 on epoch=123
05/17/2022 20:57:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.06 on epoch=124
05/17/2022 20:57:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=124
05/17/2022 20:57:44 - INFO - __main__ - Global step 1750 Train loss 1.02 Classification-F1 0.3312301715183979 on epoch=124
05/17/2022 20:57:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.97 on epoch=125
05/17/2022 20:57:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=126
05/17/2022 20:57:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.95 on epoch=127
05/17/2022 20:57:49 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.95 on epoch=127
05/17/2022 20:57:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.90 on epoch=128
05/17/2022 20:57:53 - INFO - __main__ - Global step 1800 Train loss 0.96 Classification-F1 0.3459862789937027 on epoch=128
05/17/2022 20:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3365936002906512 -> 0.3459862789937027 on epoch=128, global_step=1800
05/17/2022 20:57:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.02 on epoch=129
05/17/2022 20:57:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=129
05/17/2022 20:57:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=130
05/17/2022 20:57:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.97 on epoch=131
05/17/2022 20:57:59 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=132
05/17/2022 20:58:03 - INFO - __main__ - Global step 1850 Train loss 0.98 Classification-F1 0.4147644367495574 on epoch=132
05/17/2022 20:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3459862789937027 -> 0.4147644367495574 on epoch=132, global_step=1850
05/17/2022 20:58:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=132
05/17/2022 20:58:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=133
05/17/2022 20:58:07 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=134
05/17/2022 20:58:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.92 on epoch=134
05/17/2022 20:58:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.99 on epoch=135
05/17/2022 20:58:12 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.4140724312818008 on epoch=135
05/17/2022 20:58:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.00 on epoch=136
05/17/2022 20:58:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=137
05/17/2022 20:58:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.86 on epoch=137
05/17/2022 20:58:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.95 on epoch=138
05/17/2022 20:58:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=139
05/17/2022 20:58:22 - INFO - __main__ - Global step 1950 Train loss 0.95 Classification-F1 0.45286994954979337 on epoch=139
05/17/2022 20:58:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4147644367495574 -> 0.45286994954979337 on epoch=139, global_step=1950
05/17/2022 20:58:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.96 on epoch=139
05/17/2022 20:58:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.80 on epoch=140
05/17/2022 20:58:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=141
05/17/2022 20:58:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.96 on epoch=142
05/17/2022 20:58:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.84 on epoch=142
05/17/2022 20:58:32 - INFO - __main__ - Global step 2000 Train loss 0.93 Classification-F1 0.4448603417924918 on epoch=142
05/17/2022 20:58:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.83 on epoch=143
05/17/2022 20:58:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.81 on epoch=144
05/17/2022 20:58:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.91 on epoch=144
05/17/2022 20:58:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.78 on epoch=145
05/17/2022 20:58:39 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.94 on epoch=146
05/17/2022 20:58:43 - INFO - __main__ - Global step 2050 Train loss 0.85 Classification-F1 0.4161919430313956 on epoch=146
05/17/2022 20:58:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.90 on epoch=147
05/17/2022 20:58:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.93 on epoch=147
05/17/2022 20:58:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.82 on epoch=148
05/17/2022 20:58:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.91 on epoch=149
05/17/2022 20:58:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.82 on epoch=149
05/17/2022 20:58:53 - INFO - __main__ - Global step 2100 Train loss 0.88 Classification-F1 0.4578995363877278 on epoch=149
05/17/2022 20:58:53 - INFO - __main__ - Saving model with best Classification-F1: 0.45286994954979337 -> 0.4578995363877278 on epoch=149, global_step=2100
05/17/2022 20:58:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.74 on epoch=150
05/17/2022 20:58:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.85 on epoch=151
05/17/2022 20:58:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.87 on epoch=152
05/17/2022 20:58:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.82 on epoch=152
05/17/2022 20:59:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.76 on epoch=153
05/17/2022 20:59:04 - INFO - __main__ - Global step 2150 Train loss 0.81 Classification-F1 0.4186361906131378 on epoch=153
05/17/2022 20:59:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.80 on epoch=154
05/17/2022 20:59:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.78 on epoch=154
05/17/2022 20:59:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.70 on epoch=155
05/17/2022 20:59:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.81 on epoch=156
05/17/2022 20:59:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.85 on epoch=157
05/17/2022 20:59:14 - INFO - __main__ - Global step 2200 Train loss 0.79 Classification-F1 0.3917021229998988 on epoch=157
05/17/2022 20:59:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.84 on epoch=157
05/17/2022 20:59:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.83 on epoch=158
05/17/2022 20:59:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.76 on epoch=159
05/17/2022 20:59:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.85 on epoch=159
05/17/2022 20:59:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.84 on epoch=160
05/17/2022 20:59:24 - INFO - __main__ - Global step 2250 Train loss 0.83 Classification-F1 0.3552553570504171 on epoch=160
05/17/2022 20:59:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.81 on epoch=161
05/17/2022 20:59:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.78 on epoch=162
05/17/2022 20:59:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.83 on epoch=162
05/17/2022 20:59:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.80 on epoch=163
05/17/2022 20:59:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.78 on epoch=164
05/17/2022 20:59:34 - INFO - __main__ - Global step 2300 Train loss 0.80 Classification-F1 0.4094258708267996 on epoch=164
05/17/2022 20:59:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.88 on epoch=164
05/17/2022 20:59:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.85 on epoch=165
05/17/2022 20:59:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.81 on epoch=166
05/17/2022 20:59:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.80 on epoch=167
05/17/2022 20:59:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.81 on epoch=167
05/17/2022 20:59:44 - INFO - __main__ - Global step 2350 Train loss 0.83 Classification-F1 0.40191990256339666 on epoch=167
05/17/2022 20:59:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.80 on epoch=168
05/17/2022 20:59:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/17/2022 20:59:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.78 on epoch=169
05/17/2022 20:59:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.79 on epoch=170
05/17/2022 20:59:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.85 on epoch=171
05/17/2022 20:59:54 - INFO - __main__ - Global step 2400 Train loss 0.78 Classification-F1 0.3539887076991228 on epoch=171
05/17/2022 20:59:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.80 on epoch=172
05/17/2022 20:59:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.77 on epoch=172
05/17/2022 20:59:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.84 on epoch=173
05/17/2022 20:59:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.80 on epoch=174
05/17/2022 21:00:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.83 on epoch=174
05/17/2022 21:00:04 - INFO - __main__ - Global step 2450 Train loss 0.81 Classification-F1 0.387252392836883 on epoch=174
05/17/2022 21:00:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.74 on epoch=175
05/17/2022 21:00:07 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.77 on epoch=176
05/17/2022 21:00:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.73 on epoch=177
05/17/2022 21:00:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.78 on epoch=177
05/17/2022 21:00:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.78 on epoch=178
05/17/2022 21:00:14 - INFO - __main__ - Global step 2500 Train loss 0.76 Classification-F1 0.4023614553520452 on epoch=178
05/17/2022 21:00:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.82 on epoch=179
05/17/2022 21:00:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.75 on epoch=179
05/17/2022 21:00:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.76 on epoch=180
05/17/2022 21:00:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.89 on epoch=181
05/17/2022 21:00:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.78 on epoch=182
05/17/2022 21:00:24 - INFO - __main__ - Global step 2550 Train loss 0.80 Classification-F1 0.35604658966467834 on epoch=182
05/17/2022 21:00:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.69 on epoch=182
05/17/2022 21:00:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.78 on epoch=183
05/17/2022 21:00:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.76 on epoch=184
05/17/2022 21:00:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/17/2022 21:00:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.77 on epoch=185
05/17/2022 21:00:34 - INFO - __main__ - Global step 2600 Train loss 0.74 Classification-F1 0.432800164884039 on epoch=185
05/17/2022 21:00:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.72 on epoch=186
05/17/2022 21:00:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.73 on epoch=187
05/17/2022 21:00:38 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.72 on epoch=187
05/17/2022 21:00:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/17/2022 21:00:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.80 on epoch=189
05/17/2022 21:00:45 - INFO - __main__ - Global step 2650 Train loss 0.73 Classification-F1 0.3724132889042933 on epoch=189
05/17/2022 21:00:46 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.77 on epoch=189
05/17/2022 21:00:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.70 on epoch=190
05/17/2022 21:00:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.75 on epoch=191
05/17/2022 21:00:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.72 on epoch=192
05/17/2022 21:00:51 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.79 on epoch=192
05/17/2022 21:00:55 - INFO - __main__ - Global step 2700 Train loss 0.75 Classification-F1 0.37813756557962924 on epoch=192
05/17/2022 21:00:56 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.64 on epoch=193
05/17/2022 21:00:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.69 on epoch=194
05/17/2022 21:00:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.73 on epoch=194
05/17/2022 21:01:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.67 on epoch=195
05/17/2022 21:01:01 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.82 on epoch=196
05/17/2022 21:01:05 - INFO - __main__ - Global step 2750 Train loss 0.71 Classification-F1 0.36754263961835837 on epoch=196
05/17/2022 21:01:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.75 on epoch=197
05/17/2022 21:01:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.66 on epoch=197
05/17/2022 21:01:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.68 on epoch=198
05/17/2022 21:01:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.76 on epoch=199
05/17/2022 21:01:11 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.74 on epoch=199
05/17/2022 21:01:15 - INFO - __main__ - Global step 2800 Train loss 0.72 Classification-F1 0.41722354771853515 on epoch=199
05/17/2022 21:01:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.60 on epoch=200
05/17/2022 21:01:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.75 on epoch=201
05/17/2022 21:01:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.65 on epoch=202
05/17/2022 21:01:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/17/2022 21:01:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.63 on epoch=203
05/17/2022 21:01:26 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.3706584634719934 on epoch=203
05/17/2022 21:01:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.64 on epoch=204
05/17/2022 21:01:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.70 on epoch=204
05/17/2022 21:01:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.65 on epoch=205
05/17/2022 21:01:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.73 on epoch=206
05/17/2022 21:01:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.73 on epoch=207
05/17/2022 21:01:36 - INFO - __main__ - Global step 2900 Train loss 0.69 Classification-F1 0.3863953246358643 on epoch=207
05/17/2022 21:01:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.64 on epoch=207
05/17/2022 21:01:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.65 on epoch=208
05/17/2022 21:01:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.67 on epoch=209
05/17/2022 21:01:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/17/2022 21:01:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.60 on epoch=210
05/17/2022 21:01:46 - INFO - __main__ - Global step 2950 Train loss 0.67 Classification-F1 0.39816407030270684 on epoch=210
05/17/2022 21:01:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.70 on epoch=211
05/17/2022 21:01:48 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.71 on epoch=212
05/17/2022 21:01:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.58 on epoch=212
05/17/2022 21:01:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.58 on epoch=213
05/17/2022 21:01:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.64 on epoch=214
05/17/2022 21:01:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:01:53 - INFO - __main__ - Printing 3 examples
05/17/2022 21:01:53 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 21:01:53 - INFO - __main__ - ['Company']
05/17/2022 21:01:53 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 21:01:53 - INFO - __main__ - ['Company']
05/17/2022 21:01:53 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 21:01:53 - INFO - __main__ - ['Company']
05/17/2022 21:01:53 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:01:54 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:01:54 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:01:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:01:54 - INFO - __main__ - Printing 3 examples
05/17/2022 21:01:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 21:01:54 - INFO - __main__ - ['Company']
05/17/2022 21:01:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 21:01:54 - INFO - __main__ - ['Company']
05/17/2022 21:01:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 21:01:54 - INFO - __main__ - ['Company']
05/17/2022 21:01:54 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:01:54 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:01:54 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:01:56 - INFO - __main__ - Global step 3000 Train loss 0.64 Classification-F1 0.45159962188100183 on epoch=214
05/17/2022 21:01:56 - INFO - __main__ - save last model!
05/17/2022 21:01:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:01:56 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:01:56 - INFO - __main__ - Printing 3 examples
05/17/2022 21:01:56 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:01:56 - INFO - __main__ - ['Animal']
05/17/2022 21:01:56 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:01:56 - INFO - __main__ - ['Animal']
05/17/2022 21:01:56 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:01:56 - INFO - __main__ - ['Village']
05/17/2022 21:01:56 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:01:58 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:02:00 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:02:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:02:00 - INFO - __main__ - Starting training!
05/17/2022 21:02:01 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:03:08 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/17/2022 21:03:08 - INFO - __main__ - Classification-F1 on test data: 0.1722
05/17/2022 21:03:08 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.4578995363877278, test_performance=0.17216984638494673
05/17/2022 21:03:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/17/2022 21:03:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:03:09 - INFO - __main__ - Printing 3 examples
05/17/2022 21:03:09 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/17/2022 21:03:09 - INFO - __main__ - ['Company']
05/17/2022 21:03:09 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/17/2022 21:03:09 - INFO - __main__ - ['Company']
05/17/2022 21:03:09 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/17/2022 21:03:09 - INFO - __main__ - ['Company']
05/17/2022 21:03:09 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:03:09 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:03:10 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:03:10 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:03:10 - INFO - __main__ - Printing 3 examples
05/17/2022 21:03:10 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/17/2022 21:03:10 - INFO - __main__ - ['Company']
05/17/2022 21:03:10 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/17/2022 21:03:10 - INFO - __main__ - ['Company']
05/17/2022 21:03:10 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/17/2022 21:03:10 - INFO - __main__ - ['Company']
05/17/2022 21:03:10 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:03:10 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:03:10 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:03:16 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:03:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:03:16 - INFO - __main__ - Starting training!
05/17/2022 21:03:19 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/17/2022 21:03:21 - INFO - __main__ - Step 20 Global step 20 Train loss 7.29 on epoch=1
05/17/2022 21:03:22 - INFO - __main__ - Step 30 Global step 30 Train loss 6.73 on epoch=2
05/17/2022 21:03:24 - INFO - __main__ - Step 40 Global step 40 Train loss 6.53 on epoch=2
05/17/2022 21:03:25 - INFO - __main__ - Step 50 Global step 50 Train loss 6.34 on epoch=3
05/17/2022 21:03:28 - INFO - __main__ - Global step 50 Train loss 6.84 Classification-F1 0.0 on epoch=3
05/17/2022 21:03:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 21:03:29 - INFO - __main__ - Step 60 Global step 60 Train loss 5.99 on epoch=4
05/17/2022 21:03:31 - INFO - __main__ - Step 70 Global step 70 Train loss 6.08 on epoch=4
05/17/2022 21:03:32 - INFO - __main__ - Step 80 Global step 80 Train loss 5.54 on epoch=5
05/17/2022 21:03:33 - INFO - __main__ - Step 90 Global step 90 Train loss 5.54 on epoch=6
05/17/2022 21:03:34 - INFO - __main__ - Step 100 Global step 100 Train loss 5.35 on epoch=7
05/17/2022 21:03:37 - INFO - __main__ - Global step 100 Train loss 5.70 Classification-F1 0.0 on epoch=7
05/17/2022 21:03:39 - INFO - __main__ - Step 110 Global step 110 Train loss 5.05 on epoch=7
05/17/2022 21:03:40 - INFO - __main__ - Step 120 Global step 120 Train loss 5.06 on epoch=8
05/17/2022 21:03:41 - INFO - __main__ - Step 130 Global step 130 Train loss 4.85 on epoch=9
05/17/2022 21:03:42 - INFO - __main__ - Step 140 Global step 140 Train loss 4.78 on epoch=9
05/17/2022 21:03:44 - INFO - __main__ - Step 150 Global step 150 Train loss 4.47 on epoch=10
05/17/2022 21:03:47 - INFO - __main__ - Global step 150 Train loss 4.84 Classification-F1 0.0 on epoch=10
05/17/2022 21:03:48 - INFO - __main__ - Step 160 Global step 160 Train loss 4.42 on epoch=11
05/17/2022 21:03:49 - INFO - __main__ - Step 170 Global step 170 Train loss 4.24 on epoch=12
05/17/2022 21:03:51 - INFO - __main__ - Step 180 Global step 180 Train loss 3.99 on epoch=12
05/17/2022 21:03:52 - INFO - __main__ - Step 190 Global step 190 Train loss 4.09 on epoch=13
05/17/2022 21:03:53 - INFO - __main__ - Step 200 Global step 200 Train loss 3.85 on epoch=14
05/17/2022 21:03:57 - INFO - __main__ - Global step 200 Train loss 4.12 Classification-F1 0.0 on epoch=14
05/17/2022 21:03:58 - INFO - __main__ - Step 210 Global step 210 Train loss 3.93 on epoch=14
05/17/2022 21:03:59 - INFO - __main__ - Step 220 Global step 220 Train loss 3.55 on epoch=15
05/17/2022 21:04:01 - INFO - __main__ - Step 230 Global step 230 Train loss 3.63 on epoch=16
05/17/2022 21:04:02 - INFO - __main__ - Step 240 Global step 240 Train loss 3.53 on epoch=17
05/17/2022 21:04:03 - INFO - __main__ - Step 250 Global step 250 Train loss 3.50 on epoch=17
05/17/2022 21:04:06 - INFO - __main__ - Global step 250 Train loss 3.63 Classification-F1 0.007352941176470588 on epoch=17
05/17/2022 21:04:06 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007352941176470588 on epoch=17, global_step=250
05/17/2022 21:04:07 - INFO - __main__ - Step 260 Global step 260 Train loss 3.37 on epoch=18
05/17/2022 21:04:08 - INFO - __main__ - Step 270 Global step 270 Train loss 3.41 on epoch=19
05/17/2022 21:04:09 - INFO - __main__ - Step 280 Global step 280 Train loss 3.41 on epoch=19
05/17/2022 21:04:11 - INFO - __main__ - Step 290 Global step 290 Train loss 3.02 on epoch=20
05/17/2022 21:04:12 - INFO - __main__ - Step 300 Global step 300 Train loss 3.25 on epoch=21
05/17/2022 21:04:14 - INFO - __main__ - Global step 300 Train loss 3.29 Classification-F1 0.008259587020648967 on epoch=21
05/17/2022 21:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.007352941176470588 -> 0.008259587020648967 on epoch=21, global_step=300
05/17/2022 21:04:16 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/17/2022 21:04:17 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=22
05/17/2022 21:04:18 - INFO - __main__ - Step 330 Global step 330 Train loss 2.93 on epoch=23
05/17/2022 21:04:20 - INFO - __main__ - Step 340 Global step 340 Train loss 2.95 on epoch=24
05/17/2022 21:04:21 - INFO - __main__ - Step 350 Global step 350 Train loss 3.03 on epoch=24
05/17/2022 21:04:23 - INFO - __main__ - Global step 350 Train loss 2.99 Classification-F1 0.008333333333333335 on epoch=24
05/17/2022 21:04:23 - INFO - __main__ - Saving model with best Classification-F1: 0.008259587020648967 -> 0.008333333333333335 on epoch=24, global_step=350
05/17/2022 21:04:25 - INFO - __main__ - Step 360 Global step 360 Train loss 2.70 on epoch=25
05/17/2022 21:04:26 - INFO - __main__ - Step 370 Global step 370 Train loss 2.74 on epoch=26
05/17/2022 21:04:27 - INFO - __main__ - Step 380 Global step 380 Train loss 2.72 on epoch=27
05/17/2022 21:04:28 - INFO - __main__ - Step 390 Global step 390 Train loss 2.63 on epoch=27
05/17/2022 21:04:30 - INFO - __main__ - Step 400 Global step 400 Train loss 2.68 on epoch=28
05/17/2022 21:04:32 - INFO - __main__ - Global step 400 Train loss 2.69 Classification-F1 0.009001406469760902 on epoch=28
05/17/2022 21:04:32 - INFO - __main__ - Saving model with best Classification-F1: 0.008333333333333335 -> 0.009001406469760902 on epoch=28, global_step=400
05/17/2022 21:04:33 - INFO - __main__ - Step 410 Global step 410 Train loss 2.64 on epoch=29
05/17/2022 21:04:34 - INFO - __main__ - Step 420 Global step 420 Train loss 2.62 on epoch=29
05/17/2022 21:04:36 - INFO - __main__ - Step 430 Global step 430 Train loss 2.36 on epoch=30
05/17/2022 21:04:37 - INFO - __main__ - Step 440 Global step 440 Train loss 2.54 on epoch=31
05/17/2022 21:04:38 - INFO - __main__ - Step 450 Global step 450 Train loss 2.46 on epoch=32
05/17/2022 21:04:40 - INFO - __main__ - Global step 450 Train loss 2.52 Classification-F1 0.009523809523809523 on epoch=32
05/17/2022 21:04:40 - INFO - __main__ - Saving model with best Classification-F1: 0.009001406469760902 -> 0.009523809523809523 on epoch=32, global_step=450
05/17/2022 21:04:41 - INFO - __main__ - Step 460 Global step 460 Train loss 2.33 on epoch=32
05/17/2022 21:04:43 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=33
05/17/2022 21:04:44 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=34
05/17/2022 21:04:45 - INFO - __main__ - Step 490 Global step 490 Train loss 2.47 on epoch=34
05/17/2022 21:04:47 - INFO - __main__ - Step 500 Global step 500 Train loss 2.27 on epoch=35
05/17/2022 21:04:48 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.009523809523809523 on epoch=35
05/17/2022 21:04:50 - INFO - __main__ - Step 510 Global step 510 Train loss 2.29 on epoch=36
05/17/2022 21:04:51 - INFO - __main__ - Step 520 Global step 520 Train loss 2.23 on epoch=37
05/17/2022 21:04:52 - INFO - __main__ - Step 530 Global step 530 Train loss 2.24 on epoch=37
05/17/2022 21:04:53 - INFO - __main__ - Step 540 Global step 540 Train loss 2.24 on epoch=38
05/17/2022 21:04:55 - INFO - __main__ - Step 550 Global step 550 Train loss 2.14 on epoch=39
05/17/2022 21:04:57 - INFO - __main__ - Global step 550 Train loss 2.23 Classification-F1 0.009523809523809523 on epoch=39
05/17/2022 21:04:58 - INFO - __main__ - Step 560 Global step 560 Train loss 2.14 on epoch=39
05/17/2022 21:04:59 - INFO - __main__ - Step 570 Global step 570 Train loss 2.02 on epoch=40
05/17/2022 21:05:00 - INFO - __main__ - Step 580 Global step 580 Train loss 2.19 on epoch=41
05/17/2022 21:05:02 - INFO - __main__ - Step 590 Global step 590 Train loss 2.07 on epoch=42
05/17/2022 21:05:03 - INFO - __main__ - Step 600 Global step 600 Train loss 1.93 on epoch=42
05/17/2022 21:05:05 - INFO - __main__ - Global step 600 Train loss 2.07 Classification-F1 0.02022914428929467 on epoch=42
05/17/2022 21:05:05 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02022914428929467 on epoch=42, global_step=600
05/17/2022 21:05:06 - INFO - __main__ - Step 610 Global step 610 Train loss 1.88 on epoch=43
05/17/2022 21:05:07 - INFO - __main__ - Step 620 Global step 620 Train loss 1.94 on epoch=44
05/17/2022 21:05:09 - INFO - __main__ - Step 630 Global step 630 Train loss 2.00 on epoch=44
05/17/2022 21:05:10 - INFO - __main__ - Step 640 Global step 640 Train loss 1.91 on epoch=45
05/17/2022 21:05:11 - INFO - __main__ - Step 650 Global step 650 Train loss 2.00 on epoch=46
05/17/2022 21:05:13 - INFO - __main__ - Global step 650 Train loss 1.95 Classification-F1 0.037370503757058374 on epoch=46
05/17/2022 21:05:13 - INFO - __main__ - Saving model with best Classification-F1: 0.02022914428929467 -> 0.037370503757058374 on epoch=46, global_step=650
05/17/2022 21:05:14 - INFO - __main__ - Step 660 Global step 660 Train loss 1.94 on epoch=47
05/17/2022 21:05:16 - INFO - __main__ - Step 670 Global step 670 Train loss 1.64 on epoch=47
05/17/2022 21:05:17 - INFO - __main__ - Step 680 Global step 680 Train loss 1.81 on epoch=48
05/17/2022 21:05:18 - INFO - __main__ - Step 690 Global step 690 Train loss 1.87 on epoch=49
05/17/2022 21:05:20 - INFO - __main__ - Step 700 Global step 700 Train loss 1.72 on epoch=49
05/17/2022 21:05:21 - INFO - __main__ - Global step 700 Train loss 1.80 Classification-F1 0.024001447654142267 on epoch=49
05/17/2022 21:05:23 - INFO - __main__ - Step 710 Global step 710 Train loss 1.77 on epoch=50
05/17/2022 21:05:24 - INFO - __main__ - Step 720 Global step 720 Train loss 1.75 on epoch=51
05/17/2022 21:05:25 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=52
05/17/2022 21:05:26 - INFO - __main__ - Step 740 Global step 740 Train loss 1.63 on epoch=52
05/17/2022 21:05:28 - INFO - __main__ - Step 750 Global step 750 Train loss 1.79 on epoch=53
05/17/2022 21:05:30 - INFO - __main__ - Global step 750 Train loss 1.73 Classification-F1 0.028946684158895626 on epoch=53
05/17/2022 21:05:31 - INFO - __main__ - Step 760 Global step 760 Train loss 1.70 on epoch=54
05/17/2022 21:05:32 - INFO - __main__ - Step 770 Global step 770 Train loss 1.66 on epoch=54
05/17/2022 21:05:33 - INFO - __main__ - Step 780 Global step 780 Train loss 1.56 on epoch=55
05/17/2022 21:05:35 - INFO - __main__ - Step 790 Global step 790 Train loss 1.72 on epoch=56
05/17/2022 21:05:36 - INFO - __main__ - Step 800 Global step 800 Train loss 1.66 on epoch=57
05/17/2022 21:05:38 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.03672806290387477 on epoch=57
05/17/2022 21:05:39 - INFO - __main__ - Step 810 Global step 810 Train loss 1.55 on epoch=57
05/17/2022 21:05:40 - INFO - __main__ - Step 820 Global step 820 Train loss 1.65 on epoch=58
05/17/2022 21:05:42 - INFO - __main__ - Step 830 Global step 830 Train loss 1.57 on epoch=59
05/17/2022 21:05:43 - INFO - __main__ - Step 840 Global step 840 Train loss 1.66 on epoch=59
05/17/2022 21:05:44 - INFO - __main__ - Step 850 Global step 850 Train loss 1.53 on epoch=60
05/17/2022 21:05:47 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.055509513589878566 on epoch=60
05/17/2022 21:05:47 - INFO - __main__ - Saving model with best Classification-F1: 0.037370503757058374 -> 0.055509513589878566 on epoch=60, global_step=850
05/17/2022 21:05:48 - INFO - __main__ - Step 860 Global step 860 Train loss 1.59 on epoch=61
05/17/2022 21:05:49 - INFO - __main__ - Step 870 Global step 870 Train loss 1.61 on epoch=62
05/17/2022 21:05:50 - INFO - __main__ - Step 880 Global step 880 Train loss 1.49 on epoch=62
05/17/2022 21:05:52 - INFO - __main__ - Step 890 Global step 890 Train loss 1.50 on epoch=63
05/17/2022 21:05:53 - INFO - __main__ - Step 900 Global step 900 Train loss 1.52 on epoch=64
05/17/2022 21:05:55 - INFO - __main__ - Global step 900 Train loss 1.54 Classification-F1 0.022707901667919146 on epoch=64
05/17/2022 21:05:56 - INFO - __main__ - Step 910 Global step 910 Train loss 1.54 on epoch=64
05/17/2022 21:05:58 - INFO - __main__ - Step 920 Global step 920 Train loss 1.41 on epoch=65
05/17/2022 21:05:59 - INFO - __main__ - Step 930 Global step 930 Train loss 1.47 on epoch=66
05/17/2022 21:06:00 - INFO - __main__ - Step 940 Global step 940 Train loss 1.52 on epoch=67
05/17/2022 21:06:01 - INFO - __main__ - Step 950 Global step 950 Train loss 1.42 on epoch=67
05/17/2022 21:06:04 - INFO - __main__ - Global step 950 Train loss 1.47 Classification-F1 0.06300243323304709 on epoch=67
05/17/2022 21:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.055509513589878566 -> 0.06300243323304709 on epoch=67, global_step=950
05/17/2022 21:06:05 - INFO - __main__ - Step 960 Global step 960 Train loss 1.60 on epoch=68
05/17/2022 21:06:06 - INFO - __main__ - Step 970 Global step 970 Train loss 1.48 on epoch=69
05/17/2022 21:06:08 - INFO - __main__ - Step 980 Global step 980 Train loss 1.50 on epoch=69
05/17/2022 21:06:09 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=70
05/17/2022 21:06:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.47 on epoch=71
05/17/2022 21:06:13 - INFO - __main__ - Global step 1000 Train loss 1.48 Classification-F1 0.05109086275009557 on epoch=71
05/17/2022 21:06:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=72
05/17/2022 21:06:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.32 on epoch=72
05/17/2022 21:06:16 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.48 on epoch=73
05/17/2022 21:06:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.38 on epoch=74
05/17/2022 21:06:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.45 on epoch=74
05/17/2022 21:06:21 - INFO - __main__ - Global step 1050 Train loss 1.41 Classification-F1 0.022637707120465738 on epoch=74
05/17/2022 21:06:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.36 on epoch=75
05/17/2022 21:06:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.53 on epoch=76
05/17/2022 21:06:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.43 on epoch=77
05/17/2022 21:06:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.30 on epoch=77
05/17/2022 21:06:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.36 on epoch=78
05/17/2022 21:06:30 - INFO - __main__ - Global step 1100 Train loss 1.40 Classification-F1 0.030736905736905736 on epoch=78
05/17/2022 21:06:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=79
05/17/2022 21:06:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.40 on epoch=79
05/17/2022 21:06:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=80
05/17/2022 21:06:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=81
05/17/2022 21:06:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.29 on epoch=82
05/17/2022 21:06:39 - INFO - __main__ - Global step 1150 Train loss 1.34 Classification-F1 0.05311423553392479 on epoch=82
05/17/2022 21:06:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.36 on epoch=82
05/17/2022 21:06:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.36 on epoch=83
05/17/2022 21:06:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=84
05/17/2022 21:06:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=84
05/17/2022 21:06:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.28 on epoch=85
05/17/2022 21:06:48 - INFO - __main__ - Global step 1200 Train loss 1.34 Classification-F1 0.06193161677032644 on epoch=85
05/17/2022 21:06:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.28 on epoch=86
05/17/2022 21:06:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.34 on epoch=87
05/17/2022 21:06:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.23 on epoch=87
05/17/2022 21:06:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.32 on epoch=88
05/17/2022 21:06:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.33 on epoch=89
05/17/2022 21:06:57 - INFO - __main__ - Global step 1250 Train loss 1.30 Classification-F1 0.06691307144268817 on epoch=89
05/17/2022 21:06:57 - INFO - __main__ - Saving model with best Classification-F1: 0.06300243323304709 -> 0.06691307144268817 on epoch=89, global_step=1250
05/17/2022 21:06:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.37 on epoch=89
05/17/2022 21:07:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.25 on epoch=90
05/17/2022 21:07:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.30 on epoch=91
05/17/2022 21:07:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.29 on epoch=92
05/17/2022 21:07:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.16 on epoch=92
05/17/2022 21:07:07 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.038237688237688236 on epoch=92
05/17/2022 21:07:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.33 on epoch=93
05/17/2022 21:07:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.23 on epoch=94
05/17/2022 21:07:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.36 on epoch=94
05/17/2022 21:07:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=95
05/17/2022 21:07:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.23 on epoch=96
05/17/2022 21:07:16 - INFO - __main__ - Global step 1350 Train loss 1.28 Classification-F1 0.05144941130462268 on epoch=96
05/17/2022 21:07:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.26 on epoch=97
05/17/2022 21:07:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=97
05/17/2022 21:07:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.22 on epoch=98
05/17/2022 21:07:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.25 on epoch=99
05/17/2022 21:07:23 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.27 on epoch=99
05/17/2022 21:07:25 - INFO - __main__ - Global step 1400 Train loss 1.24 Classification-F1 0.08281992497123736 on epoch=99
05/17/2022 21:07:26 - INFO - __main__ - Saving model with best Classification-F1: 0.06691307144268817 -> 0.08281992497123736 on epoch=99, global_step=1400
05/17/2022 21:07:27 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.21 on epoch=100
05/17/2022 21:07:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.32 on epoch=101
05/17/2022 21:07:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=102
05/17/2022 21:07:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=102
05/17/2022 21:07:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.25 on epoch=103
05/17/2022 21:07:35 - INFO - __main__ - Global step 1450 Train loss 1.24 Classification-F1 0.08307322929171668 on epoch=103
05/17/2022 21:07:35 - INFO - __main__ - Saving model with best Classification-F1: 0.08281992497123736 -> 0.08307322929171668 on epoch=103, global_step=1450
05/17/2022 21:07:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.27 on epoch=104
05/17/2022 21:07:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=104
05/17/2022 21:07:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=105
05/17/2022 21:07:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.26 on epoch=106
05/17/2022 21:07:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.25 on epoch=107
05/17/2022 21:07:44 - INFO - __main__ - Global step 1500 Train loss 1.22 Classification-F1 0.12168266516092603 on epoch=107
05/17/2022 21:07:44 - INFO - __main__ - Saving model with best Classification-F1: 0.08307322929171668 -> 0.12168266516092603 on epoch=107, global_step=1500
05/17/2022 21:07:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.23 on epoch=107
05/17/2022 21:07:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.21 on epoch=108
05/17/2022 21:07:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.20 on epoch=109
05/17/2022 21:07:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.19 on epoch=109
05/17/2022 21:07:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=110
05/17/2022 21:07:54 - INFO - __main__ - Global step 1550 Train loss 1.20 Classification-F1 0.07959624603180747 on epoch=110
05/17/2022 21:07:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.20 on epoch=111
05/17/2022 21:07:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.24 on epoch=112
05/17/2022 21:07:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.06 on epoch=112
05/17/2022 21:07:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.29 on epoch=113
05/17/2022 21:08:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=114
05/17/2022 21:08:03 - INFO - __main__ - Global step 1600 Train loss 1.19 Classification-F1 0.12276730686482791 on epoch=114
05/17/2022 21:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.12168266516092603 -> 0.12276730686482791 on epoch=114, global_step=1600
05/17/2022 21:08:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.21 on epoch=114
05/17/2022 21:08:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.07 on epoch=115
05/17/2022 21:08:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.24 on epoch=116
05/17/2022 21:08:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.25 on epoch=117
05/17/2022 21:08:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.13 on epoch=117
05/17/2022 21:08:13 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.12345958502728403 on epoch=117
05/17/2022 21:08:13 - INFO - __main__ - Saving model with best Classification-F1: 0.12276730686482791 -> 0.12345958502728403 on epoch=117, global_step=1650
05/17/2022 21:08:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.21 on epoch=118
05/17/2022 21:08:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.21 on epoch=119
05/17/2022 21:08:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.15 on epoch=119
05/17/2022 21:08:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.16 on epoch=120
05/17/2022 21:08:19 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.21 on epoch=121
05/17/2022 21:08:22 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.17333122665323633 on epoch=121
05/17/2022 21:08:22 - INFO - __main__ - Saving model with best Classification-F1: 0.12345958502728403 -> 0.17333122665323633 on epoch=121, global_step=1700
05/17/2022 21:08:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.20 on epoch=122
05/17/2022 21:08:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.11 on epoch=122
05/17/2022 21:08:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/17/2022 21:08:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=124
05/17/2022 21:08:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=124
05/17/2022 21:08:32 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.2947548426917076 on epoch=124
05/17/2022 21:08:32 - INFO - __main__ - Saving model with best Classification-F1: 0.17333122665323633 -> 0.2947548426917076 on epoch=124, global_step=1750
05/17/2022 21:08:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.11 on epoch=125
05/17/2022 21:08:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.23 on epoch=126
05/17/2022 21:08:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.15 on epoch=127
05/17/2022 21:08:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=127
05/17/2022 21:08:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.19 on epoch=128
05/17/2022 21:08:41 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.28129946652764326 on epoch=128
05/17/2022 21:08:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=129
05/17/2022 21:08:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.13 on epoch=129
05/17/2022 21:08:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.05 on epoch=130
05/17/2022 21:08:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.20 on epoch=131
05/17/2022 21:08:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.17 on epoch=132
05/17/2022 21:08:51 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.2745929375554283 on epoch=132
05/17/2022 21:08:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.99 on epoch=132
05/17/2022 21:08:53 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.09 on epoch=133
05/17/2022 21:08:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.15 on epoch=134
05/17/2022 21:08:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.12 on epoch=134
05/17/2022 21:08:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.06 on epoch=135
05/17/2022 21:09:00 - INFO - __main__ - Global step 1900 Train loss 1.08 Classification-F1 0.2562242791710766 on epoch=135
05/17/2022 21:09:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=136
05/17/2022 21:09:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=137
05/17/2022 21:09:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=137
05/17/2022 21:09:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.09 on epoch=138
05/17/2022 21:09:07 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.08 on epoch=139
05/17/2022 21:09:10 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.28904887784968886 on epoch=139
05/17/2022 21:09:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=139
05/17/2022 21:09:13 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=140
05/17/2022 21:09:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=141
05/17/2022 21:09:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.12 on epoch=142
05/17/2022 21:09:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.00 on epoch=142
05/17/2022 21:09:20 - INFO - __main__ - Global step 2000 Train loss 1.05 Classification-F1 0.30186781982880856 on epoch=142
05/17/2022 21:09:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2947548426917076 -> 0.30186781982880856 on epoch=142, global_step=2000
05/17/2022 21:09:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.10 on epoch=143
05/17/2022 21:09:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=144
05/17/2022 21:09:24 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.09 on epoch=144
05/17/2022 21:09:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.99 on epoch=145
05/17/2022 21:09:26 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=146
05/17/2022 21:09:30 - INFO - __main__ - Global step 2050 Train loss 1.05 Classification-F1 0.3039998267461244 on epoch=146
05/17/2022 21:09:30 - INFO - __main__ - Saving model with best Classification-F1: 0.30186781982880856 -> 0.3039998267461244 on epoch=146, global_step=2050
05/17/2022 21:09:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.11 on epoch=147
05/17/2022 21:09:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.97 on epoch=147
05/17/2022 21:09:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=148
05/17/2022 21:09:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=149
05/17/2022 21:09:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/17/2022 21:09:39 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.29119038245893986 on epoch=149
05/17/2022 21:09:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=150
05/17/2022 21:09:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.07 on epoch=151
05/17/2022 21:09:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=152
05/17/2022 21:09:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=152
05/17/2022 21:09:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=153
05/17/2022 21:09:49 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.3507313135044227 on epoch=153
05/17/2022 21:09:49 - INFO - __main__ - Saving model with best Classification-F1: 0.3039998267461244 -> 0.3507313135044227 on epoch=153, global_step=2150
05/17/2022 21:09:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.05 on epoch=154
05/17/2022 21:09:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=154
05/17/2022 21:09:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.01 on epoch=155
05/17/2022 21:09:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.02 on epoch=156
05/17/2022 21:09:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.00 on epoch=157
05/17/2022 21:09:58 - INFO - __main__ - Global step 2200 Train loss 1.04 Classification-F1 0.33001990386978275 on epoch=157
05/17/2022 21:10:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=157
05/17/2022 21:10:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.12 on epoch=158
05/17/2022 21:10:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.08 on epoch=159
05/17/2022 21:10:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.13 on epoch=159
05/17/2022 21:10:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.88 on epoch=160
05/17/2022 21:10:08 - INFO - __main__ - Global step 2250 Train loss 1.04 Classification-F1 0.3758289588727753 on epoch=160
05/17/2022 21:10:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3507313135044227 -> 0.3758289588727753 on epoch=160, global_step=2250
05/17/2022 21:10:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.05 on epoch=161
05/17/2022 21:10:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=162
05/17/2022 21:10:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=162
05/17/2022 21:10:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=163
05/17/2022 21:10:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.04 on epoch=164
05/17/2022 21:10:18 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.4062961384389956 on epoch=164
05/17/2022 21:10:18 - INFO - __main__ - Saving model with best Classification-F1: 0.3758289588727753 -> 0.4062961384389956 on epoch=164, global_step=2300
05/17/2022 21:10:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=164
05/17/2022 21:10:20 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=165
05/17/2022 21:10:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.03 on epoch=166
05/17/2022 21:10:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.98 on epoch=167
05/17/2022 21:10:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=167
05/17/2022 21:10:28 - INFO - __main__ - Global step 2350 Train loss 0.97 Classification-F1 0.4417421361327288 on epoch=167
05/17/2022 21:10:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4062961384389956 -> 0.4417421361327288 on epoch=167, global_step=2350
05/17/2022 21:10:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.00 on epoch=168
05/17/2022 21:10:30 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=169
05/17/2022 21:10:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=169
05/17/2022 21:10:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.96 on epoch=170
05/17/2022 21:10:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.07 on epoch=171
05/17/2022 21:10:37 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.384324895188117 on epoch=171
05/17/2022 21:10:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.01 on epoch=172
05/17/2022 21:10:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.01 on epoch=172
05/17/2022 21:10:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.10 on epoch=173
05/17/2022 21:10:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.97 on epoch=174
05/17/2022 21:10:44 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.04 on epoch=174
05/17/2022 21:10:47 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.44886267316017464 on epoch=174
05/17/2022 21:10:47 - INFO - __main__ - Saving model with best Classification-F1: 0.4417421361327288 -> 0.44886267316017464 on epoch=174, global_step=2450
05/17/2022 21:10:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=175
05/17/2022 21:10:50 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=176
05/17/2022 21:10:51 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.94 on epoch=177
05/17/2022 21:10:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.91 on epoch=177
05/17/2022 21:10:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=178
05/17/2022 21:10:58 - INFO - __main__ - Global step 2500 Train loss 0.98 Classification-F1 0.4274855307233581 on epoch=178
05/17/2022 21:10:59 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.07 on epoch=179
05/17/2022 21:11:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=179
05/17/2022 21:11:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.96 on epoch=180
05/17/2022 21:11:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.06 on epoch=181
05/17/2022 21:11:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.01 on epoch=182
05/17/2022 21:11:08 - INFO - __main__ - Global step 2550 Train loss 1.01 Classification-F1 0.47661308288721277 on epoch=182
05/17/2022 21:11:08 - INFO - __main__ - Saving model with best Classification-F1: 0.44886267316017464 -> 0.47661308288721277 on epoch=182, global_step=2550
05/17/2022 21:11:09 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.88 on epoch=182
05/17/2022 21:11:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.88 on epoch=183
05/17/2022 21:11:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.95 on epoch=184
05/17/2022 21:11:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=184
05/17/2022 21:11:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.82 on epoch=185
05/17/2022 21:11:18 - INFO - __main__ - Global step 2600 Train loss 0.90 Classification-F1 0.4729061665880003 on epoch=185
05/17/2022 21:11:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.96 on epoch=186
05/17/2022 21:11:20 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=187
05/17/2022 21:11:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=187
05/17/2022 21:11:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.86 on epoch=188
05/17/2022 21:11:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.92 on epoch=189
05/17/2022 21:11:28 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.4233033097332525 on epoch=189
05/17/2022 21:11:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.94 on epoch=189
05/17/2022 21:11:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.78 on epoch=190
05/17/2022 21:11:31 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.98 on epoch=191
05/17/2022 21:11:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=192
05/17/2022 21:11:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.97 on epoch=192
05/17/2022 21:11:38 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.48210911671316004 on epoch=192
05/17/2022 21:11:38 - INFO - __main__ - Saving model with best Classification-F1: 0.47661308288721277 -> 0.48210911671316004 on epoch=192, global_step=2700
05/17/2022 21:11:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.99 on epoch=193
05/17/2022 21:11:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=194
05/17/2022 21:11:42 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.98 on epoch=194
05/17/2022 21:11:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=195
05/17/2022 21:11:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.91 on epoch=196
05/17/2022 21:11:48 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.40626823074767443 on epoch=196
05/17/2022 21:11:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.01 on epoch=197
05/17/2022 21:11:51 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.89 on epoch=197
05/17/2022 21:11:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=198
05/17/2022 21:11:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=199
05/17/2022 21:11:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=199
05/17/2022 21:11:58 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.433508534909919 on epoch=199
05/17/2022 21:11:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.84 on epoch=200
05/17/2022 21:12:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.05 on epoch=201
05/17/2022 21:12:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=202
05/17/2022 21:12:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=202
05/17/2022 21:12:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.95 on epoch=203
05/17/2022 21:12:08 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.39970260075938707 on epoch=203
05/17/2022 21:12:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.96 on epoch=204
05/17/2022 21:12:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.85 on epoch=204
05/17/2022 21:12:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.86 on epoch=205
05/17/2022 21:12:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.86 on epoch=206
05/17/2022 21:12:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.90 on epoch=207
05/17/2022 21:12:18 - INFO - __main__ - Global step 2900 Train loss 0.89 Classification-F1 0.378866203826282 on epoch=207
05/17/2022 21:12:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=207
05/17/2022 21:12:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.90 on epoch=208
05/17/2022 21:12:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=209
05/17/2022 21:12:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.86 on epoch=209
05/17/2022 21:12:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.75 on epoch=210
05/17/2022 21:12:28 - INFO - __main__ - Global step 2950 Train loss 0.86 Classification-F1 0.35299212529034485 on epoch=210
05/17/2022 21:12:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.82 on epoch=211
05/17/2022 21:12:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.86 on epoch=212
05/17/2022 21:12:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.84 on epoch=212
05/17/2022 21:12:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.89 on epoch=213
05/17/2022 21:12:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=214
05/17/2022 21:12:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:12:36 - INFO - __main__ - Printing 3 examples
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:12:36 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:12:36 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:12:36 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:12:36 - INFO - __main__ - Printing 3 examples
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:12:36 - INFO - __main__ - ['Film']
05/17/2022 21:12:36 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:12:36 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:12:36 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:12:38 - INFO - __main__ - Global step 3000 Train loss 0.87 Classification-F1 0.3544864042036155 on epoch=214
05/17/2022 21:12:38 - INFO - __main__ - save last model!
05/17/2022 21:12:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:12:38 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:12:38 - INFO - __main__ - Printing 3 examples
05/17/2022 21:12:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:12:38 - INFO - __main__ - ['Animal']
05/17/2022 21:12:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:12:38 - INFO - __main__ - ['Animal']
05/17/2022 21:12:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:12:38 - INFO - __main__ - ['Village']
05/17/2022 21:12:38 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:12:40 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:12:42 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:12:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:12:42 - INFO - __main__ - Starting training!
05/17/2022 21:12:43 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:13:41 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/17/2022 21:13:41 - INFO - __main__ - Classification-F1 on test data: 0.1239
05/17/2022 21:13:42 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.48210911671316004, test_performance=0.1238813975355325
05/17/2022 21:13:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/17/2022 21:13:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:13:43 - INFO - __main__ - Printing 3 examples
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:13:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:13:43 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:13:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:13:43 - INFO - __main__ - Printing 3 examples
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:13:43 - INFO - __main__ - ['Film']
05/17/2022 21:13:43 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:13:43 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:13:44 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:13:49 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:13:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:13:50 - INFO - __main__ - Starting training!
05/17/2022 21:13:52 - INFO - __main__ - Step 10 Global step 10 Train loss 7.55 on epoch=0
05/17/2022 21:13:54 - INFO - __main__ - Step 20 Global step 20 Train loss 6.67 on epoch=1
05/17/2022 21:13:55 - INFO - __main__ - Step 30 Global step 30 Train loss 6.11 on epoch=2
05/17/2022 21:13:57 - INFO - __main__ - Step 40 Global step 40 Train loss 5.50 on epoch=2
05/17/2022 21:13:58 - INFO - __main__ - Step 50 Global step 50 Train loss 5.08 on epoch=3
05/17/2022 21:14:01 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=3
05/17/2022 21:14:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 21:14:02 - INFO - __main__ - Step 60 Global step 60 Train loss 4.59 on epoch=4
05/17/2022 21:14:04 - INFO - __main__ - Step 70 Global step 70 Train loss 4.27 on epoch=4
05/17/2022 21:14:05 - INFO - __main__ - Step 80 Global step 80 Train loss 4.11 on epoch=5
05/17/2022 21:14:06 - INFO - __main__ - Step 90 Global step 90 Train loss 3.87 on epoch=6
05/17/2022 21:14:08 - INFO - __main__ - Step 100 Global step 100 Train loss 3.70 on epoch=7
05/17/2022 21:14:11 - INFO - __main__ - Global step 100 Train loss 4.11 Classification-F1 0.0 on epoch=7
05/17/2022 21:14:12 - INFO - __main__ - Step 110 Global step 110 Train loss 3.49 on epoch=7
05/17/2022 21:14:13 - INFO - __main__ - Step 120 Global step 120 Train loss 3.21 on epoch=8
05/17/2022 21:14:14 - INFO - __main__ - Step 130 Global step 130 Train loss 3.16 on epoch=9
05/17/2022 21:14:16 - INFO - __main__ - Step 140 Global step 140 Train loss 2.94 on epoch=9
05/17/2022 21:14:17 - INFO - __main__ - Step 150 Global step 150 Train loss 2.79 on epoch=10
05/17/2022 21:14:19 - INFO - __main__ - Global step 150 Train loss 3.12 Classification-F1 0.008080808080808083 on epoch=10
05/17/2022 21:14:19 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.008080808080808083 on epoch=10, global_step=150
05/17/2022 21:14:21 - INFO - __main__ - Step 160 Global step 160 Train loss 2.75 on epoch=11
05/17/2022 21:14:22 - INFO - __main__ - Step 170 Global step 170 Train loss 2.64 on epoch=12
05/17/2022 21:14:23 - INFO - __main__ - Step 180 Global step 180 Train loss 2.49 on epoch=12
05/17/2022 21:14:24 - INFO - __main__ - Step 190 Global step 190 Train loss 2.35 on epoch=13
05/17/2022 21:14:26 - INFO - __main__ - Step 200 Global step 200 Train loss 2.24 on epoch=14
05/17/2022 21:14:28 - INFO - __main__ - Global step 200 Train loss 2.49 Classification-F1 0.009563658099222952 on epoch=14
05/17/2022 21:14:28 - INFO - __main__ - Saving model with best Classification-F1: 0.008080808080808083 -> 0.009563658099222952 on epoch=14, global_step=200
05/17/2022 21:14:29 - INFO - __main__ - Step 210 Global step 210 Train loss 2.28 on epoch=14
05/17/2022 21:14:30 - INFO - __main__ - Step 220 Global step 220 Train loss 2.14 on epoch=15
05/17/2022 21:14:31 - INFO - __main__ - Step 230 Global step 230 Train loss 2.08 on epoch=16
05/17/2022 21:14:33 - INFO - __main__ - Step 240 Global step 240 Train loss 1.94 on epoch=17
05/17/2022 21:14:34 - INFO - __main__ - Step 250 Global step 250 Train loss 1.93 on epoch=17
05/17/2022 21:14:36 - INFO - __main__ - Global step 250 Train loss 2.07 Classification-F1 0.019982993197278913 on epoch=17
05/17/2022 21:14:36 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.019982993197278913 on epoch=17, global_step=250
05/17/2022 21:14:37 - INFO - __main__ - Step 260 Global step 260 Train loss 1.86 on epoch=18
05/17/2022 21:14:38 - INFO - __main__ - Step 270 Global step 270 Train loss 1.90 on epoch=19
05/17/2022 21:14:40 - INFO - __main__ - Step 280 Global step 280 Train loss 1.85 on epoch=19
05/17/2022 21:14:41 - INFO - __main__ - Step 290 Global step 290 Train loss 1.71 on epoch=20
05/17/2022 21:14:42 - INFO - __main__ - Step 300 Global step 300 Train loss 1.76 on epoch=21
05/17/2022 21:14:45 - INFO - __main__ - Global step 300 Train loss 1.81 Classification-F1 0.009563658099222952 on epoch=21
05/17/2022 21:14:46 - INFO - __main__ - Step 310 Global step 310 Train loss 1.55 on epoch=22
05/17/2022 21:14:47 - INFO - __main__ - Step 320 Global step 320 Train loss 1.62 on epoch=22
05/17/2022 21:14:48 - INFO - __main__ - Step 330 Global step 330 Train loss 1.54 on epoch=23
05/17/2022 21:14:50 - INFO - __main__ - Step 340 Global step 340 Train loss 1.56 on epoch=24
05/17/2022 21:14:51 - INFO - __main__ - Step 350 Global step 350 Train loss 1.58 on epoch=24
05/17/2022 21:14:53 - INFO - __main__ - Global step 350 Train loss 1.57 Classification-F1 0.009603841536614645 on epoch=24
05/17/2022 21:14:54 - INFO - __main__ - Step 360 Global step 360 Train loss 1.53 on epoch=25
05/17/2022 21:14:55 - INFO - __main__ - Step 370 Global step 370 Train loss 1.56 on epoch=26
05/17/2022 21:14:57 - INFO - __main__ - Step 380 Global step 380 Train loss 1.44 on epoch=27
05/17/2022 21:14:58 - INFO - __main__ - Step 390 Global step 390 Train loss 1.50 on epoch=27
05/17/2022 21:14:59 - INFO - __main__ - Step 400 Global step 400 Train loss 1.37 on epoch=28
05/17/2022 21:15:01 - INFO - __main__ - Global step 400 Train loss 1.48 Classification-F1 0.10126146255178514 on epoch=28
05/17/2022 21:15:01 - INFO - __main__ - Saving model with best Classification-F1: 0.019982993197278913 -> 0.10126146255178514 on epoch=28, global_step=400
05/17/2022 21:15:03 - INFO - __main__ - Step 410 Global step 410 Train loss 1.38 on epoch=29
05/17/2022 21:15:04 - INFO - __main__ - Step 420 Global step 420 Train loss 1.44 on epoch=29
05/17/2022 21:15:05 - INFO - __main__ - Step 430 Global step 430 Train loss 1.28 on epoch=30
05/17/2022 21:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 1.45 on epoch=31
05/17/2022 21:15:08 - INFO - __main__ - Step 450 Global step 450 Train loss 1.22 on epoch=32
05/17/2022 21:15:10 - INFO - __main__ - Global step 450 Train loss 1.35 Classification-F1 0.06000180375180375 on epoch=32
05/17/2022 21:15:11 - INFO - __main__ - Step 460 Global step 460 Train loss 1.34 on epoch=32
05/17/2022 21:15:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.26 on epoch=33
05/17/2022 21:15:14 - INFO - __main__ - Step 480 Global step 480 Train loss 1.24 on epoch=34
05/17/2022 21:15:15 - INFO - __main__ - Step 490 Global step 490 Train loss 1.31 on epoch=34
05/17/2022 21:15:16 - INFO - __main__ - Step 500 Global step 500 Train loss 1.31 on epoch=35
05/17/2022 21:15:18 - INFO - __main__ - Global step 500 Train loss 1.29 Classification-F1 0.07595259146983284 on epoch=35
05/17/2022 21:15:20 - INFO - __main__ - Step 510 Global step 510 Train loss 1.28 on epoch=36
05/17/2022 21:15:21 - INFO - __main__ - Step 520 Global step 520 Train loss 1.37 on epoch=37
05/17/2022 21:15:22 - INFO - __main__ - Step 530 Global step 530 Train loss 1.26 on epoch=37
05/17/2022 21:15:23 - INFO - __main__ - Step 540 Global step 540 Train loss 1.25 on epoch=38
05/17/2022 21:15:25 - INFO - __main__ - Step 550 Global step 550 Train loss 1.18 on epoch=39
05/17/2022 21:15:27 - INFO - __main__ - Global step 550 Train loss 1.27 Classification-F1 0.10223891234602155 on epoch=39
05/17/2022 21:15:27 - INFO - __main__ - Saving model with best Classification-F1: 0.10126146255178514 -> 0.10223891234602155 on epoch=39, global_step=550
05/17/2022 21:15:28 - INFO - __main__ - Step 560 Global step 560 Train loss 1.27 on epoch=39
05/17/2022 21:15:29 - INFO - __main__ - Step 570 Global step 570 Train loss 1.12 on epoch=40
05/17/2022 21:15:31 - INFO - __main__ - Step 580 Global step 580 Train loss 1.23 on epoch=41
05/17/2022 21:15:32 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/17/2022 21:15:33 - INFO - __main__ - Step 600 Global step 600 Train loss 1.18 on epoch=42
05/17/2022 21:15:35 - INFO - __main__ - Global step 600 Train loss 1.20 Classification-F1 0.10234874238173597 on epoch=42
05/17/2022 21:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.10223891234602155 -> 0.10234874238173597 on epoch=42, global_step=600
05/17/2022 21:15:36 - INFO - __main__ - Step 610 Global step 610 Train loss 1.10 on epoch=43
05/17/2022 21:15:38 - INFO - __main__ - Step 620 Global step 620 Train loss 1.25 on epoch=44
05/17/2022 21:15:39 - INFO - __main__ - Step 630 Global step 630 Train loss 1.35 on epoch=44
05/17/2022 21:15:40 - INFO - __main__ - Step 640 Global step 640 Train loss 1.15 on epoch=45
05/17/2022 21:15:42 - INFO - __main__ - Step 650 Global step 650 Train loss 1.22 on epoch=46
05/17/2022 21:15:44 - INFO - __main__ - Global step 650 Train loss 1.21 Classification-F1 0.23007386622212758 on epoch=46
05/17/2022 21:15:44 - INFO - __main__ - Saving model with best Classification-F1: 0.10234874238173597 -> 0.23007386622212758 on epoch=46, global_step=650
05/17/2022 21:15:45 - INFO - __main__ - Step 660 Global step 660 Train loss 1.10 on epoch=47
05/17/2022 21:15:46 - INFO - __main__ - Step 670 Global step 670 Train loss 1.22 on epoch=47
05/17/2022 21:15:48 - INFO - __main__ - Step 680 Global step 680 Train loss 1.05 on epoch=48
05/17/2022 21:15:49 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=49
05/17/2022 21:15:50 - INFO - __main__ - Step 700 Global step 700 Train loss 1.21 on epoch=49
05/17/2022 21:15:53 - INFO - __main__ - Global step 700 Train loss 1.16 Classification-F1 0.31285486893968034 on epoch=49
05/17/2022 21:15:53 - INFO - __main__ - Saving model with best Classification-F1: 0.23007386622212758 -> 0.31285486893968034 on epoch=49, global_step=700
05/17/2022 21:15:54 - INFO - __main__ - Step 710 Global step 710 Train loss 1.04 on epoch=50
05/17/2022 21:15:56 - INFO - __main__ - Step 720 Global step 720 Train loss 1.19 on epoch=51
05/17/2022 21:15:57 - INFO - __main__ - Step 730 Global step 730 Train loss 1.14 on epoch=52
05/17/2022 21:15:58 - INFO - __main__ - Step 740 Global step 740 Train loss 1.15 on epoch=52
05/17/2022 21:15:59 - INFO - __main__ - Step 750 Global step 750 Train loss 1.08 on epoch=53
05/17/2022 21:16:02 - INFO - __main__ - Global step 750 Train loss 1.12 Classification-F1 0.3519659926858258 on epoch=53
05/17/2022 21:16:02 - INFO - __main__ - Saving model with best Classification-F1: 0.31285486893968034 -> 0.3519659926858258 on epoch=53, global_step=750
05/17/2022 21:16:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.14 on epoch=54
05/17/2022 21:16:05 - INFO - __main__ - Step 770 Global step 770 Train loss 1.12 on epoch=54
05/17/2022 21:16:06 - INFO - __main__ - Step 780 Global step 780 Train loss 1.10 on epoch=55
05/17/2022 21:16:07 - INFO - __main__ - Step 790 Global step 790 Train loss 1.13 on epoch=56
05/17/2022 21:16:09 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/17/2022 21:16:12 - INFO - __main__ - Global step 800 Train loss 1.12 Classification-F1 0.3353294211188876 on epoch=57
05/17/2022 21:16:13 - INFO - __main__ - Step 810 Global step 810 Train loss 1.19 on epoch=57
05/17/2022 21:16:14 - INFO - __main__ - Step 820 Global step 820 Train loss 1.01 on epoch=58
05/17/2022 21:16:16 - INFO - __main__ - Step 830 Global step 830 Train loss 1.06 on epoch=59
05/17/2022 21:16:17 - INFO - __main__ - Step 840 Global step 840 Train loss 1.17 on epoch=59
05/17/2022 21:16:18 - INFO - __main__ - Step 850 Global step 850 Train loss 1.02 on epoch=60
05/17/2022 21:16:21 - INFO - __main__ - Global step 850 Train loss 1.09 Classification-F1 0.389579839230288 on epoch=60
05/17/2022 21:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.3519659926858258 -> 0.389579839230288 on epoch=60, global_step=850
05/17/2022 21:16:23 - INFO - __main__ - Step 860 Global step 860 Train loss 1.06 on epoch=61
05/17/2022 21:16:24 - INFO - __main__ - Step 870 Global step 870 Train loss 1.02 on epoch=62
05/17/2022 21:16:25 - INFO - __main__ - Step 880 Global step 880 Train loss 1.02 on epoch=62
05/17/2022 21:16:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.93 on epoch=63
05/17/2022 21:16:28 - INFO - __main__ - Step 900 Global step 900 Train loss 1.02 on epoch=64
05/17/2022 21:16:31 - INFO - __main__ - Global step 900 Train loss 1.01 Classification-F1 0.380121073190359 on epoch=64
05/17/2022 21:16:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.99 on epoch=64
05/17/2022 21:16:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.02 on epoch=65
05/17/2022 21:16:35 - INFO - __main__ - Step 930 Global step 930 Train loss 1.00 on epoch=66
05/17/2022 21:16:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.93 on epoch=67
05/17/2022 21:16:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.95 on epoch=67
05/17/2022 21:16:41 - INFO - __main__ - Global step 950 Train loss 0.98 Classification-F1 0.34361337212457854 on epoch=67
05/17/2022 21:16:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.96 on epoch=68
05/17/2022 21:16:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.94 on epoch=69
05/17/2022 21:16:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.98 on epoch=69
05/17/2022 21:16:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.86 on epoch=70
05/17/2022 21:16:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.91 on epoch=71
05/17/2022 21:16:51 - INFO - __main__ - Global step 1000 Train loss 0.93 Classification-F1 0.360171074031102 on epoch=71
05/17/2022 21:16:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.95 on epoch=72
05/17/2022 21:16:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.85 on epoch=72
05/17/2022 21:16:55 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.85 on epoch=73
05/17/2022 21:16:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.82 on epoch=74
05/17/2022 21:16:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.81 on epoch=74
05/17/2022 21:17:00 - INFO - __main__ - Global step 1050 Train loss 0.86 Classification-F1 0.4689939005423435 on epoch=74
05/17/2022 21:17:01 - INFO - __main__ - Saving model with best Classification-F1: 0.389579839230288 -> 0.4689939005423435 on epoch=74, global_step=1050
05/17/2022 21:17:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.86 on epoch=75
05/17/2022 21:17:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.95 on epoch=76
05/17/2022 21:17:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.88 on epoch=77
05/17/2022 21:17:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.83 on epoch=77
05/17/2022 21:17:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.83 on epoch=78
05/17/2022 21:17:11 - INFO - __main__ - Global step 1100 Train loss 0.87 Classification-F1 0.44881895258635673 on epoch=78
05/17/2022 21:17:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.85 on epoch=79
05/17/2022 21:17:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.84 on epoch=79
05/17/2022 21:17:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.86 on epoch=80
05/17/2022 21:17:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.86 on epoch=81
05/17/2022 21:17:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.86 on epoch=82
05/17/2022 21:17:21 - INFO - __main__ - Global step 1150 Train loss 0.86 Classification-F1 0.4365186515405813 on epoch=82
05/17/2022 21:17:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.87 on epoch=82
05/17/2022 21:17:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.84 on epoch=83
05/17/2022 21:17:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.93 on epoch=84
05/17/2022 21:17:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.85 on epoch=84
05/17/2022 21:17:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.78 on epoch=85
05/17/2022 21:17:30 - INFO - __main__ - Global step 1200 Train loss 0.85 Classification-F1 0.397994867365328 on epoch=85
05/17/2022 21:17:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.87 on epoch=86
05/17/2022 21:17:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.88 on epoch=87
05/17/2022 21:17:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.84 on epoch=87
05/17/2022 21:17:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.84 on epoch=88
05/17/2022 21:17:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.77 on epoch=89
05/17/2022 21:17:40 - INFO - __main__ - Global step 1250 Train loss 0.84 Classification-F1 0.5318285101191528 on epoch=89
05/17/2022 21:17:40 - INFO - __main__ - Saving model with best Classification-F1: 0.4689939005423435 -> 0.5318285101191528 on epoch=89, global_step=1250
05/17/2022 21:17:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.81 on epoch=89
05/17/2022 21:17:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.75 on epoch=90
05/17/2022 21:17:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.82 on epoch=91
05/17/2022 21:17:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.85 on epoch=92
05/17/2022 21:17:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.84 on epoch=92
05/17/2022 21:17:50 - INFO - __main__ - Global step 1300 Train loss 0.82 Classification-F1 0.48581846830841646 on epoch=92
05/17/2022 21:17:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.69 on epoch=93
05/17/2022 21:17:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.75 on epoch=94
05/17/2022 21:17:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.77 on epoch=94
05/17/2022 21:17:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.80 on epoch=95
05/17/2022 21:17:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.79 on epoch=96
05/17/2022 21:18:00 - INFO - __main__ - Global step 1350 Train loss 0.76 Classification-F1 0.4956556800516716 on epoch=96
05/17/2022 21:18:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.85 on epoch=97
05/17/2022 21:18:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.82 on epoch=97
05/17/2022 21:18:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.76 on epoch=98
05/17/2022 21:18:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.80 on epoch=99
05/17/2022 21:18:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.81 on epoch=99
05/17/2022 21:18:10 - INFO - __main__ - Global step 1400 Train loss 0.81 Classification-F1 0.3689093626653603 on epoch=99
05/17/2022 21:18:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/17/2022 21:18:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.78 on epoch=101
05/17/2022 21:18:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.78 on epoch=102
05/17/2022 21:18:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.67 on epoch=102
05/17/2022 21:18:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/17/2022 21:18:21 - INFO - __main__ - Global step 1450 Train loss 0.75 Classification-F1 0.3850186630345309 on epoch=103
05/17/2022 21:18:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.79 on epoch=104
05/17/2022 21:18:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.73 on epoch=104
05/17/2022 21:18:24 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.75 on epoch=105
05/17/2022 21:18:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.73 on epoch=106
05/17/2022 21:18:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.67 on epoch=107
05/17/2022 21:18:31 - INFO - __main__ - Global step 1500 Train loss 0.74 Classification-F1 0.4951428434032429 on epoch=107
05/17/2022 21:18:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.64 on epoch=107
05/17/2022 21:18:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.62 on epoch=108
05/17/2022 21:18:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.70 on epoch=109
05/17/2022 21:18:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.83 on epoch=109
05/17/2022 21:18:37 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.80 on epoch=110
05/17/2022 21:18:41 - INFO - __main__ - Global step 1550 Train loss 0.72 Classification-F1 0.4969139955083408 on epoch=110
05/17/2022 21:18:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.68 on epoch=111
05/17/2022 21:18:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.75 on epoch=112
05/17/2022 21:18:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.68 on epoch=112
05/17/2022 21:18:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.67 on epoch=113
05/17/2022 21:18:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.76 on epoch=114
05/17/2022 21:18:51 - INFO - __main__ - Global step 1600 Train loss 0.71 Classification-F1 0.4972849215162075 on epoch=114
05/17/2022 21:18:52 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.66 on epoch=114
05/17/2022 21:18:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.66 on epoch=115
05/17/2022 21:18:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.74 on epoch=116
05/17/2022 21:18:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.70 on epoch=117
05/17/2022 21:18:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.64 on epoch=117
05/17/2022 21:19:01 - INFO - __main__ - Global step 1650 Train loss 0.68 Classification-F1 0.47656793296257294 on epoch=117
05/17/2022 21:19:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.70 on epoch=118
05/17/2022 21:19:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.67 on epoch=119
05/17/2022 21:19:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.72 on epoch=119
05/17/2022 21:19:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.63 on epoch=120
05/17/2022 21:19:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.76 on epoch=121
05/17/2022 21:19:11 - INFO - __main__ - Global step 1700 Train loss 0.70 Classification-F1 0.42720131655890164 on epoch=121
05/17/2022 21:19:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.63 on epoch=122
05/17/2022 21:19:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.71 on epoch=122
05/17/2022 21:19:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.62 on epoch=123
05/17/2022 21:19:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.63 on epoch=124
05/17/2022 21:19:17 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.62 on epoch=124
05/17/2022 21:19:21 - INFO - __main__ - Global step 1750 Train loss 0.64 Classification-F1 0.46405691572143504 on epoch=124
05/17/2022 21:19:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.61 on epoch=125
05/17/2022 21:19:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.65 on epoch=126
05/17/2022 21:19:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.68 on epoch=127
05/17/2022 21:19:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.69 on epoch=127
05/17/2022 21:19:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.65 on epoch=128
05/17/2022 21:19:31 - INFO - __main__ - Global step 1800 Train loss 0.66 Classification-F1 0.4460508552749933 on epoch=128
05/17/2022 21:19:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.66 on epoch=129
05/17/2022 21:19:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.65 on epoch=129
05/17/2022 21:19:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.61 on epoch=130
05/17/2022 21:19:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.63 on epoch=131
05/17/2022 21:19:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.64 on epoch=132
05/17/2022 21:19:41 - INFO - __main__ - Global step 1850 Train loss 0.64 Classification-F1 0.41060495737560615 on epoch=132
05/17/2022 21:19:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.65 on epoch=132
05/17/2022 21:19:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.63 on epoch=133
05/17/2022 21:19:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.63 on epoch=134
05/17/2022 21:19:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.74 on epoch=134
05/17/2022 21:19:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.69 on epoch=135
05/17/2022 21:19:51 - INFO - __main__ - Global step 1900 Train loss 0.67 Classification-F1 0.379192006967777 on epoch=135
05/17/2022 21:19:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.63 on epoch=136
05/17/2022 21:19:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.69 on epoch=137
05/17/2022 21:19:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.64 on epoch=137
05/17/2022 21:19:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.65 on epoch=138
05/17/2022 21:19:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.63 on epoch=139
05/17/2022 21:20:01 - INFO - __main__ - Global step 1950 Train loss 0.65 Classification-F1 0.4417859929195246 on epoch=139
05/17/2022 21:20:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.57 on epoch=139
05/17/2022 21:20:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.56 on epoch=140
05/17/2022 21:20:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.68 on epoch=141
05/17/2022 21:20:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.63 on epoch=142
05/17/2022 21:20:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.59 on epoch=142
05/17/2022 21:20:11 - INFO - __main__ - Global step 2000 Train loss 0.60 Classification-F1 0.42149595187136285 on epoch=142
05/17/2022 21:20:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.60 on epoch=143
05/17/2022 21:20:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.64 on epoch=144
05/17/2022 21:20:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.60 on epoch=144
05/17/2022 21:20:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.63 on epoch=145
05/17/2022 21:20:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/17/2022 21:20:22 - INFO - __main__ - Global step 2050 Train loss 0.62 Classification-F1 0.46020787151263287 on epoch=146
05/17/2022 21:20:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.62 on epoch=147
05/17/2022 21:20:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.57 on epoch=147
05/17/2022 21:20:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.58 on epoch=148
05/17/2022 21:20:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.61 on epoch=149
05/17/2022 21:20:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.59 on epoch=149
05/17/2022 21:20:32 - INFO - __main__ - Global step 2100 Train loss 0.59 Classification-F1 0.4298916850992941 on epoch=149
05/17/2022 21:20:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.67 on epoch=150
05/17/2022 21:20:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/17/2022 21:20:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.54 on epoch=152
05/17/2022 21:20:37 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.61 on epoch=152
05/17/2022 21:20:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.62 on epoch=153
05/17/2022 21:20:42 - INFO - __main__ - Global step 2150 Train loss 0.62 Classification-F1 0.48407982276899697 on epoch=153
05/17/2022 21:20:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.67 on epoch=154
05/17/2022 21:20:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.58 on epoch=154
05/17/2022 21:20:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.59 on epoch=155
05/17/2022 21:20:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.59 on epoch=156
05/17/2022 21:20:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.63 on epoch=157
05/17/2022 21:20:52 - INFO - __main__ - Global step 2200 Train loss 0.61 Classification-F1 0.4976790111884787 on epoch=157
05/17/2022 21:20:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.65 on epoch=157
05/17/2022 21:20:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.55 on epoch=158
05/17/2022 21:20:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.64 on epoch=159
05/17/2022 21:20:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.59 on epoch=159
05/17/2022 21:20:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.58 on epoch=160
05/17/2022 21:21:02 - INFO - __main__ - Global step 2250 Train loss 0.60 Classification-F1 0.5912790143976662 on epoch=160
05/17/2022 21:21:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5318285101191528 -> 0.5912790143976662 on epoch=160, global_step=2250
05/17/2022 21:21:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.62 on epoch=161
05/17/2022 21:21:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.61 on epoch=162
05/17/2022 21:21:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.57 on epoch=162
05/17/2022 21:21:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.51 on epoch=163
05/17/2022 21:21:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.70 on epoch=164
05/17/2022 21:21:12 - INFO - __main__ - Global step 2300 Train loss 0.60 Classification-F1 0.5167177731314463 on epoch=164
05/17/2022 21:21:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.58 on epoch=164
05/17/2022 21:21:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.49 on epoch=165
05/17/2022 21:21:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.55 on epoch=166
05/17/2022 21:21:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.64 on epoch=167
05/17/2022 21:21:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.60 on epoch=167
05/17/2022 21:21:23 - INFO - __main__ - Global step 2350 Train loss 0.57 Classification-F1 0.48657774856844727 on epoch=167
05/17/2022 21:21:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.60 on epoch=168
05/17/2022 21:21:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/17/2022 21:21:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.60 on epoch=169
05/17/2022 21:21:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.61 on epoch=170
05/17/2022 21:21:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.58 on epoch=171
05/17/2022 21:21:33 - INFO - __main__ - Global step 2400 Train loss 0.60 Classification-F1 0.5558206170028872 on epoch=171
05/17/2022 21:21:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.52 on epoch=172
05/17/2022 21:21:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.49 on epoch=172
05/17/2022 21:21:36 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.55 on epoch=173
05/17/2022 21:21:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.61 on epoch=174
05/17/2022 21:21:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.56 on epoch=174
05/17/2022 21:21:42 - INFO - __main__ - Global step 2450 Train loss 0.55 Classification-F1 0.5338870969811212 on epoch=174
05/17/2022 21:21:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.47 on epoch=175
05/17/2022 21:21:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.53 on epoch=176
05/17/2022 21:21:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.58 on epoch=177
05/17/2022 21:21:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.52 on epoch=177
05/17/2022 21:21:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.60 on epoch=178
05/17/2022 21:21:53 - INFO - __main__ - Global step 2500 Train loss 0.54 Classification-F1 0.46726728095755105 on epoch=178
05/17/2022 21:21:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.64 on epoch=179
05/17/2022 21:21:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.53 on epoch=179
05/17/2022 21:21:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.62 on epoch=180
05/17/2022 21:21:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.51 on epoch=181
05/17/2022 21:21:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.52 on epoch=182
05/17/2022 21:22:03 - INFO - __main__ - Global step 2550 Train loss 0.56 Classification-F1 0.46749946121204383 on epoch=182
05/17/2022 21:22:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.57 on epoch=182
05/17/2022 21:22:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.63 on epoch=183
05/17/2022 21:22:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/17/2022 21:22:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.56 on epoch=184
05/17/2022 21:22:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.49 on epoch=185
05/17/2022 21:22:13 - INFO - __main__ - Global step 2600 Train loss 0.58 Classification-F1 0.5550331626731819 on epoch=185
05/17/2022 21:22:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.56 on epoch=186
05/17/2022 21:22:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.63 on epoch=187
05/17/2022 21:22:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.57 on epoch=187
05/17/2022 21:22:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.59 on epoch=188
05/17/2022 21:22:19 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.59 on epoch=189
05/17/2022 21:22:23 - INFO - __main__ - Global step 2650 Train loss 0.59 Classification-F1 0.5317821295494006 on epoch=189
05/17/2022 21:22:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.55 on epoch=189
05/17/2022 21:22:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.48 on epoch=190
05/17/2022 21:22:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.56 on epoch=191
05/17/2022 21:22:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.49 on epoch=192
05/17/2022 21:22:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/17/2022 21:22:33 - INFO - __main__ - Global step 2700 Train loss 0.53 Classification-F1 0.5402856870943622 on epoch=192
05/17/2022 21:22:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.52 on epoch=193
05/17/2022 21:22:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.53 on epoch=194
05/17/2022 21:22:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.52 on epoch=194
05/17/2022 21:22:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.61 on epoch=195
05/17/2022 21:22:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.54 on epoch=196
05/17/2022 21:22:44 - INFO - __main__ - Global step 2750 Train loss 0.55 Classification-F1 0.47607618925868217 on epoch=196
05/17/2022 21:22:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.56 on epoch=197
05/17/2022 21:22:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.45 on epoch=197
05/17/2022 21:22:47 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.51 on epoch=198
05/17/2022 21:22:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.48 on epoch=199
05/17/2022 21:22:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.51 on epoch=199
05/17/2022 21:22:54 - INFO - __main__ - Global step 2800 Train loss 0.50 Classification-F1 0.4492237220517135 on epoch=199
05/17/2022 21:22:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.56 on epoch=200
05/17/2022 21:22:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.57 on epoch=201
05/17/2022 21:22:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.53 on epoch=202
05/17/2022 21:22:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.50 on epoch=202
05/17/2022 21:23:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.43 on epoch=203
05/17/2022 21:23:04 - INFO - __main__ - Global step 2850 Train loss 0.52 Classification-F1 0.5638059574905889 on epoch=203
05/17/2022 21:23:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.53 on epoch=204
05/17/2022 21:23:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.52 on epoch=204
05/17/2022 21:23:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.53 on epoch=205
05/17/2022 21:23:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.52 on epoch=206
05/17/2022 21:23:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.54 on epoch=207
05/17/2022 21:23:15 - INFO - __main__ - Global step 2900 Train loss 0.53 Classification-F1 0.6164385602380915 on epoch=207
05/17/2022 21:23:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5912790143976662 -> 0.6164385602380915 on epoch=207, global_step=2900
05/17/2022 21:23:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.49 on epoch=207
05/17/2022 21:23:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.53 on epoch=208
05/17/2022 21:23:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.53 on epoch=209
05/17/2022 21:23:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.53 on epoch=209
05/17/2022 21:23:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.53 on epoch=210
05/17/2022 21:23:25 - INFO - __main__ - Global step 2950 Train loss 0.52 Classification-F1 0.5838923130885606 on epoch=210
05/17/2022 21:23:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.43 on epoch=211
05/17/2022 21:23:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.54 on epoch=212
05/17/2022 21:23:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.50 on epoch=212
05/17/2022 21:23:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.54 on epoch=213
05/17/2022 21:23:31 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.55 on epoch=214
05/17/2022 21:23:32 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:23:32 - INFO - __main__ - Printing 3 examples
05/17/2022 21:23:32 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:23:32 - INFO - __main__ - ['Film']
05/17/2022 21:23:32 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:23:32 - INFO - __main__ - ['Film']
05/17/2022 21:23:32 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:23:32 - INFO - __main__ - ['Film']
05/17/2022 21:23:32 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:23:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:23:33 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:23:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:23:33 - INFO - __main__ - Printing 3 examples
05/17/2022 21:23:33 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:23:33 - INFO - __main__ - ['Film']
05/17/2022 21:23:33 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:23:33 - INFO - __main__ - ['Film']
05/17/2022 21:23:33 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:23:33 - INFO - __main__ - ['Film']
05/17/2022 21:23:33 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:23:33 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:23:33 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:23:35 - INFO - __main__ - Global step 3000 Train loss 0.51 Classification-F1 0.6167040112613459 on epoch=214
05/17/2022 21:23:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6164385602380915 -> 0.6167040112613459 on epoch=214, global_step=3000
05/17/2022 21:23:35 - INFO - __main__ - save last model!
05/17/2022 21:23:35 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:23:35 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:23:35 - INFO - __main__ - Printing 3 examples
05/17/2022 21:23:35 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:23:35 - INFO - __main__ - ['Animal']
05/17/2022 21:23:35 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:23:35 - INFO - __main__ - ['Animal']
05/17/2022 21:23:35 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:23:35 - INFO - __main__ - ['Village']
05/17/2022 21:23:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:23:37 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:23:39 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:23:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:23:39 - INFO - __main__ - Starting training!
05/17/2022 21:23:40 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:24:45 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/17/2022 21:24:45 - INFO - __main__ - Classification-F1 on test data: 0.2621
05/17/2022 21:24:47 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.6167040112613459, test_performance=0.2620547890596715
05/17/2022 21:24:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/17/2022 21:24:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:24:48 - INFO - __main__ - Printing 3 examples
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:24:48 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:24:48 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:24:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:24:48 - INFO - __main__ - Printing 3 examples
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:24:48 - INFO - __main__ - ['Film']
05/17/2022 21:24:48 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:24:48 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:24:48 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:24:54 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:24:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:24:55 - INFO - __main__ - Starting training!
05/17/2022 21:24:56 - INFO - __main__ - Step 10 Global step 10 Train loss 7.61 on epoch=0
05/17/2022 21:24:58 - INFO - __main__ - Step 20 Global step 20 Train loss 7.23 on epoch=1
05/17/2022 21:24:59 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=2
05/17/2022 21:25:00 - INFO - __main__ - Step 40 Global step 40 Train loss 5.86 on epoch=2
05/17/2022 21:25:01 - INFO - __main__ - Step 50 Global step 50 Train loss 5.47 on epoch=3
05/17/2022 21:25:04 - INFO - __main__ - Global step 50 Train loss 6.51 Classification-F1 0.0 on epoch=3
05/17/2022 21:25:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 21:25:06 - INFO - __main__ - Step 60 Global step 60 Train loss 5.09 on epoch=4
05/17/2022 21:25:07 - INFO - __main__ - Step 70 Global step 70 Train loss 4.88 on epoch=4
05/17/2022 21:25:08 - INFO - __main__ - Step 80 Global step 80 Train loss 4.73 on epoch=5
05/17/2022 21:25:10 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=6
05/17/2022 21:25:11 - INFO - __main__ - Step 100 Global step 100 Train loss 4.10 on epoch=7
05/17/2022 21:25:14 - INFO - __main__ - Global step 100 Train loss 4.64 Classification-F1 0.0 on epoch=7
05/17/2022 21:25:15 - INFO - __main__ - Step 110 Global step 110 Train loss 4.02 on epoch=7
05/17/2022 21:25:17 - INFO - __main__ - Step 120 Global step 120 Train loss 3.80 on epoch=8
05/17/2022 21:25:18 - INFO - __main__ - Step 130 Global step 130 Train loss 3.59 on epoch=9
05/17/2022 21:25:19 - INFO - __main__ - Step 140 Global step 140 Train loss 3.46 on epoch=9
05/17/2022 21:25:21 - INFO - __main__ - Step 150 Global step 150 Train loss 3.32 on epoch=10
05/17/2022 21:25:24 - INFO - __main__ - Global step 150 Train loss 3.64 Classification-F1 0.003676470588235294 on epoch=10
05/17/2022 21:25:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.003676470588235294 on epoch=10, global_step=150
05/17/2022 21:25:25 - INFO - __main__ - Step 160 Global step 160 Train loss 3.25 on epoch=11
05/17/2022 21:25:27 - INFO - __main__ - Step 170 Global step 170 Train loss 3.07 on epoch=12
05/17/2022 21:25:28 - INFO - __main__ - Step 180 Global step 180 Train loss 2.92 on epoch=12
05/17/2022 21:25:29 - INFO - __main__ - Step 190 Global step 190 Train loss 2.71 on epoch=13
05/17/2022 21:25:31 - INFO - __main__ - Step 200 Global step 200 Train loss 2.75 on epoch=14
05/17/2022 21:25:33 - INFO - __main__ - Global step 200 Train loss 2.94 Classification-F1 0.00858085808580858 on epoch=14
05/17/2022 21:25:33 - INFO - __main__ - Saving model with best Classification-F1: 0.003676470588235294 -> 0.00858085808580858 on epoch=14, global_step=200
05/17/2022 21:25:34 - INFO - __main__ - Step 210 Global step 210 Train loss 2.68 on epoch=14
05/17/2022 21:25:36 - INFO - __main__ - Step 220 Global step 220 Train loss 2.44 on epoch=15
05/17/2022 21:25:37 - INFO - __main__ - Step 230 Global step 230 Train loss 2.52 on epoch=16
05/17/2022 21:25:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.33 on epoch=17
05/17/2022 21:25:39 - INFO - __main__ - Step 250 Global step 250 Train loss 2.27 on epoch=17
05/17/2022 21:25:41 - INFO - __main__ - Global step 250 Train loss 2.45 Classification-F1 0.009523809523809523 on epoch=17
05/17/2022 21:25:41 - INFO - __main__ - Saving model with best Classification-F1: 0.00858085808580858 -> 0.009523809523809523 on epoch=17, global_step=250
05/17/2022 21:25:43 - INFO - __main__ - Step 260 Global step 260 Train loss 2.30 on epoch=18
05/17/2022 21:25:44 - INFO - __main__ - Step 270 Global step 270 Train loss 2.16 on epoch=19
05/17/2022 21:25:45 - INFO - __main__ - Step 280 Global step 280 Train loss 2.12 on epoch=19
05/17/2022 21:25:46 - INFO - __main__ - Step 290 Global step 290 Train loss 1.95 on epoch=20
05/17/2022 21:25:48 - INFO - __main__ - Step 300 Global step 300 Train loss 2.03 on epoch=21
05/17/2022 21:25:50 - INFO - __main__ - Global step 300 Train loss 2.11 Classification-F1 0.019667128987517334 on epoch=21
05/17/2022 21:25:50 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.019667128987517334 on epoch=21, global_step=300
05/17/2022 21:25:51 - INFO - __main__ - Step 310 Global step 310 Train loss 1.93 on epoch=22
05/17/2022 21:25:53 - INFO - __main__ - Step 320 Global step 320 Train loss 1.90 on epoch=22
05/17/2022 21:25:54 - INFO - __main__ - Step 330 Global step 330 Train loss 1.69 on epoch=23
05/17/2022 21:25:55 - INFO - __main__ - Step 340 Global step 340 Train loss 1.84 on epoch=24
05/17/2022 21:25:56 - INFO - __main__ - Step 350 Global step 350 Train loss 1.79 on epoch=24
05/17/2022 21:25:58 - INFO - __main__ - Global step 350 Train loss 1.83 Classification-F1 0.015154185022026432 on epoch=24
05/17/2022 21:26:00 - INFO - __main__ - Step 360 Global step 360 Train loss 1.67 on epoch=25
05/17/2022 21:26:01 - INFO - __main__ - Step 370 Global step 370 Train loss 1.68 on epoch=26
05/17/2022 21:26:02 - INFO - __main__ - Step 380 Global step 380 Train loss 1.66 on epoch=27
05/17/2022 21:26:04 - INFO - __main__ - Step 390 Global step 390 Train loss 1.62 on epoch=27
05/17/2022 21:26:05 - INFO - __main__ - Step 400 Global step 400 Train loss 1.38 on epoch=28
05/17/2022 21:26:07 - INFO - __main__ - Global step 400 Train loss 1.60 Classification-F1 0.045459506457162964 on epoch=28
05/17/2022 21:26:07 - INFO - __main__ - Saving model with best Classification-F1: 0.019667128987517334 -> 0.045459506457162964 on epoch=28, global_step=400
05/17/2022 21:26:08 - INFO - __main__ - Step 410 Global step 410 Train loss 1.54 on epoch=29
05/17/2022 21:26:09 - INFO - __main__ - Step 420 Global step 420 Train loss 1.56 on epoch=29
05/17/2022 21:26:11 - INFO - __main__ - Step 430 Global step 430 Train loss 1.49 on epoch=30
05/17/2022 21:26:12 - INFO - __main__ - Step 440 Global step 440 Train loss 1.46 on epoch=31
05/17/2022 21:26:13 - INFO - __main__ - Step 450 Global step 450 Train loss 1.50 on epoch=32
05/17/2022 21:26:16 - INFO - __main__ - Global step 450 Train loss 1.51 Classification-F1 0.03774608623006792 on epoch=32
05/17/2022 21:26:17 - INFO - __main__ - Step 460 Global step 460 Train loss 1.50 on epoch=32
05/17/2022 21:26:18 - INFO - __main__ - Step 470 Global step 470 Train loss 1.36 on epoch=33
05/17/2022 21:26:20 - INFO - __main__ - Step 480 Global step 480 Train loss 1.44 on epoch=34
05/17/2022 21:26:21 - INFO - __main__ - Step 490 Global step 490 Train loss 1.43 on epoch=34
05/17/2022 21:26:22 - INFO - __main__ - Step 500 Global step 500 Train loss 1.26 on epoch=35
05/17/2022 21:26:25 - INFO - __main__ - Global step 500 Train loss 1.40 Classification-F1 0.02813282191526838 on epoch=35
05/17/2022 21:26:26 - INFO - __main__ - Step 510 Global step 510 Train loss 1.35 on epoch=36
05/17/2022 21:26:27 - INFO - __main__ - Step 520 Global step 520 Train loss 1.37 on epoch=37
05/17/2022 21:26:28 - INFO - __main__ - Step 530 Global step 530 Train loss 1.34 on epoch=37
05/17/2022 21:26:30 - INFO - __main__ - Step 540 Global step 540 Train loss 1.35 on epoch=38
05/17/2022 21:26:31 - INFO - __main__ - Step 550 Global step 550 Train loss 1.27 on epoch=39
05/17/2022 21:26:33 - INFO - __main__ - Global step 550 Train loss 1.34 Classification-F1 0.04261294261294262 on epoch=39
05/17/2022 21:26:34 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=39
05/17/2022 21:26:36 - INFO - __main__ - Step 570 Global step 570 Train loss 1.21 on epoch=40
05/17/2022 21:26:37 - INFO - __main__ - Step 580 Global step 580 Train loss 1.24 on epoch=41
05/17/2022 21:26:38 - INFO - __main__ - Step 590 Global step 590 Train loss 1.36 on epoch=42
05/17/2022 21:26:39 - INFO - __main__ - Step 600 Global step 600 Train loss 1.26 on epoch=42
05/17/2022 21:26:42 - INFO - __main__ - Global step 600 Train loss 1.28 Classification-F1 0.04870786708131615 on epoch=42
05/17/2022 21:26:42 - INFO - __main__ - Saving model with best Classification-F1: 0.045459506457162964 -> 0.04870786708131615 on epoch=42, global_step=600
05/17/2022 21:26:43 - INFO - __main__ - Step 610 Global step 610 Train loss 1.19 on epoch=43
05/17/2022 21:26:45 - INFO - __main__ - Step 620 Global step 620 Train loss 1.31 on epoch=44
05/17/2022 21:26:46 - INFO - __main__ - Step 630 Global step 630 Train loss 1.24 on epoch=44
05/17/2022 21:26:47 - INFO - __main__ - Step 640 Global step 640 Train loss 1.25 on epoch=45
05/17/2022 21:26:48 - INFO - __main__ - Step 650 Global step 650 Train loss 1.11 on epoch=46
05/17/2022 21:26:50 - INFO - __main__ - Global step 650 Train loss 1.22 Classification-F1 0.07608732619385582 on epoch=46
05/17/2022 21:26:50 - INFO - __main__ - Saving model with best Classification-F1: 0.04870786708131615 -> 0.07608732619385582 on epoch=46, global_step=650
05/17/2022 21:26:52 - INFO - __main__ - Step 660 Global step 660 Train loss 1.14 on epoch=47
05/17/2022 21:26:53 - INFO - __main__ - Step 670 Global step 670 Train loss 1.25 on epoch=47
05/17/2022 21:26:54 - INFO - __main__ - Step 680 Global step 680 Train loss 1.24 on epoch=48
05/17/2022 21:26:56 - INFO - __main__ - Step 690 Global step 690 Train loss 1.26 on epoch=49
05/17/2022 21:26:57 - INFO - __main__ - Step 700 Global step 700 Train loss 1.12 on epoch=49
05/17/2022 21:26:59 - INFO - __main__ - Global step 700 Train loss 1.20 Classification-F1 0.09761790273024754 on epoch=49
05/17/2022 21:26:59 - INFO - __main__ - Saving model with best Classification-F1: 0.07608732619385582 -> 0.09761790273024754 on epoch=49, global_step=700
05/17/2022 21:27:00 - INFO - __main__ - Step 710 Global step 710 Train loss 1.19 on epoch=50
05/17/2022 21:27:02 - INFO - __main__ - Step 720 Global step 720 Train loss 1.22 on epoch=51
05/17/2022 21:27:03 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/17/2022 21:27:04 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=52
05/17/2022 21:27:05 - INFO - __main__ - Step 750 Global step 750 Train loss 1.08 on epoch=53
05/17/2022 21:27:08 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.15153506276785378 on epoch=53
05/17/2022 21:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.09761790273024754 -> 0.15153506276785378 on epoch=53, global_step=750
05/17/2022 21:27:09 - INFO - __main__ - Step 760 Global step 760 Train loss 1.16 on epoch=54
05/17/2022 21:27:10 - INFO - __main__ - Step 770 Global step 770 Train loss 1.15 on epoch=54
05/17/2022 21:27:12 - INFO - __main__ - Step 780 Global step 780 Train loss 1.13 on epoch=55
05/17/2022 21:27:13 - INFO - __main__ - Step 790 Global step 790 Train loss 1.21 on epoch=56
05/17/2022 21:27:14 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/17/2022 21:27:17 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.20225007727336922 on epoch=57
05/17/2022 21:27:17 - INFO - __main__ - Saving model with best Classification-F1: 0.15153506276785378 -> 0.20225007727336922 on epoch=57, global_step=800
05/17/2022 21:27:18 - INFO - __main__ - Step 810 Global step 810 Train loss 1.12 on epoch=57
05/17/2022 21:27:20 - INFO - __main__ - Step 820 Global step 820 Train loss 1.18 on epoch=58
05/17/2022 21:27:21 - INFO - __main__ - Step 830 Global step 830 Train loss 1.12 on epoch=59
05/17/2022 21:27:22 - INFO - __main__ - Step 840 Global step 840 Train loss 1.22 on epoch=59
05/17/2022 21:27:23 - INFO - __main__ - Step 850 Global step 850 Train loss 1.13 on epoch=60
05/17/2022 21:27:26 - INFO - __main__ - Global step 850 Train loss 1.15 Classification-F1 0.2969762771926456 on epoch=60
05/17/2022 21:27:26 - INFO - __main__ - Saving model with best Classification-F1: 0.20225007727336922 -> 0.2969762771926456 on epoch=60, global_step=850
05/17/2022 21:27:28 - INFO - __main__ - Step 860 Global step 860 Train loss 1.21 on epoch=61
05/17/2022 21:27:29 - INFO - __main__ - Step 870 Global step 870 Train loss 1.16 on epoch=62
05/17/2022 21:27:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=62
05/17/2022 21:27:31 - INFO - __main__ - Step 890 Global step 890 Train loss 1.12 on epoch=63
05/17/2022 21:27:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.12 on epoch=64
05/17/2022 21:27:36 - INFO - __main__ - Global step 900 Train loss 1.16 Classification-F1 0.2935278609879645 on epoch=64
05/17/2022 21:27:37 - INFO - __main__ - Step 910 Global step 910 Train loss 1.16 on epoch=64
05/17/2022 21:27:38 - INFO - __main__ - Step 920 Global step 920 Train loss 1.01 on epoch=65
05/17/2022 21:27:40 - INFO - __main__ - Step 930 Global step 930 Train loss 1.20 on epoch=66
05/17/2022 21:27:41 - INFO - __main__ - Step 940 Global step 940 Train loss 1.05 on epoch=67
05/17/2022 21:27:42 - INFO - __main__ - Step 950 Global step 950 Train loss 1.09 on epoch=67
05/17/2022 21:27:45 - INFO - __main__ - Global step 950 Train loss 1.11 Classification-F1 0.3369390499279126 on epoch=67
05/17/2022 21:27:45 - INFO - __main__ - Saving model with best Classification-F1: 0.2969762771926456 -> 0.3369390499279126 on epoch=67, global_step=950
05/17/2022 21:27:47 - INFO - __main__ - Step 960 Global step 960 Train loss 1.00 on epoch=68
05/17/2022 21:27:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.03 on epoch=69
05/17/2022 21:27:49 - INFO - __main__ - Step 980 Global step 980 Train loss 1.11 on epoch=69
05/17/2022 21:27:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.98 on epoch=70
05/17/2022 21:27:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.10 on epoch=71
05/17/2022 21:27:55 - INFO - __main__ - Global step 1000 Train loss 1.04 Classification-F1 0.343701780901904 on epoch=71
05/17/2022 21:27:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3369390499279126 -> 0.343701780901904 on epoch=71, global_step=1000
05/17/2022 21:27:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/17/2022 21:27:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.15 on epoch=72
05/17/2022 21:27:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=73
05/17/2022 21:28:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.05 on epoch=74
05/17/2022 21:28:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.10 on epoch=74
05/17/2022 21:28:05 - INFO - __main__ - Global step 1050 Train loss 1.07 Classification-F1 0.37338642031846897 on epoch=74
05/17/2022 21:28:05 - INFO - __main__ - Saving model with best Classification-F1: 0.343701780901904 -> 0.37338642031846897 on epoch=74, global_step=1050
05/17/2022 21:28:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.97 on epoch=75
05/17/2022 21:28:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.95 on epoch=76
05/17/2022 21:28:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.02 on epoch=77
05/17/2022 21:28:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.02 on epoch=77
05/17/2022 21:28:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.96 on epoch=78
05/17/2022 21:28:14 - INFO - __main__ - Global step 1100 Train loss 0.98 Classification-F1 0.43537165021219787 on epoch=78
05/17/2022 21:28:14 - INFO - __main__ - Saving model with best Classification-F1: 0.37338642031846897 -> 0.43537165021219787 on epoch=78, global_step=1100
05/17/2022 21:28:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.92 on epoch=79
05/17/2022 21:28:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.05 on epoch=79
05/17/2022 21:28:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.97 on epoch=80
05/17/2022 21:28:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=81
05/17/2022 21:28:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.91 on epoch=82
05/17/2022 21:28:24 - INFO - __main__ - Global step 1150 Train loss 0.98 Classification-F1 0.42714428651850433 on epoch=82
05/17/2022 21:28:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.98 on epoch=82
05/17/2022 21:28:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.95 on epoch=83
05/17/2022 21:28:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.95 on epoch=84
05/17/2022 21:28:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.02 on epoch=84
05/17/2022 21:28:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.87 on epoch=85
05/17/2022 21:28:34 - INFO - __main__ - Global step 1200 Train loss 0.95 Classification-F1 0.44910829353455417 on epoch=85
05/17/2022 21:28:34 - INFO - __main__ - Saving model with best Classification-F1: 0.43537165021219787 -> 0.44910829353455417 on epoch=85, global_step=1200
05/17/2022 21:28:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.91 on epoch=86
05/17/2022 21:28:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.93 on epoch=87
05/17/2022 21:28:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.91 on epoch=87
05/17/2022 21:28:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.92 on epoch=88
05/17/2022 21:28:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.93 on epoch=89
05/17/2022 21:28:43 - INFO - __main__ - Global step 1250 Train loss 0.92 Classification-F1 0.4793966368612367 on epoch=89
05/17/2022 21:28:43 - INFO - __main__ - Saving model with best Classification-F1: 0.44910829353455417 -> 0.4793966368612367 on epoch=89, global_step=1250
05/17/2022 21:28:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.88 on epoch=89
05/17/2022 21:28:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.97 on epoch=90
05/17/2022 21:28:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.95 on epoch=91
05/17/2022 21:28:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.84 on epoch=92
05/17/2022 21:28:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.03 on epoch=92
05/17/2022 21:28:53 - INFO - __main__ - Global step 1300 Train loss 0.94 Classification-F1 0.4333580517887195 on epoch=92
05/17/2022 21:28:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.90 on epoch=93
05/17/2022 21:28:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.83 on epoch=94
05/17/2022 21:28:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.91 on epoch=94
05/17/2022 21:28:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.84 on epoch=95
05/17/2022 21:28:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.83 on epoch=96
05/17/2022 21:29:03 - INFO - __main__ - Global step 1350 Train loss 0.86 Classification-F1 0.4698671162599475 on epoch=96
05/17/2022 21:29:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.76 on epoch=97
05/17/2022 21:29:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.87 on epoch=97
05/17/2022 21:29:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.88 on epoch=98
05/17/2022 21:29:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.90 on epoch=99
05/17/2022 21:29:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.88 on epoch=99
05/17/2022 21:29:13 - INFO - __main__ - Global step 1400 Train loss 0.86 Classification-F1 0.47949550970726246 on epoch=99
05/17/2022 21:29:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4793966368612367 -> 0.47949550970726246 on epoch=99, global_step=1400
05/17/2022 21:29:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/17/2022 21:29:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.92 on epoch=101
05/17/2022 21:29:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.81 on epoch=102
05/17/2022 21:29:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.86 on epoch=102
05/17/2022 21:29:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.90 on epoch=103
05/17/2022 21:29:22 - INFO - __main__ - Global step 1450 Train loss 0.85 Classification-F1 0.4376252580877085 on epoch=103
05/17/2022 21:29:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.84 on epoch=104
05/17/2022 21:29:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.87 on epoch=104
05/17/2022 21:29:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.83 on epoch=105
05/17/2022 21:29:28 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.89 on epoch=106
05/17/2022 21:29:29 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.86 on epoch=107
05/17/2022 21:29:33 - INFO - __main__ - Global step 1500 Train loss 0.86 Classification-F1 0.39566403191403193 on epoch=107
05/17/2022 21:29:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.83 on epoch=107
05/17/2022 21:29:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.82 on epoch=108
05/17/2022 21:29:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.87 on epoch=109
05/17/2022 21:29:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=109
05/17/2022 21:29:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.79 on epoch=110
05/17/2022 21:29:42 - INFO - __main__ - Global step 1550 Train loss 0.83 Classification-F1 0.44913829129213584 on epoch=110
05/17/2022 21:29:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.75 on epoch=111
05/17/2022 21:29:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.80 on epoch=112
05/17/2022 21:29:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.84 on epoch=112
05/17/2022 21:29:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.74 on epoch=113
05/17/2022 21:29:49 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.80 on epoch=114
05/17/2022 21:29:52 - INFO - __main__ - Global step 1600 Train loss 0.79 Classification-F1 0.3892550605805874 on epoch=114
05/17/2022 21:29:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.86 on epoch=114
05/17/2022 21:29:55 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.73 on epoch=115
05/17/2022 21:29:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.87 on epoch=116
05/17/2022 21:29:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.76 on epoch=117
05/17/2022 21:29:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.81 on epoch=117
05/17/2022 21:30:02 - INFO - __main__ - Global step 1650 Train loss 0.80 Classification-F1 0.5256511978570801 on epoch=117
05/17/2022 21:30:02 - INFO - __main__ - Saving model with best Classification-F1: 0.47949550970726246 -> 0.5256511978570801 on epoch=117, global_step=1650
05/17/2022 21:30:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.92 on epoch=118
05/17/2022 21:30:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.80 on epoch=119
05/17/2022 21:30:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/17/2022 21:30:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.78 on epoch=120
05/17/2022 21:30:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.89 on epoch=121
05/17/2022 21:30:12 - INFO - __main__ - Global step 1700 Train loss 0.84 Classification-F1 0.48472201758971517 on epoch=121
05/17/2022 21:30:13 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.74 on epoch=122
05/17/2022 21:30:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.80 on epoch=122
05/17/2022 21:30:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.79 on epoch=123
05/17/2022 21:30:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.75 on epoch=124
05/17/2022 21:30:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.81 on epoch=124
05/17/2022 21:30:22 - INFO - __main__ - Global step 1750 Train loss 0.78 Classification-F1 0.5199893182018138 on epoch=124
05/17/2022 21:30:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/17/2022 21:30:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.71 on epoch=126
05/17/2022 21:30:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.73 on epoch=127
05/17/2022 21:30:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.88 on epoch=127
05/17/2022 21:30:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.82 on epoch=128
05/17/2022 21:30:33 - INFO - __main__ - Global step 1800 Train loss 0.77 Classification-F1 0.4781458076091719 on epoch=128
05/17/2022 21:30:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.75 on epoch=129
05/17/2022 21:30:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.77 on epoch=129
05/17/2022 21:30:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.78 on epoch=130
05/17/2022 21:30:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.80 on epoch=131
05/17/2022 21:30:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.77 on epoch=132
05/17/2022 21:30:43 - INFO - __main__ - Global step 1850 Train loss 0.77 Classification-F1 0.47460890910184605 on epoch=132
05/17/2022 21:30:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.84 on epoch=132
05/17/2022 21:30:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=133
05/17/2022 21:30:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.82 on epoch=134
05/17/2022 21:30:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.88 on epoch=134
05/17/2022 21:30:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.73 on epoch=135
05/17/2022 21:30:53 - INFO - __main__ - Global step 1900 Train loss 0.83 Classification-F1 0.5647611932600957 on epoch=135
05/17/2022 21:30:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5256511978570801 -> 0.5647611932600957 on epoch=135, global_step=1900
05/17/2022 21:30:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.80 on epoch=136
05/17/2022 21:30:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.87 on epoch=137
05/17/2022 21:30:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/17/2022 21:30:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.71 on epoch=138
05/17/2022 21:30:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.80 on epoch=139
05/17/2022 21:31:03 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.46234085215238024 on epoch=139
05/17/2022 21:31:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.77 on epoch=139
05/17/2022 21:31:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.78 on epoch=140
05/17/2022 21:31:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.73 on epoch=141
05/17/2022 21:31:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.78 on epoch=142
05/17/2022 21:31:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.77 on epoch=142
05/17/2022 21:31:13 - INFO - __main__ - Global step 2000 Train loss 0.77 Classification-F1 0.45560669923554 on epoch=142
05/17/2022 21:31:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.73 on epoch=143
05/17/2022 21:31:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.75 on epoch=144
05/17/2022 21:31:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.72 on epoch=144
05/17/2022 21:31:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.77 on epoch=145
05/17/2022 21:31:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.80 on epoch=146
05/17/2022 21:31:23 - INFO - __main__ - Global step 2050 Train loss 0.76 Classification-F1 0.42438872272077643 on epoch=146
05/17/2022 21:31:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.76 on epoch=147
05/17/2022 21:31:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.70 on epoch=147
05/17/2022 21:31:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.77 on epoch=148
05/17/2022 21:31:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.73 on epoch=149
05/17/2022 21:31:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.69 on epoch=149
05/17/2022 21:31:33 - INFO - __main__ - Global step 2100 Train loss 0.73 Classification-F1 0.48867141173513723 on epoch=149
05/17/2022 21:31:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.71 on epoch=150
05/17/2022 21:31:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.75 on epoch=151
05/17/2022 21:31:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.65 on epoch=152
05/17/2022 21:31:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.75 on epoch=152
05/17/2022 21:31:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.68 on epoch=153
05/17/2022 21:31:43 - INFO - __main__ - Global step 2150 Train loss 0.71 Classification-F1 0.4390922082556436 on epoch=153
05/17/2022 21:31:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.66 on epoch=154
05/17/2022 21:31:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.67 on epoch=154
05/17/2022 21:31:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.59 on epoch=155
05/17/2022 21:31:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.70 on epoch=156
05/17/2022 21:31:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.69 on epoch=157
05/17/2022 21:31:54 - INFO - __main__ - Global step 2200 Train loss 0.66 Classification-F1 0.46170984109300167 on epoch=157
05/17/2022 21:31:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.61 on epoch=157
05/17/2022 21:31:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.62 on epoch=158
05/17/2022 21:31:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.63 on epoch=159
05/17/2022 21:31:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/17/2022 21:32:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.63 on epoch=160
05/17/2022 21:32:04 - INFO - __main__ - Global step 2250 Train loss 0.64 Classification-F1 0.5376867394258699 on epoch=160
05/17/2022 21:32:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.66 on epoch=161
05/17/2022 21:32:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.68 on epoch=162
05/17/2022 21:32:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.72 on epoch=162
05/17/2022 21:32:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.64 on epoch=163
05/17/2022 21:32:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.69 on epoch=164
05/17/2022 21:32:14 - INFO - __main__ - Global step 2300 Train loss 0.68 Classification-F1 0.47831554988338665 on epoch=164
05/17/2022 21:32:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.70 on epoch=164
05/17/2022 21:32:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.74 on epoch=165
05/17/2022 21:32:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.62 on epoch=166
05/17/2022 21:32:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.73 on epoch=167
05/17/2022 21:32:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.75 on epoch=167
05/17/2022 21:32:24 - INFO - __main__ - Global step 2350 Train loss 0.71 Classification-F1 0.44206180315157395 on epoch=167
05/17/2022 21:32:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.64 on epoch=168
05/17/2022 21:32:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/17/2022 21:32:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.69 on epoch=169
05/17/2022 21:32:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.57 on epoch=170
05/17/2022 21:32:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.70 on epoch=171
05/17/2022 21:32:34 - INFO - __main__ - Global step 2400 Train loss 0.65 Classification-F1 0.5401854202975299 on epoch=171
05/17/2022 21:32:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.70 on epoch=172
05/17/2022 21:32:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.67 on epoch=172
05/17/2022 21:32:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.74 on epoch=173
05/17/2022 21:32:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.65 on epoch=174
05/17/2022 21:32:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.66 on epoch=174
05/17/2022 21:32:44 - INFO - __main__ - Global step 2450 Train loss 0.68 Classification-F1 0.5159776904014176 on epoch=174
05/17/2022 21:32:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.63 on epoch=175
05/17/2022 21:32:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.53 on epoch=176
05/17/2022 21:32:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.66 on epoch=177
05/17/2022 21:32:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.61 on epoch=177
05/17/2022 21:32:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.63 on epoch=178
05/17/2022 21:32:54 - INFO - __main__ - Global step 2500 Train loss 0.61 Classification-F1 0.5942302463655917 on epoch=178
05/17/2022 21:32:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5647611932600957 -> 0.5942302463655917 on epoch=178, global_step=2500
05/17/2022 21:32:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.74 on epoch=179
05/17/2022 21:32:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.62 on epoch=179
05/17/2022 21:32:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.69 on epoch=180
05/17/2022 21:32:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.74 on epoch=181
05/17/2022 21:33:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.63 on epoch=182
05/17/2022 21:33:04 - INFO - __main__ - Global step 2550 Train loss 0.68 Classification-F1 0.5189331602634396 on epoch=182
05/17/2022 21:33:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.73 on epoch=182
05/17/2022 21:33:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.69 on epoch=183
05/17/2022 21:33:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.78 on epoch=184
05/17/2022 21:33:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.62 on epoch=184
05/17/2022 21:33:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.67 on epoch=185
05/17/2022 21:33:14 - INFO - __main__ - Global step 2600 Train loss 0.70 Classification-F1 0.5579912725102983 on epoch=185
05/17/2022 21:33:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.65 on epoch=186
05/17/2022 21:33:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/17/2022 21:33:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.79 on epoch=187
05/17/2022 21:33:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.61 on epoch=188
05/17/2022 21:33:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.67 on epoch=189
05/17/2022 21:33:25 - INFO - __main__ - Global step 2650 Train loss 0.67 Classification-F1 0.4393120527914262 on epoch=189
05/17/2022 21:33:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.61 on epoch=189
05/17/2022 21:33:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.71 on epoch=190
05/17/2022 21:33:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.78 on epoch=191
05/17/2022 21:33:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.63 on epoch=192
05/17/2022 21:33:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.79 on epoch=192
05/17/2022 21:33:35 - INFO - __main__ - Global step 2700 Train loss 0.70 Classification-F1 0.4350582028086985 on epoch=192
05/17/2022 21:33:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.66 on epoch=193
05/17/2022 21:33:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.68 on epoch=194
05/17/2022 21:33:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/17/2022 21:33:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.65 on epoch=195
05/17/2022 21:33:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.70 on epoch=196
05/17/2022 21:33:45 - INFO - __main__ - Global step 2750 Train loss 0.68 Classification-F1 0.4604540222613731 on epoch=196
05/17/2022 21:33:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.60 on epoch=197
05/17/2022 21:33:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.69 on epoch=197
05/17/2022 21:33:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.61 on epoch=198
05/17/2022 21:33:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.67 on epoch=199
05/17/2022 21:33:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.62 on epoch=199
05/17/2022 21:33:56 - INFO - __main__ - Global step 2800 Train loss 0.64 Classification-F1 0.5558195734033811 on epoch=199
05/17/2022 21:33:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.61 on epoch=200
05/17/2022 21:33:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.59 on epoch=201
05/17/2022 21:34:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.67 on epoch=202
05/17/2022 21:34:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.60 on epoch=202
05/17/2022 21:34:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.71 on epoch=203
05/17/2022 21:34:06 - INFO - __main__ - Global step 2850 Train loss 0.64 Classification-F1 0.5020855956079081 on epoch=203
05/17/2022 21:34:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.61 on epoch=204
05/17/2022 21:34:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.66 on epoch=204
05/17/2022 21:34:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.59 on epoch=205
05/17/2022 21:34:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/17/2022 21:34:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.68 on epoch=207
05/17/2022 21:34:16 - INFO - __main__ - Global step 2900 Train loss 0.63 Classification-F1 0.5640058238034101 on epoch=207
05/17/2022 21:34:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.67 on epoch=207
05/17/2022 21:34:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.59 on epoch=208
05/17/2022 21:34:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.68 on epoch=209
05/17/2022 21:34:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.68 on epoch=209
05/17/2022 21:34:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.62 on epoch=210
05/17/2022 21:34:27 - INFO - __main__ - Global step 2950 Train loss 0.65 Classification-F1 0.5270329856558985 on epoch=210
05/17/2022 21:34:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.60 on epoch=211
05/17/2022 21:34:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.54 on epoch=212
05/17/2022 21:34:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.54 on epoch=212
05/17/2022 21:34:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.56 on epoch=213
05/17/2022 21:34:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.56 on epoch=214
05/17/2022 21:34:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:34:34 - INFO - __main__ - Printing 3 examples
05/17/2022 21:34:34 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:34:34 - INFO - __main__ - ['Film']
05/17/2022 21:34:34 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:34:34 - INFO - __main__ - ['Film']
05/17/2022 21:34:34 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:34:34 - INFO - __main__ - ['Film']
05/17/2022 21:34:34 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:34:34 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:34:35 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:34:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:34:35 - INFO - __main__ - Printing 3 examples
05/17/2022 21:34:35 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:34:35 - INFO - __main__ - ['Film']
05/17/2022 21:34:35 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:34:35 - INFO - __main__ - ['Film']
05/17/2022 21:34:35 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:34:35 - INFO - __main__ - ['Film']
05/17/2022 21:34:35 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:34:35 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:34:35 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:34:37 - INFO - __main__ - Global step 3000 Train loss 0.56 Classification-F1 0.445837100382555 on epoch=214
05/17/2022 21:34:37 - INFO - __main__ - save last model!
05/17/2022 21:34:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:34:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:34:37 - INFO - __main__ - Printing 3 examples
05/17/2022 21:34:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:34:37 - INFO - __main__ - ['Animal']
05/17/2022 21:34:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:34:37 - INFO - __main__ - ['Animal']
05/17/2022 21:34:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:34:37 - INFO - __main__ - ['Village']
05/17/2022 21:34:37 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:34:39 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:34:41 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:34:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:34:41 - INFO - __main__ - Starting training!
05/17/2022 21:34:42 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:35:50 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/17/2022 21:35:51 - INFO - __main__ - Classification-F1 on test data: 0.2031
05/17/2022 21:35:51 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.5942302463655917, test_performance=0.2031005213820054
05/17/2022 21:35:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/17/2022 21:35:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:35:52 - INFO - __main__ - Printing 3 examples
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:35:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:35:52 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:35:52 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:35:52 - INFO - __main__ - Printing 3 examples
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:35:52 - INFO - __main__ - ['Film']
05/17/2022 21:35:52 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:35:52 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:35:52 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:35:58 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:35:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:35:59 - INFO - __main__ - Starting training!
05/17/2022 21:36:00 - INFO - __main__ - Step 10 Global step 10 Train loss 7.30 on epoch=0
05/17/2022 21:36:01 - INFO - __main__ - Step 20 Global step 20 Train loss 6.96 on epoch=1
05/17/2022 21:36:03 - INFO - __main__ - Step 30 Global step 30 Train loss 6.45 on epoch=2
05/17/2022 21:36:04 - INFO - __main__ - Step 40 Global step 40 Train loss 6.13 on epoch=2
05/17/2022 21:36:05 - INFO - __main__ - Step 50 Global step 50 Train loss 5.73 on epoch=3
05/17/2022 21:36:08 - INFO - __main__ - Global step 50 Train loss 6.51 Classification-F1 0.0 on epoch=3
05/17/2022 21:36:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 21:36:09 - INFO - __main__ - Step 60 Global step 60 Train loss 5.37 on epoch=4
05/17/2022 21:36:11 - INFO - __main__ - Step 70 Global step 70 Train loss 5.34 on epoch=4
05/17/2022 21:36:12 - INFO - __main__ - Step 80 Global step 80 Train loss 5.06 on epoch=5
05/17/2022 21:36:13 - INFO - __main__ - Step 90 Global step 90 Train loss 5.01 on epoch=6
05/17/2022 21:36:15 - INFO - __main__ - Step 100 Global step 100 Train loss 4.60 on epoch=7
05/17/2022 21:36:18 - INFO - __main__ - Global step 100 Train loss 5.07 Classification-F1 0.0 on epoch=7
05/17/2022 21:36:19 - INFO - __main__ - Step 110 Global step 110 Train loss 4.61 on epoch=7
05/17/2022 21:36:20 - INFO - __main__ - Step 120 Global step 120 Train loss 4.39 on epoch=8
05/17/2022 21:36:22 - INFO - __main__ - Step 130 Global step 130 Train loss 3.99 on epoch=9
05/17/2022 21:36:23 - INFO - __main__ - Step 140 Global step 140 Train loss 3.89 on epoch=9
05/17/2022 21:36:24 - INFO - __main__ - Step 150 Global step 150 Train loss 3.74 on epoch=10
05/17/2022 21:36:27 - INFO - __main__ - Global step 150 Train loss 4.12 Classification-F1 0.0 on epoch=10
05/17/2022 21:36:29 - INFO - __main__ - Step 160 Global step 160 Train loss 3.62 on epoch=11
05/17/2022 21:36:30 - INFO - __main__ - Step 170 Global step 170 Train loss 3.47 on epoch=12
05/17/2022 21:36:31 - INFO - __main__ - Step 180 Global step 180 Train loss 3.44 on epoch=12
05/17/2022 21:36:32 - INFO - __main__ - Step 190 Global step 190 Train loss 3.37 on epoch=13
05/17/2022 21:36:34 - INFO - __main__ - Step 200 Global step 200 Train loss 3.24 on epoch=14
05/17/2022 21:36:37 - INFO - __main__ - Global step 200 Train loss 3.43 Classification-F1 0.0017301038062283738 on epoch=14
05/17/2022 21:36:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0017301038062283738 on epoch=14, global_step=200
05/17/2022 21:36:38 - INFO - __main__ - Step 210 Global step 210 Train loss 3.21 on epoch=14
05/17/2022 21:36:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.97 on epoch=15
05/17/2022 21:36:41 - INFO - __main__ - Step 230 Global step 230 Train loss 2.88 on epoch=16
05/17/2022 21:36:42 - INFO - __main__ - Step 240 Global step 240 Train loss 2.78 on epoch=17
05/17/2022 21:36:43 - INFO - __main__ - Step 250 Global step 250 Train loss 2.71 on epoch=17
05/17/2022 21:36:46 - INFO - __main__ - Global step 250 Train loss 2.91 Classification-F1 0.007575757575757575 on epoch=17
05/17/2022 21:36:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0017301038062283738 -> 0.007575757575757575 on epoch=17, global_step=250
05/17/2022 21:36:47 - INFO - __main__ - Step 260 Global step 260 Train loss 2.60 on epoch=18
05/17/2022 21:36:48 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/17/2022 21:36:49 - INFO - __main__ - Step 280 Global step 280 Train loss 2.60 on epoch=19
05/17/2022 21:36:51 - INFO - __main__ - Step 290 Global step 290 Train loss 2.51 on epoch=20
05/17/2022 21:36:52 - INFO - __main__ - Step 300 Global step 300 Train loss 2.53 on epoch=21
05/17/2022 21:36:54 - INFO - __main__ - Global step 300 Train loss 2.57 Classification-F1 0.009523809523809523 on epoch=21
05/17/2022 21:36:54 - INFO - __main__ - Saving model with best Classification-F1: 0.007575757575757575 -> 0.009523809523809523 on epoch=21, global_step=300
05/17/2022 21:36:55 - INFO - __main__ - Step 310 Global step 310 Train loss 2.35 on epoch=22
05/17/2022 21:36:56 - INFO - __main__ - Step 320 Global step 320 Train loss 2.34 on epoch=22
05/17/2022 21:36:58 - INFO - __main__ - Step 330 Global step 330 Train loss 2.20 on epoch=23
05/17/2022 21:36:59 - INFO - __main__ - Step 340 Global step 340 Train loss 2.16 on epoch=24
05/17/2022 21:37:00 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/17/2022 21:37:02 - INFO - __main__ - Global step 350 Train loss 2.24 Classification-F1 0.009523809523809523 on epoch=24
05/17/2022 21:37:03 - INFO - __main__ - Step 360 Global step 360 Train loss 2.03 on epoch=25
05/17/2022 21:37:04 - INFO - __main__ - Step 370 Global step 370 Train loss 2.13 on epoch=26
05/17/2022 21:37:06 - INFO - __main__ - Step 380 Global step 380 Train loss 1.93 on epoch=27
05/17/2022 21:37:07 - INFO - __main__ - Step 390 Global step 390 Train loss 2.03 on epoch=27
05/17/2022 21:37:08 - INFO - __main__ - Step 400 Global step 400 Train loss 1.93 on epoch=28
05/17/2022 21:37:10 - INFO - __main__ - Global step 400 Train loss 2.01 Classification-F1 0.02304109329928595 on epoch=28
05/17/2022 21:37:10 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02304109329928595 on epoch=28, global_step=400
05/17/2022 21:37:12 - INFO - __main__ - Step 410 Global step 410 Train loss 1.92 on epoch=29
05/17/2022 21:37:13 - INFO - __main__ - Step 420 Global step 420 Train loss 1.87 on epoch=29
05/17/2022 21:37:14 - INFO - __main__ - Step 430 Global step 430 Train loss 1.88 on epoch=30
05/17/2022 21:37:15 - INFO - __main__ - Step 440 Global step 440 Train loss 1.99 on epoch=31
05/17/2022 21:37:17 - INFO - __main__ - Step 450 Global step 450 Train loss 1.73 on epoch=32
05/17/2022 21:37:19 - INFO - __main__ - Global step 450 Train loss 1.88 Classification-F1 0.027753299029894773 on epoch=32
05/17/2022 21:37:19 - INFO - __main__ - Saving model with best Classification-F1: 0.02304109329928595 -> 0.027753299029894773 on epoch=32, global_step=450
05/17/2022 21:37:20 - INFO - __main__ - Step 460 Global step 460 Train loss 1.78 on epoch=32
05/17/2022 21:37:21 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=33
05/17/2022 21:37:22 - INFO - __main__ - Step 480 Global step 480 Train loss 1.76 on epoch=34
05/17/2022 21:37:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.81 on epoch=34
05/17/2022 21:37:25 - INFO - __main__ - Step 500 Global step 500 Train loss 1.66 on epoch=35
05/17/2022 21:37:27 - INFO - __main__ - Global step 500 Train loss 1.75 Classification-F1 0.03974396776254362 on epoch=35
05/17/2022 21:37:27 - INFO - __main__ - Saving model with best Classification-F1: 0.027753299029894773 -> 0.03974396776254362 on epoch=35, global_step=500
05/17/2022 21:37:28 - INFO - __main__ - Step 510 Global step 510 Train loss 1.74 on epoch=36
05/17/2022 21:37:30 - INFO - __main__ - Step 520 Global step 520 Train loss 1.60 on epoch=37
05/17/2022 21:37:31 - INFO - __main__ - Step 530 Global step 530 Train loss 1.74 on epoch=37
05/17/2022 21:37:32 - INFO - __main__ - Step 540 Global step 540 Train loss 1.61 on epoch=38
05/17/2022 21:37:33 - INFO - __main__ - Step 550 Global step 550 Train loss 1.59 on epoch=39
05/17/2022 21:37:35 - INFO - __main__ - Global step 550 Train loss 1.66 Classification-F1 0.03481850585013458 on epoch=39
05/17/2022 21:37:37 - INFO - __main__ - Step 560 Global step 560 Train loss 1.59 on epoch=39
05/17/2022 21:37:38 - INFO - __main__ - Step 570 Global step 570 Train loss 1.54 on epoch=40
05/17/2022 21:37:39 - INFO - __main__ - Step 580 Global step 580 Train loss 1.56 on epoch=41
05/17/2022 21:37:40 - INFO - __main__ - Step 590 Global step 590 Train loss 1.47 on epoch=42
05/17/2022 21:37:42 - INFO - __main__ - Step 600 Global step 600 Train loss 1.49 on epoch=42
05/17/2022 21:37:44 - INFO - __main__ - Global step 600 Train loss 1.53 Classification-F1 0.048030173356859045 on epoch=42
05/17/2022 21:37:44 - INFO - __main__ - Saving model with best Classification-F1: 0.03974396776254362 -> 0.048030173356859045 on epoch=42, global_step=600
05/17/2022 21:37:45 - INFO - __main__ - Step 610 Global step 610 Train loss 1.46 on epoch=43
05/17/2022 21:37:47 - INFO - __main__ - Step 620 Global step 620 Train loss 1.51 on epoch=44
05/17/2022 21:37:48 - INFO - __main__ - Step 630 Global step 630 Train loss 1.55 on epoch=44
05/17/2022 21:37:49 - INFO - __main__ - Step 640 Global step 640 Train loss 1.41 on epoch=45
05/17/2022 21:37:50 - INFO - __main__ - Step 650 Global step 650 Train loss 1.40 on epoch=46
05/17/2022 21:37:53 - INFO - __main__ - Global step 650 Train loss 1.47 Classification-F1 0.057636993927316506 on epoch=46
05/17/2022 21:37:53 - INFO - __main__ - Saving model with best Classification-F1: 0.048030173356859045 -> 0.057636993927316506 on epoch=46, global_step=650
05/17/2022 21:37:54 - INFO - __main__ - Step 660 Global step 660 Train loss 1.30 on epoch=47
05/17/2022 21:37:55 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=47
05/17/2022 21:37:57 - INFO - __main__ - Step 680 Global step 680 Train loss 1.42 on epoch=48
05/17/2022 21:37:58 - INFO - __main__ - Step 690 Global step 690 Train loss 1.39 on epoch=49
05/17/2022 21:37:59 - INFO - __main__ - Step 700 Global step 700 Train loss 1.28 on epoch=49
05/17/2022 21:38:02 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.05262563152634075 on epoch=49
05/17/2022 21:38:03 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=50
05/17/2022 21:38:04 - INFO - __main__ - Step 720 Global step 720 Train loss 1.38 on epoch=51
05/17/2022 21:38:05 - INFO - __main__ - Step 730 Global step 730 Train loss 1.25 on epoch=52
05/17/2022 21:38:07 - INFO - __main__ - Step 740 Global step 740 Train loss 1.40 on epoch=52
05/17/2022 21:38:08 - INFO - __main__ - Step 750 Global step 750 Train loss 1.28 on epoch=53
05/17/2022 21:38:10 - INFO - __main__ - Global step 750 Train loss 1.32 Classification-F1 0.05135118601078841 on epoch=53
05/17/2022 21:38:12 - INFO - __main__ - Step 760 Global step 760 Train loss 1.30 on epoch=54
05/17/2022 21:38:13 - INFO - __main__ - Step 770 Global step 770 Train loss 1.39 on epoch=54
05/17/2022 21:38:14 - INFO - __main__ - Step 780 Global step 780 Train loss 1.25 on epoch=55
05/17/2022 21:38:15 - INFO - __main__ - Step 790 Global step 790 Train loss 1.37 on epoch=56
05/17/2022 21:38:17 - INFO - __main__ - Step 800 Global step 800 Train loss 1.32 on epoch=57
05/17/2022 21:38:19 - INFO - __main__ - Global step 800 Train loss 1.33 Classification-F1 0.05428010428010427 on epoch=57
05/17/2022 21:38:20 - INFO - __main__ - Step 810 Global step 810 Train loss 1.26 on epoch=57
05/17/2022 21:38:21 - INFO - __main__ - Step 820 Global step 820 Train loss 1.31 on epoch=58
05/17/2022 21:38:23 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=59
05/17/2022 21:38:24 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=59
05/17/2022 21:38:25 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=60
05/17/2022 21:38:28 - INFO - __main__ - Global step 850 Train loss 1.26 Classification-F1 0.059070269561291334 on epoch=60
05/17/2022 21:38:28 - INFO - __main__ - Saving model with best Classification-F1: 0.057636993927316506 -> 0.059070269561291334 on epoch=60, global_step=850
05/17/2022 21:38:29 - INFO - __main__ - Step 860 Global step 860 Train loss 1.31 on epoch=61
05/17/2022 21:38:30 - INFO - __main__ - Step 870 Global step 870 Train loss 1.15 on epoch=62
05/17/2022 21:38:31 - INFO - __main__ - Step 880 Global step 880 Train loss 1.25 on epoch=62
05/17/2022 21:38:33 - INFO - __main__ - Step 890 Global step 890 Train loss 1.17 on epoch=63
05/17/2022 21:38:34 - INFO - __main__ - Step 900 Global step 900 Train loss 1.33 on epoch=64
05/17/2022 21:38:36 - INFO - __main__ - Global step 900 Train loss 1.24 Classification-F1 0.09585680572520053 on epoch=64
05/17/2022 21:38:36 - INFO - __main__ - Saving model with best Classification-F1: 0.059070269561291334 -> 0.09585680572520053 on epoch=64, global_step=900
05/17/2022 21:38:38 - INFO - __main__ - Step 910 Global step 910 Train loss 1.20 on epoch=64
05/17/2022 21:38:39 - INFO - __main__ - Step 920 Global step 920 Train loss 1.22 on epoch=65
05/17/2022 21:38:40 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=66
05/17/2022 21:38:41 - INFO - __main__ - Step 940 Global step 940 Train loss 1.22 on epoch=67
05/17/2022 21:38:43 - INFO - __main__ - Step 950 Global step 950 Train loss 1.31 on epoch=67
05/17/2022 21:38:45 - INFO - __main__ - Global step 950 Train loss 1.24 Classification-F1 0.07377961950330371 on epoch=67
05/17/2022 21:38:46 - INFO - __main__ - Step 960 Global step 960 Train loss 1.15 on epoch=68
05/17/2022 21:38:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=69
05/17/2022 21:38:49 - INFO - __main__ - Step 980 Global step 980 Train loss 1.26 on epoch=69
05/17/2022 21:38:50 - INFO - __main__ - Step 990 Global step 990 Train loss 1.22 on epoch=70
05/17/2022 21:38:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.25 on epoch=71
05/17/2022 21:38:54 - INFO - __main__ - Global step 1000 Train loss 1.21 Classification-F1 0.09379222996192248 on epoch=71
05/17/2022 21:38:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.28 on epoch=72
05/17/2022 21:38:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.22 on epoch=72
05/17/2022 21:38:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.15 on epoch=73
05/17/2022 21:38:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.16 on epoch=74
05/17/2022 21:39:00 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.21 on epoch=74
05/17/2022 21:39:02 - INFO - __main__ - Global step 1050 Train loss 1.20 Classification-F1 0.1362566752082024 on epoch=74
05/17/2022 21:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.09585680572520053 -> 0.1362566752082024 on epoch=74, global_step=1050
05/17/2022 21:39:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.06 on epoch=75
05/17/2022 21:39:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.17 on epoch=76
05/17/2022 21:39:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.18 on epoch=77
05/17/2022 21:39:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.19 on epoch=77
05/17/2022 21:39:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.10 on epoch=78
05/17/2022 21:39:12 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.15215247135586243 on epoch=78
05/17/2022 21:39:12 - INFO - __main__ - Saving model with best Classification-F1: 0.1362566752082024 -> 0.15215247135586243 on epoch=78, global_step=1100
05/17/2022 21:39:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=79
05/17/2022 21:39:14 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.16 on epoch=79
05/17/2022 21:39:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.19 on epoch=80
05/17/2022 21:39:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=81
05/17/2022 21:39:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.10 on epoch=82
05/17/2022 21:39:21 - INFO - __main__ - Global step 1150 Train loss 1.18 Classification-F1 0.17560138854070878 on epoch=82
05/17/2022 21:39:21 - INFO - __main__ - Saving model with best Classification-F1: 0.15215247135586243 -> 0.17560138854070878 on epoch=82, global_step=1150
05/17/2022 21:39:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.17 on epoch=82
05/17/2022 21:39:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.03 on epoch=83
05/17/2022 21:39:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.17 on epoch=84
05/17/2022 21:39:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.15 on epoch=84
05/17/2022 21:39:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.05 on epoch=85
05/17/2022 21:39:30 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.1806111300281909 on epoch=85
05/17/2022 21:39:30 - INFO - __main__ - Saving model with best Classification-F1: 0.17560138854070878 -> 0.1806111300281909 on epoch=85, global_step=1200
05/17/2022 21:39:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=86
05/17/2022 21:39:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.09 on epoch=87
05/17/2022 21:39:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.14 on epoch=87
05/17/2022 21:39:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=88
05/17/2022 21:39:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.14 on epoch=89
05/17/2022 21:39:40 - INFO - __main__ - Global step 1250 Train loss 1.12 Classification-F1 0.2620690422783464 on epoch=89
05/17/2022 21:39:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1806111300281909 -> 0.2620690422783464 on epoch=89, global_step=1250
05/17/2022 21:39:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.17 on epoch=89
05/17/2022 21:39:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.02 on epoch=90
05/17/2022 21:39:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.11 on epoch=91
05/17/2022 21:39:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.03 on epoch=92
05/17/2022 21:39:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=92
05/17/2022 21:39:49 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.24170885057410127 on epoch=92
05/17/2022 21:39:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.04 on epoch=93
05/17/2022 21:39:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.10 on epoch=94
05/17/2022 21:39:53 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=94
05/17/2022 21:39:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.08 on epoch=95
05/17/2022 21:39:55 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.22 on epoch=96
05/17/2022 21:39:58 - INFO - __main__ - Global step 1350 Train loss 1.12 Classification-F1 0.33113408155366825 on epoch=96
05/17/2022 21:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.2620690422783464 -> 0.33113408155366825 on epoch=96, global_step=1350
05/17/2022 21:40:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.99 on epoch=97
05/17/2022 21:40:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.22 on epoch=97
05/17/2022 21:40:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.99 on epoch=98
05/17/2022 21:40:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.04 on epoch=99
05/17/2022 21:40:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.11 on epoch=99
05/17/2022 21:40:08 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.2539671291675433 on epoch=99
05/17/2022 21:40:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.03 on epoch=100
05/17/2022 21:40:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.09 on epoch=101
05/17/2022 21:40:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.03 on epoch=102
05/17/2022 21:40:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.00 on epoch=102
05/17/2022 21:40:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.01 on epoch=103
05/17/2022 21:40:18 - INFO - __main__ - Global step 1450 Train loss 1.03 Classification-F1 0.25018028116388774 on epoch=103
05/17/2022 21:40:19 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=104
05/17/2022 21:40:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.04 on epoch=104
05/17/2022 21:40:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.92 on epoch=105
05/17/2022 21:40:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=106
05/17/2022 21:40:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.02 on epoch=107
05/17/2022 21:40:27 - INFO - __main__ - Global step 1500 Train loss 1.04 Classification-F1 0.31932222825817097 on epoch=107
05/17/2022 21:40:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=107
05/17/2022 21:40:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.00 on epoch=108
05/17/2022 21:40:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.08 on epoch=109
05/17/2022 21:40:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=109
05/17/2022 21:40:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.01 on epoch=110
05/17/2022 21:40:37 - INFO - __main__ - Global step 1550 Train loss 1.03 Classification-F1 0.34736894011029806 on epoch=110
05/17/2022 21:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.33113408155366825 -> 0.34736894011029806 on epoch=110, global_step=1550
05/17/2022 21:40:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.08 on epoch=111
05/17/2022 21:40:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.01 on epoch=112
05/17/2022 21:40:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=112
05/17/2022 21:40:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.97 on epoch=113
05/17/2022 21:40:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.04 on epoch=114
05/17/2022 21:40:47 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.388241032306253 on epoch=114
05/17/2022 21:40:47 - INFO - __main__ - Saving model with best Classification-F1: 0.34736894011029806 -> 0.388241032306253 on epoch=114, global_step=1600
05/17/2022 21:40:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=114
05/17/2022 21:40:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.86 on epoch=115
05/17/2022 21:40:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=116
05/17/2022 21:40:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.95 on epoch=117
05/17/2022 21:40:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=117
05/17/2022 21:40:56 - INFO - __main__ - Global step 1650 Train loss 0.97 Classification-F1 0.40042318597145965 on epoch=117
05/17/2022 21:40:56 - INFO - __main__ - Saving model with best Classification-F1: 0.388241032306253 -> 0.40042318597145965 on epoch=117, global_step=1650
05/17/2022 21:40:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=118
05/17/2022 21:40:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=119
05/17/2022 21:41:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.94 on epoch=119
05/17/2022 21:41:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.95 on epoch=120
05/17/2022 21:41:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.90 on epoch=121
05/17/2022 21:41:06 - INFO - __main__ - Global step 1700 Train loss 0.94 Classification-F1 0.3589553836125061 on epoch=121
05/17/2022 21:41:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.93 on epoch=122
05/17/2022 21:41:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.92 on epoch=122
05/17/2022 21:41:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.94 on epoch=123
05/17/2022 21:41:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.96 on epoch=124
05/17/2022 21:41:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.97 on epoch=124
05/17/2022 21:41:15 - INFO - __main__ - Global step 1750 Train loss 0.94 Classification-F1 0.38650011996489697 on epoch=124
05/17/2022 21:41:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.90 on epoch=125
05/17/2022 21:41:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=126
05/17/2022 21:41:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=127
05/17/2022 21:41:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.89 on epoch=127
05/17/2022 21:41:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=128
05/17/2022 21:41:25 - INFO - __main__ - Global step 1800 Train loss 0.93 Classification-F1 0.4448951395646479 on epoch=128
05/17/2022 21:41:25 - INFO - __main__ - Saving model with best Classification-F1: 0.40042318597145965 -> 0.4448951395646479 on epoch=128, global_step=1800
05/17/2022 21:41:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.87 on epoch=129
05/17/2022 21:41:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.91 on epoch=129
05/17/2022 21:41:29 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=130
05/17/2022 21:41:30 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.93 on epoch=131
05/17/2022 21:41:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.90 on epoch=132
05/17/2022 21:41:35 - INFO - __main__ - Global step 1850 Train loss 0.91 Classification-F1 0.3529172826035289 on epoch=132
05/17/2022 21:41:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.95 on epoch=132
05/17/2022 21:41:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.91 on epoch=133
05/17/2022 21:41:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.90 on epoch=134
05/17/2022 21:41:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.89 on epoch=134
05/17/2022 21:41:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.86 on epoch=135
05/17/2022 21:41:45 - INFO - __main__ - Global step 1900 Train loss 0.90 Classification-F1 0.4214078358246112 on epoch=135
05/17/2022 21:41:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.89 on epoch=136
05/17/2022 21:41:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.95 on epoch=137
05/17/2022 21:41:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.89 on epoch=137
05/17/2022 21:41:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=138
05/17/2022 21:41:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.89 on epoch=139
05/17/2022 21:41:55 - INFO - __main__ - Global step 1950 Train loss 0.90 Classification-F1 0.4092242837347885 on epoch=139
05/17/2022 21:41:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.88 on epoch=139
05/17/2022 21:41:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=140
05/17/2022 21:41:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.88 on epoch=141
05/17/2022 21:42:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.85 on epoch=142
05/17/2022 21:42:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.90 on epoch=142
05/17/2022 21:42:05 - INFO - __main__ - Global step 2000 Train loss 0.89 Classification-F1 0.46606218974640024 on epoch=142
05/17/2022 21:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4448951395646479 -> 0.46606218974640024 on epoch=142, global_step=2000
05/17/2022 21:42:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.77 on epoch=143
05/17/2022 21:42:07 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.84 on epoch=144
05/17/2022 21:42:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.89 on epoch=144
05/17/2022 21:42:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.82 on epoch=145
05/17/2022 21:42:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.84 on epoch=146
05/17/2022 21:42:15 - INFO - __main__ - Global step 2050 Train loss 0.83 Classification-F1 0.4580743754507347 on epoch=146
05/17/2022 21:42:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.79 on epoch=147
05/17/2022 21:42:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.86 on epoch=147
05/17/2022 21:42:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.74 on epoch=148
05/17/2022 21:42:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.86 on epoch=149
05/17/2022 21:42:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.79 on epoch=149
05/17/2022 21:42:25 - INFO - __main__ - Global step 2100 Train loss 0.81 Classification-F1 0.4861286218604532 on epoch=149
05/17/2022 21:42:25 - INFO - __main__ - Saving model with best Classification-F1: 0.46606218974640024 -> 0.4861286218604532 on epoch=149, global_step=2100
05/17/2022 21:42:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.75 on epoch=150
05/17/2022 21:42:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.89 on epoch=151
05/17/2022 21:42:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.86 on epoch=152
05/17/2022 21:42:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.75 on epoch=152
05/17/2022 21:42:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.72 on epoch=153
05/17/2022 21:42:36 - INFO - __main__ - Global step 2150 Train loss 0.80 Classification-F1 0.5860190904529009 on epoch=153
05/17/2022 21:42:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4861286218604532 -> 0.5860190904529009 on epoch=153, global_step=2150
05/17/2022 21:42:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.73 on epoch=154
05/17/2022 21:42:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.72 on epoch=154
05/17/2022 21:42:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.72 on epoch=155
05/17/2022 21:42:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.79 on epoch=156
05/17/2022 21:42:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.81 on epoch=157
05/17/2022 21:42:46 - INFO - __main__ - Global step 2200 Train loss 0.76 Classification-F1 0.476107576930033 on epoch=157
05/17/2022 21:42:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.81 on epoch=157
05/17/2022 21:42:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.76 on epoch=158
05/17/2022 21:42:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.79 on epoch=159
05/17/2022 21:42:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.77 on epoch=159
05/17/2022 21:42:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/17/2022 21:42:56 - INFO - __main__ - Global step 2250 Train loss 0.77 Classification-F1 0.5202854285352209 on epoch=160
05/17/2022 21:42:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.76 on epoch=161
05/17/2022 21:42:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.83 on epoch=162
05/17/2022 21:43:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.70 on epoch=162
05/17/2022 21:43:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.81 on epoch=163
05/17/2022 21:43:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.74 on epoch=164
05/17/2022 21:43:06 - INFO - __main__ - Global step 2300 Train loss 0.77 Classification-F1 0.5037744445567344 on epoch=164
05/17/2022 21:43:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.73 on epoch=164
05/17/2022 21:43:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.73 on epoch=165
05/17/2022 21:43:10 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.76 on epoch=166
05/17/2022 21:43:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.74 on epoch=167
05/17/2022 21:43:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.70 on epoch=167
05/17/2022 21:43:16 - INFO - __main__ - Global step 2350 Train loss 0.73 Classification-F1 0.49828951435561625 on epoch=167
05/17/2022 21:43:17 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.70 on epoch=168
05/17/2022 21:43:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.75 on epoch=169
05/17/2022 21:43:20 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.70 on epoch=169
05/17/2022 21:43:21 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.80 on epoch=170
05/17/2022 21:43:22 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.72 on epoch=171
05/17/2022 21:43:26 - INFO - __main__ - Global step 2400 Train loss 0.73 Classification-F1 0.598816013291626 on epoch=171
05/17/2022 21:43:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5860190904529009 -> 0.598816013291626 on epoch=171, global_step=2400
05/17/2022 21:43:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.75 on epoch=172
05/17/2022 21:43:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.70 on epoch=172
05/17/2022 21:43:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.72 on epoch=173
05/17/2022 21:43:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.73 on epoch=174
05/17/2022 21:43:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.71 on epoch=174
05/17/2022 21:43:36 - INFO - __main__ - Global step 2450 Train loss 0.72 Classification-F1 0.5893520678947957 on epoch=174
05/17/2022 21:43:37 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.58 on epoch=175
05/17/2022 21:43:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.74 on epoch=176
05/17/2022 21:43:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.68 on epoch=177
05/17/2022 21:43:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.81 on epoch=177
05/17/2022 21:43:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.80 on epoch=178
05/17/2022 21:43:46 - INFO - __main__ - Global step 2500 Train loss 0.72 Classification-F1 0.6349946706553868 on epoch=178
05/17/2022 21:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.598816013291626 -> 0.6349946706553868 on epoch=178, global_step=2500
05/17/2022 21:43:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.71 on epoch=179
05/17/2022 21:43:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.72 on epoch=179
05/17/2022 21:43:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.67 on epoch=180
05/17/2022 21:43:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.67 on epoch=181
05/17/2022 21:43:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.65 on epoch=182
05/17/2022 21:43:56 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.5581696493248975 on epoch=182
05/17/2022 21:43:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/17/2022 21:43:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.71 on epoch=183
05/17/2022 21:44:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/17/2022 21:44:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.68 on epoch=184
05/17/2022 21:44:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.72 on epoch=185
05/17/2022 21:44:07 - INFO - __main__ - Global step 2600 Train loss 0.68 Classification-F1 0.6163699205961763 on epoch=185
05/17/2022 21:44:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.60 on epoch=186
05/17/2022 21:44:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.66 on epoch=187
05/17/2022 21:44:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.58 on epoch=187
05/17/2022 21:44:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.62 on epoch=188
05/17/2022 21:44:13 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.72 on epoch=189
05/17/2022 21:44:17 - INFO - __main__ - Global step 2650 Train loss 0.64 Classification-F1 0.5371730456213174 on epoch=189
05/17/2022 21:44:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.66 on epoch=189
05/17/2022 21:44:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.62 on epoch=190
05/17/2022 21:44:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.72 on epoch=191
05/17/2022 21:44:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.63 on epoch=192
05/17/2022 21:44:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/17/2022 21:44:27 - INFO - __main__ - Global step 2700 Train loss 0.64 Classification-F1 0.6710159704729729 on epoch=192
05/17/2022 21:44:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6349946706553868 -> 0.6710159704729729 on epoch=192, global_step=2700
05/17/2022 21:44:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.57 on epoch=193
05/17/2022 21:44:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.62 on epoch=194
05/17/2022 21:44:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.63 on epoch=194
05/17/2022 21:44:32 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.69 on epoch=195
05/17/2022 21:44:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.61 on epoch=196
05/17/2022 21:44:37 - INFO - __main__ - Global step 2750 Train loss 0.63 Classification-F1 0.6251866270983918 on epoch=196
05/17/2022 21:44:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.63 on epoch=197
05/17/2022 21:44:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.61 on epoch=197
05/17/2022 21:44:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.64 on epoch=198
05/17/2022 21:44:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.69 on epoch=199
05/17/2022 21:44:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.52 on epoch=199
05/17/2022 21:44:47 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.574254708410971 on epoch=199
05/17/2022 21:44:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.65 on epoch=200
05/17/2022 21:44:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.70 on epoch=201
05/17/2022 21:44:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.72 on epoch=202
05/17/2022 21:44:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/17/2022 21:44:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.62 on epoch=203
05/17/2022 21:44:57 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.612535760926478 on epoch=203
05/17/2022 21:44:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.58 on epoch=204
05/17/2022 21:45:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.63 on epoch=204
05/17/2022 21:45:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.61 on epoch=205
05/17/2022 21:45:02 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.65 on epoch=206
05/17/2022 21:45:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.59 on epoch=207
05/17/2022 21:45:07 - INFO - __main__ - Global step 2900 Train loss 0.61 Classification-F1 0.5208521246696618 on epoch=207
05/17/2022 21:45:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.54 on epoch=207
05/17/2022 21:45:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.68 on epoch=208
05/17/2022 21:45:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.63 on epoch=209
05/17/2022 21:45:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.68 on epoch=209
05/17/2022 21:45:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.66 on epoch=210
05/17/2022 21:45:18 - INFO - __main__ - Global step 2950 Train loss 0.64 Classification-F1 0.5399057975094226 on epoch=210
05/17/2022 21:45:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.63 on epoch=211
05/17/2022 21:45:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.63 on epoch=212
05/17/2022 21:45:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.62 on epoch=212
05/17/2022 21:45:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.57 on epoch=213
05/17/2022 21:45:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.58 on epoch=214
05/17/2022 21:45:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:45:25 - INFO - __main__ - Printing 3 examples
05/17/2022 21:45:25 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:45:25 - INFO - __main__ - ['Film']
05/17/2022 21:45:25 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:45:25 - INFO - __main__ - ['Film']
05/17/2022 21:45:25 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:45:25 - INFO - __main__ - ['Film']
05/17/2022 21:45:25 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:45:25 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:45:26 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:45:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:45:26 - INFO - __main__ - Printing 3 examples
05/17/2022 21:45:26 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:45:26 - INFO - __main__ - ['Film']
05/17/2022 21:45:26 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:45:26 - INFO - __main__ - ['Film']
05/17/2022 21:45:26 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:45:26 - INFO - __main__ - ['Film']
05/17/2022 21:45:26 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:45:26 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:45:26 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:45:28 - INFO - __main__ - Global step 3000 Train loss 0.61 Classification-F1 0.5181899906104177 on epoch=214
05/17/2022 21:45:28 - INFO - __main__ - save last model!
05/17/2022 21:45:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:45:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:45:28 - INFO - __main__ - Printing 3 examples
05/17/2022 21:45:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:45:28 - INFO - __main__ - ['Animal']
05/17/2022 21:45:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:45:28 - INFO - __main__ - ['Animal']
05/17/2022 21:45:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:45:28 - INFO - __main__ - ['Village']
05/17/2022 21:45:28 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:45:30 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:45:31 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:45:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:45:31 - INFO - __main__ - Starting training!
05/17/2022 21:45:33 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:46:40 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/17/2022 21:46:40 - INFO - __main__ - Classification-F1 on test data: 0.1677
05/17/2022 21:46:41 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.6710159704729729, test_performance=0.16766593739159386
05/17/2022 21:46:41 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/17/2022 21:46:41 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:46:41 - INFO - __main__ - Printing 3 examples
05/17/2022 21:46:41 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/17/2022 21:46:41 - INFO - __main__ - ['Film']
05/17/2022 21:46:41 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/17/2022 21:46:41 - INFO - __main__ - ['Film']
05/17/2022 21:46:41 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/17/2022 21:46:41 - INFO - __main__ - ['Film']
05/17/2022 21:46:41 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:46:42 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:46:42 - INFO - __main__ - Loaded 224 examples from train data
05/17/2022 21:46:42 - INFO - __main__ - Start tokenizing ... 224 instances
05/17/2022 21:46:42 - INFO - __main__ - Printing 3 examples
05/17/2022 21:46:42 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/17/2022 21:46:42 - INFO - __main__ - ['Film']
05/17/2022 21:46:42 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/17/2022 21:46:42 - INFO - __main__ - ['Film']
05/17/2022 21:46:42 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/17/2022 21:46:42 - INFO - __main__ - ['Film']
05/17/2022 21:46:42 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:46:42 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:46:42 - INFO - __main__ - Loaded 224 examples from dev data
05/17/2022 21:46:48 - INFO - __main__ - load prompt embedding from ckpt
05/17/2022 21:46:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/17/2022 21:46:48 - INFO - __main__ - Starting training!
05/17/2022 21:46:51 - INFO - __main__ - Step 10 Global step 10 Train loss 7.51 on epoch=0
05/17/2022 21:46:53 - INFO - __main__ - Step 20 Global step 20 Train loss 7.22 on epoch=1
05/17/2022 21:46:54 - INFO - __main__ - Step 30 Global step 30 Train loss 6.83 on epoch=2
05/17/2022 21:46:55 - INFO - __main__ - Step 40 Global step 40 Train loss 6.55 on epoch=2
05/17/2022 21:46:57 - INFO - __main__ - Step 50 Global step 50 Train loss 6.27 on epoch=3
05/17/2022 21:47:00 - INFO - __main__ - Global step 50 Train loss 6.88 Classification-F1 0.0 on epoch=3
05/17/2022 21:47:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/17/2022 21:47:01 - INFO - __main__ - Step 60 Global step 60 Train loss 5.98 on epoch=4
05/17/2022 21:47:02 - INFO - __main__ - Step 70 Global step 70 Train loss 5.81 on epoch=4
05/17/2022 21:47:03 - INFO - __main__ - Step 80 Global step 80 Train loss 5.51 on epoch=5
05/17/2022 21:47:05 - INFO - __main__ - Step 90 Global step 90 Train loss 5.45 on epoch=6
05/17/2022 21:47:06 - INFO - __main__ - Step 100 Global step 100 Train loss 5.13 on epoch=7
05/17/2022 21:47:09 - INFO - __main__ - Global step 100 Train loss 5.58 Classification-F1 0.0 on epoch=7
05/17/2022 21:47:10 - INFO - __main__ - Step 110 Global step 110 Train loss 4.81 on epoch=7
05/17/2022 21:47:12 - INFO - __main__ - Step 120 Global step 120 Train loss 4.85 on epoch=8
05/17/2022 21:47:13 - INFO - __main__ - Step 130 Global step 130 Train loss 4.65 on epoch=9
05/17/2022 21:47:14 - INFO - __main__ - Step 140 Global step 140 Train loss 4.69 on epoch=9
05/17/2022 21:47:15 - INFO - __main__ - Step 150 Global step 150 Train loss 4.38 on epoch=10
05/17/2022 21:47:19 - INFO - __main__ - Global step 150 Train loss 4.67 Classification-F1 0.0 on epoch=10
05/17/2022 21:47:20 - INFO - __main__ - Step 160 Global step 160 Train loss 4.46 on epoch=11
05/17/2022 21:47:21 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=12
05/17/2022 21:47:22 - INFO - __main__ - Step 180 Global step 180 Train loss 4.05 on epoch=12
05/17/2022 21:47:24 - INFO - __main__ - Step 190 Global step 190 Train loss 4.04 on epoch=13
05/17/2022 21:47:25 - INFO - __main__ - Step 200 Global step 200 Train loss 3.66 on epoch=14
05/17/2022 21:47:28 - INFO - __main__ - Global step 200 Train loss 4.07 Classification-F1 0.0 on epoch=14
05/17/2022 21:47:29 - INFO - __main__ - Step 210 Global step 210 Train loss 3.89 on epoch=14
05/17/2022 21:47:31 - INFO - __main__ - Step 220 Global step 220 Train loss 3.61 on epoch=15
05/17/2022 21:47:32 - INFO - __main__ - Step 230 Global step 230 Train loss 3.71 on epoch=16
05/17/2022 21:47:33 - INFO - __main__ - Step 240 Global step 240 Train loss 3.58 on epoch=17
05/17/2022 21:47:34 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/17/2022 21:47:37 - INFO - __main__ - Global step 250 Train loss 3.64 Classification-F1 0.0 on epoch=17
05/17/2022 21:47:38 - INFO - __main__ - Step 260 Global step 260 Train loss 3.43 on epoch=18
05/17/2022 21:47:40 - INFO - __main__ - Step 270 Global step 270 Train loss 3.35 on epoch=19
05/17/2022 21:47:41 - INFO - __main__ - Step 280 Global step 280 Train loss 3.22 on epoch=19
05/17/2022 21:47:42 - INFO - __main__ - Step 290 Global step 290 Train loss 3.15 on epoch=20
05/17/2022 21:47:43 - INFO - __main__ - Step 300 Global step 300 Train loss 3.24 on epoch=21
05/17/2022 21:47:46 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.0035398230088495575 on epoch=21
05/17/2022 21:47:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0035398230088495575 on epoch=21, global_step=300
05/17/2022 21:47:47 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/17/2022 21:47:48 - INFO - __main__ - Step 320 Global step 320 Train loss 2.94 on epoch=22
05/17/2022 21:47:50 - INFO - __main__ - Step 330 Global step 330 Train loss 2.96 on epoch=23
05/17/2022 21:47:51 - INFO - __main__ - Step 340 Global step 340 Train loss 2.78 on epoch=24
05/17/2022 21:47:52 - INFO - __main__ - Step 350 Global step 350 Train loss 2.85 on epoch=24
05/17/2022 21:47:55 - INFO - __main__ - Global step 350 Train loss 2.91 Classification-F1 0.007246376811594203 on epoch=24
05/17/2022 21:47:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0035398230088495575 -> 0.007246376811594203 on epoch=24, global_step=350
05/17/2022 21:47:56 - INFO - __main__ - Step 360 Global step 360 Train loss 2.72 on epoch=25
05/17/2022 21:47:57 - INFO - __main__ - Step 370 Global step 370 Train loss 2.73 on epoch=26
05/17/2022 21:47:58 - INFO - __main__ - Step 380 Global step 380 Train loss 2.65 on epoch=27
05/17/2022 21:48:00 - INFO - __main__ - Step 390 Global step 390 Train loss 2.61 on epoch=27
05/17/2022 21:48:01 - INFO - __main__ - Step 400 Global step 400 Train loss 2.59 on epoch=28
05/17/2022 21:48:03 - INFO - __main__ - Global step 400 Train loss 2.66 Classification-F1 0.008849557522123895 on epoch=28
05/17/2022 21:48:03 - INFO - __main__ - Saving model with best Classification-F1: 0.007246376811594203 -> 0.008849557522123895 on epoch=28, global_step=400
05/17/2022 21:48:04 - INFO - __main__ - Step 410 Global step 410 Train loss 2.53 on epoch=29
05/17/2022 21:48:06 - INFO - __main__ - Step 420 Global step 420 Train loss 2.56 on epoch=29
05/17/2022 21:48:07 - INFO - __main__ - Step 430 Global step 430 Train loss 2.44 on epoch=30
05/17/2022 21:48:08 - INFO - __main__ - Step 440 Global step 440 Train loss 2.51 on epoch=31
05/17/2022 21:48:09 - INFO - __main__ - Step 450 Global step 450 Train loss 2.36 on epoch=32
05/17/2022 21:48:11 - INFO - __main__ - Global step 450 Train loss 2.48 Classification-F1 0.009523809523809523 on epoch=32
05/17/2022 21:48:11 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=32, global_step=450
05/17/2022 21:48:13 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=32
05/17/2022 21:48:14 - INFO - __main__ - Step 470 Global step 470 Train loss 2.29 on epoch=33
05/17/2022 21:48:15 - INFO - __main__ - Step 480 Global step 480 Train loss 2.19 on epoch=34
05/17/2022 21:48:16 - INFO - __main__ - Step 490 Global step 490 Train loss 2.19 on epoch=34
05/17/2022 21:48:18 - INFO - __main__ - Step 500 Global step 500 Train loss 2.08 on epoch=35
05/17/2022 21:48:19 - INFO - __main__ - Global step 500 Train loss 2.22 Classification-F1 0.009523809523809523 on epoch=35
05/17/2022 21:48:21 - INFO - __main__ - Step 510 Global step 510 Train loss 2.21 on epoch=36
05/17/2022 21:48:22 - INFO - __main__ - Step 520 Global step 520 Train loss 2.06 on epoch=37
05/17/2022 21:48:23 - INFO - __main__ - Step 530 Global step 530 Train loss 2.14 on epoch=37
05/17/2022 21:48:24 - INFO - __main__ - Step 540 Global step 540 Train loss 2.05 on epoch=38
05/17/2022 21:48:26 - INFO - __main__ - Step 550 Global step 550 Train loss 1.94 on epoch=39
05/17/2022 21:48:28 - INFO - __main__ - Global step 550 Train loss 2.08 Classification-F1 0.023599577762139338 on epoch=39
05/17/2022 21:48:28 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.023599577762139338 on epoch=39, global_step=550
05/17/2022 21:48:29 - INFO - __main__ - Step 560 Global step 560 Train loss 2.09 on epoch=39
05/17/2022 21:48:30 - INFO - __main__ - Step 570 Global step 570 Train loss 1.89 on epoch=40
05/17/2022 21:48:31 - INFO - __main__ - Step 580 Global step 580 Train loss 2.09 on epoch=41
05/17/2022 21:48:33 - INFO - __main__ - Step 590 Global step 590 Train loss 1.92 on epoch=42
05/17/2022 21:48:34 - INFO - __main__ - Step 600 Global step 600 Train loss 1.97 on epoch=42
05/17/2022 21:48:36 - INFO - __main__ - Global step 600 Train loss 1.99 Classification-F1 0.01793847011804071 on epoch=42
05/17/2022 21:48:37 - INFO - __main__ - Step 610 Global step 610 Train loss 1.86 on epoch=43
05/17/2022 21:48:38 - INFO - __main__ - Step 620 Global step 620 Train loss 1.85 on epoch=44
05/17/2022 21:48:40 - INFO - __main__ - Step 630 Global step 630 Train loss 1.85 on epoch=44
05/17/2022 21:48:41 - INFO - __main__ - Step 640 Global step 640 Train loss 1.79 on epoch=45
05/17/2022 21:48:42 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=46
05/17/2022 21:48:44 - INFO - __main__ - Global step 650 Train loss 1.83 Classification-F1 0.016573159430302287 on epoch=46
05/17/2022 21:48:45 - INFO - __main__ - Step 660 Global step 660 Train loss 1.77 on epoch=47
05/17/2022 21:48:47 - INFO - __main__ - Step 670 Global step 670 Train loss 1.72 on epoch=47
05/17/2022 21:48:48 - INFO - __main__ - Step 680 Global step 680 Train loss 1.72 on epoch=48
05/17/2022 21:48:49 - INFO - __main__ - Step 690 Global step 690 Train loss 1.74 on epoch=49
05/17/2022 21:48:50 - INFO - __main__ - Step 700 Global step 700 Train loss 1.84 on epoch=49
05/17/2022 21:48:52 - INFO - __main__ - Global step 700 Train loss 1.76 Classification-F1 0.03067956349206349 on epoch=49
05/17/2022 21:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.023599577762139338 -> 0.03067956349206349 on epoch=49, global_step=700
05/17/2022 21:48:53 - INFO - __main__ - Step 710 Global step 710 Train loss 1.67 on epoch=50
05/17/2022 21:48:55 - INFO - __main__ - Step 720 Global step 720 Train loss 1.81 on epoch=51
05/17/2022 21:48:56 - INFO - __main__ - Step 730 Global step 730 Train loss 1.63 on epoch=52
05/17/2022 21:48:57 - INFO - __main__ - Step 740 Global step 740 Train loss 1.76 on epoch=52
05/17/2022 21:48:58 - INFO - __main__ - Step 750 Global step 750 Train loss 1.53 on epoch=53
05/17/2022 21:49:01 - INFO - __main__ - Global step 750 Train loss 1.68 Classification-F1 0.018032069970845478 on epoch=53
05/17/2022 21:49:02 - INFO - __main__ - Step 760 Global step 760 Train loss 1.64 on epoch=54
05/17/2022 21:49:03 - INFO - __main__ - Step 770 Global step 770 Train loss 1.77 on epoch=54
05/17/2022 21:49:04 - INFO - __main__ - Step 780 Global step 780 Train loss 1.56 on epoch=55
05/17/2022 21:49:06 - INFO - __main__ - Step 790 Global step 790 Train loss 1.61 on epoch=56
05/17/2022 21:49:07 - INFO - __main__ - Step 800 Global step 800 Train loss 1.55 on epoch=57
05/17/2022 21:49:09 - INFO - __main__ - Global step 800 Train loss 1.63 Classification-F1 0.02225726654298083 on epoch=57
05/17/2022 21:49:10 - INFO - __main__ - Step 810 Global step 810 Train loss 1.59 on epoch=57
05/17/2022 21:49:11 - INFO - __main__ - Step 820 Global step 820 Train loss 1.46 on epoch=58
05/17/2022 21:49:13 - INFO - __main__ - Step 830 Global step 830 Train loss 1.55 on epoch=59
05/17/2022 21:49:14 - INFO - __main__ - Step 840 Global step 840 Train loss 1.57 on epoch=59
05/17/2022 21:49:15 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=60
05/17/2022 21:49:17 - INFO - __main__ - Global step 850 Train loss 1.51 Classification-F1 0.014767025089605737 on epoch=60
05/17/2022 21:49:19 - INFO - __main__ - Step 860 Global step 860 Train loss 1.50 on epoch=61
05/17/2022 21:49:20 - INFO - __main__ - Step 870 Global step 870 Train loss 1.47 on epoch=62
05/17/2022 21:49:21 - INFO - __main__ - Step 880 Global step 880 Train loss 1.47 on epoch=62
05/17/2022 21:49:23 - INFO - __main__ - Step 890 Global step 890 Train loss 1.45 on epoch=63
05/17/2022 21:49:24 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=64
05/17/2022 21:49:26 - INFO - __main__ - Global step 900 Train loss 1.46 Classification-F1 0.017969687875150058 on epoch=64
05/17/2022 21:49:27 - INFO - __main__ - Step 910 Global step 910 Train loss 1.56 on epoch=64
05/17/2022 21:49:29 - INFO - __main__ - Step 920 Global step 920 Train loss 1.40 on epoch=65
05/17/2022 21:49:30 - INFO - __main__ - Step 930 Global step 930 Train loss 1.45 on epoch=66
05/17/2022 21:49:31 - INFO - __main__ - Step 940 Global step 940 Train loss 1.48 on epoch=67
05/17/2022 21:49:32 - INFO - __main__ - Step 950 Global step 950 Train loss 1.41 on epoch=67
05/17/2022 21:49:35 - INFO - __main__ - Global step 950 Train loss 1.46 Classification-F1 0.04792123861973869 on epoch=67
05/17/2022 21:49:35 - INFO - __main__ - Saving model with best Classification-F1: 0.03067956349206349 -> 0.04792123861973869 on epoch=67, global_step=950
05/17/2022 21:49:36 - INFO - __main__ - Step 960 Global step 960 Train loss 1.38 on epoch=68
05/17/2022 21:49:38 - INFO - __main__ - Step 970 Global step 970 Train loss 1.45 on epoch=69
05/17/2022 21:49:39 - INFO - __main__ - Step 980 Global step 980 Train loss 1.45 on epoch=69
05/17/2022 21:49:40 - INFO - __main__ - Step 990 Global step 990 Train loss 1.39 on epoch=70
05/17/2022 21:49:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.37 on epoch=71
05/17/2022 21:49:44 - INFO - __main__ - Global step 1000 Train loss 1.41 Classification-F1 0.04939476108307277 on epoch=71
05/17/2022 21:49:44 - INFO - __main__ - Saving model with best Classification-F1: 0.04792123861973869 -> 0.04939476108307277 on epoch=71, global_step=1000
05/17/2022 21:49:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.33 on epoch=72
05/17/2022 21:49:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=72
05/17/2022 21:49:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.34 on epoch=73
05/17/2022 21:49:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.40 on epoch=74
05/17/2022 21:49:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.43 on epoch=74
05/17/2022 21:49:53 - INFO - __main__ - Global step 1050 Train loss 1.39 Classification-F1 0.04803276025050218 on epoch=74
05/17/2022 21:49:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.31 on epoch=75
05/17/2022 21:49:55 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.44 on epoch=76
05/17/2022 21:49:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.38 on epoch=77
05/17/2022 21:49:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.35 on epoch=77
05/17/2022 21:49:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.29 on epoch=78
05/17/2022 21:50:02 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.05794213277951318 on epoch=78
05/17/2022 21:50:02 - INFO - __main__ - Saving model with best Classification-F1: 0.04939476108307277 -> 0.05794213277951318 on epoch=78, global_step=1100
05/17/2022 21:50:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=79
05/17/2022 21:50:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.31 on epoch=79
05/17/2022 21:50:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.32 on epoch=80
05/17/2022 21:50:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.32 on epoch=81
05/17/2022 21:50:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.25 on epoch=82
05/17/2022 21:50:10 - INFO - __main__ - Global step 1150 Train loss 1.31 Classification-F1 0.0499343256511021 on epoch=82
05/17/2022 21:50:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=82
05/17/2022 21:50:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=83
05/17/2022 21:50:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.21 on epoch=84
05/17/2022 21:50:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.28 on epoch=84
05/17/2022 21:50:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.18 on epoch=85
05/17/2022 21:50:19 - INFO - __main__ - Global step 1200 Train loss 1.28 Classification-F1 0.04756870136893395 on epoch=85
05/17/2022 21:50:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.27 on epoch=86
05/17/2022 21:50:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.27 on epoch=87
05/17/2022 21:50:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.26 on epoch=87
05/17/2022 21:50:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.24 on epoch=88
05/17/2022 21:50:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.32 on epoch=89
05/17/2022 21:50:28 - INFO - __main__ - Global step 1250 Train loss 1.27 Classification-F1 0.06915534078324777 on epoch=89
05/17/2022 21:50:28 - INFO - __main__ - Saving model with best Classification-F1: 0.05794213277951318 -> 0.06915534078324777 on epoch=89, global_step=1250
05/17/2022 21:50:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=89
05/17/2022 21:50:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.20 on epoch=90
05/17/2022 21:50:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.25 on epoch=91
05/17/2022 21:50:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.27 on epoch=92
05/17/2022 21:50:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.27 on epoch=92
05/17/2022 21:50:37 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.05924928960982092 on epoch=92
05/17/2022 21:50:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.22 on epoch=93
05/17/2022 21:50:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.25 on epoch=94
05/17/2022 21:50:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.26 on epoch=94
05/17/2022 21:50:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.10 on epoch=95
05/17/2022 21:50:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.33 on epoch=96
05/17/2022 21:50:45 - INFO - __main__ - Global step 1350 Train loss 1.23 Classification-F1 0.08458773777922714 on epoch=96
05/17/2022 21:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.06915534078324777 -> 0.08458773777922714 on epoch=96, global_step=1350
05/17/2022 21:50:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.22 on epoch=97
05/17/2022 21:50:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.34 on epoch=97
05/17/2022 21:50:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.20 on epoch=98
05/17/2022 21:50:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.29 on epoch=99
05/17/2022 21:50:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.14 on epoch=99
05/17/2022 21:50:53 - INFO - __main__ - Global step 1400 Train loss 1.24 Classification-F1 0.0685863675720869 on epoch=99
05/17/2022 21:50:54 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.21 on epoch=100
05/17/2022 21:50:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.25 on epoch=101
05/17/2022 21:50:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=102
05/17/2022 21:50:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.30 on epoch=102
05/17/2022 21:50:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.17 on epoch=103
05/17/2022 21:51:02 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.04411696518919155 on epoch=103
05/17/2022 21:51:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.22 on epoch=104
05/17/2022 21:51:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.26 on epoch=104
05/17/2022 21:51:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.11 on epoch=105
05/17/2022 21:51:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.22 on epoch=106
05/17/2022 21:51:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.16 on epoch=107
05/17/2022 21:51:10 - INFO - __main__ - Global step 1500 Train loss 1.19 Classification-F1 0.07713626989595815 on epoch=107
05/17/2022 21:51:12 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.23 on epoch=107
05/17/2022 21:51:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.24 on epoch=108
05/17/2022 21:51:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/17/2022 21:51:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.22 on epoch=109
05/17/2022 21:51:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.21 on epoch=110
05/17/2022 21:51:19 - INFO - __main__ - Global step 1550 Train loss 1.22 Classification-F1 0.11540874584352845 on epoch=110
05/17/2022 21:51:19 - INFO - __main__ - Saving model with best Classification-F1: 0.08458773777922714 -> 0.11540874584352845 on epoch=110, global_step=1550
05/17/2022 21:51:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.20 on epoch=111
05/17/2022 21:51:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=112
05/17/2022 21:51:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=112
05/17/2022 21:51:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.16 on epoch=113
05/17/2022 21:51:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=114
05/17/2022 21:51:28 - INFO - __main__ - Global step 1600 Train loss 1.18 Classification-F1 0.11527548082169933 on epoch=114
05/17/2022 21:51:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.19 on epoch=114
05/17/2022 21:51:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.14 on epoch=115
05/17/2022 21:51:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.17 on epoch=116
05/17/2022 21:51:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.20 on epoch=117
05/17/2022 21:51:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.25 on epoch=117
05/17/2022 21:51:37 - INFO - __main__ - Global step 1650 Train loss 1.19 Classification-F1 0.13881061059158104 on epoch=117
05/17/2022 21:51:37 - INFO - __main__ - Saving model with best Classification-F1: 0.11540874584352845 -> 0.13881061059158104 on epoch=117, global_step=1650
05/17/2022 21:51:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.16 on epoch=118
05/17/2022 21:51:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.13 on epoch=119
05/17/2022 21:51:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.19 on epoch=119
05/17/2022 21:51:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=120
05/17/2022 21:51:43 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=121
05/17/2022 21:51:46 - INFO - __main__ - Global step 1700 Train loss 1.14 Classification-F1 0.14096341239198382 on epoch=121
05/17/2022 21:51:46 - INFO - __main__ - Saving model with best Classification-F1: 0.13881061059158104 -> 0.14096341239198382 on epoch=121, global_step=1700
05/17/2022 21:51:47 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.16 on epoch=122
05/17/2022 21:51:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.14 on epoch=122
05/17/2022 21:51:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=123
05/17/2022 21:51:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.18 on epoch=124
05/17/2022 21:51:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.26 on epoch=124
05/17/2022 21:51:55 - INFO - __main__ - Global step 1750 Train loss 1.19 Classification-F1 0.16674048691517346 on epoch=124
05/17/2022 21:51:55 - INFO - __main__ - Saving model with best Classification-F1: 0.14096341239198382 -> 0.16674048691517346 on epoch=124, global_step=1750
05/17/2022 21:51:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.07 on epoch=125
05/17/2022 21:51:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=126
05/17/2022 21:51:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=127
05/17/2022 21:52:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.21 on epoch=127
05/17/2022 21:52:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=128
05/17/2022 21:52:04 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.16225704664983603 on epoch=128
05/17/2022 21:52:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.19 on epoch=129
05/17/2022 21:52:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.23 on epoch=129
05/17/2022 21:52:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=130
05/17/2022 21:52:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/17/2022 21:52:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.08 on epoch=132
05/17/2022 21:52:13 - INFO - __main__ - Global step 1850 Train loss 1.16 Classification-F1 0.14134748102139408 on epoch=132
05/17/2022 21:52:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.16 on epoch=132
05/17/2022 21:52:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=133
05/17/2022 21:52:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.15 on epoch=134
05/17/2022 21:52:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.15 on epoch=134
05/17/2022 21:52:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.00 on epoch=135
05/17/2022 21:52:22 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.2222517003742705 on epoch=135
05/17/2022 21:52:22 - INFO - __main__ - Saving model with best Classification-F1: 0.16674048691517346 -> 0.2222517003742705 on epoch=135, global_step=1900
05/17/2022 21:52:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=136
05/17/2022 21:52:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=137
05/17/2022 21:52:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.16 on epoch=137
05/17/2022 21:52:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.08 on epoch=138
05/17/2022 21:52:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.10 on epoch=139
05/17/2022 21:52:31 - INFO - __main__ - Global step 1950 Train loss 1.12 Classification-F1 0.24056229689712377 on epoch=139
05/17/2022 21:52:31 - INFO - __main__ - Saving model with best Classification-F1: 0.2222517003742705 -> 0.24056229689712377 on epoch=139, global_step=1950
05/17/2022 21:52:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=139
05/17/2022 21:52:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=140
05/17/2022 21:52:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.06 on epoch=141
05/17/2022 21:52:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=142
05/17/2022 21:52:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.09 on epoch=142
05/17/2022 21:52:41 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.19641073100925074 on epoch=142
05/17/2022 21:52:42 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.07 on epoch=143
05/17/2022 21:52:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=144
05/17/2022 21:52:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.14 on epoch=144
05/17/2022 21:52:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=145
05/17/2022 21:52:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.12 on epoch=146
05/17/2022 21:52:50 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.2943865559866793 on epoch=146
05/17/2022 21:52:50 - INFO - __main__ - Saving model with best Classification-F1: 0.24056229689712377 -> 0.2943865559866793 on epoch=146, global_step=2050
05/17/2022 21:52:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=147
05/17/2022 21:52:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.13 on epoch=147
05/17/2022 21:52:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=148
05/17/2022 21:52:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=149
05/17/2022 21:52:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/17/2022 21:53:00 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.26983418179367963 on epoch=149
05/17/2022 21:53:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.02 on epoch=150
05/17/2022 21:53:02 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.06 on epoch=151
05/17/2022 21:53:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=152
05/17/2022 21:53:05 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.09 on epoch=152
05/17/2022 21:53:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.05 on epoch=153
05/17/2022 21:53:09 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.2373113189565783 on epoch=153
05/17/2022 21:53:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.07 on epoch=154
05/17/2022 21:53:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.13 on epoch=154
05/17/2022 21:53:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.08 on epoch=155
05/17/2022 21:53:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=156
05/17/2022 21:53:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=157
05/17/2022 21:53:19 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.2748616907286598 on epoch=157
05/17/2022 21:53:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=157
05/17/2022 21:53:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=158
05/17/2022 21:53:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.03 on epoch=159
05/17/2022 21:53:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.14 on epoch=159
05/17/2022 21:53:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=160
05/17/2022 21:53:28 - INFO - __main__ - Global step 2250 Train loss 1.04 Classification-F1 0.3158445048094584 on epoch=160
05/17/2022 21:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2943865559866793 -> 0.3158445048094584 on epoch=160, global_step=2250
05/17/2022 21:53:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=161
05/17/2022 21:53:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=162
05/17/2022 21:53:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.13 on epoch=162
05/17/2022 21:53:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=163
05/17/2022 21:53:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=164
05/17/2022 21:53:38 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.3075308699899804 on epoch=164
05/17/2022 21:53:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.04 on epoch=164
05/17/2022 21:53:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.03 on epoch=165
05/17/2022 21:53:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=166
05/17/2022 21:53:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=167
05/17/2022 21:53:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=167
05/17/2022 21:53:48 - INFO - __main__ - Global step 2350 Train loss 1.03 Classification-F1 0.346450658435821 on epoch=167
05/17/2022 21:53:48 - INFO - __main__ - Saving model with best Classification-F1: 0.3158445048094584 -> 0.346450658435821 on epoch=167, global_step=2350
05/17/2022 21:53:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.04 on epoch=168
05/17/2022 21:53:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.01 on epoch=169
05/17/2022 21:53:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=169
05/17/2022 21:53:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=170
05/17/2022 21:53:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=171
05/17/2022 21:53:57 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.2524536469599495 on epoch=171
05/17/2022 21:53:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=172
05/17/2022 21:54:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=172
05/17/2022 21:54:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.07 on epoch=173
05/17/2022 21:54:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.96 on epoch=174
05/17/2022 21:54:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=174
05/17/2022 21:54:07 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.36388517439658935 on epoch=174
05/17/2022 21:54:07 - INFO - __main__ - Saving model with best Classification-F1: 0.346450658435821 -> 0.36388517439658935 on epoch=174, global_step=2450
05/17/2022 21:54:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.90 on epoch=175
05/17/2022 21:54:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=176
05/17/2022 21:54:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=177
05/17/2022 21:54:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.01 on epoch=177
05/17/2022 21:54:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=178
05/17/2022 21:54:17 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.3478209128492417 on epoch=178
05/17/2022 21:54:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.93 on epoch=179
05/17/2022 21:54:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=179
05/17/2022 21:54:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=180
05/17/2022 21:54:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=181
05/17/2022 21:54:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.98 on epoch=182
05/17/2022 21:54:26 - INFO - __main__ - Global step 2550 Train loss 0.99 Classification-F1 0.35018783751025967 on epoch=182
05/17/2022 21:54:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=182
05/17/2022 21:54:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=183
05/17/2022 21:54:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.02 on epoch=184
05/17/2022 21:54:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=184
05/17/2022 21:54:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=185
05/17/2022 21:54:36 - INFO - __main__ - Global step 2600 Train loss 1.03 Classification-F1 0.3277174796744894 on epoch=185
05/17/2022 21:54:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.01 on epoch=186
05/17/2022 21:54:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.98 on epoch=187
05/17/2022 21:54:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=187
05/17/2022 21:54:41 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.91 on epoch=188
05/17/2022 21:54:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.95 on epoch=189
05/17/2022 21:54:46 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.39138654601867057 on epoch=189
05/17/2022 21:54:46 - INFO - __main__ - Saving model with best Classification-F1: 0.36388517439658935 -> 0.39138654601867057 on epoch=189, global_step=2650
05/17/2022 21:54:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=189
05/17/2022 21:54:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.90 on epoch=190
05/17/2022 21:54:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=191
05/17/2022 21:54:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.94 on epoch=192
05/17/2022 21:54:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.95 on epoch=192
05/17/2022 21:54:56 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.37441539461634454 on epoch=192
05/17/2022 21:54:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.82 on epoch=193
05/17/2022 21:54:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.04 on epoch=194
05/17/2022 21:54:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=194
05/17/2022 21:55:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.97 on epoch=195
05/17/2022 21:55:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=196
05/17/2022 21:55:05 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.4095379807471741 on epoch=196
05/17/2022 21:55:05 - INFO - __main__ - Saving model with best Classification-F1: 0.39138654601867057 -> 0.4095379807471741 on epoch=196, global_step=2750
05/17/2022 21:55:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=197
05/17/2022 21:55:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.96 on epoch=197
05/17/2022 21:55:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=198
05/17/2022 21:55:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=199
05/17/2022 21:55:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.04 on epoch=199
05/17/2022 21:55:15 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.46417910590680617 on epoch=199
05/17/2022 21:55:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4095379807471741 -> 0.46417910590680617 on epoch=199, global_step=2800
05/17/2022 21:55:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/17/2022 21:55:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=201
05/17/2022 21:55:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=202
05/17/2022 21:55:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.91 on epoch=202
05/17/2022 21:55:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.87 on epoch=203
05/17/2022 21:55:25 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.4684274225952281 on epoch=203
05/17/2022 21:55:25 - INFO - __main__ - Saving model with best Classification-F1: 0.46417910590680617 -> 0.4684274225952281 on epoch=203, global_step=2850
05/17/2022 21:55:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.96 on epoch=204
05/17/2022 21:55:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=204
05/17/2022 21:55:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.01 on epoch=205
05/17/2022 21:55:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=206
05/17/2022 21:55:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.92 on epoch=207
05/17/2022 21:55:35 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.4571062386029635 on epoch=207
05/17/2022 21:55:36 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.08 on epoch=207
05/17/2022 21:55:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.96 on epoch=208
05/17/2022 21:55:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=209
05/17/2022 21:55:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.90 on epoch=209
05/17/2022 21:55:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.85 on epoch=210
05/17/2022 21:55:45 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.45229996661549016 on epoch=210
05/17/2022 21:55:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=211
05/17/2022 21:55:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=212
05/17/2022 21:55:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.02 on epoch=212
05/17/2022 21:55:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=213
05/17/2022 21:55:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=214
05/17/2022 21:55:55 - INFO - __main__ - Global step 3000 Train loss 0.95 Classification-F1 0.4312321683226501 on epoch=214
05/17/2022 21:55:55 - INFO - __main__ - save last model!
05/17/2022 21:55:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/17/2022 21:55:55 - INFO - __main__ - Start tokenizing ... 3500 instances
05/17/2022 21:55:55 - INFO - __main__ - Printing 3 examples
05/17/2022 21:55:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/17/2022 21:55:55 - INFO - __main__ - ['Animal']
05/17/2022 21:55:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/17/2022 21:55:55 - INFO - __main__ - ['Animal']
05/17/2022 21:55:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/17/2022 21:55:55 - INFO - __main__ - ['Village']
05/17/2022 21:55:55 - INFO - __main__ - Tokenizing Input ...
05/17/2022 21:55:57 - INFO - __main__ - Tokenizing Output ...
05/17/2022 21:56:00 - INFO - __main__ - Loaded 3500 examples from test data
05/17/2022 21:56:59 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/17/2022 21:56:59 - INFO - __main__ - Classification-F1 on test data: 0.2797
05/17/2022 21:57:00 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.4684274225952281, test_performance=0.27969846356523553
05/21/2022 03:48:11 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-multitask-cls2cls-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
05/21/2022 03:48:11 - INFO - __main__ - models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14
05/21/2022 03:48:11 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-base-multitask-cls2cls-5e-1-4-20', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-base-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/base/pytorch_model.bin', model='google/t5-v1_1-base', prompt_number=100, cuda='4,5')
05/21/2022 03:48:11 - INFO - __main__ - models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14
05/21/2022 03:48:13 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 03:48:13 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 03:48:13 - INFO - __main__ - args.device: cuda:0
05/21/2022 03:48:13 - INFO - __main__ - Using 2 gpus
05/21/2022 03:48:13 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 03:48:13 - INFO - __main__ - args.device: cuda:1
05/21/2022 03:48:13 - INFO - __main__ - Using 2 gpus
05/21/2022 03:48:13 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 03:48:21 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/21/2022 03:48:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:48:22 - INFO - __main__ - Printing 3 examples
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:48:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:48:22 - INFO - __main__ - Printing 3 examples
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:48:22 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 03:48:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:48:22 - INFO - __main__ - Printing 3 examples
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:48:22 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 03:48:22 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:48:22 - INFO - __main__ - Printing 3 examples
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 03:48:22 - INFO - __main__ - ['Animal']
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:48:22 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:48:22 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 03:48:22 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 03:48:28 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 03:48:28 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 03:48:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 03:48:29 - INFO - __main__ - Starting training!
05/21/2022 03:48:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 03:48:34 - INFO - __main__ - Starting training!
05/21/2022 03:48:36 - INFO - __main__ - Step 10 Global step 10 Train loss 7.28 on epoch=0
05/21/2022 03:48:38 - INFO - __main__ - Step 20 Global step 20 Train loss 6.86 on epoch=1
05/21/2022 03:48:39 - INFO - __main__ - Step 30 Global step 30 Train loss 6.21 on epoch=2
05/21/2022 03:48:40 - INFO - __main__ - Step 40 Global step 40 Train loss 5.46 on epoch=2
05/21/2022 03:48:41 - INFO - __main__ - Step 50 Global step 50 Train loss 5.23 on epoch=3
05/21/2022 03:48:45 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=3
05/21/2022 03:48:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 03:48:46 - INFO - __main__ - Step 60 Global step 60 Train loss 4.86 on epoch=4
05/21/2022 03:48:47 - INFO - __main__ - Step 70 Global step 70 Train loss 4.31 on epoch=4
05/21/2022 03:48:49 - INFO - __main__ - Step 80 Global step 80 Train loss 4.33 on epoch=5
05/21/2022 03:48:50 - INFO - __main__ - Step 90 Global step 90 Train loss 3.68 on epoch=6
05/21/2022 03:48:51 - INFO - __main__ - Step 100 Global step 100 Train loss 3.79 on epoch=7
05/21/2022 03:48:55 - INFO - __main__ - Global step 100 Train loss 4.19 Classification-F1 0.0 on epoch=7
05/21/2022 03:48:56 - INFO - __main__ - Step 110 Global step 110 Train loss 3.37 on epoch=7
05/21/2022 03:48:57 - INFO - __main__ - Step 120 Global step 120 Train loss 3.39 on epoch=8
05/21/2022 03:48:58 - INFO - __main__ - Step 130 Global step 130 Train loss 3.10 on epoch=9
05/21/2022 03:49:00 - INFO - __main__ - Step 140 Global step 140 Train loss 3.03 on epoch=9
05/21/2022 03:49:01 - INFO - __main__ - Step 150 Global step 150 Train loss 2.97 on epoch=10
05/21/2022 03:49:03 - INFO - __main__ - Global step 150 Train loss 3.17 Classification-F1 0.009523809523809523 on epoch=10
05/21/2022 03:49:04 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009523809523809523 on epoch=10, global_step=150
05/21/2022 03:49:05 - INFO - __main__ - Step 160 Global step 160 Train loss 2.71 on epoch=11
05/21/2022 03:49:06 - INFO - __main__ - Step 170 Global step 170 Train loss 2.62 on epoch=12
05/21/2022 03:49:07 - INFO - __main__ - Step 180 Global step 180 Train loss 2.64 on epoch=12
05/21/2022 03:49:09 - INFO - __main__ - Step 190 Global step 190 Train loss 2.40 on epoch=13
05/21/2022 03:49:10 - INFO - __main__ - Step 200 Global step 200 Train loss 2.25 on epoch=14
05/21/2022 03:49:12 - INFO - __main__ - Global step 200 Train loss 2.53 Classification-F1 0.009523809523809523 on epoch=14
05/21/2022 03:49:13 - INFO - __main__ - Step 210 Global step 210 Train loss 2.34 on epoch=14
05/21/2022 03:49:14 - INFO - __main__ - Step 220 Global step 220 Train loss 2.12 on epoch=15
05/21/2022 03:49:15 - INFO - __main__ - Step 230 Global step 230 Train loss 2.11 on epoch=16
05/21/2022 03:49:17 - INFO - __main__ - Step 240 Global step 240 Train loss 2.10 on epoch=17
05/21/2022 03:49:18 - INFO - __main__ - Step 250 Global step 250 Train loss 1.97 on epoch=17
05/21/2022 03:49:20 - INFO - __main__ - Global step 250 Train loss 2.13 Classification-F1 0.009523809523809523 on epoch=17
05/21/2022 03:49:22 - INFO - __main__ - Step 260 Global step 260 Train loss 2.10 on epoch=18
05/21/2022 03:49:23 - INFO - __main__ - Step 270 Global step 270 Train loss 1.83 on epoch=19
05/21/2022 03:49:24 - INFO - __main__ - Step 280 Global step 280 Train loss 1.84 on epoch=19
05/21/2022 03:49:25 - INFO - __main__ - Step 290 Global step 290 Train loss 1.80 on epoch=20
05/21/2022 03:49:27 - INFO - __main__ - Step 300 Global step 300 Train loss 1.80 on epoch=21
05/21/2022 03:49:29 - INFO - __main__ - Global step 300 Train loss 1.87 Classification-F1 0.01728337236533958 on epoch=21
05/21/2022 03:49:29 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01728337236533958 on epoch=21, global_step=300
05/21/2022 03:49:30 - INFO - __main__ - Step 310 Global step 310 Train loss 1.67 on epoch=22
05/21/2022 03:49:32 - INFO - __main__ - Step 320 Global step 320 Train loss 1.66 on epoch=22
05/21/2022 03:49:33 - INFO - __main__ - Step 330 Global step 330 Train loss 1.63 on epoch=23
05/21/2022 03:49:34 - INFO - __main__ - Step 340 Global step 340 Train loss 1.54 on epoch=24
05/21/2022 03:49:36 - INFO - __main__ - Step 350 Global step 350 Train loss 1.55 on epoch=24
05/21/2022 03:49:38 - INFO - __main__ - Global step 350 Train loss 1.61 Classification-F1 0.03886910830946177 on epoch=24
05/21/2022 03:49:38 - INFO - __main__ - Saving model with best Classification-F1: 0.01728337236533958 -> 0.03886910830946177 on epoch=24, global_step=350
05/21/2022 03:49:40 - INFO - __main__ - Step 360 Global step 360 Train loss 1.54 on epoch=25
05/21/2022 03:49:41 - INFO - __main__ - Step 370 Global step 370 Train loss 1.48 on epoch=26
05/21/2022 03:49:42 - INFO - __main__ - Step 380 Global step 380 Train loss 1.50 on epoch=27
05/21/2022 03:49:44 - INFO - __main__ - Step 390 Global step 390 Train loss 1.43 on epoch=27
05/21/2022 03:49:45 - INFO - __main__ - Step 400 Global step 400 Train loss 1.41 on epoch=28
05/21/2022 03:49:48 - INFO - __main__ - Global step 400 Train loss 1.47 Classification-F1 0.03216419492132231 on epoch=28
05/21/2022 03:49:49 - INFO - __main__ - Step 410 Global step 410 Train loss 1.39 on epoch=29
05/21/2022 03:49:50 - INFO - __main__ - Step 420 Global step 420 Train loss 1.37 on epoch=29
05/21/2022 03:49:52 - INFO - __main__ - Step 430 Global step 430 Train loss 1.40 on epoch=30
05/21/2022 03:49:53 - INFO - __main__ - Step 440 Global step 440 Train loss 1.42 on epoch=31
05/21/2022 03:49:54 - INFO - __main__ - Step 450 Global step 450 Train loss 1.30 on epoch=32
05/21/2022 03:49:58 - INFO - __main__ - Global step 450 Train loss 1.38 Classification-F1 0.061876928790714936 on epoch=32
05/21/2022 03:49:58 - INFO - __main__ - Saving model with best Classification-F1: 0.03886910830946177 -> 0.061876928790714936 on epoch=32, global_step=450
05/21/2022 03:49:59 - INFO - __main__ - Step 460 Global step 460 Train loss 1.37 on epoch=32
05/21/2022 03:50:00 - INFO - __main__ - Step 470 Global step 470 Train loss 1.33 on epoch=33
05/21/2022 03:50:01 - INFO - __main__ - Step 480 Global step 480 Train loss 1.25 on epoch=34
05/21/2022 03:50:03 - INFO - __main__ - Step 490 Global step 490 Train loss 1.37 on epoch=34
05/21/2022 03:50:04 - INFO - __main__ - Step 500 Global step 500 Train loss 1.29 on epoch=35
05/21/2022 03:50:06 - INFO - __main__ - Global step 500 Train loss 1.32 Classification-F1 0.08144766775324959 on epoch=35
05/21/2022 03:50:06 - INFO - __main__ - Saving model with best Classification-F1: 0.061876928790714936 -> 0.08144766775324959 on epoch=35, global_step=500
05/21/2022 03:50:08 - INFO - __main__ - Step 510 Global step 510 Train loss 1.25 on epoch=36
05/21/2022 03:50:09 - INFO - __main__ - Step 520 Global step 520 Train loss 1.28 on epoch=37
05/21/2022 03:50:10 - INFO - __main__ - Step 530 Global step 530 Train loss 1.24 on epoch=37
05/21/2022 03:50:12 - INFO - __main__ - Step 540 Global step 540 Train loss 1.24 on epoch=38
05/21/2022 03:50:13 - INFO - __main__ - Step 550 Global step 550 Train loss 1.19 on epoch=39
05/21/2022 03:50:16 - INFO - __main__ - Global step 550 Train loss 1.24 Classification-F1 0.15418477854189722 on epoch=39
05/21/2022 03:50:16 - INFO - __main__ - Saving model with best Classification-F1: 0.08144766775324959 -> 0.15418477854189722 on epoch=39, global_step=550
05/21/2022 03:50:17 - INFO - __main__ - Step 560 Global step 560 Train loss 1.25 on epoch=39
05/21/2022 03:50:19 - INFO - __main__ - Step 570 Global step 570 Train loss 1.21 on epoch=40
05/21/2022 03:50:20 - INFO - __main__ - Step 580 Global step 580 Train loss 1.10 on epoch=41
05/21/2022 03:50:22 - INFO - __main__ - Step 590 Global step 590 Train loss 1.27 on epoch=42
05/21/2022 03:50:23 - INFO - __main__ - Step 600 Global step 600 Train loss 1.22 on epoch=42
05/21/2022 03:50:26 - INFO - __main__ - Global step 600 Train loss 1.21 Classification-F1 0.0996702189647789 on epoch=42
05/21/2022 03:50:27 - INFO - __main__ - Step 610 Global step 610 Train loss 1.21 on epoch=43
05/21/2022 03:50:28 - INFO - __main__ - Step 620 Global step 620 Train loss 1.17 on epoch=44
05/21/2022 03:50:30 - INFO - __main__ - Step 630 Global step 630 Train loss 1.27 on epoch=44
05/21/2022 03:50:31 - INFO - __main__ - Step 640 Global step 640 Train loss 1.11 on epoch=45
05/21/2022 03:50:32 - INFO - __main__ - Step 650 Global step 650 Train loss 1.20 on epoch=46
05/21/2022 03:50:35 - INFO - __main__ - Global step 650 Train loss 1.19 Classification-F1 0.09371274882764875 on epoch=46
05/21/2022 03:50:37 - INFO - __main__ - Step 660 Global step 660 Train loss 1.28 on epoch=47
05/21/2022 03:50:38 - INFO - __main__ - Step 670 Global step 670 Train loss 1.16 on epoch=47
05/21/2022 03:50:40 - INFO - __main__ - Step 680 Global step 680 Train loss 1.17 on epoch=48
05/21/2022 03:50:41 - INFO - __main__ - Step 690 Global step 690 Train loss 1.11 on epoch=49
05/21/2022 03:50:42 - INFO - __main__ - Step 700 Global step 700 Train loss 1.25 on epoch=49
05/21/2022 03:50:46 - INFO - __main__ - Global step 700 Train loss 1.19 Classification-F1 0.04073679222932954 on epoch=49
05/21/2022 03:50:47 - INFO - __main__ - Step 710 Global step 710 Train loss 1.11 on epoch=50
05/21/2022 03:50:48 - INFO - __main__ - Step 720 Global step 720 Train loss 1.17 on epoch=51
05/21/2022 03:50:50 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/21/2022 03:50:51 - INFO - __main__ - Step 740 Global step 740 Train loss 1.19 on epoch=52
05/21/2022 03:50:52 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/21/2022 03:50:55 - INFO - __main__ - Global step 750 Train loss 1.15 Classification-F1 0.07860756879500853 on epoch=53
05/21/2022 03:50:57 - INFO - __main__ - Step 760 Global step 760 Train loss 1.07 on epoch=54
05/21/2022 03:50:58 - INFO - __main__ - Step 770 Global step 770 Train loss 1.17 on epoch=54
05/21/2022 03:50:59 - INFO - __main__ - Step 780 Global step 780 Train loss 1.17 on epoch=55
05/21/2022 03:51:01 - INFO - __main__ - Step 790 Global step 790 Train loss 1.18 on epoch=56
05/21/2022 03:51:02 - INFO - __main__ - Step 800 Global step 800 Train loss 1.13 on epoch=57
05/21/2022 03:51:05 - INFO - __main__ - Global step 800 Train loss 1.14 Classification-F1 0.18043113784568243 on epoch=57
05/21/2022 03:51:05 - INFO - __main__ - Saving model with best Classification-F1: 0.15418477854189722 -> 0.18043113784568243 on epoch=57, global_step=800
05/21/2022 03:51:06 - INFO - __main__ - Step 810 Global step 810 Train loss 1.09 on epoch=57
05/21/2022 03:51:08 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=58
05/21/2022 03:51:09 - INFO - __main__ - Step 830 Global step 830 Train loss 1.01 on epoch=59
05/21/2022 03:51:10 - INFO - __main__ - Step 840 Global step 840 Train loss 1.04 on epoch=59
05/21/2022 03:51:12 - INFO - __main__ - Step 850 Global step 850 Train loss 1.06 on epoch=60
05/21/2022 03:51:15 - INFO - __main__ - Global step 850 Train loss 1.07 Classification-F1 0.29804622826647764 on epoch=60
05/21/2022 03:51:15 - INFO - __main__ - Saving model with best Classification-F1: 0.18043113784568243 -> 0.29804622826647764 on epoch=60, global_step=850
05/21/2022 03:51:16 - INFO - __main__ - Step 860 Global step 860 Train loss 1.14 on epoch=61
05/21/2022 03:51:17 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=62
05/21/2022 03:51:19 - INFO - __main__ - Step 880 Global step 880 Train loss 1.07 on epoch=62
05/21/2022 03:51:20 - INFO - __main__ - Step 890 Global step 890 Train loss 1.09 on epoch=63
05/21/2022 03:51:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.98 on epoch=64
05/21/2022 03:51:24 - INFO - __main__ - Global step 900 Train loss 1.09 Classification-F1 0.34361367156739214 on epoch=64
05/21/2022 03:51:25 - INFO - __main__ - Saving model with best Classification-F1: 0.29804622826647764 -> 0.34361367156739214 on epoch=64, global_step=900
05/21/2022 03:51:26 - INFO - __main__ - Step 910 Global step 910 Train loss 1.11 on epoch=64
05/21/2022 03:51:27 - INFO - __main__ - Step 920 Global step 920 Train loss 1.05 on epoch=65
05/21/2022 03:51:28 - INFO - __main__ - Step 930 Global step 930 Train loss 1.14 on epoch=66
05/21/2022 03:51:30 - INFO - __main__ - Step 940 Global step 940 Train loss 1.10 on epoch=67
05/21/2022 03:51:31 - INFO - __main__ - Step 950 Global step 950 Train loss 1.00 on epoch=67
05/21/2022 03:51:35 - INFO - __main__ - Global step 950 Train loss 1.08 Classification-F1 0.35467541863793733 on epoch=67
05/21/2022 03:51:35 - INFO - __main__ - Saving model with best Classification-F1: 0.34361367156739214 -> 0.35467541863793733 on epoch=67, global_step=950
05/21/2022 03:51:36 - INFO - __main__ - Step 960 Global step 960 Train loss 1.03 on epoch=68
05/21/2022 03:51:37 - INFO - __main__ - Step 970 Global step 970 Train loss 0.98 on epoch=69
05/21/2022 03:51:38 - INFO - __main__ - Step 980 Global step 980 Train loss 1.05 on epoch=69
05/21/2022 03:51:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.99 on epoch=70
05/21/2022 03:51:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.98 on epoch=71
05/21/2022 03:51:45 - INFO - __main__ - Global step 1000 Train loss 1.01 Classification-F1 0.41515727280869835 on epoch=71
05/21/2022 03:51:45 - INFO - __main__ - Saving model with best Classification-F1: 0.35467541863793733 -> 0.41515727280869835 on epoch=71, global_step=1000
05/21/2022 03:51:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/21/2022 03:51:47 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.99 on epoch=72
05/21/2022 03:51:48 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.01 on epoch=73
05/21/2022 03:51:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.96 on epoch=74
05/21/2022 03:51:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.97 on epoch=74
05/21/2022 03:51:55 - INFO - __main__ - Global step 1050 Train loss 0.99 Classification-F1 0.4906442202748969 on epoch=74
05/21/2022 03:51:55 - INFO - __main__ - Saving model with best Classification-F1: 0.41515727280869835 -> 0.4906442202748969 on epoch=74, global_step=1050
05/21/2022 03:51:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.06 on epoch=75
05/21/2022 03:51:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.04 on epoch=76
05/21/2022 03:51:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.01 on epoch=77
05/21/2022 03:52:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.02 on epoch=77
05/21/2022 03:52:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.00 on epoch=78
05/21/2022 03:52:05 - INFO - __main__ - Global step 1100 Train loss 1.02 Classification-F1 0.49409776660497573 on epoch=78
05/21/2022 03:52:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4906442202748969 -> 0.49409776660497573 on epoch=78, global_step=1100
05/21/2022 03:52:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.95 on epoch=79
05/21/2022 03:52:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/21/2022 03:52:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.91 on epoch=80
05/21/2022 03:52:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.95 on epoch=81
05/21/2022 03:52:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.00 on epoch=82
05/21/2022 03:52:15 - INFO - __main__ - Global step 1150 Train loss 0.95 Classification-F1 0.4647273301318002 on epoch=82
05/21/2022 03:52:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.83 on epoch=82
05/21/2022 03:52:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.85 on epoch=83
05/21/2022 03:52:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.85 on epoch=84
05/21/2022 03:52:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.84 on epoch=84
05/21/2022 03:52:21 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.85 on epoch=85
05/21/2022 03:52:25 - INFO - __main__ - Global step 1200 Train loss 0.84 Classification-F1 0.44596596604260846 on epoch=85
05/21/2022 03:52:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.82 on epoch=86
05/21/2022 03:52:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.82 on epoch=87
05/21/2022 03:52:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.81 on epoch=87
05/21/2022 03:52:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.85 on epoch=88
05/21/2022 03:52:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.79 on epoch=89
05/21/2022 03:52:35 - INFO - __main__ - Global step 1250 Train loss 0.82 Classification-F1 0.4157357352808112 on epoch=89
05/21/2022 03:52:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.90 on epoch=89
05/21/2022 03:52:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.86 on epoch=90
05/21/2022 03:52:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.79 on epoch=91
05/21/2022 03:52:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.81 on epoch=92
05/21/2022 03:52:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.83 on epoch=92
05/21/2022 03:52:45 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.4303783422080275 on epoch=92
05/21/2022 03:52:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.84 on epoch=93
05/21/2022 03:52:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.83 on epoch=94
05/21/2022 03:52:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.76 on epoch=94
05/21/2022 03:52:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.78 on epoch=95
05/21/2022 03:52:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.87 on epoch=96
05/21/2022 03:52:56 - INFO - __main__ - Global step 1350 Train loss 0.82 Classification-F1 0.42396406673620746 on epoch=96
05/21/2022 03:52:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.79 on epoch=97
05/21/2022 03:52:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.82 on epoch=97
05/21/2022 03:52:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.84 on epoch=98
05/21/2022 03:53:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.72 on epoch=99
05/21/2022 03:53:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.79 on epoch=99
05/21/2022 03:53:06 - INFO - __main__ - Global step 1400 Train loss 0.79 Classification-F1 0.39703179314276027 on epoch=99
05/21/2022 03:53:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/21/2022 03:53:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.85 on epoch=101
05/21/2022 03:53:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.74 on epoch=102
05/21/2022 03:53:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.78 on epoch=102
05/21/2022 03:53:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.81 on epoch=103
05/21/2022 03:53:16 - INFO - __main__ - Global step 1450 Train loss 0.79 Classification-F1 0.4088886866270234 on epoch=103
05/21/2022 03:53:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.74 on epoch=104
05/21/2022 03:53:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.79 on epoch=104
05/21/2022 03:53:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.66 on epoch=105
05/21/2022 03:53:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.79 on epoch=106
05/21/2022 03:53:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.74 on epoch=107
05/21/2022 03:53:27 - INFO - __main__ - Global step 1500 Train loss 0.74 Classification-F1 0.3813207016205517 on epoch=107
05/21/2022 03:53:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.75 on epoch=107
05/21/2022 03:53:29 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.78 on epoch=108
05/21/2022 03:53:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.79 on epoch=109
05/21/2022 03:53:32 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.70 on epoch=109
05/21/2022 03:53:34 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.77 on epoch=110
05/21/2022 03:53:38 - INFO - __main__ - Global step 1550 Train loss 0.76 Classification-F1 0.4055562518259034 on epoch=110
05/21/2022 03:53:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.69 on epoch=111
05/21/2022 03:53:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.70 on epoch=112
05/21/2022 03:53:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.68 on epoch=112
05/21/2022 03:53:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.73 on epoch=113
05/21/2022 03:53:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.67 on epoch=114
05/21/2022 03:53:48 - INFO - __main__ - Global step 1600 Train loss 0.70 Classification-F1 0.4397956662852786 on epoch=114
05/21/2022 03:53:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.78 on epoch=114
05/21/2022 03:53:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.73 on epoch=115
05/21/2022 03:53:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.66 on epoch=116
05/21/2022 03:53:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.81 on epoch=117
05/21/2022 03:53:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.57 on epoch=117
05/21/2022 03:53:58 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.5000456559314505 on epoch=117
05/21/2022 03:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.49409776660497573 -> 0.5000456559314505 on epoch=117, global_step=1650
05/21/2022 03:53:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.70 on epoch=118
05/21/2022 03:54:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.78 on epoch=119
05/21/2022 03:54:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.72 on epoch=119
05/21/2022 03:54:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.69 on epoch=120
05/21/2022 03:54:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.69 on epoch=121
05/21/2022 03:54:08 - INFO - __main__ - Global step 1700 Train loss 0.71 Classification-F1 0.4807801533850428 on epoch=121
05/21/2022 03:54:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.65 on epoch=122
05/21/2022 03:54:11 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.74 on epoch=122
05/21/2022 03:54:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.63 on epoch=123
05/21/2022 03:54:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.66 on epoch=124
05/21/2022 03:54:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.66 on epoch=124
05/21/2022 03:54:18 - INFO - __main__ - Global step 1750 Train loss 0.67 Classification-F1 0.49192001551749576 on epoch=124
05/21/2022 03:54:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.66 on epoch=125
05/21/2022 03:54:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.64 on epoch=126
05/21/2022 03:54:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.70 on epoch=127
05/21/2022 03:54:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.61 on epoch=127
05/21/2022 03:54:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.71 on epoch=128
05/21/2022 03:54:29 - INFO - __main__ - Global step 1800 Train loss 0.66 Classification-F1 0.49738870897331466 on epoch=128
05/21/2022 03:54:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.68 on epoch=129
05/21/2022 03:54:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.58 on epoch=129
05/21/2022 03:54:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.70 on epoch=130
05/21/2022 03:54:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.61 on epoch=131
05/21/2022 03:54:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.74 on epoch=132
05/21/2022 03:54:39 - INFO - __main__ - Global step 1850 Train loss 0.66 Classification-F1 0.5213543692622968 on epoch=132
05/21/2022 03:54:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5000456559314505 -> 0.5213543692622968 on epoch=132, global_step=1850
05/21/2022 03:54:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.57 on epoch=132
05/21/2022 03:54:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.60 on epoch=133
05/21/2022 03:54:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.64 on epoch=134
05/21/2022 03:54:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.65 on epoch=134
05/21/2022 03:54:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.70 on epoch=135
05/21/2022 03:54:49 - INFO - __main__ - Global step 1900 Train loss 0.63 Classification-F1 0.5604500882249385 on epoch=135
05/21/2022 03:54:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5213543692622968 -> 0.5604500882249385 on epoch=135, global_step=1900
05/21/2022 03:54:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.73 on epoch=136
05/21/2022 03:54:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.61 on epoch=137
05/21/2022 03:54:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.66 on epoch=137
05/21/2022 03:54:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.66 on epoch=138
05/21/2022 03:54:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.57 on epoch=139
05/21/2022 03:55:00 - INFO - __main__ - Global step 1950 Train loss 0.65 Classification-F1 0.5810103345855768 on epoch=139
05/21/2022 03:55:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5604500882249385 -> 0.5810103345855768 on epoch=139, global_step=1950
05/21/2022 03:55:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.62 on epoch=139
05/21/2022 03:55:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.60 on epoch=140
05/21/2022 03:55:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.66 on epoch=141
05/21/2022 03:55:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.72 on epoch=142
05/21/2022 03:55:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.60 on epoch=142
05/21/2022 03:55:10 - INFO - __main__ - Global step 2000 Train loss 0.64 Classification-F1 0.4721492983216242 on epoch=142
05/21/2022 03:55:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/21/2022 03:55:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.53 on epoch=144
05/21/2022 03:55:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.60 on epoch=144
05/21/2022 03:55:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.67 on epoch=145
05/21/2022 03:55:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/21/2022 03:55:21 - INFO - __main__ - Global step 2050 Train loss 0.62 Classification-F1 0.4613431389341754 on epoch=146
05/21/2022 03:55:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.67 on epoch=147
05/21/2022 03:55:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.68 on epoch=147
05/21/2022 03:55:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.54 on epoch=148
05/21/2022 03:55:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.60 on epoch=149
05/21/2022 03:55:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.57 on epoch=149
05/21/2022 03:55:31 - INFO - __main__ - Global step 2100 Train loss 0.61 Classification-F1 0.5011425157483176 on epoch=149
05/21/2022 03:55:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.57 on epoch=150
05/21/2022 03:55:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/21/2022 03:55:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.58 on epoch=152
05/21/2022 03:55:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.47 on epoch=152
05/21/2022 03:55:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.61 on epoch=153
05/21/2022 03:55:41 - INFO - __main__ - Global step 2150 Train loss 0.58 Classification-F1 0.5212033172741882 on epoch=153
05/21/2022 03:55:43 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.64 on epoch=154
05/21/2022 03:55:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.55 on epoch=154
05/21/2022 03:55:46 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.52 on epoch=155
05/21/2022 03:55:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.61 on epoch=156
05/21/2022 03:55:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.61 on epoch=157
05/21/2022 03:55:53 - INFO - __main__ - Global step 2200 Train loss 0.59 Classification-F1 0.5587170084863549 on epoch=157
05/21/2022 03:55:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.59 on epoch=157
05/21/2022 03:55:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.65 on epoch=158
05/21/2022 03:55:56 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.64 on epoch=159
05/21/2022 03:55:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.64 on epoch=159
05/21/2022 03:55:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.57 on epoch=160
05/21/2022 03:56:03 - INFO - __main__ - Global step 2250 Train loss 0.62 Classification-F1 0.5315857433050192 on epoch=160
05/21/2022 03:56:04 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.60 on epoch=161
05/21/2022 03:56:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.56 on epoch=162
05/21/2022 03:56:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.55 on epoch=162
05/21/2022 03:56:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.56 on epoch=163
05/21/2022 03:56:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.56 on epoch=164
05/21/2022 03:56:13 - INFO - __main__ - Global step 2300 Train loss 0.57 Classification-F1 0.5893967581245858 on epoch=164
05/21/2022 03:56:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5810103345855768 -> 0.5893967581245858 on epoch=164, global_step=2300
05/21/2022 03:56:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.49 on epoch=164
05/21/2022 03:56:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.54 on epoch=165
05/21/2022 03:56:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.58 on epoch=166
05/21/2022 03:56:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.63 on epoch=167
05/21/2022 03:56:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.61 on epoch=167
05/21/2022 03:56:24 - INFO - __main__ - Global step 2350 Train loss 0.57 Classification-F1 0.5502445599476751 on epoch=167
05/21/2022 03:56:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.54 on epoch=168
05/21/2022 03:56:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/21/2022 03:56:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.57 on epoch=169
05/21/2022 03:56:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.55 on epoch=170
05/21/2022 03:56:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.59 on epoch=171
05/21/2022 03:56:34 - INFO - __main__ - Global step 2400 Train loss 0.57 Classification-F1 0.5930741515106841 on epoch=171
05/21/2022 03:56:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5893967581245858 -> 0.5930741515106841 on epoch=171, global_step=2400
05/21/2022 03:56:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.63 on epoch=172
05/21/2022 03:56:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.53 on epoch=172
05/21/2022 03:56:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.52 on epoch=173
05/21/2022 03:56:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.52 on epoch=174
05/21/2022 03:56:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.64 on epoch=174
05/21/2022 03:56:44 - INFO - __main__ - Global step 2450 Train loss 0.57 Classification-F1 0.5441148301002042 on epoch=174
05/21/2022 03:56:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.63 on epoch=175
05/21/2022 03:56:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.50 on epoch=176
05/21/2022 03:56:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.60 on epoch=177
05/21/2022 03:56:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.48 on epoch=177
05/21/2022 03:56:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.61 on epoch=178
05/21/2022 03:56:54 - INFO - __main__ - Global step 2500 Train loss 0.56 Classification-F1 0.452659064310203 on epoch=178
05/21/2022 03:56:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.57 on epoch=179
05/21/2022 03:56:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.56 on epoch=179
05/21/2022 03:56:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.50 on epoch=180
05/21/2022 03:56:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.61 on epoch=181
05/21/2022 03:57:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.56 on epoch=182
05/21/2022 03:57:04 - INFO - __main__ - Global step 2550 Train loss 0.56 Classification-F1 0.5791584331718795 on epoch=182
05/21/2022 03:57:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.60 on epoch=182
05/21/2022 03:57:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.58 on epoch=183
05/21/2022 03:57:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.47 on epoch=184
05/21/2022 03:57:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/21/2022 03:57:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.53 on epoch=185
05/21/2022 03:57:14 - INFO - __main__ - Global step 2600 Train loss 0.56 Classification-F1 0.6664702370618898 on epoch=185
05/21/2022 03:57:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5930741515106841 -> 0.6664702370618898 on epoch=185, global_step=2600
05/21/2022 03:57:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.57 on epoch=186
05/21/2022 03:57:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.59 on epoch=187
05/21/2022 03:57:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.45 on epoch=187
05/21/2022 03:57:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.58 on epoch=188
05/21/2022 03:57:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.50 on epoch=189
05/21/2022 03:57:25 - INFO - __main__ - Global step 2650 Train loss 0.54 Classification-F1 0.5138024422824834 on epoch=189
05/21/2022 03:57:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.57 on epoch=189
05/21/2022 03:57:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.49 on epoch=190
05/21/2022 03:57:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.60 on epoch=191
05/21/2022 03:57:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.60 on epoch=192
05/21/2022 03:57:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.45 on epoch=192
05/21/2022 03:57:35 - INFO - __main__ - Global step 2700 Train loss 0.54 Classification-F1 0.5347081936633972 on epoch=192
05/21/2022 03:57:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.53 on epoch=193
05/21/2022 03:57:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.54 on epoch=194
05/21/2022 03:57:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.51 on epoch=194
05/21/2022 03:57:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.53 on epoch=195
05/21/2022 03:57:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.55 on epoch=196
05/21/2022 03:57:45 - INFO - __main__ - Global step 2750 Train loss 0.53 Classification-F1 0.5578858877171465 on epoch=196
05/21/2022 03:57:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.50 on epoch=197
05/21/2022 03:57:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.50 on epoch=197
05/21/2022 03:57:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.59 on epoch=198
05/21/2022 03:57:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.52 on epoch=199
05/21/2022 03:57:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.53 on epoch=199
05/21/2022 03:57:56 - INFO - __main__ - Global step 2800 Train loss 0.53 Classification-F1 0.5570213093246195 on epoch=199
05/21/2022 03:57:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.60 on epoch=200
05/21/2022 03:57:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.48 on epoch=201
05/21/2022 03:58:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.55 on epoch=202
05/21/2022 03:58:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.55 on epoch=202
05/21/2022 03:58:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.56 on epoch=203
05/21/2022 03:58:06 - INFO - __main__ - Global step 2850 Train loss 0.55 Classification-F1 0.5298437737394837 on epoch=203
05/21/2022 03:58:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.60 on epoch=204
05/21/2022 03:58:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.58 on epoch=204
05/21/2022 03:58:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.49 on epoch=205
05/21/2022 03:58:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.61 on epoch=206
05/21/2022 03:58:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.53 on epoch=207
05/21/2022 03:58:16 - INFO - __main__ - Global step 2900 Train loss 0.56 Classification-F1 0.5902234446180112 on epoch=207
05/21/2022 03:58:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.53 on epoch=207
05/21/2022 03:58:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.54 on epoch=208
05/21/2022 03:58:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.53 on epoch=209
05/21/2022 03:58:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.51 on epoch=209
05/21/2022 03:58:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.49 on epoch=210
05/21/2022 03:58:27 - INFO - __main__ - Global step 2950 Train loss 0.52 Classification-F1 0.5632930009797108 on epoch=210
05/21/2022 03:58:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.53 on epoch=211
05/21/2022 03:58:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/21/2022 03:58:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.52 on epoch=212
05/21/2022 03:58:32 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.54 on epoch=213
05/21/2022 03:58:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.51 on epoch=214
05/21/2022 03:58:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:58:34 - INFO - __main__ - Printing 3 examples
05/21/2022 03:58:34 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 03:58:34 - INFO - __main__ - ['Animal']
05/21/2022 03:58:34 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 03:58:34 - INFO - __main__ - ['Animal']
05/21/2022 03:58:34 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 03:58:34 - INFO - __main__ - ['Animal']
05/21/2022 03:58:34 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:58:34 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:58:35 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 03:58:35 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:58:35 - INFO - __main__ - Printing 3 examples
05/21/2022 03:58:35 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 03:58:35 - INFO - __main__ - ['Animal']
05/21/2022 03:58:35 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 03:58:35 - INFO - __main__ - ['Animal']
05/21/2022 03:58:35 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 03:58:35 - INFO - __main__ - ['Animal']
05/21/2022 03:58:35 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:58:35 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:58:35 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 03:58:37 - INFO - __main__ - Global step 3000 Train loss 0.54 Classification-F1 0.5956866760463084 on epoch=214
05/21/2022 03:58:37 - INFO - __main__ - save last model!
05/21/2022 03:58:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 03:58:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 03:58:37 - INFO - __main__ - Printing 3 examples
05/21/2022 03:58:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 03:58:37 - INFO - __main__ - ['Animal']
05/21/2022 03:58:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 03:58:37 - INFO - __main__ - ['Animal']
05/21/2022 03:58:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 03:58:37 - INFO - __main__ - ['Village']
05/21/2022 03:58:37 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:58:39 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:58:41 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 03:58:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 03:58:41 - INFO - __main__ - Starting training!
05/21/2022 03:58:42 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 03:59:52 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
05/21/2022 03:59:52 - INFO - __main__ - Classification-F1 on test data: 0.2895
05/21/2022 03:59:52 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.6664702370618898, test_performance=0.28952662875832763
05/21/2022 03:59:53 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
05/21/2022 03:59:53 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:59:53 - INFO - __main__ - Printing 3 examples
05/21/2022 03:59:53 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 03:59:53 - INFO - __main__ - ['Animal']
05/21/2022 03:59:53 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 03:59:53 - INFO - __main__ - ['Animal']
05/21/2022 03:59:53 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 03:59:53 - INFO - __main__ - ['Animal']
05/21/2022 03:59:53 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:59:54 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:59:54 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 03:59:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 03:59:54 - INFO - __main__ - Printing 3 examples
05/21/2022 03:59:54 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 03:59:54 - INFO - __main__ - ['Animal']
05/21/2022 03:59:54 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 03:59:54 - INFO - __main__ - ['Animal']
05/21/2022 03:59:54 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 03:59:54 - INFO - __main__ - ['Animal']
05/21/2022 03:59:54 - INFO - __main__ - Tokenizing Input ...
05/21/2022 03:59:54 - INFO - __main__ - Tokenizing Output ...
05/21/2022 03:59:54 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:00:00 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:00:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:00:01 - INFO - __main__ - Starting training!
05/21/2022 04:00:02 - INFO - __main__ - Step 10 Global step 10 Train loss 7.49 on epoch=0
05/21/2022 04:00:03 - INFO - __main__ - Step 20 Global step 20 Train loss 7.16 on epoch=1
05/21/2022 04:00:05 - INFO - __main__ - Step 30 Global step 30 Train loss 6.05 on epoch=2
05/21/2022 04:00:06 - INFO - __main__ - Step 40 Global step 40 Train loss 5.69 on epoch=2
05/21/2022 04:00:07 - INFO - __main__ - Step 50 Global step 50 Train loss 5.60 on epoch=3
05/21/2022 04:00:10 - INFO - __main__ - Global step 50 Train loss 6.40 Classification-F1 0.0 on epoch=3
05/21/2022 04:00:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:00:11 - INFO - __main__ - Step 60 Global step 60 Train loss 4.91 on epoch=4
05/21/2022 04:00:13 - INFO - __main__ - Step 70 Global step 70 Train loss 4.72 on epoch=4
05/21/2022 04:00:14 - INFO - __main__ - Step 80 Global step 80 Train loss 4.51 on epoch=5
05/21/2022 04:00:15 - INFO - __main__ - Step 90 Global step 90 Train loss 4.16 on epoch=6
05/21/2022 04:00:16 - INFO - __main__ - Step 100 Global step 100 Train loss 3.93 on epoch=7
05/21/2022 04:00:19 - INFO - __main__ - Global step 100 Train loss 4.45 Classification-F1 0.0 on epoch=7
05/21/2022 04:00:21 - INFO - __main__ - Step 110 Global step 110 Train loss 3.69 on epoch=7
05/21/2022 04:00:22 - INFO - __main__ - Step 120 Global step 120 Train loss 3.71 on epoch=8
05/21/2022 04:00:23 - INFO - __main__ - Step 130 Global step 130 Train loss 3.49 on epoch=9
05/21/2022 04:00:24 - INFO - __main__ - Step 140 Global step 140 Train loss 3.16 on epoch=9
05/21/2022 04:00:26 - INFO - __main__ - Step 150 Global step 150 Train loss 3.28 on epoch=10
05/21/2022 04:00:28 - INFO - __main__ - Global step 150 Train loss 3.47 Classification-F1 0.0 on epoch=10
05/21/2022 04:00:29 - INFO - __main__ - Step 160 Global step 160 Train loss 3.14 on epoch=11
05/21/2022 04:00:31 - INFO - __main__ - Step 170 Global step 170 Train loss 2.88 on epoch=12
05/21/2022 04:00:32 - INFO - __main__ - Step 180 Global step 180 Train loss 2.87 on epoch=12
05/21/2022 04:00:33 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=13
05/21/2022 04:00:34 - INFO - __main__ - Step 200 Global step 200 Train loss 2.57 on epoch=14
05/21/2022 04:00:37 - INFO - __main__ - Global step 200 Train loss 2.86 Classification-F1 0.009785932721712538 on epoch=14
05/21/2022 04:00:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.009785932721712538 on epoch=14, global_step=200
05/21/2022 04:00:38 - INFO - __main__ - Step 210 Global step 210 Train loss 2.52 on epoch=14
05/21/2022 04:00:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.62 on epoch=15
05/21/2022 04:00:40 - INFO - __main__ - Step 230 Global step 230 Train loss 2.44 on epoch=16
05/21/2022 04:00:42 - INFO - __main__ - Step 240 Global step 240 Train loss 2.34 on epoch=17
05/21/2022 04:00:43 - INFO - __main__ - Step 250 Global step 250 Train loss 2.25 on epoch=17
05/21/2022 04:00:45 - INFO - __main__ - Global step 250 Train loss 2.43 Classification-F1 0.009523809523809523 on epoch=17
05/21/2022 04:00:46 - INFO - __main__ - Step 260 Global step 260 Train loss 2.28 on epoch=18
05/21/2022 04:00:47 - INFO - __main__ - Step 270 Global step 270 Train loss 2.15 on epoch=19
05/21/2022 04:00:48 - INFO - __main__ - Step 280 Global step 280 Train loss 2.10 on epoch=19
05/21/2022 04:00:50 - INFO - __main__ - Step 290 Global step 290 Train loss 2.06 on epoch=20
05/21/2022 04:00:51 - INFO - __main__ - Step 300 Global step 300 Train loss 1.97 on epoch=21
05/21/2022 04:00:53 - INFO - __main__ - Global step 300 Train loss 2.11 Classification-F1 0.014298055393945807 on epoch=21
05/21/2022 04:00:53 - INFO - __main__ - Saving model with best Classification-F1: 0.009785932721712538 -> 0.014298055393945807 on epoch=21, global_step=300
05/21/2022 04:00:54 - INFO - __main__ - Step 310 Global step 310 Train loss 1.85 on epoch=22
05/21/2022 04:00:55 - INFO - __main__ - Step 320 Global step 320 Train loss 1.86 on epoch=22
05/21/2022 04:00:57 - INFO - __main__ - Step 330 Global step 330 Train loss 1.89 on epoch=23
05/21/2022 04:00:58 - INFO - __main__ - Step 340 Global step 340 Train loss 1.78 on epoch=24
05/21/2022 04:00:59 - INFO - __main__ - Step 350 Global step 350 Train loss 1.83 on epoch=24
05/21/2022 04:01:01 - INFO - __main__ - Global step 350 Train loss 1.84 Classification-F1 0.04309644806539216 on epoch=24
05/21/2022 04:01:01 - INFO - __main__ - Saving model with best Classification-F1: 0.014298055393945807 -> 0.04309644806539216 on epoch=24, global_step=350
05/21/2022 04:01:02 - INFO - __main__ - Step 360 Global step 360 Train loss 1.85 on epoch=25
05/21/2022 04:01:04 - INFO - __main__ - Step 370 Global step 370 Train loss 1.76 on epoch=26
05/21/2022 04:01:05 - INFO - __main__ - Step 380 Global step 380 Train loss 1.66 on epoch=27
05/21/2022 04:01:06 - INFO - __main__ - Step 390 Global step 390 Train loss 1.68 on epoch=27
05/21/2022 04:01:07 - INFO - __main__ - Step 400 Global step 400 Train loss 1.66 on epoch=28
05/21/2022 04:01:10 - INFO - __main__ - Global step 400 Train loss 1.72 Classification-F1 0.034324530655254724 on epoch=28
05/21/2022 04:01:11 - INFO - __main__ - Step 410 Global step 410 Train loss 1.53 on epoch=29
05/21/2022 04:01:13 - INFO - __main__ - Step 420 Global step 420 Train loss 1.55 on epoch=29
05/21/2022 04:01:14 - INFO - __main__ - Step 430 Global step 430 Train loss 1.56 on epoch=30
05/21/2022 04:01:15 - INFO - __main__ - Step 440 Global step 440 Train loss 1.55 on epoch=31
05/21/2022 04:01:16 - INFO - __main__ - Step 450 Global step 450 Train loss 1.60 on epoch=32
05/21/2022 04:01:19 - INFO - __main__ - Global step 450 Train loss 1.56 Classification-F1 0.07826827617962007 on epoch=32
05/21/2022 04:01:19 - INFO - __main__ - Saving model with best Classification-F1: 0.04309644806539216 -> 0.07826827617962007 on epoch=32, global_step=450
05/21/2022 04:01:21 - INFO - __main__ - Step 460 Global step 460 Train loss 1.48 on epoch=32
05/21/2022 04:01:22 - INFO - __main__ - Step 470 Global step 470 Train loss 1.42 on epoch=33
05/21/2022 04:01:23 - INFO - __main__ - Step 480 Global step 480 Train loss 1.44 on epoch=34
05/21/2022 04:01:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.41 on epoch=34
05/21/2022 04:01:26 - INFO - __main__ - Step 500 Global step 500 Train loss 1.39 on epoch=35
05/21/2022 04:01:29 - INFO - __main__ - Global step 500 Train loss 1.43 Classification-F1 0.03487188872310663 on epoch=35
05/21/2022 04:01:30 - INFO - __main__ - Step 510 Global step 510 Train loss 1.45 on epoch=36
05/21/2022 04:01:31 - INFO - __main__ - Step 520 Global step 520 Train loss 1.40 on epoch=37
05/21/2022 04:01:32 - INFO - __main__ - Step 530 Global step 530 Train loss 1.42 on epoch=37
05/21/2022 04:01:34 - INFO - __main__ - Step 540 Global step 540 Train loss 1.35 on epoch=38
05/21/2022 04:01:35 - INFO - __main__ - Step 550 Global step 550 Train loss 1.22 on epoch=39
05/21/2022 04:01:38 - INFO - __main__ - Global step 550 Train loss 1.37 Classification-F1 0.061327336609948345 on epoch=39
05/21/2022 04:01:39 - INFO - __main__ - Step 560 Global step 560 Train loss 1.34 on epoch=39
05/21/2022 04:01:41 - INFO - __main__ - Step 570 Global step 570 Train loss 1.35 on epoch=40
05/21/2022 04:01:42 - INFO - __main__ - Step 580 Global step 580 Train loss 1.27 on epoch=41
05/21/2022 04:01:43 - INFO - __main__ - Step 590 Global step 590 Train loss 1.29 on epoch=42
05/21/2022 04:01:44 - INFO - __main__ - Step 600 Global step 600 Train loss 1.20 on epoch=42
05/21/2022 04:01:48 - INFO - __main__ - Global step 600 Train loss 1.29 Classification-F1 0.07899773584383592 on epoch=42
05/21/2022 04:01:48 - INFO - __main__ - Saving model with best Classification-F1: 0.07826827617962007 -> 0.07899773584383592 on epoch=42, global_step=600
05/21/2022 04:01:49 - INFO - __main__ - Step 610 Global step 610 Train loss 1.29 on epoch=43
05/21/2022 04:01:50 - INFO - __main__ - Step 620 Global step 620 Train loss 1.19 on epoch=44
05/21/2022 04:01:51 - INFO - __main__ - Step 630 Global step 630 Train loss 1.21 on epoch=44
05/21/2022 04:01:53 - INFO - __main__ - Step 640 Global step 640 Train loss 1.24 on epoch=45
05/21/2022 04:01:54 - INFO - __main__ - Step 650 Global step 650 Train loss 1.25 on epoch=46
05/21/2022 04:01:57 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.13331495319683048 on epoch=46
05/21/2022 04:01:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07899773584383592 -> 0.13331495319683048 on epoch=46, global_step=650
05/21/2022 04:01:58 - INFO - __main__ - Step 660 Global step 660 Train loss 1.30 on epoch=47
05/21/2022 04:02:00 - INFO - __main__ - Step 670 Global step 670 Train loss 1.14 on epoch=47
05/21/2022 04:02:01 - INFO - __main__ - Step 680 Global step 680 Train loss 1.19 on epoch=48
05/21/2022 04:02:02 - INFO - __main__ - Step 690 Global step 690 Train loss 1.08 on epoch=49
05/21/2022 04:02:04 - INFO - __main__ - Step 700 Global step 700 Train loss 1.19 on epoch=49
05/21/2022 04:02:07 - INFO - __main__ - Global step 700 Train loss 1.18 Classification-F1 0.14212667799352308 on epoch=49
05/21/2022 04:02:07 - INFO - __main__ - Saving model with best Classification-F1: 0.13331495319683048 -> 0.14212667799352308 on epoch=49, global_step=700
05/21/2022 04:02:08 - INFO - __main__ - Step 710 Global step 710 Train loss 1.18 on epoch=50
05/21/2022 04:02:09 - INFO - __main__ - Step 720 Global step 720 Train loss 1.19 on epoch=51
05/21/2022 04:02:11 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/21/2022 04:02:12 - INFO - __main__ - Step 740 Global step 740 Train loss 1.17 on epoch=52
05/21/2022 04:02:13 - INFO - __main__ - Step 750 Global step 750 Train loss 1.21 on epoch=53
05/21/2022 04:02:16 - INFO - __main__ - Global step 750 Train loss 1.17 Classification-F1 0.16906558744591985 on epoch=53
05/21/2022 04:02:16 - INFO - __main__ - Saving model with best Classification-F1: 0.14212667799352308 -> 0.16906558744591985 on epoch=53, global_step=750
05/21/2022 04:02:18 - INFO - __main__ - Step 760 Global step 760 Train loss 1.07 on epoch=54
05/21/2022 04:02:19 - INFO - __main__ - Step 770 Global step 770 Train loss 1.17 on epoch=54
05/21/2022 04:02:20 - INFO - __main__ - Step 780 Global step 780 Train loss 1.20 on epoch=55
05/21/2022 04:02:22 - INFO - __main__ - Step 790 Global step 790 Train loss 1.16 on epoch=56
05/21/2022 04:02:23 - INFO - __main__ - Step 800 Global step 800 Train loss 1.06 on epoch=57
05/21/2022 04:02:26 - INFO - __main__ - Global step 800 Train loss 1.13 Classification-F1 0.24929134367264796 on epoch=57
05/21/2022 04:02:26 - INFO - __main__ - Saving model with best Classification-F1: 0.16906558744591985 -> 0.24929134367264796 on epoch=57, global_step=800
05/21/2022 04:02:27 - INFO - __main__ - Step 810 Global step 810 Train loss 1.08 on epoch=57
05/21/2022 04:02:29 - INFO - __main__ - Step 820 Global step 820 Train loss 1.06 on epoch=58
05/21/2022 04:02:30 - INFO - __main__ - Step 830 Global step 830 Train loss 1.06 on epoch=59
05/21/2022 04:02:31 - INFO - __main__ - Step 840 Global step 840 Train loss 1.12 on epoch=59
05/21/2022 04:02:32 - INFO - __main__ - Step 850 Global step 850 Train loss 1.11 on epoch=60
05/21/2022 04:02:36 - INFO - __main__ - Global step 850 Train loss 1.09 Classification-F1 0.30456822002346423 on epoch=60
05/21/2022 04:02:36 - INFO - __main__ - Saving model with best Classification-F1: 0.24929134367264796 -> 0.30456822002346423 on epoch=60, global_step=850
05/21/2022 04:02:37 - INFO - __main__ - Step 860 Global step 860 Train loss 1.10 on epoch=61
05/21/2022 04:02:39 - INFO - __main__ - Step 870 Global step 870 Train loss 1.09 on epoch=62
05/21/2022 04:02:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.96 on epoch=62
05/21/2022 04:02:41 - INFO - __main__ - Step 890 Global step 890 Train loss 1.11 on epoch=63
05/21/2022 04:02:43 - INFO - __main__ - Step 900 Global step 900 Train loss 1.06 on epoch=64
05/21/2022 04:02:47 - INFO - __main__ - Global step 900 Train loss 1.06 Classification-F1 0.35131702187264585 on epoch=64
05/21/2022 04:02:47 - INFO - __main__ - Saving model with best Classification-F1: 0.30456822002346423 -> 0.35131702187264585 on epoch=64, global_step=900
05/21/2022 04:02:48 - INFO - __main__ - Step 910 Global step 910 Train loss 1.06 on epoch=64
05/21/2022 04:02:49 - INFO - __main__ - Step 920 Global step 920 Train loss 1.00 on epoch=65
05/21/2022 04:02:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.98 on epoch=66
05/21/2022 04:02:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.98 on epoch=67
05/21/2022 04:02:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.95 on epoch=67
05/21/2022 04:02:57 - INFO - __main__ - Global step 950 Train loss 0.99 Classification-F1 0.4101250300979744 on epoch=67
05/21/2022 04:02:57 - INFO - __main__ - Saving model with best Classification-F1: 0.35131702187264585 -> 0.4101250300979744 on epoch=67, global_step=950
05/21/2022 04:02:58 - INFO - __main__ - Step 960 Global step 960 Train loss 1.01 on epoch=68
05/21/2022 04:03:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.95 on epoch=69
05/21/2022 04:03:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.97 on epoch=69
05/21/2022 04:03:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.89 on epoch=70
05/21/2022 04:03:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.03 on epoch=71
05/21/2022 04:03:08 - INFO - __main__ - Global step 1000 Train loss 0.97 Classification-F1 0.456588069954116 on epoch=71
05/21/2022 04:03:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4101250300979744 -> 0.456588069954116 on epoch=71, global_step=1000
05/21/2022 04:03:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.02 on epoch=72
05/21/2022 04:03:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.92 on epoch=72
05/21/2022 04:03:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.93 on epoch=73
05/21/2022 04:03:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.94 on epoch=74
05/21/2022 04:03:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.95 on epoch=74
05/21/2022 04:03:18 - INFO - __main__ - Global step 1050 Train loss 0.95 Classification-F1 0.47919324019441867 on epoch=74
05/21/2022 04:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.456588069954116 -> 0.47919324019441867 on epoch=74, global_step=1050
05/21/2022 04:03:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.03 on epoch=75
05/21/2022 04:03:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.01 on epoch=76
05/21/2022 04:03:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.91 on epoch=77
05/21/2022 04:03:23 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.86 on epoch=77
05/21/2022 04:03:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.92 on epoch=78
05/21/2022 04:03:28 - INFO - __main__ - Global step 1100 Train loss 0.95 Classification-F1 0.47343967718990726 on epoch=78
05/21/2022 04:03:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.87 on epoch=79
05/21/2022 04:03:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/21/2022 04:03:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.90 on epoch=80
05/21/2022 04:03:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.93 on epoch=81
05/21/2022 04:03:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.88 on epoch=82
05/21/2022 04:03:39 - INFO - __main__ - Global step 1150 Train loss 0.91 Classification-F1 0.43130726106502343 on epoch=82
05/21/2022 04:03:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.89 on epoch=82
05/21/2022 04:03:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.93 on epoch=83
05/21/2022 04:03:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.84 on epoch=84
05/21/2022 04:03:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.86 on epoch=84
05/21/2022 04:03:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.92 on epoch=85
05/21/2022 04:03:49 - INFO - __main__ - Global step 1200 Train loss 0.89 Classification-F1 0.40266052258739754 on epoch=85
05/21/2022 04:03:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.97 on epoch=86
05/21/2022 04:03:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.86 on epoch=87
05/21/2022 04:03:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.75 on epoch=87
05/21/2022 04:03:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.79 on epoch=88
05/21/2022 04:03:55 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.89 on epoch=89
05/21/2022 04:03:59 - INFO - __main__ - Global step 1250 Train loss 0.85 Classification-F1 0.40548807376391255 on epoch=89
05/21/2022 04:04:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.93 on epoch=89
05/21/2022 04:04:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.89 on epoch=90
05/21/2022 04:04:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.84 on epoch=91
05/21/2022 04:04:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.80 on epoch=92
05/21/2022 04:04:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.75 on epoch=92
05/21/2022 04:04:09 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.366030039447711 on epoch=92
05/21/2022 04:04:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.80 on epoch=93
05/21/2022 04:04:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.74 on epoch=94
05/21/2022 04:04:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.87 on epoch=94
05/21/2022 04:04:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.84 on epoch=95
05/21/2022 04:04:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.77 on epoch=96
05/21/2022 04:04:19 - INFO - __main__ - Global step 1350 Train loss 0.80 Classification-F1 0.3681833528180866 on epoch=96
05/21/2022 04:04:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.80 on epoch=97
05/21/2022 04:04:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.76 on epoch=97
05/21/2022 04:04:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.87 on epoch=98
05/21/2022 04:04:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.77 on epoch=99
05/21/2022 04:04:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.82 on epoch=99
05/21/2022 04:04:29 - INFO - __main__ - Global step 1400 Train loss 0.80 Classification-F1 0.41386811779126775 on epoch=99
05/21/2022 04:04:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.84 on epoch=100
05/21/2022 04:04:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.88 on epoch=101
05/21/2022 04:04:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.82 on epoch=102
05/21/2022 04:04:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.73 on epoch=102
05/21/2022 04:04:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.79 on epoch=103
05/21/2022 04:04:39 - INFO - __main__ - Global step 1450 Train loss 0.81 Classification-F1 0.3839908109426604 on epoch=103
05/21/2022 04:04:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.75 on epoch=104
05/21/2022 04:04:42 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.79 on epoch=104
05/21/2022 04:04:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.84 on epoch=105
05/21/2022 04:04:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.80 on epoch=106
05/21/2022 04:04:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.78 on epoch=107
05/21/2022 04:04:49 - INFO - __main__ - Global step 1500 Train loss 0.79 Classification-F1 0.3912747357747128 on epoch=107
05/21/2022 04:04:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.75 on epoch=107
05/21/2022 04:04:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.80 on epoch=108
05/21/2022 04:04:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.82 on epoch=109
05/21/2022 04:04:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.67 on epoch=109
05/21/2022 04:04:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.70 on epoch=110
05/21/2022 04:05:00 - INFO - __main__ - Global step 1550 Train loss 0.75 Classification-F1 0.4246924225563416 on epoch=110
05/21/2022 04:05:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.82 on epoch=111
05/21/2022 04:05:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.75 on epoch=112
05/21/2022 04:05:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.69 on epoch=112
05/21/2022 04:05:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.74 on epoch=113
05/21/2022 04:05:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.76 on epoch=114
05/21/2022 04:05:10 - INFO - __main__ - Global step 1600 Train loss 0.75 Classification-F1 0.41851569066784816 on epoch=114
05/21/2022 04:05:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.78 on epoch=114
05/21/2022 04:05:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.78 on epoch=115
05/21/2022 04:05:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.82 on epoch=116
05/21/2022 04:05:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.80 on epoch=117
05/21/2022 04:05:16 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.65 on epoch=117
05/21/2022 04:05:20 - INFO - __main__ - Global step 1650 Train loss 0.77 Classification-F1 0.4055750832065744 on epoch=117
05/21/2022 04:05:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.83 on epoch=118
05/21/2022 04:05:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.72 on epoch=119
05/21/2022 04:05:24 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/21/2022 04:05:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.68 on epoch=120
05/21/2022 04:05:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.76 on epoch=121
05/21/2022 04:05:30 - INFO - __main__ - Global step 1700 Train loss 0.76 Classification-F1 0.3854818856418984 on epoch=121
05/21/2022 04:05:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.77 on epoch=122
05/21/2022 04:05:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.75 on epoch=122
05/21/2022 04:05:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.70 on epoch=123
05/21/2022 04:05:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.73 on epoch=124
05/21/2022 04:05:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.83 on epoch=124
05/21/2022 04:05:40 - INFO - __main__ - Global step 1750 Train loss 0.75 Classification-F1 0.37066543016420694 on epoch=124
05/21/2022 04:05:41 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/21/2022 04:05:43 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.74 on epoch=126
05/21/2022 04:05:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.71 on epoch=127
05/21/2022 04:05:45 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.68 on epoch=127
05/21/2022 04:05:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.69 on epoch=128
05/21/2022 04:05:50 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.43132548947766347 on epoch=128
05/21/2022 04:05:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.72 on epoch=129
05/21/2022 04:05:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.80 on epoch=129
05/21/2022 04:05:54 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.62 on epoch=130
05/21/2022 04:05:55 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.67 on epoch=131
05/21/2022 04:05:57 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.77 on epoch=132
05/21/2022 04:06:00 - INFO - __main__ - Global step 1850 Train loss 0.72 Classification-F1 0.39239213117090355 on epoch=132
05/21/2022 04:06:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/21/2022 04:06:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.75 on epoch=133
05/21/2022 04:06:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.71 on epoch=134
05/21/2022 04:06:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.73 on epoch=134
05/21/2022 04:06:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.68 on epoch=135
05/21/2022 04:06:10 - INFO - __main__ - Global step 1900 Train loss 0.70 Classification-F1 0.4241063681150352 on epoch=135
05/21/2022 04:06:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.67 on epoch=136
05/21/2022 04:06:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/21/2022 04:06:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.65 on epoch=137
05/21/2022 04:06:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.65 on epoch=138
05/21/2022 04:06:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.75 on epoch=139
05/21/2022 04:06:21 - INFO - __main__ - Global step 1950 Train loss 0.68 Classification-F1 0.4457470747661885 on epoch=139
05/21/2022 04:06:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.61 on epoch=139
05/21/2022 04:06:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.61 on epoch=140
05/21/2022 04:06:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.68 on epoch=141
05/21/2022 04:06:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.73 on epoch=142
05/21/2022 04:06:27 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.74 on epoch=142
05/21/2022 04:06:31 - INFO - __main__ - Global step 2000 Train loss 0.67 Classification-F1 0.4495267826237229 on epoch=142
05/21/2022 04:06:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.76 on epoch=143
05/21/2022 04:06:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.67 on epoch=144
05/21/2022 04:06:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.79 on epoch=144
05/21/2022 04:06:36 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.66 on epoch=145
05/21/2022 04:06:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.66 on epoch=146
05/21/2022 04:06:41 - INFO - __main__ - Global step 2050 Train loss 0.71 Classification-F1 0.4400233348279832 on epoch=146
05/21/2022 04:06:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.71 on epoch=147
05/21/2022 04:06:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.63 on epoch=147
05/21/2022 04:06:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.72 on epoch=148
05/21/2022 04:06:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.63 on epoch=149
05/21/2022 04:06:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.67 on epoch=149
05/21/2022 04:06:51 - INFO - __main__ - Global step 2100 Train loss 0.67 Classification-F1 0.4952540229869061 on epoch=149
05/21/2022 04:06:51 - INFO - __main__ - Saving model with best Classification-F1: 0.47919324019441867 -> 0.4952540229869061 on epoch=149, global_step=2100
05/21/2022 04:06:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.64 on epoch=150
05/21/2022 04:06:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/21/2022 04:06:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.63 on epoch=152
05/21/2022 04:06:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.60 on epoch=152
05/21/2022 04:06:58 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.67 on epoch=153
05/21/2022 04:07:02 - INFO - __main__ - Global step 2150 Train loss 0.64 Classification-F1 0.5393649860244972 on epoch=153
05/21/2022 04:07:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4952540229869061 -> 0.5393649860244972 on epoch=153, global_step=2150
05/21/2022 04:07:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.64 on epoch=154
05/21/2022 04:07:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.62 on epoch=154
05/21/2022 04:07:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.68 on epoch=155
05/21/2022 04:07:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.64 on epoch=156
05/21/2022 04:07:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.66 on epoch=157
05/21/2022 04:07:12 - INFO - __main__ - Global step 2200 Train loss 0.65 Classification-F1 0.4858707259698933 on epoch=157
05/21/2022 04:07:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.66 on epoch=157
05/21/2022 04:07:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.60 on epoch=158
05/21/2022 04:07:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.59 on epoch=159
05/21/2022 04:07:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.68 on epoch=159
05/21/2022 04:07:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.61 on epoch=160
05/21/2022 04:07:22 - INFO - __main__ - Global step 2250 Train loss 0.63 Classification-F1 0.5264624203052217 on epoch=160
05/21/2022 04:07:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.66 on epoch=161
05/21/2022 04:07:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.74 on epoch=162
05/21/2022 04:07:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.58 on epoch=162
05/21/2022 04:07:27 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.65 on epoch=163
05/21/2022 04:07:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.62 on epoch=164
05/21/2022 04:07:32 - INFO - __main__ - Global step 2300 Train loss 0.65 Classification-F1 0.5824887321991088 on epoch=164
05/21/2022 04:07:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5393649860244972 -> 0.5824887321991088 on epoch=164, global_step=2300
05/21/2022 04:07:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.60 on epoch=164
05/21/2022 04:07:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.66 on epoch=165
05/21/2022 04:07:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.61 on epoch=166
05/21/2022 04:07:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.62 on epoch=167
05/21/2022 04:07:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.66 on epoch=167
05/21/2022 04:07:43 - INFO - __main__ - Global step 2350 Train loss 0.63 Classification-F1 0.4958570029301608 on epoch=167
05/21/2022 04:07:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.62 on epoch=168
05/21/2022 04:07:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/21/2022 04:07:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.59 on epoch=169
05/21/2022 04:07:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.72 on epoch=170
05/21/2022 04:07:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.64 on epoch=171
05/21/2022 04:07:53 - INFO - __main__ - Global step 2400 Train loss 0.66 Classification-F1 0.5097427830917706 on epoch=171
05/21/2022 04:07:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.64 on epoch=172
05/21/2022 04:07:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.60 on epoch=172
05/21/2022 04:07:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.68 on epoch=173
05/21/2022 04:07:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.54 on epoch=174
05/21/2022 04:07:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.60 on epoch=174
05/21/2022 04:08:03 - INFO - __main__ - Global step 2450 Train loss 0.61 Classification-F1 0.5188916602411094 on epoch=174
05/21/2022 04:08:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.65 on epoch=175
05/21/2022 04:08:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.66 on epoch=176
05/21/2022 04:08:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.65 on epoch=177
05/21/2022 04:08:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.64 on epoch=177
05/21/2022 04:08:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.56 on epoch=178
05/21/2022 04:08:13 - INFO - __main__ - Global step 2500 Train loss 0.63 Classification-F1 0.5475319963698936 on epoch=178
05/21/2022 04:08:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.62 on epoch=179
05/21/2022 04:08:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.61 on epoch=179
05/21/2022 04:08:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.62 on epoch=180
05/21/2022 04:08:19 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.62 on epoch=181
05/21/2022 04:08:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.66 on epoch=182
05/21/2022 04:08:24 - INFO - __main__ - Global step 2550 Train loss 0.63 Classification-F1 0.5123070978560996 on epoch=182
05/21/2022 04:08:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.62 on epoch=182
05/21/2022 04:08:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.66 on epoch=183
05/21/2022 04:08:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.56 on epoch=184
05/21/2022 04:08:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.54 on epoch=184
05/21/2022 04:08:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.55 on epoch=185
05/21/2022 04:08:35 - INFO - __main__ - Global step 2600 Train loss 0.59 Classification-F1 0.49804322564971654 on epoch=185
05/21/2022 04:08:36 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.59 on epoch=186
05/21/2022 04:08:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.61 on epoch=187
05/21/2022 04:08:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.53 on epoch=187
05/21/2022 04:08:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.65 on epoch=188
05/21/2022 04:08:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.54 on epoch=189
05/21/2022 04:08:45 - INFO - __main__ - Global step 2650 Train loss 0.59 Classification-F1 0.5600636077664599 on epoch=189
05/21/2022 04:08:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.61 on epoch=189
05/21/2022 04:08:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.64 on epoch=190
05/21/2022 04:08:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.56 on epoch=191
05/21/2022 04:08:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.67 on epoch=192
05/21/2022 04:08:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.65 on epoch=192
05/21/2022 04:08:56 - INFO - __main__ - Global step 2700 Train loss 0.63 Classification-F1 0.5541726924343412 on epoch=192
05/21/2022 04:08:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.61 on epoch=193
05/21/2022 04:08:59 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.70 on epoch=194
05/21/2022 04:09:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.60 on epoch=194
05/21/2022 04:09:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.65 on epoch=195
05/21/2022 04:09:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.62 on epoch=196
05/21/2022 04:09:06 - INFO - __main__ - Global step 2750 Train loss 0.64 Classification-F1 0.5936413465228644 on epoch=196
05/21/2022 04:09:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5824887321991088 -> 0.5936413465228644 on epoch=196, global_step=2750
05/21/2022 04:09:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.72 on epoch=197
05/21/2022 04:09:09 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.60 on epoch=197
05/21/2022 04:09:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.62 on epoch=198
05/21/2022 04:09:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.55 on epoch=199
05/21/2022 04:09:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.59 on epoch=199
05/21/2022 04:09:16 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.6126826037831731 on epoch=199
05/21/2022 04:09:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5936413465228644 -> 0.6126826037831731 on epoch=199, global_step=2800
05/21/2022 04:09:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.57 on epoch=200
05/21/2022 04:09:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.66 on epoch=201
05/21/2022 04:09:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.63 on epoch=202
05/21/2022 04:09:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/21/2022 04:09:23 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.64 on epoch=203
05/21/2022 04:09:27 - INFO - __main__ - Global step 2850 Train loss 0.62 Classification-F1 0.6015875477335924 on epoch=203
05/21/2022 04:09:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.66 on epoch=204
05/21/2022 04:09:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/21/2022 04:09:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.56 on epoch=205
05/21/2022 04:09:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.61 on epoch=206
05/21/2022 04:09:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.65 on epoch=207
05/21/2022 04:09:38 - INFO - __main__ - Global step 2900 Train loss 0.62 Classification-F1 0.6037594944731524 on epoch=207
05/21/2022 04:09:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.58 on epoch=207
05/21/2022 04:09:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.64 on epoch=208
05/21/2022 04:09:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.60 on epoch=209
05/21/2022 04:09:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.55 on epoch=209
05/21/2022 04:09:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/21/2022 04:09:48 - INFO - __main__ - Global step 2950 Train loss 0.59 Classification-F1 0.6206961504867482 on epoch=210
05/21/2022 04:09:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6126826037831731 -> 0.6206961504867482 on epoch=210, global_step=2950
05/21/2022 04:09:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.64 on epoch=211
05/21/2022 04:09:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/21/2022 04:09:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.61 on epoch=212
05/21/2022 04:09:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.58 on epoch=213
05/21/2022 04:09:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.58 on epoch=214
05/21/2022 04:09:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:09:56 - INFO - __main__ - Printing 3 examples
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:09:56 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:09:56 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:09:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:09:56 - INFO - __main__ - Printing 3 examples
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 04:09:56 - INFO - __main__ - ['Animal']
05/21/2022 04:09:56 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:09:56 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:09:57 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:09:59 - INFO - __main__ - Global step 3000 Train loss 0.61 Classification-F1 0.5825785720986958 on epoch=214
05/21/2022 04:09:59 - INFO - __main__ - save last model!
05/21/2022 04:09:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 04:09:59 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 04:09:59 - INFO - __main__ - Printing 3 examples
05/21/2022 04:09:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 04:09:59 - INFO - __main__ - ['Animal']
05/21/2022 04:09:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 04:09:59 - INFO - __main__ - ['Animal']
05/21/2022 04:09:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 04:09:59 - INFO - __main__ - ['Village']
05/21/2022 04:09:59 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:10:01 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:10:02 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:10:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:10:03 - INFO - __main__ - Starting training!
05/21/2022 04:10:04 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 04:11:18 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
05/21/2022 04:11:18 - INFO - __main__ - Classification-F1 on test data: 0.2656
05/21/2022 04:11:19 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.6206961504867482, test_performance=0.2655662030944191
05/21/2022 04:11:19 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
05/21/2022 04:11:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:11:20 - INFO - __main__ - Printing 3 examples
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:11:20 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:11:20 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:11:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:11:20 - INFO - __main__ - Printing 3 examples
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 04:11:20 - INFO - __main__ - ['Animal']
05/21/2022 04:11:20 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:11:20 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:11:20 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:11:26 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:11:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:11:26 - INFO - __main__ - Starting training!
05/21/2022 04:11:28 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/21/2022 04:11:29 - INFO - __main__ - Step 20 Global step 20 Train loss 7.12 on epoch=1
05/21/2022 04:11:30 - INFO - __main__ - Step 30 Global step 30 Train loss 6.31 on epoch=2
05/21/2022 04:11:32 - INFO - __main__ - Step 40 Global step 40 Train loss 6.09 on epoch=2
05/21/2022 04:11:33 - INFO - __main__ - Step 50 Global step 50 Train loss 5.98 on epoch=3
05/21/2022 04:11:36 - INFO - __main__ - Global step 50 Train loss 6.62 Classification-F1 0.0 on epoch=3
05/21/2022 04:11:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:11:37 - INFO - __main__ - Step 60 Global step 60 Train loss 5.38 on epoch=4
05/21/2022 04:11:38 - INFO - __main__ - Step 70 Global step 70 Train loss 5.10 on epoch=4
05/21/2022 04:11:40 - INFO - __main__ - Step 80 Global step 80 Train loss 4.84 on epoch=5
05/21/2022 04:11:41 - INFO - __main__ - Step 90 Global step 90 Train loss 4.61 on epoch=6
05/21/2022 04:11:42 - INFO - __main__ - Step 100 Global step 100 Train loss 4.36 on epoch=7
05/21/2022 04:11:45 - INFO - __main__ - Global step 100 Train loss 4.86 Classification-F1 0.0 on epoch=7
05/21/2022 04:11:47 - INFO - __main__ - Step 110 Global step 110 Train loss 4.21 on epoch=7
05/21/2022 04:11:48 - INFO - __main__ - Step 120 Global step 120 Train loss 4.11 on epoch=8
05/21/2022 04:11:49 - INFO - __main__ - Step 130 Global step 130 Train loss 4.08 on epoch=9
05/21/2022 04:11:50 - INFO - __main__ - Step 140 Global step 140 Train loss 3.62 on epoch=9
05/21/2022 04:11:52 - INFO - __main__ - Step 150 Global step 150 Train loss 3.71 on epoch=10
05/21/2022 04:11:55 - INFO - __main__ - Global step 150 Train loss 3.95 Classification-F1 0.0 on epoch=10
05/21/2022 04:11:56 - INFO - __main__ - Step 160 Global step 160 Train loss 3.68 on epoch=11
05/21/2022 04:11:57 - INFO - __main__ - Step 170 Global step 170 Train loss 3.41 on epoch=12
05/21/2022 04:11:59 - INFO - __main__ - Step 180 Global step 180 Train loss 3.25 on epoch=12
05/21/2022 04:12:00 - INFO - __main__ - Step 190 Global step 190 Train loss 3.22 on epoch=13
05/21/2022 04:12:01 - INFO - __main__ - Step 200 Global step 200 Train loss 3.00 on epoch=14
05/21/2022 04:12:04 - INFO - __main__ - Global step 200 Train loss 3.31 Classification-F1 0.002588996763754045 on epoch=14
05/21/2022 04:12:04 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.002588996763754045 on epoch=14, global_step=200
05/21/2022 04:12:05 - INFO - __main__ - Step 210 Global step 210 Train loss 3.00 on epoch=14
05/21/2022 04:12:07 - INFO - __main__ - Step 220 Global step 220 Train loss 3.00 on epoch=15
05/21/2022 04:12:08 - INFO - __main__ - Step 230 Global step 230 Train loss 3.02 on epoch=16
05/21/2022 04:12:09 - INFO - __main__ - Step 240 Global step 240 Train loss 2.78 on epoch=17
05/21/2022 04:12:10 - INFO - __main__ - Step 250 Global step 250 Train loss 2.72 on epoch=17
05/21/2022 04:12:13 - INFO - __main__ - Global step 250 Train loss 2.90 Classification-F1 0.010509031198686371 on epoch=17
05/21/2022 04:12:13 - INFO - __main__ - Saving model with best Classification-F1: 0.002588996763754045 -> 0.010509031198686371 on epoch=17, global_step=250
05/21/2022 04:12:14 - INFO - __main__ - Step 260 Global step 260 Train loss 2.71 on epoch=18
05/21/2022 04:12:15 - INFO - __main__ - Step 270 Global step 270 Train loss 2.56 on epoch=19
05/21/2022 04:12:17 - INFO - __main__ - Step 280 Global step 280 Train loss 2.56 on epoch=19
05/21/2022 04:12:18 - INFO - __main__ - Step 290 Global step 290 Train loss 2.48 on epoch=20
05/21/2022 04:12:19 - INFO - __main__ - Step 300 Global step 300 Train loss 2.48 on epoch=21
05/21/2022 04:12:21 - INFO - __main__ - Global step 300 Train loss 2.56 Classification-F1 0.009523809523809523 on epoch=21
05/21/2022 04:12:23 - INFO - __main__ - Step 310 Global step 310 Train loss 2.30 on epoch=22
05/21/2022 04:12:24 - INFO - __main__ - Step 320 Global step 320 Train loss 2.29 on epoch=22
05/21/2022 04:12:26 - INFO - __main__ - Step 330 Global step 330 Train loss 2.36 on epoch=23
05/21/2022 04:12:27 - INFO - __main__ - Step 340 Global step 340 Train loss 2.22 on epoch=24
05/21/2022 04:12:29 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/21/2022 04:12:30 - INFO - __main__ - Global step 350 Train loss 2.27 Classification-F1 0.009523809523809523 on epoch=24
05/21/2022 04:12:32 - INFO - __main__ - Step 360 Global step 360 Train loss 2.16 on epoch=25
05/21/2022 04:12:34 - INFO - __main__ - Step 370 Global step 370 Train loss 2.11 on epoch=26
05/21/2022 04:12:35 - INFO - __main__ - Step 380 Global step 380 Train loss 2.01 on epoch=27
05/21/2022 04:12:36 - INFO - __main__ - Step 390 Global step 390 Train loss 1.99 on epoch=27
05/21/2022 04:12:38 - INFO - __main__ - Step 400 Global step 400 Train loss 2.11 on epoch=28
05/21/2022 04:12:40 - INFO - __main__ - Global step 400 Train loss 2.07 Classification-F1 0.016828087167070217 on epoch=28
05/21/2022 04:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.010509031198686371 -> 0.016828087167070217 on epoch=28, global_step=400
05/21/2022 04:12:42 - INFO - __main__ - Step 410 Global step 410 Train loss 1.94 on epoch=29
05/21/2022 04:12:44 - INFO - __main__ - Step 420 Global step 420 Train loss 1.90 on epoch=29
05/21/2022 04:12:45 - INFO - __main__ - Step 430 Global step 430 Train loss 1.91 on epoch=30
05/21/2022 04:12:47 - INFO - __main__ - Step 440 Global step 440 Train loss 1.86 on epoch=31
05/21/2022 04:12:49 - INFO - __main__ - Step 450 Global step 450 Train loss 1.79 on epoch=32
05/21/2022 04:12:51 - INFO - __main__ - Global step 450 Train loss 1.88 Classification-F1 0.020833637288463804 on epoch=32
05/21/2022 04:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.016828087167070217 -> 0.020833637288463804 on epoch=32, global_step=450
05/21/2022 04:12:52 - INFO - __main__ - Step 460 Global step 460 Train loss 1.71 on epoch=32
05/21/2022 04:12:54 - INFO - __main__ - Step 470 Global step 470 Train loss 1.89 on epoch=33
05/21/2022 04:12:55 - INFO - __main__ - Step 480 Global step 480 Train loss 1.68 on epoch=34
05/21/2022 04:12:56 - INFO - __main__ - Step 490 Global step 490 Train loss 1.59 on epoch=34
05/21/2022 04:12:58 - INFO - __main__ - Step 500 Global step 500 Train loss 1.74 on epoch=35
05/21/2022 04:13:00 - INFO - __main__ - Global step 500 Train loss 1.72 Classification-F1 0.01196719651716108 on epoch=35
05/21/2022 04:13:02 - INFO - __main__ - Step 510 Global step 510 Train loss 1.70 on epoch=36
05/21/2022 04:13:04 - INFO - __main__ - Step 520 Global step 520 Train loss 1.60 on epoch=37
05/21/2022 04:13:05 - INFO - __main__ - Step 530 Global step 530 Train loss 1.49 on epoch=37
05/21/2022 04:13:07 - INFO - __main__ - Step 540 Global step 540 Train loss 1.56 on epoch=38
05/21/2022 04:13:09 - INFO - __main__ - Step 550 Global step 550 Train loss 1.56 on epoch=39
05/21/2022 04:13:12 - INFO - __main__ - Global step 550 Train loss 1.58 Classification-F1 0.029890744176458463 on epoch=39
05/21/2022 04:13:12 - INFO - __main__ - Saving model with best Classification-F1: 0.020833637288463804 -> 0.029890744176458463 on epoch=39, global_step=550
05/21/2022 04:13:13 - INFO - __main__ - Step 560 Global step 560 Train loss 1.73 on epoch=39
05/21/2022 04:13:14 - INFO - __main__ - Step 570 Global step 570 Train loss 1.53 on epoch=40
05/21/2022 04:13:16 - INFO - __main__ - Step 580 Global step 580 Train loss 1.49 on epoch=41
05/21/2022 04:13:17 - INFO - __main__ - Step 590 Global step 590 Train loss 1.52 on epoch=42
05/21/2022 04:13:19 - INFO - __main__ - Step 600 Global step 600 Train loss 1.50 on epoch=42
05/21/2022 04:13:21 - INFO - __main__ - Global step 600 Train loss 1.55 Classification-F1 0.05003562755275028 on epoch=42
05/21/2022 04:13:21 - INFO - __main__ - Saving model with best Classification-F1: 0.029890744176458463 -> 0.05003562755275028 on epoch=42, global_step=600
05/21/2022 04:13:23 - INFO - __main__ - Step 610 Global step 610 Train loss 1.49 on epoch=43
05/21/2022 04:13:24 - INFO - __main__ - Step 620 Global step 620 Train loss 1.44 on epoch=44
05/21/2022 04:13:26 - INFO - __main__ - Step 630 Global step 630 Train loss 1.52 on epoch=44
05/21/2022 04:13:27 - INFO - __main__ - Step 640 Global step 640 Train loss 1.50 on epoch=45
05/21/2022 04:13:28 - INFO - __main__ - Step 650 Global step 650 Train loss 1.30 on epoch=46
05/21/2022 04:13:31 - INFO - __main__ - Global step 650 Train loss 1.45 Classification-F1 0.031858198096087705 on epoch=46
05/21/2022 04:13:32 - INFO - __main__ - Step 660 Global step 660 Train loss 1.36 on epoch=47
05/21/2022 04:13:34 - INFO - __main__ - Step 670 Global step 670 Train loss 1.41 on epoch=47
05/21/2022 04:13:35 - INFO - __main__ - Step 680 Global step 680 Train loss 1.36 on epoch=48
05/21/2022 04:13:36 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=49
05/21/2022 04:13:38 - INFO - __main__ - Step 700 Global step 700 Train loss 1.37 on epoch=49
05/21/2022 04:13:40 - INFO - __main__ - Global step 700 Train loss 1.35 Classification-F1 0.04600419487038839 on epoch=49
05/21/2022 04:13:42 - INFO - __main__ - Step 710 Global step 710 Train loss 1.27 on epoch=50
05/21/2022 04:13:43 - INFO - __main__ - Step 720 Global step 720 Train loss 1.38 on epoch=51
05/21/2022 04:13:45 - INFO - __main__ - Step 730 Global step 730 Train loss 1.35 on epoch=52
05/21/2022 04:13:46 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=52
05/21/2022 04:13:47 - INFO - __main__ - Step 750 Global step 750 Train loss 1.35 on epoch=53
05/21/2022 04:13:50 - INFO - __main__ - Global step 750 Train loss 1.33 Classification-F1 0.06833992338194018 on epoch=53
05/21/2022 04:13:50 - INFO - __main__ - Saving model with best Classification-F1: 0.05003562755275028 -> 0.06833992338194018 on epoch=53, global_step=750
05/21/2022 04:13:51 - INFO - __main__ - Step 760 Global step 760 Train loss 1.19 on epoch=54
05/21/2022 04:13:53 - INFO - __main__ - Step 770 Global step 770 Train loss 1.29 on epoch=54
05/21/2022 04:13:54 - INFO - __main__ - Step 780 Global step 780 Train loss 1.30 on epoch=55
05/21/2022 04:13:56 - INFO - __main__ - Step 790 Global step 790 Train loss 1.30 on epoch=56
05/21/2022 04:13:57 - INFO - __main__ - Step 800 Global step 800 Train loss 1.23 on epoch=57
05/21/2022 04:14:00 - INFO - __main__ - Global step 800 Train loss 1.26 Classification-F1 0.04716400798592579 on epoch=57
05/21/2022 04:14:01 - INFO - __main__ - Step 810 Global step 810 Train loss 1.24 on epoch=57
05/21/2022 04:14:02 - INFO - __main__ - Step 820 Global step 820 Train loss 1.36 on epoch=58
05/21/2022 04:14:03 - INFO - __main__ - Step 830 Global step 830 Train loss 1.24 on epoch=59
05/21/2022 04:14:05 - INFO - __main__ - Step 840 Global step 840 Train loss 1.34 on epoch=59
05/21/2022 04:14:06 - INFO - __main__ - Step 850 Global step 850 Train loss 1.17 on epoch=60
05/21/2022 04:14:09 - INFO - __main__ - Global step 850 Train loss 1.27 Classification-F1 0.10194360748807454 on epoch=60
05/21/2022 04:14:09 - INFO - __main__ - Saving model with best Classification-F1: 0.06833992338194018 -> 0.10194360748807454 on epoch=60, global_step=850
05/21/2022 04:14:10 - INFO - __main__ - Step 860 Global step 860 Train loss 1.26 on epoch=61
05/21/2022 04:14:11 - INFO - __main__ - Step 870 Global step 870 Train loss 1.21 on epoch=62
05/21/2022 04:14:13 - INFO - __main__ - Step 880 Global step 880 Train loss 1.28 on epoch=62
05/21/2022 04:14:14 - INFO - __main__ - Step 890 Global step 890 Train loss 1.25 on epoch=63
05/21/2022 04:14:15 - INFO - __main__ - Step 900 Global step 900 Train loss 1.18 on epoch=64
05/21/2022 04:14:18 - INFO - __main__ - Global step 900 Train loss 1.24 Classification-F1 0.15839783039112884 on epoch=64
05/21/2022 04:14:18 - INFO - __main__ - Saving model with best Classification-F1: 0.10194360748807454 -> 0.15839783039112884 on epoch=64, global_step=900
05/21/2022 04:14:19 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=64
05/21/2022 04:14:21 - INFO - __main__ - Step 920 Global step 920 Train loss 1.24 on epoch=65
05/21/2022 04:14:22 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=66
05/21/2022 04:14:23 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=67
05/21/2022 04:14:25 - INFO - __main__ - Step 950 Global step 950 Train loss 1.23 on epoch=67
05/21/2022 04:14:27 - INFO - __main__ - Global step 950 Train loss 1.23 Classification-F1 0.22510255958546163 on epoch=67
05/21/2022 04:14:27 - INFO - __main__ - Saving model with best Classification-F1: 0.15839783039112884 -> 0.22510255958546163 on epoch=67, global_step=950
05/21/2022 04:14:29 - INFO - __main__ - Step 960 Global step 960 Train loss 1.25 on epoch=68
05/21/2022 04:14:30 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=69
05/21/2022 04:14:31 - INFO - __main__ - Step 980 Global step 980 Train loss 1.16 on epoch=69
05/21/2022 04:14:33 - INFO - __main__ - Step 990 Global step 990 Train loss 1.19 on epoch=70
05/21/2022 04:14:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.22 on epoch=71
05/21/2022 04:14:37 - INFO - __main__ - Global step 1000 Train loss 1.20 Classification-F1 0.24081254093637186 on epoch=71
05/21/2022 04:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.22510255958546163 -> 0.24081254093637186 on epoch=71, global_step=1000
05/21/2022 04:14:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.22 on epoch=72
05/21/2022 04:14:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=72
05/21/2022 04:14:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.22 on epoch=73
05/21/2022 04:14:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.09 on epoch=74
05/21/2022 04:14:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.18 on epoch=74
05/21/2022 04:14:46 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.19794558253319655 on epoch=74
05/21/2022 04:14:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.24 on epoch=75
05/21/2022 04:14:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=76
05/21/2022 04:14:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.13 on epoch=77
05/21/2022 04:14:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.19 on epoch=77
05/21/2022 04:14:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=78
05/21/2022 04:14:56 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.28217891310906107 on epoch=78
05/21/2022 04:14:56 - INFO - __main__ - Saving model with best Classification-F1: 0.24081254093637186 -> 0.28217891310906107 on epoch=78, global_step=1100
05/21/2022 04:14:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.18 on epoch=79
05/21/2022 04:14:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.15 on epoch=79
05/21/2022 04:15:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.16 on epoch=80
05/21/2022 04:15:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=81
05/21/2022 04:15:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.13 on epoch=82
05/21/2022 04:15:05 - INFO - __main__ - Global step 1150 Train loss 1.17 Classification-F1 0.3084193599238327 on epoch=82
05/21/2022 04:15:05 - INFO - __main__ - Saving model with best Classification-F1: 0.28217891310906107 -> 0.3084193599238327 on epoch=82, global_step=1150
05/21/2022 04:15:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.10 on epoch=82
05/21/2022 04:15:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.13 on epoch=83
05/21/2022 04:15:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.18 on epoch=84
05/21/2022 04:15:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.19 on epoch=84
05/21/2022 04:15:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.08 on epoch=85
05/21/2022 04:15:15 - INFO - __main__ - Global step 1200 Train loss 1.13 Classification-F1 0.24772580040641495 on epoch=85
05/21/2022 04:15:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=86
05/21/2022 04:15:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.10 on epoch=87
05/21/2022 04:15:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.12 on epoch=87
05/21/2022 04:15:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.08 on epoch=88
05/21/2022 04:15:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.11 on epoch=89
05/21/2022 04:15:25 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.3244081058752295 on epoch=89
05/21/2022 04:15:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3084193599238327 -> 0.3244081058752295 on epoch=89, global_step=1250
05/21/2022 04:15:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.13 on epoch=89
05/21/2022 04:15:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.10 on epoch=90
05/21/2022 04:15:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.08 on epoch=91
05/21/2022 04:15:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.05 on epoch=92
05/21/2022 04:15:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=92
05/21/2022 04:15:34 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.3026272734763301 on epoch=92
05/21/2022 04:15:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.10 on epoch=93
05/21/2022 04:15:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.02 on epoch=94
05/21/2022 04:15:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.04 on epoch=94
05/21/2022 04:15:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.11 on epoch=95
05/21/2022 04:15:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.12 on epoch=96
05/21/2022 04:15:44 - INFO - __main__ - Global step 1350 Train loss 1.08 Classification-F1 0.38615900000016407 on epoch=96
05/21/2022 04:15:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3244081058752295 -> 0.38615900000016407 on epoch=96, global_step=1350
05/21/2022 04:15:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.13 on epoch=97
05/21/2022 04:15:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=97
05/21/2022 04:15:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.08 on epoch=98
05/21/2022 04:15:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.02 on epoch=99
05/21/2022 04:15:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.10 on epoch=99
05/21/2022 04:15:54 - INFO - __main__ - Global step 1400 Train loss 1.08 Classification-F1 0.2945966559374147 on epoch=99
05/21/2022 04:15:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.06 on epoch=100
05/21/2022 04:15:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.06 on epoch=101
05/21/2022 04:15:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.04 on epoch=102
05/21/2022 04:15:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.04 on epoch=102
05/21/2022 04:16:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.12 on epoch=103
05/21/2022 04:16:03 - INFO - __main__ - Global step 1450 Train loss 1.06 Classification-F1 0.38536839055483113 on epoch=103
05/21/2022 04:16:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.99 on epoch=104
05/21/2022 04:16:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.13 on epoch=104
05/21/2022 04:16:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.07 on epoch=105
05/21/2022 04:16:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.02 on epoch=106
05/21/2022 04:16:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.09 on epoch=107
05/21/2022 04:16:13 - INFO - __main__ - Global step 1500 Train loss 1.06 Classification-F1 0.4352167964825921 on epoch=107
05/21/2022 04:16:13 - INFO - __main__ - Saving model with best Classification-F1: 0.38615900000016407 -> 0.4352167964825921 on epoch=107, global_step=1500
05/21/2022 04:16:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.93 on epoch=107
05/21/2022 04:16:15 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.02 on epoch=108
05/21/2022 04:16:17 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.96 on epoch=109
05/21/2022 04:16:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=109
05/21/2022 04:16:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.00 on epoch=110
05/21/2022 04:16:23 - INFO - __main__ - Global step 1550 Train loss 0.98 Classification-F1 0.45133714354923715 on epoch=110
05/21/2022 04:16:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4352167964825921 -> 0.45133714354923715 on epoch=110, global_step=1550
05/21/2022 04:16:24 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.06 on epoch=111
05/21/2022 04:16:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.98 on epoch=112
05/21/2022 04:16:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=112
05/21/2022 04:16:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.03 on epoch=113
05/21/2022 04:16:29 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.95 on epoch=114
05/21/2022 04:16:33 - INFO - __main__ - Global step 1600 Train loss 1.00 Classification-F1 0.44848765390932854 on epoch=114
05/21/2022 04:16:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.99 on epoch=114
05/21/2022 04:16:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=115
05/21/2022 04:16:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.05 on epoch=116
05/21/2022 04:16:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.03 on epoch=117
05/21/2022 04:16:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.90 on epoch=117
05/21/2022 04:16:43 - INFO - __main__ - Global step 1650 Train loss 1.00 Classification-F1 0.4160904020440013 on epoch=117
05/21/2022 04:16:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.93 on epoch=118
05/21/2022 04:16:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.90 on epoch=119
05/21/2022 04:16:47 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.98 on epoch=119
05/21/2022 04:16:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=120
05/21/2022 04:16:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.00 on epoch=121
05/21/2022 04:16:53 - INFO - __main__ - Global step 1700 Train loss 0.97 Classification-F1 0.4321265194582038 on epoch=121
05/21/2022 04:16:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.99 on epoch=122
05/21/2022 04:16:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.93 on epoch=122
05/21/2022 04:16:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.95 on epoch=123
05/21/2022 04:16:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.91 on epoch=124
05/21/2022 04:16:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.04 on epoch=124
05/21/2022 04:17:02 - INFO - __main__ - Global step 1750 Train loss 0.96 Classification-F1 0.4693252731313539 on epoch=124
05/21/2022 04:17:02 - INFO - __main__ - Saving model with best Classification-F1: 0.45133714354923715 -> 0.4693252731313539 on epoch=124, global_step=1750
05/21/2022 04:17:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.94 on epoch=125
05/21/2022 04:17:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=126
05/21/2022 04:17:06 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.93 on epoch=127
05/21/2022 04:17:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.90 on epoch=127
05/21/2022 04:17:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=128
05/21/2022 04:17:13 - INFO - __main__ - Global step 1800 Train loss 0.93 Classification-F1 0.40048573158326434 on epoch=128
05/21/2022 04:17:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.90 on epoch=129
05/21/2022 04:17:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.08 on epoch=129
05/21/2022 04:17:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.90 on epoch=130
05/21/2022 04:17:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.04 on epoch=131
05/21/2022 04:17:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.94 on epoch=132
05/21/2022 04:17:22 - INFO - __main__ - Global step 1850 Train loss 0.97 Classification-F1 0.42247431068467334 on epoch=132
05/21/2022 04:17:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=132
05/21/2022 04:17:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.95 on epoch=133
05/21/2022 04:17:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=134
05/21/2022 04:17:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.90 on epoch=134
05/21/2022 04:17:29 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.93 on epoch=135
05/21/2022 04:17:33 - INFO - __main__ - Global step 1900 Train loss 0.94 Classification-F1 0.4410405162256907 on epoch=135
05/21/2022 04:17:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.03 on epoch=136
05/21/2022 04:17:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=137
05/21/2022 04:17:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.02 on epoch=137
05/21/2022 04:17:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.95 on epoch=138
05/21/2022 04:17:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.93 on epoch=139
05/21/2022 04:17:43 - INFO - __main__ - Global step 1950 Train loss 0.99 Classification-F1 0.44553645385086593 on epoch=139
05/21/2022 04:17:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.95 on epoch=139
05/21/2022 04:17:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=140
05/21/2022 04:17:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.00 on epoch=141
05/21/2022 04:17:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.94 on epoch=142
05/21/2022 04:17:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.89 on epoch=142
05/21/2022 04:17:53 - INFO - __main__ - Global step 2000 Train loss 0.94 Classification-F1 0.5234964749910304 on epoch=142
05/21/2022 04:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4693252731313539 -> 0.5234964749910304 on epoch=142, global_step=2000
05/21/2022 04:17:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.87 on epoch=143
05/21/2022 04:17:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.98 on epoch=144
05/21/2022 04:17:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.97 on epoch=144
05/21/2022 04:17:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.97 on epoch=145
05/21/2022 04:18:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.89 on epoch=146
05/21/2022 04:18:03 - INFO - __main__ - Global step 2050 Train loss 0.94 Classification-F1 0.4901172331380159 on epoch=146
05/21/2022 04:18:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.98 on epoch=147
05/21/2022 04:18:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.84 on epoch=147
05/21/2022 04:18:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.92 on epoch=148
05/21/2022 04:18:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.93 on epoch=149
05/21/2022 04:18:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.95 on epoch=149
05/21/2022 04:18:13 - INFO - __main__ - Global step 2100 Train loss 0.93 Classification-F1 0.4284721152776708 on epoch=149
05/21/2022 04:18:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.89 on epoch=150
05/21/2022 04:18:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.98 on epoch=151
05/21/2022 04:18:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.97 on epoch=152
05/21/2022 04:18:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.81 on epoch=152
05/21/2022 04:18:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.98 on epoch=153
05/21/2022 04:18:23 - INFO - __main__ - Global step 2150 Train loss 0.92 Classification-F1 0.41954848706064235 on epoch=153
05/21/2022 04:18:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.85 on epoch=154
05/21/2022 04:18:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.98 on epoch=154
05/21/2022 04:18:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.93 on epoch=155
05/21/2022 04:18:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.96 on epoch=156
05/21/2022 04:18:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.91 on epoch=157
05/21/2022 04:18:33 - INFO - __main__ - Global step 2200 Train loss 0.92 Classification-F1 0.41453420664222285 on epoch=157
05/21/2022 04:18:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.76 on epoch=157
05/21/2022 04:18:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.84 on epoch=158
05/21/2022 04:18:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.93 on epoch=159
05/21/2022 04:18:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.92 on epoch=159
05/21/2022 04:18:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.81 on epoch=160
05/21/2022 04:18:43 - INFO - __main__ - Global step 2250 Train loss 0.85 Classification-F1 0.4034057190881158 on epoch=160
05/21/2022 04:18:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.92 on epoch=161
05/21/2022 04:18:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.90 on epoch=162
05/21/2022 04:18:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.89 on epoch=162
05/21/2022 04:18:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.88 on epoch=163
05/21/2022 04:18:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.83 on epoch=164
05/21/2022 04:18:54 - INFO - __main__ - Global step 2300 Train loss 0.88 Classification-F1 0.5161942724218016 on epoch=164
05/21/2022 04:18:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.86 on epoch=164
05/21/2022 04:18:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.85 on epoch=165
05/21/2022 04:18:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.94 on epoch=166
05/21/2022 04:18:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.81 on epoch=167
05/21/2022 04:19:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.82 on epoch=167
05/21/2022 04:19:04 - INFO - __main__ - Global step 2350 Train loss 0.86 Classification-F1 0.44529019786648033 on epoch=167
05/21/2022 04:19:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.94 on epoch=168
05/21/2022 04:19:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.87 on epoch=169
05/21/2022 04:19:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.92 on epoch=169
05/21/2022 04:19:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.91 on epoch=170
05/21/2022 04:19:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.91 on epoch=171
05/21/2022 04:19:14 - INFO - __main__ - Global step 2400 Train loss 0.91 Classification-F1 0.4201725168324829 on epoch=171
05/21/2022 04:19:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.79 on epoch=172
05/21/2022 04:19:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.81 on epoch=172
05/21/2022 04:19:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.90 on epoch=173
05/21/2022 04:19:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.82 on epoch=174
05/21/2022 04:19:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.85 on epoch=174
05/21/2022 04:19:24 - INFO - __main__ - Global step 2450 Train loss 0.83 Classification-F1 0.4456636840639611 on epoch=174
05/21/2022 04:19:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.88 on epoch=175
05/21/2022 04:19:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=176
05/21/2022 04:19:28 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.83 on epoch=177
05/21/2022 04:19:29 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.82 on epoch=177
05/21/2022 04:19:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.88 on epoch=178
05/21/2022 04:19:34 - INFO - __main__ - Global step 2500 Train loss 0.85 Classification-F1 0.4104894813622855 on epoch=178
05/21/2022 04:19:35 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.86 on epoch=179
05/21/2022 04:19:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.78 on epoch=179
05/21/2022 04:19:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.90 on epoch=180
05/21/2022 04:19:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.87 on epoch=181
05/21/2022 04:19:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.82 on epoch=182
05/21/2022 04:19:44 - INFO - __main__ - Global step 2550 Train loss 0.85 Classification-F1 0.3628275957452159 on epoch=182
05/21/2022 04:19:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.84 on epoch=182
05/21/2022 04:19:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.80 on epoch=183
05/21/2022 04:19:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.89 on epoch=184
05/21/2022 04:19:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.86 on epoch=184
05/21/2022 04:19:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.78 on epoch=185
05/21/2022 04:19:54 - INFO - __main__ - Global step 2600 Train loss 0.83 Classification-F1 0.4019924525118885 on epoch=185
05/21/2022 04:19:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.81 on epoch=186
05/21/2022 04:19:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.81 on epoch=187
05/21/2022 04:19:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.92 on epoch=187
05/21/2022 04:20:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.79 on epoch=188
05/21/2022 04:20:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.78 on epoch=189
05/21/2022 04:20:04 - INFO - __main__ - Global step 2650 Train loss 0.82 Classification-F1 0.4551111892182133 on epoch=189
05/21/2022 04:20:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.81 on epoch=189
05/21/2022 04:20:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.79 on epoch=190
05/21/2022 04:20:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.88 on epoch=191
05/21/2022 04:20:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.93 on epoch=192
05/21/2022 04:20:11 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.83 on epoch=192
05/21/2022 04:20:15 - INFO - __main__ - Global step 2700 Train loss 0.85 Classification-F1 0.4713447887289862 on epoch=192
05/21/2022 04:20:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.80 on epoch=193
05/21/2022 04:20:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.84 on epoch=194
05/21/2022 04:20:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.80 on epoch=194
05/21/2022 04:20:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.75 on epoch=195
05/21/2022 04:20:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.83 on epoch=196
05/21/2022 04:20:25 - INFO - __main__ - Global step 2750 Train loss 0.81 Classification-F1 0.42151938633145164 on epoch=196
05/21/2022 04:20:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.77 on epoch=197
05/21/2022 04:20:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.84 on epoch=197
05/21/2022 04:20:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.82 on epoch=198
05/21/2022 04:20:30 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.83 on epoch=199
05/21/2022 04:20:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.82 on epoch=199
05/21/2022 04:20:35 - INFO - __main__ - Global step 2800 Train loss 0.82 Classification-F1 0.40111263432040023 on epoch=199
05/21/2022 04:20:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.85 on epoch=200
05/21/2022 04:20:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.85 on epoch=201
05/21/2022 04:20:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.85 on epoch=202
05/21/2022 04:20:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.83 on epoch=202
05/21/2022 04:20:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.84 on epoch=203
05/21/2022 04:20:45 - INFO - __main__ - Global step 2850 Train loss 0.84 Classification-F1 0.3784448726439597 on epoch=203
05/21/2022 04:20:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.85 on epoch=204
05/21/2022 04:20:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.84 on epoch=204
05/21/2022 04:20:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.81 on epoch=205
05/21/2022 04:20:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.82 on epoch=206
05/21/2022 04:20:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.78 on epoch=207
05/21/2022 04:20:55 - INFO - __main__ - Global step 2900 Train loss 0.82 Classification-F1 0.440980902802955 on epoch=207
05/21/2022 04:20:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.84 on epoch=207
05/21/2022 04:20:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.80 on epoch=208
05/21/2022 04:20:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.77 on epoch=209
05/21/2022 04:21:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.84 on epoch=209
05/21/2022 04:21:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.73 on epoch=210
05/21/2022 04:21:05 - INFO - __main__ - Global step 2950 Train loss 0.79 Classification-F1 0.4676090754963934 on epoch=210
05/21/2022 04:21:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.86 on epoch=211
05/21/2022 04:21:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.89 on epoch=212
05/21/2022 04:21:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.78 on epoch=212
05/21/2022 04:21:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.82 on epoch=213
05/21/2022 04:21:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.74 on epoch=214
05/21/2022 04:21:12 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:21:12 - INFO - __main__ - Printing 3 examples
05/21/2022 04:21:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 04:21:12 - INFO - __main__ - ['Animal']
05/21/2022 04:21:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 04:21:12 - INFO - __main__ - ['Animal']
05/21/2022 04:21:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 04:21:12 - INFO - __main__ - ['Animal']
05/21/2022 04:21:12 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:21:12 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:21:13 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:21:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:21:13 - INFO - __main__ - Printing 3 examples
05/21/2022 04:21:13 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 04:21:13 - INFO - __main__ - ['Animal']
05/21/2022 04:21:13 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 04:21:13 - INFO - __main__ - ['Animal']
05/21/2022 04:21:13 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 04:21:13 - INFO - __main__ - ['Animal']
05/21/2022 04:21:13 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:21:13 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:21:13 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:21:15 - INFO - __main__ - Global step 3000 Train loss 0.82 Classification-F1 0.4110119510104774 on epoch=214
05/21/2022 04:21:15 - INFO - __main__ - save last model!
05/21/2022 04:21:15 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 04:21:15 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 04:21:15 - INFO - __main__ - Printing 3 examples
05/21/2022 04:21:15 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 04:21:15 - INFO - __main__ - ['Animal']
05/21/2022 04:21:15 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 04:21:15 - INFO - __main__ - ['Animal']
05/21/2022 04:21:15 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 04:21:15 - INFO - __main__ - ['Village']
05/21/2022 04:21:15 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:21:17 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:21:19 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:21:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:21:19 - INFO - __main__ - Starting training!
05/21/2022 04:21:20 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 04:22:19 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
05/21/2022 04:22:19 - INFO - __main__ - Classification-F1 on test data: 0.1416
05/21/2022 04:22:20 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.5234964749910304, test_performance=0.14163478437566152
05/21/2022 04:22:20 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
05/21/2022 04:22:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:22:21 - INFO - __main__ - Printing 3 examples
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:22:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:22:21 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:22:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:22:21 - INFO - __main__ - Printing 3 examples
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 04:22:21 - INFO - __main__ - ['Animal']
05/21/2022 04:22:21 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:22:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:22:21 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:22:27 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:22:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:22:28 - INFO - __main__ - Starting training!
05/21/2022 04:22:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.55 on epoch=0
05/21/2022 04:22:30 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/21/2022 04:22:32 - INFO - __main__ - Step 30 Global step 30 Train loss 6.71 on epoch=2
05/21/2022 04:22:33 - INFO - __main__ - Step 40 Global step 40 Train loss 6.60 on epoch=2
05/21/2022 04:22:34 - INFO - __main__ - Step 50 Global step 50 Train loss 6.37 on epoch=3
05/21/2022 04:22:37 - INFO - __main__ - Global step 50 Train loss 6.87 Classification-F1 0.0 on epoch=3
05/21/2022 04:22:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:22:38 - INFO - __main__ - Step 60 Global step 60 Train loss 6.05 on epoch=4
05/21/2022 04:22:40 - INFO - __main__ - Step 70 Global step 70 Train loss 5.57 on epoch=4
05/21/2022 04:22:41 - INFO - __main__ - Step 80 Global step 80 Train loss 5.41 on epoch=5
05/21/2022 04:22:42 - INFO - __main__ - Step 90 Global step 90 Train loss 5.24 on epoch=6
05/21/2022 04:22:43 - INFO - __main__ - Step 100 Global step 100 Train loss 5.21 on epoch=7
05/21/2022 04:22:46 - INFO - __main__ - Global step 100 Train loss 5.50 Classification-F1 0.0 on epoch=7
05/21/2022 04:22:48 - INFO - __main__ - Step 110 Global step 110 Train loss 4.89 on epoch=7
05/21/2022 04:22:49 - INFO - __main__ - Step 120 Global step 120 Train loss 4.94 on epoch=8
05/21/2022 04:22:50 - INFO - __main__ - Step 130 Global step 130 Train loss 4.67 on epoch=9
05/21/2022 04:22:52 - INFO - __main__ - Step 140 Global step 140 Train loss 4.70 on epoch=9
05/21/2022 04:22:53 - INFO - __main__ - Step 150 Global step 150 Train loss 4.57 on epoch=10
05/21/2022 04:22:56 - INFO - __main__ - Global step 150 Train loss 4.75 Classification-F1 0.0 on epoch=10
05/21/2022 04:22:57 - INFO - __main__ - Step 160 Global step 160 Train loss 4.34 on epoch=11
05/21/2022 04:22:59 - INFO - __main__ - Step 170 Global step 170 Train loss 4.04 on epoch=12
05/21/2022 04:23:00 - INFO - __main__ - Step 180 Global step 180 Train loss 4.17 on epoch=12
05/21/2022 04:23:01 - INFO - __main__ - Step 190 Global step 190 Train loss 4.12 on epoch=13
05/21/2022 04:23:02 - INFO - __main__ - Step 200 Global step 200 Train loss 3.85 on epoch=14
05/21/2022 04:23:06 - INFO - __main__ - Global step 200 Train loss 4.10 Classification-F1 0.0 on epoch=14
05/21/2022 04:23:07 - INFO - __main__ - Step 210 Global step 210 Train loss 3.80 on epoch=14
05/21/2022 04:23:08 - INFO - __main__ - Step 220 Global step 220 Train loss 3.78 on epoch=15
05/21/2022 04:23:09 - INFO - __main__ - Step 230 Global step 230 Train loss 3.64 on epoch=16
05/21/2022 04:23:11 - INFO - __main__ - Step 240 Global step 240 Train loss 3.65 on epoch=17
05/21/2022 04:23:12 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/21/2022 04:23:14 - INFO - __main__ - Global step 250 Train loss 3.66 Classification-F1 0.0 on epoch=17
05/21/2022 04:23:16 - INFO - __main__ - Step 260 Global step 260 Train loss 3.49 on epoch=18
05/21/2022 04:23:17 - INFO - __main__ - Step 270 Global step 270 Train loss 3.32 on epoch=19
05/21/2022 04:23:18 - INFO - __main__ - Step 280 Global step 280 Train loss 3.43 on epoch=19
05/21/2022 04:23:19 - INFO - __main__ - Step 290 Global step 290 Train loss 3.35 on epoch=20
05/21/2022 04:23:21 - INFO - __main__ - Step 300 Global step 300 Train loss 3.02 on epoch=21
05/21/2022 04:23:23 - INFO - __main__ - Global step 300 Train loss 3.32 Classification-F1 0.006666666666666666 on epoch=21
05/21/2022 04:23:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.006666666666666666 on epoch=21, global_step=300
05/21/2022 04:23:25 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/21/2022 04:23:26 - INFO - __main__ - Step 320 Global step 320 Train loss 3.01 on epoch=22
05/21/2022 04:23:27 - INFO - __main__ - Step 330 Global step 330 Train loss 3.03 on epoch=23
05/21/2022 04:23:28 - INFO - __main__ - Step 340 Global step 340 Train loss 2.99 on epoch=24
05/21/2022 04:23:29 - INFO - __main__ - Step 350 Global step 350 Train loss 2.88 on epoch=24
05/21/2022 04:23:32 - INFO - __main__ - Global step 350 Train loss 2.99 Classification-F1 0.010136452241715398 on epoch=24
05/21/2022 04:23:32 - INFO - __main__ - Saving model with best Classification-F1: 0.006666666666666666 -> 0.010136452241715398 on epoch=24, global_step=350
05/21/2022 04:23:33 - INFO - __main__ - Step 360 Global step 360 Train loss 2.91 on epoch=25
05/21/2022 04:23:34 - INFO - __main__ - Step 370 Global step 370 Train loss 2.77 on epoch=26
05/21/2022 04:23:36 - INFO - __main__ - Step 380 Global step 380 Train loss 2.56 on epoch=27
05/21/2022 04:23:37 - INFO - __main__ - Step 390 Global step 390 Train loss 2.67 on epoch=27
05/21/2022 04:23:38 - INFO - __main__ - Step 400 Global step 400 Train loss 2.70 on epoch=28
05/21/2022 04:23:40 - INFO - __main__ - Global step 400 Train loss 2.72 Classification-F1 0.009315866084425035 on epoch=28
05/21/2022 04:23:42 - INFO - __main__ - Step 410 Global step 410 Train loss 2.46 on epoch=29
05/21/2022 04:23:43 - INFO - __main__ - Step 420 Global step 420 Train loss 2.56 on epoch=29
05/21/2022 04:23:44 - INFO - __main__ - Step 430 Global step 430 Train loss 2.50 on epoch=30
05/21/2022 04:23:45 - INFO - __main__ - Step 440 Global step 440 Train loss 2.47 on epoch=31
05/21/2022 04:23:47 - INFO - __main__ - Step 450 Global step 450 Train loss 2.38 on epoch=32
05/21/2022 04:23:49 - INFO - __main__ - Global step 450 Train loss 2.47 Classification-F1 0.009523809523809523 on epoch=32
05/21/2022 04:23:50 - INFO - __main__ - Step 460 Global step 460 Train loss 2.43 on epoch=32
05/21/2022 04:23:51 - INFO - __main__ - Step 470 Global step 470 Train loss 2.52 on epoch=33
05/21/2022 04:23:53 - INFO - __main__ - Step 480 Global step 480 Train loss 2.31 on epoch=34
05/21/2022 04:23:54 - INFO - __main__ - Step 490 Global step 490 Train loss 2.24 on epoch=34
05/21/2022 04:23:55 - INFO - __main__ - Step 500 Global step 500 Train loss 2.35 on epoch=35
05/21/2022 04:23:57 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.009523809523809523 on epoch=35
05/21/2022 04:23:58 - INFO - __main__ - Step 510 Global step 510 Train loss 2.21 on epoch=36
05/21/2022 04:24:00 - INFO - __main__ - Step 520 Global step 520 Train loss 2.20 on epoch=37
05/21/2022 04:24:01 - INFO - __main__ - Step 530 Global step 530 Train loss 2.09 on epoch=37
05/21/2022 04:24:02 - INFO - __main__ - Step 540 Global step 540 Train loss 2.23 on epoch=38
05/21/2022 04:24:04 - INFO - __main__ - Step 550 Global step 550 Train loss 1.99 on epoch=39
05/21/2022 04:24:06 - INFO - __main__ - Global step 550 Train loss 2.14 Classification-F1 0.009563658099222952 on epoch=39
05/21/2022 04:24:07 - INFO - __main__ - Step 560 Global step 560 Train loss 2.04 on epoch=39
05/21/2022 04:24:08 - INFO - __main__ - Step 570 Global step 570 Train loss 2.05 on epoch=40
05/21/2022 04:24:10 - INFO - __main__ - Step 580 Global step 580 Train loss 2.03 on epoch=41
05/21/2022 04:24:11 - INFO - __main__ - Step 590 Global step 590 Train loss 1.94 on epoch=42
05/21/2022 04:24:12 - INFO - __main__ - Step 600 Global step 600 Train loss 1.97 on epoch=42
05/21/2022 04:24:14 - INFO - __main__ - Global step 600 Train loss 2.01 Classification-F1 0.009603841536614645 on epoch=42
05/21/2022 04:24:15 - INFO - __main__ - Step 610 Global step 610 Train loss 1.94 on epoch=43
05/21/2022 04:24:17 - INFO - __main__ - Step 620 Global step 620 Train loss 2.01 on epoch=44
05/21/2022 04:24:18 - INFO - __main__ - Step 630 Global step 630 Train loss 1.82 on epoch=44
05/21/2022 04:24:19 - INFO - __main__ - Step 640 Global step 640 Train loss 1.89 on epoch=45
05/21/2022 04:24:21 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=46
05/21/2022 04:24:23 - INFO - __main__ - Global step 650 Train loss 1.89 Classification-F1 0.018224349907518225 on epoch=46
05/21/2022 04:24:23 - INFO - __main__ - Saving model with best Classification-F1: 0.010136452241715398 -> 0.018224349907518225 on epoch=46, global_step=650
05/21/2022 04:24:24 - INFO - __main__ - Step 660 Global step 660 Train loss 1.77 on epoch=47
05/21/2022 04:24:26 - INFO - __main__ - Step 670 Global step 670 Train loss 1.75 on epoch=47
05/21/2022 04:24:27 - INFO - __main__ - Step 680 Global step 680 Train loss 1.78 on epoch=48
05/21/2022 04:24:28 - INFO - __main__ - Step 690 Global step 690 Train loss 1.73 on epoch=49
05/21/2022 04:24:29 - INFO - __main__ - Step 700 Global step 700 Train loss 1.67 on epoch=49
05/21/2022 04:24:32 - INFO - __main__ - Global step 700 Train loss 1.74 Classification-F1 0.020874570564011558 on epoch=49
05/21/2022 04:24:32 - INFO - __main__ - Saving model with best Classification-F1: 0.018224349907518225 -> 0.020874570564011558 on epoch=49, global_step=700
05/21/2022 04:24:33 - INFO - __main__ - Step 710 Global step 710 Train loss 1.73 on epoch=50
05/21/2022 04:24:35 - INFO - __main__ - Step 720 Global step 720 Train loss 1.82 on epoch=51
05/21/2022 04:24:36 - INFO - __main__ - Step 730 Global step 730 Train loss 1.62 on epoch=52
05/21/2022 04:24:37 - INFO - __main__ - Step 740 Global step 740 Train loss 1.58 on epoch=52
05/21/2022 04:24:38 - INFO - __main__ - Step 750 Global step 750 Train loss 1.70 on epoch=53
05/21/2022 04:24:41 - INFO - __main__ - Global step 750 Train loss 1.69 Classification-F1 0.023928222315319086 on epoch=53
05/21/2022 04:24:41 - INFO - __main__ - Saving model with best Classification-F1: 0.020874570564011558 -> 0.023928222315319086 on epoch=53, global_step=750
05/21/2022 04:24:42 - INFO - __main__ - Step 760 Global step 760 Train loss 1.59 on epoch=54
05/21/2022 04:24:44 - INFO - __main__ - Step 770 Global step 770 Train loss 1.63 on epoch=54
05/21/2022 04:24:45 - INFO - __main__ - Step 780 Global step 780 Train loss 1.62 on epoch=55
05/21/2022 04:24:47 - INFO - __main__ - Step 790 Global step 790 Train loss 1.52 on epoch=56
05/21/2022 04:24:48 - INFO - __main__ - Step 800 Global step 800 Train loss 1.63 on epoch=57
05/21/2022 04:24:51 - INFO - __main__ - Global step 800 Train loss 1.60 Classification-F1 0.04258697812704781 on epoch=57
05/21/2022 04:24:51 - INFO - __main__ - Saving model with best Classification-F1: 0.023928222315319086 -> 0.04258697812704781 on epoch=57, global_step=800
05/21/2022 04:24:52 - INFO - __main__ - Step 810 Global step 810 Train loss 1.71 on epoch=57
05/21/2022 04:24:53 - INFO - __main__ - Step 820 Global step 820 Train loss 1.62 on epoch=58
05/21/2022 04:24:55 - INFO - __main__ - Step 830 Global step 830 Train loss 1.54 on epoch=59
05/21/2022 04:24:56 - INFO - __main__ - Step 840 Global step 840 Train loss 1.63 on epoch=59
05/21/2022 04:24:57 - INFO - __main__ - Step 850 Global step 850 Train loss 1.51 on epoch=60
05/21/2022 04:25:01 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.048646619797698576 on epoch=60
05/21/2022 04:25:01 - INFO - __main__ - Saving model with best Classification-F1: 0.04258697812704781 -> 0.048646619797698576 on epoch=60, global_step=850
05/21/2022 04:25:02 - INFO - __main__ - Step 860 Global step 860 Train loss 1.58 on epoch=61
05/21/2022 04:25:03 - INFO - __main__ - Step 870 Global step 870 Train loss 1.54 on epoch=62
05/21/2022 04:25:04 - INFO - __main__ - Step 880 Global step 880 Train loss 1.53 on epoch=62
05/21/2022 04:25:06 - INFO - __main__ - Step 890 Global step 890 Train loss 1.49 on epoch=63
05/21/2022 04:25:07 - INFO - __main__ - Step 900 Global step 900 Train loss 1.41 on epoch=64
05/21/2022 04:25:10 - INFO - __main__ - Global step 900 Train loss 1.51 Classification-F1 0.040875134696645 on epoch=64
05/21/2022 04:25:11 - INFO - __main__ - Step 910 Global step 910 Train loss 1.47 on epoch=64
05/21/2022 04:25:13 - INFO - __main__ - Step 920 Global step 920 Train loss 1.44 on epoch=65
05/21/2022 04:25:14 - INFO - __main__ - Step 930 Global step 930 Train loss 1.50 on epoch=66
05/21/2022 04:25:16 - INFO - __main__ - Step 940 Global step 940 Train loss 1.50 on epoch=67
05/21/2022 04:25:17 - INFO - __main__ - Step 950 Global step 950 Train loss 1.33 on epoch=67
05/21/2022 04:25:21 - INFO - __main__ - Global step 950 Train loss 1.45 Classification-F1 0.05319937010668263 on epoch=67
05/21/2022 04:25:21 - INFO - __main__ - Saving model with best Classification-F1: 0.048646619797698576 -> 0.05319937010668263 on epoch=67, global_step=950
05/21/2022 04:25:22 - INFO - __main__ - Step 960 Global step 960 Train loss 1.40 on epoch=68
05/21/2022 04:25:23 - INFO - __main__ - Step 970 Global step 970 Train loss 1.41 on epoch=69
05/21/2022 04:25:24 - INFO - __main__ - Step 980 Global step 980 Train loss 1.46 on epoch=69
05/21/2022 04:25:26 - INFO - __main__ - Step 990 Global step 990 Train loss 1.51 on epoch=70
05/21/2022 04:25:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.34 on epoch=71
05/21/2022 04:25:30 - INFO - __main__ - Global step 1000 Train loss 1.42 Classification-F1 0.04023225451796881 on epoch=71
05/21/2022 04:25:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.35 on epoch=72
05/21/2022 04:25:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.40 on epoch=72
05/21/2022 04:25:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.37 on epoch=73
05/21/2022 04:25:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.40 on epoch=74
05/21/2022 04:25:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.37 on epoch=74
05/21/2022 04:25:40 - INFO - __main__ - Global step 1050 Train loss 1.38 Classification-F1 0.07086439125732572 on epoch=74
05/21/2022 04:25:40 - INFO - __main__ - Saving model with best Classification-F1: 0.05319937010668263 -> 0.07086439125732572 on epoch=74, global_step=1050
05/21/2022 04:25:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.38 on epoch=75
05/21/2022 04:25:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.44 on epoch=76
05/21/2022 04:25:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.34 on epoch=77
05/21/2022 04:25:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.26 on epoch=77
05/21/2022 04:25:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.40 on epoch=78
05/21/2022 04:25:49 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.07781640333275444 on epoch=78
05/21/2022 04:25:49 - INFO - __main__ - Saving model with best Classification-F1: 0.07086439125732572 -> 0.07781640333275444 on epoch=78, global_step=1100
05/21/2022 04:25:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.30 on epoch=79
05/21/2022 04:25:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.33 on epoch=79
05/21/2022 04:25:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.38 on epoch=80
05/21/2022 04:25:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.28 on epoch=81
05/21/2022 04:25:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.32 on epoch=82
05/21/2022 04:25:59 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.05736797924297925 on epoch=82
05/21/2022 04:26:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.22 on epoch=82
05/21/2022 04:26:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.29 on epoch=83
05/21/2022 04:26:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.30 on epoch=84
05/21/2022 04:26:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=84
05/21/2022 04:26:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.29 on epoch=85
05/21/2022 04:26:10 - INFO - __main__ - Global step 1200 Train loss 1.29 Classification-F1 0.0634405436207731 on epoch=85
05/21/2022 04:26:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.29 on epoch=86
05/21/2022 04:26:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.25 on epoch=87
05/21/2022 04:26:14 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.27 on epoch=87
05/21/2022 04:26:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.23 on epoch=88
05/21/2022 04:26:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.20 on epoch=89
05/21/2022 04:26:20 - INFO - __main__ - Global step 1250 Train loss 1.25 Classification-F1 0.1364790602235259 on epoch=89
05/21/2022 04:26:20 - INFO - __main__ - Saving model with best Classification-F1: 0.07781640333275444 -> 0.1364790602235259 on epoch=89, global_step=1250
05/21/2022 04:26:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.27 on epoch=89
05/21/2022 04:26:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.18 on epoch=90
05/21/2022 04:26:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.32 on epoch=91
05/21/2022 04:26:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.15 on epoch=92
05/21/2022 04:26:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.32 on epoch=92
05/21/2022 04:26:29 - INFO - __main__ - Global step 1300 Train loss 1.25 Classification-F1 0.1281577070046249 on epoch=92
05/21/2022 04:26:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.25 on epoch=93
05/21/2022 04:26:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.22 on epoch=94
05/21/2022 04:26:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=94
05/21/2022 04:26:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.25 on epoch=95
05/21/2022 04:26:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.29 on epoch=96
05/21/2022 04:26:38 - INFO - __main__ - Global step 1350 Train loss 1.24 Classification-F1 0.16371727787126897 on epoch=96
05/21/2022 04:26:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1364790602235259 -> 0.16371727787126897 on epoch=96, global_step=1350
05/21/2022 04:26:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.16 on epoch=97
05/21/2022 04:26:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.19 on epoch=97
05/21/2022 04:26:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=98
05/21/2022 04:26:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.17 on epoch=99
05/21/2022 04:26:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.26 on epoch=99
05/21/2022 04:26:48 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.12559956796079016 on epoch=99
05/21/2022 04:26:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.15 on epoch=100
05/21/2022 04:26:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.20 on epoch=101
05/21/2022 04:26:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.17 on epoch=102
05/21/2022 04:26:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=102
05/21/2022 04:26:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.31 on epoch=103
05/21/2022 04:26:58 - INFO - __main__ - Global step 1450 Train loss 1.20 Classification-F1 0.16384565106732807 on epoch=103
05/21/2022 04:26:58 - INFO - __main__ - Saving model with best Classification-F1: 0.16371727787126897 -> 0.16384565106732807 on epoch=103, global_step=1450
05/21/2022 04:26:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.07 on epoch=104
05/21/2022 04:27:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.23 on epoch=104
05/21/2022 04:27:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.20 on epoch=105
05/21/2022 04:27:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.21 on epoch=106
05/21/2022 04:27:04 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.13 on epoch=107
05/21/2022 04:27:07 - INFO - __main__ - Global step 1500 Train loss 1.17 Classification-F1 0.15844320231025139 on epoch=107
05/21/2022 04:27:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.17 on epoch=107
05/21/2022 04:27:10 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.18 on epoch=108
05/21/2022 04:27:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/21/2022 04:27:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.18 on epoch=109
05/21/2022 04:27:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.16 on epoch=110
05/21/2022 04:27:17 - INFO - __main__ - Global step 1550 Train loss 1.17 Classification-F1 0.1340554863494626 on epoch=110
05/21/2022 04:27:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.18 on epoch=111
05/21/2022 04:27:20 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=112
05/21/2022 04:27:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.20 on epoch=112
05/21/2022 04:27:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.12 on epoch=113
05/21/2022 04:27:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=114
05/21/2022 04:27:27 - INFO - __main__ - Global step 1600 Train loss 1.16 Classification-F1 0.1908294723536181 on epoch=114
05/21/2022 04:27:27 - INFO - __main__ - Saving model with best Classification-F1: 0.16384565106732807 -> 0.1908294723536181 on epoch=114, global_step=1600
05/21/2022 04:27:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.22 on epoch=114
05/21/2022 04:27:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.21 on epoch=115
05/21/2022 04:27:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.11 on epoch=116
05/21/2022 04:27:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.17 on epoch=117
05/21/2022 04:27:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.12 on epoch=117
05/21/2022 04:27:38 - INFO - __main__ - Global step 1650 Train loss 1.16 Classification-F1 0.27573401512963097 on epoch=117
05/21/2022 04:27:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1908294723536181 -> 0.27573401512963097 on epoch=117, global_step=1650
05/21/2022 04:27:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.14 on epoch=118
05/21/2022 04:27:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.06 on epoch=119
05/21/2022 04:27:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.16 on epoch=119
05/21/2022 04:27:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.08 on epoch=120
05/21/2022 04:27:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.15 on epoch=121
05/21/2022 04:27:48 - INFO - __main__ - Global step 1700 Train loss 1.12 Classification-F1 0.27069685824947803 on epoch=121
05/21/2022 04:27:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.25 on epoch=122
05/21/2022 04:27:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.09 on epoch=122
05/21/2022 04:27:53 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/21/2022 04:27:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.10 on epoch=124
05/21/2022 04:27:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.23 on epoch=124
05/21/2022 04:27:59 - INFO - __main__ - Global step 1750 Train loss 1.17 Classification-F1 0.2173480933668585 on epoch=124
05/21/2022 04:28:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.14 on epoch=125
05/21/2022 04:28:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.13 on epoch=126
05/21/2022 04:28:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.17 on epoch=127
05/21/2022 04:28:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.05 on epoch=127
05/21/2022 04:28:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.18 on epoch=128
05/21/2022 04:28:08 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.181865040915349 on epoch=128
05/21/2022 04:28:09 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.05 on epoch=129
05/21/2022 04:28:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.15 on epoch=129
05/21/2022 04:28:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.07 on epoch=130
05/21/2022 04:28:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/21/2022 04:28:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.24 on epoch=132
05/21/2022 04:28:17 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.257960577998172 on epoch=132
05/21/2022 04:28:18 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.11 on epoch=132
05/21/2022 04:28:20 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.07 on epoch=133
05/21/2022 04:28:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.05 on epoch=134
05/21/2022 04:28:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=134
05/21/2022 04:28:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.20 on epoch=135
05/21/2022 04:28:26 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.19473692682919355 on epoch=135
05/21/2022 04:28:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=136
05/21/2022 04:28:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.11 on epoch=137
05/21/2022 04:28:30 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.03 on epoch=137
05/21/2022 04:28:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.10 on epoch=138
05/21/2022 04:28:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.99 on epoch=139
05/21/2022 04:28:36 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.2642080560836954 on epoch=139
05/21/2022 04:28:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=139
05/21/2022 04:28:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.06 on epoch=140
05/21/2022 04:28:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=141
05/21/2022 04:28:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.11 on epoch=142
05/21/2022 04:28:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.04 on epoch=142
05/21/2022 04:28:45 - INFO - __main__ - Global step 2000 Train loss 1.09 Classification-F1 0.25248283094714624 on epoch=142
05/21/2022 04:28:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.03 on epoch=143
05/21/2022 04:28:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=144
05/21/2022 04:28:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.04 on epoch=144
05/21/2022 04:28:50 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.18 on epoch=145
05/21/2022 04:28:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.10 on epoch=146
05/21/2022 04:28:55 - INFO - __main__ - Global step 2050 Train loss 1.08 Classification-F1 0.2763105182437324 on epoch=146
05/21/2022 04:28:55 - INFO - __main__ - Saving model with best Classification-F1: 0.27573401512963097 -> 0.2763105182437324 on epoch=146, global_step=2050
05/21/2022 04:28:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=147
05/21/2022 04:28:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.06 on epoch=147
05/21/2022 04:28:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.05 on epoch=148
05/21/2022 04:29:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.99 on epoch=149
05/21/2022 04:29:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.14 on epoch=149
05/21/2022 04:29:04 - INFO - __main__ - Global step 2100 Train loss 1.06 Classification-F1 0.31450358106288767 on epoch=149
05/21/2022 04:29:04 - INFO - __main__ - Saving model with best Classification-F1: 0.2763105182437324 -> 0.31450358106288767 on epoch=149, global_step=2100
05/21/2022 04:29:06 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.02 on epoch=150
05/21/2022 04:29:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.02 on epoch=151
05/21/2022 04:29:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.00 on epoch=152
05/21/2022 04:29:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.06 on epoch=152
05/21/2022 04:29:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.94 on epoch=153
05/21/2022 04:29:14 - INFO - __main__ - Global step 2150 Train loss 1.01 Classification-F1 0.3666756543332173 on epoch=153
05/21/2022 04:29:14 - INFO - __main__ - Saving model with best Classification-F1: 0.31450358106288767 -> 0.3666756543332173 on epoch=153, global_step=2150
05/21/2022 04:29:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.02 on epoch=154
05/21/2022 04:29:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.92 on epoch=154
05/21/2022 04:29:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.00 on epoch=155
05/21/2022 04:29:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.11 on epoch=156
05/21/2022 04:29:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.03 on epoch=157
05/21/2022 04:29:24 - INFO - __main__ - Global step 2200 Train loss 1.02 Classification-F1 0.3393428364195746 on epoch=157
05/21/2022 04:29:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=157
05/21/2022 04:29:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.09 on epoch=158
05/21/2022 04:29:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.97 on epoch=159
05/21/2022 04:29:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.00 on epoch=159
05/21/2022 04:29:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.93 on epoch=160
05/21/2022 04:29:34 - INFO - __main__ - Global step 2250 Train loss 1.01 Classification-F1 0.38058716827510003 on epoch=160
05/21/2022 04:29:34 - INFO - __main__ - Saving model with best Classification-F1: 0.3666756543332173 -> 0.38058716827510003 on epoch=160, global_step=2250
05/21/2022 04:29:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.02 on epoch=161
05/21/2022 04:29:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.88 on epoch=162
05/21/2022 04:29:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.03 on epoch=162
05/21/2022 04:29:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.03 on epoch=163
05/21/2022 04:29:40 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.99 on epoch=164
05/21/2022 04:29:44 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.36915953180392014 on epoch=164
05/21/2022 04:29:45 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.13 on epoch=164
05/21/2022 04:29:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=165
05/21/2022 04:29:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=166
05/21/2022 04:29:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.04 on epoch=167
05/21/2022 04:29:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.97 on epoch=167
05/21/2022 04:29:54 - INFO - __main__ - Global step 2350 Train loss 1.02 Classification-F1 0.37466226399371766 on epoch=167
05/21/2022 04:29:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.96 on epoch=168
05/21/2022 04:29:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.95 on epoch=169
05/21/2022 04:29:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.03 on epoch=169
05/21/2022 04:29:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=170
05/21/2022 04:30:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.92 on epoch=171
05/21/2022 04:30:04 - INFO - __main__ - Global step 2400 Train loss 0.98 Classification-F1 0.40388057773279457 on epoch=171
05/21/2022 04:30:04 - INFO - __main__ - Saving model with best Classification-F1: 0.38058716827510003 -> 0.40388057773279457 on epoch=171, global_step=2400
05/21/2022 04:30:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.94 on epoch=172
05/21/2022 04:30:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.97 on epoch=172
05/21/2022 04:30:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.96 on epoch=173
05/21/2022 04:30:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=174
05/21/2022 04:30:10 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.00 on epoch=174
05/21/2022 04:30:14 - INFO - __main__ - Global step 2450 Train loss 0.96 Classification-F1 0.3785887639002958 on epoch=174
05/21/2022 04:30:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.99 on epoch=175
05/21/2022 04:30:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.93 on epoch=176
05/21/2022 04:30:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.95 on epoch=177
05/21/2022 04:30:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.95 on epoch=177
05/21/2022 04:30:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.97 on epoch=178
05/21/2022 04:30:24 - INFO - __main__ - Global step 2500 Train loss 0.96 Classification-F1 0.45565598905917354 on epoch=178
05/21/2022 04:30:24 - INFO - __main__ - Saving model with best Classification-F1: 0.40388057773279457 -> 0.45565598905917354 on epoch=178, global_step=2500
05/21/2022 04:30:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.89 on epoch=179
05/21/2022 04:30:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=179
05/21/2022 04:30:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.96 on epoch=180
05/21/2022 04:30:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.99 on epoch=181
05/21/2022 04:30:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.92 on epoch=182
05/21/2022 04:30:34 - INFO - __main__ - Global step 2550 Train loss 0.95 Classification-F1 0.46606850338207034 on epoch=182
05/21/2022 04:30:34 - INFO - __main__ - Saving model with best Classification-F1: 0.45565598905917354 -> 0.46606850338207034 on epoch=182, global_step=2550
05/21/2022 04:30:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.95 on epoch=182
05/21/2022 04:30:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.97 on epoch=183
05/21/2022 04:30:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.00 on epoch=184
05/21/2022 04:30:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.92 on epoch=184
05/21/2022 04:30:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=185
05/21/2022 04:30:44 - INFO - __main__ - Global step 2600 Train loss 0.97 Classification-F1 0.473825980162187 on epoch=185
05/21/2022 04:30:44 - INFO - __main__ - Saving model with best Classification-F1: 0.46606850338207034 -> 0.473825980162187 on epoch=185, global_step=2600
05/21/2022 04:30:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.00 on epoch=186
05/21/2022 04:30:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.99 on epoch=187
05/21/2022 04:30:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.96 on epoch=187
05/21/2022 04:30:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.92 on epoch=188
05/21/2022 04:30:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.98 on epoch=189
05/21/2022 04:30:53 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.40039965636270486 on epoch=189
05/21/2022 04:30:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.97 on epoch=189
05/21/2022 04:30:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.81 on epoch=190
05/21/2022 04:30:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.96 on epoch=191
05/21/2022 04:30:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.90 on epoch=192
05/21/2022 04:31:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=192
05/21/2022 04:31:03 - INFO - __main__ - Global step 2700 Train loss 0.91 Classification-F1 0.4140104987289586 on epoch=192
05/21/2022 04:31:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.90 on epoch=193
05/21/2022 04:31:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.93 on epoch=194
05/21/2022 04:31:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.86 on epoch=194
05/21/2022 04:31:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.89 on epoch=195
05/21/2022 04:31:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.92 on epoch=196
05/21/2022 04:31:13 - INFO - __main__ - Global step 2750 Train loss 0.90 Classification-F1 0.4775948738486042 on epoch=196
05/21/2022 04:31:13 - INFO - __main__ - Saving model with best Classification-F1: 0.473825980162187 -> 0.4775948738486042 on epoch=196, global_step=2750
05/21/2022 04:31:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.92 on epoch=197
05/21/2022 04:31:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.87 on epoch=197
05/21/2022 04:31:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.84 on epoch=198
05/21/2022 04:31:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.85 on epoch=199
05/21/2022 04:31:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.97 on epoch=199
05/21/2022 04:31:23 - INFO - __main__ - Global step 2800 Train loss 0.89 Classification-F1 0.49525713013674233 on epoch=199
05/21/2022 04:31:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4775948738486042 -> 0.49525713013674233 on epoch=199, global_step=2800
05/21/2022 04:31:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/21/2022 04:31:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.99 on epoch=201
05/21/2022 04:31:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.91 on epoch=202
05/21/2022 04:31:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.82 on epoch=202
05/21/2022 04:31:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 1.01 on epoch=203
05/21/2022 04:31:33 - INFO - __main__ - Global step 2850 Train loss 0.93 Classification-F1 0.5035235606567374 on epoch=203
05/21/2022 04:31:33 - INFO - __main__ - Saving model with best Classification-F1: 0.49525713013674233 -> 0.5035235606567374 on epoch=203, global_step=2850
05/21/2022 04:31:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.85 on epoch=204
05/21/2022 04:31:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.90 on epoch=204
05/21/2022 04:31:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.85 on epoch=205
05/21/2022 04:31:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.88 on epoch=206
05/21/2022 04:31:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.87 on epoch=207
05/21/2022 04:31:43 - INFO - __main__ - Global step 2900 Train loss 0.87 Classification-F1 0.4539915686299956 on epoch=207
05/21/2022 04:31:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.86 on epoch=207
05/21/2022 04:31:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.90 on epoch=208
05/21/2022 04:31:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.82 on epoch=209
05/21/2022 04:31:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/21/2022 04:31:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.84 on epoch=210
05/21/2022 04:31:53 - INFO - __main__ - Global step 2950 Train loss 0.84 Classification-F1 0.4499097976468869 on epoch=210
05/21/2022 04:31:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.92 on epoch=211
05/21/2022 04:31:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 1.05 on epoch=212
05/21/2022 04:31:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.85 on epoch=212
05/21/2022 04:31:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.80 on epoch=213
05/21/2022 04:32:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.88 on epoch=214
05/21/2022 04:32:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:32:01 - INFO - __main__ - Printing 3 examples
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:32:01 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:32:01 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:32:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:32:01 - INFO - __main__ - Printing 3 examples
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:32:01 - INFO - __main__ - ['Animal']
05/21/2022 04:32:01 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:32:02 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:32:02 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:32:03 - INFO - __main__ - Global step 3000 Train loss 0.90 Classification-F1 0.40907132777267635 on epoch=214
05/21/2022 04:32:03 - INFO - __main__ - save last model!
05/21/2022 04:32:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 04:32:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 04:32:03 - INFO - __main__ - Printing 3 examples
05/21/2022 04:32:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 04:32:03 - INFO - __main__ - ['Animal']
05/21/2022 04:32:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 04:32:03 - INFO - __main__ - ['Animal']
05/21/2022 04:32:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 04:32:03 - INFO - __main__ - ['Village']
05/21/2022 04:32:03 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:32:05 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:32:07 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:32:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:32:07 - INFO - __main__ - Starting training!
05/21/2022 04:32:09 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 04:33:08 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
05/21/2022 04:33:08 - INFO - __main__ - Classification-F1 on test data: 0.1417
05/21/2022 04:33:08 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.5035235606567374, test_performance=0.14166563649230043
05/21/2022 04:33:08 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
05/21/2022 04:33:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:33:09 - INFO - __main__ - Printing 3 examples
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:33:09 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:33:09 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:33:09 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:33:09 - INFO - __main__ - Printing 3 examples
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:33:09 - INFO - __main__ - ['Animal']
05/21/2022 04:33:09 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:33:09 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:33:10 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:33:15 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:33:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:33:16 - INFO - __main__ - Starting training!
05/21/2022 04:33:20 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/21/2022 04:33:21 - INFO - __main__ - Step 20 Global step 20 Train loss 6.91 on epoch=1
05/21/2022 04:33:22 - INFO - __main__ - Step 30 Global step 30 Train loss 5.95 on epoch=2
05/21/2022 04:33:23 - INFO - __main__ - Step 40 Global step 40 Train loss 5.32 on epoch=2
05/21/2022 04:33:25 - INFO - __main__ - Step 50 Global step 50 Train loss 5.08 on epoch=3
05/21/2022 04:33:28 - INFO - __main__ - Global step 50 Train loss 6.13 Classification-F1 0.0 on epoch=3
05/21/2022 04:33:28 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:33:30 - INFO - __main__ - Step 60 Global step 60 Train loss 4.89 on epoch=4
05/21/2022 04:33:31 - INFO - __main__ - Step 70 Global step 70 Train loss 4.55 on epoch=4
05/21/2022 04:33:33 - INFO - __main__ - Step 80 Global step 80 Train loss 4.21 on epoch=5
05/21/2022 04:33:34 - INFO - __main__ - Step 90 Global step 90 Train loss 3.86 on epoch=6
05/21/2022 04:33:36 - INFO - __main__ - Step 100 Global step 100 Train loss 3.60 on epoch=7
05/21/2022 04:33:39 - INFO - __main__ - Global step 100 Train loss 4.22 Classification-F1 0.0 on epoch=7
05/21/2022 04:33:40 - INFO - __main__ - Step 110 Global step 110 Train loss 3.35 on epoch=7
05/21/2022 04:33:42 - INFO - __main__ - Step 120 Global step 120 Train loss 3.31 on epoch=8
05/21/2022 04:33:43 - INFO - __main__ - Step 130 Global step 130 Train loss 3.33 on epoch=9
05/21/2022 04:33:44 - INFO - __main__ - Step 140 Global step 140 Train loss 3.12 on epoch=9
05/21/2022 04:33:45 - INFO - __main__ - Step 150 Global step 150 Train loss 2.85 on epoch=10
05/21/2022 04:33:48 - INFO - __main__ - Global step 150 Train loss 3.19 Classification-F1 0.008121827411167511 on epoch=10
05/21/2022 04:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.008121827411167511 on epoch=10, global_step=150
05/21/2022 04:33:49 - INFO - __main__ - Step 160 Global step 160 Train loss 2.82 on epoch=11
05/21/2022 04:33:51 - INFO - __main__ - Step 170 Global step 170 Train loss 2.57 on epoch=12
05/21/2022 04:33:52 - INFO - __main__ - Step 180 Global step 180 Train loss 2.49 on epoch=12
05/21/2022 04:33:53 - INFO - __main__ - Step 190 Global step 190 Train loss 2.42 on epoch=13
05/21/2022 04:33:54 - INFO - __main__ - Step 200 Global step 200 Train loss 2.40 on epoch=14
05/21/2022 04:33:56 - INFO - __main__ - Global step 200 Train loss 2.54 Classification-F1 0.009523809523809523 on epoch=14
05/21/2022 04:33:56 - INFO - __main__ - Saving model with best Classification-F1: 0.008121827411167511 -> 0.009523809523809523 on epoch=14, global_step=200
05/21/2022 04:33:58 - INFO - __main__ - Step 210 Global step 210 Train loss 2.35 on epoch=14
05/21/2022 04:33:59 - INFO - __main__ - Step 220 Global step 220 Train loss 2.22 on epoch=15
05/21/2022 04:34:00 - INFO - __main__ - Step 230 Global step 230 Train loss 2.22 on epoch=16
05/21/2022 04:34:01 - INFO - __main__ - Step 240 Global step 240 Train loss 2.06 on epoch=17
05/21/2022 04:34:03 - INFO - __main__ - Step 250 Global step 250 Train loss 1.94 on epoch=17
05/21/2022 04:34:05 - INFO - __main__ - Global step 250 Train loss 2.16 Classification-F1 0.018567737172388337 on epoch=17
05/21/2022 04:34:05 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.018567737172388337 on epoch=17, global_step=250
05/21/2022 04:34:06 - INFO - __main__ - Step 260 Global step 260 Train loss 1.86 on epoch=18
05/21/2022 04:34:07 - INFO - __main__ - Step 270 Global step 270 Train loss 2.02 on epoch=19
05/21/2022 04:34:09 - INFO - __main__ - Step 280 Global step 280 Train loss 1.85 on epoch=19
05/21/2022 04:34:10 - INFO - __main__ - Step 290 Global step 290 Train loss 1.74 on epoch=20
05/21/2022 04:34:11 - INFO - __main__ - Step 300 Global step 300 Train loss 1.83 on epoch=21
05/21/2022 04:34:14 - INFO - __main__ - Global step 300 Train loss 1.86 Classification-F1 0.0381820560391989 on epoch=21
05/21/2022 04:34:14 - INFO - __main__ - Saving model with best Classification-F1: 0.018567737172388337 -> 0.0381820560391989 on epoch=21, global_step=300
05/21/2022 04:34:16 - INFO - __main__ - Step 310 Global step 310 Train loss 1.72 on epoch=22
05/21/2022 04:34:17 - INFO - __main__ - Step 320 Global step 320 Train loss 1.68 on epoch=22
05/21/2022 04:34:18 - INFO - __main__ - Step 330 Global step 330 Train loss 1.60 on epoch=23
05/21/2022 04:34:20 - INFO - __main__ - Step 340 Global step 340 Train loss 1.66 on epoch=24
05/21/2022 04:34:21 - INFO - __main__ - Step 350 Global step 350 Train loss 1.57 on epoch=24
05/21/2022 04:34:24 - INFO - __main__ - Global step 350 Train loss 1.65 Classification-F1 0.04671846760682295 on epoch=24
05/21/2022 04:34:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0381820560391989 -> 0.04671846760682295 on epoch=24, global_step=350
05/21/2022 04:34:25 - INFO - __main__ - Step 360 Global step 360 Train loss 1.55 on epoch=25
05/21/2022 04:34:27 - INFO - __main__ - Step 370 Global step 370 Train loss 1.47 on epoch=26
05/21/2022 04:34:28 - INFO - __main__ - Step 380 Global step 380 Train loss 1.41 on epoch=27
05/21/2022 04:34:29 - INFO - __main__ - Step 390 Global step 390 Train loss 1.43 on epoch=27
05/21/2022 04:34:30 - INFO - __main__ - Step 400 Global step 400 Train loss 1.42 on epoch=28
05/21/2022 04:34:34 - INFO - __main__ - Global step 400 Train loss 1.46 Classification-F1 0.031160474980699703 on epoch=28
05/21/2022 04:34:35 - INFO - __main__ - Step 410 Global step 410 Train loss 1.36 on epoch=29
05/21/2022 04:34:36 - INFO - __main__ - Step 420 Global step 420 Train loss 1.41 on epoch=29
05/21/2022 04:34:37 - INFO - __main__ - Step 430 Global step 430 Train loss 1.25 on epoch=30
05/21/2022 04:34:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.36 on epoch=31
05/21/2022 04:34:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.44 on epoch=32
05/21/2022 04:34:43 - INFO - __main__ - Global step 450 Train loss 1.36 Classification-F1 0.06569257115412609 on epoch=32
05/21/2022 04:34:43 - INFO - __main__ - Saving model with best Classification-F1: 0.04671846760682295 -> 0.06569257115412609 on epoch=32, global_step=450
05/21/2022 04:34:44 - INFO - __main__ - Step 460 Global step 460 Train loss 1.31 on epoch=32
05/21/2022 04:34:45 - INFO - __main__ - Step 470 Global step 470 Train loss 1.26 on epoch=33
05/21/2022 04:34:47 - INFO - __main__ - Step 480 Global step 480 Train loss 1.30 on epoch=34
05/21/2022 04:34:48 - INFO - __main__ - Step 490 Global step 490 Train loss 1.39 on epoch=34
05/21/2022 04:34:49 - INFO - __main__ - Step 500 Global step 500 Train loss 1.24 on epoch=35
05/21/2022 04:34:52 - INFO - __main__ - Global step 500 Train loss 1.30 Classification-F1 0.02726742871061468 on epoch=35
05/21/2022 04:34:53 - INFO - __main__ - Step 510 Global step 510 Train loss 1.35 on epoch=36
05/21/2022 04:34:55 - INFO - __main__ - Step 520 Global step 520 Train loss 1.27 on epoch=37
05/21/2022 04:34:56 - INFO - __main__ - Step 530 Global step 530 Train loss 1.33 on epoch=37
05/21/2022 04:34:57 - INFO - __main__ - Step 540 Global step 540 Train loss 1.27 on epoch=38
05/21/2022 04:34:58 - INFO - __main__ - Step 550 Global step 550 Train loss 1.26 on epoch=39
05/21/2022 04:35:02 - INFO - __main__ - Global step 550 Train loss 1.30 Classification-F1 0.07825015486305809 on epoch=39
05/21/2022 04:35:02 - INFO - __main__ - Saving model with best Classification-F1: 0.06569257115412609 -> 0.07825015486305809 on epoch=39, global_step=550
05/21/2022 04:35:03 - INFO - __main__ - Step 560 Global step 560 Train loss 1.28 on epoch=39
05/21/2022 04:35:04 - INFO - __main__ - Step 570 Global step 570 Train loss 1.32 on epoch=40
05/21/2022 04:35:05 - INFO - __main__ - Step 580 Global step 580 Train loss 1.19 on epoch=41
05/21/2022 04:35:07 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/21/2022 04:35:08 - INFO - __main__ - Step 600 Global step 600 Train loss 1.26 on epoch=42
05/21/2022 04:35:11 - INFO - __main__ - Global step 600 Train loss 1.25 Classification-F1 0.049771254746958066 on epoch=42
05/21/2022 04:35:12 - INFO - __main__ - Step 610 Global step 610 Train loss 1.22 on epoch=43
05/21/2022 04:35:13 - INFO - __main__ - Step 620 Global step 620 Train loss 1.24 on epoch=44
05/21/2022 04:35:15 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=44
05/21/2022 04:35:16 - INFO - __main__ - Step 640 Global step 640 Train loss 1.22 on epoch=45
05/21/2022 04:35:17 - INFO - __main__ - Step 650 Global step 650 Train loss 1.23 on epoch=46
05/21/2022 04:35:20 - INFO - __main__ - Global step 650 Train loss 1.23 Classification-F1 0.09135531938851137 on epoch=46
05/21/2022 04:35:20 - INFO - __main__ - Saving model with best Classification-F1: 0.07825015486305809 -> 0.09135531938851137 on epoch=46, global_step=650
05/21/2022 04:35:22 - INFO - __main__ - Step 660 Global step 660 Train loss 1.22 on epoch=47
05/21/2022 04:35:23 - INFO - __main__ - Step 670 Global step 670 Train loss 1.24 on epoch=47
05/21/2022 04:35:24 - INFO - __main__ - Step 680 Global step 680 Train loss 1.14 on epoch=48
05/21/2022 04:35:25 - INFO - __main__ - Step 690 Global step 690 Train loss 1.31 on epoch=49
05/21/2022 04:35:27 - INFO - __main__ - Step 700 Global step 700 Train loss 1.16 on epoch=49
05/21/2022 04:35:29 - INFO - __main__ - Global step 700 Train loss 1.21 Classification-F1 0.08736098013890373 on epoch=49
05/21/2022 04:35:31 - INFO - __main__ - Step 710 Global step 710 Train loss 1.15 on epoch=50
05/21/2022 04:35:32 - INFO - __main__ - Step 720 Global step 720 Train loss 1.31 on epoch=51
05/21/2022 04:35:33 - INFO - __main__ - Step 730 Global step 730 Train loss 1.15 on epoch=52
05/21/2022 04:35:35 - INFO - __main__ - Step 740 Global step 740 Train loss 1.16 on epoch=52
05/21/2022 04:35:36 - INFO - __main__ - Step 750 Global step 750 Train loss 1.11 on epoch=53
05/21/2022 04:35:39 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.1426971915826405 on epoch=53
05/21/2022 04:35:39 - INFO - __main__ - Saving model with best Classification-F1: 0.09135531938851137 -> 0.1426971915826405 on epoch=53, global_step=750
05/21/2022 04:35:40 - INFO - __main__ - Step 760 Global step 760 Train loss 1.24 on epoch=54
05/21/2022 04:35:41 - INFO - __main__ - Step 770 Global step 770 Train loss 1.15 on epoch=54
05/21/2022 04:35:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.12 on epoch=55
05/21/2022 04:35:44 - INFO - __main__ - Step 790 Global step 790 Train loss 1.18 on epoch=56
05/21/2022 04:35:45 - INFO - __main__ - Step 800 Global step 800 Train loss 1.11 on epoch=57
05/21/2022 04:35:48 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.14175972687584742 on epoch=57
05/21/2022 04:35:50 - INFO - __main__ - Step 810 Global step 810 Train loss 1.04 on epoch=57
05/21/2022 04:35:51 - INFO - __main__ - Step 820 Global step 820 Train loss 1.17 on epoch=58
05/21/2022 04:35:53 - INFO - __main__ - Step 830 Global step 830 Train loss 1.12 on epoch=59
05/21/2022 04:35:54 - INFO - __main__ - Step 840 Global step 840 Train loss 1.12 on epoch=59
05/21/2022 04:35:55 - INFO - __main__ - Step 850 Global step 850 Train loss 1.09 on epoch=60
05/21/2022 04:35:58 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.296695194206715 on epoch=60
05/21/2022 04:35:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1426971915826405 -> 0.296695194206715 on epoch=60, global_step=850
05/21/2022 04:36:00 - INFO - __main__ - Step 860 Global step 860 Train loss 1.19 on epoch=61
05/21/2022 04:36:01 - INFO - __main__ - Step 870 Global step 870 Train loss 1.07 on epoch=62
05/21/2022 04:36:03 - INFO - __main__ - Step 880 Global step 880 Train loss 1.02 on epoch=62
05/21/2022 04:36:04 - INFO - __main__ - Step 890 Global step 890 Train loss 1.07 on epoch=63
05/21/2022 04:36:05 - INFO - __main__ - Step 900 Global step 900 Train loss 1.08 on epoch=64
05/21/2022 04:36:09 - INFO - __main__ - Global step 900 Train loss 1.08 Classification-F1 0.22397482234197003 on epoch=64
05/21/2022 04:36:10 - INFO - __main__ - Step 910 Global step 910 Train loss 1.01 on epoch=64
05/21/2022 04:36:11 - INFO - __main__ - Step 920 Global step 920 Train loss 1.05 on epoch=65
05/21/2022 04:36:12 - INFO - __main__ - Step 930 Global step 930 Train loss 1.04 on epoch=66
05/21/2022 04:36:14 - INFO - __main__ - Step 940 Global step 940 Train loss 1.00 on epoch=67
05/21/2022 04:36:15 - INFO - __main__ - Step 950 Global step 950 Train loss 1.00 on epoch=67
05/21/2022 04:36:18 - INFO - __main__ - Global step 950 Train loss 1.02 Classification-F1 0.3420675478242199 on epoch=67
05/21/2022 04:36:18 - INFO - __main__ - Saving model with best Classification-F1: 0.296695194206715 -> 0.3420675478242199 on epoch=67, global_step=950
05/21/2022 04:36:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.95 on epoch=68
05/21/2022 04:36:21 - INFO - __main__ - Step 970 Global step 970 Train loss 1.08 on epoch=69
05/21/2022 04:36:22 - INFO - __main__ - Step 980 Global step 980 Train loss 1.00 on epoch=69
05/21/2022 04:36:23 - INFO - __main__ - Step 990 Global step 990 Train loss 1.02 on epoch=70
05/21/2022 04:36:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.99 on epoch=71
05/21/2022 04:36:28 - INFO - __main__ - Global step 1000 Train loss 1.01 Classification-F1 0.29767263529375965 on epoch=71
05/21/2022 04:36:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/21/2022 04:36:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.96 on epoch=72
05/21/2022 04:36:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.94 on epoch=73
05/21/2022 04:36:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/21/2022 04:36:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.03 on epoch=74
05/21/2022 04:36:38 - INFO - __main__ - Global step 1050 Train loss 0.98 Classification-F1 0.3710029673812576 on epoch=74
05/21/2022 04:36:38 - INFO - __main__ - Saving model with best Classification-F1: 0.3420675478242199 -> 0.3710029673812576 on epoch=74, global_step=1050
05/21/2022 04:36:39 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.93 on epoch=75
05/21/2022 04:36:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.10 on epoch=76
05/21/2022 04:36:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.89 on epoch=77
05/21/2022 04:36:43 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.95 on epoch=77
05/21/2022 04:36:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.86 on epoch=78
05/21/2022 04:36:47 - INFO - __main__ - Global step 1100 Train loss 0.95 Classification-F1 0.4156813020277727 on epoch=78
05/21/2022 04:36:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3710029673812576 -> 0.4156813020277727 on epoch=78, global_step=1100
05/21/2022 04:36:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.97 on epoch=79
05/21/2022 04:36:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.90 on epoch=79
05/21/2022 04:36:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.88 on epoch=80
05/21/2022 04:36:52 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.86 on epoch=81
05/21/2022 04:36:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.91 on epoch=82
05/21/2022 04:36:58 - INFO - __main__ - Global step 1150 Train loss 0.91 Classification-F1 0.43352326937020275 on epoch=82
05/21/2022 04:36:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4156813020277727 -> 0.43352326937020275 on epoch=82, global_step=1150
05/21/2022 04:36:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.95 on epoch=82
05/21/2022 04:37:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.88 on epoch=83
05/21/2022 04:37:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.87 on epoch=84
05/21/2022 04:37:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.95 on epoch=84
05/21/2022 04:37:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.80 on epoch=85
05/21/2022 04:37:07 - INFO - __main__ - Global step 1200 Train loss 0.89 Classification-F1 0.4577580796556713 on epoch=85
05/21/2022 04:37:07 - INFO - __main__ - Saving model with best Classification-F1: 0.43352326937020275 -> 0.4577580796556713 on epoch=85, global_step=1200
05/21/2022 04:37:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.97 on epoch=86
05/21/2022 04:37:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.89 on epoch=87
05/21/2022 04:37:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.81 on epoch=87
05/21/2022 04:37:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.92 on epoch=88
05/21/2022 04:37:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.88 on epoch=89
05/21/2022 04:37:17 - INFO - __main__ - Global step 1250 Train loss 0.90 Classification-F1 0.47943398774760554 on epoch=89
05/21/2022 04:37:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4577580796556713 -> 0.47943398774760554 on epoch=89, global_step=1250
05/21/2022 04:37:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.81 on epoch=89
05/21/2022 04:37:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.92 on epoch=90
05/21/2022 04:37:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.82 on epoch=91
05/21/2022 04:37:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.84 on epoch=92
05/21/2022 04:37:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.81 on epoch=92
05/21/2022 04:37:28 - INFO - __main__ - Global step 1300 Train loss 0.84 Classification-F1 0.48033639728824784 on epoch=92
05/21/2022 04:37:28 - INFO - __main__ - Saving model with best Classification-F1: 0.47943398774760554 -> 0.48033639728824784 on epoch=92, global_step=1300
05/21/2022 04:37:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.81 on epoch=93
05/21/2022 04:37:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.88 on epoch=94
05/21/2022 04:37:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.83 on epoch=94
05/21/2022 04:37:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.78 on epoch=95
05/21/2022 04:37:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.82 on epoch=96
05/21/2022 04:37:38 - INFO - __main__ - Global step 1350 Train loss 0.82 Classification-F1 0.5088131656176287 on epoch=96
05/21/2022 04:37:38 - INFO - __main__ - Saving model with best Classification-F1: 0.48033639728824784 -> 0.5088131656176287 on epoch=96, global_step=1350
05/21/2022 04:37:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.78 on epoch=97
05/21/2022 04:37:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.74 on epoch=97
05/21/2022 04:37:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.82 on epoch=98
05/21/2022 04:37:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.74 on epoch=99
05/21/2022 04:37:44 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.77 on epoch=99
05/21/2022 04:37:48 - INFO - __main__ - Global step 1400 Train loss 0.77 Classification-F1 0.49265165008692335 on epoch=99
05/21/2022 04:37:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.79 on epoch=100
05/21/2022 04:37:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.79 on epoch=101
05/21/2022 04:37:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.66 on epoch=102
05/21/2022 04:37:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.70 on epoch=102
05/21/2022 04:37:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.68 on epoch=103
05/21/2022 04:37:58 - INFO - __main__ - Global step 1450 Train loss 0.72 Classification-F1 0.5174556741085561 on epoch=103
05/21/2022 04:37:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5088131656176287 -> 0.5174556741085561 on epoch=103, global_step=1450
05/21/2022 04:37:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.89 on epoch=104
05/21/2022 04:38:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.77 on epoch=104
05/21/2022 04:38:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.69 on epoch=105
05/21/2022 04:38:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.72 on epoch=106
05/21/2022 04:38:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.77 on epoch=107
05/21/2022 04:38:09 - INFO - __main__ - Global step 1500 Train loss 0.77 Classification-F1 0.5256229339578652 on epoch=107
05/21/2022 04:38:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5174556741085561 -> 0.5256229339578652 on epoch=107, global_step=1500
05/21/2022 04:38:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.66 on epoch=107
05/21/2022 04:38:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.65 on epoch=108
05/21/2022 04:38:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.74 on epoch=109
05/21/2022 04:38:15 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.78 on epoch=109
05/21/2022 04:38:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.82 on epoch=110
05/21/2022 04:38:20 - INFO - __main__ - Global step 1550 Train loss 0.73 Classification-F1 0.5820198745481442 on epoch=110
05/21/2022 04:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5256229339578652 -> 0.5820198745481442 on epoch=110, global_step=1550
05/21/2022 04:38:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.82 on epoch=111
05/21/2022 04:38:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.71 on epoch=112
05/21/2022 04:38:24 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.60 on epoch=112
05/21/2022 04:38:25 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.65 on epoch=113
05/21/2022 04:38:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.85 on epoch=114
05/21/2022 04:38:30 - INFO - __main__ - Global step 1600 Train loss 0.73 Classification-F1 0.5848265517046514 on epoch=114
05/21/2022 04:38:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5820198745481442 -> 0.5848265517046514 on epoch=114, global_step=1600
05/21/2022 04:38:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.75 on epoch=114
05/21/2022 04:38:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.74 on epoch=115
05/21/2022 04:38:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.63 on epoch=116
05/21/2022 04:38:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.74 on epoch=117
05/21/2022 04:38:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.77 on epoch=117
05/21/2022 04:38:40 - INFO - __main__ - Global step 1650 Train loss 0.73 Classification-F1 0.5015725346814093 on epoch=117
05/21/2022 04:38:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.65 on epoch=118
05/21/2022 04:38:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.76 on epoch=119
05/21/2022 04:38:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.69 on epoch=119
05/21/2022 04:38:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.73 on epoch=120
05/21/2022 04:38:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.68 on epoch=121
05/21/2022 04:38:50 - INFO - __main__ - Global step 1700 Train loss 0.70 Classification-F1 0.5579131238908087 on epoch=121
05/21/2022 04:38:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.74 on epoch=122
05/21/2022 04:38:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.66 on epoch=122
05/21/2022 04:38:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.73 on epoch=123
05/21/2022 04:38:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.69 on epoch=124
05/21/2022 04:38:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.73 on epoch=124
05/21/2022 04:39:01 - INFO - __main__ - Global step 1750 Train loss 0.71 Classification-F1 0.5881912321422317 on epoch=124
05/21/2022 04:39:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5848265517046514 -> 0.5881912321422317 on epoch=124, global_step=1750
05/21/2022 04:39:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.66 on epoch=125
05/21/2022 04:39:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.74 on epoch=126
05/21/2022 04:39:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.77 on epoch=127
05/21/2022 04:39:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.65 on epoch=127
05/21/2022 04:39:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.65 on epoch=128
05/21/2022 04:39:11 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.6263649401606022 on epoch=128
05/21/2022 04:39:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5881912321422317 -> 0.6263649401606022 on epoch=128, global_step=1800
05/21/2022 04:39:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.63 on epoch=129
05/21/2022 04:39:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.67 on epoch=129
05/21/2022 04:39:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.72 on epoch=130
05/21/2022 04:39:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.64 on epoch=131
05/21/2022 04:39:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.71 on epoch=132
05/21/2022 04:39:22 - INFO - __main__ - Global step 1850 Train loss 0.67 Classification-F1 0.5660488061927783 on epoch=132
05/21/2022 04:39:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/21/2022 04:39:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.67 on epoch=133
05/21/2022 04:39:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.70 on epoch=134
05/21/2022 04:39:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.66 on epoch=134
05/21/2022 04:39:28 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.65 on epoch=135
05/21/2022 04:39:32 - INFO - __main__ - Global step 1900 Train loss 0.66 Classification-F1 0.5507182584378699 on epoch=135
05/21/2022 04:39:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.69 on epoch=136
05/21/2022 04:39:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/21/2022 04:39:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.63 on epoch=137
05/21/2022 04:39:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.58 on epoch=138
05/21/2022 04:39:38 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.65 on epoch=139
05/21/2022 04:39:42 - INFO - __main__ - Global step 1950 Train loss 0.64 Classification-F1 0.5508859426198135 on epoch=139
05/21/2022 04:39:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.62 on epoch=139
05/21/2022 04:39:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.66 on epoch=140
05/21/2022 04:39:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.63 on epoch=141
05/21/2022 04:39:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.68 on epoch=142
05/21/2022 04:39:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.68 on epoch=142
05/21/2022 04:39:52 - INFO - __main__ - Global step 2000 Train loss 0.65 Classification-F1 0.5078998378647774 on epoch=142
05/21/2022 04:39:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.55 on epoch=143
05/21/2022 04:39:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.65 on epoch=144
05/21/2022 04:39:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.63 on epoch=144
05/21/2022 04:39:58 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.67 on epoch=145
05/21/2022 04:39:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.66 on epoch=146
05/21/2022 04:40:03 - INFO - __main__ - Global step 2050 Train loss 0.63 Classification-F1 0.5370402955147103 on epoch=146
05/21/2022 04:40:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.65 on epoch=147
05/21/2022 04:40:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.66 on epoch=147
05/21/2022 04:40:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.64 on epoch=148
05/21/2022 04:40:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.62 on epoch=149
05/21/2022 04:40:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.64 on epoch=149
05/21/2022 04:40:13 - INFO - __main__ - Global step 2100 Train loss 0.64 Classification-F1 0.617303771989218 on epoch=149
05/21/2022 04:40:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.60 on epoch=150
05/21/2022 04:40:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.54 on epoch=151
05/21/2022 04:40:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.60 on epoch=152
05/21/2022 04:40:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.62 on epoch=152
05/21/2022 04:40:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.61 on epoch=153
05/21/2022 04:40:23 - INFO - __main__ - Global step 2150 Train loss 0.59 Classification-F1 0.6191714862454281 on epoch=153
05/21/2022 04:40:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.69 on epoch=154
05/21/2022 04:40:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.56 on epoch=154
05/21/2022 04:40:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.62 on epoch=155
05/21/2022 04:40:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.67 on epoch=156
05/21/2022 04:40:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.61 on epoch=157
05/21/2022 04:40:34 - INFO - __main__ - Global step 2200 Train loss 0.63 Classification-F1 0.6420258196022015 on epoch=157
05/21/2022 04:40:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6263649401606022 -> 0.6420258196022015 on epoch=157, global_step=2200
05/21/2022 04:40:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.58 on epoch=157
05/21/2022 04:40:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.59 on epoch=158
05/21/2022 04:40:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.73 on epoch=159
05/21/2022 04:40:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.64 on epoch=159
05/21/2022 04:40:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.62 on epoch=160
05/21/2022 04:40:44 - INFO - __main__ - Global step 2250 Train loss 0.63 Classification-F1 0.593803666524819 on epoch=160
05/21/2022 04:40:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.54 on epoch=161
05/21/2022 04:40:47 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.64 on epoch=162
05/21/2022 04:40:48 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.66 on epoch=162
05/21/2022 04:40:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.63 on epoch=163
05/21/2022 04:40:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.66 on epoch=164
05/21/2022 04:40:54 - INFO - __main__ - Global step 2300 Train loss 0.63 Classification-F1 0.6457658482431301 on epoch=164
05/21/2022 04:40:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6420258196022015 -> 0.6457658482431301 on epoch=164, global_step=2300
05/21/2022 04:40:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.57 on epoch=164
05/21/2022 04:40:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.64 on epoch=165
05/21/2022 04:40:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.59 on epoch=166
05/21/2022 04:41:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.59 on epoch=167
05/21/2022 04:41:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.59 on epoch=167
05/21/2022 04:41:05 - INFO - __main__ - Global step 2350 Train loss 0.60 Classification-F1 0.5928688434335039 on epoch=167
05/21/2022 04:41:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.46 on epoch=168
05/21/2022 04:41:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.65 on epoch=169
05/21/2022 04:41:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.63 on epoch=169
05/21/2022 04:41:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.56 on epoch=170
05/21/2022 04:41:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.54 on epoch=171
05/21/2022 04:41:16 - INFO - __main__ - Global step 2400 Train loss 0.57 Classification-F1 0.6467508631135759 on epoch=171
05/21/2022 04:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6457658482431301 -> 0.6467508631135759 on epoch=171, global_step=2400
05/21/2022 04:41:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.62 on epoch=172
05/21/2022 04:41:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.53 on epoch=172
05/21/2022 04:41:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.62 on epoch=173
05/21/2022 04:41:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.61 on epoch=174
05/21/2022 04:41:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.56 on epoch=174
05/21/2022 04:41:27 - INFO - __main__ - Global step 2450 Train loss 0.59 Classification-F1 0.5614129865403209 on epoch=174
05/21/2022 04:41:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.66 on epoch=175
05/21/2022 04:41:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.56 on epoch=176
05/21/2022 04:41:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.52 on epoch=177
05/21/2022 04:41:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.60 on epoch=177
05/21/2022 04:41:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.55 on epoch=178
05/21/2022 04:41:38 - INFO - __main__ - Global step 2500 Train loss 0.58 Classification-F1 0.6080456941743887 on epoch=178
05/21/2022 04:41:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.55 on epoch=179
05/21/2022 04:41:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.55 on epoch=179
05/21/2022 04:41:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.66 on epoch=180
05/21/2022 04:41:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.62 on epoch=181
05/21/2022 04:41:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.59 on epoch=182
05/21/2022 04:41:49 - INFO - __main__ - Global step 2550 Train loss 0.59 Classification-F1 0.6275411080786937 on epoch=182
05/21/2022 04:41:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.61 on epoch=182
05/21/2022 04:41:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.58 on epoch=183
05/21/2022 04:41:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.57 on epoch=184
05/21/2022 04:41:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/21/2022 04:41:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/21/2022 04:41:59 - INFO - __main__ - Global step 2600 Train loss 0.59 Classification-F1 0.5860984360984361 on epoch=185
05/21/2022 04:42:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.55 on epoch=186
05/21/2022 04:42:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.51 on epoch=187
05/21/2022 04:42:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.62 on epoch=187
05/21/2022 04:42:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.47 on epoch=188
05/21/2022 04:42:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.54 on epoch=189
05/21/2022 04:42:09 - INFO - __main__ - Global step 2650 Train loss 0.54 Classification-F1 0.6426412587754625 on epoch=189
05/21/2022 04:42:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.58 on epoch=189
05/21/2022 04:42:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.45 on epoch=190
05/21/2022 04:42:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.67 on epoch=191
05/21/2022 04:42:15 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.54 on epoch=192
05/21/2022 04:42:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/21/2022 04:42:20 - INFO - __main__ - Global step 2700 Train loss 0.56 Classification-F1 0.6017365219880997 on epoch=192
05/21/2022 04:42:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.55 on epoch=193
05/21/2022 04:42:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.54 on epoch=194
05/21/2022 04:42:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.57 on epoch=194
05/21/2022 04:42:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.63 on epoch=195
05/21/2022 04:42:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.50 on epoch=196
05/21/2022 04:42:31 - INFO - __main__ - Global step 2750 Train loss 0.56 Classification-F1 0.5971294340493688 on epoch=196
05/21/2022 04:42:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.47 on epoch=197
05/21/2022 04:42:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.53 on epoch=197
05/21/2022 04:42:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.51 on epoch=198
05/21/2022 04:42:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.54 on epoch=199
05/21/2022 04:42:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.48 on epoch=199
05/21/2022 04:42:41 - INFO - __main__ - Global step 2800 Train loss 0.51 Classification-F1 0.5333459741210591 on epoch=199
05/21/2022 04:42:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.48 on epoch=200
05/21/2022 04:42:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.50 on epoch=201
05/21/2022 04:42:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.53 on epoch=202
05/21/2022 04:42:46 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.48 on epoch=202
05/21/2022 04:42:48 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.53 on epoch=203
05/21/2022 04:42:52 - INFO - __main__ - Global step 2850 Train loss 0.51 Classification-F1 0.5839422757242092 on epoch=203
05/21/2022 04:42:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.53 on epoch=204
05/21/2022 04:42:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.50 on epoch=204
05/21/2022 04:42:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.52 on epoch=205
05/21/2022 04:42:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.56 on epoch=206
05/21/2022 04:42:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.56 on epoch=207
05/21/2022 04:43:02 - INFO - __main__ - Global step 2900 Train loss 0.54 Classification-F1 0.6164217444628414 on epoch=207
05/21/2022 04:43:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.48 on epoch=207
05/21/2022 04:43:05 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.49 on epoch=208
05/21/2022 04:43:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.47 on epoch=209
05/21/2022 04:43:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.53 on epoch=209
05/21/2022 04:43:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.56 on epoch=210
05/21/2022 04:43:13 - INFO - __main__ - Global step 2950 Train loss 0.51 Classification-F1 0.6304720769187915 on epoch=210
05/21/2022 04:43:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.50 on epoch=211
05/21/2022 04:43:15 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.58 on epoch=212
05/21/2022 04:43:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.57 on epoch=212
05/21/2022 04:43:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.47 on epoch=213
05/21/2022 04:43:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.62 on epoch=214
05/21/2022 04:43:20 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:43:20 - INFO - __main__ - Printing 3 examples
05/21/2022 04:43:20 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:43:20 - INFO - __main__ - ['Animal']
05/21/2022 04:43:20 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:43:20 - INFO - __main__ - ['Animal']
05/21/2022 04:43:20 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:43:20 - INFO - __main__ - ['Animal']
05/21/2022 04:43:20 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:43:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:43:21 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:43:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:43:21 - INFO - __main__ - Printing 3 examples
05/21/2022 04:43:21 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:43:21 - INFO - __main__ - ['Animal']
05/21/2022 04:43:21 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:43:21 - INFO - __main__ - ['Animal']
05/21/2022 04:43:21 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:43:21 - INFO - __main__ - ['Animal']
05/21/2022 04:43:21 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:43:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:43:21 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:43:23 - INFO - __main__ - Global step 3000 Train loss 0.55 Classification-F1 0.656294644427364 on epoch=214
05/21/2022 04:43:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6467508631135759 -> 0.656294644427364 on epoch=214, global_step=3000
05/21/2022 04:43:23 - INFO - __main__ - save last model!
05/21/2022 04:43:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 04:43:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 04:43:23 - INFO - __main__ - Printing 3 examples
05/21/2022 04:43:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 04:43:23 - INFO - __main__ - ['Animal']
05/21/2022 04:43:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 04:43:23 - INFO - __main__ - ['Animal']
05/21/2022 04:43:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 04:43:23 - INFO - __main__ - ['Village']
05/21/2022 04:43:23 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:43:25 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:43:27 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:43:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:43:27 - INFO - __main__ - Starting training!
05/21/2022 04:43:29 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 04:44:42 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
05/21/2022 04:44:42 - INFO - __main__ - Classification-F1 on test data: 0.3476
05/21/2022 04:44:42 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.656294644427364, test_performance=0.3475793006374498
05/21/2022 04:44:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
05/21/2022 04:44:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:44:43 - INFO - __main__ - Printing 3 examples
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:44:43 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:44:43 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:44:43 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:44:43 - INFO - __main__ - Printing 3 examples
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:44:43 - INFO - __main__ - ['Animal']
05/21/2022 04:44:43 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:44:43 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:44:43 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:44:49 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:44:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:44:50 - INFO - __main__ - Starting training!
05/21/2022 04:44:52 - INFO - __main__ - Step 10 Global step 10 Train loss 7.76 on epoch=0
05/21/2022 04:44:53 - INFO - __main__ - Step 20 Global step 20 Train loss 6.73 on epoch=1
05/21/2022 04:44:54 - INFO - __main__ - Step 30 Global step 30 Train loss 6.17 on epoch=2
05/21/2022 04:44:56 - INFO - __main__ - Step 40 Global step 40 Train loss 5.79 on epoch=2
05/21/2022 04:44:57 - INFO - __main__ - Step 50 Global step 50 Train loss 5.39 on epoch=3
05/21/2022 04:45:00 - INFO - __main__ - Global step 50 Train loss 6.37 Classification-F1 0.0 on epoch=3
05/21/2022 04:45:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:45:01 - INFO - __main__ - Step 60 Global step 60 Train loss 5.25 on epoch=4
05/21/2022 04:45:03 - INFO - __main__ - Step 70 Global step 70 Train loss 4.89 on epoch=4
05/21/2022 04:45:04 - INFO - __main__ - Step 80 Global step 80 Train loss 4.39 on epoch=5
05/21/2022 04:45:05 - INFO - __main__ - Step 90 Global step 90 Train loss 4.12 on epoch=6
05/21/2022 04:45:06 - INFO - __main__ - Step 100 Global step 100 Train loss 4.13 on epoch=7
05/21/2022 04:45:09 - INFO - __main__ - Global step 100 Train loss 4.55 Classification-F1 0.0 on epoch=7
05/21/2022 04:45:11 - INFO - __main__ - Step 110 Global step 110 Train loss 3.80 on epoch=7
05/21/2022 04:45:12 - INFO - __main__ - Step 120 Global step 120 Train loss 3.71 on epoch=8
05/21/2022 04:45:13 - INFO - __main__ - Step 130 Global step 130 Train loss 3.54 on epoch=9
05/21/2022 04:45:14 - INFO - __main__ - Step 140 Global step 140 Train loss 3.43 on epoch=9
05/21/2022 04:45:16 - INFO - __main__ - Step 150 Global step 150 Train loss 3.06 on epoch=10
05/21/2022 04:45:18 - INFO - __main__ - Global step 150 Train loss 3.51 Classification-F1 0.0035714285714285713 on epoch=10
05/21/2022 04:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0035714285714285713 on epoch=10, global_step=150
05/21/2022 04:45:20 - INFO - __main__ - Step 160 Global step 160 Train loss 3.16 on epoch=11
05/21/2022 04:45:21 - INFO - __main__ - Step 170 Global step 170 Train loss 2.94 on epoch=12
05/21/2022 04:45:22 - INFO - __main__ - Step 180 Global step 180 Train loss 2.88 on epoch=12
05/21/2022 04:45:23 - INFO - __main__ - Step 190 Global step 190 Train loss 2.72 on epoch=13
05/21/2022 04:45:25 - INFO - __main__ - Step 200 Global step 200 Train loss 2.72 on epoch=14
05/21/2022 04:45:27 - INFO - __main__ - Global step 200 Train loss 2.88 Classification-F1 0.009315866084425035 on epoch=14
05/21/2022 04:45:27 - INFO - __main__ - Saving model with best Classification-F1: 0.0035714285714285713 -> 0.009315866084425035 on epoch=14, global_step=200
05/21/2022 04:45:28 - INFO - __main__ - Step 210 Global step 210 Train loss 2.55 on epoch=14
05/21/2022 04:45:30 - INFO - __main__ - Step 220 Global step 220 Train loss 2.49 on epoch=15
05/21/2022 04:45:31 - INFO - __main__ - Step 230 Global step 230 Train loss 2.42 on epoch=16
05/21/2022 04:45:32 - INFO - __main__ - Step 240 Global step 240 Train loss 2.27 on epoch=17
05/21/2022 04:45:33 - INFO - __main__ - Step 250 Global step 250 Train loss 2.28 on epoch=17
05/21/2022 04:45:35 - INFO - __main__ - Global step 250 Train loss 2.40 Classification-F1 0.009523809523809523 on epoch=17
05/21/2022 04:45:35 - INFO - __main__ - Saving model with best Classification-F1: 0.009315866084425035 -> 0.009523809523809523 on epoch=17, global_step=250
05/21/2022 04:45:37 - INFO - __main__ - Step 260 Global step 260 Train loss 2.32 on epoch=18
05/21/2022 04:45:38 - INFO - __main__ - Step 270 Global step 270 Train loss 2.19 on epoch=19
05/21/2022 04:45:39 - INFO - __main__ - Step 280 Global step 280 Train loss 2.21 on epoch=19
05/21/2022 04:45:41 - INFO - __main__ - Step 290 Global step 290 Train loss 1.99 on epoch=20
05/21/2022 04:45:42 - INFO - __main__ - Step 300 Global step 300 Train loss 2.08 on epoch=21
05/21/2022 04:45:44 - INFO - __main__ - Global step 300 Train loss 2.16 Classification-F1 0.024535554131966692 on epoch=21
05/21/2022 04:45:44 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.024535554131966692 on epoch=21, global_step=300
05/21/2022 04:45:45 - INFO - __main__ - Step 310 Global step 310 Train loss 1.88 on epoch=22
05/21/2022 04:45:47 - INFO - __main__ - Step 320 Global step 320 Train loss 1.82 on epoch=22
05/21/2022 04:45:48 - INFO - __main__ - Step 330 Global step 330 Train loss 1.89 on epoch=23
05/21/2022 04:45:49 - INFO - __main__ - Step 340 Global step 340 Train loss 1.82 on epoch=24
05/21/2022 04:45:50 - INFO - __main__ - Step 350 Global step 350 Train loss 1.74 on epoch=24
05/21/2022 04:45:53 - INFO - __main__ - Global step 350 Train loss 1.83 Classification-F1 0.029036288292428523 on epoch=24
05/21/2022 04:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.024535554131966692 -> 0.029036288292428523 on epoch=24, global_step=350
05/21/2022 04:45:55 - INFO - __main__ - Step 360 Global step 360 Train loss 1.67 on epoch=25
05/21/2022 04:45:56 - INFO - __main__ - Step 370 Global step 370 Train loss 1.74 on epoch=26
05/21/2022 04:45:57 - INFO - __main__ - Step 380 Global step 380 Train loss 1.65 on epoch=27
05/21/2022 04:45:59 - INFO - __main__ - Step 390 Global step 390 Train loss 1.72 on epoch=27
05/21/2022 04:46:00 - INFO - __main__ - Step 400 Global step 400 Train loss 1.60 on epoch=28
05/21/2022 04:46:02 - INFO - __main__ - Global step 400 Train loss 1.68 Classification-F1 0.04736231497903119 on epoch=28
05/21/2022 04:46:02 - INFO - __main__ - Saving model with best Classification-F1: 0.029036288292428523 -> 0.04736231497903119 on epoch=28, global_step=400
05/21/2022 04:46:03 - INFO - __main__ - Step 410 Global step 410 Train loss 1.63 on epoch=29
05/21/2022 04:46:05 - INFO - __main__ - Step 420 Global step 420 Train loss 1.59 on epoch=29
05/21/2022 04:46:06 - INFO - __main__ - Step 430 Global step 430 Train loss 1.58 on epoch=30
05/21/2022 04:46:07 - INFO - __main__ - Step 440 Global step 440 Train loss 1.59 on epoch=31
05/21/2022 04:46:09 - INFO - __main__ - Step 450 Global step 450 Train loss 1.47 on epoch=32
05/21/2022 04:46:12 - INFO - __main__ - Global step 450 Train loss 1.57 Classification-F1 0.03994744386048734 on epoch=32
05/21/2022 04:46:13 - INFO - __main__ - Step 460 Global step 460 Train loss 1.47 on epoch=32
05/21/2022 04:46:14 - INFO - __main__ - Step 470 Global step 470 Train loss 1.51 on epoch=33
05/21/2022 04:46:15 - INFO - __main__ - Step 480 Global step 480 Train loss 1.52 on epoch=34
05/21/2022 04:46:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.50 on epoch=34
05/21/2022 04:46:18 - INFO - __main__ - Step 500 Global step 500 Train loss 1.32 on epoch=35
05/21/2022 04:46:21 - INFO - __main__ - Global step 500 Train loss 1.46 Classification-F1 0.029159650789946038 on epoch=35
05/21/2022 04:46:22 - INFO - __main__ - Step 510 Global step 510 Train loss 1.46 on epoch=36
05/21/2022 04:46:23 - INFO - __main__ - Step 520 Global step 520 Train loss 1.20 on epoch=37
05/21/2022 04:46:24 - INFO - __main__ - Step 530 Global step 530 Train loss 1.43 on epoch=37
05/21/2022 04:46:25 - INFO - __main__ - Step 540 Global step 540 Train loss 1.48 on epoch=38
05/21/2022 04:46:27 - INFO - __main__ - Step 550 Global step 550 Train loss 1.49 on epoch=39
05/21/2022 04:46:30 - INFO - __main__ - Global step 550 Train loss 1.41 Classification-F1 0.04402436350924593 on epoch=39
05/21/2022 04:46:31 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=39
05/21/2022 04:46:32 - INFO - __main__ - Step 570 Global step 570 Train loss 1.26 on epoch=40
05/21/2022 04:46:33 - INFO - __main__ - Step 580 Global step 580 Train loss 1.29 on epoch=41
05/21/2022 04:46:35 - INFO - __main__ - Step 590 Global step 590 Train loss 1.30 on epoch=42
05/21/2022 04:46:36 - INFO - __main__ - Step 600 Global step 600 Train loss 1.30 on epoch=42
05/21/2022 04:46:39 - INFO - __main__ - Global step 600 Train loss 1.30 Classification-F1 0.07027649769585255 on epoch=42
05/21/2022 04:46:39 - INFO - __main__ - Saving model with best Classification-F1: 0.04736231497903119 -> 0.07027649769585255 on epoch=42, global_step=600
05/21/2022 04:46:40 - INFO - __main__ - Step 610 Global step 610 Train loss 1.25 on epoch=43
05/21/2022 04:46:41 - INFO - __main__ - Step 620 Global step 620 Train loss 1.27 on epoch=44
05/21/2022 04:46:42 - INFO - __main__ - Step 630 Global step 630 Train loss 1.25 on epoch=44
05/21/2022 04:46:44 - INFO - __main__ - Step 640 Global step 640 Train loss 1.18 on epoch=45
05/21/2022 04:46:45 - INFO - __main__ - Step 650 Global step 650 Train loss 1.24 on epoch=46
05/21/2022 04:46:48 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.15303232950001752 on epoch=46
05/21/2022 04:46:48 - INFO - __main__ - Saving model with best Classification-F1: 0.07027649769585255 -> 0.15303232950001752 on epoch=46, global_step=650
05/21/2022 04:46:49 - INFO - __main__ - Step 660 Global step 660 Train loss 1.26 on epoch=47
05/21/2022 04:46:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.20 on epoch=47
05/21/2022 04:46:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.25 on epoch=48
05/21/2022 04:46:53 - INFO - __main__ - Step 690 Global step 690 Train loss 1.29 on epoch=49
05/21/2022 04:46:54 - INFO - __main__ - Step 700 Global step 700 Train loss 1.33 on epoch=49
05/21/2022 04:46:58 - INFO - __main__ - Global step 700 Train loss 1.27 Classification-F1 0.2371194384861121 on epoch=49
05/21/2022 04:46:58 - INFO - __main__ - Saving model with best Classification-F1: 0.15303232950001752 -> 0.2371194384861121 on epoch=49, global_step=700
05/21/2022 04:46:59 - INFO - __main__ - Step 710 Global step 710 Train loss 1.14 on epoch=50
05/21/2022 04:47:00 - INFO - __main__ - Step 720 Global step 720 Train loss 1.26 on epoch=51
05/21/2022 04:47:01 - INFO - __main__ - Step 730 Global step 730 Train loss 1.19 on epoch=52
05/21/2022 04:47:03 - INFO - __main__ - Step 740 Global step 740 Train loss 1.22 on epoch=52
05/21/2022 04:47:04 - INFO - __main__ - Step 750 Global step 750 Train loss 1.13 on epoch=53
05/21/2022 04:47:07 - INFO - __main__ - Global step 750 Train loss 1.19 Classification-F1 0.27584183695970516 on epoch=53
05/21/2022 04:47:07 - INFO - __main__ - Saving model with best Classification-F1: 0.2371194384861121 -> 0.27584183695970516 on epoch=53, global_step=750
05/21/2022 04:47:08 - INFO - __main__ - Step 760 Global step 760 Train loss 1.16 on epoch=54
05/21/2022 04:47:10 - INFO - __main__ - Step 770 Global step 770 Train loss 1.19 on epoch=54
05/21/2022 04:47:11 - INFO - __main__ - Step 780 Global step 780 Train loss 1.13 on epoch=55
05/21/2022 04:47:12 - INFO - __main__ - Step 790 Global step 790 Train loss 1.11 on epoch=56
05/21/2022 04:47:13 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=57
05/21/2022 04:47:17 - INFO - __main__ - Global step 800 Train loss 1.15 Classification-F1 0.28699401324660384 on epoch=57
05/21/2022 04:47:17 - INFO - __main__ - Saving model with best Classification-F1: 0.27584183695970516 -> 0.28699401324660384 on epoch=57, global_step=800
05/21/2022 04:47:18 - INFO - __main__ - Step 810 Global step 810 Train loss 1.14 on epoch=57
05/21/2022 04:47:20 - INFO - __main__ - Step 820 Global step 820 Train loss 1.03 on epoch=58
05/21/2022 04:47:21 - INFO - __main__ - Step 830 Global step 830 Train loss 1.15 on epoch=59
05/21/2022 04:47:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.99 on epoch=59
05/21/2022 04:47:23 - INFO - __main__ - Step 850 Global step 850 Train loss 1.00 on epoch=60
05/21/2022 04:47:26 - INFO - __main__ - Global step 850 Train loss 1.06 Classification-F1 0.3613625120605195 on epoch=60
05/21/2022 04:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.28699401324660384 -> 0.3613625120605195 on epoch=60, global_step=850
05/21/2022 04:47:28 - INFO - __main__ - Step 860 Global step 860 Train loss 1.13 on epoch=61
05/21/2022 04:47:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.98 on epoch=62
05/21/2022 04:47:30 - INFO - __main__ - Step 880 Global step 880 Train loss 1.11 on epoch=62
05/21/2022 04:47:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.91 on epoch=63
05/21/2022 04:47:33 - INFO - __main__ - Step 900 Global step 900 Train loss 1.06 on epoch=64
05/21/2022 04:47:36 - INFO - __main__ - Global step 900 Train loss 1.04 Classification-F1 0.3770910367176884 on epoch=64
05/21/2022 04:47:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3613625120605195 -> 0.3770910367176884 on epoch=64, global_step=900
05/21/2022 04:47:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.96 on epoch=64
05/21/2022 04:47:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.86 on epoch=65
05/21/2022 04:47:40 - INFO - __main__ - Step 930 Global step 930 Train loss 1.03 on epoch=66
05/21/2022 04:47:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.93 on epoch=67
05/21/2022 04:47:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.97 on epoch=67
05/21/2022 04:47:46 - INFO - __main__ - Global step 950 Train loss 0.95 Classification-F1 0.32836793482567933 on epoch=67
05/21/2022 04:47:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.92 on epoch=68
05/21/2022 04:47:48 - INFO - __main__ - Step 970 Global step 970 Train loss 1.01 on epoch=69
05/21/2022 04:47:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.95 on epoch=69
05/21/2022 04:47:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.88 on epoch=70
05/21/2022 04:47:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.93 on epoch=71
05/21/2022 04:47:55 - INFO - __main__ - Global step 1000 Train loss 0.94 Classification-F1 0.38193952812537174 on epoch=71
05/21/2022 04:47:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3770910367176884 -> 0.38193952812537174 on epoch=71, global_step=1000
05/21/2022 04:47:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.96 on epoch=72
05/21/2022 04:47:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.87 on epoch=72
05/21/2022 04:47:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.94 on epoch=73
05/21/2022 04:48:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.92 on epoch=74
05/21/2022 04:48:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.97 on epoch=74
05/21/2022 04:48:05 - INFO - __main__ - Global step 1050 Train loss 0.93 Classification-F1 0.4694736745788746 on epoch=74
05/21/2022 04:48:05 - INFO - __main__ - Saving model with best Classification-F1: 0.38193952812537174 -> 0.4694736745788746 on epoch=74, global_step=1050
05/21/2022 04:48:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.81 on epoch=75
05/21/2022 04:48:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.78 on epoch=76
05/21/2022 04:48:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.96 on epoch=77
05/21/2022 04:48:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.86 on epoch=77
05/21/2022 04:48:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.81 on epoch=78
05/21/2022 04:48:15 - INFO - __main__ - Global step 1100 Train loss 0.84 Classification-F1 0.4769979548918512 on epoch=78
05/21/2022 04:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4694736745788746 -> 0.4769979548918512 on epoch=78, global_step=1100
05/21/2022 04:48:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.93 on epoch=79
05/21/2022 04:48:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.87 on epoch=79
05/21/2022 04:48:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.86 on epoch=80
05/21/2022 04:48:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.78 on epoch=81
05/21/2022 04:48:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.85 on epoch=82
05/21/2022 04:48:24 - INFO - __main__ - Global step 1150 Train loss 0.86 Classification-F1 0.4305798004124109 on epoch=82
05/21/2022 04:48:26 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.80 on epoch=82
05/21/2022 04:48:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.79 on epoch=83
05/21/2022 04:48:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.89 on epoch=84
05/21/2022 04:48:29 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.89 on epoch=84
05/21/2022 04:48:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.78 on epoch=85
05/21/2022 04:48:34 - INFO - __main__ - Global step 1200 Train loss 0.83 Classification-F1 0.5371970798521823 on epoch=85
05/21/2022 04:48:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4769979548918512 -> 0.5371970798521823 on epoch=85, global_step=1200
05/21/2022 04:48:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.77 on epoch=86
05/21/2022 04:48:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.83 on epoch=87
05/21/2022 04:48:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.88 on epoch=87
05/21/2022 04:48:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.69 on epoch=88
05/21/2022 04:48:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.84 on epoch=89
05/21/2022 04:48:44 - INFO - __main__ - Global step 1250 Train loss 0.80 Classification-F1 0.5593650014403917 on epoch=89
05/21/2022 04:48:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5371970798521823 -> 0.5593650014403917 on epoch=89, global_step=1250
05/21/2022 04:48:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.78 on epoch=89
05/21/2022 04:48:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.79 on epoch=90
05/21/2022 04:48:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.78 on epoch=91
05/21/2022 04:48:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.79 on epoch=92
05/21/2022 04:48:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.83 on epoch=92
05/21/2022 04:48:54 - INFO - __main__ - Global step 1300 Train loss 0.79 Classification-F1 0.46245018567333085 on epoch=92
05/21/2022 04:48:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.73 on epoch=93
05/21/2022 04:48:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.74 on epoch=94
05/21/2022 04:48:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.71 on epoch=94
05/21/2022 04:48:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.79 on epoch=95
05/21/2022 04:49:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.79 on epoch=96
05/21/2022 04:49:04 - INFO - __main__ - Global step 1350 Train loss 0.75 Classification-F1 0.514171196821693 on epoch=96
05/21/2022 04:49:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.81 on epoch=97
05/21/2022 04:49:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.78 on epoch=97
05/21/2022 04:49:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.77 on epoch=98
05/21/2022 04:49:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.85 on epoch=99
05/21/2022 04:49:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.82 on epoch=99
05/21/2022 04:49:14 - INFO - __main__ - Global step 1400 Train loss 0.81 Classification-F1 0.45885190522232133 on epoch=99
05/21/2022 04:49:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.74 on epoch=100
05/21/2022 04:49:17 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.83 on epoch=101
05/21/2022 04:49:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.80 on epoch=102
05/21/2022 04:49:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.69 on epoch=102
05/21/2022 04:49:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/21/2022 04:49:25 - INFO - __main__ - Global step 1450 Train loss 0.76 Classification-F1 0.4647919654626045 on epoch=103
05/21/2022 04:49:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.71 on epoch=104
05/21/2022 04:49:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.67 on epoch=104
05/21/2022 04:49:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.79 on epoch=105
05/21/2022 04:49:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.76 on epoch=106
05/21/2022 04:49:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.67 on epoch=107
05/21/2022 04:49:34 - INFO - __main__ - Global step 1500 Train loss 0.72 Classification-F1 0.5217045329109063 on epoch=107
05/21/2022 04:49:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.71 on epoch=107
05/21/2022 04:49:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.65 on epoch=108
05/21/2022 04:49:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.70 on epoch=109
05/21/2022 04:49:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.69 on epoch=109
05/21/2022 04:49:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.67 on epoch=110
05/21/2022 04:49:44 - INFO - __main__ - Global step 1550 Train loss 0.68 Classification-F1 0.6252889229109214 on epoch=110
05/21/2022 04:49:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5593650014403917 -> 0.6252889229109214 on epoch=110, global_step=1550
05/21/2022 04:49:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.75 on epoch=111
05/21/2022 04:49:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.74 on epoch=112
05/21/2022 04:49:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.77 on epoch=112
05/21/2022 04:49:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.68 on epoch=113
05/21/2022 04:49:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.68 on epoch=114
05/21/2022 04:49:54 - INFO - __main__ - Global step 1600 Train loss 0.73 Classification-F1 0.4436415620083209 on epoch=114
05/21/2022 04:49:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.75 on epoch=114
05/21/2022 04:49:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.69 on epoch=115
05/21/2022 04:49:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.66 on epoch=116
05/21/2022 04:50:00 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.78 on epoch=117
05/21/2022 04:50:01 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.65 on epoch=117
05/21/2022 04:50:05 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.5261308911788498 on epoch=117
05/21/2022 04:50:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.71 on epoch=118
05/21/2022 04:50:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.72 on epoch=119
05/21/2022 04:50:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.70 on epoch=119
05/21/2022 04:50:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.70 on epoch=120
05/21/2022 04:50:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.72 on epoch=121
05/21/2022 04:50:15 - INFO - __main__ - Global step 1700 Train loss 0.71 Classification-F1 0.5564639916088828 on epoch=121
05/21/2022 04:50:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.72 on epoch=122
05/21/2022 04:50:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.70 on epoch=122
05/21/2022 04:50:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.69 on epoch=123
05/21/2022 04:50:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.75 on epoch=124
05/21/2022 04:50:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.70 on epoch=124
05/21/2022 04:50:25 - INFO - __main__ - Global step 1750 Train loss 0.71 Classification-F1 0.5757153753161872 on epoch=124
05/21/2022 04:50:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.68 on epoch=125
05/21/2022 04:50:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.59 on epoch=126
05/21/2022 04:50:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.68 on epoch=127
05/21/2022 04:50:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.69 on epoch=127
05/21/2022 04:50:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.70 on epoch=128
05/21/2022 04:50:34 - INFO - __main__ - Global step 1800 Train loss 0.67 Classification-F1 0.5445356731173963 on epoch=128
05/21/2022 04:50:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.66 on epoch=129
05/21/2022 04:50:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.71 on epoch=129
05/21/2022 04:50:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.65 on epoch=130
05/21/2022 04:50:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.67 on epoch=131
05/21/2022 04:50:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.64 on epoch=132
05/21/2022 04:50:44 - INFO - __main__ - Global step 1850 Train loss 0.67 Classification-F1 0.54820611318046 on epoch=132
05/21/2022 04:50:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.64 on epoch=132
05/21/2022 04:50:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.65 on epoch=133
05/21/2022 04:50:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.78 on epoch=134
05/21/2022 04:50:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.58 on epoch=134
05/21/2022 04:50:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.67 on epoch=135
05/21/2022 04:50:54 - INFO - __main__ - Global step 1900 Train loss 0.66 Classification-F1 0.6386547337414972 on epoch=135
05/21/2022 04:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6252889229109214 -> 0.6386547337414972 on epoch=135, global_step=1900
05/21/2022 04:50:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.71 on epoch=136
05/21/2022 04:50:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.67 on epoch=137
05/21/2022 04:50:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.69 on epoch=137
05/21/2022 04:50:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.59 on epoch=138
05/21/2022 04:51:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.68 on epoch=139
05/21/2022 04:51:04 - INFO - __main__ - Global step 1950 Train loss 0.67 Classification-F1 0.5211593207481449 on epoch=139
05/21/2022 04:51:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.67 on epoch=139
05/21/2022 04:51:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.59 on epoch=140
05/21/2022 04:51:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.64 on epoch=141
05/21/2022 04:51:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.70 on epoch=142
05/21/2022 04:51:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.71 on epoch=142
05/21/2022 04:51:14 - INFO - __main__ - Global step 2000 Train loss 0.66 Classification-F1 0.5850281050730608 on epoch=142
05/21/2022 04:51:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/21/2022 04:51:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.73 on epoch=144
05/21/2022 04:51:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.71 on epoch=144
05/21/2022 04:51:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.64 on epoch=145
05/21/2022 04:51:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.69 on epoch=146
05/21/2022 04:51:24 - INFO - __main__ - Global step 2050 Train loss 0.69 Classification-F1 0.5373458421383714 on epoch=146
05/21/2022 04:51:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.61 on epoch=147
05/21/2022 04:51:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.60 on epoch=147
05/21/2022 04:51:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.65 on epoch=148
05/21/2022 04:51:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.67 on epoch=149
05/21/2022 04:51:30 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.64 on epoch=149
05/21/2022 04:51:34 - INFO - __main__ - Global step 2100 Train loss 0.63 Classification-F1 0.6005097757154294 on epoch=149
05/21/2022 04:51:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.61 on epoch=150
05/21/2022 04:51:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.67 on epoch=151
05/21/2022 04:51:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.71 on epoch=152
05/21/2022 04:51:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.57 on epoch=152
05/21/2022 04:51:40 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.53 on epoch=153
05/21/2022 04:51:44 - INFO - __main__ - Global step 2150 Train loss 0.62 Classification-F1 0.6792367523739249 on epoch=153
05/21/2022 04:51:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6386547337414972 -> 0.6792367523739249 on epoch=153, global_step=2150
05/21/2022 04:51:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.72 on epoch=154
05/21/2022 04:51:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.57 on epoch=154
05/21/2022 04:51:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.57 on epoch=155
05/21/2022 04:51:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.53 on epoch=156
05/21/2022 04:51:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.68 on epoch=157
05/21/2022 04:51:54 - INFO - __main__ - Global step 2200 Train loss 0.62 Classification-F1 0.6759610981256092 on epoch=157
05/21/2022 04:51:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.61 on epoch=157
05/21/2022 04:51:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.59 on epoch=158
05/21/2022 04:51:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.54 on epoch=159
05/21/2022 04:51:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.59 on epoch=159
05/21/2022 04:52:01 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.59 on epoch=160
05/21/2022 04:52:05 - INFO - __main__ - Global step 2250 Train loss 0.58 Classification-F1 0.6152329833956565 on epoch=160
05/21/2022 04:52:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.62 on epoch=161
05/21/2022 04:52:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.56 on epoch=162
05/21/2022 04:52:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.61 on epoch=162
05/21/2022 04:52:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.52 on epoch=163
05/21/2022 04:52:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.62 on epoch=164
05/21/2022 04:52:15 - INFO - __main__ - Global step 2300 Train loss 0.59 Classification-F1 0.6267403480995284 on epoch=164
05/21/2022 04:52:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.58 on epoch=164
05/21/2022 04:52:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.62 on epoch=165
05/21/2022 04:52:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.50 on epoch=166
05/21/2022 04:52:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.59 on epoch=167
05/21/2022 04:52:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.60 on epoch=167
05/21/2022 04:52:25 - INFO - __main__ - Global step 2350 Train loss 0.58 Classification-F1 0.6547887836728481 on epoch=167
05/21/2022 04:52:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.52 on epoch=168
05/21/2022 04:52:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.61 on epoch=169
05/21/2022 04:52:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.57 on epoch=169
05/21/2022 04:52:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.55 on epoch=170
05/21/2022 04:52:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.56 on epoch=171
05/21/2022 04:52:35 - INFO - __main__ - Global step 2400 Train loss 0.56 Classification-F1 0.6257600064274917 on epoch=171
05/21/2022 04:52:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.63 on epoch=172
05/21/2022 04:52:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.59 on epoch=172
05/21/2022 04:52:39 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.57 on epoch=173
05/21/2022 04:52:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.59 on epoch=174
05/21/2022 04:52:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.55 on epoch=174
05/21/2022 04:52:45 - INFO - __main__ - Global step 2450 Train loss 0.59 Classification-F1 0.6542722359638171 on epoch=174
05/21/2022 04:52:47 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.59 on epoch=175
05/21/2022 04:52:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.58 on epoch=176
05/21/2022 04:52:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.64 on epoch=177
05/21/2022 04:52:50 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.60 on epoch=177
05/21/2022 04:52:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.53 on epoch=178
05/21/2022 04:52:55 - INFO - __main__ - Global step 2500 Train loss 0.59 Classification-F1 0.6756890612974471 on epoch=178
05/21/2022 04:52:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.62 on epoch=179
05/21/2022 04:52:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.67 on epoch=179
05/21/2022 04:52:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.57 on epoch=180
05/21/2022 04:53:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.54 on epoch=181
05/21/2022 04:53:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.55 on epoch=182
05/21/2022 04:53:05 - INFO - __main__ - Global step 2550 Train loss 0.59 Classification-F1 0.6012919464450097 on epoch=182
05/21/2022 04:53:07 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.49 on epoch=182
05/21/2022 04:53:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.56 on epoch=183
05/21/2022 04:53:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.62 on epoch=184
05/21/2022 04:53:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.60 on epoch=184
05/21/2022 04:53:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.58 on epoch=185
05/21/2022 04:53:15 - INFO - __main__ - Global step 2600 Train loss 0.57 Classification-F1 0.5842080153308914 on epoch=185
05/21/2022 04:53:17 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.52 on epoch=186
05/21/2022 04:53:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.51 on epoch=187
05/21/2022 04:53:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.57 on epoch=187
05/21/2022 04:53:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.46 on epoch=188
05/21/2022 04:53:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.59 on epoch=189
05/21/2022 04:53:25 - INFO - __main__ - Global step 2650 Train loss 0.53 Classification-F1 0.6525689705915226 on epoch=189
05/21/2022 04:53:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.60 on epoch=189
05/21/2022 04:53:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.47 on epoch=190
05/21/2022 04:53:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.61 on epoch=191
05/21/2022 04:53:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.64 on epoch=192
05/21/2022 04:53:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.44 on epoch=192
05/21/2022 04:53:36 - INFO - __main__ - Global step 2700 Train loss 0.55 Classification-F1 0.6877502583064932 on epoch=192
05/21/2022 04:53:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6792367523739249 -> 0.6877502583064932 on epoch=192, global_step=2700
05/21/2022 04:53:37 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.52 on epoch=193
05/21/2022 04:53:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.67 on epoch=194
05/21/2022 04:53:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.58 on epoch=194
05/21/2022 04:53:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.57 on epoch=195
05/21/2022 04:53:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.52 on epoch=196
05/21/2022 04:53:46 - INFO - __main__ - Global step 2750 Train loss 0.57 Classification-F1 0.6726047977560075 on epoch=196
05/21/2022 04:53:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.49 on epoch=197
05/21/2022 04:53:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.53 on epoch=197
05/21/2022 04:53:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.47 on epoch=198
05/21/2022 04:53:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.60 on epoch=199
05/21/2022 04:53:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.60 on epoch=199
05/21/2022 04:53:56 - INFO - __main__ - Global step 2800 Train loss 0.54 Classification-F1 0.5990672744968453 on epoch=199
05/21/2022 04:53:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.53 on epoch=200
05/21/2022 04:53:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.49 on epoch=201
05/21/2022 04:54:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.60 on epoch=202
05/21/2022 04:54:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.51 on epoch=202
05/21/2022 04:54:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.43 on epoch=203
05/21/2022 04:54:06 - INFO - __main__ - Global step 2850 Train loss 0.51 Classification-F1 0.6896904394230257 on epoch=203
05/21/2022 04:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6877502583064932 -> 0.6896904394230257 on epoch=203, global_step=2850
05/21/2022 04:54:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.55 on epoch=204
05/21/2022 04:54:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.51 on epoch=204
05/21/2022 04:54:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.53 on epoch=205
05/21/2022 04:54:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.49 on epoch=206
05/21/2022 04:54:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.54 on epoch=207
05/21/2022 04:54:16 - INFO - __main__ - Global step 2900 Train loss 0.52 Classification-F1 0.7572429597919794 on epoch=207
05/21/2022 04:54:16 - INFO - __main__ - Saving model with best Classification-F1: 0.6896904394230257 -> 0.7572429597919794 on epoch=207, global_step=2900
05/21/2022 04:54:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.44 on epoch=207
05/21/2022 04:54:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.46 on epoch=208
05/21/2022 04:54:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.56 on epoch=209
05/21/2022 04:54:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.43 on epoch=209
05/21/2022 04:54:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/21/2022 04:54:26 - INFO - __main__ - Global step 2950 Train loss 0.49 Classification-F1 0.6595539474418737 on epoch=210
05/21/2022 04:54:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.44 on epoch=211
05/21/2022 04:54:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.46 on epoch=212
05/21/2022 04:54:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.52 on epoch=212
05/21/2022 04:54:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.51 on epoch=213
05/21/2022 04:54:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.53 on epoch=214
05/21/2022 04:54:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:54:34 - INFO - __main__ - Printing 3 examples
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:54:34 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:54:34 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:54:34 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:54:34 - INFO - __main__ - Printing 3 examples
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:54:34 - INFO - __main__ - ['Animal']
05/21/2022 04:54:34 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:54:34 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:54:34 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:54:37 - INFO - __main__ - Global step 3000 Train loss 0.49 Classification-F1 0.6517473383912353 on epoch=214
05/21/2022 04:54:37 - INFO - __main__ - save last model!
05/21/2022 04:54:37 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 04:54:37 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 04:54:37 - INFO - __main__ - Printing 3 examples
05/21/2022 04:54:37 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 04:54:37 - INFO - __main__ - ['Animal']
05/21/2022 04:54:37 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 04:54:37 - INFO - __main__ - ['Animal']
05/21/2022 04:54:37 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 04:54:37 - INFO - __main__ - ['Village']
05/21/2022 04:54:37 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:54:38 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:54:40 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:54:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:54:41 - INFO - __main__ - Starting training!
05/21/2022 04:54:42 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 04:55:54 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
05/21/2022 04:55:54 - INFO - __main__ - Classification-F1 on test data: 0.3095
05/21/2022 04:55:54 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.7572429597919794, test_performance=0.3094864968159179
05/21/2022 04:55:54 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
05/21/2022 04:55:55 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:55:55 - INFO - __main__ - Printing 3 examples
05/21/2022 04:55:55 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 04:55:55 - INFO - __main__ - ['Animal']
05/21/2022 04:55:55 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 04:55:55 - INFO - __main__ - ['Animal']
05/21/2022 04:55:55 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 04:55:55 - INFO - __main__ - ['Animal']
05/21/2022 04:55:55 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:55:55 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:55:56 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 04:55:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 04:55:56 - INFO - __main__ - Printing 3 examples
05/21/2022 04:55:56 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 04:55:56 - INFO - __main__ - ['Animal']
05/21/2022 04:55:56 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 04:55:56 - INFO - __main__ - ['Animal']
05/21/2022 04:55:56 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 04:55:56 - INFO - __main__ - ['Animal']
05/21/2022 04:55:56 - INFO - __main__ - Tokenizing Input ...
05/21/2022 04:55:56 - INFO - __main__ - Tokenizing Output ...
05/21/2022 04:55:56 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 04:56:01 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 04:56:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 04:56:02 - INFO - __main__ - Starting training!
05/21/2022 04:56:03 - INFO - __main__ - Step 10 Global step 10 Train loss 7.49 on epoch=0
05/21/2022 04:56:04 - INFO - __main__ - Step 20 Global step 20 Train loss 6.97 on epoch=1
05/21/2022 04:56:06 - INFO - __main__ - Step 30 Global step 30 Train loss 6.32 on epoch=2
05/21/2022 04:56:07 - INFO - __main__ - Step 40 Global step 40 Train loss 6.09 on epoch=2
05/21/2022 04:56:08 - INFO - __main__ - Step 50 Global step 50 Train loss 5.85 on epoch=3
05/21/2022 04:56:11 - INFO - __main__ - Global step 50 Train loss 6.54 Classification-F1 0.0 on epoch=3
05/21/2022 04:56:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 04:56:12 - INFO - __main__ - Step 60 Global step 60 Train loss 5.63 on epoch=4
05/21/2022 04:56:13 - INFO - __main__ - Step 70 Global step 70 Train loss 5.35 on epoch=4
05/21/2022 04:56:15 - INFO - __main__ - Step 80 Global step 80 Train loss 4.82 on epoch=5
05/21/2022 04:56:16 - INFO - __main__ - Step 90 Global step 90 Train loss 4.76 on epoch=6
05/21/2022 04:56:17 - INFO - __main__ - Step 100 Global step 100 Train loss 4.45 on epoch=7
05/21/2022 04:56:20 - INFO - __main__ - Global step 100 Train loss 5.00 Classification-F1 0.0 on epoch=7
05/21/2022 04:56:22 - INFO - __main__ - Step 110 Global step 110 Train loss 4.26 on epoch=7
05/21/2022 04:56:23 - INFO - __main__ - Step 120 Global step 120 Train loss 4.08 on epoch=8
05/21/2022 04:56:24 - INFO - __main__ - Step 130 Global step 130 Train loss 3.78 on epoch=9
05/21/2022 04:56:25 - INFO - __main__ - Step 140 Global step 140 Train loss 3.88 on epoch=9
05/21/2022 04:56:27 - INFO - __main__ - Step 150 Global step 150 Train loss 3.53 on epoch=10
05/21/2022 04:56:30 - INFO - __main__ - Global step 150 Train loss 3.91 Classification-F1 0.0 on epoch=10
05/21/2022 04:56:31 - INFO - __main__ - Step 160 Global step 160 Train loss 3.57 on epoch=11
05/21/2022 04:56:32 - INFO - __main__ - Step 170 Global step 170 Train loss 3.55 on epoch=12
05/21/2022 04:56:33 - INFO - __main__ - Step 180 Global step 180 Train loss 3.27 on epoch=12
05/21/2022 04:56:35 - INFO - __main__ - Step 190 Global step 190 Train loss 3.20 on epoch=13
05/21/2022 04:56:36 - INFO - __main__ - Step 200 Global step 200 Train loss 3.14 on epoch=14
05/21/2022 04:56:38 - INFO - __main__ - Global step 200 Train loss 3.35 Classification-F1 0.0024922118380062306 on epoch=14
05/21/2022 04:56:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0024922118380062306 on epoch=14, global_step=200
05/21/2022 04:56:40 - INFO - __main__ - Step 210 Global step 210 Train loss 3.15 on epoch=14
05/21/2022 04:56:41 - INFO - __main__ - Step 220 Global step 220 Train loss 2.87 on epoch=15
05/21/2022 04:56:42 - INFO - __main__ - Step 230 Global step 230 Train loss 2.89 on epoch=16
05/21/2022 04:56:44 - INFO - __main__ - Step 240 Global step 240 Train loss 2.86 on epoch=17
05/21/2022 04:56:45 - INFO - __main__ - Step 250 Global step 250 Train loss 2.70 on epoch=17
05/21/2022 04:56:47 - INFO - __main__ - Global step 250 Train loss 2.89 Classification-F1 0.008333333333333333 on epoch=17
05/21/2022 04:56:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0024922118380062306 -> 0.008333333333333333 on epoch=17, global_step=250
05/21/2022 04:56:48 - INFO - __main__ - Step 260 Global step 260 Train loss 2.51 on epoch=18
05/21/2022 04:56:50 - INFO - __main__ - Step 270 Global step 270 Train loss 2.61 on epoch=19
05/21/2022 04:56:51 - INFO - __main__ - Step 280 Global step 280 Train loss 2.60 on epoch=19
05/21/2022 04:56:52 - INFO - __main__ - Step 290 Global step 290 Train loss 2.40 on epoch=20
05/21/2022 04:56:54 - INFO - __main__ - Step 300 Global step 300 Train loss 2.50 on epoch=21
05/21/2022 04:56:55 - INFO - __main__ - Global step 300 Train loss 2.52 Classification-F1 0.00892608089260809 on epoch=21
05/21/2022 04:56:55 - INFO - __main__ - Saving model with best Classification-F1: 0.008333333333333333 -> 0.00892608089260809 on epoch=21, global_step=300
05/21/2022 04:56:57 - INFO - __main__ - Step 310 Global step 310 Train loss 2.32 on epoch=22
05/21/2022 04:56:58 - INFO - __main__ - Step 320 Global step 320 Train loss 2.28 on epoch=22
05/21/2022 04:56:59 - INFO - __main__ - Step 330 Global step 330 Train loss 2.17 on epoch=23
05/21/2022 04:57:00 - INFO - __main__ - Step 340 Global step 340 Train loss 2.19 on epoch=24
05/21/2022 04:57:02 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/21/2022 04:57:04 - INFO - __main__ - Global step 350 Train loss 2.22 Classification-F1 0.009001406469760902 on epoch=24
05/21/2022 04:57:04 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009001406469760902 on epoch=24, global_step=350
05/21/2022 04:57:05 - INFO - __main__ - Step 360 Global step 360 Train loss 2.12 on epoch=25
05/21/2022 04:57:06 - INFO - __main__ - Step 370 Global step 370 Train loss 2.03 on epoch=26
05/21/2022 04:57:08 - INFO - __main__ - Step 380 Global step 380 Train loss 2.07 on epoch=27
05/21/2022 04:57:09 - INFO - __main__ - Step 390 Global step 390 Train loss 2.01 on epoch=27
05/21/2022 04:57:10 - INFO - __main__ - Step 400 Global step 400 Train loss 1.93 on epoch=28
05/21/2022 04:57:12 - INFO - __main__ - Global step 400 Train loss 2.03 Classification-F1 0.023682036532754032 on epoch=28
05/21/2022 04:57:12 - INFO - __main__ - Saving model with best Classification-F1: 0.009001406469760902 -> 0.023682036532754032 on epoch=28, global_step=400
05/21/2022 04:57:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.03 on epoch=29
05/21/2022 04:57:15 - INFO - __main__ - Step 420 Global step 420 Train loss 1.91 on epoch=29
05/21/2022 04:57:16 - INFO - __main__ - Step 430 Global step 430 Train loss 1.90 on epoch=30
05/21/2022 04:57:17 - INFO - __main__ - Step 440 Global step 440 Train loss 1.86 on epoch=31
05/21/2022 04:57:18 - INFO - __main__ - Step 450 Global step 450 Train loss 1.80 on epoch=32
05/21/2022 04:57:20 - INFO - __main__ - Global step 450 Train loss 1.90 Classification-F1 0.02449537390713861 on epoch=32
05/21/2022 04:57:20 - INFO - __main__ - Saving model with best Classification-F1: 0.023682036532754032 -> 0.02449537390713861 on epoch=32, global_step=450
05/21/2022 04:57:22 - INFO - __main__ - Step 460 Global step 460 Train loss 1.80 on epoch=32
05/21/2022 04:57:23 - INFO - __main__ - Step 470 Global step 470 Train loss 1.71 on epoch=33
05/21/2022 04:57:24 - INFO - __main__ - Step 480 Global step 480 Train loss 1.66 on epoch=34
05/21/2022 04:57:25 - INFO - __main__ - Step 490 Global step 490 Train loss 1.82 on epoch=34
05/21/2022 04:57:27 - INFO - __main__ - Step 500 Global step 500 Train loss 1.50 on epoch=35
05/21/2022 04:57:29 - INFO - __main__ - Global step 500 Train loss 1.70 Classification-F1 0.030796980796980795 on epoch=35
05/21/2022 04:57:29 - INFO - __main__ - Saving model with best Classification-F1: 0.02449537390713861 -> 0.030796980796980795 on epoch=35, global_step=500
05/21/2022 04:57:30 - INFO - __main__ - Step 510 Global step 510 Train loss 1.72 on epoch=36
05/21/2022 04:57:31 - INFO - __main__ - Step 520 Global step 520 Train loss 1.64 on epoch=37
05/21/2022 04:57:33 - INFO - __main__ - Step 530 Global step 530 Train loss 1.60 on epoch=37
05/21/2022 04:57:34 - INFO - __main__ - Step 540 Global step 540 Train loss 1.57 on epoch=38
05/21/2022 04:57:35 - INFO - __main__ - Step 550 Global step 550 Train loss 1.53 on epoch=39
05/21/2022 04:57:37 - INFO - __main__ - Global step 550 Train loss 1.61 Classification-F1 0.0362671384343211 on epoch=39
05/21/2022 04:57:37 - INFO - __main__ - Saving model with best Classification-F1: 0.030796980796980795 -> 0.0362671384343211 on epoch=39, global_step=550
05/21/2022 04:57:39 - INFO - __main__ - Step 560 Global step 560 Train loss 1.60 on epoch=39
05/21/2022 04:57:40 - INFO - __main__ - Step 570 Global step 570 Train loss 1.50 on epoch=40
05/21/2022 04:57:41 - INFO - __main__ - Step 580 Global step 580 Train loss 1.50 on epoch=41
05/21/2022 04:57:43 - INFO - __main__ - Step 590 Global step 590 Train loss 1.47 on epoch=42
05/21/2022 04:57:44 - INFO - __main__ - Step 600 Global step 600 Train loss 1.52 on epoch=42
05/21/2022 04:57:47 - INFO - __main__ - Global step 600 Train loss 1.52 Classification-F1 0.05157937596153971 on epoch=42
05/21/2022 04:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0362671384343211 -> 0.05157937596153971 on epoch=42, global_step=600
05/21/2022 04:57:48 - INFO - __main__ - Step 610 Global step 610 Train loss 1.46 on epoch=43
05/21/2022 04:57:49 - INFO - __main__ - Step 620 Global step 620 Train loss 1.51 on epoch=44
05/21/2022 04:57:51 - INFO - __main__ - Step 630 Global step 630 Train loss 1.45 on epoch=44
05/21/2022 04:57:52 - INFO - __main__ - Step 640 Global step 640 Train loss 1.43 on epoch=45
05/21/2022 04:57:53 - INFO - __main__ - Step 650 Global step 650 Train loss 1.52 on epoch=46
05/21/2022 04:57:56 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.05001770972907253 on epoch=46
05/21/2022 04:57:58 - INFO - __main__ - Step 660 Global step 660 Train loss 1.38 on epoch=47
05/21/2022 04:57:59 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=47
05/21/2022 04:58:00 - INFO - __main__ - Step 680 Global step 680 Train loss 1.42 on epoch=48
05/21/2022 04:58:01 - INFO - __main__ - Step 690 Global step 690 Train loss 1.42 on epoch=49
05/21/2022 04:58:03 - INFO - __main__ - Step 700 Global step 700 Train loss 1.50 on epoch=49
05/21/2022 04:58:06 - INFO - __main__ - Global step 700 Train loss 1.44 Classification-F1 0.05177440805273735 on epoch=49
05/21/2022 04:58:06 - INFO - __main__ - Saving model with best Classification-F1: 0.05157937596153971 -> 0.05177440805273735 on epoch=49, global_step=700
05/21/2022 04:58:07 - INFO - __main__ - Step 710 Global step 710 Train loss 1.40 on epoch=50
05/21/2022 04:58:08 - INFO - __main__ - Step 720 Global step 720 Train loss 1.37 on epoch=51
05/21/2022 04:58:09 - INFO - __main__ - Step 730 Global step 730 Train loss 1.41 on epoch=52
05/21/2022 04:58:11 - INFO - __main__ - Step 740 Global step 740 Train loss 1.43 on epoch=52
05/21/2022 04:58:12 - INFO - __main__ - Step 750 Global step 750 Train loss 1.23 on epoch=53
05/21/2022 04:58:15 - INFO - __main__ - Global step 750 Train loss 1.37 Classification-F1 0.04950527059434245 on epoch=53
05/21/2022 04:58:16 - INFO - __main__ - Step 760 Global step 760 Train loss 1.29 on epoch=54
05/21/2022 04:58:17 - INFO - __main__ - Step 770 Global step 770 Train loss 1.40 on epoch=54
05/21/2022 04:58:18 - INFO - __main__ - Step 780 Global step 780 Train loss 1.34 on epoch=55
05/21/2022 04:58:19 - INFO - __main__ - Step 790 Global step 790 Train loss 1.39 on epoch=56
05/21/2022 04:58:21 - INFO - __main__ - Step 800 Global step 800 Train loss 1.39 on epoch=57
05/21/2022 04:58:23 - INFO - __main__ - Global step 800 Train loss 1.36 Classification-F1 0.0882849787512259 on epoch=57
05/21/2022 04:58:23 - INFO - __main__ - Saving model with best Classification-F1: 0.05177440805273735 -> 0.0882849787512259 on epoch=57, global_step=800
05/21/2022 04:58:24 - INFO - __main__ - Step 810 Global step 810 Train loss 1.34 on epoch=57
05/21/2022 04:58:25 - INFO - __main__ - Step 820 Global step 820 Train loss 1.27 on epoch=58
05/21/2022 04:58:27 - INFO - __main__ - Step 830 Global step 830 Train loss 1.34 on epoch=59
05/21/2022 04:58:28 - INFO - __main__ - Step 840 Global step 840 Train loss 1.33 on epoch=59
05/21/2022 04:58:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=60
05/21/2022 04:58:32 - INFO - __main__ - Global step 850 Train loss 1.30 Classification-F1 0.0679465394860987 on epoch=60
05/21/2022 04:58:33 - INFO - __main__ - Step 860 Global step 860 Train loss 1.32 on epoch=61
05/21/2022 04:58:34 - INFO - __main__ - Step 870 Global step 870 Train loss 1.27 on epoch=62
05/21/2022 04:58:36 - INFO - __main__ - Step 880 Global step 880 Train loss 1.23 on epoch=62
05/21/2022 04:58:37 - INFO - __main__ - Step 890 Global step 890 Train loss 1.16 on epoch=63
05/21/2022 04:58:38 - INFO - __main__ - Step 900 Global step 900 Train loss 1.30 on epoch=64
05/21/2022 04:58:41 - INFO - __main__ - Global step 900 Train loss 1.26 Classification-F1 0.13070547198145605 on epoch=64
05/21/2022 04:58:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0882849787512259 -> 0.13070547198145605 on epoch=64, global_step=900
05/21/2022 04:58:42 - INFO - __main__ - Step 910 Global step 910 Train loss 1.29 on epoch=64
05/21/2022 04:58:43 - INFO - __main__ - Step 920 Global step 920 Train loss 1.14 on epoch=65
05/21/2022 04:58:45 - INFO - __main__ - Step 930 Global step 930 Train loss 1.12 on epoch=66
05/21/2022 04:58:46 - INFO - __main__ - Step 940 Global step 940 Train loss 1.27 on epoch=67
05/21/2022 04:58:47 - INFO - __main__ - Step 950 Global step 950 Train loss 1.19 on epoch=67
05/21/2022 04:58:50 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.14456472535032905 on epoch=67
05/21/2022 04:58:50 - INFO - __main__ - Saving model with best Classification-F1: 0.13070547198145605 -> 0.14456472535032905 on epoch=67, global_step=950
05/21/2022 04:58:51 - INFO - __main__ - Step 960 Global step 960 Train loss 1.14 on epoch=68
05/21/2022 04:58:52 - INFO - __main__ - Step 970 Global step 970 Train loss 1.20 on epoch=69
05/21/2022 04:58:54 - INFO - __main__ - Step 980 Global step 980 Train loss 1.13 on epoch=69
05/21/2022 04:58:55 - INFO - __main__ - Step 990 Global step 990 Train loss 1.23 on epoch=70
05/21/2022 04:58:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.21 on epoch=71
05/21/2022 04:58:59 - INFO - __main__ - Global step 1000 Train loss 1.18 Classification-F1 0.16793494340091927 on epoch=71
05/21/2022 04:58:59 - INFO - __main__ - Saving model with best Classification-F1: 0.14456472535032905 -> 0.16793494340091927 on epoch=71, global_step=1000
05/21/2022 04:59:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.12 on epoch=72
05/21/2022 04:59:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.13 on epoch=72
05/21/2022 04:59:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.18 on epoch=73
05/21/2022 04:59:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.26 on epoch=74
05/21/2022 04:59:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.20 on epoch=74
05/21/2022 04:59:09 - INFO - __main__ - Global step 1050 Train loss 1.18 Classification-F1 0.24728569766536715 on epoch=74
05/21/2022 04:59:09 - INFO - __main__ - Saving model with best Classification-F1: 0.16793494340091927 -> 0.24728569766536715 on epoch=74, global_step=1050
05/21/2022 04:59:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.08 on epoch=75
05/21/2022 04:59:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.24 on epoch=76
05/21/2022 04:59:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.08 on epoch=77
05/21/2022 04:59:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.31 on epoch=77
05/21/2022 04:59:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.01 on epoch=78
05/21/2022 04:59:18 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.3244508084266361 on epoch=78
05/21/2022 04:59:18 - INFO - __main__ - Saving model with best Classification-F1: 0.24728569766536715 -> 0.3244508084266361 on epoch=78, global_step=1100
05/21/2022 04:59:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=79
05/21/2022 04:59:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.19 on epoch=79
05/21/2022 04:59:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.12 on epoch=80
05/21/2022 04:59:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.10 on epoch=81
05/21/2022 04:59:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.00 on epoch=82
05/21/2022 04:59:27 - INFO - __main__ - Global step 1150 Train loss 1.13 Classification-F1 0.33462911378952453 on epoch=82
05/21/2022 04:59:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3244508084266361 -> 0.33462911378952453 on epoch=82, global_step=1150
05/21/2022 04:59:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.08 on epoch=82
05/21/2022 04:59:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=83
05/21/2022 04:59:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.20 on epoch=84
05/21/2022 04:59:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=84
05/21/2022 04:59:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.03 on epoch=85
05/21/2022 04:59:37 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.3499950377394849 on epoch=85
05/21/2022 04:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.33462911378952453 -> 0.3499950377394849 on epoch=85, global_step=1200
05/21/2022 04:59:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.96 on epoch=86
05/21/2022 04:59:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/21/2022 04:59:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.96 on epoch=87
05/21/2022 04:59:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.02 on epoch=88
05/21/2022 04:59:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=89
05/21/2022 04:59:46 - INFO - __main__ - Global step 1250 Train loss 1.02 Classification-F1 0.3811215708879141 on epoch=89
05/21/2022 04:59:46 - INFO - __main__ - Saving model with best Classification-F1: 0.3499950377394849 -> 0.3811215708879141 on epoch=89, global_step=1250
05/21/2022 04:59:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.00 on epoch=89
05/21/2022 04:59:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.97 on epoch=90
05/21/2022 04:59:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.00 on epoch=91
05/21/2022 04:59:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.03 on epoch=92
05/21/2022 04:59:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.04 on epoch=92
05/21/2022 04:59:56 - INFO - __main__ - Global step 1300 Train loss 1.01 Classification-F1 0.34966306417270004 on epoch=92
05/21/2022 04:59:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.90 on epoch=93
05/21/2022 04:59:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.04 on epoch=94
05/21/2022 05:00:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.03 on epoch=94
05/21/2022 05:00:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.96 on epoch=95
05/21/2022 05:00:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.99 on epoch=96
05/21/2022 05:00:06 - INFO - __main__ - Global step 1350 Train loss 0.98 Classification-F1 0.39252550793041907 on epoch=96
05/21/2022 05:00:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3811215708879141 -> 0.39252550793041907 on epoch=96, global_step=1350
05/21/2022 05:00:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.99 on epoch=97
05/21/2022 05:00:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.92 on epoch=97
05/21/2022 05:00:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.97 on epoch=98
05/21/2022 05:00:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.99 on epoch=99
05/21/2022 05:00:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.96 on epoch=99
05/21/2022 05:00:16 - INFO - __main__ - Global step 1400 Train loss 0.96 Classification-F1 0.4497458919869441 on epoch=99
05/21/2022 05:00:16 - INFO - __main__ - Saving model with best Classification-F1: 0.39252550793041907 -> 0.4497458919869441 on epoch=99, global_step=1400
05/21/2022 05:00:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.93 on epoch=100
05/21/2022 05:00:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.98 on epoch=101
05/21/2022 05:00:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.02 on epoch=102
05/21/2022 05:00:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.87 on epoch=102
05/21/2022 05:00:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.88 on epoch=103
05/21/2022 05:00:25 - INFO - __main__ - Global step 1450 Train loss 0.94 Classification-F1 0.41630367333307927 on epoch=103
05/21/2022 05:00:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.95 on epoch=104
05/21/2022 05:00:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.84 on epoch=104
05/21/2022 05:00:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.93 on epoch=105
05/21/2022 05:00:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.94 on epoch=106
05/21/2022 05:00:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.91 on epoch=107
05/21/2022 05:00:35 - INFO - __main__ - Global step 1500 Train loss 0.92 Classification-F1 0.46933153432715374 on epoch=107
05/21/2022 05:00:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4497458919869441 -> 0.46933153432715374 on epoch=107, global_step=1500
05/21/2022 05:00:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.96 on epoch=107
05/21/2022 05:00:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.94 on epoch=108
05/21/2022 05:00:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.95 on epoch=109
05/21/2022 05:00:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.93 on epoch=109
05/21/2022 05:00:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.83 on epoch=110
05/21/2022 05:00:45 - INFO - __main__ - Global step 1550 Train loss 0.92 Classification-F1 0.49318817290229383 on epoch=110
05/21/2022 05:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.46933153432715374 -> 0.49318817290229383 on epoch=110, global_step=1550
05/21/2022 05:00:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=111
05/21/2022 05:00:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.94 on epoch=112
05/21/2022 05:00:48 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.90 on epoch=112
05/21/2022 05:00:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.82 on epoch=113
05/21/2022 05:00:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.86 on epoch=114
05/21/2022 05:00:54 - INFO - __main__ - Global step 1600 Train loss 0.88 Classification-F1 0.42450281516158767 on epoch=114
05/21/2022 05:00:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.88 on epoch=114
05/21/2022 05:00:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.88 on epoch=115
05/21/2022 05:00:58 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.88 on epoch=116
05/21/2022 05:00:59 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.82 on epoch=117
05/21/2022 05:01:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.81 on epoch=117
05/21/2022 05:01:04 - INFO - __main__ - Global step 1650 Train loss 0.86 Classification-F1 0.4514951089616117 on epoch=117
05/21/2022 05:01:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.81 on epoch=118
05/21/2022 05:01:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.84 on epoch=119
05/21/2022 05:01:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/21/2022 05:01:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.79 on epoch=120
05/21/2022 05:01:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.88 on epoch=121
05/21/2022 05:01:14 - INFO - __main__ - Global step 1700 Train loss 0.82 Classification-F1 0.4319419459764785 on epoch=121
05/21/2022 05:01:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.89 on epoch=122
05/21/2022 05:01:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.75 on epoch=122
05/21/2022 05:01:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.77 on epoch=123
05/21/2022 05:01:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.84 on epoch=124
05/21/2022 05:01:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.84 on epoch=124
05/21/2022 05:01:24 - INFO - __main__ - Global step 1750 Train loss 0.82 Classification-F1 0.44668164012539724 on epoch=124
05/21/2022 05:01:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.88 on epoch=125
05/21/2022 05:01:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.76 on epoch=126
05/21/2022 05:01:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.83 on epoch=127
05/21/2022 05:01:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.80 on epoch=127
05/21/2022 05:01:31 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.80 on epoch=128
05/21/2022 05:01:34 - INFO - __main__ - Global step 1800 Train loss 0.81 Classification-F1 0.4773163201989948 on epoch=128
05/21/2022 05:01:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.73 on epoch=129
05/21/2022 05:01:37 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.77 on epoch=129
05/21/2022 05:01:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.80 on epoch=130
05/21/2022 05:01:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.73 on epoch=131
05/21/2022 05:01:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.70 on epoch=132
05/21/2022 05:01:44 - INFO - __main__ - Global step 1850 Train loss 0.75 Classification-F1 0.4906395921602844 on epoch=132
05/21/2022 05:01:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.75 on epoch=132
05/21/2022 05:01:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.72 on epoch=133
05/21/2022 05:01:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.82 on epoch=134
05/21/2022 05:01:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.73 on epoch=134
05/21/2022 05:01:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.82 on epoch=135
05/21/2022 05:01:54 - INFO - __main__ - Global step 1900 Train loss 0.77 Classification-F1 0.470824544450079 on epoch=135
05/21/2022 05:01:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.76 on epoch=136
05/21/2022 05:01:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.88 on epoch=137
05/21/2022 05:01:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/21/2022 05:01:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/21/2022 05:02:00 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.78 on epoch=139
05/21/2022 05:02:04 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.46654291136274834 on epoch=139
05/21/2022 05:02:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.72 on epoch=139
05/21/2022 05:02:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.82 on epoch=140
05/21/2022 05:02:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.78 on epoch=141
05/21/2022 05:02:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.84 on epoch=142
05/21/2022 05:02:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.74 on epoch=142
05/21/2022 05:02:14 - INFO - __main__ - Global step 2000 Train loss 0.78 Classification-F1 0.5063532676543112 on epoch=142
05/21/2022 05:02:14 - INFO - __main__ - Saving model with best Classification-F1: 0.49318817290229383 -> 0.5063532676543112 on epoch=142, global_step=2000
05/21/2022 05:02:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.68 on epoch=143
05/21/2022 05:02:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.86 on epoch=144
05/21/2022 05:02:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.69 on epoch=144
05/21/2022 05:02:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.74 on epoch=145
05/21/2022 05:02:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.79 on epoch=146
05/21/2022 05:02:23 - INFO - __main__ - Global step 2050 Train loss 0.75 Classification-F1 0.5245277129700868 on epoch=146
05/21/2022 05:02:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5063532676543112 -> 0.5245277129700868 on epoch=146, global_step=2050
05/21/2022 05:02:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.82 on epoch=147
05/21/2022 05:02:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.78 on epoch=147
05/21/2022 05:02:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.77 on epoch=148
05/21/2022 05:02:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.80 on epoch=149
05/21/2022 05:02:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.75 on epoch=149
05/21/2022 05:02:33 - INFO - __main__ - Global step 2100 Train loss 0.78 Classification-F1 0.5664838387116167 on epoch=149
05/21/2022 05:02:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5245277129700868 -> 0.5664838387116167 on epoch=149, global_step=2100
05/21/2022 05:02:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.70 on epoch=150
05/21/2022 05:02:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.74 on epoch=151
05/21/2022 05:02:37 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.80 on epoch=152
05/21/2022 05:02:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.77 on epoch=152
05/21/2022 05:02:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.71 on epoch=153
05/21/2022 05:02:43 - INFO - __main__ - Global step 2150 Train loss 0.74 Classification-F1 0.5412912509851706 on epoch=153
05/21/2022 05:02:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.78 on epoch=154
05/21/2022 05:02:46 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.76 on epoch=154
05/21/2022 05:02:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.74 on epoch=155
05/21/2022 05:02:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.69 on epoch=156
05/21/2022 05:02:49 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.80 on epoch=157
05/21/2022 05:02:53 - INFO - __main__ - Global step 2200 Train loss 0.76 Classification-F1 0.5114314623599602 on epoch=157
05/21/2022 05:02:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.80 on epoch=157
05/21/2022 05:02:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.64 on epoch=158
05/21/2022 05:02:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.77 on epoch=159
05/21/2022 05:02:58 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.73 on epoch=159
05/21/2022 05:03:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.64 on epoch=160
05/21/2022 05:03:03 - INFO - __main__ - Global step 2250 Train loss 0.72 Classification-F1 0.4745899658204248 on epoch=160
05/21/2022 05:03:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.68 on epoch=161
05/21/2022 05:03:06 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.82 on epoch=162
05/21/2022 05:03:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.67 on epoch=162
05/21/2022 05:03:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.60 on epoch=163
05/21/2022 05:03:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.70 on epoch=164
05/21/2022 05:03:13 - INFO - __main__ - Global step 2300 Train loss 0.69 Classification-F1 0.5205749157488563 on epoch=164
05/21/2022 05:03:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.69 on epoch=164
05/21/2022 05:03:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.72 on epoch=165
05/21/2022 05:03:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.65 on epoch=166
05/21/2022 05:03:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.64 on epoch=167
05/21/2022 05:03:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.63 on epoch=167
05/21/2022 05:03:23 - INFO - __main__ - Global step 2350 Train loss 0.66 Classification-F1 0.5071473033764607 on epoch=167
05/21/2022 05:03:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.61 on epoch=168
05/21/2022 05:03:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/21/2022 05:03:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.70 on epoch=169
05/21/2022 05:03:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.76 on epoch=170
05/21/2022 05:03:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.70 on epoch=171
05/21/2022 05:03:33 - INFO - __main__ - Global step 2400 Train loss 0.69 Classification-F1 0.4987281237999801 on epoch=171
05/21/2022 05:03:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.75 on epoch=172
05/21/2022 05:03:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.66 on epoch=172
05/21/2022 05:03:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.66 on epoch=173
05/21/2022 05:03:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.71 on epoch=174
05/21/2022 05:03:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.72 on epoch=174
05/21/2022 05:03:43 - INFO - __main__ - Global step 2450 Train loss 0.70 Classification-F1 0.5445179902841671 on epoch=174
05/21/2022 05:03:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.81 on epoch=175
05/21/2022 05:03:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.66 on epoch=176
05/21/2022 05:03:47 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.73 on epoch=177
05/21/2022 05:03:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.77 on epoch=177
05/21/2022 05:03:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.71 on epoch=178
05/21/2022 05:03:53 - INFO - __main__ - Global step 2500 Train loss 0.74 Classification-F1 0.487774540587213 on epoch=178
05/21/2022 05:03:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.64 on epoch=179
05/21/2022 05:03:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.76 on epoch=179
05/21/2022 05:03:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.69 on epoch=180
05/21/2022 05:03:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.69 on epoch=181
05/21/2022 05:03:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.64 on epoch=182
05/21/2022 05:04:03 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.5939992895987185 on epoch=182
05/21/2022 05:04:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5664838387116167 -> 0.5939992895987185 on epoch=182, global_step=2550
05/21/2022 05:04:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/21/2022 05:04:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.61 on epoch=183
05/21/2022 05:04:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/21/2022 05:04:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/21/2022 05:04:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.67 on epoch=185
05/21/2022 05:04:13 - INFO - __main__ - Global step 2600 Train loss 0.65 Classification-F1 0.524013833261686 on epoch=185
05/21/2022 05:04:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.71 on epoch=186
05/21/2022 05:04:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/21/2022 05:04:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.64 on epoch=187
05/21/2022 05:04:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.64 on epoch=188
05/21/2022 05:04:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.75 on epoch=189
05/21/2022 05:04:23 - INFO - __main__ - Global step 2650 Train loss 0.68 Classification-F1 0.47390262610063505 on epoch=189
05/21/2022 05:04:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.66 on epoch=189
05/21/2022 05:04:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.68 on epoch=190
05/21/2022 05:04:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.70 on epoch=191
05/21/2022 05:04:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.66 on epoch=192
05/21/2022 05:04:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.70 on epoch=192
05/21/2022 05:04:34 - INFO - __main__ - Global step 2700 Train loss 0.68 Classification-F1 0.46085450738617956 on epoch=192
05/21/2022 05:04:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.63 on epoch=193
05/21/2022 05:04:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.64 on epoch=194
05/21/2022 05:04:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/21/2022 05:04:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.68 on epoch=195
05/21/2022 05:04:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.63 on epoch=196
05/21/2022 05:04:45 - INFO - __main__ - Global step 2750 Train loss 0.66 Classification-F1 0.5085851663971163 on epoch=196
05/21/2022 05:04:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.73 on epoch=197
05/21/2022 05:04:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.70 on epoch=197
05/21/2022 05:04:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.67 on epoch=198
05/21/2022 05:04:50 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.75 on epoch=199
05/21/2022 05:04:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.69 on epoch=199
05/21/2022 05:04:55 - INFO - __main__ - Global step 2800 Train loss 0.71 Classification-F1 0.5663433183771196 on epoch=199
05/21/2022 05:04:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.61 on epoch=200
05/21/2022 05:04:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.72 on epoch=201
05/21/2022 05:04:59 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.73 on epoch=202
05/21/2022 05:05:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/21/2022 05:05:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.59 on epoch=203
05/21/2022 05:05:05 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.4675305015124251 on epoch=203
05/21/2022 05:05:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.69 on epoch=204
05/21/2022 05:05:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.65 on epoch=204
05/21/2022 05:05:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.58 on epoch=205
05/21/2022 05:05:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/21/2022 05:05:11 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.72 on epoch=207
05/21/2022 05:05:15 - INFO - __main__ - Global step 2900 Train loss 0.65 Classification-F1 0.6283857038623236 on epoch=207
05/21/2022 05:05:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5939992895987185 -> 0.6283857038623236 on epoch=207, global_step=2900
05/21/2022 05:05:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.71 on epoch=207
05/21/2022 05:05:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.61 on epoch=208
05/21/2022 05:05:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.67 on epoch=209
05/21/2022 05:05:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.74 on epoch=209
05/21/2022 05:05:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.70 on epoch=210
05/21/2022 05:05:25 - INFO - __main__ - Global step 2950 Train loss 0.69 Classification-F1 0.5959853034172045 on epoch=210
05/21/2022 05:05:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.59 on epoch=211
05/21/2022 05:05:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.70 on epoch=212
05/21/2022 05:05:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.69 on epoch=212
05/21/2022 05:05:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.62 on epoch=213
05/21/2022 05:05:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.53 on epoch=214
05/21/2022 05:05:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:05:33 - INFO - __main__ - Printing 3 examples
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:05:33 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:05:33 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:05:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:05:33 - INFO - __main__ - Printing 3 examples
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 05:05:33 - INFO - __main__ - ['Animal']
05/21/2022 05:05:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:05:34 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:05:34 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:05:36 - INFO - __main__ - Global step 3000 Train loss 0.63 Classification-F1 0.5543464184768533 on epoch=214
05/21/2022 05:05:36 - INFO - __main__ - save last model!
05/21/2022 05:05:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:05:36 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:05:36 - INFO - __main__ - Printing 3 examples
05/21/2022 05:05:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:05:36 - INFO - __main__ - ['Animal']
05/21/2022 05:05:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:05:36 - INFO - __main__ - ['Animal']
05/21/2022 05:05:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:05:36 - INFO - __main__ - ['Village']
05/21/2022 05:05:36 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:05:38 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:05:39 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:05:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:05:40 - INFO - __main__ - Starting training!
05/21/2022 05:05:41 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 05:06:49 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
05/21/2022 05:06:49 - INFO - __main__ - Classification-F1 on test data: 0.2268
05/21/2022 05:06:50 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.6283857038623236, test_performance=0.22678688553921758
05/21/2022 05:06:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
05/21/2022 05:06:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:06:51 - INFO - __main__ - Printing 3 examples
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 6080 mm.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:06:51 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:06:51 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:06:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:06:51 - INFO - __main__ - Printing 3 examples
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
05/21/2022 05:06:51 - INFO - __main__ - ['Animal']
05/21/2022 05:06:51 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:06:51 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:06:51 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:06:57 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:06:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:06:57 - INFO - __main__ - Starting training!
05/21/2022 05:06:58 - INFO - __main__ - Step 10 Global step 10 Train loss 7.23 on epoch=0
05/21/2022 05:07:00 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/21/2022 05:07:01 - INFO - __main__ - Step 30 Global step 30 Train loss 6.75 on epoch=2
05/21/2022 05:07:02 - INFO - __main__ - Step 40 Global step 40 Train loss 6.38 on epoch=2
05/21/2022 05:07:03 - INFO - __main__ - Step 50 Global step 50 Train loss 6.28 on epoch=3
05/21/2022 05:07:07 - INFO - __main__ - Global step 50 Train loss 6.75 Classification-F1 0.0 on epoch=3
05/21/2022 05:07:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 05:07:08 - INFO - __main__ - Step 60 Global step 60 Train loss 5.84 on epoch=4
05/21/2022 05:07:09 - INFO - __main__ - Step 70 Global step 70 Train loss 5.82 on epoch=4
05/21/2022 05:07:10 - INFO - __main__ - Step 80 Global step 80 Train loss 5.51 on epoch=5
05/21/2022 05:07:12 - INFO - __main__ - Step 90 Global step 90 Train loss 5.35 on epoch=6
05/21/2022 05:07:13 - INFO - __main__ - Step 100 Global step 100 Train loss 5.13 on epoch=7
05/21/2022 05:07:16 - INFO - __main__ - Global step 100 Train loss 5.53 Classification-F1 0.0 on epoch=7
05/21/2022 05:07:17 - INFO - __main__ - Step 110 Global step 110 Train loss 4.96 on epoch=7
05/21/2022 05:07:18 - INFO - __main__ - Step 120 Global step 120 Train loss 4.82 on epoch=8
05/21/2022 05:07:20 - INFO - __main__ - Step 130 Global step 130 Train loss 5.01 on epoch=9
05/21/2022 05:07:21 - INFO - __main__ - Step 140 Global step 140 Train loss 4.65 on epoch=9
05/21/2022 05:07:22 - INFO - __main__ - Step 150 Global step 150 Train loss 4.41 on epoch=10
05/21/2022 05:07:25 - INFO - __main__ - Global step 150 Train loss 4.77 Classification-F1 0.0 on epoch=10
05/21/2022 05:07:27 - INFO - __main__ - Step 160 Global step 160 Train loss 4.29 on epoch=11
05/21/2022 05:07:28 - INFO - __main__ - Step 170 Global step 170 Train loss 4.24 on epoch=12
05/21/2022 05:07:29 - INFO - __main__ - Step 180 Global step 180 Train loss 4.11 on epoch=12
05/21/2022 05:07:30 - INFO - __main__ - Step 190 Global step 190 Train loss 4.05 on epoch=13
05/21/2022 05:07:31 - INFO - __main__ - Step 200 Global step 200 Train loss 3.96 on epoch=14
05/21/2022 05:07:35 - INFO - __main__ - Global step 200 Train loss 4.13 Classification-F1 0.0 on epoch=14
05/21/2022 05:07:36 - INFO - __main__ - Step 210 Global step 210 Train loss 3.97 on epoch=14
05/21/2022 05:07:38 - INFO - __main__ - Step 220 Global step 220 Train loss 3.66 on epoch=15
05/21/2022 05:07:39 - INFO - __main__ - Step 230 Global step 230 Train loss 3.77 on epoch=16
05/21/2022 05:07:40 - INFO - __main__ - Step 240 Global step 240 Train loss 3.59 on epoch=17
05/21/2022 05:07:41 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/21/2022 05:07:45 - INFO - __main__ - Global step 250 Train loss 3.69 Classification-F1 0.0 on epoch=17
05/21/2022 05:07:46 - INFO - __main__ - Step 260 Global step 260 Train loss 3.44 on epoch=18
05/21/2022 05:07:47 - INFO - __main__ - Step 270 Global step 270 Train loss 3.55 on epoch=19
05/21/2022 05:07:48 - INFO - __main__ - Step 280 Global step 280 Train loss 3.35 on epoch=19
05/21/2022 05:07:50 - INFO - __main__ - Step 290 Global step 290 Train loss 3.11 on epoch=20
05/21/2022 05:07:51 - INFO - __main__ - Step 300 Global step 300 Train loss 3.19 on epoch=21
05/21/2022 05:07:54 - INFO - __main__ - Global step 300 Train loss 3.33 Classification-F1 0.0025510204081632655 on epoch=21
05/21/2022 05:07:54 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0025510204081632655 on epoch=21, global_step=300
05/21/2022 05:07:55 - INFO - __main__ - Step 310 Global step 310 Train loss 3.14 on epoch=22
05/21/2022 05:07:56 - INFO - __main__ - Step 320 Global step 320 Train loss 3.12 on epoch=22
05/21/2022 05:07:58 - INFO - __main__ - Step 330 Global step 330 Train loss 3.06 on epoch=23
05/21/2022 05:07:59 - INFO - __main__ - Step 340 Global step 340 Train loss 2.96 on epoch=24
05/21/2022 05:08:00 - INFO - __main__ - Step 350 Global step 350 Train loss 2.86 on epoch=24
05/21/2022 05:08:03 - INFO - __main__ - Global step 350 Train loss 3.03 Classification-F1 0.00670391061452514 on epoch=24
05/21/2022 05:08:03 - INFO - __main__ - Saving model with best Classification-F1: 0.0025510204081632655 -> 0.00670391061452514 on epoch=24, global_step=350
05/21/2022 05:08:04 - INFO - __main__ - Step 360 Global step 360 Train loss 2.88 on epoch=25
05/21/2022 05:08:05 - INFO - __main__ - Step 370 Global step 370 Train loss 2.78 on epoch=26
05/21/2022 05:08:07 - INFO - __main__ - Step 380 Global step 380 Train loss 2.71 on epoch=27
05/21/2022 05:08:08 - INFO - __main__ - Step 390 Global step 390 Train loss 2.62 on epoch=27
05/21/2022 05:08:09 - INFO - __main__ - Step 400 Global step 400 Train loss 2.58 on epoch=28
05/21/2022 05:08:12 - INFO - __main__ - Global step 400 Train loss 2.71 Classification-F1 0.00880503144654088 on epoch=28
05/21/2022 05:08:12 - INFO - __main__ - Saving model with best Classification-F1: 0.00670391061452514 -> 0.00880503144654088 on epoch=28, global_step=400
05/21/2022 05:08:13 - INFO - __main__ - Step 410 Global step 410 Train loss 2.62 on epoch=29
05/21/2022 05:08:14 - INFO - __main__ - Step 420 Global step 420 Train loss 2.60 on epoch=29
05/21/2022 05:08:15 - INFO - __main__ - Step 430 Global step 430 Train loss 2.47 on epoch=30
05/21/2022 05:08:17 - INFO - __main__ - Step 440 Global step 440 Train loss 2.43 on epoch=31
05/21/2022 05:08:18 - INFO - __main__ - Step 450 Global step 450 Train loss 2.40 on epoch=32
05/21/2022 05:08:20 - INFO - __main__ - Global step 450 Train loss 2.50 Classification-F1 0.009523809523809523 on epoch=32
05/21/2022 05:08:20 - INFO - __main__ - Saving model with best Classification-F1: 0.00880503144654088 -> 0.009523809523809523 on epoch=32, global_step=450
05/21/2022 05:08:21 - INFO - __main__ - Step 460 Global step 460 Train loss 2.37 on epoch=32
05/21/2022 05:08:23 - INFO - __main__ - Step 470 Global step 470 Train loss 2.34 on epoch=33
05/21/2022 05:08:24 - INFO - __main__ - Step 480 Global step 480 Train loss 2.39 on epoch=34
05/21/2022 05:08:25 - INFO - __main__ - Step 490 Global step 490 Train loss 2.30 on epoch=34
05/21/2022 05:08:27 - INFO - __main__ - Step 500 Global step 500 Train loss 2.05 on epoch=35
05/21/2022 05:08:28 - INFO - __main__ - Global step 500 Train loss 2.29 Classification-F1 0.009523809523809523 on epoch=35
05/21/2022 05:08:30 - INFO - __main__ - Step 510 Global step 510 Train loss 2.24 on epoch=36
05/21/2022 05:08:31 - INFO - __main__ - Step 520 Global step 520 Train loss 2.31 on epoch=37
05/21/2022 05:08:32 - INFO - __main__ - Step 530 Global step 530 Train loss 2.10 on epoch=37
05/21/2022 05:08:34 - INFO - __main__ - Step 540 Global step 540 Train loss 2.15 on epoch=38
05/21/2022 05:08:35 - INFO - __main__ - Step 550 Global step 550 Train loss 2.16 on epoch=39
05/21/2022 05:08:37 - INFO - __main__ - Global step 550 Train loss 2.19 Classification-F1 0.009644364074743823 on epoch=39
05/21/2022 05:08:37 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009644364074743823 on epoch=39, global_step=550
05/21/2022 05:08:39 - INFO - __main__ - Step 560 Global step 560 Train loss 2.13 on epoch=39
05/21/2022 05:08:40 - INFO - __main__ - Step 570 Global step 570 Train loss 2.09 on epoch=40
05/21/2022 05:08:41 - INFO - __main__ - Step 580 Global step 580 Train loss 2.15 on epoch=41
05/21/2022 05:08:43 - INFO - __main__ - Step 590 Global step 590 Train loss 1.96 on epoch=42
05/21/2022 05:08:44 - INFO - __main__ - Step 600 Global step 600 Train loss 2.03 on epoch=42
05/21/2022 05:08:46 - INFO - __main__ - Global step 600 Train loss 2.07 Classification-F1 0.009894867037724181 on epoch=42
05/21/2022 05:08:46 - INFO - __main__ - Saving model with best Classification-F1: 0.009644364074743823 -> 0.009894867037724181 on epoch=42, global_step=600
05/21/2022 05:08:47 - INFO - __main__ - Step 610 Global step 610 Train loss 1.96 on epoch=43
05/21/2022 05:08:49 - INFO - __main__ - Step 620 Global step 620 Train loss 1.93 on epoch=44
05/21/2022 05:08:50 - INFO - __main__ - Step 630 Global step 630 Train loss 1.94 on epoch=44
05/21/2022 05:08:51 - INFO - __main__ - Step 640 Global step 640 Train loss 1.73 on epoch=45
05/21/2022 05:08:52 - INFO - __main__ - Step 650 Global step 650 Train loss 1.93 on epoch=46
05/21/2022 05:08:55 - INFO - __main__ - Global step 650 Train loss 1.90 Classification-F1 0.02328801902806262 on epoch=46
05/21/2022 05:08:55 - INFO - __main__ - Saving model with best Classification-F1: 0.009894867037724181 -> 0.02328801902806262 on epoch=46, global_step=650
05/21/2022 05:08:56 - INFO - __main__ - Step 660 Global step 660 Train loss 1.85 on epoch=47
05/21/2022 05:08:57 - INFO - __main__ - Step 670 Global step 670 Train loss 1.86 on epoch=47
05/21/2022 05:08:59 - INFO - __main__ - Step 680 Global step 680 Train loss 1.76 on epoch=48
05/21/2022 05:09:00 - INFO - __main__ - Step 690 Global step 690 Train loss 1.90 on epoch=49
05/21/2022 05:09:01 - INFO - __main__ - Step 700 Global step 700 Train loss 1.77 on epoch=49
05/21/2022 05:09:04 - INFO - __main__ - Global step 700 Train loss 1.83 Classification-F1 0.03189765172035549 on epoch=49
05/21/2022 05:09:04 - INFO - __main__ - Saving model with best Classification-F1: 0.02328801902806262 -> 0.03189765172035549 on epoch=49, global_step=700
05/21/2022 05:09:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.79 on epoch=50
05/21/2022 05:09:07 - INFO - __main__ - Step 720 Global step 720 Train loss 1.74 on epoch=51
05/21/2022 05:09:08 - INFO - __main__ - Step 730 Global step 730 Train loss 1.76 on epoch=52
05/21/2022 05:09:09 - INFO - __main__ - Step 740 Global step 740 Train loss 1.72 on epoch=52
05/21/2022 05:09:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.68 on epoch=53
05/21/2022 05:09:13 - INFO - __main__ - Global step 750 Train loss 1.74 Classification-F1 0.03432355190596949 on epoch=53
05/21/2022 05:09:13 - INFO - __main__ - Saving model with best Classification-F1: 0.03189765172035549 -> 0.03432355190596949 on epoch=53, global_step=750
05/21/2022 05:09:14 - INFO - __main__ - Step 760 Global step 760 Train loss 1.70 on epoch=54
05/21/2022 05:09:16 - INFO - __main__ - Step 770 Global step 770 Train loss 1.84 on epoch=54
05/21/2022 05:09:17 - INFO - __main__ - Step 780 Global step 780 Train loss 1.54 on epoch=55
05/21/2022 05:09:18 - INFO - __main__ - Step 790 Global step 790 Train loss 1.62 on epoch=56
05/21/2022 05:09:20 - INFO - __main__ - Step 800 Global step 800 Train loss 1.62 on epoch=57
05/21/2022 05:09:22 - INFO - __main__ - Global step 800 Train loss 1.67 Classification-F1 0.04788472365468425 on epoch=57
05/21/2022 05:09:22 - INFO - __main__ - Saving model with best Classification-F1: 0.03432355190596949 -> 0.04788472365468425 on epoch=57, global_step=800
05/21/2022 05:09:23 - INFO - __main__ - Step 810 Global step 810 Train loss 1.66 on epoch=57
05/21/2022 05:09:25 - INFO - __main__ - Step 820 Global step 820 Train loss 1.55 on epoch=58
05/21/2022 05:09:26 - INFO - __main__ - Step 830 Global step 830 Train loss 1.60 on epoch=59
05/21/2022 05:09:27 - INFO - __main__ - Step 840 Global step 840 Train loss 1.55 on epoch=59
05/21/2022 05:09:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.58 on epoch=60
05/21/2022 05:09:31 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.06756831318640903 on epoch=60
05/21/2022 05:09:31 - INFO - __main__ - Saving model with best Classification-F1: 0.04788472365468425 -> 0.06756831318640903 on epoch=60, global_step=850
05/21/2022 05:09:33 - INFO - __main__ - Step 860 Global step 860 Train loss 1.47 on epoch=61
05/21/2022 05:09:34 - INFO - __main__ - Step 870 Global step 870 Train loss 1.58 on epoch=62
05/21/2022 05:09:35 - INFO - __main__ - Step 880 Global step 880 Train loss 1.55 on epoch=62
05/21/2022 05:09:37 - INFO - __main__ - Step 890 Global step 890 Train loss 1.44 on epoch=63
05/21/2022 05:09:38 - INFO - __main__ - Step 900 Global step 900 Train loss 1.58 on epoch=64
05/21/2022 05:09:41 - INFO - __main__ - Global step 900 Train loss 1.53 Classification-F1 0.03124522180783524 on epoch=64
05/21/2022 05:09:42 - INFO - __main__ - Step 910 Global step 910 Train loss 1.57 on epoch=64
05/21/2022 05:09:43 - INFO - __main__ - Step 920 Global step 920 Train loss 1.44 on epoch=65
05/21/2022 05:09:45 - INFO - __main__ - Step 930 Global step 930 Train loss 1.48 on epoch=66
05/21/2022 05:09:46 - INFO - __main__ - Step 940 Global step 940 Train loss 1.44 on epoch=67
05/21/2022 05:09:47 - INFO - __main__ - Step 950 Global step 950 Train loss 1.48 on epoch=67
05/21/2022 05:09:50 - INFO - __main__ - Global step 950 Train loss 1.48 Classification-F1 0.04890332582087136 on epoch=67
05/21/2022 05:09:51 - INFO - __main__ - Step 960 Global step 960 Train loss 1.46 on epoch=68
05/21/2022 05:09:53 - INFO - __main__ - Step 970 Global step 970 Train loss 1.47 on epoch=69
05/21/2022 05:09:54 - INFO - __main__ - Step 980 Global step 980 Train loss 1.44 on epoch=69
05/21/2022 05:09:55 - INFO - __main__ - Step 990 Global step 990 Train loss 1.36 on epoch=70
05/21/2022 05:09:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.40 on epoch=71
05/21/2022 05:09:59 - INFO - __main__ - Global step 1000 Train loss 1.43 Classification-F1 0.05979590826958037 on epoch=71
05/21/2022 05:10:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.39 on epoch=72
05/21/2022 05:10:02 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.48 on epoch=72
05/21/2022 05:10:03 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.41 on epoch=73
05/21/2022 05:10:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.41 on epoch=74
05/21/2022 05:10:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.39 on epoch=74
05/21/2022 05:10:09 - INFO - __main__ - Global step 1050 Train loss 1.42 Classification-F1 0.047322775263951726 on epoch=74
05/21/2022 05:10:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.31 on epoch=75
05/21/2022 05:10:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.31 on epoch=76
05/21/2022 05:10:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.31 on epoch=77
05/21/2022 05:10:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.37 on epoch=77
05/21/2022 05:10:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.32 on epoch=78
05/21/2022 05:10:18 - INFO - __main__ - Global step 1100 Train loss 1.32 Classification-F1 0.0571118186658662 on epoch=78
05/21/2022 05:10:19 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.39 on epoch=79
05/21/2022 05:10:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.34 on epoch=79
05/21/2022 05:10:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=80
05/21/2022 05:10:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.33 on epoch=81
05/21/2022 05:10:24 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.29 on epoch=82
05/21/2022 05:10:27 - INFO - __main__ - Global step 1150 Train loss 1.32 Classification-F1 0.06400942195059842 on epoch=82
05/21/2022 05:10:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.29 on epoch=82
05/21/2022 05:10:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.30 on epoch=83
05/21/2022 05:10:31 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.33 on epoch=84
05/21/2022 05:10:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.39 on epoch=84
05/21/2022 05:10:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.29 on epoch=85
05/21/2022 05:10:37 - INFO - __main__ - Global step 1200 Train loss 1.32 Classification-F1 0.07487880319591952 on epoch=85
05/21/2022 05:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06756831318640903 -> 0.07487880319591952 on epoch=85, global_step=1200
05/21/2022 05:10:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.37 on epoch=86
05/21/2022 05:10:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.29 on epoch=87
05/21/2022 05:10:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.29 on epoch=87
05/21/2022 05:10:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.29 on epoch=88
05/21/2022 05:10:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.37 on epoch=89
05/21/2022 05:10:47 - INFO - __main__ - Global step 1250 Train loss 1.32 Classification-F1 0.13571681729576465 on epoch=89
05/21/2022 05:10:47 - INFO - __main__ - Saving model with best Classification-F1: 0.07487880319591952 -> 0.13571681729576465 on epoch=89, global_step=1250
05/21/2022 05:10:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.29 on epoch=89
05/21/2022 05:10:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.19 on epoch=90
05/21/2022 05:10:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.35 on epoch=91
05/21/2022 05:10:52 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.23 on epoch=92
05/21/2022 05:10:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.34 on epoch=92
05/21/2022 05:10:56 - INFO - __main__ - Global step 1300 Train loss 1.28 Classification-F1 0.15165816984761937 on epoch=92
05/21/2022 05:10:56 - INFO - __main__ - Saving model with best Classification-F1: 0.13571681729576465 -> 0.15165816984761937 on epoch=92, global_step=1300
05/21/2022 05:10:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.11 on epoch=93
05/21/2022 05:10:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=94
05/21/2022 05:11:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.24 on epoch=94
05/21/2022 05:11:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=95
05/21/2022 05:11:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=96
05/21/2022 05:11:06 - INFO - __main__ - Global step 1350 Train loss 1.23 Classification-F1 0.1574902292881518 on epoch=96
05/21/2022 05:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.15165816984761937 -> 0.1574902292881518 on epoch=96, global_step=1350
05/21/2022 05:11:07 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.23 on epoch=97
05/21/2022 05:11:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.20 on epoch=97
05/21/2022 05:11:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.25 on epoch=98
05/21/2022 05:11:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.20 on epoch=99
05/21/2022 05:11:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.18 on epoch=99
05/21/2022 05:11:15 - INFO - __main__ - Global step 1400 Train loss 1.21 Classification-F1 0.16232871877118576 on epoch=99
05/21/2022 05:11:15 - INFO - __main__ - Saving model with best Classification-F1: 0.1574902292881518 -> 0.16232871877118576 on epoch=99, global_step=1400
05/21/2022 05:11:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.14 on epoch=100
05/21/2022 05:11:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.22 on epoch=101
05/21/2022 05:11:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=102
05/21/2022 05:11:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.26 on epoch=102
05/21/2022 05:11:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.19 on epoch=103
05/21/2022 05:11:25 - INFO - __main__ - Global step 1450 Train loss 1.19 Classification-F1 0.2142795195751142 on epoch=103
05/21/2022 05:11:25 - INFO - __main__ - Saving model with best Classification-F1: 0.16232871877118576 -> 0.2142795195751142 on epoch=103, global_step=1450
05/21/2022 05:11:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.15 on epoch=104
05/21/2022 05:11:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.25 on epoch=104
05/21/2022 05:11:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.14 on epoch=105
05/21/2022 05:11:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.12 on epoch=106
05/21/2022 05:11:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.11 on epoch=107
05/21/2022 05:11:34 - INFO - __main__ - Global step 1500 Train loss 1.15 Classification-F1 0.31443214423755345 on epoch=107
05/21/2022 05:11:34 - INFO - __main__ - Saving model with best Classification-F1: 0.2142795195751142 -> 0.31443214423755345 on epoch=107, global_step=1500
05/21/2022 05:11:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.29 on epoch=107
05/21/2022 05:11:37 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.15 on epoch=108
05/21/2022 05:11:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.13 on epoch=109
05/21/2022 05:11:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.19 on epoch=109
05/21/2022 05:11:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.12 on epoch=110
05/21/2022 05:11:44 - INFO - __main__ - Global step 1550 Train loss 1.18 Classification-F1 0.34313132927220524 on epoch=110
05/21/2022 05:11:44 - INFO - __main__ - Saving model with best Classification-F1: 0.31443214423755345 -> 0.34313132927220524 on epoch=110, global_step=1550
05/21/2022 05:11:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.19 on epoch=111
05/21/2022 05:11:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.18 on epoch=112
05/21/2022 05:11:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.13 on epoch=112
05/21/2022 05:11:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.12 on epoch=113
05/21/2022 05:11:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.14 on epoch=114
05/21/2022 05:11:53 - INFO - __main__ - Global step 1600 Train loss 1.15 Classification-F1 0.30428786275882225 on epoch=114
05/21/2022 05:11:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.12 on epoch=114
05/21/2022 05:11:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.05 on epoch=115
05/21/2022 05:11:57 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.15 on epoch=116
05/21/2022 05:11:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.02 on epoch=117
05/21/2022 05:12:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.05 on epoch=117
05/21/2022 05:12:03 - INFO - __main__ - Global step 1650 Train loss 1.08 Classification-F1 0.32333790488294817 on epoch=117
05/21/2022 05:12:04 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.06 on epoch=118
05/21/2022 05:12:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=119
05/21/2022 05:12:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.11 on epoch=119
05/21/2022 05:12:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.07 on epoch=120
05/21/2022 05:12:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.07 on epoch=121
05/21/2022 05:12:13 - INFO - __main__ - Global step 1700 Train loss 1.08 Classification-F1 0.32756463176333633 on epoch=121
05/21/2022 05:12:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.03 on epoch=122
05/21/2022 05:12:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.04 on epoch=122
05/21/2022 05:12:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.08 on epoch=123
05/21/2022 05:12:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.12 on epoch=124
05/21/2022 05:12:19 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.07 on epoch=124
05/21/2022 05:12:22 - INFO - __main__ - Global step 1750 Train loss 1.07 Classification-F1 0.3664782154837658 on epoch=124
05/21/2022 05:12:22 - INFO - __main__ - Saving model with best Classification-F1: 0.34313132927220524 -> 0.3664782154837658 on epoch=124, global_step=1750
05/21/2022 05:12:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.97 on epoch=125
05/21/2022 05:12:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.08 on epoch=126
05/21/2022 05:12:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=127
05/21/2022 05:12:28 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=127
05/21/2022 05:12:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.09 on epoch=128
05/21/2022 05:12:32 - INFO - __main__ - Global step 1800 Train loss 1.07 Classification-F1 0.35711236990576317 on epoch=128
05/21/2022 05:12:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.08 on epoch=129
05/21/2022 05:12:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.04 on epoch=129
05/21/2022 05:12:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.04 on epoch=130
05/21/2022 05:12:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.05 on epoch=131
05/21/2022 05:12:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.12 on epoch=132
05/21/2022 05:12:42 - INFO - __main__ - Global step 1850 Train loss 1.06 Classification-F1 0.407880574472203 on epoch=132
05/21/2022 05:12:42 - INFO - __main__ - Saving model with best Classification-F1: 0.3664782154837658 -> 0.407880574472203 on epoch=132, global_step=1850
05/21/2022 05:12:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.98 on epoch=132
05/21/2022 05:12:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.03 on epoch=133
05/21/2022 05:12:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.01 on epoch=134
05/21/2022 05:12:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.13 on epoch=134
05/21/2022 05:12:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.01 on epoch=135
05/21/2022 05:12:51 - INFO - __main__ - Global step 1900 Train loss 1.03 Classification-F1 0.42413357853871486 on epoch=135
05/21/2022 05:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.407880574472203 -> 0.42413357853871486 on epoch=135, global_step=1900
05/21/2022 05:12:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.04 on epoch=136
05/21/2022 05:12:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.01 on epoch=137
05/21/2022 05:12:55 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=137
05/21/2022 05:12:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.03 on epoch=138
05/21/2022 05:12:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.12 on epoch=139
05/21/2022 05:13:01 - INFO - __main__ - Global step 1950 Train loss 1.04 Classification-F1 0.40211789341680154 on epoch=139
05/21/2022 05:13:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.12 on epoch=139
05/21/2022 05:13:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.07 on epoch=140
05/21/2022 05:13:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.96 on epoch=141
05/21/2022 05:13:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.02 on epoch=142
05/21/2022 05:13:08 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.08 on epoch=142
05/21/2022 05:13:11 - INFO - __main__ - Global step 2000 Train loss 1.05 Classification-F1 0.4104689983672708 on epoch=142
05/21/2022 05:13:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.97 on epoch=143
05/21/2022 05:13:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.93 on epoch=144
05/21/2022 05:13:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.98 on epoch=144
05/21/2022 05:13:16 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.00 on epoch=145
05/21/2022 05:13:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.07 on epoch=146
05/21/2022 05:13:21 - INFO - __main__ - Global step 2050 Train loss 0.99 Classification-F1 0.4102114730209184 on epoch=146
05/21/2022 05:13:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.99 on epoch=147
05/21/2022 05:13:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.03 on epoch=147
05/21/2022 05:13:25 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=148
05/21/2022 05:13:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=149
05/21/2022 05:13:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.16 on epoch=149
05/21/2022 05:13:31 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.4193092844655344 on epoch=149
05/21/2022 05:13:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.88 on epoch=150
05/21/2022 05:13:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.01 on epoch=151
05/21/2022 05:13:34 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.86 on epoch=152
05/21/2022 05:13:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=152
05/21/2022 05:13:37 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.96 on epoch=153
05/21/2022 05:13:41 - INFO - __main__ - Global step 2150 Train loss 0.95 Classification-F1 0.4373458279758817 on epoch=153
05/21/2022 05:13:41 - INFO - __main__ - Saving model with best Classification-F1: 0.42413357853871486 -> 0.4373458279758817 on epoch=153, global_step=2150
05/21/2022 05:13:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.04 on epoch=154
05/21/2022 05:13:43 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.07 on epoch=154
05/21/2022 05:13:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.95 on epoch=155
05/21/2022 05:13:46 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.00 on epoch=156
05/21/2022 05:13:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.95 on epoch=157
05/21/2022 05:13:50 - INFO - __main__ - Global step 2200 Train loss 1.00 Classification-F1 0.46914545395802887 on epoch=157
05/21/2022 05:13:51 - INFO - __main__ - Saving model with best Classification-F1: 0.4373458279758817 -> 0.46914545395802887 on epoch=157, global_step=2200
05/21/2022 05:13:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.88 on epoch=157
05/21/2022 05:13:53 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.99 on epoch=158
05/21/2022 05:13:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.06 on epoch=159
05/21/2022 05:13:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.95 on epoch=159
05/21/2022 05:13:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.93 on epoch=160
05/21/2022 05:14:01 - INFO - __main__ - Global step 2250 Train loss 0.96 Classification-F1 0.36186512730373427 on epoch=160
05/21/2022 05:14:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.98 on epoch=161
05/21/2022 05:14:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=162
05/21/2022 05:14:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=162
05/21/2022 05:14:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.92 on epoch=163
05/21/2022 05:14:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.05 on epoch=164
05/21/2022 05:14:11 - INFO - __main__ - Global step 2300 Train loss 0.99 Classification-F1 0.492250036106172 on epoch=164
05/21/2022 05:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.46914545395802887 -> 0.492250036106172 on epoch=164, global_step=2300
05/21/2022 05:14:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.08 on epoch=164
05/21/2022 05:14:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.96 on epoch=165
05/21/2022 05:14:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.95 on epoch=166
05/21/2022 05:14:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=167
05/21/2022 05:14:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.95 on epoch=167
05/21/2022 05:14:21 - INFO - __main__ - Global step 2350 Train loss 0.99 Classification-F1 0.497193331044547 on epoch=167
05/21/2022 05:14:21 - INFO - __main__ - Saving model with best Classification-F1: 0.492250036106172 -> 0.497193331044547 on epoch=167, global_step=2350
05/21/2022 05:14:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.89 on epoch=168
05/21/2022 05:14:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.94 on epoch=169
05/21/2022 05:14:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.01 on epoch=169
05/21/2022 05:14:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.90 on epoch=170
05/21/2022 05:14:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.96 on epoch=171
05/21/2022 05:14:31 - INFO - __main__ - Global step 2400 Train loss 0.94 Classification-F1 0.47662941813856025 on epoch=171
05/21/2022 05:14:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.01 on epoch=172
05/21/2022 05:14:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.92 on epoch=172
05/21/2022 05:14:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.95 on epoch=173
05/21/2022 05:14:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.95 on epoch=174
05/21/2022 05:14:37 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.02 on epoch=174
05/21/2022 05:14:41 - INFO - __main__ - Global step 2450 Train loss 0.97 Classification-F1 0.4870166209403959 on epoch=174
05/21/2022 05:14:42 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.91 on epoch=175
05/21/2022 05:14:44 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.02 on epoch=176
05/21/2022 05:14:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.92 on epoch=177
05/21/2022 05:14:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.87 on epoch=177
05/21/2022 05:14:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.85 on epoch=178
05/21/2022 05:14:51 - INFO - __main__ - Global step 2500 Train loss 0.91 Classification-F1 0.4571216569907926 on epoch=178
05/21/2022 05:14:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.96 on epoch=179
05/21/2022 05:14:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.98 on epoch=179
05/21/2022 05:14:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.85 on epoch=180
05/21/2022 05:14:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.96 on epoch=181
05/21/2022 05:14:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.88 on epoch=182
05/21/2022 05:15:01 - INFO - __main__ - Global step 2550 Train loss 0.93 Classification-F1 0.49724040344662623 on epoch=182
05/21/2022 05:15:01 - INFO - __main__ - Saving model with best Classification-F1: 0.497193331044547 -> 0.49724040344662623 on epoch=182, global_step=2550
05/21/2022 05:15:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.89 on epoch=182
05/21/2022 05:15:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.87 on epoch=183
05/21/2022 05:15:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.87 on epoch=184
05/21/2022 05:15:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.06 on epoch=184
05/21/2022 05:15:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.89 on epoch=185
05/21/2022 05:15:11 - INFO - __main__ - Global step 2600 Train loss 0.92 Classification-F1 0.5475490730996848 on epoch=185
05/21/2022 05:15:11 - INFO - __main__ - Saving model with best Classification-F1: 0.49724040344662623 -> 0.5475490730996848 on epoch=185, global_step=2600
05/21/2022 05:15:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.91 on epoch=186
05/21/2022 05:15:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.89 on epoch=187
05/21/2022 05:15:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.84 on epoch=187
05/21/2022 05:15:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.81 on epoch=188
05/21/2022 05:15:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.90 on epoch=189
05/21/2022 05:15:21 - INFO - __main__ - Global step 2650 Train loss 0.87 Classification-F1 0.5348265149366306 on epoch=189
05/21/2022 05:15:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.83 on epoch=189
05/21/2022 05:15:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.91 on epoch=190
05/21/2022 05:15:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.89 on epoch=191
05/21/2022 05:15:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.96 on epoch=192
05/21/2022 05:15:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.93 on epoch=192
05/21/2022 05:15:32 - INFO - __main__ - Global step 2700 Train loss 0.90 Classification-F1 0.44645601641566895 on epoch=192
05/21/2022 05:15:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.96 on epoch=193
05/21/2022 05:15:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.03 on epoch=194
05/21/2022 05:15:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.85 on epoch=194
05/21/2022 05:15:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.86 on epoch=195
05/21/2022 05:15:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.89 on epoch=196
05/21/2022 05:15:42 - INFO - __main__ - Global step 2750 Train loss 0.92 Classification-F1 0.48783690611785957 on epoch=196
05/21/2022 05:15:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.93 on epoch=197
05/21/2022 05:15:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.91 on epoch=197
05/21/2022 05:15:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.82 on epoch=198
05/21/2022 05:15:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.99 on epoch=199
05/21/2022 05:15:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.91 on epoch=199
05/21/2022 05:15:52 - INFO - __main__ - Global step 2800 Train loss 0.91 Classification-F1 0.48960719228332755 on epoch=199
05/21/2022 05:15:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.87 on epoch=200
05/21/2022 05:15:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.90 on epoch=201
05/21/2022 05:15:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.96 on epoch=202
05/21/2022 05:15:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.78 on epoch=202
05/21/2022 05:15:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.80 on epoch=203
05/21/2022 05:16:02 - INFO - __main__ - Global step 2850 Train loss 0.86 Classification-F1 0.5443174414488889 on epoch=203
05/21/2022 05:16:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.91 on epoch=204
05/21/2022 05:16:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.94 on epoch=204
05/21/2022 05:16:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.86 on epoch=205
05/21/2022 05:16:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.82 on epoch=206
05/21/2022 05:16:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.99 on epoch=207
05/21/2022 05:16:13 - INFO - __main__ - Global step 2900 Train loss 0.91 Classification-F1 0.5014152174358549 on epoch=207
05/21/2022 05:16:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.94 on epoch=207
05/21/2022 05:16:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.78 on epoch=208
05/21/2022 05:16:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.94 on epoch=209
05/21/2022 05:16:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/21/2022 05:16:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.89 on epoch=210
05/21/2022 05:16:22 - INFO - __main__ - Global step 2950 Train loss 0.87 Classification-F1 0.5610991655183694 on epoch=210
05/21/2022 05:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5475490730996848 -> 0.5610991655183694 on epoch=210, global_step=2950
05/21/2022 05:16:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.91 on epoch=211
05/21/2022 05:16:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.87 on epoch=212
05/21/2022 05:16:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.83 on epoch=212
05/21/2022 05:16:28 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.88 on epoch=213
05/21/2022 05:16:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.82 on epoch=214
05/21/2022 05:16:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:16:30 - INFO - __main__ - Printing 3 examples
05/21/2022 05:16:30 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:16:30 - INFO - __main__ - ['Plant']
05/21/2022 05:16:30 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:16:30 - INFO - __main__ - ['Plant']
05/21/2022 05:16:30 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:16:30 - INFO - __main__ - ['Plant']
05/21/2022 05:16:30 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:16:30 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:16:31 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:16:31 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:16:31 - INFO - __main__ - Printing 3 examples
05/21/2022 05:16:31 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:16:31 - INFO - __main__ - ['Plant']
05/21/2022 05:16:31 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:16:31 - INFO - __main__ - ['Plant']
05/21/2022 05:16:31 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:16:31 - INFO - __main__ - ['Plant']
05/21/2022 05:16:31 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:16:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:16:31 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:16:33 - INFO - __main__ - Global step 3000 Train loss 0.86 Classification-F1 0.5168053985098775 on epoch=214
05/21/2022 05:16:33 - INFO - __main__ - save last model!
05/21/2022 05:16:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:16:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:16:33 - INFO - __main__ - Printing 3 examples
05/21/2022 05:16:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:16:33 - INFO - __main__ - ['Animal']
05/21/2022 05:16:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:16:33 - INFO - __main__ - ['Animal']
05/21/2022 05:16:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:16:33 - INFO - __main__ - ['Village']
05/21/2022 05:16:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:16:35 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:16:36 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:16:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:16:37 - INFO - __main__ - Starting training!
05/21/2022 05:16:38 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 05:17:36 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
05/21/2022 05:17:36 - INFO - __main__ - Classification-F1 on test data: 0.1913
05/21/2022 05:17:36 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.5610991655183694, test_performance=0.19132566812166832
05/21/2022 05:17:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
05/21/2022 05:17:37 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:17:37 - INFO - __main__ - Printing 3 examples
05/21/2022 05:17:37 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:17:37 - INFO - __main__ - ['Plant']
05/21/2022 05:17:37 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:17:37 - INFO - __main__ - ['Plant']
05/21/2022 05:17:37 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:17:37 - INFO - __main__ - ['Plant']
05/21/2022 05:17:37 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:17:37 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:17:38 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:17:38 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:17:38 - INFO - __main__ - Printing 3 examples
05/21/2022 05:17:38 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:17:38 - INFO - __main__ - ['Plant']
05/21/2022 05:17:38 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:17:38 - INFO - __main__ - ['Plant']
05/21/2022 05:17:38 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:17:38 - INFO - __main__ - ['Plant']
05/21/2022 05:17:38 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:17:38 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:17:38 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:17:43 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:17:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:17:44 - INFO - __main__ - Starting training!
05/21/2022 05:17:45 - INFO - __main__ - Step 10 Global step 10 Train loss 7.73 on epoch=0
05/21/2022 05:17:46 - INFO - __main__ - Step 20 Global step 20 Train loss 6.75 on epoch=1
05/21/2022 05:17:48 - INFO - __main__ - Step 30 Global step 30 Train loss 5.96 on epoch=2
05/21/2022 05:17:49 - INFO - __main__ - Step 40 Global step 40 Train loss 5.53 on epoch=2
05/21/2022 05:17:50 - INFO - __main__ - Step 50 Global step 50 Train loss 5.10 on epoch=3
05/21/2022 05:17:53 - INFO - __main__ - Global step 50 Train loss 6.21 Classification-F1 0.0 on epoch=3
05/21/2022 05:17:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 05:17:55 - INFO - __main__ - Step 60 Global step 60 Train loss 4.87 on epoch=4
05/21/2022 05:17:56 - INFO - __main__ - Step 70 Global step 70 Train loss 4.35 on epoch=4
05/21/2022 05:17:57 - INFO - __main__ - Step 80 Global step 80 Train loss 4.22 on epoch=5
05/21/2022 05:17:59 - INFO - __main__ - Step 90 Global step 90 Train loss 3.78 on epoch=6
05/21/2022 05:18:00 - INFO - __main__ - Step 100 Global step 100 Train loss 3.62 on epoch=7
05/21/2022 05:18:05 - INFO - __main__ - Global step 100 Train loss 4.17 Classification-F1 0.0 on epoch=7
05/21/2022 05:18:06 - INFO - __main__ - Step 110 Global step 110 Train loss 3.51 on epoch=7
05/21/2022 05:18:07 - INFO - __main__ - Step 120 Global step 120 Train loss 3.33 on epoch=8
05/21/2022 05:18:09 - INFO - __main__ - Step 130 Global step 130 Train loss 3.33 on epoch=9
05/21/2022 05:18:10 - INFO - __main__ - Step 140 Global step 140 Train loss 2.89 on epoch=9
05/21/2022 05:18:12 - INFO - __main__ - Step 150 Global step 150 Train loss 2.99 on epoch=10
05/21/2022 05:18:15 - INFO - __main__ - Global step 150 Train loss 3.21 Classification-F1 0.005893186003683242 on epoch=10
05/21/2022 05:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005893186003683242 on epoch=10, global_step=150
05/21/2022 05:18:16 - INFO - __main__ - Step 160 Global step 160 Train loss 2.74 on epoch=11
05/21/2022 05:18:17 - INFO - __main__ - Step 170 Global step 170 Train loss 2.69 on epoch=12
05/21/2022 05:18:19 - INFO - __main__ - Step 180 Global step 180 Train loss 2.57 on epoch=12
05/21/2022 05:18:20 - INFO - __main__ - Step 190 Global step 190 Train loss 2.49 on epoch=13
05/21/2022 05:18:21 - INFO - __main__ - Step 200 Global step 200 Train loss 2.41 on epoch=14
05/21/2022 05:18:23 - INFO - __main__ - Global step 200 Train loss 2.58 Classification-F1 0.009523809523809523 on epoch=14
05/21/2022 05:18:23 - INFO - __main__ - Saving model with best Classification-F1: 0.005893186003683242 -> 0.009523809523809523 on epoch=14, global_step=200
05/21/2022 05:18:24 - INFO - __main__ - Step 210 Global step 210 Train loss 2.31 on epoch=14
05/21/2022 05:18:25 - INFO - __main__ - Step 220 Global step 220 Train loss 2.25 on epoch=15
05/21/2022 05:18:27 - INFO - __main__ - Step 230 Global step 230 Train loss 2.10 on epoch=16
05/21/2022 05:18:28 - INFO - __main__ - Step 240 Global step 240 Train loss 2.16 on epoch=17
05/21/2022 05:18:29 - INFO - __main__ - Step 250 Global step 250 Train loss 2.02 on epoch=17
05/21/2022 05:18:31 - INFO - __main__ - Global step 250 Train loss 2.17 Classification-F1 0.03466486043255069 on epoch=17
05/21/2022 05:18:31 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.03466486043255069 on epoch=17, global_step=250
05/21/2022 05:18:32 - INFO - __main__ - Step 260 Global step 260 Train loss 1.96 on epoch=18
05/21/2022 05:18:33 - INFO - __main__ - Step 270 Global step 270 Train loss 1.89 on epoch=19
05/21/2022 05:18:35 - INFO - __main__ - Step 280 Global step 280 Train loss 1.76 on epoch=19
05/21/2022 05:18:36 - INFO - __main__ - Step 290 Global step 290 Train loss 1.80 on epoch=20
05/21/2022 05:18:37 - INFO - __main__ - Step 300 Global step 300 Train loss 1.77 on epoch=21
05/21/2022 05:18:39 - INFO - __main__ - Global step 300 Train loss 1.84 Classification-F1 0.029542102051052704 on epoch=21
05/21/2022 05:18:40 - INFO - __main__ - Step 310 Global step 310 Train loss 1.88 on epoch=22
05/21/2022 05:18:41 - INFO - __main__ - Step 320 Global step 320 Train loss 1.74 on epoch=22
05/21/2022 05:18:43 - INFO - __main__ - Step 330 Global step 330 Train loss 1.63 on epoch=23
05/21/2022 05:18:44 - INFO - __main__ - Step 340 Global step 340 Train loss 1.55 on epoch=24
05/21/2022 05:18:45 - INFO - __main__ - Step 350 Global step 350 Train loss 1.56 on epoch=24
05/21/2022 05:18:48 - INFO - __main__ - Global step 350 Train loss 1.67 Classification-F1 0.025014459224985543 on epoch=24
05/21/2022 05:18:49 - INFO - __main__ - Step 360 Global step 360 Train loss 1.58 on epoch=25
05/21/2022 05:18:50 - INFO - __main__ - Step 370 Global step 370 Train loss 1.50 on epoch=26
05/21/2022 05:18:51 - INFO - __main__ - Step 380 Global step 380 Train loss 1.53 on epoch=27
05/21/2022 05:18:53 - INFO - __main__ - Step 390 Global step 390 Train loss 1.59 on epoch=27
05/21/2022 05:18:54 - INFO - __main__ - Step 400 Global step 400 Train loss 1.40 on epoch=28
05/21/2022 05:18:56 - INFO - __main__ - Global step 400 Train loss 1.52 Classification-F1 0.0417027417027417 on epoch=28
05/21/2022 05:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.03466486043255069 -> 0.0417027417027417 on epoch=28, global_step=400
05/21/2022 05:18:57 - INFO - __main__ - Step 410 Global step 410 Train loss 1.35 on epoch=29
05/21/2022 05:18:59 - INFO - __main__ - Step 420 Global step 420 Train loss 1.40 on epoch=29
05/21/2022 05:19:00 - INFO - __main__ - Step 430 Global step 430 Train loss 1.39 on epoch=30
05/21/2022 05:19:01 - INFO - __main__ - Step 440 Global step 440 Train loss 1.33 on epoch=31
05/21/2022 05:19:02 - INFO - __main__ - Step 450 Global step 450 Train loss 1.37 on epoch=32
05/21/2022 05:19:05 - INFO - __main__ - Global step 450 Train loss 1.37 Classification-F1 0.06903634986747445 on epoch=32
05/21/2022 05:19:05 - INFO - __main__ - Saving model with best Classification-F1: 0.0417027417027417 -> 0.06903634986747445 on epoch=32, global_step=450
05/21/2022 05:19:06 - INFO - __main__ - Step 460 Global step 460 Train loss 1.44 on epoch=32
05/21/2022 05:19:08 - INFO - __main__ - Step 470 Global step 470 Train loss 1.37 on epoch=33
05/21/2022 05:19:09 - INFO - __main__ - Step 480 Global step 480 Train loss 1.29 on epoch=34
05/21/2022 05:19:10 - INFO - __main__ - Step 490 Global step 490 Train loss 1.35 on epoch=34
05/21/2022 05:19:11 - INFO - __main__ - Step 500 Global step 500 Train loss 1.37 on epoch=35
05/21/2022 05:19:14 - INFO - __main__ - Global step 500 Train loss 1.36 Classification-F1 0.05584639652962635 on epoch=35
05/21/2022 05:19:15 - INFO - __main__ - Step 510 Global step 510 Train loss 1.28 on epoch=36
05/21/2022 05:19:17 - INFO - __main__ - Step 520 Global step 520 Train loss 1.34 on epoch=37
05/21/2022 05:19:18 - INFO - __main__ - Step 530 Global step 530 Train loss 1.36 on epoch=37
05/21/2022 05:19:19 - INFO - __main__ - Step 540 Global step 540 Train loss 1.24 on epoch=38
05/21/2022 05:19:20 - INFO - __main__ - Step 550 Global step 550 Train loss 1.44 on epoch=39
05/21/2022 05:19:22 - INFO - __main__ - Global step 550 Train loss 1.33 Classification-F1 0.09019348333018215 on epoch=39
05/21/2022 05:19:22 - INFO - __main__ - Saving model with best Classification-F1: 0.06903634986747445 -> 0.09019348333018215 on epoch=39, global_step=550
05/21/2022 05:19:24 - INFO - __main__ - Step 560 Global step 560 Train loss 1.32 on epoch=39
05/21/2022 05:19:25 - INFO - __main__ - Step 570 Global step 570 Train loss 1.42 on epoch=40
05/21/2022 05:19:26 - INFO - __main__ - Step 580 Global step 580 Train loss 1.19 on epoch=41
05/21/2022 05:19:27 - INFO - __main__ - Step 590 Global step 590 Train loss 1.18 on epoch=42
05/21/2022 05:19:28 - INFO - __main__ - Step 600 Global step 600 Train loss 1.27 on epoch=42
05/21/2022 05:19:31 - INFO - __main__ - Global step 600 Train loss 1.28 Classification-F1 0.12639005869099465 on epoch=42
05/21/2022 05:19:31 - INFO - __main__ - Saving model with best Classification-F1: 0.09019348333018215 -> 0.12639005869099465 on epoch=42, global_step=600
05/21/2022 05:19:32 - INFO - __main__ - Step 610 Global step 610 Train loss 1.30 on epoch=43
05/21/2022 05:19:33 - INFO - __main__ - Step 620 Global step 620 Train loss 1.32 on epoch=44
05/21/2022 05:19:35 - INFO - __main__ - Step 630 Global step 630 Train loss 1.23 on epoch=44
05/21/2022 05:19:36 - INFO - __main__ - Step 640 Global step 640 Train loss 1.24 on epoch=45
05/21/2022 05:19:37 - INFO - __main__ - Step 650 Global step 650 Train loss 1.24 on epoch=46
05/21/2022 05:19:40 - INFO - __main__ - Global step 650 Train loss 1.26 Classification-F1 0.12436852486790807 on epoch=46
05/21/2022 05:19:41 - INFO - __main__ - Step 660 Global step 660 Train loss 1.23 on epoch=47
05/21/2022 05:19:42 - INFO - __main__ - Step 670 Global step 670 Train loss 1.21 on epoch=47
05/21/2022 05:19:44 - INFO - __main__ - Step 680 Global step 680 Train loss 1.20 on epoch=48
05/21/2022 05:19:45 - INFO - __main__ - Step 690 Global step 690 Train loss 1.18 on epoch=49
05/21/2022 05:19:46 - INFO - __main__ - Step 700 Global step 700 Train loss 1.14 on epoch=49
05/21/2022 05:19:49 - INFO - __main__ - Global step 700 Train loss 1.19 Classification-F1 0.20575474634298163 on epoch=49
05/21/2022 05:19:49 - INFO - __main__ - Saving model with best Classification-F1: 0.12639005869099465 -> 0.20575474634298163 on epoch=49, global_step=700
05/21/2022 05:19:50 - INFO - __main__ - Step 710 Global step 710 Train loss 1.21 on epoch=50
05/21/2022 05:19:52 - INFO - __main__ - Step 720 Global step 720 Train loss 1.09 on epoch=51
05/21/2022 05:19:53 - INFO - __main__ - Step 730 Global step 730 Train loss 1.20 on epoch=52
05/21/2022 05:19:54 - INFO - __main__ - Step 740 Global step 740 Train loss 1.26 on epoch=52
05/21/2022 05:19:55 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/21/2022 05:19:58 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.21818166880278683 on epoch=53
05/21/2022 05:19:58 - INFO - __main__ - Saving model with best Classification-F1: 0.20575474634298163 -> 0.21818166880278683 on epoch=53, global_step=750
05/21/2022 05:20:00 - INFO - __main__ - Step 760 Global step 760 Train loss 1.15 on epoch=54
05/21/2022 05:20:01 - INFO - __main__ - Step 770 Global step 770 Train loss 1.10 on epoch=54
05/21/2022 05:20:02 - INFO - __main__ - Step 780 Global step 780 Train loss 1.25 on epoch=55
05/21/2022 05:20:03 - INFO - __main__ - Step 790 Global step 790 Train loss 1.14 on epoch=56
05/21/2022 05:20:04 - INFO - __main__ - Step 800 Global step 800 Train loss 1.17 on epoch=57
05/21/2022 05:20:07 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.2213537502234789 on epoch=57
05/21/2022 05:20:08 - INFO - __main__ - Saving model with best Classification-F1: 0.21818166880278683 -> 0.2213537502234789 on epoch=57, global_step=800
05/21/2022 05:20:09 - INFO - __main__ - Step 810 Global step 810 Train loss 1.16 on epoch=57
05/21/2022 05:20:10 - INFO - __main__ - Step 820 Global step 820 Train loss 1.09 on epoch=58
05/21/2022 05:20:11 - INFO - __main__ - Step 830 Global step 830 Train loss 1.11 on epoch=59
05/21/2022 05:20:12 - INFO - __main__ - Step 840 Global step 840 Train loss 1.06 on epoch=59
05/21/2022 05:20:14 - INFO - __main__ - Step 850 Global step 850 Train loss 1.20 on epoch=60
05/21/2022 05:20:17 - INFO - __main__ - Global step 850 Train loss 1.12 Classification-F1 0.2686510861677969 on epoch=60
05/21/2022 05:20:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2213537502234789 -> 0.2686510861677969 on epoch=60, global_step=850
05/21/2022 05:20:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.99 on epoch=61
05/21/2022 05:20:19 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=62
05/21/2022 05:20:20 - INFO - __main__ - Step 880 Global step 880 Train loss 1.10 on epoch=62
05/21/2022 05:20:21 - INFO - __main__ - Step 890 Global step 890 Train loss 1.09 on epoch=63
05/21/2022 05:20:23 - INFO - __main__ - Step 900 Global step 900 Train loss 1.07 on epoch=64
05/21/2022 05:20:27 - INFO - __main__ - Global step 900 Train loss 1.07 Classification-F1 0.3415945209243633 on epoch=64
05/21/2022 05:20:27 - INFO - __main__ - Saving model with best Classification-F1: 0.2686510861677969 -> 0.3415945209243633 on epoch=64, global_step=900
05/21/2022 05:20:28 - INFO - __main__ - Step 910 Global step 910 Train loss 1.05 on epoch=64
05/21/2022 05:20:29 - INFO - __main__ - Step 920 Global step 920 Train loss 1.02 on epoch=65
05/21/2022 05:20:30 - INFO - __main__ - Step 930 Global step 930 Train loss 1.04 on epoch=66
05/21/2022 05:20:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.96 on epoch=67
05/21/2022 05:20:33 - INFO - __main__ - Step 950 Global step 950 Train loss 1.03 on epoch=67
05/21/2022 05:20:36 - INFO - __main__ - Global step 950 Train loss 1.02 Classification-F1 0.35030232828005886 on epoch=67
05/21/2022 05:20:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3415945209243633 -> 0.35030232828005886 on epoch=67, global_step=950
05/21/2022 05:20:37 - INFO - __main__ - Step 960 Global step 960 Train loss 1.01 on epoch=68
05/21/2022 05:20:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.94 on epoch=69
05/21/2022 05:20:40 - INFO - __main__ - Step 980 Global step 980 Train loss 1.05 on epoch=69
05/21/2022 05:20:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.99 on epoch=70
05/21/2022 05:20:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.00 on epoch=71
05/21/2022 05:20:46 - INFO - __main__ - Global step 1000 Train loss 1.00 Classification-F1 0.419783329073688 on epoch=71
05/21/2022 05:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.35030232828005886 -> 0.419783329073688 on epoch=71, global_step=1000
05/21/2022 05:20:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/21/2022 05:20:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.07 on epoch=72
05/21/2022 05:20:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.00 on epoch=73
05/21/2022 05:20:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/21/2022 05:20:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.95 on epoch=74
05/21/2022 05:20:56 - INFO - __main__ - Global step 1050 Train loss 1.00 Classification-F1 0.421410562645707 on epoch=74
05/21/2022 05:20:56 - INFO - __main__ - Saving model with best Classification-F1: 0.419783329073688 -> 0.421410562645707 on epoch=74, global_step=1050
05/21/2022 05:20:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.00 on epoch=75
05/21/2022 05:20:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.88 on epoch=76
05/21/2022 05:20:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.01 on epoch=77
05/21/2022 05:21:00 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.05 on epoch=77
05/21/2022 05:21:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.00 on epoch=78
05/21/2022 05:21:06 - INFO - __main__ - Global step 1100 Train loss 0.99 Classification-F1 0.41006870775272275 on epoch=78
05/21/2022 05:21:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.88 on epoch=79
05/21/2022 05:21:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.94 on epoch=79
05/21/2022 05:21:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.05 on epoch=80
05/21/2022 05:21:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.93 on epoch=81
05/21/2022 05:21:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.92 on epoch=82
05/21/2022 05:21:16 - INFO - __main__ - Global step 1150 Train loss 0.94 Classification-F1 0.474635812320912 on epoch=82
05/21/2022 05:21:16 - INFO - __main__ - Saving model with best Classification-F1: 0.421410562645707 -> 0.474635812320912 on epoch=82, global_step=1150
05/21/2022 05:21:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.99 on epoch=82
05/21/2022 05:21:18 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.83 on epoch=83
05/21/2022 05:21:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.96 on epoch=84
05/21/2022 05:21:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.89 on epoch=84
05/21/2022 05:21:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.91 on epoch=85
05/21/2022 05:21:25 - INFO - __main__ - Global step 1200 Train loss 0.91 Classification-F1 0.47827616344142804 on epoch=85
05/21/2022 05:21:25 - INFO - __main__ - Saving model with best Classification-F1: 0.474635812320912 -> 0.47827616344142804 on epoch=85, global_step=1200
05/21/2022 05:21:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.77 on epoch=86
05/21/2022 05:21:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.87 on epoch=87
05/21/2022 05:21:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.87 on epoch=87
05/21/2022 05:21:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.84 on epoch=88
05/21/2022 05:21:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.91 on epoch=89
05/21/2022 05:21:35 - INFO - __main__ - Global step 1250 Train loss 0.85 Classification-F1 0.44523899533611566 on epoch=89
05/21/2022 05:21:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.82 on epoch=89
05/21/2022 05:21:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.87 on epoch=90
05/21/2022 05:21:39 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.79 on epoch=91
05/21/2022 05:21:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.73 on epoch=92
05/21/2022 05:21:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.88 on epoch=92
05/21/2022 05:21:45 - INFO - __main__ - Global step 1300 Train loss 0.82 Classification-F1 0.39888438584915775 on epoch=92
05/21/2022 05:21:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.85 on epoch=93
05/21/2022 05:21:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.79 on epoch=94
05/21/2022 05:21:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.75 on epoch=94
05/21/2022 05:21:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.82 on epoch=95
05/21/2022 05:21:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.74 on epoch=96
05/21/2022 05:21:55 - INFO - __main__ - Global step 1350 Train loss 0.79 Classification-F1 0.3781056614084473 on epoch=96
05/21/2022 05:21:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.80 on epoch=97
05/21/2022 05:21:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.79 on epoch=97
05/21/2022 05:21:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.75 on epoch=98
05/21/2022 05:22:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.81 on epoch=99
05/21/2022 05:22:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.73 on epoch=99
05/21/2022 05:22:04 - INFO - __main__ - Global step 1400 Train loss 0.78 Classification-F1 0.4098662105435753 on epoch=99
05/21/2022 05:22:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.82 on epoch=100
05/21/2022 05:22:07 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.73 on epoch=101
05/21/2022 05:22:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.68 on epoch=102
05/21/2022 05:22:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.73 on epoch=102
05/21/2022 05:22:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/21/2022 05:22:14 - INFO - __main__ - Global step 1450 Train loss 0.74 Classification-F1 0.459368662313528 on epoch=103
05/21/2022 05:22:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.75 on epoch=104
05/21/2022 05:22:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.86 on epoch=104
05/21/2022 05:22:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.78 on epoch=105
05/21/2022 05:22:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.78 on epoch=106
05/21/2022 05:22:20 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.62 on epoch=107
05/21/2022 05:22:24 - INFO - __main__ - Global step 1500 Train loss 0.76 Classification-F1 0.4010885226148551 on epoch=107
05/21/2022 05:22:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.65 on epoch=107
05/21/2022 05:22:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.74 on epoch=108
05/21/2022 05:22:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.71 on epoch=109
05/21/2022 05:22:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.80 on epoch=109
05/21/2022 05:22:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.67 on epoch=110
05/21/2022 05:22:33 - INFO - __main__ - Global step 1550 Train loss 0.71 Classification-F1 0.41263511740784475 on epoch=110
05/21/2022 05:22:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.64 on epoch=111
05/21/2022 05:22:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.64 on epoch=112
05/21/2022 05:22:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.73 on epoch=112
05/21/2022 05:22:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.78 on epoch=113
05/21/2022 05:22:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.71 on epoch=114
05/21/2022 05:22:44 - INFO - __main__ - Global step 1600 Train loss 0.70 Classification-F1 0.44496651672735416 on epoch=114
05/21/2022 05:22:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.77 on epoch=114
05/21/2022 05:22:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.75 on epoch=115
05/21/2022 05:22:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.55 on epoch=116
05/21/2022 05:22:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.74 on epoch=117
05/21/2022 05:22:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.75 on epoch=117
05/21/2022 05:22:53 - INFO - __main__ - Global step 1650 Train loss 0.71 Classification-F1 0.39997980805850797 on epoch=117
05/21/2022 05:22:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.79 on epoch=118
05/21/2022 05:22:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.67 on epoch=119
05/21/2022 05:22:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.65 on epoch=119
05/21/2022 05:22:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.64 on epoch=120
05/21/2022 05:22:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.63 on epoch=121
05/21/2022 05:23:03 - INFO - __main__ - Global step 1700 Train loss 0.68 Classification-F1 0.45450599532503705 on epoch=121
05/21/2022 05:23:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.69 on epoch=122
05/21/2022 05:23:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.70 on epoch=122
05/21/2022 05:23:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.58 on epoch=123
05/21/2022 05:23:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.60 on epoch=124
05/21/2022 05:23:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.63 on epoch=124
05/21/2022 05:23:13 - INFO - __main__ - Global step 1750 Train loss 0.64 Classification-F1 0.46922142612269313 on epoch=124
05/21/2022 05:23:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.61 on epoch=125
05/21/2022 05:23:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.59 on epoch=126
05/21/2022 05:23:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.64 on epoch=127
05/21/2022 05:23:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.67 on epoch=127
05/21/2022 05:23:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.52 on epoch=128
05/21/2022 05:23:23 - INFO - __main__ - Global step 1800 Train loss 0.61 Classification-F1 0.45894600381013434 on epoch=128
05/21/2022 05:23:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.65 on epoch=129
05/21/2022 05:23:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.73 on epoch=129
05/21/2022 05:23:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.74 on epoch=130
05/21/2022 05:23:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.60 on epoch=131
05/21/2022 05:23:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.66 on epoch=132
05/21/2022 05:23:33 - INFO - __main__ - Global step 1850 Train loss 0.68 Classification-F1 0.49048938633875117 on epoch=132
05/21/2022 05:23:33 - INFO - __main__ - Saving model with best Classification-F1: 0.47827616344142804 -> 0.49048938633875117 on epoch=132, global_step=1850
05/21/2022 05:23:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.65 on epoch=132
05/21/2022 05:23:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.59 on epoch=133
05/21/2022 05:23:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.61 on epoch=134
05/21/2022 05:23:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.62 on epoch=134
05/21/2022 05:23:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.55 on epoch=135
05/21/2022 05:23:43 - INFO - __main__ - Global step 1900 Train loss 0.60 Classification-F1 0.4462474635952298 on epoch=135
05/21/2022 05:23:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.60 on epoch=136
05/21/2022 05:23:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.54 on epoch=137
05/21/2022 05:23:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.57 on epoch=137
05/21/2022 05:23:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.63 on epoch=138
05/21/2022 05:23:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.59 on epoch=139
05/21/2022 05:23:53 - INFO - __main__ - Global step 1950 Train loss 0.59 Classification-F1 0.5194691271741799 on epoch=139
05/21/2022 05:23:53 - INFO - __main__ - Saving model with best Classification-F1: 0.49048938633875117 -> 0.5194691271741799 on epoch=139, global_step=1950
05/21/2022 05:23:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.54 on epoch=139
05/21/2022 05:23:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.61 on epoch=140
05/21/2022 05:23:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.55 on epoch=141
05/21/2022 05:23:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.58 on epoch=142
05/21/2022 05:23:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.51 on epoch=142
05/21/2022 05:24:03 - INFO - __main__ - Global step 2000 Train loss 0.56 Classification-F1 0.4638218208907028 on epoch=142
05/21/2022 05:24:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.56 on epoch=143
05/21/2022 05:24:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.63 on epoch=144
05/21/2022 05:24:07 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.56 on epoch=144
05/21/2022 05:24:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.60 on epoch=145
05/21/2022 05:24:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.53 on epoch=146
05/21/2022 05:24:13 - INFO - __main__ - Global step 2050 Train loss 0.58 Classification-F1 0.4757923062584945 on epoch=146
05/21/2022 05:24:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.58 on epoch=147
05/21/2022 05:24:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.51 on epoch=147
05/21/2022 05:24:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.56 on epoch=148
05/21/2022 05:24:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.60 on epoch=149
05/21/2022 05:24:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.55 on epoch=149
05/21/2022 05:24:23 - INFO - __main__ - Global step 2100 Train loss 0.56 Classification-F1 0.46934569956977645 on epoch=149
05/21/2022 05:24:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.57 on epoch=150
05/21/2022 05:24:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.50 on epoch=151
05/21/2022 05:24:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.48 on epoch=152
05/21/2022 05:24:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.53 on epoch=152
05/21/2022 05:24:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.59 on epoch=153
05/21/2022 05:24:33 - INFO - __main__ - Global step 2150 Train loss 0.53 Classification-F1 0.5102246728682145 on epoch=153
05/21/2022 05:24:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.53 on epoch=154
05/21/2022 05:24:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.55 on epoch=154
05/21/2022 05:24:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.49 on epoch=155
05/21/2022 05:24:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.44 on epoch=156
05/21/2022 05:24:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.50 on epoch=157
05/21/2022 05:24:43 - INFO - __main__ - Global step 2200 Train loss 0.50 Classification-F1 0.5401720452243565 on epoch=157
05/21/2022 05:24:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5194691271741799 -> 0.5401720452243565 on epoch=157, global_step=2200
05/21/2022 05:24:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.53 on epoch=157
05/21/2022 05:24:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.60 on epoch=158
05/21/2022 05:24:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.50 on epoch=159
05/21/2022 05:24:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.54 on epoch=159
05/21/2022 05:24:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.58 on epoch=160
05/21/2022 05:24:53 - INFO - __main__ - Global step 2250 Train loss 0.55 Classification-F1 0.5546702891001137 on epoch=160
05/21/2022 05:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5401720452243565 -> 0.5546702891001137 on epoch=160, global_step=2250
05/21/2022 05:24:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.51 on epoch=161
05/21/2022 05:24:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.55 on epoch=162
05/21/2022 05:24:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.50 on epoch=162
05/21/2022 05:24:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.48 on epoch=163
05/21/2022 05:25:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.57 on epoch=164
05/21/2022 05:25:04 - INFO - __main__ - Global step 2300 Train loss 0.52 Classification-F1 0.5895819500425334 on epoch=164
05/21/2022 05:25:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5546702891001137 -> 0.5895819500425334 on epoch=164, global_step=2300
05/21/2022 05:25:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.44 on epoch=164
05/21/2022 05:25:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.51 on epoch=165
05/21/2022 05:25:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.48 on epoch=166
05/21/2022 05:25:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.52 on epoch=167
05/21/2022 05:25:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.49 on epoch=167
05/21/2022 05:25:14 - INFO - __main__ - Global step 2350 Train loss 0.49 Classification-F1 0.5121021762894827 on epoch=167
05/21/2022 05:25:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.50 on epoch=168
05/21/2022 05:25:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.53 on epoch=169
05/21/2022 05:25:18 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.50 on epoch=169
05/21/2022 05:25:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.49 on epoch=170
05/21/2022 05:25:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.40 on epoch=171
05/21/2022 05:25:24 - INFO - __main__ - Global step 2400 Train loss 0.48 Classification-F1 0.5775754475035223 on epoch=171
05/21/2022 05:25:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.50 on epoch=172
05/21/2022 05:25:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.45 on epoch=172
05/21/2022 05:25:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.52 on epoch=173
05/21/2022 05:25:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.52 on epoch=174
05/21/2022 05:25:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.54 on epoch=174
05/21/2022 05:25:35 - INFO - __main__ - Global step 2450 Train loss 0.50 Classification-F1 0.5164688960746263 on epoch=174
05/21/2022 05:25:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.51 on epoch=175
05/21/2022 05:25:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.55 on epoch=176
05/21/2022 05:25:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.57 on epoch=177
05/21/2022 05:25:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.47 on epoch=177
05/21/2022 05:25:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.43 on epoch=178
05/21/2022 05:25:45 - INFO - __main__ - Global step 2500 Train loss 0.51 Classification-F1 0.5878894835537837 on epoch=178
05/21/2022 05:25:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.52 on epoch=179
05/21/2022 05:25:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.47 on epoch=179
05/21/2022 05:25:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.38 on epoch=180
05/21/2022 05:25:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.52 on epoch=181
05/21/2022 05:25:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.51 on epoch=182
05/21/2022 05:25:55 - INFO - __main__ - Global step 2550 Train loss 0.48 Classification-F1 0.622853140067673 on epoch=182
05/21/2022 05:25:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5895819500425334 -> 0.622853140067673 on epoch=182, global_step=2550
05/21/2022 05:25:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.43 on epoch=182
05/21/2022 05:25:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.44 on epoch=183
05/21/2022 05:25:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.44 on epoch=184
05/21/2022 05:26:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.48 on epoch=184
05/21/2022 05:26:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.52 on epoch=185
05/21/2022 05:26:05 - INFO - __main__ - Global step 2600 Train loss 0.46 Classification-F1 0.5711073942931766 on epoch=185
05/21/2022 05:26:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.44 on epoch=186
05/21/2022 05:26:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.39 on epoch=187
05/21/2022 05:26:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.46 on epoch=187
05/21/2022 05:26:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.55 on epoch=188
05/21/2022 05:26:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.49 on epoch=189
05/21/2022 05:26:15 - INFO - __main__ - Global step 2650 Train loss 0.47 Classification-F1 0.59442134214024 on epoch=189
05/21/2022 05:26:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.45 on epoch=189
05/21/2022 05:26:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.47 on epoch=190
05/21/2022 05:26:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.46 on epoch=191
05/21/2022 05:26:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.49 on epoch=192
05/21/2022 05:26:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.45 on epoch=192
05/21/2022 05:26:26 - INFO - __main__ - Global step 2700 Train loss 0.46 Classification-F1 0.6905446912156471 on epoch=192
05/21/2022 05:26:26 - INFO - __main__ - Saving model with best Classification-F1: 0.622853140067673 -> 0.6905446912156471 on epoch=192, global_step=2700
05/21/2022 05:26:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.46 on epoch=193
05/21/2022 05:26:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.49 on epoch=194
05/21/2022 05:26:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.47 on epoch=194
05/21/2022 05:26:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.44 on epoch=195
05/21/2022 05:26:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.37 on epoch=196
05/21/2022 05:26:37 - INFO - __main__ - Global step 2750 Train loss 0.45 Classification-F1 0.6484918126243961 on epoch=196
05/21/2022 05:26:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.46 on epoch=197
05/21/2022 05:26:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.52 on epoch=197
05/21/2022 05:26:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.56 on epoch=198
05/21/2022 05:26:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.42 on epoch=199
05/21/2022 05:26:43 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.49 on epoch=199
05/21/2022 05:26:47 - INFO - __main__ - Global step 2800 Train loss 0.49 Classification-F1 0.6705482373972107 on epoch=199
05/21/2022 05:26:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.44 on epoch=200
05/21/2022 05:26:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.44 on epoch=201
05/21/2022 05:26:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.43 on epoch=202
05/21/2022 05:26:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.43 on epoch=202
05/21/2022 05:26:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.37 on epoch=203
05/21/2022 05:26:57 - INFO - __main__ - Global step 2850 Train loss 0.42 Classification-F1 0.6821218186578614 on epoch=203
05/21/2022 05:26:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.39 on epoch=204
05/21/2022 05:27:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.40 on epoch=204
05/21/2022 05:27:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.43 on epoch=205
05/21/2022 05:27:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.42 on epoch=206
05/21/2022 05:27:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.44 on epoch=207
05/21/2022 05:27:08 - INFO - __main__ - Global step 2900 Train loss 0.42 Classification-F1 0.7125912269791526 on epoch=207
05/21/2022 05:27:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6905446912156471 -> 0.7125912269791526 on epoch=207, global_step=2900
05/21/2022 05:27:09 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.47 on epoch=207
05/21/2022 05:27:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.48 on epoch=208
05/21/2022 05:27:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.45 on epoch=209
05/21/2022 05:27:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.48 on epoch=209
05/21/2022 05:27:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.48 on epoch=210
05/21/2022 05:27:18 - INFO - __main__ - Global step 2950 Train loss 0.47 Classification-F1 0.7012383225941694 on epoch=210
05/21/2022 05:27:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.45 on epoch=211
05/21/2022 05:27:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.37 on epoch=212
05/21/2022 05:27:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.37 on epoch=212
05/21/2022 05:27:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.44 on epoch=213
05/21/2022 05:27:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.51 on epoch=214
05/21/2022 05:27:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:27:26 - INFO - __main__ - Printing 3 examples
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:27:26 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:27:26 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:27:26 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:27:26 - INFO - __main__ - Printing 3 examples
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:27:26 - INFO - __main__ - ['Plant']
05/21/2022 05:27:26 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:27:26 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:27:26 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:27:29 - INFO - __main__ - Global step 3000 Train loss 0.43 Classification-F1 0.6955418566939027 on epoch=214
05/21/2022 05:27:29 - INFO - __main__ - save last model!
05/21/2022 05:27:29 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:27:29 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:27:29 - INFO - __main__ - Printing 3 examples
05/21/2022 05:27:29 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:27:29 - INFO - __main__ - ['Animal']
05/21/2022 05:27:29 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:27:29 - INFO - __main__ - ['Animal']
05/21/2022 05:27:29 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:27:29 - INFO - __main__ - ['Village']
05/21/2022 05:27:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:27:31 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:27:32 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:27:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:27:32 - INFO - __main__ - Starting training!
05/21/2022 05:27:34 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 05:28:47 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
05/21/2022 05:28:47 - INFO - __main__ - Classification-F1 on test data: 0.2515
05/21/2022 05:28:47 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.7125912269791526, test_performance=0.251529457532102
05/21/2022 05:28:47 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
05/21/2022 05:28:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:28:48 - INFO - __main__ - Printing 3 examples
05/21/2022 05:28:48 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:28:48 - INFO - __main__ - ['Plant']
05/21/2022 05:28:48 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:28:48 - INFO - __main__ - ['Plant']
05/21/2022 05:28:48 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:28:48 - INFO - __main__ - ['Plant']
05/21/2022 05:28:48 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:28:49 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:28:49 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:28:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:28:49 - INFO - __main__ - Printing 3 examples
05/21/2022 05:28:49 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:28:49 - INFO - __main__ - ['Plant']
05/21/2022 05:28:49 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:28:49 - INFO - __main__ - ['Plant']
05/21/2022 05:28:49 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:28:49 - INFO - __main__ - ['Plant']
05/21/2022 05:28:49 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:28:49 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:28:49 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:28:55 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:28:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:28:55 - INFO - __main__ - Starting training!
05/21/2022 05:28:56 - INFO - __main__ - Step 10 Global step 10 Train loss 7.67 on epoch=0
05/21/2022 05:28:58 - INFO - __main__ - Step 20 Global step 20 Train loss 6.74 on epoch=1
05/21/2022 05:28:59 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=2
05/21/2022 05:29:00 - INFO - __main__ - Step 40 Global step 40 Train loss 5.85 on epoch=2
05/21/2022 05:29:01 - INFO - __main__ - Step 50 Global step 50 Train loss 5.42 on epoch=3
05/21/2022 05:29:04 - INFO - __main__ - Global step 50 Train loss 6.42 Classification-F1 0.0 on epoch=3
05/21/2022 05:29:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 05:29:05 - INFO - __main__ - Step 60 Global step 60 Train loss 5.18 on epoch=4
05/21/2022 05:29:07 - INFO - __main__ - Step 70 Global step 70 Train loss 4.58 on epoch=4
05/21/2022 05:29:08 - INFO - __main__ - Step 80 Global step 80 Train loss 4.46 on epoch=5
05/21/2022 05:29:09 - INFO - __main__ - Step 90 Global step 90 Train loss 4.09 on epoch=6
05/21/2022 05:29:10 - INFO - __main__ - Step 100 Global step 100 Train loss 3.99 on epoch=7
05/21/2022 05:29:13 - INFO - __main__ - Global step 100 Train loss 4.46 Classification-F1 0.0 on epoch=7
05/21/2022 05:29:14 - INFO - __main__ - Step 110 Global step 110 Train loss 3.80 on epoch=7
05/21/2022 05:29:16 - INFO - __main__ - Step 120 Global step 120 Train loss 3.69 on epoch=8
05/21/2022 05:29:17 - INFO - __main__ - Step 130 Global step 130 Train loss 3.42 on epoch=9
05/21/2022 05:29:18 - INFO - __main__ - Step 140 Global step 140 Train loss 3.24 on epoch=9
05/21/2022 05:29:19 - INFO - __main__ - Step 150 Global step 150 Train loss 3.19 on epoch=10
05/21/2022 05:29:22 - INFO - __main__ - Global step 150 Train loss 3.47 Classification-F1 0.005797101449275362 on epoch=10
05/21/2022 05:29:22 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.005797101449275362 on epoch=10, global_step=150
05/21/2022 05:29:23 - INFO - __main__ - Step 160 Global step 160 Train loss 3.12 on epoch=11
05/21/2022 05:29:24 - INFO - __main__ - Step 170 Global step 170 Train loss 3.05 on epoch=12
05/21/2022 05:29:25 - INFO - __main__ - Step 180 Global step 180 Train loss 2.98 on epoch=12
05/21/2022 05:29:27 - INFO - __main__ - Step 190 Global step 190 Train loss 2.83 on epoch=13
05/21/2022 05:29:28 - INFO - __main__ - Step 200 Global step 200 Train loss 2.76 on epoch=14
05/21/2022 05:29:30 - INFO - __main__ - Global step 200 Train loss 2.95 Classification-F1 0.0072607260726072625 on epoch=14
05/21/2022 05:29:30 - INFO - __main__ - Saving model with best Classification-F1: 0.005797101449275362 -> 0.0072607260726072625 on epoch=14, global_step=200
05/21/2022 05:29:31 - INFO - __main__ - Step 210 Global step 210 Train loss 2.56 on epoch=14
05/21/2022 05:29:33 - INFO - __main__ - Step 220 Global step 220 Train loss 2.62 on epoch=15
05/21/2022 05:29:34 - INFO - __main__ - Step 230 Global step 230 Train loss 2.42 on epoch=16
05/21/2022 05:29:35 - INFO - __main__ - Step 240 Global step 240 Train loss 2.53 on epoch=17
05/21/2022 05:29:36 - INFO - __main__ - Step 250 Global step 250 Train loss 2.40 on epoch=17
05/21/2022 05:29:38 - INFO - __main__ - Global step 250 Train loss 2.51 Classification-F1 0.008963585434173669 on epoch=17
05/21/2022 05:29:38 - INFO - __main__ - Saving model with best Classification-F1: 0.0072607260726072625 -> 0.008963585434173669 on epoch=17, global_step=250
05/21/2022 05:29:40 - INFO - __main__ - Step 260 Global step 260 Train loss 2.20 on epoch=18
05/21/2022 05:29:41 - INFO - __main__ - Step 270 Global step 270 Train loss 2.18 on epoch=19
05/21/2022 05:29:42 - INFO - __main__ - Step 280 Global step 280 Train loss 2.15 on epoch=19
05/21/2022 05:29:43 - INFO - __main__ - Step 290 Global step 290 Train loss 2.16 on epoch=20
05/21/2022 05:29:44 - INFO - __main__ - Step 300 Global step 300 Train loss 2.06 on epoch=21
05/21/2022 05:29:46 - INFO - __main__ - Global step 300 Train loss 2.15 Classification-F1 0.02866586391932014 on epoch=21
05/21/2022 05:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.008963585434173669 -> 0.02866586391932014 on epoch=21, global_step=300
05/21/2022 05:29:48 - INFO - __main__ - Step 310 Global step 310 Train loss 1.96 on epoch=22
05/21/2022 05:29:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.00 on epoch=22
05/21/2022 05:29:50 - INFO - __main__ - Step 330 Global step 330 Train loss 1.92 on epoch=23
05/21/2022 05:29:51 - INFO - __main__ - Step 340 Global step 340 Train loss 1.86 on epoch=24
05/21/2022 05:29:52 - INFO - __main__ - Step 350 Global step 350 Train loss 1.82 on epoch=24
05/21/2022 05:29:54 - INFO - __main__ - Global step 350 Train loss 1.91 Classification-F1 0.031997971602434075 on epoch=24
05/21/2022 05:29:54 - INFO - __main__ - Saving model with best Classification-F1: 0.02866586391932014 -> 0.031997971602434075 on epoch=24, global_step=350
05/21/2022 05:29:55 - INFO - __main__ - Step 360 Global step 360 Train loss 1.88 on epoch=25
05/21/2022 05:29:57 - INFO - __main__ - Step 370 Global step 370 Train loss 1.74 on epoch=26
05/21/2022 05:29:58 - INFO - __main__ - Step 380 Global step 380 Train loss 1.76 on epoch=27
05/21/2022 05:29:59 - INFO - __main__ - Step 390 Global step 390 Train loss 1.77 on epoch=27
05/21/2022 05:30:00 - INFO - __main__ - Step 400 Global step 400 Train loss 1.57 on epoch=28
05/21/2022 05:30:02 - INFO - __main__ - Global step 400 Train loss 1.74 Classification-F1 0.02652674706246135 on epoch=28
05/21/2022 05:30:03 - INFO - __main__ - Step 410 Global step 410 Train loss 1.68 on epoch=29
05/21/2022 05:30:05 - INFO - __main__ - Step 420 Global step 420 Train loss 1.64 on epoch=29
05/21/2022 05:30:06 - INFO - __main__ - Step 430 Global step 430 Train loss 1.65 on epoch=30
05/21/2022 05:30:07 - INFO - __main__ - Step 440 Global step 440 Train loss 1.56 on epoch=31
05/21/2022 05:30:08 - INFO - __main__ - Step 450 Global step 450 Train loss 1.58 on epoch=32
05/21/2022 05:30:11 - INFO - __main__ - Global step 450 Train loss 1.62 Classification-F1 0.041171997645211934 on epoch=32
05/21/2022 05:30:11 - INFO - __main__ - Saving model with best Classification-F1: 0.031997971602434075 -> 0.041171997645211934 on epoch=32, global_step=450
05/21/2022 05:30:12 - INFO - __main__ - Step 460 Global step 460 Train loss 1.71 on epoch=32
05/21/2022 05:30:13 - INFO - __main__ - Step 470 Global step 470 Train loss 1.53 on epoch=33
05/21/2022 05:30:15 - INFO - __main__ - Step 480 Global step 480 Train loss 1.49 on epoch=34
05/21/2022 05:30:16 - INFO - __main__ - Step 490 Global step 490 Train loss 1.59 on epoch=34
05/21/2022 05:30:17 - INFO - __main__ - Step 500 Global step 500 Train loss 1.53 on epoch=35
05/21/2022 05:30:20 - INFO - __main__ - Global step 500 Train loss 1.57 Classification-F1 0.05247357572011572 on epoch=35
05/21/2022 05:30:20 - INFO - __main__ - Saving model with best Classification-F1: 0.041171997645211934 -> 0.05247357572011572 on epoch=35, global_step=500
05/21/2022 05:30:21 - INFO - __main__ - Step 510 Global step 510 Train loss 1.48 on epoch=36
05/21/2022 05:30:22 - INFO - __main__ - Step 520 Global step 520 Train loss 1.36 on epoch=37
05/21/2022 05:30:24 - INFO - __main__ - Step 530 Global step 530 Train loss 1.44 on epoch=37
05/21/2022 05:30:25 - INFO - __main__ - Step 540 Global step 540 Train loss 1.44 on epoch=38
05/21/2022 05:30:26 - INFO - __main__ - Step 550 Global step 550 Train loss 1.48 on epoch=39
05/21/2022 05:30:29 - INFO - __main__ - Global step 550 Train loss 1.44 Classification-F1 0.05324532043419951 on epoch=39
05/21/2022 05:30:29 - INFO - __main__ - Saving model with best Classification-F1: 0.05247357572011572 -> 0.05324532043419951 on epoch=39, global_step=550
05/21/2022 05:30:30 - INFO - __main__ - Step 560 Global step 560 Train loss 1.37 on epoch=39
05/21/2022 05:30:31 - INFO - __main__ - Step 570 Global step 570 Train loss 1.40 on epoch=40
05/21/2022 05:30:32 - INFO - __main__ - Step 580 Global step 580 Train loss 1.42 on epoch=41
05/21/2022 05:30:34 - INFO - __main__ - Step 590 Global step 590 Train loss 1.42 on epoch=42
05/21/2022 05:30:35 - INFO - __main__ - Step 600 Global step 600 Train loss 1.41 on epoch=42
05/21/2022 05:30:38 - INFO - __main__ - Global step 600 Train loss 1.41 Classification-F1 0.05234340205915485 on epoch=42
05/21/2022 05:30:39 - INFO - __main__ - Step 610 Global step 610 Train loss 1.38 on epoch=43
05/21/2022 05:30:40 - INFO - __main__ - Step 620 Global step 620 Train loss 1.33 on epoch=44
05/21/2022 05:30:41 - INFO - __main__ - Step 630 Global step 630 Train loss 1.28 on epoch=44
05/21/2022 05:30:43 - INFO - __main__ - Step 640 Global step 640 Train loss 1.33 on epoch=45
05/21/2022 05:30:44 - INFO - __main__ - Step 650 Global step 650 Train loss 1.32 on epoch=46
05/21/2022 05:30:46 - INFO - __main__ - Global step 650 Train loss 1.33 Classification-F1 0.09314302212929959 on epoch=46
05/21/2022 05:30:46 - INFO - __main__ - Saving model with best Classification-F1: 0.05324532043419951 -> 0.09314302212929959 on epoch=46, global_step=650
05/21/2022 05:30:47 - INFO - __main__ - Step 660 Global step 660 Train loss 1.41 on epoch=47
05/21/2022 05:30:48 - INFO - __main__ - Step 670 Global step 670 Train loss 1.38 on epoch=47
05/21/2022 05:30:50 - INFO - __main__ - Step 680 Global step 680 Train loss 1.27 on epoch=48
05/21/2022 05:30:51 - INFO - __main__ - Step 690 Global step 690 Train loss 1.35 on epoch=49
05/21/2022 05:30:52 - INFO - __main__ - Step 700 Global step 700 Train loss 1.23 on epoch=49
05/21/2022 05:30:55 - INFO - __main__ - Global step 700 Train loss 1.33 Classification-F1 0.07513082155939299 on epoch=49
05/21/2022 05:30:56 - INFO - __main__ - Step 710 Global step 710 Train loss 1.27 on epoch=50
05/21/2022 05:30:58 - INFO - __main__ - Step 720 Global step 720 Train loss 1.27 on epoch=51
05/21/2022 05:30:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.27 on epoch=52
05/21/2022 05:31:00 - INFO - __main__ - Step 740 Global step 740 Train loss 1.35 on epoch=52
05/21/2022 05:31:01 - INFO - __main__ - Step 750 Global step 750 Train loss 1.32 on epoch=53
05/21/2022 05:31:04 - INFO - __main__ - Global step 750 Train loss 1.30 Classification-F1 0.09220293192418626 on epoch=53
05/21/2022 05:31:05 - INFO - __main__ - Step 760 Global step 760 Train loss 1.34 on epoch=54
05/21/2022 05:31:07 - INFO - __main__ - Step 770 Global step 770 Train loss 1.23 on epoch=54
05/21/2022 05:31:08 - INFO - __main__ - Step 780 Global step 780 Train loss 1.30 on epoch=55
05/21/2022 05:31:09 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=56
05/21/2022 05:31:10 - INFO - __main__ - Step 800 Global step 800 Train loss 1.28 on epoch=57
05/21/2022 05:31:14 - INFO - __main__ - Global step 800 Train loss 1.28 Classification-F1 0.06905450799967804 on epoch=57
05/21/2022 05:31:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.21 on epoch=57
05/21/2022 05:31:16 - INFO - __main__ - Step 820 Global step 820 Train loss 1.15 on epoch=58
05/21/2022 05:31:17 - INFO - __main__ - Step 830 Global step 830 Train loss 1.21 on epoch=59
05/21/2022 05:31:18 - INFO - __main__ - Step 840 Global step 840 Train loss 1.19 on epoch=59
05/21/2022 05:31:20 - INFO - __main__ - Step 850 Global step 850 Train loss 1.26 on epoch=60
05/21/2022 05:31:23 - INFO - __main__ - Global step 850 Train loss 1.20 Classification-F1 0.10873378788650424 on epoch=60
05/21/2022 05:31:23 - INFO - __main__ - Saving model with best Classification-F1: 0.09314302212929959 -> 0.10873378788650424 on epoch=60, global_step=850
05/21/2022 05:31:24 - INFO - __main__ - Step 860 Global step 860 Train loss 1.20 on epoch=61
05/21/2022 05:31:25 - INFO - __main__ - Step 870 Global step 870 Train loss 1.17 on epoch=62
05/21/2022 05:31:26 - INFO - __main__ - Step 880 Global step 880 Train loss 1.25 on epoch=62
05/21/2022 05:31:28 - INFO - __main__ - Step 890 Global step 890 Train loss 1.13 on epoch=63
05/21/2022 05:31:29 - INFO - __main__ - Step 900 Global step 900 Train loss 1.22 on epoch=64
05/21/2022 05:31:32 - INFO - __main__ - Global step 900 Train loss 1.19 Classification-F1 0.1596063650208572 on epoch=64
05/21/2022 05:31:32 - INFO - __main__ - Saving model with best Classification-F1: 0.10873378788650424 -> 0.1596063650208572 on epoch=64, global_step=900
05/21/2022 05:31:33 - INFO - __main__ - Step 910 Global step 910 Train loss 1.19 on epoch=64
05/21/2022 05:31:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.22 on epoch=65
05/21/2022 05:31:36 - INFO - __main__ - Step 930 Global step 930 Train loss 1.21 on epoch=66
05/21/2022 05:31:37 - INFO - __main__ - Step 940 Global step 940 Train loss 1.17 on epoch=67
05/21/2022 05:31:38 - INFO - __main__ - Step 950 Global step 950 Train loss 1.20 on epoch=67
05/21/2022 05:31:41 - INFO - __main__ - Global step 950 Train loss 1.20 Classification-F1 0.2026036065329301 on epoch=67
05/21/2022 05:31:41 - INFO - __main__ - Saving model with best Classification-F1: 0.1596063650208572 -> 0.2026036065329301 on epoch=67, global_step=950
05/21/2022 05:31:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.13 on epoch=68
05/21/2022 05:31:44 - INFO - __main__ - Step 970 Global step 970 Train loss 1.21 on epoch=69
05/21/2022 05:31:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.10 on epoch=69
05/21/2022 05:31:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.08 on epoch=70
05/21/2022 05:31:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.20 on epoch=71
05/21/2022 05:31:50 - INFO - __main__ - Global step 1000 Train loss 1.14 Classification-F1 0.24822447914293694 on epoch=71
05/21/2022 05:31:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2026036065329301 -> 0.24822447914293694 on epoch=71, global_step=1000
05/21/2022 05:31:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.14 on epoch=72
05/21/2022 05:31:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.16 on epoch=72
05/21/2022 05:31:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.10 on epoch=73
05/21/2022 05:31:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=74
05/21/2022 05:31:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.13 on epoch=74
05/21/2022 05:32:00 - INFO - __main__ - Global step 1050 Train loss 1.13 Classification-F1 0.2727657735886707 on epoch=74
05/21/2022 05:32:00 - INFO - __main__ - Saving model with best Classification-F1: 0.24822447914293694 -> 0.2727657735886707 on epoch=74, global_step=1050
05/21/2022 05:32:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.13 on epoch=75
05/21/2022 05:32:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.15 on epoch=76
05/21/2022 05:32:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.11 on epoch=77
05/21/2022 05:32:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.12 on epoch=77
05/21/2022 05:32:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.01 on epoch=78
05/21/2022 05:32:10 - INFO - __main__ - Global step 1100 Train loss 1.10 Classification-F1 0.27167641830782246 on epoch=78
05/21/2022 05:32:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.11 on epoch=79
05/21/2022 05:32:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=79
05/21/2022 05:32:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.11 on epoch=80
05/21/2022 05:32:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.01 on epoch=81
05/21/2022 05:32:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.10 on epoch=82
05/21/2022 05:32:19 - INFO - __main__ - Global step 1150 Train loss 1.08 Classification-F1 0.300431811399176 on epoch=82
05/21/2022 05:32:19 - INFO - __main__ - Saving model with best Classification-F1: 0.2727657735886707 -> 0.300431811399176 on epoch=82, global_step=1150
05/21/2022 05:32:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.00 on epoch=82
05/21/2022 05:32:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.05 on epoch=83
05/21/2022 05:32:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.01 on epoch=84
05/21/2022 05:32:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.02 on epoch=84
05/21/2022 05:32:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.10 on epoch=85
05/21/2022 05:32:29 - INFO - __main__ - Global step 1200 Train loss 1.04 Classification-F1 0.34806335312967424 on epoch=85
05/21/2022 05:32:29 - INFO - __main__ - Saving model with best Classification-F1: 0.300431811399176 -> 0.34806335312967424 on epoch=85, global_step=1200
05/21/2022 05:32:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.01 on epoch=86
05/21/2022 05:32:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/21/2022 05:32:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.11 on epoch=87
05/21/2022 05:32:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.02 on epoch=88
05/21/2022 05:32:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.07 on epoch=89
05/21/2022 05:32:38 - INFO - __main__ - Global step 1250 Train loss 1.05 Classification-F1 0.38216840101473826 on epoch=89
05/21/2022 05:32:38 - INFO - __main__ - Saving model with best Classification-F1: 0.34806335312967424 -> 0.38216840101473826 on epoch=89, global_step=1250
05/21/2022 05:32:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.91 on epoch=89
05/21/2022 05:32:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.93 on epoch=90
05/21/2022 05:32:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.98 on epoch=91
05/21/2022 05:32:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.97 on epoch=92
05/21/2022 05:32:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=92
05/21/2022 05:32:48 - INFO - __main__ - Global step 1300 Train loss 0.98 Classification-F1 0.3875282221753237 on epoch=92
05/21/2022 05:32:48 - INFO - __main__ - Saving model with best Classification-F1: 0.38216840101473826 -> 0.3875282221753237 on epoch=92, global_step=1300
05/21/2022 05:32:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.98 on epoch=93
05/21/2022 05:32:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.08 on epoch=94
05/21/2022 05:32:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.91 on epoch=94
05/21/2022 05:32:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.96 on epoch=95
05/21/2022 05:32:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.94 on epoch=96
05/21/2022 05:32:58 - INFO - __main__ - Global step 1350 Train loss 0.97 Classification-F1 0.42243569823875426 on epoch=96
05/21/2022 05:32:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3875282221753237 -> 0.42243569823875426 on epoch=96, global_step=1350
05/21/2022 05:32:59 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.96 on epoch=97
05/21/2022 05:33:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.00 on epoch=97
05/21/2022 05:33:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.92 on epoch=98
05/21/2022 05:33:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.94 on epoch=99
05/21/2022 05:33:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.92 on epoch=99
05/21/2022 05:33:08 - INFO - __main__ - Global step 1400 Train loss 0.95 Classification-F1 0.46936844209583717 on epoch=99
05/21/2022 05:33:08 - INFO - __main__ - Saving model with best Classification-F1: 0.42243569823875426 -> 0.46936844209583717 on epoch=99, global_step=1400
05/21/2022 05:33:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.94 on epoch=100
05/21/2022 05:33:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.93 on epoch=101
05/21/2022 05:33:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.02 on epoch=102
05/21/2022 05:33:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.95 on epoch=102
05/21/2022 05:33:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.02 on epoch=103
05/21/2022 05:33:18 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.4525355104665449 on epoch=103
05/21/2022 05:33:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.88 on epoch=104
05/21/2022 05:33:21 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.90 on epoch=104
05/21/2022 05:33:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.94 on epoch=105
05/21/2022 05:33:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.88 on epoch=106
05/21/2022 05:33:25 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.85 on epoch=107
05/21/2022 05:33:28 - INFO - __main__ - Global step 1500 Train loss 0.89 Classification-F1 0.4940221312176071 on epoch=107
05/21/2022 05:33:28 - INFO - __main__ - Saving model with best Classification-F1: 0.46936844209583717 -> 0.4940221312176071 on epoch=107, global_step=1500
05/21/2022 05:33:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.85 on epoch=107
05/21/2022 05:33:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.77 on epoch=108
05/21/2022 05:33:32 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.83 on epoch=109
05/21/2022 05:33:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.77 on epoch=109
05/21/2022 05:33:35 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.87 on epoch=110
05/21/2022 05:33:38 - INFO - __main__ - Global step 1550 Train loss 0.82 Classification-F1 0.5083913693625749 on epoch=110
05/21/2022 05:33:38 - INFO - __main__ - Saving model with best Classification-F1: 0.4940221312176071 -> 0.5083913693625749 on epoch=110, global_step=1550
05/21/2022 05:33:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.87 on epoch=111
05/21/2022 05:33:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.90 on epoch=112
05/21/2022 05:33:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.70 on epoch=112
05/21/2022 05:33:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.78 on epoch=113
05/21/2022 05:33:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.83 on epoch=114
05/21/2022 05:33:48 - INFO - __main__ - Global step 1600 Train loss 0.82 Classification-F1 0.5174731922274491 on epoch=114
05/21/2022 05:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5083913693625749 -> 0.5174731922274491 on epoch=114, global_step=1600
05/21/2022 05:33:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.90 on epoch=114
05/21/2022 05:33:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.76 on epoch=115
05/21/2022 05:33:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.81 on epoch=116
05/21/2022 05:33:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.85 on epoch=117
05/21/2022 05:33:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.79 on epoch=117
05/21/2022 05:33:58 - INFO - __main__ - Global step 1650 Train loss 0.82 Classification-F1 0.5451205044093885 on epoch=117
05/21/2022 05:33:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5174731922274491 -> 0.5451205044093885 on epoch=117, global_step=1650
05/21/2022 05:33:59 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.77 on epoch=118
05/21/2022 05:34:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.81 on epoch=119
05/21/2022 05:34:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.78 on epoch=119
05/21/2022 05:34:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.81 on epoch=120
05/21/2022 05:34:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.67 on epoch=121
05/21/2022 05:34:08 - INFO - __main__ - Global step 1700 Train loss 0.77 Classification-F1 0.4919108200670532 on epoch=121
05/21/2022 05:34:09 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.70 on epoch=122
05/21/2022 05:34:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.78 on epoch=122
05/21/2022 05:34:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.73 on epoch=123
05/21/2022 05:34:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.71 on epoch=124
05/21/2022 05:34:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.82 on epoch=124
05/21/2022 05:34:18 - INFO - __main__ - Global step 1750 Train loss 0.75 Classification-F1 0.509559247238019 on epoch=124
05/21/2022 05:34:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/21/2022 05:34:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.75 on epoch=126
05/21/2022 05:34:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.67 on epoch=127
05/21/2022 05:34:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.71 on epoch=127
05/21/2022 05:34:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.67 on epoch=128
05/21/2022 05:34:28 - INFO - __main__ - Global step 1800 Train loss 0.70 Classification-F1 0.5315294940748904 on epoch=128
05/21/2022 05:34:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.75 on epoch=129
05/21/2022 05:34:30 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.70 on epoch=129
05/21/2022 05:34:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.65 on epoch=130
05/21/2022 05:34:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.70 on epoch=131
05/21/2022 05:34:34 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.71 on epoch=132
05/21/2022 05:34:37 - INFO - __main__ - Global step 1850 Train loss 0.70 Classification-F1 0.5077311619829451 on epoch=132
05/21/2022 05:34:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.77 on epoch=132
05/21/2022 05:34:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.68 on epoch=133
05/21/2022 05:34:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.67 on epoch=134
05/21/2022 05:34:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.72 on epoch=134
05/21/2022 05:34:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.71 on epoch=135
05/21/2022 05:34:47 - INFO - __main__ - Global step 1900 Train loss 0.71 Classification-F1 0.5399268935940604 on epoch=135
05/21/2022 05:34:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.67 on epoch=136
05/21/2022 05:34:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.77 on epoch=137
05/21/2022 05:34:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.68 on epoch=137
05/21/2022 05:34:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/21/2022 05:34:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.62 on epoch=139
05/21/2022 05:34:57 - INFO - __main__ - Global step 1950 Train loss 0.70 Classification-F1 0.5391985936447581 on epoch=139
05/21/2022 05:34:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.70 on epoch=139
05/21/2022 05:35:00 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.63 on epoch=140
05/21/2022 05:35:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.66 on epoch=141
05/21/2022 05:35:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.60 on epoch=142
05/21/2022 05:35:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.64 on epoch=142
05/21/2022 05:35:07 - INFO - __main__ - Global step 2000 Train loss 0.65 Classification-F1 0.5059524267657879 on epoch=142
05/21/2022 05:35:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.67 on epoch=143
05/21/2022 05:35:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.67 on epoch=144
05/21/2022 05:35:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.66 on epoch=144
05/21/2022 05:35:12 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.65 on epoch=145
05/21/2022 05:35:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/21/2022 05:35:17 - INFO - __main__ - Global step 2050 Train loss 0.66 Classification-F1 0.42088753418298863 on epoch=146
05/21/2022 05:35:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.77 on epoch=147
05/21/2022 05:35:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.67 on epoch=147
05/21/2022 05:35:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.65 on epoch=148
05/21/2022 05:35:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.69 on epoch=149
05/21/2022 05:35:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.75 on epoch=149
05/21/2022 05:35:27 - INFO - __main__ - Global step 2100 Train loss 0.71 Classification-F1 0.47938028846400726 on epoch=149
05/21/2022 05:35:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.68 on epoch=150
05/21/2022 05:35:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.61 on epoch=151
05/21/2022 05:35:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.58 on epoch=152
05/21/2022 05:35:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.71 on epoch=152
05/21/2022 05:35:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.63 on epoch=153
05/21/2022 05:35:38 - INFO - __main__ - Global step 2150 Train loss 0.64 Classification-F1 0.41135459603298846 on epoch=153
05/21/2022 05:35:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.66 on epoch=154
05/21/2022 05:35:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.66 on epoch=154
05/21/2022 05:35:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.71 on epoch=155
05/21/2022 05:35:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.62 on epoch=156
05/21/2022 05:35:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.68 on epoch=157
05/21/2022 05:35:48 - INFO - __main__ - Global step 2200 Train loss 0.67 Classification-F1 0.5283378605217686 on epoch=157
05/21/2022 05:35:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.68 on epoch=157
05/21/2022 05:35:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.66 on epoch=158
05/21/2022 05:35:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.61 on epoch=159
05/21/2022 05:35:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/21/2022 05:35:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/21/2022 05:35:58 - INFO - __main__ - Global step 2250 Train loss 0.68 Classification-F1 0.5290302982118624 on epoch=160
05/21/2022 05:35:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.56 on epoch=161
05/21/2022 05:36:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.66 on epoch=162
05/21/2022 05:36:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.61 on epoch=162
05/21/2022 05:36:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.70 on epoch=163
05/21/2022 05:36:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.57 on epoch=164
05/21/2022 05:36:08 - INFO - __main__ - Global step 2300 Train loss 0.62 Classification-F1 0.45205589272409546 on epoch=164
05/21/2022 05:36:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.67 on epoch=164
05/21/2022 05:36:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.70 on epoch=165
05/21/2022 05:36:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.62 on epoch=166
05/21/2022 05:36:13 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.68 on epoch=167
05/21/2022 05:36:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.66 on epoch=167
05/21/2022 05:36:18 - INFO - __main__ - Global step 2350 Train loss 0.66 Classification-F1 0.4622387271992328 on epoch=167
05/21/2022 05:36:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.63 on epoch=168
05/21/2022 05:36:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.66 on epoch=169
05/21/2022 05:36:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.58 on epoch=169
05/21/2022 05:36:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.62 on epoch=170
05/21/2022 05:36:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.65 on epoch=171
05/21/2022 05:36:28 - INFO - __main__ - Global step 2400 Train loss 0.63 Classification-F1 0.504928620456147 on epoch=171
05/21/2022 05:36:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.57 on epoch=172
05/21/2022 05:36:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.70 on epoch=172
05/21/2022 05:36:32 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.63 on epoch=173
05/21/2022 05:36:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.62 on epoch=174
05/21/2022 05:36:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.58 on epoch=174
05/21/2022 05:36:38 - INFO - __main__ - Global step 2450 Train loss 0.62 Classification-F1 0.45292572023328764 on epoch=174
05/21/2022 05:36:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.61 on epoch=175
05/21/2022 05:36:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.56 on epoch=176
05/21/2022 05:36:42 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.60 on epoch=177
05/21/2022 05:36:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.58 on epoch=177
05/21/2022 05:36:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.63 on epoch=178
05/21/2022 05:36:49 - INFO - __main__ - Global step 2500 Train loss 0.60 Classification-F1 0.4696354581058407 on epoch=178
05/21/2022 05:36:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.68 on epoch=179
05/21/2022 05:36:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.60 on epoch=179
05/21/2022 05:36:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.65 on epoch=180
05/21/2022 05:36:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.64 on epoch=181
05/21/2022 05:36:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.56 on epoch=182
05/21/2022 05:36:59 - INFO - __main__ - Global step 2550 Train loss 0.62 Classification-F1 0.46752012148416855 on epoch=182
05/21/2022 05:37:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/21/2022 05:37:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.60 on epoch=183
05/21/2022 05:37:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.67 on epoch=184
05/21/2022 05:37:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.53 on epoch=184
05/21/2022 05:37:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/21/2022 05:37:09 - INFO - __main__ - Global step 2600 Train loss 0.61 Classification-F1 0.502043806049571 on epoch=185
05/21/2022 05:37:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.54 on epoch=186
05/21/2022 05:37:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.69 on epoch=187
05/21/2022 05:37:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.63 on epoch=187
05/21/2022 05:37:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.66 on epoch=188
05/21/2022 05:37:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.64 on epoch=189
05/21/2022 05:37:19 - INFO - __main__ - Global step 2650 Train loss 0.63 Classification-F1 0.46489714715078917 on epoch=189
05/21/2022 05:37:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.60 on epoch=189
05/21/2022 05:37:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.69 on epoch=190
05/21/2022 05:37:23 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.53 on epoch=191
05/21/2022 05:37:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.62 on epoch=192
05/21/2022 05:37:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.72 on epoch=192
05/21/2022 05:37:29 - INFO - __main__ - Global step 2700 Train loss 0.63 Classification-F1 0.4486575016695601 on epoch=192
05/21/2022 05:37:30 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.58 on epoch=193
05/21/2022 05:37:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.53 on epoch=194
05/21/2022 05:37:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.69 on epoch=194
05/21/2022 05:37:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.53 on epoch=195
05/21/2022 05:37:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.58 on epoch=196
05/21/2022 05:37:39 - INFO - __main__ - Global step 2750 Train loss 0.58 Classification-F1 0.5028305654763484 on epoch=196
05/21/2022 05:37:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.63 on epoch=197
05/21/2022 05:37:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.59 on epoch=197
05/21/2022 05:37:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.71 on epoch=198
05/21/2022 05:37:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.66 on epoch=199
05/21/2022 05:37:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.53 on epoch=199
05/21/2022 05:37:50 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.5061377064972391 on epoch=199
05/21/2022 05:37:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.63 on epoch=200
05/21/2022 05:37:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.57 on epoch=201
05/21/2022 05:37:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.61 on epoch=202
05/21/2022 05:37:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.57 on epoch=202
05/21/2022 05:37:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.58 on epoch=203
05/21/2022 05:38:00 - INFO - __main__ - Global step 2850 Train loss 0.59 Classification-F1 0.5031510894281706 on epoch=203
05/21/2022 05:38:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.57 on epoch=204
05/21/2022 05:38:03 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.61 on epoch=204
05/21/2022 05:38:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.59 on epoch=205
05/21/2022 05:38:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/21/2022 05:38:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.52 on epoch=207
05/21/2022 05:38:10 - INFO - __main__ - Global step 2900 Train loss 0.58 Classification-F1 0.4526871050483903 on epoch=207
05/21/2022 05:38:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.66 on epoch=207
05/21/2022 05:38:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.60 on epoch=208
05/21/2022 05:38:14 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.61 on epoch=209
05/21/2022 05:38:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.56 on epoch=209
05/21/2022 05:38:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.58 on epoch=210
05/21/2022 05:38:21 - INFO - __main__ - Global step 2950 Train loss 0.60 Classification-F1 0.4780956162273541 on epoch=210
05/21/2022 05:38:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.50 on epoch=211
05/21/2022 05:38:23 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.67 on epoch=212
05/21/2022 05:38:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.55 on epoch=212
05/21/2022 05:38:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.59 on epoch=213
05/21/2022 05:38:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.63 on epoch=214
05/21/2022 05:38:28 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:38:28 - INFO - __main__ - Printing 3 examples
05/21/2022 05:38:28 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:38:28 - INFO - __main__ - ['Plant']
05/21/2022 05:38:28 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:38:28 - INFO - __main__ - ['Plant']
05/21/2022 05:38:28 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:38:28 - INFO - __main__ - ['Plant']
05/21/2022 05:38:28 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:38:28 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:38:29 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:38:29 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:38:29 - INFO - __main__ - Printing 3 examples
05/21/2022 05:38:29 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:38:29 - INFO - __main__ - ['Plant']
05/21/2022 05:38:29 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:38:29 - INFO - __main__ - ['Plant']
05/21/2022 05:38:29 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:38:29 - INFO - __main__ - ['Plant']
05/21/2022 05:38:29 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:38:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:38:29 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:38:31 - INFO - __main__ - Global step 3000 Train loss 0.59 Classification-F1 0.4556341274369846 on epoch=214
05/21/2022 05:38:31 - INFO - __main__ - save last model!
05/21/2022 05:38:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:38:32 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:38:32 - INFO - __main__ - Printing 3 examples
05/21/2022 05:38:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:38:32 - INFO - __main__ - ['Animal']
05/21/2022 05:38:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:38:32 - INFO - __main__ - ['Animal']
05/21/2022 05:38:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:38:32 - INFO - __main__ - ['Village']
05/21/2022 05:38:32 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:38:33 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:38:35 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:38:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:38:35 - INFO - __main__ - Starting training!
05/21/2022 05:38:37 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 05:39:47 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
05/21/2022 05:39:47 - INFO - __main__ - Classification-F1 on test data: 0.1490
05/21/2022 05:39:48 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.5451205044093885, test_performance=0.1490095654550946
05/21/2022 05:39:48 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
05/21/2022 05:39:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:39:49 - INFO - __main__ - Printing 3 examples
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:39:49 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:39:49 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:39:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:39:49 - INFO - __main__ - Printing 3 examples
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:39:49 - INFO - __main__ - ['Plant']
05/21/2022 05:39:49 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:39:49 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:39:50 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:39:55 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:39:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:39:55 - INFO - __main__ - Starting training!
05/21/2022 05:39:57 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/21/2022 05:39:58 - INFO - __main__ - Step 20 Global step 20 Train loss 7.05 on epoch=1
05/21/2022 05:39:59 - INFO - __main__ - Step 30 Global step 30 Train loss 6.54 on epoch=2
05/21/2022 05:40:01 - INFO - __main__ - Step 40 Global step 40 Train loss 6.44 on epoch=2
05/21/2022 05:40:02 - INFO - __main__ - Step 50 Global step 50 Train loss 5.89 on epoch=3
05/21/2022 05:40:05 - INFO - __main__ - Global step 50 Train loss 6.70 Classification-F1 0.0 on epoch=3
05/21/2022 05:40:05 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 05:40:06 - INFO - __main__ - Step 60 Global step 60 Train loss 5.64 on epoch=4
05/21/2022 05:40:07 - INFO - __main__ - Step 70 Global step 70 Train loss 5.26 on epoch=4
05/21/2022 05:40:09 - INFO - __main__ - Step 80 Global step 80 Train loss 5.04 on epoch=5
05/21/2022 05:40:10 - INFO - __main__ - Step 90 Global step 90 Train loss 4.83 on epoch=6
05/21/2022 05:40:11 - INFO - __main__ - Step 100 Global step 100 Train loss 4.62 on epoch=7
05/21/2022 05:40:14 - INFO - __main__ - Global step 100 Train loss 5.08 Classification-F1 0.0 on epoch=7
05/21/2022 05:40:16 - INFO - __main__ - Step 110 Global step 110 Train loss 4.44 on epoch=7
05/21/2022 05:40:17 - INFO - __main__ - Step 120 Global step 120 Train loss 4.26 on epoch=8
05/21/2022 05:40:18 - INFO - __main__ - Step 130 Global step 130 Train loss 4.06 on epoch=9
05/21/2022 05:40:19 - INFO - __main__ - Step 140 Global step 140 Train loss 3.81 on epoch=9
05/21/2022 05:40:21 - INFO - __main__ - Step 150 Global step 150 Train loss 3.95 on epoch=10
05/21/2022 05:40:24 - INFO - __main__ - Global step 150 Train loss 4.10 Classification-F1 0.0 on epoch=10
05/21/2022 05:40:25 - INFO - __main__ - Step 160 Global step 160 Train loss 3.68 on epoch=11
05/21/2022 05:40:26 - INFO - __main__ - Step 170 Global step 170 Train loss 3.55 on epoch=12
05/21/2022 05:40:27 - INFO - __main__ - Step 180 Global step 180 Train loss 3.47 on epoch=12
05/21/2022 05:40:29 - INFO - __main__ - Step 190 Global step 190 Train loss 3.31 on epoch=13
05/21/2022 05:40:30 - INFO - __main__ - Step 200 Global step 200 Train loss 3.27 on epoch=14
05/21/2022 05:40:33 - INFO - __main__ - Global step 200 Train loss 3.45 Classification-F1 0.002530044275774826 on epoch=14
05/21/2022 05:40:33 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.002530044275774826 on epoch=14, global_step=200
05/21/2022 05:40:34 - INFO - __main__ - Step 210 Global step 210 Train loss 3.02 on epoch=14
05/21/2022 05:40:35 - INFO - __main__ - Step 220 Global step 220 Train loss 3.14 on epoch=15
05/21/2022 05:40:36 - INFO - __main__ - Step 230 Global step 230 Train loss 3.02 on epoch=16
05/21/2022 05:40:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.89 on epoch=17
05/21/2022 05:40:39 - INFO - __main__ - Step 250 Global step 250 Train loss 2.79 on epoch=17
05/21/2022 05:40:41 - INFO - __main__ - Global step 250 Train loss 2.97 Classification-F1 0.005490196078431373 on epoch=17
05/21/2022 05:40:41 - INFO - __main__ - Saving model with best Classification-F1: 0.002530044275774826 -> 0.005490196078431373 on epoch=17, global_step=250
05/21/2022 05:40:43 - INFO - __main__ - Step 260 Global step 260 Train loss 2.72 on epoch=18
05/21/2022 05:40:44 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/21/2022 05:40:45 - INFO - __main__ - Step 280 Global step 280 Train loss 2.53 on epoch=19
05/21/2022 05:40:46 - INFO - __main__ - Step 290 Global step 290 Train loss 2.59 on epoch=20
05/21/2022 05:40:47 - INFO - __main__ - Step 300 Global step 300 Train loss 2.40 on epoch=21
05/21/2022 05:40:49 - INFO - __main__ - Global step 300 Train loss 2.57 Classification-F1 0.00892608089260809 on epoch=21
05/21/2022 05:40:49 - INFO - __main__ - Saving model with best Classification-F1: 0.005490196078431373 -> 0.00892608089260809 on epoch=21, global_step=300
05/21/2022 05:40:51 - INFO - __main__ - Step 310 Global step 310 Train loss 2.43 on epoch=22
05/21/2022 05:40:52 - INFO - __main__ - Step 320 Global step 320 Train loss 2.37 on epoch=22
05/21/2022 05:40:53 - INFO - __main__ - Step 330 Global step 330 Train loss 2.36 on epoch=23
05/21/2022 05:40:54 - INFO - __main__ - Step 340 Global step 340 Train loss 2.31 on epoch=24
05/21/2022 05:40:56 - INFO - __main__ - Step 350 Global step 350 Train loss 2.25 on epoch=24
05/21/2022 05:40:57 - INFO - __main__ - Global step 350 Train loss 2.35 Classification-F1 0.009523809523809523 on epoch=24
05/21/2022 05:40:57 - INFO - __main__ - Saving model with best Classification-F1: 0.00892608089260809 -> 0.009523809523809523 on epoch=24, global_step=350
05/21/2022 05:40:59 - INFO - __main__ - Step 360 Global step 360 Train loss 2.28 on epoch=25
05/21/2022 05:41:00 - INFO - __main__ - Step 370 Global step 370 Train loss 2.12 on epoch=26
05/21/2022 05:41:01 - INFO - __main__ - Step 380 Global step 380 Train loss 2.20 on epoch=27
05/21/2022 05:41:02 - INFO - __main__ - Step 390 Global step 390 Train loss 2.19 on epoch=27
05/21/2022 05:41:04 - INFO - __main__ - Step 400 Global step 400 Train loss 2.13 on epoch=28
05/21/2022 05:41:05 - INFO - __main__ - Global step 400 Train loss 2.18 Classification-F1 0.01083276912660799 on epoch=28
05/21/2022 05:41:05 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.01083276912660799 on epoch=28, global_step=400
05/21/2022 05:41:07 - INFO - __main__ - Step 410 Global step 410 Train loss 2.03 on epoch=29
05/21/2022 05:41:08 - INFO - __main__ - Step 420 Global step 420 Train loss 2.04 on epoch=29
05/21/2022 05:41:09 - INFO - __main__ - Step 430 Global step 430 Train loss 2.06 on epoch=30
05/21/2022 05:41:10 - INFO - __main__ - Step 440 Global step 440 Train loss 1.90 on epoch=31
05/21/2022 05:41:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=32
05/21/2022 05:41:14 - INFO - __main__ - Global step 450 Train loss 1.98 Classification-F1 0.034133420493967795 on epoch=32
05/21/2022 05:41:14 - INFO - __main__ - Saving model with best Classification-F1: 0.01083276912660799 -> 0.034133420493967795 on epoch=32, global_step=450
05/21/2022 05:41:15 - INFO - __main__ - Step 460 Global step 460 Train loss 1.88 on epoch=32
05/21/2022 05:41:16 - INFO - __main__ - Step 470 Global step 470 Train loss 1.84 on epoch=33
05/21/2022 05:41:17 - INFO - __main__ - Step 480 Global step 480 Train loss 1.83 on epoch=34
05/21/2022 05:41:19 - INFO - __main__ - Step 490 Global step 490 Train loss 1.78 on epoch=34
05/21/2022 05:41:20 - INFO - __main__ - Step 500 Global step 500 Train loss 1.85 on epoch=35
05/21/2022 05:41:22 - INFO - __main__ - Global step 500 Train loss 1.84 Classification-F1 0.026049068302589427 on epoch=35
05/21/2022 05:41:23 - INFO - __main__ - Step 510 Global step 510 Train loss 1.64 on epoch=36
05/21/2022 05:41:24 - INFO - __main__ - Step 520 Global step 520 Train loss 1.71 on epoch=37
05/21/2022 05:41:25 - INFO - __main__ - Step 530 Global step 530 Train loss 1.72 on epoch=37
05/21/2022 05:41:27 - INFO - __main__ - Step 540 Global step 540 Train loss 1.70 on epoch=38
05/21/2022 05:41:28 - INFO - __main__ - Step 550 Global step 550 Train loss 1.63 on epoch=39
05/21/2022 05:41:30 - INFO - __main__ - Global step 550 Train loss 1.68 Classification-F1 0.03996362433862433 on epoch=39
05/21/2022 05:41:30 - INFO - __main__ - Saving model with best Classification-F1: 0.034133420493967795 -> 0.03996362433862433 on epoch=39, global_step=550
05/21/2022 05:41:31 - INFO - __main__ - Step 560 Global step 560 Train loss 1.58 on epoch=39
05/21/2022 05:41:32 - INFO - __main__ - Step 570 Global step 570 Train loss 1.58 on epoch=40
05/21/2022 05:41:34 - INFO - __main__ - Step 580 Global step 580 Train loss 1.56 on epoch=41
05/21/2022 05:41:35 - INFO - __main__ - Step 590 Global step 590 Train loss 1.58 on epoch=42
05/21/2022 05:41:36 - INFO - __main__ - Step 600 Global step 600 Train loss 1.62 on epoch=42
05/21/2022 05:41:38 - INFO - __main__ - Global step 600 Train loss 1.59 Classification-F1 0.060707955638831204 on epoch=42
05/21/2022 05:41:38 - INFO - __main__ - Saving model with best Classification-F1: 0.03996362433862433 -> 0.060707955638831204 on epoch=42, global_step=600
05/21/2022 05:41:39 - INFO - __main__ - Step 610 Global step 610 Train loss 1.45 on epoch=43
05/21/2022 05:41:41 - INFO - __main__ - Step 620 Global step 620 Train loss 1.53 on epoch=44
05/21/2022 05:41:42 - INFO - __main__ - Step 630 Global step 630 Train loss 1.50 on epoch=44
05/21/2022 05:41:43 - INFO - __main__ - Step 640 Global step 640 Train loss 1.49 on epoch=45
05/21/2022 05:41:44 - INFO - __main__ - Step 650 Global step 650 Train loss 1.40 on epoch=46
05/21/2022 05:41:46 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.0195970695970696 on epoch=46
05/21/2022 05:41:48 - INFO - __main__ - Step 660 Global step 660 Train loss 1.42 on epoch=47
05/21/2022 05:41:49 - INFO - __main__ - Step 670 Global step 670 Train loss 1.56 on epoch=47
05/21/2022 05:41:50 - INFO - __main__ - Step 680 Global step 680 Train loss 1.47 on epoch=48
05/21/2022 05:41:52 - INFO - __main__ - Step 690 Global step 690 Train loss 1.43 on epoch=49
05/21/2022 05:41:53 - INFO - __main__ - Step 700 Global step 700 Train loss 1.51 on epoch=49
05/21/2022 05:41:55 - INFO - __main__ - Global step 700 Train loss 1.48 Classification-F1 0.020545028741750054 on epoch=49
05/21/2022 05:41:56 - INFO - __main__ - Step 710 Global step 710 Train loss 1.50 on epoch=50
05/21/2022 05:41:57 - INFO - __main__ - Step 720 Global step 720 Train loss 1.32 on epoch=51
05/21/2022 05:41:59 - INFO - __main__ - Step 730 Global step 730 Train loss 1.49 on epoch=52
05/21/2022 05:42:00 - INFO - __main__ - Step 740 Global step 740 Train loss 1.33 on epoch=52
05/21/2022 05:42:01 - INFO - __main__ - Step 750 Global step 750 Train loss 1.36 on epoch=53
05/21/2022 05:42:03 - INFO - __main__ - Global step 750 Train loss 1.40 Classification-F1 0.050526777950217 on epoch=53
05/21/2022 05:42:04 - INFO - __main__ - Step 760 Global step 760 Train loss 1.45 on epoch=54
05/21/2022 05:42:05 - INFO - __main__ - Step 770 Global step 770 Train loss 1.32 on epoch=54
05/21/2022 05:42:07 - INFO - __main__ - Step 780 Global step 780 Train loss 1.28 on epoch=55
05/21/2022 05:42:08 - INFO - __main__ - Step 790 Global step 790 Train loss 1.29 on epoch=56
05/21/2022 05:42:09 - INFO - __main__ - Step 800 Global step 800 Train loss 1.32 on epoch=57
05/21/2022 05:42:12 - INFO - __main__ - Global step 800 Train loss 1.33 Classification-F1 0.06943822119138983 on epoch=57
05/21/2022 05:42:12 - INFO - __main__ - Saving model with best Classification-F1: 0.060707955638831204 -> 0.06943822119138983 on epoch=57, global_step=800
05/21/2022 05:42:13 - INFO - __main__ - Step 810 Global step 810 Train loss 1.47 on epoch=57
05/21/2022 05:42:15 - INFO - __main__ - Step 820 Global step 820 Train loss 1.36 on epoch=58
05/21/2022 05:42:16 - INFO - __main__ - Step 830 Global step 830 Train loss 1.42 on epoch=59
05/21/2022 05:42:17 - INFO - __main__ - Step 840 Global step 840 Train loss 1.28 on epoch=59
05/21/2022 05:42:18 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=60
05/21/2022 05:42:20 - INFO - __main__ - Global step 850 Train loss 1.39 Classification-F1 0.044114069190088374 on epoch=60
05/21/2022 05:42:22 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/21/2022 05:42:23 - INFO - __main__ - Step 870 Global step 870 Train loss 1.28 on epoch=62
05/21/2022 05:42:24 - INFO - __main__ - Step 880 Global step 880 Train loss 1.41 on epoch=62
05/21/2022 05:42:25 - INFO - __main__ - Step 890 Global step 890 Train loss 1.28 on epoch=63
05/21/2022 05:42:27 - INFO - __main__ - Step 900 Global step 900 Train loss 1.39 on epoch=64
05/21/2022 05:42:29 - INFO - __main__ - Global step 900 Train loss 1.33 Classification-F1 0.03970641613662208 on epoch=64
05/21/2022 05:42:30 - INFO - __main__ - Step 910 Global step 910 Train loss 1.30 on epoch=64
05/21/2022 05:42:31 - INFO - __main__ - Step 920 Global step 920 Train loss 1.31 on epoch=65
05/21/2022 05:42:32 - INFO - __main__ - Step 930 Global step 930 Train loss 1.34 on epoch=66
05/21/2022 05:42:34 - INFO - __main__ - Step 940 Global step 940 Train loss 1.36 on epoch=67
05/21/2022 05:42:35 - INFO - __main__ - Step 950 Global step 950 Train loss 1.35 on epoch=67
05/21/2022 05:42:37 - INFO - __main__ - Global step 950 Train loss 1.33 Classification-F1 0.11142225815602004 on epoch=67
05/21/2022 05:42:37 - INFO - __main__ - Saving model with best Classification-F1: 0.06943822119138983 -> 0.11142225815602004 on epoch=67, global_step=950
05/21/2022 05:42:39 - INFO - __main__ - Step 960 Global step 960 Train loss 1.26 on epoch=68
05/21/2022 05:42:40 - INFO - __main__ - Step 970 Global step 970 Train loss 1.22 on epoch=69
05/21/2022 05:42:41 - INFO - __main__ - Step 980 Global step 980 Train loss 1.26 on epoch=69
05/21/2022 05:42:42 - INFO - __main__ - Step 990 Global step 990 Train loss 1.30 on epoch=70
05/21/2022 05:42:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.24 on epoch=71
05/21/2022 05:42:47 - INFO - __main__ - Global step 1000 Train loss 1.26 Classification-F1 0.16134746283508378 on epoch=71
05/21/2022 05:42:47 - INFO - __main__ - Saving model with best Classification-F1: 0.11142225815602004 -> 0.16134746283508378 on epoch=71, global_step=1000
05/21/2022 05:42:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.30 on epoch=72
05/21/2022 05:42:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.23 on epoch=72
05/21/2022 05:42:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.29 on epoch=73
05/21/2022 05:42:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.21 on epoch=74
05/21/2022 05:42:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=74
05/21/2022 05:42:56 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.25977981476750467 on epoch=74
05/21/2022 05:42:56 - INFO - __main__ - Saving model with best Classification-F1: 0.16134746283508378 -> 0.25977981476750467 on epoch=74, global_step=1050
05/21/2022 05:42:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.27 on epoch=75
05/21/2022 05:42:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.16 on epoch=76
05/21/2022 05:42:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.23 on epoch=77
05/21/2022 05:43:01 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.18 on epoch=77
05/21/2022 05:43:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.15 on epoch=78
05/21/2022 05:43:05 - INFO - __main__ - Global step 1100 Train loss 1.20 Classification-F1 0.2554424553523898 on epoch=78
05/21/2022 05:43:06 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.09 on epoch=79
05/21/2022 05:43:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.11 on epoch=79
05/21/2022 05:43:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.21 on epoch=80
05/21/2022 05:43:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.11 on epoch=81
05/21/2022 05:43:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.14 on epoch=82
05/21/2022 05:43:14 - INFO - __main__ - Global step 1150 Train loss 1.13 Classification-F1 0.31771979645600373 on epoch=82
05/21/2022 05:43:14 - INFO - __main__ - Saving model with best Classification-F1: 0.25977981476750467 -> 0.31771979645600373 on epoch=82, global_step=1150
05/21/2022 05:43:15 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.16 on epoch=82
05/21/2022 05:43:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.12 on epoch=83
05/21/2022 05:43:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.21 on epoch=84
05/21/2022 05:43:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.06 on epoch=84
05/21/2022 05:43:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.06 on epoch=85
05/21/2022 05:43:24 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.3442867242670859 on epoch=85
05/21/2022 05:43:24 - INFO - __main__ - Saving model with best Classification-F1: 0.31771979645600373 -> 0.3442867242670859 on epoch=85, global_step=1200
05/21/2022 05:43:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.14 on epoch=86
05/21/2022 05:43:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.04 on epoch=87
05/21/2022 05:43:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.22 on epoch=87
05/21/2022 05:43:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.12 on epoch=88
05/21/2022 05:43:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.05 on epoch=89
05/21/2022 05:43:33 - INFO - __main__ - Global step 1250 Train loss 1.11 Classification-F1 0.4456553088342209 on epoch=89
05/21/2022 05:43:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3442867242670859 -> 0.4456553088342209 on epoch=89, global_step=1250
05/21/2022 05:43:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.08 on epoch=89
05/21/2022 05:43:36 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.11 on epoch=90
05/21/2022 05:43:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.06 on epoch=91
05/21/2022 05:43:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.11 on epoch=92
05/21/2022 05:43:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.13 on epoch=92
05/21/2022 05:43:43 - INFO - __main__ - Global step 1300 Train loss 1.10 Classification-F1 0.4388525810890392 on epoch=92
05/21/2022 05:43:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.98 on epoch=93
05/21/2022 05:43:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.09 on epoch=94
05/21/2022 05:43:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.97 on epoch=94
05/21/2022 05:43:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.03 on epoch=95
05/21/2022 05:43:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.92 on epoch=96
05/21/2022 05:43:52 - INFO - __main__ - Global step 1350 Train loss 1.00 Classification-F1 0.42621259067053263 on epoch=96
05/21/2022 05:43:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.01 on epoch=97
05/21/2022 05:43:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.08 on epoch=97
05/21/2022 05:43:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.00 on epoch=98
05/21/2022 05:43:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.00 on epoch=99
05/21/2022 05:43:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.01 on epoch=99
05/21/2022 05:44:02 - INFO - __main__ - Global step 1400 Train loss 1.02 Classification-F1 0.474250777363385 on epoch=99
05/21/2022 05:44:02 - INFO - __main__ - Saving model with best Classification-F1: 0.4456553088342209 -> 0.474250777363385 on epoch=99, global_step=1400
05/21/2022 05:44:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.93 on epoch=100
05/21/2022 05:44:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.99 on epoch=101
05/21/2022 05:44:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.00 on epoch=102
05/21/2022 05:44:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.01 on epoch=102
05/21/2022 05:44:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.91 on epoch=103
05/21/2022 05:44:11 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.4342149569980718 on epoch=103
05/21/2022 05:44:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.91 on epoch=104
05/21/2022 05:44:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.90 on epoch=104
05/21/2022 05:44:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.91 on epoch=105
05/21/2022 05:44:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.00 on epoch=106
05/21/2022 05:44:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.00 on epoch=107
05/21/2022 05:44:21 - INFO - __main__ - Global step 1500 Train loss 0.94 Classification-F1 0.4457592809389973 on epoch=107
05/21/2022 05:44:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.01 on epoch=107
05/21/2022 05:44:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.85 on epoch=108
05/21/2022 05:44:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.99 on epoch=109
05/21/2022 05:44:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.96 on epoch=109
05/21/2022 05:44:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.88 on epoch=110
05/21/2022 05:44:30 - INFO - __main__ - Global step 1550 Train loss 0.94 Classification-F1 0.4464614953989707 on epoch=110
05/21/2022 05:44:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.89 on epoch=111
05/21/2022 05:44:33 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.86 on epoch=112
05/21/2022 05:44:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.97 on epoch=112
05/21/2022 05:44:36 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.92 on epoch=113
05/21/2022 05:44:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.82 on epoch=114
05/21/2022 05:44:40 - INFO - __main__ - Global step 1600 Train loss 0.89 Classification-F1 0.5185460927442817 on epoch=114
05/21/2022 05:44:40 - INFO - __main__ - Saving model with best Classification-F1: 0.474250777363385 -> 0.5185460927442817 on epoch=114, global_step=1600
05/21/2022 05:44:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.96 on epoch=114
05/21/2022 05:44:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.83 on epoch=115
05/21/2022 05:44:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.85 on epoch=116
05/21/2022 05:44:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.79 on epoch=117
05/21/2022 05:44:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.74 on epoch=117
05/21/2022 05:44:50 - INFO - __main__ - Global step 1650 Train loss 0.83 Classification-F1 0.45009135125995453 on epoch=117
05/21/2022 05:44:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.88 on epoch=118
05/21/2022 05:44:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.83 on epoch=119
05/21/2022 05:44:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.83 on epoch=119
05/21/2022 05:44:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.93 on epoch=120
05/21/2022 05:44:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.82 on epoch=121
05/21/2022 05:45:00 - INFO - __main__ - Global step 1700 Train loss 0.86 Classification-F1 0.49069730582644916 on epoch=121
05/21/2022 05:45:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.81 on epoch=122
05/21/2022 05:45:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=122
05/21/2022 05:45:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.84 on epoch=123
05/21/2022 05:45:05 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.85 on epoch=124
05/21/2022 05:45:06 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.80 on epoch=124
05/21/2022 05:45:10 - INFO - __main__ - Global step 1750 Train loss 0.85 Classification-F1 0.4850740572575491 on epoch=124
05/21/2022 05:45:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.76 on epoch=125
05/21/2022 05:45:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.83 on epoch=126
05/21/2022 05:45:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.85 on epoch=127
05/21/2022 05:45:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.83 on epoch=127
05/21/2022 05:45:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.88 on epoch=128
05/21/2022 05:45:20 - INFO - __main__ - Global step 1800 Train loss 0.83 Classification-F1 0.4155008599036395 on epoch=128
05/21/2022 05:45:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.84 on epoch=129
05/21/2022 05:45:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.88 on epoch=129
05/21/2022 05:45:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.75 on epoch=130
05/21/2022 05:45:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.82 on epoch=131
05/21/2022 05:45:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.86 on epoch=132
05/21/2022 05:45:30 - INFO - __main__ - Global step 1850 Train loss 0.83 Classification-F1 0.4638013882623782 on epoch=132
05/21/2022 05:45:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.85 on epoch=132
05/21/2022 05:45:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.83 on epoch=133
05/21/2022 05:45:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.79 on epoch=134
05/21/2022 05:45:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.99 on epoch=134
05/21/2022 05:45:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.87 on epoch=135
05/21/2022 05:45:40 - INFO - __main__ - Global step 1900 Train loss 0.86 Classification-F1 0.41182997628515194 on epoch=135
05/21/2022 05:45:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.71 on epoch=136
05/21/2022 05:45:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.81 on epoch=137
05/21/2022 05:45:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/21/2022 05:45:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.75 on epoch=138
05/21/2022 05:45:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.73 on epoch=139
05/21/2022 05:45:49 - INFO - __main__ - Global step 1950 Train loss 0.76 Classification-F1 0.43181665859582796 on epoch=139
05/21/2022 05:45:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.69 on epoch=139
05/21/2022 05:45:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.68 on epoch=140
05/21/2022 05:45:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.77 on epoch=141
05/21/2022 05:45:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.75 on epoch=142
05/21/2022 05:45:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.77 on epoch=142
05/21/2022 05:45:59 - INFO - __main__ - Global step 2000 Train loss 0.73 Classification-F1 0.4544399551491709 on epoch=142
05/21/2022 05:46:00 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.81 on epoch=143
05/21/2022 05:46:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.82 on epoch=144
05/21/2022 05:46:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.78 on epoch=144
05/21/2022 05:46:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.81 on epoch=145
05/21/2022 05:46:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.73 on epoch=146
05/21/2022 05:46:09 - INFO - __main__ - Global step 2050 Train loss 0.79 Classification-F1 0.3853243129934757 on epoch=146
05/21/2022 05:46:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.75 on epoch=147
05/21/2022 05:46:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.73 on epoch=147
05/21/2022 05:46:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.72 on epoch=148
05/21/2022 05:46:14 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.73 on epoch=149
05/21/2022 05:46:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.74 on epoch=149
05/21/2022 05:46:19 - INFO - __main__ - Global step 2100 Train loss 0.73 Classification-F1 0.49391005923900655 on epoch=149
05/21/2022 05:46:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.74 on epoch=150
05/21/2022 05:46:21 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.78 on epoch=151
05/21/2022 05:46:23 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.67 on epoch=152
05/21/2022 05:46:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.73 on epoch=152
05/21/2022 05:46:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.70 on epoch=153
05/21/2022 05:46:29 - INFO - __main__ - Global step 2150 Train loss 0.73 Classification-F1 0.42771344563243857 on epoch=153
05/21/2022 05:46:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.74 on epoch=154
05/21/2022 05:46:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.79 on epoch=154
05/21/2022 05:46:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.81 on epoch=155
05/21/2022 05:46:34 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.75 on epoch=156
05/21/2022 05:46:35 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.80 on epoch=157
05/21/2022 05:46:39 - INFO - __main__ - Global step 2200 Train loss 0.78 Classification-F1 0.3922719280128331 on epoch=157
05/21/2022 05:46:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.78 on epoch=157
05/21/2022 05:46:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.74 on epoch=158
05/21/2022 05:46:42 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.77 on epoch=159
05/21/2022 05:46:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.75 on epoch=159
05/21/2022 05:46:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.86 on epoch=160
05/21/2022 05:46:48 - INFO - __main__ - Global step 2250 Train loss 0.78 Classification-F1 0.4405858438883079 on epoch=160
05/21/2022 05:46:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.78 on epoch=161
05/21/2022 05:46:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.75 on epoch=162
05/21/2022 05:46:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.81 on epoch=162
05/21/2022 05:46:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.78 on epoch=163
05/21/2022 05:46:55 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.80 on epoch=164
05/21/2022 05:46:59 - INFO - __main__ - Global step 2300 Train loss 0.78 Classification-F1 0.44904966092607185 on epoch=164
05/21/2022 05:47:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.84 on epoch=164
05/21/2022 05:47:01 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.78 on epoch=165
05/21/2022 05:47:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.78 on epoch=166
05/21/2022 05:47:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.78 on epoch=167
05/21/2022 05:47:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.82 on epoch=167
05/21/2022 05:47:08 - INFO - __main__ - Global step 2350 Train loss 0.80 Classification-F1 0.3845386778635046 on epoch=167
05/21/2022 05:47:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.74 on epoch=168
05/21/2022 05:47:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.82 on epoch=169
05/21/2022 05:47:12 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.77 on epoch=169
05/21/2022 05:47:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.70 on epoch=170
05/21/2022 05:47:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.69 on epoch=171
05/21/2022 05:47:18 - INFO - __main__ - Global step 2400 Train loss 0.74 Classification-F1 0.40877091022026135 on epoch=171
05/21/2022 05:47:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.80 on epoch=172
05/21/2022 05:47:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.72 on epoch=172
05/21/2022 05:47:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.79 on epoch=173
05/21/2022 05:47:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.78 on epoch=174
05/21/2022 05:47:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.86 on epoch=174
05/21/2022 05:47:28 - INFO - __main__ - Global step 2450 Train loss 0.79 Classification-F1 0.3875351177337717 on epoch=174
05/21/2022 05:47:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.86 on epoch=175
05/21/2022 05:47:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.82 on epoch=176
05/21/2022 05:47:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.87 on epoch=177
05/21/2022 05:47:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.76 on epoch=177
05/21/2022 05:47:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.66 on epoch=178
05/21/2022 05:47:38 - INFO - __main__ - Global step 2500 Train loss 0.79 Classification-F1 0.4368257148599654 on epoch=178
05/21/2022 05:47:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.69 on epoch=179
05/21/2022 05:47:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.65 on epoch=179
05/21/2022 05:47:42 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.76 on epoch=180
05/21/2022 05:47:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.71 on epoch=181
05/21/2022 05:47:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.62 on epoch=182
05/21/2022 05:47:48 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.4707824754818409 on epoch=182
05/21/2022 05:47:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.69 on epoch=182
05/21/2022 05:47:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.69 on epoch=183
05/21/2022 05:47:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.80 on epoch=184
05/21/2022 05:47:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/21/2022 05:47:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.70 on epoch=185
05/21/2022 05:47:57 - INFO - __main__ - Global step 2600 Train loss 0.72 Classification-F1 0.4466566312651423 on epoch=185
05/21/2022 05:47:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.68 on epoch=186
05/21/2022 05:48:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.74 on epoch=187
05/21/2022 05:48:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.70 on epoch=187
05/21/2022 05:48:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/21/2022 05:48:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.74 on epoch=189
05/21/2022 05:48:08 - INFO - __main__ - Global step 2650 Train loss 0.71 Classification-F1 0.38128984293697443 on epoch=189
05/21/2022 05:48:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.64 on epoch=189
05/21/2022 05:48:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.76 on epoch=190
05/21/2022 05:48:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.64 on epoch=191
05/21/2022 05:48:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.68 on epoch=192
05/21/2022 05:48:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.74 on epoch=192
05/21/2022 05:48:18 - INFO - __main__ - Global step 2700 Train loss 0.69 Classification-F1 0.4694359592947054 on epoch=192
05/21/2022 05:48:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.67 on epoch=193
05/21/2022 05:48:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.67 on epoch=194
05/21/2022 05:48:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/21/2022 05:48:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.75 on epoch=195
05/21/2022 05:48:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.62 on epoch=196
05/21/2022 05:48:28 - INFO - __main__ - Global step 2750 Train loss 0.68 Classification-F1 0.4905953124454761 on epoch=196
05/21/2022 05:48:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.74 on epoch=197
05/21/2022 05:48:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.65 on epoch=197
05/21/2022 05:48:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.66 on epoch=198
05/21/2022 05:48:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.73 on epoch=199
05/21/2022 05:48:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.67 on epoch=199
05/21/2022 05:48:39 - INFO - __main__ - Global step 2800 Train loss 0.69 Classification-F1 0.5005729849885869 on epoch=199
05/21/2022 05:48:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.65 on epoch=200
05/21/2022 05:48:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.76 on epoch=201
05/21/2022 05:48:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.68 on epoch=202
05/21/2022 05:48:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.64 on epoch=202
05/21/2022 05:48:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.73 on epoch=203
05/21/2022 05:48:50 - INFO - __main__ - Global step 2850 Train loss 0.69 Classification-F1 0.48186980686980685 on epoch=203
05/21/2022 05:48:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.63 on epoch=204
05/21/2022 05:48:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/21/2022 05:48:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.62 on epoch=205
05/21/2022 05:48:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.66 on epoch=206
05/21/2022 05:48:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.57 on epoch=207
05/21/2022 05:49:00 - INFO - __main__ - Global step 2900 Train loss 0.62 Classification-F1 0.40065539268381994 on epoch=207
05/21/2022 05:49:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.61 on epoch=207
05/21/2022 05:49:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.65 on epoch=208
05/21/2022 05:49:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.64 on epoch=209
05/21/2022 05:49:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.65 on epoch=209
05/21/2022 05:49:06 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.63 on epoch=210
05/21/2022 05:49:10 - INFO - __main__ - Global step 2950 Train loss 0.64 Classification-F1 0.44125545022067475 on epoch=210
05/21/2022 05:49:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.56 on epoch=211
05/21/2022 05:49:12 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.62 on epoch=212
05/21/2022 05:49:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.65 on epoch=212
05/21/2022 05:49:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.62 on epoch=213
05/21/2022 05:49:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.63 on epoch=214
05/21/2022 05:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:49:18 - INFO - __main__ - Printing 3 examples
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:49:18 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:49:18 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:49:18 - INFO - __main__ - Printing 3 examples
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:49:18 - INFO - __main__ - ['Plant']
05/21/2022 05:49:18 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:49:18 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:49:18 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:49:20 - INFO - __main__ - Global step 3000 Train loss 0.62 Classification-F1 0.38930880757379566 on epoch=214
05/21/2022 05:49:20 - INFO - __main__ - save last model!
05/21/2022 05:49:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:49:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:49:20 - INFO - __main__ - Printing 3 examples
05/21/2022 05:49:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:49:20 - INFO - __main__ - ['Animal']
05/21/2022 05:49:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:49:20 - INFO - __main__ - ['Animal']
05/21/2022 05:49:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:49:20 - INFO - __main__ - ['Village']
05/21/2022 05:49:20 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:49:22 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:49:24 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:49:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:49:24 - INFO - __main__ - Starting training!
05/21/2022 05:49:25 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 05:50:31 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
05/21/2022 05:50:32 - INFO - __main__ - Classification-F1 on test data: 0.1897
05/21/2022 05:50:32 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.5185460927442817, test_performance=0.18968790860185245
05/21/2022 05:50:32 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
05/21/2022 05:50:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:50:33 - INFO - __main__ - Printing 3 examples
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:50:33 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:50:33 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:50:33 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:50:33 - INFO - __main__ - Printing 3 examples
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceaesunflower family. The plant is native to Europe and Asia.
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
05/21/2022 05:50:33 - INFO - __main__ - ['Plant']
05/21/2022 05:50:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:50:33 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:50:33 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:50:40 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:50:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:50:40 - INFO - __main__ - Starting training!
05/21/2022 05:50:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.48 on epoch=0
05/21/2022 05:50:43 - INFO - __main__ - Step 20 Global step 20 Train loss 7.14 on epoch=1
05/21/2022 05:50:44 - INFO - __main__ - Step 30 Global step 30 Train loss 6.73 on epoch=2
05/21/2022 05:50:45 - INFO - __main__ - Step 40 Global step 40 Train loss 6.74 on epoch=2
05/21/2022 05:50:47 - INFO - __main__ - Step 50 Global step 50 Train loss 6.31 on epoch=3
05/21/2022 05:50:51 - INFO - __main__ - Global step 50 Train loss 6.88 Classification-F1 0.0 on epoch=3
05/21/2022 05:50:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 05:50:52 - INFO - __main__ - Step 60 Global step 60 Train loss 5.85 on epoch=4
05/21/2022 05:50:53 - INFO - __main__ - Step 70 Global step 70 Train loss 5.75 on epoch=4
05/21/2022 05:50:54 - INFO - __main__ - Step 80 Global step 80 Train loss 5.76 on epoch=5
05/21/2022 05:50:56 - INFO - __main__ - Step 90 Global step 90 Train loss 5.46 on epoch=6
05/21/2022 05:50:57 - INFO - __main__ - Step 100 Global step 100 Train loss 5.31 on epoch=7
05/21/2022 05:51:00 - INFO - __main__ - Global step 100 Train loss 5.63 Classification-F1 0.0 on epoch=7
05/21/2022 05:51:01 - INFO - __main__ - Step 110 Global step 110 Train loss 5.16 on epoch=7
05/21/2022 05:51:02 - INFO - __main__ - Step 120 Global step 120 Train loss 5.03 on epoch=8
05/21/2022 05:51:04 - INFO - __main__ - Step 130 Global step 130 Train loss 5.02 on epoch=9
05/21/2022 05:51:05 - INFO - __main__ - Step 140 Global step 140 Train loss 4.60 on epoch=9
05/21/2022 05:51:06 - INFO - __main__ - Step 150 Global step 150 Train loss 4.63 on epoch=10
05/21/2022 05:51:09 - INFO - __main__ - Global step 150 Train loss 4.89 Classification-F1 0.0 on epoch=10
05/21/2022 05:51:11 - INFO - __main__ - Step 160 Global step 160 Train loss 4.37 on epoch=11
05/21/2022 05:51:12 - INFO - __main__ - Step 170 Global step 170 Train loss 4.36 on epoch=12
05/21/2022 05:51:13 - INFO - __main__ - Step 180 Global step 180 Train loss 4.24 on epoch=12
05/21/2022 05:51:14 - INFO - __main__ - Step 190 Global step 190 Train loss 4.06 on epoch=13
05/21/2022 05:51:16 - INFO - __main__ - Step 200 Global step 200 Train loss 4.06 on epoch=14
05/21/2022 05:51:19 - INFO - __main__ - Global step 200 Train loss 4.22 Classification-F1 0.0 on epoch=14
05/21/2022 05:51:21 - INFO - __main__ - Step 210 Global step 210 Train loss 3.74 on epoch=14
05/21/2022 05:51:22 - INFO - __main__ - Step 220 Global step 220 Train loss 3.70 on epoch=15
05/21/2022 05:51:23 - INFO - __main__ - Step 230 Global step 230 Train loss 3.69 on epoch=16
05/21/2022 05:51:24 - INFO - __main__ - Step 240 Global step 240 Train loss 3.49 on epoch=17
05/21/2022 05:51:26 - INFO - __main__ - Step 250 Global step 250 Train loss 3.50 on epoch=17
05/21/2022 05:51:29 - INFO - __main__ - Global step 250 Train loss 3.62 Classification-F1 0.0 on epoch=17
05/21/2022 05:51:30 - INFO - __main__ - Step 260 Global step 260 Train loss 3.40 on epoch=18
05/21/2022 05:51:32 - INFO - __main__ - Step 270 Global step 270 Train loss 3.39 on epoch=19
05/21/2022 05:51:33 - INFO - __main__ - Step 280 Global step 280 Train loss 3.25 on epoch=19
05/21/2022 05:51:34 - INFO - __main__ - Step 290 Global step 290 Train loss 3.31 on epoch=20
05/21/2022 05:51:35 - INFO - __main__ - Step 300 Global step 300 Train loss 3.05 on epoch=21
05/21/2022 05:51:39 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.0060331825037707384 on epoch=21
05/21/2022 05:51:39 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0060331825037707384 on epoch=21, global_step=300
05/21/2022 05:51:40 - INFO - __main__ - Step 310 Global step 310 Train loss 3.19 on epoch=22
05/21/2022 05:51:42 - INFO - __main__ - Step 320 Global step 320 Train loss 3.02 on epoch=22
05/21/2022 05:51:43 - INFO - __main__ - Step 330 Global step 330 Train loss 3.07 on epoch=23
05/21/2022 05:51:44 - INFO - __main__ - Step 340 Global step 340 Train loss 3.02 on epoch=24
05/21/2022 05:51:46 - INFO - __main__ - Step 350 Global step 350 Train loss 2.86 on epoch=24
05/21/2022 05:51:48 - INFO - __main__ - Global step 350 Train loss 3.03 Classification-F1 0.006436781609195402 on epoch=24
05/21/2022 05:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0060331825037707384 -> 0.006436781609195402 on epoch=24, global_step=350
05/21/2022 05:51:49 - INFO - __main__ - Step 360 Global step 360 Train loss 2.92 on epoch=25
05/21/2022 05:51:50 - INFO - __main__ - Step 370 Global step 370 Train loss 2.70 on epoch=26
05/21/2022 05:51:52 - INFO - __main__ - Step 380 Global step 380 Train loss 2.72 on epoch=27
05/21/2022 05:51:53 - INFO - __main__ - Step 390 Global step 390 Train loss 2.67 on epoch=27
05/21/2022 05:51:54 - INFO - __main__ - Step 400 Global step 400 Train loss 2.67 on epoch=28
05/21/2022 05:51:57 - INFO - __main__ - Global step 400 Train loss 2.74 Classification-F1 0.008641975308641974 on epoch=28
05/21/2022 05:51:57 - INFO - __main__ - Saving model with best Classification-F1: 0.006436781609195402 -> 0.008641975308641974 on epoch=28, global_step=400
05/21/2022 05:51:58 - INFO - __main__ - Step 410 Global step 410 Train loss 2.66 on epoch=29
05/21/2022 05:51:59 - INFO - __main__ - Step 420 Global step 420 Train loss 2.49 on epoch=29
05/21/2022 05:52:00 - INFO - __main__ - Step 430 Global step 430 Train loss 2.67 on epoch=30
05/21/2022 05:52:02 - INFO - __main__ - Step 440 Global step 440 Train loss 2.42 on epoch=31
05/21/2022 05:52:03 - INFO - __main__ - Step 450 Global step 450 Train loss 2.45 on epoch=32
05/21/2022 05:52:05 - INFO - __main__ - Global step 450 Train loss 2.54 Classification-F1 0.007943262411347516 on epoch=32
05/21/2022 05:52:06 - INFO - __main__ - Step 460 Global step 460 Train loss 2.49 on epoch=32
05/21/2022 05:52:08 - INFO - __main__ - Step 470 Global step 470 Train loss 2.46 on epoch=33
05/21/2022 05:52:09 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=34
05/21/2022 05:52:10 - INFO - __main__ - Step 490 Global step 490 Train loss 2.31 on epoch=34
05/21/2022 05:52:11 - INFO - __main__ - Step 500 Global step 500 Train loss 2.46 on epoch=35
05/21/2022 05:52:13 - INFO - __main__ - Global step 500 Train loss 2.41 Classification-F1 0.009523809523809523 on epoch=35
05/21/2022 05:52:13 - INFO - __main__ - Saving model with best Classification-F1: 0.008641975308641974 -> 0.009523809523809523 on epoch=35, global_step=500
05/21/2022 05:52:14 - INFO - __main__ - Step 510 Global step 510 Train loss 2.34 on epoch=36
05/21/2022 05:52:16 - INFO - __main__ - Step 520 Global step 520 Train loss 2.29 on epoch=37
05/21/2022 05:52:17 - INFO - __main__ - Step 530 Global step 530 Train loss 2.26 on epoch=37
05/21/2022 05:52:18 - INFO - __main__ - Step 540 Global step 540 Train loss 2.32 on epoch=38
05/21/2022 05:52:19 - INFO - __main__ - Step 550 Global step 550 Train loss 2.12 on epoch=39
05/21/2022 05:52:21 - INFO - __main__ - Global step 550 Train loss 2.27 Classification-F1 0.02779503105590062 on epoch=39
05/21/2022 05:52:21 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02779503105590062 on epoch=39, global_step=550
05/21/2022 05:52:23 - INFO - __main__ - Step 560 Global step 560 Train loss 2.04 on epoch=39
05/21/2022 05:52:24 - INFO - __main__ - Step 570 Global step 570 Train loss 2.14 on epoch=40
05/21/2022 05:52:25 - INFO - __main__ - Step 580 Global step 580 Train loss 2.02 on epoch=41
05/21/2022 05:52:26 - INFO - __main__ - Step 590 Global step 590 Train loss 2.22 on epoch=42
05/21/2022 05:52:28 - INFO - __main__ - Step 600 Global step 600 Train loss 2.00 on epoch=42
05/21/2022 05:52:30 - INFO - __main__ - Global step 600 Train loss 2.08 Classification-F1 0.035080050111869286 on epoch=42
05/21/2022 05:52:30 - INFO - __main__ - Saving model with best Classification-F1: 0.02779503105590062 -> 0.035080050111869286 on epoch=42, global_step=600
05/21/2022 05:52:31 - INFO - __main__ - Step 610 Global step 610 Train loss 2.07 on epoch=43
05/21/2022 05:52:32 - INFO - __main__ - Step 620 Global step 620 Train loss 1.99 on epoch=44
05/21/2022 05:52:33 - INFO - __main__ - Step 630 Global step 630 Train loss 1.94 on epoch=44
05/21/2022 05:52:35 - INFO - __main__ - Step 640 Global step 640 Train loss 2.00 on epoch=45
05/21/2022 05:52:36 - INFO - __main__ - Step 650 Global step 650 Train loss 1.87 on epoch=46
05/21/2022 05:52:38 - INFO - __main__ - Global step 650 Train loss 1.97 Classification-F1 0.03837252585411643 on epoch=46
05/21/2022 05:52:38 - INFO - __main__ - Saving model with best Classification-F1: 0.035080050111869286 -> 0.03837252585411643 on epoch=46, global_step=650
05/21/2022 05:52:39 - INFO - __main__ - Step 660 Global step 660 Train loss 1.86 on epoch=47
05/21/2022 05:52:41 - INFO - __main__ - Step 670 Global step 670 Train loss 1.88 on epoch=47
05/21/2022 05:52:42 - INFO - __main__ - Step 680 Global step 680 Train loss 1.82 on epoch=48
05/21/2022 05:52:43 - INFO - __main__ - Step 690 Global step 690 Train loss 1.73 on epoch=49
05/21/2022 05:52:44 - INFO - __main__ - Step 700 Global step 700 Train loss 1.86 on epoch=49
05/21/2022 05:52:47 - INFO - __main__ - Global step 700 Train loss 1.83 Classification-F1 0.03678996610621815 on epoch=49
05/21/2022 05:52:48 - INFO - __main__ - Step 710 Global step 710 Train loss 1.83 on epoch=50
05/21/2022 05:52:49 - INFO - __main__ - Step 720 Global step 720 Train loss 1.74 on epoch=51
05/21/2022 05:52:50 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=52
05/21/2022 05:52:52 - INFO - __main__ - Step 740 Global step 740 Train loss 1.83 on epoch=52
05/21/2022 05:52:53 - INFO - __main__ - Step 750 Global step 750 Train loss 1.73 on epoch=53
05/21/2022 05:52:55 - INFO - __main__ - Global step 750 Train loss 1.77 Classification-F1 0.03291641551135222 on epoch=53
05/21/2022 05:52:56 - INFO - __main__ - Step 760 Global step 760 Train loss 1.66 on epoch=54
05/21/2022 05:52:57 - INFO - __main__ - Step 770 Global step 770 Train loss 1.62 on epoch=54
05/21/2022 05:52:59 - INFO - __main__ - Step 780 Global step 780 Train loss 1.77 on epoch=55
05/21/2022 05:53:00 - INFO - __main__ - Step 790 Global step 790 Train loss 1.58 on epoch=56
05/21/2022 05:53:01 - INFO - __main__ - Step 800 Global step 800 Train loss 1.67 on epoch=57
05/21/2022 05:53:03 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.04233794125186992 on epoch=57
05/21/2022 05:53:03 - INFO - __main__ - Saving model with best Classification-F1: 0.03837252585411643 -> 0.04233794125186992 on epoch=57, global_step=800
05/21/2022 05:53:04 - INFO - __main__ - Step 810 Global step 810 Train loss 1.67 on epoch=57
05/21/2022 05:53:06 - INFO - __main__ - Step 820 Global step 820 Train loss 1.54 on epoch=58
05/21/2022 05:53:07 - INFO - __main__ - Step 830 Global step 830 Train loss 1.64 on epoch=59
05/21/2022 05:53:08 - INFO - __main__ - Step 840 Global step 840 Train loss 1.50 on epoch=59
05/21/2022 05:53:09 - INFO - __main__ - Step 850 Global step 850 Train loss 1.65 on epoch=60
05/21/2022 05:53:11 - INFO - __main__ - Global step 850 Train loss 1.60 Classification-F1 0.03842807263859895 on epoch=60
05/21/2022 05:53:13 - INFO - __main__ - Step 860 Global step 860 Train loss 1.54 on epoch=61
05/21/2022 05:53:14 - INFO - __main__ - Step 870 Global step 870 Train loss 1.68 on epoch=62
05/21/2022 05:53:15 - INFO - __main__ - Step 880 Global step 880 Train loss 1.59 on epoch=62
05/21/2022 05:53:17 - INFO - __main__ - Step 890 Global step 890 Train loss 1.50 on epoch=63
05/21/2022 05:53:18 - INFO - __main__ - Step 900 Global step 900 Train loss 1.57 on epoch=64
05/21/2022 05:53:20 - INFO - __main__ - Global step 900 Train loss 1.57 Classification-F1 0.033387989342078296 on epoch=64
05/21/2022 05:53:21 - INFO - __main__ - Step 910 Global step 910 Train loss 1.40 on epoch=64
05/21/2022 05:53:22 - INFO - __main__ - Step 920 Global step 920 Train loss 1.53 on epoch=65
05/21/2022 05:53:23 - INFO - __main__ - Step 930 Global step 930 Train loss 1.51 on epoch=66
05/21/2022 05:53:25 - INFO - __main__ - Step 940 Global step 940 Train loss 1.41 on epoch=67
05/21/2022 05:53:26 - INFO - __main__ - Step 950 Global step 950 Train loss 1.45 on epoch=67
05/21/2022 05:53:28 - INFO - __main__ - Global step 950 Train loss 1.46 Classification-F1 0.063718733107278 on epoch=67
05/21/2022 05:53:28 - INFO - __main__ - Saving model with best Classification-F1: 0.04233794125186992 -> 0.063718733107278 on epoch=67, global_step=950
05/21/2022 05:53:29 - INFO - __main__ - Step 960 Global step 960 Train loss 1.41 on epoch=68
05/21/2022 05:53:31 - INFO - __main__ - Step 970 Global step 970 Train loss 1.50 on epoch=69
05/21/2022 05:53:32 - INFO - __main__ - Step 980 Global step 980 Train loss 1.53 on epoch=69
05/21/2022 05:53:33 - INFO - __main__ - Step 990 Global step 990 Train loss 1.50 on epoch=70
05/21/2022 05:53:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.47 on epoch=71
05/21/2022 05:53:37 - INFO - __main__ - Global step 1000 Train loss 1.48 Classification-F1 0.07074884484667965 on epoch=71
05/21/2022 05:53:37 - INFO - __main__ - Saving model with best Classification-F1: 0.063718733107278 -> 0.07074884484667965 on epoch=71, global_step=1000
05/21/2022 05:53:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=72
05/21/2022 05:53:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.49 on epoch=72
05/21/2022 05:53:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.42 on epoch=73
05/21/2022 05:53:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.43 on epoch=74
05/21/2022 05:53:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.47 on epoch=74
05/21/2022 05:53:45 - INFO - __main__ - Global step 1050 Train loss 1.44 Classification-F1 0.033074113127965654 on epoch=74
05/21/2022 05:53:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.47 on epoch=75
05/21/2022 05:53:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.41 on epoch=76
05/21/2022 05:53:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.37 on epoch=77
05/21/2022 05:53:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.45 on epoch=77
05/21/2022 05:53:52 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.38 on epoch=78
05/21/2022 05:53:54 - INFO - __main__ - Global step 1100 Train loss 1.42 Classification-F1 0.035624625904719896 on epoch=78
05/21/2022 05:53:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.38 on epoch=79
05/21/2022 05:53:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.36 on epoch=79
05/21/2022 05:53:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.39 on epoch=80
05/21/2022 05:53:59 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.37 on epoch=81
05/21/2022 05:54:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.37 on epoch=82
05/21/2022 05:54:03 - INFO - __main__ - Global step 1150 Train loss 1.37 Classification-F1 0.05253305398719269 on epoch=82
05/21/2022 05:54:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.39 on epoch=82
05/21/2022 05:54:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.30 on epoch=83
05/21/2022 05:54:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=84
05/21/2022 05:54:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.38 on epoch=84
05/21/2022 05:54:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.41 on epoch=85
05/21/2022 05:54:12 - INFO - __main__ - Global step 1200 Train loss 1.36 Classification-F1 0.0521799628942486 on epoch=85
05/21/2022 05:54:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.31 on epoch=86
05/21/2022 05:54:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.31 on epoch=87
05/21/2022 05:54:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.46 on epoch=87
05/21/2022 05:54:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.39 on epoch=88
05/21/2022 05:54:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.40 on epoch=89
05/21/2022 05:54:20 - INFO - __main__ - Global step 1250 Train loss 1.37 Classification-F1 0.07507378794972779 on epoch=89
05/21/2022 05:54:20 - INFO - __main__ - Saving model with best Classification-F1: 0.07074884484667965 -> 0.07507378794972779 on epoch=89, global_step=1250
05/21/2022 05:54:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.21 on epoch=89
05/21/2022 05:54:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.30 on epoch=90
05/21/2022 05:54:24 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.38 on epoch=91
05/21/2022 05:54:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.34 on epoch=92
05/21/2022 05:54:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.42 on epoch=92
05/21/2022 05:54:29 - INFO - __main__ - Global step 1300 Train loss 1.33 Classification-F1 0.07700710595447437 on epoch=92
05/21/2022 05:54:29 - INFO - __main__ - Saving model with best Classification-F1: 0.07507378794972779 -> 0.07700710595447437 on epoch=92, global_step=1300
05/21/2022 05:54:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.30 on epoch=93
05/21/2022 05:54:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.35 on epoch=94
05/21/2022 05:54:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.29 on epoch=94
05/21/2022 05:54:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.41 on epoch=95
05/21/2022 05:54:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.19 on epoch=96
05/21/2022 05:54:38 - INFO - __main__ - Global step 1350 Train loss 1.31 Classification-F1 0.1058599360086783 on epoch=96
05/21/2022 05:54:38 - INFO - __main__ - Saving model with best Classification-F1: 0.07700710595447437 -> 0.1058599360086783 on epoch=96, global_step=1350
05/21/2022 05:54:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.32 on epoch=97
05/21/2022 05:54:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.39 on epoch=97
05/21/2022 05:54:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.23 on epoch=98
05/21/2022 05:54:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.32 on epoch=99
05/21/2022 05:54:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.34 on epoch=99
05/21/2022 05:54:47 - INFO - __main__ - Global step 1400 Train loss 1.32 Classification-F1 0.07324306353284367 on epoch=99
05/21/2022 05:54:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.30 on epoch=100
05/21/2022 05:54:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.24 on epoch=101
05/21/2022 05:54:50 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.23 on epoch=102
05/21/2022 05:54:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.31 on epoch=102
05/21/2022 05:54:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.16 on epoch=103
05/21/2022 05:54:56 - INFO - __main__ - Global step 1450 Train loss 1.25 Classification-F1 0.09630235705859218 on epoch=103
05/21/2022 05:54:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.24 on epoch=104
05/21/2022 05:54:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.32 on epoch=104
05/21/2022 05:55:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.31 on epoch=105
05/21/2022 05:55:01 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.27 on epoch=106
05/21/2022 05:55:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.22 on epoch=107
05/21/2022 05:55:05 - INFO - __main__ - Global step 1500 Train loss 1.27 Classification-F1 0.08698789133571741 on epoch=107
05/21/2022 05:55:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.37 on epoch=107
05/21/2022 05:55:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.31 on epoch=108
05/21/2022 05:55:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/21/2022 05:55:10 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.25 on epoch=109
05/21/2022 05:55:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.26 on epoch=110
05/21/2022 05:55:14 - INFO - __main__ - Global step 1550 Train loss 1.27 Classification-F1 0.09281412018638295 on epoch=110
05/21/2022 05:55:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.32 on epoch=111
05/21/2022 05:55:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.26 on epoch=112
05/21/2022 05:55:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.24 on epoch=112
05/21/2022 05:55:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.15 on epoch=113
05/21/2022 05:55:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.22 on epoch=114
05/21/2022 05:55:23 - INFO - __main__ - Global step 1600 Train loss 1.24 Classification-F1 0.1201514232935497 on epoch=114
05/21/2022 05:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.1058599360086783 -> 0.1201514232935497 on epoch=114, global_step=1600
05/21/2022 05:55:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.23 on epoch=114
05/21/2022 05:55:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.29 on epoch=115
05/21/2022 05:55:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.19 on epoch=116
05/21/2022 05:55:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.28 on epoch=117
05/21/2022 05:55:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.21 on epoch=117
05/21/2022 05:55:31 - INFO - __main__ - Global step 1650 Train loss 1.24 Classification-F1 0.11154888850289464 on epoch=117
05/21/2022 05:55:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.22 on epoch=118
05/21/2022 05:55:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.16 on epoch=119
05/21/2022 05:55:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.31 on epoch=119
05/21/2022 05:55:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.32 on epoch=120
05/21/2022 05:55:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.22 on epoch=121
05/21/2022 05:55:40 - INFO - __main__ - Global step 1700 Train loss 1.25 Classification-F1 0.15071644432747724 on epoch=121
05/21/2022 05:55:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1201514232935497 -> 0.15071644432747724 on epoch=121, global_step=1700
05/21/2022 05:55:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.24 on epoch=122
05/21/2022 05:55:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.23 on epoch=122
05/21/2022 05:55:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/21/2022 05:55:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.22 on epoch=124
05/21/2022 05:55:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.21 on epoch=124
05/21/2022 05:55:50 - INFO - __main__ - Global step 1750 Train loss 1.21 Classification-F1 0.16705088219405015 on epoch=124
05/21/2022 05:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.15071644432747724 -> 0.16705088219405015 on epoch=124, global_step=1750
05/21/2022 05:55:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.29 on epoch=125
05/21/2022 05:55:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.20 on epoch=126
05/21/2022 05:55:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.20 on epoch=127
05/21/2022 05:55:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.30 on epoch=127
05/21/2022 05:55:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.23 on epoch=128
05/21/2022 05:55:59 - INFO - __main__ - Global step 1800 Train loss 1.24 Classification-F1 0.17544664640283036 on epoch=128
05/21/2022 05:55:59 - INFO - __main__ - Saving model with best Classification-F1: 0.16705088219405015 -> 0.17544664640283036 on epoch=128, global_step=1800
05/21/2022 05:56:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.21 on epoch=129
05/21/2022 05:56:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.25 on epoch=129
05/21/2022 05:56:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.32 on epoch=130
05/21/2022 05:56:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/21/2022 05:56:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.14 on epoch=132
05/21/2022 05:56:08 - INFO - __main__ - Global step 1850 Train loss 1.23 Classification-F1 0.22221992773005234 on epoch=132
05/21/2022 05:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.17544664640283036 -> 0.22221992773005234 on epoch=132, global_step=1850
05/21/2022 05:56:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.19 on epoch=132
05/21/2022 05:56:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=133
05/21/2022 05:56:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.27 on epoch=134
05/21/2022 05:56:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.18 on epoch=134
05/21/2022 05:56:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.21 on epoch=135
05/21/2022 05:56:18 - INFO - __main__ - Global step 1900 Train loss 1.19 Classification-F1 0.18159169470814723 on epoch=135
05/21/2022 05:56:19 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.16 on epoch=136
05/21/2022 05:56:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.11 on epoch=137
05/21/2022 05:56:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.18 on epoch=137
05/21/2022 05:56:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.17 on epoch=138
05/21/2022 05:56:24 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.21 on epoch=139
05/21/2022 05:56:27 - INFO - __main__ - Global step 1950 Train loss 1.17 Classification-F1 0.2506412634984063 on epoch=139
05/21/2022 05:56:27 - INFO - __main__ - Saving model with best Classification-F1: 0.22221992773005234 -> 0.2506412634984063 on epoch=139, global_step=1950
05/21/2022 05:56:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.16 on epoch=139
05/21/2022 05:56:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 1.17 on epoch=140
05/21/2022 05:56:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.13 on epoch=141
05/21/2022 05:56:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.22 on epoch=142
05/21/2022 05:56:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.21 on epoch=142
05/21/2022 05:56:37 - INFO - __main__ - Global step 2000 Train loss 1.18 Classification-F1 0.30080052368650856 on epoch=142
05/21/2022 05:56:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2506412634984063 -> 0.30080052368650856 on epoch=142, global_step=2000
05/21/2022 05:56:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.10 on epoch=143
05/21/2022 05:56:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.16 on epoch=144
05/21/2022 05:56:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.10 on epoch=144
05/21/2022 05:56:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.10 on epoch=145
05/21/2022 05:56:43 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.13 on epoch=146
05/21/2022 05:56:46 - INFO - __main__ - Global step 2050 Train loss 1.12 Classification-F1 0.32803541285440746 on epoch=146
05/21/2022 05:56:46 - INFO - __main__ - Saving model with best Classification-F1: 0.30080052368650856 -> 0.32803541285440746 on epoch=146, global_step=2050
05/21/2022 05:56:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.06 on epoch=147
05/21/2022 05:56:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.07 on epoch=147
05/21/2022 05:56:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.09 on epoch=148
05/21/2022 05:56:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.12 on epoch=149
05/21/2022 05:56:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/21/2022 05:56:56 - INFO - __main__ - Global step 2100 Train loss 1.09 Classification-F1 0.30424961030994363 on epoch=149
05/21/2022 05:56:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.17 on epoch=150
05/21/2022 05:56:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.14 on epoch=151
05/21/2022 05:57:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.14 on epoch=152
05/21/2022 05:57:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.04 on epoch=152
05/21/2022 05:57:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.07 on epoch=153
05/21/2022 05:57:06 - INFO - __main__ - Global step 2150 Train loss 1.11 Classification-F1 0.3824772151460708 on epoch=153
05/21/2022 05:57:06 - INFO - __main__ - Saving model with best Classification-F1: 0.32803541285440746 -> 0.3824772151460708 on epoch=153, global_step=2150
05/21/2022 05:57:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.08 on epoch=154
05/21/2022 05:57:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.03 on epoch=154
05/21/2022 05:57:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.04 on epoch=155
05/21/2022 05:57:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.06 on epoch=156
05/21/2022 05:57:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=157
05/21/2022 05:57:15 - INFO - __main__ - Global step 2200 Train loss 1.05 Classification-F1 0.3585204599524737 on epoch=157
05/21/2022 05:57:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.18 on epoch=157
05/21/2022 05:57:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.06 on epoch=158
05/21/2022 05:57:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.02 on epoch=159
05/21/2022 05:57:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.11 on epoch=159
05/21/2022 05:57:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 1.07 on epoch=160
05/21/2022 05:57:25 - INFO - __main__ - Global step 2250 Train loss 1.09 Classification-F1 0.37779875333120116 on epoch=160
05/21/2022 05:57:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.04 on epoch=161
05/21/2022 05:57:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.08 on epoch=162
05/21/2022 05:57:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.11 on epoch=162
05/21/2022 05:57:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.09 on epoch=163
05/21/2022 05:57:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.02 on epoch=164
05/21/2022 05:57:34 - INFO - __main__ - Global step 2300 Train loss 1.07 Classification-F1 0.35963522992311886 on epoch=164
05/21/2022 05:57:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.98 on epoch=164
05/21/2022 05:57:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.10 on epoch=165
05/21/2022 05:57:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.01 on epoch=166
05/21/2022 05:57:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.99 on epoch=167
05/21/2022 05:57:40 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.94 on epoch=167
05/21/2022 05:57:44 - INFO - __main__ - Global step 2350 Train loss 1.01 Classification-F1 0.38558155284969187 on epoch=167
05/21/2022 05:57:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3824772151460708 -> 0.38558155284969187 on epoch=167, global_step=2350
05/21/2022 05:57:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.99 on epoch=168
05/21/2022 05:57:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.05 on epoch=169
05/21/2022 05:57:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.07 on epoch=169
05/21/2022 05:57:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.02 on epoch=170
05/21/2022 05:57:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.95 on epoch=171
05/21/2022 05:57:54 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.35135670283378395 on epoch=171
05/21/2022 05:57:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.95 on epoch=172
05/21/2022 05:57:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.07 on epoch=172
05/21/2022 05:57:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.97 on epoch=173
05/21/2022 05:57:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.98 on epoch=174
05/21/2022 05:58:00 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=174
05/21/2022 05:58:03 - INFO - __main__ - Global step 2450 Train loss 1.01 Classification-F1 0.3938095700582353 on epoch=174
05/21/2022 05:58:03 - INFO - __main__ - Saving model with best Classification-F1: 0.38558155284969187 -> 0.3938095700582353 on epoch=174, global_step=2450
05/21/2022 05:58:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.05 on epoch=175
05/21/2022 05:58:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.97 on epoch=176
05/21/2022 05:58:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=177
05/21/2022 05:58:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.04 on epoch=177
05/21/2022 05:58:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.96 on epoch=178
05/21/2022 05:58:13 - INFO - __main__ - Global step 2500 Train loss 1.01 Classification-F1 0.41167843562596523 on epoch=178
05/21/2022 05:58:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3938095700582353 -> 0.41167843562596523 on epoch=178, global_step=2500
05/21/2022 05:58:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.95 on epoch=179
05/21/2022 05:58:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=179
05/21/2022 05:58:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=180
05/21/2022 05:58:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.93 on epoch=181
05/21/2022 05:58:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.95 on epoch=182
05/21/2022 05:58:23 - INFO - __main__ - Global step 2550 Train loss 0.94 Classification-F1 0.4565433747000566 on epoch=182
05/21/2022 05:58:23 - INFO - __main__ - Saving model with best Classification-F1: 0.41167843562596523 -> 0.4565433747000566 on epoch=182, global_step=2550
05/21/2022 05:58:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.94 on epoch=182
05/21/2022 05:58:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.99 on epoch=183
05/21/2022 05:58:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.97 on epoch=184
05/21/2022 05:58:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.04 on epoch=184
05/21/2022 05:58:29 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.05 on epoch=185
05/21/2022 05:58:33 - INFO - __main__ - Global step 2600 Train loss 1.00 Classification-F1 0.44056165949431725 on epoch=185
05/21/2022 05:58:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.92 on epoch=186
05/21/2022 05:58:35 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.97 on epoch=187
05/21/2022 05:58:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 1.00 on epoch=187
05/21/2022 05:58:38 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.97 on epoch=188
05/21/2022 05:58:39 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.91 on epoch=189
05/21/2022 05:58:42 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.4019290226750264 on epoch=189
05/21/2022 05:58:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.95 on epoch=189
05/21/2022 05:58:45 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.98 on epoch=190
05/21/2022 05:58:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.90 on epoch=191
05/21/2022 05:58:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.03 on epoch=192
05/21/2022 05:58:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.92 on epoch=192
05/21/2022 05:58:52 - INFO - __main__ - Global step 2700 Train loss 0.96 Classification-F1 0.4722289573244759 on epoch=192
05/21/2022 05:58:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4565433747000566 -> 0.4722289573244759 on epoch=192, global_step=2700
05/21/2022 05:58:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.83 on epoch=193
05/21/2022 05:58:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.06 on epoch=194
05/21/2022 05:58:56 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.89 on epoch=194
05/21/2022 05:58:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.98 on epoch=195
05/21/2022 05:58:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.95 on epoch=196
05/21/2022 05:59:02 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.38454704201844114 on epoch=196
05/21/2022 05:59:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=197
05/21/2022 05:59:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.94 on epoch=197
05/21/2022 05:59:06 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.91 on epoch=198
05/21/2022 05:59:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=199
05/21/2022 05:59:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.95 on epoch=199
05/21/2022 05:59:12 - INFO - __main__ - Global step 2800 Train loss 0.93 Classification-F1 0.399421405594835 on epoch=199
05/21/2022 05:59:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/21/2022 05:59:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.93 on epoch=201
05/21/2022 05:59:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=202
05/21/2022 05:59:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.93 on epoch=202
05/21/2022 05:59:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.93 on epoch=203
05/21/2022 05:59:22 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.3164567177078194 on epoch=203
05/21/2022 05:59:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.78 on epoch=204
05/21/2022 05:59:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.91 on epoch=204
05/21/2022 05:59:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.03 on epoch=205
05/21/2022 05:59:27 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.89 on epoch=206
05/21/2022 05:59:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.83 on epoch=207
05/21/2022 05:59:32 - INFO - __main__ - Global step 2900 Train loss 0.89 Classification-F1 0.43546896084126263 on epoch=207
05/21/2022 05:59:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.99 on epoch=207
05/21/2022 05:59:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.87 on epoch=208
05/21/2022 05:59:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.86 on epoch=209
05/21/2022 05:59:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.91 on epoch=209
05/21/2022 05:59:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.93 on epoch=210
05/21/2022 05:59:41 - INFO - __main__ - Global step 2950 Train loss 0.91 Classification-F1 0.37539250658524503 on epoch=210
05/21/2022 05:59:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.83 on epoch=211
05/21/2022 05:59:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.83 on epoch=212
05/21/2022 05:59:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.94 on epoch=212
05/21/2022 05:59:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.81 on epoch=213
05/21/2022 05:59:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.89 on epoch=214
05/21/2022 05:59:49 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:59:49 - INFO - __main__ - Printing 3 examples
05/21/2022 05:59:49 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 05:59:49 - INFO - __main__ - ['Company']
05/21/2022 05:59:49 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 05:59:49 - INFO - __main__ - ['Company']
05/21/2022 05:59:49 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 05:59:49 - INFO - __main__ - ['Company']
05/21/2022 05:59:49 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:59:49 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:59:50 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 05:59:50 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 05:59:50 - INFO - __main__ - Printing 3 examples
05/21/2022 05:59:50 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 05:59:50 - INFO - __main__ - ['Company']
05/21/2022 05:59:50 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 05:59:50 - INFO - __main__ - ['Company']
05/21/2022 05:59:50 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 05:59:50 - INFO - __main__ - ['Company']
05/21/2022 05:59:50 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:59:50 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:59:50 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 05:59:51 - INFO - __main__ - Global step 3000 Train loss 0.86 Classification-F1 0.35547057046280073 on epoch=214
05/21/2022 05:59:51 - INFO - __main__ - save last model!
05/21/2022 05:59:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 05:59:51 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 05:59:51 - INFO - __main__ - Printing 3 examples
05/21/2022 05:59:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 05:59:51 - INFO - __main__ - ['Animal']
05/21/2022 05:59:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 05:59:51 - INFO - __main__ - ['Animal']
05/21/2022 05:59:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 05:59:51 - INFO - __main__ - ['Village']
05/21/2022 05:59:51 - INFO - __main__ - Tokenizing Input ...
05/21/2022 05:59:53 - INFO - __main__ - Tokenizing Output ...
05/21/2022 05:59:55 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 05:59:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 05:59:56 - INFO - __main__ - Starting training!
05/21/2022 05:59:57 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:00:52 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
05/21/2022 06:00:52 - INFO - __main__ - Classification-F1 on test data: 0.1797
05/21/2022 06:00:53 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.4722289573244759, test_performance=0.17965025799953324
05/21/2022 06:00:53 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
05/21/2022 06:00:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:00:54 - INFO - __main__ - Printing 3 examples
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:00:54 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:00:54 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:00:54 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:00:54 - INFO - __main__ - Printing 3 examples
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:00:54 - INFO - __main__ - ['Company']
05/21/2022 06:00:54 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:00:54 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:00:54 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:01:00 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:01:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:01:01 - INFO - __main__ - Starting training!
05/21/2022 06:01:02 - INFO - __main__ - Step 10 Global step 10 Train loss 7.50 on epoch=0
05/21/2022 06:01:03 - INFO - __main__ - Step 20 Global step 20 Train loss 6.99 on epoch=1
05/21/2022 06:01:05 - INFO - __main__ - Step 30 Global step 30 Train loss 6.10 on epoch=2
05/21/2022 06:01:06 - INFO - __main__ - Step 40 Global step 40 Train loss 5.38 on epoch=2
05/21/2022 06:01:07 - INFO - __main__ - Step 50 Global step 50 Train loss 5.03 on epoch=3
05/21/2022 06:01:10 - INFO - __main__ - Global step 50 Train loss 6.20 Classification-F1 0.0 on epoch=3
05/21/2022 06:01:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:01:12 - INFO - __main__ - Step 60 Global step 60 Train loss 4.66 on epoch=4
05/21/2022 06:01:13 - INFO - __main__ - Step 70 Global step 70 Train loss 4.39 on epoch=4
05/21/2022 06:01:14 - INFO - __main__ - Step 80 Global step 80 Train loss 3.91 on epoch=5
05/21/2022 06:01:16 - INFO - __main__ - Step 90 Global step 90 Train loss 3.88 on epoch=6
05/21/2022 06:01:17 - INFO - __main__ - Step 100 Global step 100 Train loss 3.61 on epoch=7
05/21/2022 06:01:19 - INFO - __main__ - Global step 100 Train loss 4.09 Classification-F1 0.0 on epoch=7
05/21/2022 06:01:21 - INFO - __main__ - Step 110 Global step 110 Train loss 3.43 on epoch=7
05/21/2022 06:01:22 - INFO - __main__ - Step 120 Global step 120 Train loss 3.22 on epoch=8
05/21/2022 06:01:23 - INFO - __main__ - Step 130 Global step 130 Train loss 3.01 on epoch=9
05/21/2022 06:01:24 - INFO - __main__ - Step 140 Global step 140 Train loss 3.06 on epoch=9
05/21/2022 06:01:26 - INFO - __main__ - Step 150 Global step 150 Train loss 2.59 on epoch=10
05/21/2022 06:01:28 - INFO - __main__ - Global step 150 Train loss 3.06 Classification-F1 0.0077972709551656924 on epoch=10
05/21/2022 06:01:28 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0077972709551656924 on epoch=10, global_step=150
05/21/2022 06:01:29 - INFO - __main__ - Step 160 Global step 160 Train loss 2.77 on epoch=11
05/21/2022 06:01:31 - INFO - __main__ - Step 170 Global step 170 Train loss 2.57 on epoch=12
05/21/2022 06:01:32 - INFO - __main__ - Step 180 Global step 180 Train loss 2.37 on epoch=12
05/21/2022 06:01:33 - INFO - __main__ - Step 190 Global step 190 Train loss 2.36 on epoch=13
05/21/2022 06:01:34 - INFO - __main__ - Step 200 Global step 200 Train loss 2.32 on epoch=14
05/21/2022 06:01:37 - INFO - __main__ - Global step 200 Train loss 2.48 Classification-F1 0.009078014184397163 on epoch=14
05/21/2022 06:01:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0077972709551656924 -> 0.009078014184397163 on epoch=14, global_step=200
05/21/2022 06:01:38 - INFO - __main__ - Step 210 Global step 210 Train loss 2.30 on epoch=14
05/21/2022 06:01:39 - INFO - __main__ - Step 220 Global step 220 Train loss 2.00 on epoch=15
05/21/2022 06:01:40 - INFO - __main__ - Step 230 Global step 230 Train loss 2.12 on epoch=16
05/21/2022 06:01:42 - INFO - __main__ - Step 240 Global step 240 Train loss 2.02 on epoch=17
05/21/2022 06:01:43 - INFO - __main__ - Step 250 Global step 250 Train loss 1.81 on epoch=17
05/21/2022 06:01:45 - INFO - __main__ - Global step 250 Train loss 2.05 Classification-F1 0.0308350150294238 on epoch=17
05/21/2022 06:01:45 - INFO - __main__ - Saving model with best Classification-F1: 0.009078014184397163 -> 0.0308350150294238 on epoch=17, global_step=250
05/21/2022 06:01:46 - INFO - __main__ - Step 260 Global step 260 Train loss 1.90 on epoch=18
05/21/2022 06:01:47 - INFO - __main__ - Step 270 Global step 270 Train loss 1.93 on epoch=19
05/21/2022 06:01:49 - INFO - __main__ - Step 280 Global step 280 Train loss 1.76 on epoch=19
05/21/2022 06:01:50 - INFO - __main__ - Step 290 Global step 290 Train loss 1.77 on epoch=20
05/21/2022 06:01:51 - INFO - __main__ - Step 300 Global step 300 Train loss 1.78 on epoch=21
05/21/2022 06:01:53 - INFO - __main__ - Global step 300 Train loss 1.83 Classification-F1 0.03898509030477863 on epoch=21
05/21/2022 06:01:53 - INFO - __main__ - Saving model with best Classification-F1: 0.0308350150294238 -> 0.03898509030477863 on epoch=21, global_step=300
05/21/2022 06:01:55 - INFO - __main__ - Step 310 Global step 310 Train loss 1.78 on epoch=22
05/21/2022 06:01:56 - INFO - __main__ - Step 320 Global step 320 Train loss 1.61 on epoch=22
05/21/2022 06:01:57 - INFO - __main__ - Step 330 Global step 330 Train loss 1.61 on epoch=23
05/21/2022 06:01:58 - INFO - __main__ - Step 340 Global step 340 Train loss 1.60 on epoch=24
05/21/2022 06:02:00 - INFO - __main__ - Step 350 Global step 350 Train loss 1.64 on epoch=24
05/21/2022 06:02:02 - INFO - __main__ - Global step 350 Train loss 1.65 Classification-F1 0.0630286147477859 on epoch=24
05/21/2022 06:02:02 - INFO - __main__ - Saving model with best Classification-F1: 0.03898509030477863 -> 0.0630286147477859 on epoch=24, global_step=350
05/21/2022 06:02:03 - INFO - __main__ - Step 360 Global step 360 Train loss 1.48 on epoch=25
05/21/2022 06:02:05 - INFO - __main__ - Step 370 Global step 370 Train loss 1.59 on epoch=26
05/21/2022 06:02:06 - INFO - __main__ - Step 380 Global step 380 Train loss 1.53 on epoch=27
05/21/2022 06:02:07 - INFO - __main__ - Step 390 Global step 390 Train loss 1.34 on epoch=27
05/21/2022 06:02:08 - INFO - __main__ - Step 400 Global step 400 Train loss 1.43 on epoch=28
05/21/2022 06:02:11 - INFO - __main__ - Global step 400 Train loss 1.47 Classification-F1 0.03799379898296264 on epoch=28
05/21/2022 06:02:12 - INFO - __main__ - Step 410 Global step 410 Train loss 1.43 on epoch=29
05/21/2022 06:02:13 - INFO - __main__ - Step 420 Global step 420 Train loss 1.45 on epoch=29
05/21/2022 06:02:14 - INFO - __main__ - Step 430 Global step 430 Train loss 1.40 on epoch=30
05/21/2022 06:02:16 - INFO - __main__ - Step 440 Global step 440 Train loss 1.52 on epoch=31
05/21/2022 06:02:17 - INFO - __main__ - Step 450 Global step 450 Train loss 1.39 on epoch=32
05/21/2022 06:02:19 - INFO - __main__ - Global step 450 Train loss 1.44 Classification-F1 0.06022126113059998 on epoch=32
05/21/2022 06:02:21 - INFO - __main__ - Step 460 Global step 460 Train loss 1.18 on epoch=32
05/21/2022 06:02:22 - INFO - __main__ - Step 470 Global step 470 Train loss 1.29 on epoch=33
05/21/2022 06:02:23 - INFO - __main__ - Step 480 Global step 480 Train loss 1.35 on epoch=34
05/21/2022 06:02:24 - INFO - __main__ - Step 490 Global step 490 Train loss 1.23 on epoch=34
05/21/2022 06:02:26 - INFO - __main__ - Step 500 Global step 500 Train loss 1.26 on epoch=35
05/21/2022 06:02:28 - INFO - __main__ - Global step 500 Train loss 1.26 Classification-F1 0.05104708550086702 on epoch=35
05/21/2022 06:02:29 - INFO - __main__ - Step 510 Global step 510 Train loss 1.29 on epoch=36
05/21/2022 06:02:30 - INFO - __main__ - Step 520 Global step 520 Train loss 1.33 on epoch=37
05/21/2022 06:02:32 - INFO - __main__ - Step 530 Global step 530 Train loss 1.22 on epoch=37
05/21/2022 06:02:33 - INFO - __main__ - Step 540 Global step 540 Train loss 1.25 on epoch=38
05/21/2022 06:02:34 - INFO - __main__ - Step 550 Global step 550 Train loss 1.32 on epoch=39
05/21/2022 06:02:37 - INFO - __main__ - Global step 550 Train loss 1.28 Classification-F1 0.13310542296631808 on epoch=39
05/21/2022 06:02:37 - INFO - __main__ - Saving model with best Classification-F1: 0.0630286147477859 -> 0.13310542296631808 on epoch=39, global_step=550
05/21/2022 06:02:38 - INFO - __main__ - Step 560 Global step 560 Train loss 1.31 on epoch=39
05/21/2022 06:02:39 - INFO - __main__ - Step 570 Global step 570 Train loss 1.25 on epoch=40
05/21/2022 06:02:41 - INFO - __main__ - Step 580 Global step 580 Train loss 1.35 on epoch=41
05/21/2022 06:02:42 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/21/2022 06:02:43 - INFO - __main__ - Step 600 Global step 600 Train loss 1.10 on epoch=42
05/21/2022 06:02:46 - INFO - __main__ - Global step 600 Train loss 1.25 Classification-F1 0.14538533379578394 on epoch=42
05/21/2022 06:02:46 - INFO - __main__ - Saving model with best Classification-F1: 0.13310542296631808 -> 0.14538533379578394 on epoch=42, global_step=600
05/21/2022 06:02:47 - INFO - __main__ - Step 610 Global step 610 Train loss 1.27 on epoch=43
05/21/2022 06:02:48 - INFO - __main__ - Step 620 Global step 620 Train loss 1.36 on epoch=44
05/21/2022 06:02:49 - INFO - __main__ - Step 630 Global step 630 Train loss 1.20 on epoch=44
05/21/2022 06:02:51 - INFO - __main__ - Step 640 Global step 640 Train loss 1.16 on epoch=45
05/21/2022 06:02:52 - INFO - __main__ - Step 650 Global step 650 Train loss 1.20 on epoch=46
05/21/2022 06:02:55 - INFO - __main__ - Global step 650 Train loss 1.24 Classification-F1 0.13266304996445563 on epoch=46
05/21/2022 06:02:56 - INFO - __main__ - Step 660 Global step 660 Train loss 1.24 on epoch=47
05/21/2022 06:02:57 - INFO - __main__ - Step 670 Global step 670 Train loss 1.09 on epoch=47
05/21/2022 06:02:59 - INFO - __main__ - Step 680 Global step 680 Train loss 1.26 on epoch=48
05/21/2022 06:03:00 - INFO - __main__ - Step 690 Global step 690 Train loss 1.18 on epoch=49
05/21/2022 06:03:01 - INFO - __main__ - Step 700 Global step 700 Train loss 1.11 on epoch=49
05/21/2022 06:03:04 - INFO - __main__ - Global step 700 Train loss 1.18 Classification-F1 0.1782529250443686 on epoch=49
05/21/2022 06:03:04 - INFO - __main__ - Saving model with best Classification-F1: 0.14538533379578394 -> 0.1782529250443686 on epoch=49, global_step=700
05/21/2022 06:03:05 - INFO - __main__ - Step 710 Global step 710 Train loss 1.11 on epoch=50
05/21/2022 06:03:07 - INFO - __main__ - Step 720 Global step 720 Train loss 1.24 on epoch=51
05/21/2022 06:03:08 - INFO - __main__ - Step 730 Global step 730 Train loss 1.18 on epoch=52
05/21/2022 06:03:09 - INFO - __main__ - Step 740 Global step 740 Train loss 1.10 on epoch=52
05/21/2022 06:03:10 - INFO - __main__ - Step 750 Global step 750 Train loss 1.17 on epoch=53
05/21/2022 06:03:14 - INFO - __main__ - Global step 750 Train loss 1.16 Classification-F1 0.21646305422840342 on epoch=53
05/21/2022 06:03:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1782529250443686 -> 0.21646305422840342 on epoch=53, global_step=750
05/21/2022 06:03:15 - INFO - __main__ - Step 760 Global step 760 Train loss 1.20 on epoch=54
05/21/2022 06:03:16 - INFO - __main__ - Step 770 Global step 770 Train loss 1.23 on epoch=54
05/21/2022 06:03:17 - INFO - __main__ - Step 780 Global step 780 Train loss 1.16 on epoch=55
05/21/2022 06:03:19 - INFO - __main__ - Step 790 Global step 790 Train loss 1.26 on epoch=56
05/21/2022 06:03:20 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/21/2022 06:03:23 - INFO - __main__ - Global step 800 Train loss 1.20 Classification-F1 0.3100162140274763 on epoch=57
05/21/2022 06:03:23 - INFO - __main__ - Saving model with best Classification-F1: 0.21646305422840342 -> 0.3100162140274763 on epoch=57, global_step=800
05/21/2022 06:03:24 - INFO - __main__ - Step 810 Global step 810 Train loss 1.06 on epoch=57
05/21/2022 06:03:26 - INFO - __main__ - Step 820 Global step 820 Train loss 1.09 on epoch=58
05/21/2022 06:03:27 - INFO - __main__ - Step 830 Global step 830 Train loss 1.10 on epoch=59
05/21/2022 06:03:28 - INFO - __main__ - Step 840 Global step 840 Train loss 1.21 on epoch=59
05/21/2022 06:03:29 - INFO - __main__ - Step 850 Global step 850 Train loss 1.07 on epoch=60
05/21/2022 06:03:32 - INFO - __main__ - Global step 850 Train loss 1.11 Classification-F1 0.33943086003792666 on epoch=60
05/21/2022 06:03:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3100162140274763 -> 0.33943086003792666 on epoch=60, global_step=850
05/21/2022 06:03:33 - INFO - __main__ - Step 860 Global step 860 Train loss 1.16 on epoch=61
05/21/2022 06:03:35 - INFO - __main__ - Step 870 Global step 870 Train loss 1.13 on epoch=62
05/21/2022 06:03:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.99 on epoch=62
05/21/2022 06:03:37 - INFO - __main__ - Step 890 Global step 890 Train loss 1.11 on epoch=63
05/21/2022 06:03:38 - INFO - __main__ - Step 900 Global step 900 Train loss 1.14 on epoch=64
05/21/2022 06:03:42 - INFO - __main__ - Global step 900 Train loss 1.11 Classification-F1 0.3251227380333354 on epoch=64
05/21/2022 06:03:43 - INFO - __main__ - Step 910 Global step 910 Train loss 1.15 on epoch=64
05/21/2022 06:03:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.98 on epoch=65
05/21/2022 06:03:46 - INFO - __main__ - Step 930 Global step 930 Train loss 1.08 on epoch=66
05/21/2022 06:03:47 - INFO - __main__ - Step 940 Global step 940 Train loss 1.08 on epoch=67
05/21/2022 06:03:48 - INFO - __main__ - Step 950 Global step 950 Train loss 1.05 on epoch=67
05/21/2022 06:03:51 - INFO - __main__ - Global step 950 Train loss 1.07 Classification-F1 0.3592671278106849 on epoch=67
05/21/2022 06:03:51 - INFO - __main__ - Saving model with best Classification-F1: 0.33943086003792666 -> 0.3592671278106849 on epoch=67, global_step=950
05/21/2022 06:03:53 - INFO - __main__ - Step 960 Global step 960 Train loss 1.12 on epoch=68
05/21/2022 06:03:54 - INFO - __main__ - Step 970 Global step 970 Train loss 1.17 on epoch=69
05/21/2022 06:03:55 - INFO - __main__ - Step 980 Global step 980 Train loss 1.08 on epoch=69
05/21/2022 06:03:56 - INFO - __main__ - Step 990 Global step 990 Train loss 1.03 on epoch=70
05/21/2022 06:03:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.10 on epoch=71
05/21/2022 06:04:01 - INFO - __main__ - Global step 1000 Train loss 1.10 Classification-F1 0.3400494040446876 on epoch=71
05/21/2022 06:04:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.13 on epoch=72
05/21/2022 06:04:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.02 on epoch=72
05/21/2022 06:04:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.00 on epoch=73
05/21/2022 06:04:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.98 on epoch=74
05/21/2022 06:04:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.02 on epoch=74
05/21/2022 06:04:10 - INFO - __main__ - Global step 1050 Train loss 1.03 Classification-F1 0.4177538126361656 on epoch=74
05/21/2022 06:04:10 - INFO - __main__ - Saving model with best Classification-F1: 0.3592671278106849 -> 0.4177538126361656 on epoch=74, global_step=1050
05/21/2022 06:04:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.97 on epoch=75
05/21/2022 06:04:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.12 on epoch=76
05/21/2022 06:04:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.09 on epoch=77
05/21/2022 06:04:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.90 on epoch=77
05/21/2022 06:04:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.08 on epoch=78
05/21/2022 06:04:20 - INFO - __main__ - Global step 1100 Train loss 1.03 Classification-F1 0.41833994047487305 on epoch=78
05/21/2022 06:04:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4177538126361656 -> 0.41833994047487305 on epoch=78, global_step=1100
05/21/2022 06:04:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.04 on epoch=79
05/21/2022 06:04:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.00 on epoch=79
05/21/2022 06:04:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.95 on epoch=80
05/21/2022 06:04:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=81
05/21/2022 06:04:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.98 on epoch=82
05/21/2022 06:04:30 - INFO - __main__ - Global step 1150 Train loss 1.01 Classification-F1 0.48492477247681354 on epoch=82
05/21/2022 06:04:30 - INFO - __main__ - Saving model with best Classification-F1: 0.41833994047487305 -> 0.48492477247681354 on epoch=82, global_step=1150
05/21/2022 06:04:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.01 on epoch=82
05/21/2022 06:04:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.04 on epoch=83
05/21/2022 06:04:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.00 on epoch=84
05/21/2022 06:04:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.91 on epoch=84
05/21/2022 06:04:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.83 on epoch=85
05/21/2022 06:04:39 - INFO - __main__ - Global step 1200 Train loss 0.96 Classification-F1 0.43635901222902496 on epoch=85
05/21/2022 06:04:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.04 on epoch=86
05/21/2022 06:04:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.98 on epoch=87
05/21/2022 06:04:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.93 on epoch=87
05/21/2022 06:04:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.96 on epoch=88
05/21/2022 06:04:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.97 on epoch=89
05/21/2022 06:04:49 - INFO - __main__ - Global step 1250 Train loss 0.97 Classification-F1 0.4746489791316136 on epoch=89
05/21/2022 06:04:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.03 on epoch=89
05/21/2022 06:04:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.88 on epoch=90
05/21/2022 06:04:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.97 on epoch=91
05/21/2022 06:04:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.96 on epoch=92
05/21/2022 06:04:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.94 on epoch=92
05/21/2022 06:04:59 - INFO - __main__ - Global step 1300 Train loss 0.96 Classification-F1 0.4108643677025864 on epoch=92
05/21/2022 06:05:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.92 on epoch=93
05/21/2022 06:05:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.91 on epoch=94
05/21/2022 06:05:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.88 on epoch=94
05/21/2022 06:05:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.80 on epoch=95
05/21/2022 06:05:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.87 on epoch=96
05/21/2022 06:05:09 - INFO - __main__ - Global step 1350 Train loss 0.88 Classification-F1 0.4329445401263793 on epoch=96
05/21/2022 06:05:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.92 on epoch=97
05/21/2022 06:05:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.84 on epoch=97
05/21/2022 06:05:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.88 on epoch=98
05/21/2022 06:05:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.88 on epoch=99
05/21/2022 06:05:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.98 on epoch=99
05/21/2022 06:05:18 - INFO - __main__ - Global step 1400 Train loss 0.90 Classification-F1 0.4739033840244181 on epoch=99
05/21/2022 06:05:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.84 on epoch=100
05/21/2022 06:05:21 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.99 on epoch=101
05/21/2022 06:05:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.97 on epoch=102
05/21/2022 06:05:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.79 on epoch=102
05/21/2022 06:05:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.93 on epoch=103
05/21/2022 06:05:28 - INFO - __main__ - Global step 1450 Train loss 0.90 Classification-F1 0.3952154096666231 on epoch=103
05/21/2022 06:05:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.79 on epoch=104
05/21/2022 06:05:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.91 on epoch=104
05/21/2022 06:05:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.83 on epoch=105
05/21/2022 06:05:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.91 on epoch=106
05/21/2022 06:05:34 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.91 on epoch=107
05/21/2022 06:05:37 - INFO - __main__ - Global step 1500 Train loss 0.87 Classification-F1 0.4373502776701951 on epoch=107
05/21/2022 06:05:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.90 on epoch=107
05/21/2022 06:05:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.79 on epoch=108
05/21/2022 06:05:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.98 on epoch=109
05/21/2022 06:05:42 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.98 on epoch=109
05/21/2022 06:05:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.84 on epoch=110
05/21/2022 06:05:47 - INFO - __main__ - Global step 1550 Train loss 0.90 Classification-F1 0.40330712399095575 on epoch=110
05/21/2022 06:05:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.88 on epoch=111
05/21/2022 06:05:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.85 on epoch=112
05/21/2022 06:05:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.86 on epoch=112
05/21/2022 06:05:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.87 on epoch=113
05/21/2022 06:05:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.83 on epoch=114
05/21/2022 06:05:57 - INFO - __main__ - Global step 1600 Train loss 0.86 Classification-F1 0.41708146683921876 on epoch=114
05/21/2022 06:05:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.85 on epoch=114
05/21/2022 06:06:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.87 on epoch=115
05/21/2022 06:06:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.97 on epoch=116
05/21/2022 06:06:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.90 on epoch=117
05/21/2022 06:06:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.91 on epoch=117
05/21/2022 06:06:07 - INFO - __main__ - Global step 1650 Train loss 0.90 Classification-F1 0.35716845985819723 on epoch=117
05/21/2022 06:06:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.83 on epoch=118
05/21/2022 06:06:09 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.85 on epoch=119
05/21/2022 06:06:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.10 on epoch=119
05/21/2022 06:06:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.74 on epoch=120
05/21/2022 06:06:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.90 on epoch=121
05/21/2022 06:06:17 - INFO - __main__ - Global step 1700 Train loss 0.88 Classification-F1 0.3736332093988351 on epoch=121
05/21/2022 06:06:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.94 on epoch=122
05/21/2022 06:06:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.81 on epoch=122
05/21/2022 06:06:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.87 on epoch=123
05/21/2022 06:06:21 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.86 on epoch=124
05/21/2022 06:06:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.79 on epoch=124
05/21/2022 06:06:26 - INFO - __main__ - Global step 1750 Train loss 0.86 Classification-F1 0.3727163633176147 on epoch=124
05/21/2022 06:06:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.78 on epoch=125
05/21/2022 06:06:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.90 on epoch=126
05/21/2022 06:06:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.85 on epoch=127
05/21/2022 06:06:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.93 on epoch=127
05/21/2022 06:06:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.83 on epoch=128
05/21/2022 06:06:36 - INFO - __main__ - Global step 1800 Train loss 0.86 Classification-F1 0.4304162308929294 on epoch=128
05/21/2022 06:06:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.82 on epoch=129
05/21/2022 06:06:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.93 on epoch=129
05/21/2022 06:06:40 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.85 on epoch=130
05/21/2022 06:06:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.90 on epoch=131
05/21/2022 06:06:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.85 on epoch=132
05/21/2022 06:06:46 - INFO - __main__ - Global step 1850 Train loss 0.87 Classification-F1 0.4623991618423324 on epoch=132
05/21/2022 06:06:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.85 on epoch=132
05/21/2022 06:06:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.77 on epoch=133
05/21/2022 06:06:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.76 on epoch=134
05/21/2022 06:06:50 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.90 on epoch=134
05/21/2022 06:06:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.74 on epoch=135
05/21/2022 06:06:55 - INFO - __main__ - Global step 1900 Train loss 0.80 Classification-F1 0.4436138168874514 on epoch=135
05/21/2022 06:06:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.78 on epoch=136
05/21/2022 06:06:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.89 on epoch=137
05/21/2022 06:06:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/21/2022 06:07:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.77 on epoch=138
05/21/2022 06:07:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.81 on epoch=139
05/21/2022 06:07:05 - INFO - __main__ - Global step 1950 Train loss 0.81 Classification-F1 0.42787276712649647 on epoch=139
05/21/2022 06:07:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.86 on epoch=139
05/21/2022 06:07:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.71 on epoch=140
05/21/2022 06:07:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.85 on epoch=141
05/21/2022 06:07:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.90 on epoch=142
05/21/2022 06:07:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.76 on epoch=142
05/21/2022 06:07:15 - INFO - __main__ - Global step 2000 Train loss 0.82 Classification-F1 0.4385453812835994 on epoch=142
05/21/2022 06:07:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.79 on epoch=143
05/21/2022 06:07:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.83 on epoch=144
05/21/2022 06:07:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.95 on epoch=144
05/21/2022 06:07:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.72 on epoch=145
05/21/2022 06:07:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.81 on epoch=146
05/21/2022 06:07:25 - INFO - __main__ - Global step 2050 Train loss 0.82 Classification-F1 0.46395882373409864 on epoch=146
05/21/2022 06:07:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.78 on epoch=147
05/21/2022 06:07:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.84 on epoch=147
05/21/2022 06:07:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.80 on epoch=148
05/21/2022 06:07:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.88 on epoch=149
05/21/2022 06:07:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.79 on epoch=149
05/21/2022 06:07:34 - INFO - __main__ - Global step 2100 Train loss 0.82 Classification-F1 0.42404557595046066 on epoch=149
05/21/2022 06:07:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.83 on epoch=150
05/21/2022 06:07:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.85 on epoch=151
05/21/2022 06:07:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.87 on epoch=152
05/21/2022 06:07:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.85 on epoch=152
05/21/2022 06:07:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.75 on epoch=153
05/21/2022 06:07:44 - INFO - __main__ - Global step 2150 Train loss 0.83 Classification-F1 0.39032234008527106 on epoch=153
05/21/2022 06:07:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.84 on epoch=154
05/21/2022 06:07:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.81 on epoch=154
05/21/2022 06:07:48 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.72 on epoch=155
05/21/2022 06:07:49 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.82 on epoch=156
05/21/2022 06:07:51 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.87 on epoch=157
05/21/2022 06:07:54 - INFO - __main__ - Global step 2200 Train loss 0.81 Classification-F1 0.48344509779627665 on epoch=157
05/21/2022 06:07:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.71 on epoch=157
05/21/2022 06:07:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.86 on epoch=158
05/21/2022 06:07:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.72 on epoch=159
05/21/2022 06:07:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.85 on epoch=159
05/21/2022 06:08:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/21/2022 06:08:04 - INFO - __main__ - Global step 2250 Train loss 0.77 Classification-F1 0.3770890103392523 on epoch=160
05/21/2022 06:08:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.79 on epoch=161
05/21/2022 06:08:07 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.79 on epoch=162
05/21/2022 06:08:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.81 on epoch=162
05/21/2022 06:08:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.76 on epoch=163
05/21/2022 06:08:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.82 on epoch=164
05/21/2022 06:08:14 - INFO - __main__ - Global step 2300 Train loss 0.79 Classification-F1 0.37133132629956583 on epoch=164
05/21/2022 06:08:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.84 on epoch=164
05/21/2022 06:08:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.65 on epoch=165
05/21/2022 06:08:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.81 on epoch=166
05/21/2022 06:08:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.71 on epoch=167
05/21/2022 06:08:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.77 on epoch=167
05/21/2022 06:08:24 - INFO - __main__ - Global step 2350 Train loss 0.75 Classification-F1 0.3817790774202439 on epoch=167
05/21/2022 06:08:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.82 on epoch=168
05/21/2022 06:08:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.84 on epoch=169
05/21/2022 06:08:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.73 on epoch=169
05/21/2022 06:08:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.72 on epoch=170
05/21/2022 06:08:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.72 on epoch=171
05/21/2022 06:08:33 - INFO - __main__ - Global step 2400 Train loss 0.77 Classification-F1 0.4012833977222862 on epoch=171
05/21/2022 06:08:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.86 on epoch=172
05/21/2022 06:08:36 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.78 on epoch=172
05/21/2022 06:08:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.67 on epoch=173
05/21/2022 06:08:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.75 on epoch=174
05/21/2022 06:08:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.80 on epoch=174
05/21/2022 06:08:43 - INFO - __main__ - Global step 2450 Train loss 0.77 Classification-F1 0.4042802324383157 on epoch=174
05/21/2022 06:08:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.70 on epoch=175
05/21/2022 06:08:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.86 on epoch=176
05/21/2022 06:08:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.80 on epoch=177
05/21/2022 06:08:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.81 on epoch=177
05/21/2022 06:08:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.71 on epoch=178
05/21/2022 06:08:53 - INFO - __main__ - Global step 2500 Train loss 0.77 Classification-F1 0.39453271162975767 on epoch=178
05/21/2022 06:08:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.81 on epoch=179
05/21/2022 06:08:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.82 on epoch=179
05/21/2022 06:08:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.67 on epoch=180
05/21/2022 06:08:57 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.73 on epoch=181
05/21/2022 06:08:59 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.83 on epoch=182
05/21/2022 06:09:02 - INFO - __main__ - Global step 2550 Train loss 0.77 Classification-F1 0.3518740033362488 on epoch=182
05/21/2022 06:09:04 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.75 on epoch=182
05/21/2022 06:09:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.77 on epoch=183
05/21/2022 06:09:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.78 on epoch=184
05/21/2022 06:09:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.72 on epoch=184
05/21/2022 06:09:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.70 on epoch=185
05/21/2022 06:09:12 - INFO - __main__ - Global step 2600 Train loss 0.75 Classification-F1 0.31745212753394786 on epoch=185
05/21/2022 06:09:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.69 on epoch=186
05/21/2022 06:09:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.76 on epoch=187
05/21/2022 06:09:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.79 on epoch=187
05/21/2022 06:09:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.62 on epoch=188
05/21/2022 06:09:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.74 on epoch=189
05/21/2022 06:09:22 - INFO - __main__ - Global step 2650 Train loss 0.72 Classification-F1 0.40372174283738904 on epoch=189
05/21/2022 06:09:23 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.71 on epoch=189
05/21/2022 06:09:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.66 on epoch=190
05/21/2022 06:09:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.83 on epoch=191
05/21/2022 06:09:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.79 on epoch=192
05/21/2022 06:09:28 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.69 on epoch=192
05/21/2022 06:09:32 - INFO - __main__ - Global step 2700 Train loss 0.74 Classification-F1 0.4100883127046888 on epoch=192
05/21/2022 06:09:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.70 on epoch=193
05/21/2022 06:09:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.79 on epoch=194
05/21/2022 06:09:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.76 on epoch=194
05/21/2022 06:09:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.63 on epoch=195
05/21/2022 06:09:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.77 on epoch=196
05/21/2022 06:09:42 - INFO - __main__ - Global step 2750 Train loss 0.73 Classification-F1 0.3883938026508039 on epoch=196
05/21/2022 06:09:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.72 on epoch=197
05/21/2022 06:09:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.76 on epoch=197
05/21/2022 06:09:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.60 on epoch=198
05/21/2022 06:09:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.62 on epoch=199
05/21/2022 06:09:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.70 on epoch=199
05/21/2022 06:09:52 - INFO - __main__ - Global step 2800 Train loss 0.68 Classification-F1 0.3833147974452322 on epoch=199
05/21/2022 06:09:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.69 on epoch=200
05/21/2022 06:09:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.63 on epoch=201
05/21/2022 06:09:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.72 on epoch=202
05/21/2022 06:09:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/21/2022 06:09:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.66 on epoch=203
05/21/2022 06:10:02 - INFO - __main__ - Global step 2850 Train loss 0.68 Classification-F1 0.39932651326204033 on epoch=203
05/21/2022 06:10:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.62 on epoch=204
05/21/2022 06:10:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.72 on epoch=204
05/21/2022 06:10:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.74 on epoch=205
05/21/2022 06:10:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.74 on epoch=206
05/21/2022 06:10:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.71 on epoch=207
05/21/2022 06:10:12 - INFO - __main__ - Global step 2900 Train loss 0.71 Classification-F1 0.4870131073648216 on epoch=207
05/21/2022 06:10:12 - INFO - __main__ - Saving model with best Classification-F1: 0.48492477247681354 -> 0.4870131073648216 on epoch=207, global_step=2900
05/21/2022 06:10:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.62 on epoch=207
05/21/2022 06:10:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.64 on epoch=208
05/21/2022 06:10:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.69 on epoch=209
05/21/2022 06:10:17 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.79 on epoch=209
05/21/2022 06:10:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.71 on epoch=210
05/21/2022 06:10:22 - INFO - __main__ - Global step 2950 Train loss 0.69 Classification-F1 0.4705511760006969 on epoch=210
05/21/2022 06:10:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.78 on epoch=211
05/21/2022 06:10:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.75 on epoch=212
05/21/2022 06:10:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.64 on epoch=212
05/21/2022 06:10:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.60 on epoch=213
05/21/2022 06:10:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.80 on epoch=214
05/21/2022 06:10:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:10:30 - INFO - __main__ - Printing 3 examples
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:10:30 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:10:30 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:10:30 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:10:30 - INFO - __main__ - Printing 3 examples
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:10:30 - INFO - __main__ - ['Company']
05/21/2022 06:10:30 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:10:30 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:10:30 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:10:33 - INFO - __main__ - Global step 3000 Train loss 0.71 Classification-F1 0.41897897647316046 on epoch=214
05/21/2022 06:10:33 - INFO - __main__ - save last model!
05/21/2022 06:10:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 06:10:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 06:10:33 - INFO - __main__ - Printing 3 examples
05/21/2022 06:10:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 06:10:33 - INFO - __main__ - ['Animal']
05/21/2022 06:10:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 06:10:33 - INFO - __main__ - ['Animal']
05/21/2022 06:10:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 06:10:33 - INFO - __main__ - ['Village']
05/21/2022 06:10:33 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:10:34 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:10:36 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:10:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:10:36 - INFO - __main__ - Starting training!
05/21/2022 06:10:38 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:11:49 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
05/21/2022 06:11:49 - INFO - __main__ - Classification-F1 on test data: 0.2252
05/21/2022 06:11:50 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.4870131073648216, test_performance=0.22521467901078668
05/21/2022 06:11:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
05/21/2022 06:11:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:11:51 - INFO - __main__ - Printing 3 examples
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:11:51 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:11:51 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:11:51 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:11:51 - INFO - __main__ - Printing 3 examples
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:11:51 - INFO - __main__ - ['Company']
05/21/2022 06:11:51 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:11:51 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:11:51 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:11:57 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:11:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:11:58 - INFO - __main__ - Starting training!
05/21/2022 06:11:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.75 on epoch=0
05/21/2022 06:12:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.92 on epoch=1
05/21/2022 06:12:02 - INFO - __main__ - Step 30 Global step 30 Train loss 6.28 on epoch=2
05/21/2022 06:12:03 - INFO - __main__ - Step 40 Global step 40 Train loss 5.64 on epoch=2
05/21/2022 06:12:04 - INFO - __main__ - Step 50 Global step 50 Train loss 5.55 on epoch=3
05/21/2022 06:12:07 - INFO - __main__ - Global step 50 Train loss 6.43 Classification-F1 0.0 on epoch=3
05/21/2022 06:12:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:12:08 - INFO - __main__ - Step 60 Global step 60 Train loss 5.02 on epoch=4
05/21/2022 06:12:10 - INFO - __main__ - Step 70 Global step 70 Train loss 4.93 on epoch=4
05/21/2022 06:12:11 - INFO - __main__ - Step 80 Global step 80 Train loss 4.37 on epoch=5
05/21/2022 06:12:12 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=6
05/21/2022 06:12:13 - INFO - __main__ - Step 100 Global step 100 Train loss 4.05 on epoch=7
05/21/2022 06:12:17 - INFO - __main__ - Global step 100 Train loss 4.56 Classification-F1 0.0 on epoch=7
05/21/2022 06:12:18 - INFO - __main__ - Step 110 Global step 110 Train loss 3.62 on epoch=7
05/21/2022 06:12:19 - INFO - __main__ - Step 120 Global step 120 Train loss 3.78 on epoch=8
05/21/2022 06:12:21 - INFO - __main__ - Step 130 Global step 130 Train loss 3.55 on epoch=9
05/21/2022 06:12:22 - INFO - __main__ - Step 140 Global step 140 Train loss 3.51 on epoch=9
05/21/2022 06:12:23 - INFO - __main__ - Step 150 Global step 150 Train loss 3.11 on epoch=10
05/21/2022 06:12:25 - INFO - __main__ - Global step 150 Train loss 3.51 Classification-F1 0.007909604519774013 on epoch=10
05/21/2022 06:12:25 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007909604519774013 on epoch=10, global_step=150
05/21/2022 06:12:27 - INFO - __main__ - Step 160 Global step 160 Train loss 3.17 on epoch=11
05/21/2022 06:12:28 - INFO - __main__ - Step 170 Global step 170 Train loss 2.95 on epoch=12
05/21/2022 06:12:29 - INFO - __main__ - Step 180 Global step 180 Train loss 2.79 on epoch=12
05/21/2022 06:12:30 - INFO - __main__ - Step 190 Global step 190 Train loss 2.76 on epoch=13
05/21/2022 06:12:32 - INFO - __main__ - Step 200 Global step 200 Train loss 2.59 on epoch=14
05/21/2022 06:12:34 - INFO - __main__ - Global step 200 Train loss 2.85 Classification-F1 0.008849557522123895 on epoch=14
05/21/2022 06:12:34 - INFO - __main__ - Saving model with best Classification-F1: 0.007909604519774013 -> 0.008849557522123895 on epoch=14, global_step=200
05/21/2022 06:12:35 - INFO - __main__ - Step 210 Global step 210 Train loss 2.72 on epoch=14
05/21/2022 06:12:36 - INFO - __main__ - Step 220 Global step 220 Train loss 2.36 on epoch=15
05/21/2022 06:12:38 - INFO - __main__ - Step 230 Global step 230 Train loss 2.51 on epoch=16
05/21/2022 06:12:39 - INFO - __main__ - Step 240 Global step 240 Train loss 2.44 on epoch=17
05/21/2022 06:12:40 - INFO - __main__ - Step 250 Global step 250 Train loss 2.19 on epoch=17
05/21/2022 06:12:42 - INFO - __main__ - Global step 250 Train loss 2.44 Classification-F1 0.009523809523809523 on epoch=17
05/21/2022 06:12:42 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=17, global_step=250
05/21/2022 06:12:43 - INFO - __main__ - Step 260 Global step 260 Train loss 2.33 on epoch=18
05/21/2022 06:12:44 - INFO - __main__ - Step 270 Global step 270 Train loss 2.23 on epoch=19
05/21/2022 06:12:46 - INFO - __main__ - Step 280 Global step 280 Train loss 2.16 on epoch=19
05/21/2022 06:12:47 - INFO - __main__ - Step 290 Global step 290 Train loss 1.94 on epoch=20
05/21/2022 06:12:48 - INFO - __main__ - Step 300 Global step 300 Train loss 1.99 on epoch=21
05/21/2022 06:12:50 - INFO - __main__ - Global step 300 Train loss 2.13 Classification-F1 0.009603841536614645 on epoch=21
05/21/2022 06:12:50 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.009603841536614645 on epoch=21, global_step=300
05/21/2022 06:12:51 - INFO - __main__ - Step 310 Global step 310 Train loss 2.07 on epoch=22
05/21/2022 06:12:52 - INFO - __main__ - Step 320 Global step 320 Train loss 1.87 on epoch=22
05/21/2022 06:12:54 - INFO - __main__ - Step 330 Global step 330 Train loss 1.86 on epoch=23
05/21/2022 06:12:55 - INFO - __main__ - Step 340 Global step 340 Train loss 1.85 on epoch=24
05/21/2022 06:12:56 - INFO - __main__ - Step 350 Global step 350 Train loss 1.93 on epoch=24
05/21/2022 06:12:58 - INFO - __main__ - Global step 350 Train loss 1.91 Classification-F1 0.03281995365953387 on epoch=24
05/21/2022 06:12:58 - INFO - __main__ - Saving model with best Classification-F1: 0.009603841536614645 -> 0.03281995365953387 on epoch=24, global_step=350
05/21/2022 06:12:59 - INFO - __main__ - Step 360 Global step 360 Train loss 1.65 on epoch=25
05/21/2022 06:13:00 - INFO - __main__ - Step 370 Global step 370 Train loss 1.79 on epoch=26
05/21/2022 06:13:02 - INFO - __main__ - Step 380 Global step 380 Train loss 1.76 on epoch=27
05/21/2022 06:13:03 - INFO - __main__ - Step 390 Global step 390 Train loss 1.61 on epoch=27
05/21/2022 06:13:04 - INFO - __main__ - Step 400 Global step 400 Train loss 1.59 on epoch=28
05/21/2022 06:13:06 - INFO - __main__ - Global step 400 Train loss 1.68 Classification-F1 0.022251980169810243 on epoch=28
05/21/2022 06:13:07 - INFO - __main__ - Step 410 Global step 410 Train loss 1.57 on epoch=29
05/21/2022 06:13:08 - INFO - __main__ - Step 420 Global step 420 Train loss 1.61 on epoch=29
05/21/2022 06:13:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.48 on epoch=30
05/21/2022 06:13:11 - INFO - __main__ - Step 440 Global step 440 Train loss 1.59 on epoch=31
05/21/2022 06:13:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.56 on epoch=32
05/21/2022 06:13:14 - INFO - __main__ - Global step 450 Train loss 1.56 Classification-F1 0.0257512276917554 on epoch=32
05/21/2022 06:13:15 - INFO - __main__ - Step 460 Global step 460 Train loss 1.43 on epoch=32
05/21/2022 06:13:17 - INFO - __main__ - Step 470 Global step 470 Train loss 1.52 on epoch=33
05/21/2022 06:13:18 - INFO - __main__ - Step 480 Global step 480 Train loss 1.48 on epoch=34
05/21/2022 06:13:19 - INFO - __main__ - Step 490 Global step 490 Train loss 1.45 on epoch=34
05/21/2022 06:13:20 - INFO - __main__ - Step 500 Global step 500 Train loss 1.44 on epoch=35
05/21/2022 06:13:23 - INFO - __main__ - Global step 500 Train loss 1.47 Classification-F1 0.0268251128716245 on epoch=35
05/21/2022 06:13:24 - INFO - __main__ - Step 510 Global step 510 Train loss 1.37 on epoch=36
05/21/2022 06:13:25 - INFO - __main__ - Step 520 Global step 520 Train loss 1.47 on epoch=37
05/21/2022 06:13:26 - INFO - __main__ - Step 530 Global step 530 Train loss 1.33 on epoch=37
05/21/2022 06:13:27 - INFO - __main__ - Step 540 Global step 540 Train loss 1.32 on epoch=38
05/21/2022 06:13:29 - INFO - __main__ - Step 550 Global step 550 Train loss 1.38 on epoch=39
05/21/2022 06:13:31 - INFO - __main__ - Global step 550 Train loss 1.37 Classification-F1 0.023153331193325712 on epoch=39
05/21/2022 06:13:32 - INFO - __main__ - Step 560 Global step 560 Train loss 1.28 on epoch=39
05/21/2022 06:13:34 - INFO - __main__ - Step 570 Global step 570 Train loss 1.28 on epoch=40
05/21/2022 06:13:35 - INFO - __main__ - Step 580 Global step 580 Train loss 1.38 on epoch=41
05/21/2022 06:13:36 - INFO - __main__ - Step 590 Global step 590 Train loss 1.29 on epoch=42
05/21/2022 06:13:37 - INFO - __main__ - Step 600 Global step 600 Train loss 1.31 on epoch=42
05/21/2022 06:13:39 - INFO - __main__ - Global step 600 Train loss 1.31 Classification-F1 0.07989073342810764 on epoch=42
05/21/2022 06:13:39 - INFO - __main__ - Saving model with best Classification-F1: 0.03281995365953387 -> 0.07989073342810764 on epoch=42, global_step=600
05/21/2022 06:13:41 - INFO - __main__ - Step 610 Global step 610 Train loss 1.28 on epoch=43
05/21/2022 06:13:42 - INFO - __main__ - Step 620 Global step 620 Train loss 1.26 on epoch=44
05/21/2022 06:13:43 - INFO - __main__ - Step 630 Global step 630 Train loss 1.29 on epoch=44
05/21/2022 06:13:44 - INFO - __main__ - Step 640 Global step 640 Train loss 1.25 on epoch=45
05/21/2022 06:13:46 - INFO - __main__ - Step 650 Global step 650 Train loss 1.36 on epoch=46
05/21/2022 06:13:48 - INFO - __main__ - Global step 650 Train loss 1.29 Classification-F1 0.0333884537714907 on epoch=46
05/21/2022 06:13:49 - INFO - __main__ - Step 660 Global step 660 Train loss 1.27 on epoch=47
05/21/2022 06:13:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.20 on epoch=47
05/21/2022 06:13:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.22 on epoch=48
05/21/2022 06:13:53 - INFO - __main__ - Step 690 Global step 690 Train loss 1.33 on epoch=49
05/21/2022 06:13:54 - INFO - __main__ - Step 700 Global step 700 Train loss 1.32 on epoch=49
05/21/2022 06:13:57 - INFO - __main__ - Global step 700 Train loss 1.27 Classification-F1 0.06235792947315912 on epoch=49
05/21/2022 06:13:58 - INFO - __main__ - Step 710 Global step 710 Train loss 1.20 on epoch=50
05/21/2022 06:14:00 - INFO - __main__ - Step 720 Global step 720 Train loss 1.33 on epoch=51
05/21/2022 06:14:01 - INFO - __main__ - Step 730 Global step 730 Train loss 1.23 on epoch=52
05/21/2022 06:14:02 - INFO - __main__ - Step 740 Global step 740 Train loss 1.10 on epoch=52
05/21/2022 06:14:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.20 on epoch=53
05/21/2022 06:14:06 - INFO - __main__ - Global step 750 Train loss 1.21 Classification-F1 0.03989622202212662 on epoch=53
05/21/2022 06:14:07 - INFO - __main__ - Step 760 Global step 760 Train loss 1.25 on epoch=54
05/21/2022 06:14:09 - INFO - __main__ - Step 770 Global step 770 Train loss 1.22 on epoch=54
05/21/2022 06:14:10 - INFO - __main__ - Step 780 Global step 780 Train loss 1.15 on epoch=55
05/21/2022 06:14:11 - INFO - __main__ - Step 790 Global step 790 Train loss 1.24 on epoch=56
05/21/2022 06:14:12 - INFO - __main__ - Step 800 Global step 800 Train loss 1.23 on epoch=57
05/21/2022 06:14:15 - INFO - __main__ - Global step 800 Train loss 1.22 Classification-F1 0.17678883366948178 on epoch=57
05/21/2022 06:14:15 - INFO - __main__ - Saving model with best Classification-F1: 0.07989073342810764 -> 0.17678883366948178 on epoch=57, global_step=800
05/21/2022 06:14:16 - INFO - __main__ - Step 810 Global step 810 Train loss 1.18 on epoch=57
05/21/2022 06:14:17 - INFO - __main__ - Step 820 Global step 820 Train loss 1.20 on epoch=58
05/21/2022 06:14:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.22 on epoch=59
05/21/2022 06:14:20 - INFO - __main__ - Step 840 Global step 840 Train loss 1.16 on epoch=59
05/21/2022 06:14:21 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=60
05/21/2022 06:14:24 - INFO - __main__ - Global step 850 Train loss 1.19 Classification-F1 0.06428265786417263 on epoch=60
05/21/2022 06:14:25 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/21/2022 06:14:26 - INFO - __main__ - Step 870 Global step 870 Train loss 1.24 on epoch=62
05/21/2022 06:14:28 - INFO - __main__ - Step 880 Global step 880 Train loss 1.08 on epoch=62
05/21/2022 06:14:29 - INFO - __main__ - Step 890 Global step 890 Train loss 1.20 on epoch=63
05/21/2022 06:14:30 - INFO - __main__ - Step 900 Global step 900 Train loss 1.20 on epoch=64
05/21/2022 06:14:32 - INFO - __main__ - Global step 900 Train loss 1.20 Classification-F1 0.1396898040660333 on epoch=64
05/21/2022 06:14:34 - INFO - __main__ - Step 910 Global step 910 Train loss 1.14 on epoch=64
05/21/2022 06:14:35 - INFO - __main__ - Step 920 Global step 920 Train loss 1.03 on epoch=65
05/21/2022 06:14:36 - INFO - __main__ - Step 930 Global step 930 Train loss 1.25 on epoch=66
05/21/2022 06:14:37 - INFO - __main__ - Step 940 Global step 940 Train loss 1.16 on epoch=67
05/21/2022 06:14:39 - INFO - __main__ - Step 950 Global step 950 Train loss 1.09 on epoch=67
05/21/2022 06:14:41 - INFO - __main__ - Global step 950 Train loss 1.13 Classification-F1 0.2607884080056811 on epoch=67
05/21/2022 06:14:41 - INFO - __main__ - Saving model with best Classification-F1: 0.17678883366948178 -> 0.2607884080056811 on epoch=67, global_step=950
05/21/2022 06:14:43 - INFO - __main__ - Step 960 Global step 960 Train loss 1.19 on epoch=68
05/21/2022 06:14:44 - INFO - __main__ - Step 970 Global step 970 Train loss 1.13 on epoch=69
05/21/2022 06:14:45 - INFO - __main__ - Step 980 Global step 980 Train loss 1.19 on epoch=69
05/21/2022 06:14:46 - INFO - __main__ - Step 990 Global step 990 Train loss 1.15 on epoch=70
05/21/2022 06:14:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.15 on epoch=71
05/21/2022 06:14:51 - INFO - __main__ - Global step 1000 Train loss 1.16 Classification-F1 0.208198847391394 on epoch=71
05/21/2022 06:14:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.13 on epoch=72
05/21/2022 06:14:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.00 on epoch=72
05/21/2022 06:14:54 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.11 on epoch=73
05/21/2022 06:14:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.11 on epoch=74
05/21/2022 06:14:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.11 on epoch=74
05/21/2022 06:15:00 - INFO - __main__ - Global step 1050 Train loss 1.09 Classification-F1 0.296853977886774 on epoch=74
05/21/2022 06:15:00 - INFO - __main__ - Saving model with best Classification-F1: 0.2607884080056811 -> 0.296853977886774 on epoch=74, global_step=1050
05/21/2022 06:15:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.05 on epoch=75
05/21/2022 06:15:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.08 on epoch=76
05/21/2022 06:15:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.17 on epoch=77
05/21/2022 06:15:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.97 on epoch=77
05/21/2022 06:15:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.05 on epoch=78
05/21/2022 06:15:09 - INFO - __main__ - Global step 1100 Train loss 1.06 Classification-F1 0.2971531826107923 on epoch=78
05/21/2022 06:15:09 - INFO - __main__ - Saving model with best Classification-F1: 0.296853977886774 -> 0.2971531826107923 on epoch=78, global_step=1100
05/21/2022 06:15:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.11 on epoch=79
05/21/2022 06:15:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.08 on epoch=79
05/21/2022 06:15:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.98 on epoch=80
05/21/2022 06:15:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.17 on epoch=81
05/21/2022 06:15:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.11 on epoch=82
05/21/2022 06:15:19 - INFO - __main__ - Global step 1150 Train loss 1.09 Classification-F1 0.3746964368208783 on epoch=82
05/21/2022 06:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.2971531826107923 -> 0.3746964368208783 on epoch=82, global_step=1150
05/21/2022 06:15:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.04 on epoch=82
05/21/2022 06:15:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.08 on epoch=83
05/21/2022 06:15:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.10 on epoch=84
05/21/2022 06:15:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.03 on epoch=84
05/21/2022 06:15:25 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.15 on epoch=85
05/21/2022 06:15:28 - INFO - __main__ - Global step 1200 Train loss 1.08 Classification-F1 0.37118110361533346 on epoch=85
05/21/2022 06:15:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.02 on epoch=86
05/21/2022 06:15:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.06 on epoch=87
05/21/2022 06:15:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.04 on epoch=87
05/21/2022 06:15:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.07 on epoch=88
05/21/2022 06:15:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.00 on epoch=89
05/21/2022 06:15:37 - INFO - __main__ - Global step 1250 Train loss 1.04 Classification-F1 0.362679676992809 on epoch=89
05/21/2022 06:15:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.04 on epoch=89
05/21/2022 06:15:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.94 on epoch=90
05/21/2022 06:15:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.09 on epoch=91
05/21/2022 06:15:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.09 on epoch=92
05/21/2022 06:15:44 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.96 on epoch=92
05/21/2022 06:15:47 - INFO - __main__ - Global step 1300 Train loss 1.02 Classification-F1 0.3896652264780717 on epoch=92
05/21/2022 06:15:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3746964368208783 -> 0.3896652264780717 on epoch=92, global_step=1300
05/21/2022 06:15:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.96 on epoch=93
05/21/2022 06:15:50 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.98 on epoch=94
05/21/2022 06:15:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.98 on epoch=94
05/21/2022 06:15:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.02 on epoch=95
05/21/2022 06:15:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.07 on epoch=96
05/21/2022 06:15:57 - INFO - __main__ - Global step 1350 Train loss 1.00 Classification-F1 0.3896999813761542 on epoch=96
05/21/2022 06:15:57 - INFO - __main__ - Saving model with best Classification-F1: 0.3896652264780717 -> 0.3896999813761542 on epoch=96, global_step=1350
05/21/2022 06:15:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.93 on epoch=97
05/21/2022 06:15:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.99 on epoch=97
05/21/2022 06:16:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.01 on epoch=98
05/21/2022 06:16:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.96 on epoch=99
05/21/2022 06:16:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.93 on epoch=99
05/21/2022 06:16:06 - INFO - __main__ - Global step 1400 Train loss 0.96 Classification-F1 0.397766103351814 on epoch=99
05/21/2022 06:16:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3896999813761542 -> 0.397766103351814 on epoch=99, global_step=1400
05/21/2022 06:16:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.92 on epoch=100
05/21/2022 06:16:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.05 on epoch=101
05/21/2022 06:16:10 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.98 on epoch=102
05/21/2022 06:16:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.96 on epoch=102
05/21/2022 06:16:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.91 on epoch=103
05/21/2022 06:16:15 - INFO - __main__ - Global step 1450 Train loss 0.97 Classification-F1 0.44688606739496894 on epoch=103
05/21/2022 06:16:15 - INFO - __main__ - Saving model with best Classification-F1: 0.397766103351814 -> 0.44688606739496894 on epoch=103, global_step=1450
05/21/2022 06:16:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.92 on epoch=104
05/21/2022 06:16:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.00 on epoch=104
05/21/2022 06:16:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.86 on epoch=105
05/21/2022 06:16:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.99 on epoch=106
05/21/2022 06:16:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.86 on epoch=107
05/21/2022 06:16:25 - INFO - __main__ - Global step 1500 Train loss 0.93 Classification-F1 0.4668924486250462 on epoch=107
05/21/2022 06:16:25 - INFO - __main__ - Saving model with best Classification-F1: 0.44688606739496894 -> 0.4668924486250462 on epoch=107, global_step=1500
05/21/2022 06:16:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.87 on epoch=107
05/21/2022 06:16:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.90 on epoch=108
05/21/2022 06:16:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.88 on epoch=109
05/21/2022 06:16:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.02 on epoch=109
05/21/2022 06:16:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.77 on epoch=110
05/21/2022 06:16:35 - INFO - __main__ - Global step 1550 Train loss 0.89 Classification-F1 0.45929679817693514 on epoch=110
05/21/2022 06:16:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.96 on epoch=111
05/21/2022 06:16:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.88 on epoch=112
05/21/2022 06:16:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.89 on epoch=112
05/21/2022 06:16:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.82 on epoch=113
05/21/2022 06:16:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.87 on epoch=114
05/21/2022 06:16:44 - INFO - __main__ - Global step 1600 Train loss 0.89 Classification-F1 0.46867252096240897 on epoch=114
05/21/2022 06:16:44 - INFO - __main__ - Saving model with best Classification-F1: 0.4668924486250462 -> 0.46867252096240897 on epoch=114, global_step=1600
05/21/2022 06:16:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.94 on epoch=114
05/21/2022 06:16:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.76 on epoch=115
05/21/2022 06:16:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.82 on epoch=116
05/21/2022 06:16:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.88 on epoch=117
05/21/2022 06:16:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.89 on epoch=117
05/21/2022 06:16:53 - INFO - __main__ - Global step 1650 Train loss 0.86 Classification-F1 0.41486922134730125 on epoch=117
05/21/2022 06:16:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.89 on epoch=118
05/21/2022 06:16:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.82 on epoch=119
05/21/2022 06:16:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.83 on epoch=119
05/21/2022 06:16:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.90 on epoch=120
05/21/2022 06:17:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.87 on epoch=121
05/21/2022 06:17:03 - INFO - __main__ - Global step 1700 Train loss 0.86 Classification-F1 0.407162480865902 on epoch=121
05/21/2022 06:17:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.88 on epoch=122
05/21/2022 06:17:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.78 on epoch=122
05/21/2022 06:17:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.91 on epoch=123
05/21/2022 06:17:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.83 on epoch=124
05/21/2022 06:17:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.85 on epoch=124
05/21/2022 06:17:12 - INFO - __main__ - Global step 1750 Train loss 0.85 Classification-F1 0.4141797550425481 on epoch=124
05/21/2022 06:17:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.88 on epoch=125
05/21/2022 06:17:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.85 on epoch=126
05/21/2022 06:17:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=127
05/21/2022 06:17:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.80 on epoch=127
05/21/2022 06:17:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.76 on epoch=128
05/21/2022 06:17:22 - INFO - __main__ - Global step 1800 Train loss 0.85 Classification-F1 0.4869835940982847 on epoch=128
05/21/2022 06:17:22 - INFO - __main__ - Saving model with best Classification-F1: 0.46867252096240897 -> 0.4869835940982847 on epoch=128, global_step=1800
05/21/2022 06:17:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.81 on epoch=129
05/21/2022 06:17:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.85 on epoch=129
05/21/2022 06:17:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.87 on epoch=130
05/21/2022 06:17:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.89 on epoch=131
05/21/2022 06:17:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.89 on epoch=132
05/21/2022 06:17:31 - INFO - __main__ - Global step 1850 Train loss 0.86 Classification-F1 0.48301759213671386 on epoch=132
05/21/2022 06:17:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.75 on epoch=132
05/21/2022 06:17:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.69 on epoch=133
05/21/2022 06:17:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.79 on epoch=134
05/21/2022 06:17:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.82 on epoch=134
05/21/2022 06:17:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.79 on epoch=135
05/21/2022 06:17:41 - INFO - __main__ - Global step 1900 Train loss 0.77 Classification-F1 0.38612758447344914 on epoch=135
05/21/2022 06:17:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.82 on epoch=136
05/21/2022 06:17:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.84 on epoch=137
05/21/2022 06:17:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.74 on epoch=137
05/21/2022 06:17:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.79 on epoch=138
05/21/2022 06:17:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.78 on epoch=139
05/21/2022 06:17:51 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.45631396664893387 on epoch=139
05/21/2022 06:17:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.81 on epoch=139
05/21/2022 06:17:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.77 on epoch=140
05/21/2022 06:17:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.74 on epoch=141
05/21/2022 06:17:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.79 on epoch=142
05/21/2022 06:17:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.80 on epoch=142
05/21/2022 06:18:01 - INFO - __main__ - Global step 2000 Train loss 0.78 Classification-F1 0.473439897988087 on epoch=142
05/21/2022 06:18:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.75 on epoch=143
05/21/2022 06:18:04 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.77 on epoch=144
05/21/2022 06:18:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.72 on epoch=144
05/21/2022 06:18:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.72 on epoch=145
05/21/2022 06:18:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.86 on epoch=146
05/21/2022 06:18:11 - INFO - __main__ - Global step 2050 Train loss 0.76 Classification-F1 0.39693075524138 on epoch=146
05/21/2022 06:18:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.77 on epoch=147
05/21/2022 06:18:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.69 on epoch=147
05/21/2022 06:18:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.78 on epoch=148
05/21/2022 06:18:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.76 on epoch=149
05/21/2022 06:18:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.76 on epoch=149
05/21/2022 06:18:21 - INFO - __main__ - Global step 2100 Train loss 0.75 Classification-F1 0.363243387048246 on epoch=149
05/21/2022 06:18:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.65 on epoch=150
05/21/2022 06:18:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.75 on epoch=151
05/21/2022 06:18:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.79 on epoch=152
05/21/2022 06:18:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.73 on epoch=152
05/21/2022 06:18:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.71 on epoch=153
05/21/2022 06:18:31 - INFO - __main__ - Global step 2150 Train loss 0.73 Classification-F1 0.371111735372387 on epoch=153
05/21/2022 06:18:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.71 on epoch=154
05/21/2022 06:18:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.73 on epoch=154
05/21/2022 06:18:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.67 on epoch=155
05/21/2022 06:18:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.66 on epoch=156
05/21/2022 06:18:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.71 on epoch=157
05/21/2022 06:18:41 - INFO - __main__ - Global step 2200 Train loss 0.70 Classification-F1 0.3883600191804526 on epoch=157
05/21/2022 06:18:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.71 on epoch=157
05/21/2022 06:18:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.63 on epoch=158
05/21/2022 06:18:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.67 on epoch=159
05/21/2022 06:18:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/21/2022 06:18:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.59 on epoch=160
05/21/2022 06:18:52 - INFO - __main__ - Global step 2250 Train loss 0.66 Classification-F1 0.4039625981765836 on epoch=160
05/21/2022 06:18:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.74 on epoch=161
05/21/2022 06:18:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.70 on epoch=162
05/21/2022 06:18:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.60 on epoch=162
05/21/2022 06:18:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.75 on epoch=163
05/21/2022 06:18:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.66 on epoch=164
05/21/2022 06:19:02 - INFO - __main__ - Global step 2300 Train loss 0.69 Classification-F1 0.3713061408729262 on epoch=164
05/21/2022 06:19:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.74 on epoch=164
05/21/2022 06:19:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.63 on epoch=165
05/21/2022 06:19:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.67 on epoch=166
05/21/2022 06:19:07 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.74 on epoch=167
05/21/2022 06:19:09 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.69 on epoch=167
05/21/2022 06:19:12 - INFO - __main__ - Global step 2350 Train loss 0.69 Classification-F1 0.41441566576375116 on epoch=167
05/21/2022 06:19:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.72 on epoch=168
05/21/2022 06:19:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/21/2022 06:19:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.73 on epoch=169
05/21/2022 06:19:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.60 on epoch=170
05/21/2022 06:19:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.76 on epoch=171
05/21/2022 06:19:22 - INFO - __main__ - Global step 2400 Train loss 0.70 Classification-F1 0.4528631908331156 on epoch=171
05/21/2022 06:19:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.66 on epoch=172
05/21/2022 06:19:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.66 on epoch=172
05/21/2022 06:19:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.61 on epoch=173
05/21/2022 06:19:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.68 on epoch=174
05/21/2022 06:19:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.64 on epoch=174
05/21/2022 06:19:33 - INFO - __main__ - Global step 2450 Train loss 0.65 Classification-F1 0.44983506232721326 on epoch=174
05/21/2022 06:19:34 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.60 on epoch=175
05/21/2022 06:19:35 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.67 on epoch=176
05/21/2022 06:19:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.72 on epoch=177
05/21/2022 06:19:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.68 on epoch=177
05/21/2022 06:19:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.68 on epoch=178
05/21/2022 06:19:43 - INFO - __main__ - Global step 2500 Train loss 0.67 Classification-F1 0.4961425596654536 on epoch=178
05/21/2022 06:19:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4869835940982847 -> 0.4961425596654536 on epoch=178, global_step=2500
05/21/2022 06:19:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.66 on epoch=179
05/21/2022 06:19:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.76 on epoch=179
05/21/2022 06:19:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.54 on epoch=180
05/21/2022 06:19:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.64 on epoch=181
05/21/2022 06:19:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.69 on epoch=182
05/21/2022 06:19:54 - INFO - __main__ - Global step 2550 Train loss 0.66 Classification-F1 0.4380040061994949 on epoch=182
05/21/2022 06:19:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/21/2022 06:19:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.60 on epoch=183
05/21/2022 06:19:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.63 on epoch=184
05/21/2022 06:19:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.69 on epoch=184
05/21/2022 06:20:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.60 on epoch=185
05/21/2022 06:20:04 - INFO - __main__ - Global step 2600 Train loss 0.63 Classification-F1 0.43946915881729876 on epoch=185
05/21/2022 06:20:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.65 on epoch=186
05/21/2022 06:20:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/21/2022 06:20:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.64 on epoch=187
05/21/2022 06:20:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/21/2022 06:20:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.71 on epoch=189
05/21/2022 06:20:14 - INFO - __main__ - Global step 2650 Train loss 0.66 Classification-F1 0.5118123463765093 on epoch=189
05/21/2022 06:20:14 - INFO - __main__ - Saving model with best Classification-F1: 0.4961425596654536 -> 0.5118123463765093 on epoch=189, global_step=2650
05/21/2022 06:20:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.68 on epoch=189
05/21/2022 06:20:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.48 on epoch=190
05/21/2022 06:20:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.66 on epoch=191
05/21/2022 06:20:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.62 on epoch=192
05/21/2022 06:20:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.65 on epoch=192
05/21/2022 06:20:25 - INFO - __main__ - Global step 2700 Train loss 0.62 Classification-F1 0.4512262285221224 on epoch=192
05/21/2022 06:20:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.62 on epoch=193
05/21/2022 06:20:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.69 on epoch=194
05/21/2022 06:20:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.62 on epoch=194
05/21/2022 06:20:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.56 on epoch=195
05/21/2022 06:20:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.69 on epoch=196
05/21/2022 06:20:35 - INFO - __main__ - Global step 2750 Train loss 0.64 Classification-F1 0.48441908506193476 on epoch=196
05/21/2022 06:20:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.70 on epoch=197
05/21/2022 06:20:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.63 on epoch=197
05/21/2022 06:20:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.59 on epoch=198
05/21/2022 06:20:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.55 on epoch=199
05/21/2022 06:20:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.64 on epoch=199
05/21/2022 06:20:46 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.5247447941080094 on epoch=199
05/21/2022 06:20:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5118123463765093 -> 0.5247447941080094 on epoch=199, global_step=2800
05/21/2022 06:20:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.62 on epoch=200
05/21/2022 06:20:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.58 on epoch=201
05/21/2022 06:20:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.67 on epoch=202
05/21/2022 06:20:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/21/2022 06:20:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.63 on epoch=203
05/21/2022 06:20:56 - INFO - __main__ - Global step 2850 Train loss 0.62 Classification-F1 0.4913647250859154 on epoch=203
05/21/2022 06:20:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.63 on epoch=204
05/21/2022 06:20:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.62 on epoch=204
05/21/2022 06:21:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.55 on epoch=205
05/21/2022 06:21:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/21/2022 06:21:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.63 on epoch=207
05/21/2022 06:21:07 - INFO - __main__ - Global step 2900 Train loss 0.61 Classification-F1 0.4880918233240215 on epoch=207
05/21/2022 06:21:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.55 on epoch=207
05/21/2022 06:21:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.56 on epoch=208
05/21/2022 06:21:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.65 on epoch=209
05/21/2022 06:21:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.71 on epoch=209
05/21/2022 06:21:13 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.51 on epoch=210
05/21/2022 06:21:17 - INFO - __main__ - Global step 2950 Train loss 0.60 Classification-F1 0.4856148914289321 on epoch=210
05/21/2022 06:21:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.58 on epoch=211
05/21/2022 06:21:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.65 on epoch=212
05/21/2022 06:21:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.62 on epoch=212
05/21/2022 06:21:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.64 on epoch=213
05/21/2022 06:21:24 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.52 on epoch=214
05/21/2022 06:21:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:21:25 - INFO - __main__ - Printing 3 examples
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:21:25 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:21:25 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:21:25 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:21:25 - INFO - __main__ - Printing 3 examples
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:21:25 - INFO - __main__ - ['Company']
05/21/2022 06:21:25 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:21:25 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:21:25 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:21:27 - INFO - __main__ - Global step 3000 Train loss 0.60 Classification-F1 0.5410753259914368 on epoch=214
05/21/2022 06:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5247447941080094 -> 0.5410753259914368 on epoch=214, global_step=3000
05/21/2022 06:21:28 - INFO - __main__ - save last model!
05/21/2022 06:21:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 06:21:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 06:21:28 - INFO - __main__ - Printing 3 examples
05/21/2022 06:21:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 06:21:28 - INFO - __main__ - ['Animal']
05/21/2022 06:21:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 06:21:28 - INFO - __main__ - ['Animal']
05/21/2022 06:21:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 06:21:28 - INFO - __main__ - ['Village']
05/21/2022 06:21:28 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:21:29 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:21:31 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:21:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:21:32 - INFO - __main__ - Starting training!
05/21/2022 06:21:33 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:22:45 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
05/21/2022 06:22:45 - INFO - __main__ - Classification-F1 on test data: 0.2168
05/21/2022 06:22:46 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.5410753259914368, test_performance=0.2168230204016608
05/21/2022 06:22:46 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
05/21/2022 06:22:47 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:22:47 - INFO - __main__ - Printing 3 examples
05/21/2022 06:22:47 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:22:47 - INFO - __main__ - ['Company']
05/21/2022 06:22:47 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:22:47 - INFO - __main__ - ['Company']
05/21/2022 06:22:47 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:22:47 - INFO - __main__ - ['Company']
05/21/2022 06:22:47 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:22:47 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:22:48 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:22:48 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:22:48 - INFO - __main__ - Printing 3 examples
05/21/2022 06:22:48 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:22:48 - INFO - __main__ - ['Company']
05/21/2022 06:22:48 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:22:48 - INFO - __main__ - ['Company']
05/21/2022 06:22:48 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:22:48 - INFO - __main__ - ['Company']
05/21/2022 06:22:48 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:22:48 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:22:48 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:22:53 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:22:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:22:54 - INFO - __main__ - Starting training!
05/21/2022 06:22:55 - INFO - __main__ - Step 10 Global step 10 Train loss 7.58 on epoch=0
05/21/2022 06:22:56 - INFO - __main__ - Step 20 Global step 20 Train loss 7.32 on epoch=1
05/21/2022 06:22:58 - INFO - __main__ - Step 30 Global step 30 Train loss 6.29 on epoch=2
05/21/2022 06:22:59 - INFO - __main__ - Step 40 Global step 40 Train loss 6.26 on epoch=2
05/21/2022 06:23:00 - INFO - __main__ - Step 50 Global step 50 Train loss 5.84 on epoch=3
05/21/2022 06:23:03 - INFO - __main__ - Global step 50 Train loss 6.66 Classification-F1 0.0 on epoch=3
05/21/2022 06:23:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:23:05 - INFO - __main__ - Step 60 Global step 60 Train loss 5.53 on epoch=4
05/21/2022 06:23:06 - INFO - __main__ - Step 70 Global step 70 Train loss 5.44 on epoch=4
05/21/2022 06:23:07 - INFO - __main__ - Step 80 Global step 80 Train loss 4.79 on epoch=5
05/21/2022 06:23:08 - INFO - __main__ - Step 90 Global step 90 Train loss 4.74 on epoch=6
05/21/2022 06:23:10 - INFO - __main__ - Step 100 Global step 100 Train loss 4.88 on epoch=7
05/21/2022 06:23:13 - INFO - __main__ - Global step 100 Train loss 5.08 Classification-F1 0.0 on epoch=7
05/21/2022 06:23:14 - INFO - __main__ - Step 110 Global step 110 Train loss 4.41 on epoch=7
05/21/2022 06:23:15 - INFO - __main__ - Step 120 Global step 120 Train loss 4.28 on epoch=8
05/21/2022 06:23:17 - INFO - __main__ - Step 130 Global step 130 Train loss 4.14 on epoch=9
05/21/2022 06:23:18 - INFO - __main__ - Step 140 Global step 140 Train loss 4.06 on epoch=9
05/21/2022 06:23:19 - INFO - __main__ - Step 150 Global step 150 Train loss 3.60 on epoch=10
05/21/2022 06:23:23 - INFO - __main__ - Global step 150 Train loss 4.10 Classification-F1 0.0 on epoch=10
05/21/2022 06:23:24 - INFO - __main__ - Step 160 Global step 160 Train loss 3.80 on epoch=11
05/21/2022 06:23:26 - INFO - __main__ - Step 170 Global step 170 Train loss 3.63 on epoch=12
05/21/2022 06:23:27 - INFO - __main__ - Step 180 Global step 180 Train loss 3.30 on epoch=12
05/21/2022 06:23:28 - INFO - __main__ - Step 190 Global step 190 Train loss 3.29 on epoch=13
05/21/2022 06:23:29 - INFO - __main__ - Step 200 Global step 200 Train loss 3.14 on epoch=14
05/21/2022 06:23:33 - INFO - __main__ - Global step 200 Train loss 3.43 Classification-F1 0.0056022408963585435 on epoch=14
05/21/2022 06:23:33 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0056022408963585435 on epoch=14, global_step=200
05/21/2022 06:23:34 - INFO - __main__ - Step 210 Global step 210 Train loss 3.18 on epoch=14
05/21/2022 06:23:35 - INFO - __main__ - Step 220 Global step 220 Train loss 2.85 on epoch=15
05/21/2022 06:23:37 - INFO - __main__ - Step 230 Global step 230 Train loss 3.04 on epoch=16
05/21/2022 06:23:38 - INFO - __main__ - Step 240 Global step 240 Train loss 2.97 on epoch=17
05/21/2022 06:23:39 - INFO - __main__ - Step 250 Global step 250 Train loss 2.66 on epoch=17
05/21/2022 06:23:41 - INFO - __main__ - Global step 250 Train loss 2.94 Classification-F1 0.008011444921316165 on epoch=17
05/21/2022 06:23:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0056022408963585435 -> 0.008011444921316165 on epoch=17, global_step=250
05/21/2022 06:23:43 - INFO - __main__ - Step 260 Global step 260 Train loss 2.79 on epoch=18
05/21/2022 06:23:44 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/21/2022 06:23:45 - INFO - __main__ - Step 280 Global step 280 Train loss 2.71 on epoch=19
05/21/2022 06:23:47 - INFO - __main__ - Step 290 Global step 290 Train loss 2.43 on epoch=20
05/21/2022 06:23:48 - INFO - __main__ - Step 300 Global step 300 Train loss 2.61 on epoch=21
05/21/2022 06:23:50 - INFO - __main__ - Global step 300 Train loss 2.63 Classification-F1 0.009523809523809523 on epoch=21
05/21/2022 06:23:50 - INFO - __main__ - Saving model with best Classification-F1: 0.008011444921316165 -> 0.009523809523809523 on epoch=21, global_step=300
05/21/2022 06:23:51 - INFO - __main__ - Step 310 Global step 310 Train loss 2.42 on epoch=22
05/21/2022 06:23:52 - INFO - __main__ - Step 320 Global step 320 Train loss 2.27 on epoch=22
05/21/2022 06:23:53 - INFO - __main__ - Step 330 Global step 330 Train loss 2.31 on epoch=23
05/21/2022 06:23:55 - INFO - __main__ - Step 340 Global step 340 Train loss 2.37 on epoch=24
05/21/2022 06:23:56 - INFO - __main__ - Step 350 Global step 350 Train loss 2.28 on epoch=24
05/21/2022 06:23:58 - INFO - __main__ - Global step 350 Train loss 2.33 Classification-F1 0.009523809523809523 on epoch=24
05/21/2022 06:23:59 - INFO - __main__ - Step 360 Global step 360 Train loss 2.05 on epoch=25
05/21/2022 06:24:00 - INFO - __main__ - Step 370 Global step 370 Train loss 2.11 on epoch=26
05/21/2022 06:24:02 - INFO - __main__ - Step 380 Global step 380 Train loss 2.07 on epoch=27
05/21/2022 06:24:03 - INFO - __main__ - Step 390 Global step 390 Train loss 1.91 on epoch=27
05/21/2022 06:24:04 - INFO - __main__ - Step 400 Global step 400 Train loss 2.06 on epoch=28
05/21/2022 06:24:06 - INFO - __main__ - Global step 400 Train loss 2.04 Classification-F1 0.009523809523809523 on epoch=28
05/21/2022 06:24:07 - INFO - __main__ - Step 410 Global step 410 Train loss 1.96 on epoch=29
05/21/2022 06:24:09 - INFO - __main__ - Step 420 Global step 420 Train loss 1.93 on epoch=29
05/21/2022 06:24:10 - INFO - __main__ - Step 430 Global step 430 Train loss 1.75 on epoch=30
05/21/2022 06:24:11 - INFO - __main__ - Step 440 Global step 440 Train loss 1.93 on epoch=31
05/21/2022 06:24:12 - INFO - __main__ - Step 450 Global step 450 Train loss 1.90 on epoch=32
05/21/2022 06:24:14 - INFO - __main__ - Global step 450 Train loss 1.90 Classification-F1 0.027493106144791536 on epoch=32
05/21/2022 06:24:14 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.027493106144791536 on epoch=32, global_step=450
05/21/2022 06:24:16 - INFO - __main__ - Step 460 Global step 460 Train loss 1.73 on epoch=32
05/21/2022 06:24:17 - INFO - __main__ - Step 470 Global step 470 Train loss 1.74 on epoch=33
05/21/2022 06:24:18 - INFO - __main__ - Step 480 Global step 480 Train loss 1.72 on epoch=34
05/21/2022 06:24:19 - INFO - __main__ - Step 490 Global step 490 Train loss 1.68 on epoch=34
05/21/2022 06:24:21 - INFO - __main__ - Step 500 Global step 500 Train loss 1.56 on epoch=35
05/21/2022 06:24:23 - INFO - __main__ - Global step 500 Train loss 1.69 Classification-F1 0.022157666894508994 on epoch=35
05/21/2022 06:24:24 - INFO - __main__ - Step 510 Global step 510 Train loss 1.71 on epoch=36
05/21/2022 06:24:25 - INFO - __main__ - Step 520 Global step 520 Train loss 1.69 on epoch=37
05/21/2022 06:24:27 - INFO - __main__ - Step 530 Global step 530 Train loss 1.53 on epoch=37
05/21/2022 06:24:28 - INFO - __main__ - Step 540 Global step 540 Train loss 1.65 on epoch=38
05/21/2022 06:24:29 - INFO - __main__ - Step 550 Global step 550 Train loss 1.56 on epoch=39
05/21/2022 06:24:31 - INFO - __main__ - Global step 550 Train loss 1.63 Classification-F1 0.03300506249011232 on epoch=39
05/21/2022 06:24:31 - INFO - __main__ - Saving model with best Classification-F1: 0.027493106144791536 -> 0.03300506249011232 on epoch=39, global_step=550
05/21/2022 06:24:32 - INFO - __main__ - Step 560 Global step 560 Train loss 1.68 on epoch=39
05/21/2022 06:24:34 - INFO - __main__ - Step 570 Global step 570 Train loss 1.54 on epoch=40
05/21/2022 06:24:35 - INFO - __main__ - Step 580 Global step 580 Train loss 1.59 on epoch=41
05/21/2022 06:24:36 - INFO - __main__ - Step 590 Global step 590 Train loss 1.63 on epoch=42
05/21/2022 06:24:37 - INFO - __main__ - Step 600 Global step 600 Train loss 1.49 on epoch=42
05/21/2022 06:24:40 - INFO - __main__ - Global step 600 Train loss 1.58 Classification-F1 0.054354680728307105 on epoch=42
05/21/2022 06:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.03300506249011232 -> 0.054354680728307105 on epoch=42, global_step=600
05/21/2022 06:24:41 - INFO - __main__ - Step 610 Global step 610 Train loss 1.57 on epoch=43
05/21/2022 06:24:42 - INFO - __main__ - Step 620 Global step 620 Train loss 1.48 on epoch=44
05/21/2022 06:24:44 - INFO - __main__ - Step 630 Global step 630 Train loss 1.52 on epoch=44
05/21/2022 06:24:45 - INFO - __main__ - Step 640 Global step 640 Train loss 1.35 on epoch=45
05/21/2022 06:24:46 - INFO - __main__ - Step 650 Global step 650 Train loss 1.46 on epoch=46
05/21/2022 06:24:49 - INFO - __main__ - Global step 650 Train loss 1.48 Classification-F1 0.036130555281693996 on epoch=46
05/21/2022 06:24:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.38 on epoch=47
05/21/2022 06:24:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.37 on epoch=47
05/21/2022 06:24:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.40 on epoch=48
05/21/2022 06:24:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.31 on epoch=49
05/21/2022 06:24:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.41 on epoch=49
05/21/2022 06:24:57 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.02838988822761642 on epoch=49
05/21/2022 06:24:59 - INFO - __main__ - Step 710 Global step 710 Train loss 1.30 on epoch=50
05/21/2022 06:25:00 - INFO - __main__ - Step 720 Global step 720 Train loss 1.48 on epoch=51
05/21/2022 06:25:01 - INFO - __main__ - Step 730 Global step 730 Train loss 1.29 on epoch=52
05/21/2022 06:25:02 - INFO - __main__ - Step 740 Global step 740 Train loss 1.30 on epoch=52
05/21/2022 06:25:04 - INFO - __main__ - Step 750 Global step 750 Train loss 1.37 on epoch=53
05/21/2022 06:25:06 - INFO - __main__ - Global step 750 Train loss 1.35 Classification-F1 0.02770658651057322 on epoch=53
05/21/2022 06:25:07 - INFO - __main__ - Step 760 Global step 760 Train loss 1.31 on epoch=54
05/21/2022 06:25:08 - INFO - __main__ - Step 770 Global step 770 Train loss 1.37 on epoch=54
05/21/2022 06:25:09 - INFO - __main__ - Step 780 Global step 780 Train loss 1.23 on epoch=55
05/21/2022 06:25:11 - INFO - __main__ - Step 790 Global step 790 Train loss 1.36 on epoch=56
05/21/2022 06:25:12 - INFO - __main__ - Step 800 Global step 800 Train loss 1.35 on epoch=57
05/21/2022 06:25:14 - INFO - __main__ - Global step 800 Train loss 1.32 Classification-F1 0.06126147506499391 on epoch=57
05/21/2022 06:25:14 - INFO - __main__ - Saving model with best Classification-F1: 0.054354680728307105 -> 0.06126147506499391 on epoch=57, global_step=800
05/21/2022 06:25:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.23 on epoch=57
05/21/2022 06:25:16 - INFO - __main__ - Step 820 Global step 820 Train loss 1.29 on epoch=58
05/21/2022 06:25:18 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=59
05/21/2022 06:25:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=59
05/21/2022 06:25:20 - INFO - __main__ - Step 850 Global step 850 Train loss 1.22 on epoch=60
05/21/2022 06:25:22 - INFO - __main__ - Global step 850 Train loss 1.26 Classification-F1 0.047836100847586015 on epoch=60
05/21/2022 06:25:24 - INFO - __main__ - Step 860 Global step 860 Train loss 1.29 on epoch=61
05/21/2022 06:25:25 - INFO - __main__ - Step 870 Global step 870 Train loss 1.26 on epoch=62
05/21/2022 06:25:26 - INFO - __main__ - Step 880 Global step 880 Train loss 1.21 on epoch=62
05/21/2022 06:25:27 - INFO - __main__ - Step 890 Global step 890 Train loss 1.36 on epoch=63
05/21/2022 06:25:29 - INFO - __main__ - Step 900 Global step 900 Train loss 1.32 on epoch=64
05/21/2022 06:25:31 - INFO - __main__ - Global step 900 Train loss 1.29 Classification-F1 0.11557459638638222 on epoch=64
05/21/2022 06:25:31 - INFO - __main__ - Saving model with best Classification-F1: 0.06126147506499391 -> 0.11557459638638222 on epoch=64, global_step=900
05/21/2022 06:25:32 - INFO - __main__ - Step 910 Global step 910 Train loss 1.31 on epoch=64
05/21/2022 06:25:34 - INFO - __main__ - Step 920 Global step 920 Train loss 1.23 on epoch=65
05/21/2022 06:25:35 - INFO - __main__ - Step 930 Global step 930 Train loss 1.39 on epoch=66
05/21/2022 06:25:36 - INFO - __main__ - Step 940 Global step 940 Train loss 1.31 on epoch=67
05/21/2022 06:25:37 - INFO - __main__ - Step 950 Global step 950 Train loss 1.21 on epoch=67
05/21/2022 06:25:40 - INFO - __main__ - Global step 950 Train loss 1.29 Classification-F1 0.06785377420460463 on epoch=67
05/21/2022 06:25:42 - INFO - __main__ - Step 960 Global step 960 Train loss 1.21 on epoch=68
05/21/2022 06:25:43 - INFO - __main__ - Step 970 Global step 970 Train loss 1.23 on epoch=69
05/21/2022 06:25:44 - INFO - __main__ - Step 980 Global step 980 Train loss 1.25 on epoch=69
05/21/2022 06:25:45 - INFO - __main__ - Step 990 Global step 990 Train loss 1.20 on epoch=70
05/21/2022 06:25:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.33 on epoch=71
05/21/2022 06:25:50 - INFO - __main__ - Global step 1000 Train loss 1.24 Classification-F1 0.06692553692300231 on epoch=71
05/21/2022 06:25:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.31 on epoch=72
05/21/2022 06:25:52 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.23 on epoch=72
05/21/2022 06:25:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.21 on epoch=73
05/21/2022 06:25:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.22 on epoch=74
05/21/2022 06:25:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.19 on epoch=74
05/21/2022 06:25:59 - INFO - __main__ - Global step 1050 Train loss 1.23 Classification-F1 0.11813815806741963 on epoch=74
05/21/2022 06:25:59 - INFO - __main__ - Saving model with best Classification-F1: 0.11557459638638222 -> 0.11813815806741963 on epoch=74, global_step=1050
05/21/2022 06:26:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.21 on epoch=75
05/21/2022 06:26:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.15 on epoch=76
05/21/2022 06:26:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.23 on epoch=77
05/21/2022 06:26:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.17 on epoch=77
05/21/2022 06:26:05 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.27 on epoch=78
05/21/2022 06:26:08 - INFO - __main__ - Global step 1100 Train loss 1.21 Classification-F1 0.07429862458719813 on epoch=78
05/21/2022 06:26:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.20 on epoch=79
05/21/2022 06:26:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.18 on epoch=79
05/21/2022 06:26:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.00 on epoch=80
05/21/2022 06:26:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.16 on epoch=81
05/21/2022 06:26:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.22 on epoch=82
05/21/2022 06:26:17 - INFO - __main__ - Global step 1150 Train loss 1.15 Classification-F1 0.14739075999517076 on epoch=82
05/21/2022 06:26:17 - INFO - __main__ - Saving model with best Classification-F1: 0.11813815806741963 -> 0.14739075999517076 on epoch=82, global_step=1150
05/21/2022 06:26:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.12 on epoch=82
05/21/2022 06:26:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.27 on epoch=83
05/21/2022 06:26:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.14 on epoch=84
05/21/2022 06:26:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.22 on epoch=84
05/21/2022 06:26:24 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.08 on epoch=85
05/21/2022 06:26:27 - INFO - __main__ - Global step 1200 Train loss 1.17 Classification-F1 0.10988781477503283 on epoch=85
05/21/2022 06:26:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.23 on epoch=86
05/21/2022 06:26:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.17 on epoch=87
05/21/2022 06:26:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.15 on epoch=87
05/21/2022 06:26:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.23 on epoch=88
05/21/2022 06:26:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.16 on epoch=89
05/21/2022 06:26:36 - INFO - __main__ - Global step 1250 Train loss 1.19 Classification-F1 0.17702530555924315 on epoch=89
05/21/2022 06:26:37 - INFO - __main__ - Saving model with best Classification-F1: 0.14739075999517076 -> 0.17702530555924315 on epoch=89, global_step=1250
05/21/2022 06:26:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.15 on epoch=89
05/21/2022 06:26:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.20 on epoch=90
05/21/2022 06:26:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.16 on epoch=91
05/21/2022 06:26:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.24 on epoch=92
05/21/2022 06:26:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.04 on epoch=92
05/21/2022 06:26:46 - INFO - __main__ - Global step 1300 Train loss 1.16 Classification-F1 0.222351411484978 on epoch=92
05/21/2022 06:26:46 - INFO - __main__ - Saving model with best Classification-F1: 0.17702530555924315 -> 0.222351411484978 on epoch=92, global_step=1300
05/21/2022 06:26:48 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.21 on epoch=93
05/21/2022 06:26:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.16 on epoch=94
05/21/2022 06:26:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.21 on epoch=94
05/21/2022 06:26:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.05 on epoch=95
05/21/2022 06:26:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.15 on epoch=96
05/21/2022 06:26:56 - INFO - __main__ - Global step 1350 Train loss 1.15 Classification-F1 0.22686934578553866 on epoch=96
05/21/2022 06:26:56 - INFO - __main__ - Saving model with best Classification-F1: 0.222351411484978 -> 0.22686934578553866 on epoch=96, global_step=1350
05/21/2022 06:26:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.15 on epoch=97
05/21/2022 06:26:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.99 on epoch=97
05/21/2022 06:27:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.12 on epoch=98
05/21/2022 06:27:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.14 on epoch=99
05/21/2022 06:27:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.16 on epoch=99
05/21/2022 06:27:05 - INFO - __main__ - Global step 1400 Train loss 1.11 Classification-F1 0.19625122903563574 on epoch=99
05/21/2022 06:27:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.04 on epoch=100
05/21/2022 06:27:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.15 on epoch=101
05/21/2022 06:27:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.15 on epoch=102
05/21/2022 06:27:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.00 on epoch=102
05/21/2022 06:27:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.06 on epoch=103
05/21/2022 06:27:15 - INFO - __main__ - Global step 1450 Train loss 1.08 Classification-F1 0.2789831843937262 on epoch=103
05/21/2022 06:27:15 - INFO - __main__ - Saving model with best Classification-F1: 0.22686934578553866 -> 0.2789831843937262 on epoch=103, global_step=1450
05/21/2022 06:27:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.14 on epoch=104
05/21/2022 06:27:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.12 on epoch=104
05/21/2022 06:27:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.02 on epoch=105
05/21/2022 06:27:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.09 on epoch=106
05/21/2022 06:27:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.04 on epoch=107
05/21/2022 06:27:25 - INFO - __main__ - Global step 1500 Train loss 1.08 Classification-F1 0.28943887063532603 on epoch=107
05/21/2022 06:27:25 - INFO - __main__ - Saving model with best Classification-F1: 0.2789831843937262 -> 0.28943887063532603 on epoch=107, global_step=1500
05/21/2022 06:27:26 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=107
05/21/2022 06:27:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.10 on epoch=108
05/21/2022 06:27:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.07 on epoch=109
05/21/2022 06:27:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.08 on epoch=109
05/21/2022 06:27:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.98 on epoch=110
05/21/2022 06:27:34 - INFO - __main__ - Global step 1550 Train loss 1.05 Classification-F1 0.23803130228099195 on epoch=110
05/21/2022 06:27:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.13 on epoch=111
05/21/2022 06:27:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.07 on epoch=112
05/21/2022 06:27:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.98 on epoch=112
05/21/2022 06:27:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.10 on epoch=113
05/21/2022 06:27:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.00 on epoch=114
05/21/2022 06:27:44 - INFO - __main__ - Global step 1600 Train loss 1.06 Classification-F1 0.3365936002906512 on epoch=114
05/21/2022 06:27:44 - INFO - __main__ - Saving model with best Classification-F1: 0.28943887063532603 -> 0.3365936002906512 on epoch=114, global_step=1600
05/21/2022 06:27:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.03 on epoch=114
05/21/2022 06:27:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.02 on epoch=115
05/21/2022 06:27:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.06 on epoch=116
05/21/2022 06:27:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.10 on epoch=117
05/21/2022 06:27:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.96 on epoch=117
05/21/2022 06:27:54 - INFO - __main__ - Global step 1650 Train loss 1.03 Classification-F1 0.330305749372405 on epoch=117
05/21/2022 06:27:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=118
05/21/2022 06:27:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.07 on epoch=119
05/21/2022 06:27:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.99 on epoch=119
05/21/2022 06:27:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.91 on epoch=120
05/21/2022 06:28:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.09 on epoch=121
05/21/2022 06:28:03 - INFO - __main__ - Global step 1700 Train loss 1.01 Classification-F1 0.3156618269432915 on epoch=121
05/21/2022 06:28:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.01 on epoch=122
05/21/2022 06:28:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.95 on epoch=122
05/21/2022 06:28:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.02 on epoch=123
05/21/2022 06:28:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.06 on epoch=124
05/21/2022 06:28:10 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=124
05/21/2022 06:28:13 - INFO - __main__ - Global step 1750 Train loss 1.02 Classification-F1 0.3312301715183979 on epoch=124
05/21/2022 06:28:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.97 on epoch=125
05/21/2022 06:28:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.02 on epoch=126
05/21/2022 06:28:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.95 on epoch=127
05/21/2022 06:28:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.95 on epoch=127
05/21/2022 06:28:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.90 on epoch=128
05/21/2022 06:28:23 - INFO - __main__ - Global step 1800 Train loss 0.96 Classification-F1 0.3459862789937027 on epoch=128
05/21/2022 06:28:23 - INFO - __main__ - Saving model with best Classification-F1: 0.3365936002906512 -> 0.3459862789937027 on epoch=128, global_step=1800
05/21/2022 06:28:24 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.02 on epoch=129
05/21/2022 06:28:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.00 on epoch=129
05/21/2022 06:28:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=130
05/21/2022 06:28:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.97 on epoch=131
05/21/2022 06:28:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.99 on epoch=132
05/21/2022 06:28:33 - INFO - __main__ - Global step 1850 Train loss 0.98 Classification-F1 0.4147644367495574 on epoch=132
05/21/2022 06:28:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3459862789937027 -> 0.4147644367495574 on epoch=132, global_step=1850
05/21/2022 06:28:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.97 on epoch=132
05/21/2022 06:28:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.01 on epoch=133
05/21/2022 06:28:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.97 on epoch=134
05/21/2022 06:28:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.92 on epoch=134
05/21/2022 06:28:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.99 on epoch=135
05/21/2022 06:28:42 - INFO - __main__ - Global step 1900 Train loss 0.97 Classification-F1 0.4140724312818008 on epoch=135
05/21/2022 06:28:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.00 on epoch=136
05/21/2022 06:28:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.02 on epoch=137
05/21/2022 06:28:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.86 on epoch=137
05/21/2022 06:28:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.95 on epoch=138
05/21/2022 06:28:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.95 on epoch=139
05/21/2022 06:28:52 - INFO - __main__ - Global step 1950 Train loss 0.95 Classification-F1 0.45286994954979337 on epoch=139
05/21/2022 06:28:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4147644367495574 -> 0.45286994954979337 on epoch=139, global_step=1950
05/21/2022 06:28:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.96 on epoch=139
05/21/2022 06:28:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.80 on epoch=140
05/21/2022 06:28:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.11 on epoch=141
05/21/2022 06:28:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.96 on epoch=142
05/21/2022 06:28:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.84 on epoch=142
05/21/2022 06:29:02 - INFO - __main__ - Global step 2000 Train loss 0.93 Classification-F1 0.4448603417924918 on epoch=142
05/21/2022 06:29:04 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.83 on epoch=143
05/21/2022 06:29:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.81 on epoch=144
05/21/2022 06:29:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.91 on epoch=144
05/21/2022 06:29:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.78 on epoch=145
05/21/2022 06:29:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.94 on epoch=146
05/21/2022 06:29:13 - INFO - __main__ - Global step 2050 Train loss 0.85 Classification-F1 0.4161919430313956 on epoch=146
05/21/2022 06:29:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.90 on epoch=147
05/21/2022 06:29:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.93 on epoch=147
05/21/2022 06:29:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.82 on epoch=148
05/21/2022 06:29:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.91 on epoch=149
05/21/2022 06:29:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.82 on epoch=149
05/21/2022 06:29:23 - INFO - __main__ - Global step 2100 Train loss 0.88 Classification-F1 0.4578995363877278 on epoch=149
05/21/2022 06:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.45286994954979337 -> 0.4578995363877278 on epoch=149, global_step=2100
05/21/2022 06:29:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.74 on epoch=150
05/21/2022 06:29:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.85 on epoch=151
05/21/2022 06:29:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.87 on epoch=152
05/21/2022 06:29:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.82 on epoch=152
05/21/2022 06:29:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.76 on epoch=153
05/21/2022 06:29:33 - INFO - __main__ - Global step 2150 Train loss 0.81 Classification-F1 0.4186361906131378 on epoch=153
05/21/2022 06:29:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.80 on epoch=154
05/21/2022 06:29:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.78 on epoch=154
05/21/2022 06:29:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.70 on epoch=155
05/21/2022 06:29:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.81 on epoch=156
05/21/2022 06:29:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.85 on epoch=157
05/21/2022 06:29:43 - INFO - __main__ - Global step 2200 Train loss 0.79 Classification-F1 0.3917021229998988 on epoch=157
05/21/2022 06:29:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.84 on epoch=157
05/21/2022 06:29:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.83 on epoch=158
05/21/2022 06:29:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.76 on epoch=159
05/21/2022 06:29:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.85 on epoch=159
05/21/2022 06:29:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.84 on epoch=160
05/21/2022 06:29:53 - INFO - __main__ - Global step 2250 Train loss 0.83 Classification-F1 0.3552553570504171 on epoch=160
05/21/2022 06:29:54 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.81 on epoch=161
05/21/2022 06:29:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.78 on epoch=162
05/21/2022 06:29:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.83 on epoch=162
05/21/2022 06:29:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.80 on epoch=163
05/21/2022 06:29:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.78 on epoch=164
05/21/2022 06:30:03 - INFO - __main__ - Global step 2300 Train loss 0.80 Classification-F1 0.4094258708267996 on epoch=164
05/21/2022 06:30:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.88 on epoch=164
05/21/2022 06:30:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.85 on epoch=165
05/21/2022 06:30:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.81 on epoch=166
05/21/2022 06:30:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.80 on epoch=167
05/21/2022 06:30:10 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.81 on epoch=167
05/21/2022 06:30:13 - INFO - __main__ - Global step 2350 Train loss 0.83 Classification-F1 0.40191990256339666 on epoch=167
05/21/2022 06:30:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.80 on epoch=168
05/21/2022 06:30:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.70 on epoch=169
05/21/2022 06:30:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.78 on epoch=169
05/21/2022 06:30:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.79 on epoch=170
05/21/2022 06:30:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.85 on epoch=171
05/21/2022 06:30:23 - INFO - __main__ - Global step 2400 Train loss 0.78 Classification-F1 0.3539887076991228 on epoch=171
05/21/2022 06:30:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.80 on epoch=172
05/21/2022 06:30:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.77 on epoch=172
05/21/2022 06:30:27 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.84 on epoch=173
05/21/2022 06:30:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.80 on epoch=174
05/21/2022 06:30:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.83 on epoch=174
05/21/2022 06:30:33 - INFO - __main__ - Global step 2450 Train loss 0.81 Classification-F1 0.387252392836883 on epoch=174
05/21/2022 06:30:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.74 on epoch=175
05/21/2022 06:30:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.77 on epoch=176
05/21/2022 06:30:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.73 on epoch=177
05/21/2022 06:30:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.78 on epoch=177
05/21/2022 06:30:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.78 on epoch=178
05/21/2022 06:30:44 - INFO - __main__ - Global step 2500 Train loss 0.76 Classification-F1 0.4023614553520452 on epoch=178
05/21/2022 06:30:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.82 on epoch=179
05/21/2022 06:30:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.75 on epoch=179
05/21/2022 06:30:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.76 on epoch=180
05/21/2022 06:30:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.89 on epoch=181
05/21/2022 06:30:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.78 on epoch=182
05/21/2022 06:30:54 - INFO - __main__ - Global step 2550 Train loss 0.80 Classification-F1 0.35604658966467834 on epoch=182
05/21/2022 06:30:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.69 on epoch=182
05/21/2022 06:30:57 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.78 on epoch=183
05/21/2022 06:30:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.76 on epoch=184
05/21/2022 06:30:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.70 on epoch=184
05/21/2022 06:31:00 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.77 on epoch=185
05/21/2022 06:31:04 - INFO - __main__ - Global step 2600 Train loss 0.74 Classification-F1 0.432800164884039 on epoch=185
05/21/2022 06:31:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.72 on epoch=186
05/21/2022 06:31:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.73 on epoch=187
05/21/2022 06:31:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.72 on epoch=187
05/21/2022 06:31:10 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.68 on epoch=188
05/21/2022 06:31:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.80 on epoch=189
05/21/2022 06:31:15 - INFO - __main__ - Global step 2650 Train loss 0.73 Classification-F1 0.3724132889042933 on epoch=189
05/21/2022 06:31:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.77 on epoch=189
05/21/2022 06:31:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.70 on epoch=190
05/21/2022 06:31:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.75 on epoch=191
05/21/2022 06:31:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.72 on epoch=192
05/21/2022 06:31:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.79 on epoch=192
05/21/2022 06:31:25 - INFO - __main__ - Global step 2700 Train loss 0.75 Classification-F1 0.37813756557962924 on epoch=192
05/21/2022 06:31:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.64 on epoch=193
05/21/2022 06:31:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.69 on epoch=194
05/21/2022 06:31:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.73 on epoch=194
05/21/2022 06:31:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.67 on epoch=195
05/21/2022 06:31:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.82 on epoch=196
05/21/2022 06:31:36 - INFO - __main__ - Global step 2750 Train loss 0.71 Classification-F1 0.36754263961835837 on epoch=196
05/21/2022 06:31:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.75 on epoch=197
05/21/2022 06:31:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.66 on epoch=197
05/21/2022 06:31:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.68 on epoch=198
05/21/2022 06:31:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.76 on epoch=199
05/21/2022 06:31:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.74 on epoch=199
05/21/2022 06:31:46 - INFO - __main__ - Global step 2800 Train loss 0.72 Classification-F1 0.41722354771853515 on epoch=199
05/21/2022 06:31:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.60 on epoch=200
05/21/2022 06:31:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.75 on epoch=201
05/21/2022 06:31:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.65 on epoch=202
05/21/2022 06:31:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.67 on epoch=202
05/21/2022 06:31:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.63 on epoch=203
05/21/2022 06:31:56 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.3706584634719934 on epoch=203
05/21/2022 06:31:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.64 on epoch=204
05/21/2022 06:31:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.70 on epoch=204
05/21/2022 06:32:00 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.65 on epoch=205
05/21/2022 06:32:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.73 on epoch=206
05/21/2022 06:32:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.73 on epoch=207
05/21/2022 06:32:06 - INFO - __main__ - Global step 2900 Train loss 0.69 Classification-F1 0.3863953246358643 on epoch=207
05/21/2022 06:32:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.64 on epoch=207
05/21/2022 06:32:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.65 on epoch=208
05/21/2022 06:32:10 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.67 on epoch=209
05/21/2022 06:32:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.80 on epoch=209
05/21/2022 06:32:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.60 on epoch=210
05/21/2022 06:32:16 - INFO - __main__ - Global step 2950 Train loss 0.67 Classification-F1 0.39816407030270684 on epoch=210
05/21/2022 06:32:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.70 on epoch=211
05/21/2022 06:32:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.71 on epoch=212
05/21/2022 06:32:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.58 on epoch=212
05/21/2022 06:32:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.58 on epoch=213
05/21/2022 06:32:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.64 on epoch=214
05/21/2022 06:32:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:32:24 - INFO - __main__ - Printing 3 examples
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:32:24 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:32:24 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:32:24 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:32:24 - INFO - __main__ - Printing 3 examples
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:32:24 - INFO - __main__ - ['Company']
05/21/2022 06:32:24 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:32:24 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:32:24 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:32:26 - INFO - __main__ - Global step 3000 Train loss 0.64 Classification-F1 0.45159962188100183 on epoch=214
05/21/2022 06:32:26 - INFO - __main__ - save last model!
05/21/2022 06:32:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 06:32:27 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 06:32:27 - INFO - __main__ - Printing 3 examples
05/21/2022 06:32:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 06:32:27 - INFO - __main__ - ['Animal']
05/21/2022 06:32:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 06:32:27 - INFO - __main__ - ['Animal']
05/21/2022 06:32:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 06:32:27 - INFO - __main__ - ['Village']
05/21/2022 06:32:27 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:32:28 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:32:30 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:32:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:32:30 - INFO - __main__ - Starting training!
05/21/2022 06:32:32 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:33:43 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
05/21/2022 06:33:43 - INFO - __main__ - Classification-F1 on test data: 0.1722
05/21/2022 06:33:44 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.4578995363877278, test_performance=0.17216984638494673
05/21/2022 06:33:44 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
05/21/2022 06:33:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:33:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:33:45 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:33:45 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:33:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:33:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Scz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
05/21/2022 06:33:45 - INFO - __main__ - ['Company']
05/21/2022 06:33:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:33:45 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:33:45 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:33:51 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:33:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:33:52 - INFO - __main__ - Starting training!
05/21/2022 06:33:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.32 on epoch=0
05/21/2022 06:33:55 - INFO - __main__ - Step 20 Global step 20 Train loss 7.29 on epoch=1
05/21/2022 06:33:56 - INFO - __main__ - Step 30 Global step 30 Train loss 6.73 on epoch=2
05/21/2022 06:33:57 - INFO - __main__ - Step 40 Global step 40 Train loss 6.53 on epoch=2
05/21/2022 06:33:59 - INFO - __main__ - Step 50 Global step 50 Train loss 6.34 on epoch=3
05/21/2022 06:34:02 - INFO - __main__ - Global step 50 Train loss 6.84 Classification-F1 0.0 on epoch=3
05/21/2022 06:34:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:34:03 - INFO - __main__ - Step 60 Global step 60 Train loss 5.99 on epoch=4
05/21/2022 06:34:04 - INFO - __main__ - Step 70 Global step 70 Train loss 6.08 on epoch=4
05/21/2022 06:34:05 - INFO - __main__ - Step 80 Global step 80 Train loss 5.54 on epoch=5
05/21/2022 06:34:07 - INFO - __main__ - Step 90 Global step 90 Train loss 5.54 on epoch=6
05/21/2022 06:34:08 - INFO - __main__ - Step 100 Global step 100 Train loss 5.35 on epoch=7
05/21/2022 06:34:11 - INFO - __main__ - Global step 100 Train loss 5.70 Classification-F1 0.0 on epoch=7
05/21/2022 06:34:13 - INFO - __main__ - Step 110 Global step 110 Train loss 5.05 on epoch=7
05/21/2022 06:34:14 - INFO - __main__ - Step 120 Global step 120 Train loss 5.06 on epoch=8
05/21/2022 06:34:15 - INFO - __main__ - Step 130 Global step 130 Train loss 4.85 on epoch=9
05/21/2022 06:34:17 - INFO - __main__ - Step 140 Global step 140 Train loss 4.78 on epoch=9
05/21/2022 06:34:18 - INFO - __main__ - Step 150 Global step 150 Train loss 4.47 on epoch=10
05/21/2022 06:34:21 - INFO - __main__ - Global step 150 Train loss 4.84 Classification-F1 0.0 on epoch=10
05/21/2022 06:34:23 - INFO - __main__ - Step 160 Global step 160 Train loss 4.42 on epoch=11
05/21/2022 06:34:24 - INFO - __main__ - Step 170 Global step 170 Train loss 4.24 on epoch=12
05/21/2022 06:34:25 - INFO - __main__ - Step 180 Global step 180 Train loss 3.99 on epoch=12
05/21/2022 06:34:26 - INFO - __main__ - Step 190 Global step 190 Train loss 4.09 on epoch=13
05/21/2022 06:34:28 - INFO - __main__ - Step 200 Global step 200 Train loss 3.85 on epoch=14
05/21/2022 06:34:31 - INFO - __main__ - Global step 200 Train loss 4.12 Classification-F1 0.0 on epoch=14
05/21/2022 06:34:33 - INFO - __main__ - Step 210 Global step 210 Train loss 3.93 on epoch=14
05/21/2022 06:34:34 - INFO - __main__ - Step 220 Global step 220 Train loss 3.55 on epoch=15
05/21/2022 06:34:35 - INFO - __main__ - Step 230 Global step 230 Train loss 3.63 on epoch=16
05/21/2022 06:34:37 - INFO - __main__ - Step 240 Global step 240 Train loss 3.53 on epoch=17
05/21/2022 06:34:38 - INFO - __main__ - Step 250 Global step 250 Train loss 3.50 on epoch=17
05/21/2022 06:34:40 - INFO - __main__ - Global step 250 Train loss 3.63 Classification-F1 0.007352941176470588 on epoch=17
05/21/2022 06:34:40 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.007352941176470588 on epoch=17, global_step=250
05/21/2022 06:34:42 - INFO - __main__ - Step 260 Global step 260 Train loss 3.37 on epoch=18
05/21/2022 06:34:43 - INFO - __main__ - Step 270 Global step 270 Train loss 3.41 on epoch=19
05/21/2022 06:34:44 - INFO - __main__ - Step 280 Global step 280 Train loss 3.41 on epoch=19
05/21/2022 06:34:46 - INFO - __main__ - Step 290 Global step 290 Train loss 3.02 on epoch=20
05/21/2022 06:34:47 - INFO - __main__ - Step 300 Global step 300 Train loss 3.25 on epoch=21
05/21/2022 06:34:49 - INFO - __main__ - Global step 300 Train loss 3.29 Classification-F1 0.008259587020648967 on epoch=21
05/21/2022 06:34:49 - INFO - __main__ - Saving model with best Classification-F1: 0.007352941176470588 -> 0.008259587020648967 on epoch=21, global_step=300
05/21/2022 06:34:51 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/21/2022 06:34:52 - INFO - __main__ - Step 320 Global step 320 Train loss 3.00 on epoch=22
05/21/2022 06:34:53 - INFO - __main__ - Step 330 Global step 330 Train loss 2.93 on epoch=23
05/21/2022 06:34:55 - INFO - __main__ - Step 340 Global step 340 Train loss 2.95 on epoch=24
05/21/2022 06:34:56 - INFO - __main__ - Step 350 Global step 350 Train loss 3.03 on epoch=24
05/21/2022 06:34:58 - INFO - __main__ - Global step 350 Train loss 2.99 Classification-F1 0.008333333333333335 on epoch=24
05/21/2022 06:34:58 - INFO - __main__ - Saving model with best Classification-F1: 0.008259587020648967 -> 0.008333333333333335 on epoch=24, global_step=350
05/21/2022 06:34:59 - INFO - __main__ - Step 360 Global step 360 Train loss 2.70 on epoch=25
05/21/2022 06:35:01 - INFO - __main__ - Step 370 Global step 370 Train loss 2.74 on epoch=26
05/21/2022 06:35:02 - INFO - __main__ - Step 380 Global step 380 Train loss 2.72 on epoch=27
05/21/2022 06:35:03 - INFO - __main__ - Step 390 Global step 390 Train loss 2.63 on epoch=27
05/21/2022 06:35:05 - INFO - __main__ - Step 400 Global step 400 Train loss 2.68 on epoch=28
05/21/2022 06:35:07 - INFO - __main__ - Global step 400 Train loss 2.69 Classification-F1 0.009001406469760902 on epoch=28
05/21/2022 06:35:07 - INFO - __main__ - Saving model with best Classification-F1: 0.008333333333333335 -> 0.009001406469760902 on epoch=28, global_step=400
05/21/2022 06:35:08 - INFO - __main__ - Step 410 Global step 410 Train loss 2.64 on epoch=29
05/21/2022 06:35:09 - INFO - __main__ - Step 420 Global step 420 Train loss 2.62 on epoch=29
05/21/2022 06:35:11 - INFO - __main__ - Step 430 Global step 430 Train loss 2.36 on epoch=30
05/21/2022 06:35:12 - INFO - __main__ - Step 440 Global step 440 Train loss 2.54 on epoch=31
05/21/2022 06:35:13 - INFO - __main__ - Step 450 Global step 450 Train loss 2.46 on epoch=32
05/21/2022 06:35:15 - INFO - __main__ - Global step 450 Train loss 2.52 Classification-F1 0.009523809523809523 on epoch=32
05/21/2022 06:35:15 - INFO - __main__ - Saving model with best Classification-F1: 0.009001406469760902 -> 0.009523809523809523 on epoch=32, global_step=450
05/21/2022 06:35:17 - INFO - __main__ - Step 460 Global step 460 Train loss 2.33 on epoch=32
05/21/2022 06:35:18 - INFO - __main__ - Step 470 Global step 470 Train loss 2.43 on epoch=33
05/21/2022 06:35:19 - INFO - __main__ - Step 480 Global step 480 Train loss 2.34 on epoch=34
05/21/2022 06:35:20 - INFO - __main__ - Step 490 Global step 490 Train loss 2.47 on epoch=34
05/21/2022 06:35:22 - INFO - __main__ - Step 500 Global step 500 Train loss 2.27 on epoch=35
05/21/2022 06:35:24 - INFO - __main__ - Global step 500 Train loss 2.37 Classification-F1 0.009523809523809523 on epoch=35
05/21/2022 06:35:25 - INFO - __main__ - Step 510 Global step 510 Train loss 2.29 on epoch=36
05/21/2022 06:35:26 - INFO - __main__ - Step 520 Global step 520 Train loss 2.23 on epoch=37
05/21/2022 06:35:27 - INFO - __main__ - Step 530 Global step 530 Train loss 2.24 on epoch=37
05/21/2022 06:35:29 - INFO - __main__ - Step 540 Global step 540 Train loss 2.24 on epoch=38
05/21/2022 06:35:30 - INFO - __main__ - Step 550 Global step 550 Train loss 2.14 on epoch=39
05/21/2022 06:35:32 - INFO - __main__ - Global step 550 Train loss 2.23 Classification-F1 0.009523809523809523 on epoch=39
05/21/2022 06:35:33 - INFO - __main__ - Step 560 Global step 560 Train loss 2.14 on epoch=39
05/21/2022 06:35:34 - INFO - __main__ - Step 570 Global step 570 Train loss 2.02 on epoch=40
05/21/2022 06:35:36 - INFO - __main__ - Step 580 Global step 580 Train loss 2.19 on epoch=41
05/21/2022 06:35:37 - INFO - __main__ - Step 590 Global step 590 Train loss 2.07 on epoch=42
05/21/2022 06:35:38 - INFO - __main__ - Step 600 Global step 600 Train loss 1.93 on epoch=42
05/21/2022 06:35:40 - INFO - __main__ - Global step 600 Train loss 2.07 Classification-F1 0.02022914428929467 on epoch=42
05/21/2022 06:35:40 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02022914428929467 on epoch=42, global_step=600
05/21/2022 06:35:42 - INFO - __main__ - Step 610 Global step 610 Train loss 1.88 on epoch=43
05/21/2022 06:35:43 - INFO - __main__ - Step 620 Global step 620 Train loss 1.94 on epoch=44
05/21/2022 06:35:44 - INFO - __main__ - Step 630 Global step 630 Train loss 2.00 on epoch=44
05/21/2022 06:35:45 - INFO - __main__ - Step 640 Global step 640 Train loss 1.91 on epoch=45
05/21/2022 06:35:47 - INFO - __main__ - Step 650 Global step 650 Train loss 2.00 on epoch=46
05/21/2022 06:35:49 - INFO - __main__ - Global step 650 Train loss 1.95 Classification-F1 0.037370503757058374 on epoch=46
05/21/2022 06:35:49 - INFO - __main__ - Saving model with best Classification-F1: 0.02022914428929467 -> 0.037370503757058374 on epoch=46, global_step=650
05/21/2022 06:35:50 - INFO - __main__ - Step 660 Global step 660 Train loss 1.94 on epoch=47
05/21/2022 06:35:51 - INFO - __main__ - Step 670 Global step 670 Train loss 1.64 on epoch=47
05/21/2022 06:35:52 - INFO - __main__ - Step 680 Global step 680 Train loss 1.81 on epoch=48
05/21/2022 06:35:54 - INFO - __main__ - Step 690 Global step 690 Train loss 1.87 on epoch=49
05/21/2022 06:35:55 - INFO - __main__ - Step 700 Global step 700 Train loss 1.72 on epoch=49
05/21/2022 06:35:57 - INFO - __main__ - Global step 700 Train loss 1.80 Classification-F1 0.024001447654142267 on epoch=49
05/21/2022 06:35:58 - INFO - __main__ - Step 710 Global step 710 Train loss 1.77 on epoch=50
05/21/2022 06:35:59 - INFO - __main__ - Step 720 Global step 720 Train loss 1.75 on epoch=51
05/21/2022 06:36:00 - INFO - __main__ - Step 730 Global step 730 Train loss 1.73 on epoch=52
05/21/2022 06:36:02 - INFO - __main__ - Step 740 Global step 740 Train loss 1.63 on epoch=52
05/21/2022 06:36:03 - INFO - __main__ - Step 750 Global step 750 Train loss 1.79 on epoch=53
05/21/2022 06:36:05 - INFO - __main__ - Global step 750 Train loss 1.73 Classification-F1 0.028946684158895626 on epoch=53
05/21/2022 06:36:06 - INFO - __main__ - Step 760 Global step 760 Train loss 1.70 on epoch=54
05/21/2022 06:36:07 - INFO - __main__ - Step 770 Global step 770 Train loss 1.66 on epoch=54
05/21/2022 06:36:09 - INFO - __main__ - Step 780 Global step 780 Train loss 1.56 on epoch=55
05/21/2022 06:36:10 - INFO - __main__ - Step 790 Global step 790 Train loss 1.72 on epoch=56
05/21/2022 06:36:12 - INFO - __main__ - Step 800 Global step 800 Train loss 1.66 on epoch=57
05/21/2022 06:36:13 - INFO - __main__ - Global step 800 Train loss 1.66 Classification-F1 0.03672806290387477 on epoch=57
05/21/2022 06:36:15 - INFO - __main__ - Step 810 Global step 810 Train loss 1.55 on epoch=57
05/21/2022 06:36:16 - INFO - __main__ - Step 820 Global step 820 Train loss 1.65 on epoch=58
05/21/2022 06:36:17 - INFO - __main__ - Step 830 Global step 830 Train loss 1.57 on epoch=59
05/21/2022 06:36:19 - INFO - __main__ - Step 840 Global step 840 Train loss 1.66 on epoch=59
05/21/2022 06:36:20 - INFO - __main__ - Step 850 Global step 850 Train loss 1.53 on epoch=60
05/21/2022 06:36:22 - INFO - __main__ - Global step 850 Train loss 1.59 Classification-F1 0.055509513589878566 on epoch=60
05/21/2022 06:36:22 - INFO - __main__ - Saving model with best Classification-F1: 0.037370503757058374 -> 0.055509513589878566 on epoch=60, global_step=850
05/21/2022 06:36:24 - INFO - __main__ - Step 860 Global step 860 Train loss 1.59 on epoch=61
05/21/2022 06:36:25 - INFO - __main__ - Step 870 Global step 870 Train loss 1.61 on epoch=62
05/21/2022 06:36:26 - INFO - __main__ - Step 880 Global step 880 Train loss 1.49 on epoch=62
05/21/2022 06:36:27 - INFO - __main__ - Step 890 Global step 890 Train loss 1.50 on epoch=63
05/21/2022 06:36:29 - INFO - __main__ - Step 900 Global step 900 Train loss 1.52 on epoch=64
05/21/2022 06:36:31 - INFO - __main__ - Global step 900 Train loss 1.54 Classification-F1 0.022707901667919146 on epoch=64
05/21/2022 06:36:32 - INFO - __main__ - Step 910 Global step 910 Train loss 1.54 on epoch=64
05/21/2022 06:36:33 - INFO - __main__ - Step 920 Global step 920 Train loss 1.41 on epoch=65
05/21/2022 06:36:35 - INFO - __main__ - Step 930 Global step 930 Train loss 1.47 on epoch=66
05/21/2022 06:36:36 - INFO - __main__ - Step 940 Global step 940 Train loss 1.52 on epoch=67
05/21/2022 06:36:37 - INFO - __main__ - Step 950 Global step 950 Train loss 1.42 on epoch=67
05/21/2022 06:36:40 - INFO - __main__ - Global step 950 Train loss 1.47 Classification-F1 0.06300243323304709 on epoch=67
05/21/2022 06:36:40 - INFO - __main__ - Saving model with best Classification-F1: 0.055509513589878566 -> 0.06300243323304709 on epoch=67, global_step=950
05/21/2022 06:36:41 - INFO - __main__ - Step 960 Global step 960 Train loss 1.60 on epoch=68
05/21/2022 06:36:42 - INFO - __main__ - Step 970 Global step 970 Train loss 1.48 on epoch=69
05/21/2022 06:36:44 - INFO - __main__ - Step 980 Global step 980 Train loss 1.50 on epoch=69
05/21/2022 06:36:45 - INFO - __main__ - Step 990 Global step 990 Train loss 1.35 on epoch=70
05/21/2022 06:36:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.47 on epoch=71
05/21/2022 06:36:49 - INFO - __main__ - Global step 1000 Train loss 1.48 Classification-F1 0.05109086275009557 on epoch=71
05/21/2022 06:36:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.40 on epoch=72
05/21/2022 06:36:51 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.32 on epoch=72
05/21/2022 06:36:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.48 on epoch=73
05/21/2022 06:36:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.38 on epoch=74
05/21/2022 06:36:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.45 on epoch=74
05/21/2022 06:36:58 - INFO - __main__ - Global step 1050 Train loss 1.41 Classification-F1 0.022637707120465738 on epoch=74
05/21/2022 06:36:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.36 on epoch=75
05/21/2022 06:37:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.53 on epoch=76
05/21/2022 06:37:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.43 on epoch=77
05/21/2022 06:37:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.30 on epoch=77
05/21/2022 06:37:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.36 on epoch=78
05/21/2022 06:37:07 - INFO - __main__ - Global step 1100 Train loss 1.40 Classification-F1 0.030736905736905736 on epoch=78
05/21/2022 06:37:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=79
05/21/2022 06:37:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.40 on epoch=79
05/21/2022 06:37:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.25 on epoch=80
05/21/2022 06:37:12 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.39 on epoch=81
05/21/2022 06:37:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.29 on epoch=82
05/21/2022 06:37:16 - INFO - __main__ - Global step 1150 Train loss 1.34 Classification-F1 0.05311423553392479 on epoch=82
05/21/2022 06:37:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.36 on epoch=82
05/21/2022 06:37:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.36 on epoch=83
05/21/2022 06:37:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.34 on epoch=84
05/21/2022 06:37:22 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.33 on epoch=84
05/21/2022 06:37:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.28 on epoch=85
05/21/2022 06:37:26 - INFO - __main__ - Global step 1200 Train loss 1.34 Classification-F1 0.06193161677032644 on epoch=85
05/21/2022 06:37:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.28 on epoch=86
05/21/2022 06:37:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.34 on epoch=87
05/21/2022 06:37:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.23 on epoch=87
05/21/2022 06:37:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.32 on epoch=88
05/21/2022 06:37:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.33 on epoch=89
05/21/2022 06:37:35 - INFO - __main__ - Global step 1250 Train loss 1.30 Classification-F1 0.06691307144268817 on epoch=89
05/21/2022 06:37:35 - INFO - __main__ - Saving model with best Classification-F1: 0.06300243323304709 -> 0.06691307144268817 on epoch=89, global_step=1250
05/21/2022 06:37:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.37 on epoch=89
05/21/2022 06:37:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.25 on epoch=90
05/21/2022 06:37:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.30 on epoch=91
05/21/2022 06:37:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.29 on epoch=92
05/21/2022 06:37:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.16 on epoch=92
05/21/2022 06:37:46 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.038237688237688236 on epoch=92
05/21/2022 06:37:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.33 on epoch=93
05/21/2022 06:37:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.23 on epoch=94
05/21/2022 06:37:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.36 on epoch=94
05/21/2022 06:37:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.26 on epoch=95
05/21/2022 06:37:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.23 on epoch=96
05/21/2022 06:37:56 - INFO - __main__ - Global step 1350 Train loss 1.28 Classification-F1 0.05144941130462268 on epoch=96
05/21/2022 06:37:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.26 on epoch=97
05/21/2022 06:37:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.21 on epoch=97
05/21/2022 06:38:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.22 on epoch=98
05/21/2022 06:38:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.25 on epoch=99
05/21/2022 06:38:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.27 on epoch=99
05/21/2022 06:38:05 - INFO - __main__ - Global step 1400 Train loss 1.24 Classification-F1 0.08281992497123736 on epoch=99
05/21/2022 06:38:05 - INFO - __main__ - Saving model with best Classification-F1: 0.06691307144268817 -> 0.08281992497123736 on epoch=99, global_step=1400
05/21/2022 06:38:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.21 on epoch=100
05/21/2022 06:38:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.32 on epoch=101
05/21/2022 06:38:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.27 on epoch=102
05/21/2022 06:38:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.15 on epoch=102
05/21/2022 06:38:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.25 on epoch=103
05/21/2022 06:38:15 - INFO - __main__ - Global step 1450 Train loss 1.24 Classification-F1 0.08307322929171668 on epoch=103
05/21/2022 06:38:15 - INFO - __main__ - Saving model with best Classification-F1: 0.08281992497123736 -> 0.08307322929171668 on epoch=103, global_step=1450
05/21/2022 06:38:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.27 on epoch=104
05/21/2022 06:38:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.14 on epoch=104
05/21/2022 06:38:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.19 on epoch=105
05/21/2022 06:38:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.26 on epoch=106
05/21/2022 06:38:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.25 on epoch=107
05/21/2022 06:38:24 - INFO - __main__ - Global step 1500 Train loss 1.22 Classification-F1 0.12168266516092603 on epoch=107
05/21/2022 06:38:24 - INFO - __main__ - Saving model with best Classification-F1: 0.08307322929171668 -> 0.12168266516092603 on epoch=107, global_step=1500
05/21/2022 06:38:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.23 on epoch=107
05/21/2022 06:38:27 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.21 on epoch=108
05/21/2022 06:38:28 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.20 on epoch=109
05/21/2022 06:38:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.19 on epoch=109
05/21/2022 06:38:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.19 on epoch=110
05/21/2022 06:38:34 - INFO - __main__ - Global step 1550 Train loss 1.20 Classification-F1 0.07959624603180747 on epoch=110
05/21/2022 06:38:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.20 on epoch=111
05/21/2022 06:38:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.24 on epoch=112
05/21/2022 06:38:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.06 on epoch=112
05/21/2022 06:38:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.29 on epoch=113
05/21/2022 06:38:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.16 on epoch=114
05/21/2022 06:38:43 - INFO - __main__ - Global step 1600 Train loss 1.19 Classification-F1 0.12276730686482791 on epoch=114
05/21/2022 06:38:43 - INFO - __main__ - Saving model with best Classification-F1: 0.12168266516092603 -> 0.12276730686482791 on epoch=114, global_step=1600
05/21/2022 06:38:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.21 on epoch=114
05/21/2022 06:38:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.07 on epoch=115
05/21/2022 06:38:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.24 on epoch=116
05/21/2022 06:38:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.25 on epoch=117
05/21/2022 06:38:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.13 on epoch=117
05/21/2022 06:38:53 - INFO - __main__ - Global step 1650 Train loss 1.18 Classification-F1 0.12345958502728403 on epoch=117
05/21/2022 06:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.12276730686482791 -> 0.12345958502728403 on epoch=117, global_step=1650
05/21/2022 06:38:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.21 on epoch=118
05/21/2022 06:38:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.21 on epoch=119
05/21/2022 06:38:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.15 on epoch=119
05/21/2022 06:38:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.16 on epoch=120
05/21/2022 06:38:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.21 on epoch=121
05/21/2022 06:39:03 - INFO - __main__ - Global step 1700 Train loss 1.19 Classification-F1 0.17333122665323633 on epoch=121
05/21/2022 06:39:03 - INFO - __main__ - Saving model with best Classification-F1: 0.12345958502728403 -> 0.17333122665323633 on epoch=121, global_step=1700
05/21/2022 06:39:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.20 on epoch=122
05/21/2022 06:39:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.11 on epoch=122
05/21/2022 06:39:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.16 on epoch=123
05/21/2022 06:39:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.15 on epoch=124
05/21/2022 06:39:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.06 on epoch=124
05/21/2022 06:39:12 - INFO - __main__ - Global step 1750 Train loss 1.14 Classification-F1 0.2947548426917076 on epoch=124
05/21/2022 06:39:12 - INFO - __main__ - Saving model with best Classification-F1: 0.17333122665323633 -> 0.2947548426917076 on epoch=124, global_step=1750
05/21/2022 06:39:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.11 on epoch=125
05/21/2022 06:39:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.23 on epoch=126
05/21/2022 06:39:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.15 on epoch=127
05/21/2022 06:39:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.09 on epoch=127
05/21/2022 06:39:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.19 on epoch=128
05/21/2022 06:39:22 - INFO - __main__ - Global step 1800 Train loss 1.15 Classification-F1 0.28129946652764326 on epoch=128
05/21/2022 06:39:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.16 on epoch=129
05/21/2022 06:39:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.13 on epoch=129
05/21/2022 06:39:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.05 on epoch=130
05/21/2022 06:39:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.20 on epoch=131
05/21/2022 06:39:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.17 on epoch=132
05/21/2022 06:39:32 - INFO - __main__ - Global step 1850 Train loss 1.14 Classification-F1 0.2745929375554283 on epoch=132
05/21/2022 06:39:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.99 on epoch=132
05/21/2022 06:39:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.09 on epoch=133
05/21/2022 06:39:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.15 on epoch=134
05/21/2022 06:39:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.12 on epoch=134
05/21/2022 06:39:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.06 on epoch=135
05/21/2022 06:39:41 - INFO - __main__ - Global step 1900 Train loss 1.08 Classification-F1 0.2562242791710766 on epoch=135
05/21/2022 06:39:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.12 on epoch=136
05/21/2022 06:39:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=137
05/21/2022 06:39:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.01 on epoch=137
05/21/2022 06:39:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.09 on epoch=138
05/21/2022 06:39:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.08 on epoch=139
05/21/2022 06:39:51 - INFO - __main__ - Global step 1950 Train loss 1.08 Classification-F1 0.28904887784968886 on epoch=139
05/21/2022 06:39:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.13 on epoch=139
05/21/2022 06:39:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.91 on epoch=140
05/21/2022 06:39:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.09 on epoch=141
05/21/2022 06:39:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.12 on epoch=142
05/21/2022 06:39:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.00 on epoch=142
05/21/2022 06:40:01 - INFO - __main__ - Global step 2000 Train loss 1.05 Classification-F1 0.30186781982880856 on epoch=142
05/21/2022 06:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.2947548426917076 -> 0.30186781982880856 on epoch=142, global_step=2000
05/21/2022 06:40:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.10 on epoch=143
05/21/2022 06:40:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.06 on epoch=144
05/21/2022 06:40:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.09 on epoch=144
05/21/2022 06:40:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.99 on epoch=145
05/21/2022 06:40:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.99 on epoch=146
05/21/2022 06:40:11 - INFO - __main__ - Global step 2050 Train loss 1.05 Classification-F1 0.3039998267461244 on epoch=146
05/21/2022 06:40:11 - INFO - __main__ - Saving model with best Classification-F1: 0.30186781982880856 -> 0.3039998267461244 on epoch=146, global_step=2050
05/21/2022 06:40:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.11 on epoch=147
05/21/2022 06:40:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.97 on epoch=147
05/21/2022 06:40:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.02 on epoch=148
05/21/2022 06:40:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.04 on epoch=149
05/21/2022 06:40:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/21/2022 06:40:20 - INFO - __main__ - Global step 2100 Train loss 1.05 Classification-F1 0.29119038245893986 on epoch=149
05/21/2022 06:40:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.07 on epoch=150
05/21/2022 06:40:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.07 on epoch=151
05/21/2022 06:40:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=152
05/21/2022 06:40:26 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.05 on epoch=152
05/21/2022 06:40:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.04 on epoch=153
05/21/2022 06:40:30 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.3507313135044227 on epoch=153
05/21/2022 06:40:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3039998267461244 -> 0.3507313135044227 on epoch=153, global_step=2150
05/21/2022 06:40:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.05 on epoch=154
05/21/2022 06:40:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.11 on epoch=154
05/21/2022 06:40:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.01 on epoch=155
05/21/2022 06:40:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.02 on epoch=156
05/21/2022 06:40:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.00 on epoch=157
05/21/2022 06:40:40 - INFO - __main__ - Global step 2200 Train loss 1.04 Classification-F1 0.33001990386978275 on epoch=157
05/21/2022 06:40:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.00 on epoch=157
05/21/2022 06:40:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.12 on epoch=158
05/21/2022 06:40:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.08 on epoch=159
05/21/2022 06:40:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.13 on epoch=159
05/21/2022 06:40:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.88 on epoch=160
05/21/2022 06:40:50 - INFO - __main__ - Global step 2250 Train loss 1.04 Classification-F1 0.3758289588727753 on epoch=160
05/21/2022 06:40:50 - INFO - __main__ - Saving model with best Classification-F1: 0.3507313135044227 -> 0.3758289588727753 on epoch=160, global_step=2250
05/21/2022 06:40:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.05 on epoch=161
05/21/2022 06:40:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.05 on epoch=162
05/21/2022 06:40:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.95 on epoch=162
05/21/2022 06:40:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 1.01 on epoch=163
05/21/2022 06:40:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 1.04 on epoch=164
05/21/2022 06:41:00 - INFO - __main__ - Global step 2300 Train loss 1.02 Classification-F1 0.4062961384389956 on epoch=164
05/21/2022 06:41:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3758289588727753 -> 0.4062961384389956 on epoch=164, global_step=2300
05/21/2022 06:41:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.92 on epoch=164
05/21/2022 06:41:02 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.97 on epoch=165
05/21/2022 06:41:04 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.03 on epoch=166
05/21/2022 06:41:05 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.98 on epoch=167
05/21/2022 06:41:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.93 on epoch=167
05/21/2022 06:41:10 - INFO - __main__ - Global step 2350 Train loss 0.97 Classification-F1 0.4417421361327288 on epoch=167
05/21/2022 06:41:10 - INFO - __main__ - Saving model with best Classification-F1: 0.4062961384389956 -> 0.4417421361327288 on epoch=167, global_step=2350
05/21/2022 06:41:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.00 on epoch=168
05/21/2022 06:41:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.10 on epoch=169
05/21/2022 06:41:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 1.05 on epoch=169
05/21/2022 06:41:15 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.96 on epoch=170
05/21/2022 06:41:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.07 on epoch=171
05/21/2022 06:41:19 - INFO - __main__ - Global step 2400 Train loss 1.04 Classification-F1 0.384324895188117 on epoch=171
05/21/2022 06:41:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 1.01 on epoch=172
05/21/2022 06:41:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.01 on epoch=172
05/21/2022 06:41:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.10 on epoch=173
05/21/2022 06:41:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.97 on epoch=174
05/21/2022 06:41:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.04 on epoch=174
05/21/2022 06:41:29 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.44886267316017464 on epoch=174
05/21/2022 06:41:29 - INFO - __main__ - Saving model with best Classification-F1: 0.4417421361327288 -> 0.44886267316017464 on epoch=174, global_step=2450
05/21/2022 06:41:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 1.00 on epoch=175
05/21/2022 06:41:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.09 on epoch=176
05/21/2022 06:41:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.94 on epoch=177
05/21/2022 06:41:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.91 on epoch=177
05/21/2022 06:41:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.98 on epoch=178
05/21/2022 06:41:39 - INFO - __main__ - Global step 2500 Train loss 0.98 Classification-F1 0.4274855307233581 on epoch=178
05/21/2022 06:41:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 1.07 on epoch=179
05/21/2022 06:41:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.94 on epoch=179
05/21/2022 06:41:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.96 on epoch=180
05/21/2022 06:41:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.06 on epoch=181
05/21/2022 06:41:45 - INFO - __main__ - Step 2550 Global step 2550 Train loss 1.01 on epoch=182
05/21/2022 06:41:49 - INFO - __main__ - Global step 2550 Train loss 1.01 Classification-F1 0.47661308288721277 on epoch=182
05/21/2022 06:41:49 - INFO - __main__ - Saving model with best Classification-F1: 0.44886267316017464 -> 0.47661308288721277 on epoch=182, global_step=2550
05/21/2022 06:41:50 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.88 on epoch=182
05/21/2022 06:41:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.88 on epoch=183
05/21/2022 06:41:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.95 on epoch=184
05/21/2022 06:41:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.98 on epoch=184
05/21/2022 06:41:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.82 on epoch=185
05/21/2022 06:41:59 - INFO - __main__ - Global step 2600 Train loss 0.90 Classification-F1 0.4729061665880003 on epoch=185
05/21/2022 06:42:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.96 on epoch=186
05/21/2022 06:42:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 1.02 on epoch=187
05/21/2022 06:42:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.98 on epoch=187
05/21/2022 06:42:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.86 on epoch=188
05/21/2022 06:42:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.92 on epoch=189
05/21/2022 06:42:08 - INFO - __main__ - Global step 2650 Train loss 0.95 Classification-F1 0.4233033097332525 on epoch=189
05/21/2022 06:42:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.94 on epoch=189
05/21/2022 06:42:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.78 on epoch=190
05/21/2022 06:42:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.98 on epoch=191
05/21/2022 06:42:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 1.00 on epoch=192
05/21/2022 06:42:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.97 on epoch=192
05/21/2022 06:42:18 - INFO - __main__ - Global step 2700 Train loss 0.93 Classification-F1 0.48210911671316004 on epoch=192
05/21/2022 06:42:18 - INFO - __main__ - Saving model with best Classification-F1: 0.47661308288721277 -> 0.48210911671316004 on epoch=192, global_step=2700
05/21/2022 06:42:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.99 on epoch=193
05/21/2022 06:42:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.95 on epoch=194
05/21/2022 06:42:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.98 on epoch=194
05/21/2022 06:42:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.88 on epoch=195
05/21/2022 06:42:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.91 on epoch=196
05/21/2022 06:42:28 - INFO - __main__ - Global step 2750 Train loss 0.94 Classification-F1 0.40626823074767443 on epoch=196
05/21/2022 06:42:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 1.01 on epoch=197
05/21/2022 06:42:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.89 on epoch=197
05/21/2022 06:42:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.89 on epoch=198
05/21/2022 06:42:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.91 on epoch=199
05/21/2022 06:42:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.93 on epoch=199
05/21/2022 06:42:38 - INFO - __main__ - Global step 2800 Train loss 0.92 Classification-F1 0.433508534909919 on epoch=199
05/21/2022 06:42:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.84 on epoch=200
05/21/2022 06:42:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 1.05 on epoch=201
05/21/2022 06:42:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.92 on epoch=202
05/21/2022 06:42:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.86 on epoch=202
05/21/2022 06:42:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.95 on epoch=203
05/21/2022 06:42:48 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.39970260075938707 on epoch=203
05/21/2022 06:42:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.96 on epoch=204
05/21/2022 06:42:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.85 on epoch=204
05/21/2022 06:42:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.86 on epoch=205
05/21/2022 06:42:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.86 on epoch=206
05/21/2022 06:42:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.90 on epoch=207
05/21/2022 06:42:57 - INFO - __main__ - Global step 2900 Train loss 0.89 Classification-F1 0.378866203826282 on epoch=207
05/21/2022 06:42:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.90 on epoch=207
05/21/2022 06:43:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.90 on epoch=208
05/21/2022 06:43:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.89 on epoch=209
05/21/2022 06:43:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.86 on epoch=209
05/21/2022 06:43:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.75 on epoch=210
05/21/2022 06:43:07 - INFO - __main__ - Global step 2950 Train loss 0.86 Classification-F1 0.35299212529034485 on epoch=210
05/21/2022 06:43:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.82 on epoch=211
05/21/2022 06:43:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.86 on epoch=212
05/21/2022 06:43:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.84 on epoch=212
05/21/2022 06:43:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.89 on epoch=213
05/21/2022 06:43:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.93 on epoch=214
05/21/2022 06:43:14 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:43:14 - INFO - __main__ - Printing 3 examples
05/21/2022 06:43:14 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 06:43:14 - INFO - __main__ - ['Film']
05/21/2022 06:43:14 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 06:43:14 - INFO - __main__ - ['Film']
05/21/2022 06:43:14 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 06:43:14 - INFO - __main__ - ['Film']
05/21/2022 06:43:14 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:43:15 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:43:15 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:43:15 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:43:15 - INFO - __main__ - Printing 3 examples
05/21/2022 06:43:15 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 06:43:15 - INFO - __main__ - ['Film']
05/21/2022 06:43:15 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 06:43:15 - INFO - __main__ - ['Film']
05/21/2022 06:43:15 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 06:43:15 - INFO - __main__ - ['Film']
05/21/2022 06:43:15 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:43:15 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:43:15 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:43:17 - INFO - __main__ - Global step 3000 Train loss 0.87 Classification-F1 0.3544864042036155 on epoch=214
05/21/2022 06:43:17 - INFO - __main__ - save last model!
05/21/2022 06:43:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 06:43:17 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 06:43:17 - INFO - __main__ - Printing 3 examples
05/21/2022 06:43:17 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 06:43:17 - INFO - __main__ - ['Animal']
05/21/2022 06:43:17 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 06:43:17 - INFO - __main__ - ['Animal']
05/21/2022 06:43:17 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 06:43:17 - INFO - __main__ - ['Village']
05/21/2022 06:43:17 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:43:19 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:43:21 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:43:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:43:21 - INFO - __main__ - Starting training!
05/21/2022 06:43:22 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:44:19 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
05/21/2022 06:44:19 - INFO - __main__ - Classification-F1 on test data: 0.1239
05/21/2022 06:44:20 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.48210911671316004, test_performance=0.1238813975355325
05/21/2022 06:44:20 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
05/21/2022 06:44:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:44:21 - INFO - __main__ - Printing 3 examples
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:44:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:44:21 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:44:21 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:44:21 - INFO - __main__ - Printing 3 examples
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 06:44:21 - INFO - __main__ - ['Film']
05/21/2022 06:44:21 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:44:21 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:44:22 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:44:27 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:44:28 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:44:28 - INFO - __main__ - Starting training!
05/21/2022 06:44:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.55 on epoch=0
05/21/2022 06:44:31 - INFO - __main__ - Step 20 Global step 20 Train loss 6.67 on epoch=1
05/21/2022 06:44:32 - INFO - __main__ - Step 30 Global step 30 Train loss 6.11 on epoch=2
05/21/2022 06:44:33 - INFO - __main__ - Step 40 Global step 40 Train loss 5.50 on epoch=2
05/21/2022 06:44:35 - INFO - __main__ - Step 50 Global step 50 Train loss 5.08 on epoch=3
05/21/2022 06:44:38 - INFO - __main__ - Global step 50 Train loss 6.18 Classification-F1 0.0 on epoch=3
05/21/2022 06:44:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:44:39 - INFO - __main__ - Step 60 Global step 60 Train loss 4.59 on epoch=4
05/21/2022 06:44:40 - INFO - __main__ - Step 70 Global step 70 Train loss 4.27 on epoch=4
05/21/2022 06:44:42 - INFO - __main__ - Step 80 Global step 80 Train loss 4.11 on epoch=5
05/21/2022 06:44:43 - INFO - __main__ - Step 90 Global step 90 Train loss 3.87 on epoch=6
05/21/2022 06:44:44 - INFO - __main__ - Step 100 Global step 100 Train loss 3.70 on epoch=7
05/21/2022 06:44:47 - INFO - __main__ - Global step 100 Train loss 4.11 Classification-F1 0.0 on epoch=7
05/21/2022 06:44:48 - INFO - __main__ - Step 110 Global step 110 Train loss 3.49 on epoch=7
05/21/2022 06:44:50 - INFO - __main__ - Step 120 Global step 120 Train loss 3.21 on epoch=8
05/21/2022 06:44:51 - INFO - __main__ - Step 130 Global step 130 Train loss 3.16 on epoch=9
05/21/2022 06:44:52 - INFO - __main__ - Step 140 Global step 140 Train loss 2.94 on epoch=9
05/21/2022 06:44:53 - INFO - __main__ - Step 150 Global step 150 Train loss 2.79 on epoch=10
05/21/2022 06:44:56 - INFO - __main__ - Global step 150 Train loss 3.12 Classification-F1 0.008080808080808083 on epoch=10
05/21/2022 06:44:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.008080808080808083 on epoch=10, global_step=150
05/21/2022 06:44:57 - INFO - __main__ - Step 160 Global step 160 Train loss 2.75 on epoch=11
05/21/2022 06:44:58 - INFO - __main__ - Step 170 Global step 170 Train loss 2.64 on epoch=12
05/21/2022 06:44:59 - INFO - __main__ - Step 180 Global step 180 Train loss 2.49 on epoch=12
05/21/2022 06:45:01 - INFO - __main__ - Step 190 Global step 190 Train loss 2.35 on epoch=13
05/21/2022 06:45:02 - INFO - __main__ - Step 200 Global step 200 Train loss 2.24 on epoch=14
05/21/2022 06:45:04 - INFO - __main__ - Global step 200 Train loss 2.49 Classification-F1 0.009563658099222952 on epoch=14
05/21/2022 06:45:04 - INFO - __main__ - Saving model with best Classification-F1: 0.008080808080808083 -> 0.009563658099222952 on epoch=14, global_step=200
05/21/2022 06:45:05 - INFO - __main__ - Step 210 Global step 210 Train loss 2.28 on epoch=14
05/21/2022 06:45:06 - INFO - __main__ - Step 220 Global step 220 Train loss 2.14 on epoch=15
05/21/2022 06:45:08 - INFO - __main__ - Step 230 Global step 230 Train loss 2.08 on epoch=16
05/21/2022 06:45:09 - INFO - __main__ - Step 240 Global step 240 Train loss 1.94 on epoch=17
05/21/2022 06:45:10 - INFO - __main__ - Step 250 Global step 250 Train loss 1.93 on epoch=17
05/21/2022 06:45:12 - INFO - __main__ - Global step 250 Train loss 2.07 Classification-F1 0.019982993197278913 on epoch=17
05/21/2022 06:45:12 - INFO - __main__ - Saving model with best Classification-F1: 0.009563658099222952 -> 0.019982993197278913 on epoch=17, global_step=250
05/21/2022 06:45:13 - INFO - __main__ - Step 260 Global step 260 Train loss 1.86 on epoch=18
05/21/2022 06:45:14 - INFO - __main__ - Step 270 Global step 270 Train loss 1.90 on epoch=19
05/21/2022 06:45:16 - INFO - __main__ - Step 280 Global step 280 Train loss 1.85 on epoch=19
05/21/2022 06:45:17 - INFO - __main__ - Step 290 Global step 290 Train loss 1.71 on epoch=20
05/21/2022 06:45:18 - INFO - __main__ - Step 300 Global step 300 Train loss 1.76 on epoch=21
05/21/2022 06:45:20 - INFO - __main__ - Global step 300 Train loss 1.81 Classification-F1 0.009563658099222952 on epoch=21
05/21/2022 06:45:22 - INFO - __main__ - Step 310 Global step 310 Train loss 1.55 on epoch=22
05/21/2022 06:45:23 - INFO - __main__ - Step 320 Global step 320 Train loss 1.62 on epoch=22
05/21/2022 06:45:24 - INFO - __main__ - Step 330 Global step 330 Train loss 1.54 on epoch=23
05/21/2022 06:45:25 - INFO - __main__ - Step 340 Global step 340 Train loss 1.56 on epoch=24
05/21/2022 06:45:27 - INFO - __main__ - Step 350 Global step 350 Train loss 1.58 on epoch=24
05/21/2022 06:45:29 - INFO - __main__ - Global step 350 Train loss 1.57 Classification-F1 0.009603841536614645 on epoch=24
05/21/2022 06:45:30 - INFO - __main__ - Step 360 Global step 360 Train loss 1.53 on epoch=25
05/21/2022 06:45:31 - INFO - __main__ - Step 370 Global step 370 Train loss 1.56 on epoch=26
05/21/2022 06:45:32 - INFO - __main__ - Step 380 Global step 380 Train loss 1.44 on epoch=27
05/21/2022 06:45:33 - INFO - __main__ - Step 390 Global step 390 Train loss 1.50 on epoch=27
05/21/2022 06:45:35 - INFO - __main__ - Step 400 Global step 400 Train loss 1.37 on epoch=28
05/21/2022 06:45:37 - INFO - __main__ - Global step 400 Train loss 1.48 Classification-F1 0.10126146255178514 on epoch=28
05/21/2022 06:45:37 - INFO - __main__ - Saving model with best Classification-F1: 0.019982993197278913 -> 0.10126146255178514 on epoch=28, global_step=400
05/21/2022 06:45:38 - INFO - __main__ - Step 410 Global step 410 Train loss 1.38 on epoch=29
05/21/2022 06:45:39 - INFO - __main__ - Step 420 Global step 420 Train loss 1.44 on epoch=29
05/21/2022 06:45:40 - INFO - __main__ - Step 430 Global step 430 Train loss 1.28 on epoch=30
05/21/2022 06:45:42 - INFO - __main__ - Step 440 Global step 440 Train loss 1.45 on epoch=31
05/21/2022 06:45:43 - INFO - __main__ - Step 450 Global step 450 Train loss 1.22 on epoch=32
05/21/2022 06:45:45 - INFO - __main__ - Global step 450 Train loss 1.35 Classification-F1 0.06000180375180375 on epoch=32
05/21/2022 06:45:47 - INFO - __main__ - Step 460 Global step 460 Train loss 1.34 on epoch=32
05/21/2022 06:45:48 - INFO - __main__ - Step 470 Global step 470 Train loss 1.26 on epoch=33
05/21/2022 06:45:49 - INFO - __main__ - Step 480 Global step 480 Train loss 1.24 on epoch=34
05/21/2022 06:45:50 - INFO - __main__ - Step 490 Global step 490 Train loss 1.31 on epoch=34
05/21/2022 06:45:52 - INFO - __main__ - Step 500 Global step 500 Train loss 1.31 on epoch=35
05/21/2022 06:45:54 - INFO - __main__ - Global step 500 Train loss 1.29 Classification-F1 0.07595259146983284 on epoch=35
05/21/2022 06:45:55 - INFO - __main__ - Step 510 Global step 510 Train loss 1.28 on epoch=36
05/21/2022 06:45:56 - INFO - __main__ - Step 520 Global step 520 Train loss 1.37 on epoch=37
05/21/2022 06:45:57 - INFO - __main__ - Step 530 Global step 530 Train loss 1.26 on epoch=37
05/21/2022 06:45:58 - INFO - __main__ - Step 540 Global step 540 Train loss 1.25 on epoch=38
05/21/2022 06:46:00 - INFO - __main__ - Step 550 Global step 550 Train loss 1.18 on epoch=39
05/21/2022 06:46:02 - INFO - __main__ - Global step 550 Train loss 1.27 Classification-F1 0.10223891234602155 on epoch=39
05/21/2022 06:46:02 - INFO - __main__ - Saving model with best Classification-F1: 0.10126146255178514 -> 0.10223891234602155 on epoch=39, global_step=550
05/21/2022 06:46:03 - INFO - __main__ - Step 560 Global step 560 Train loss 1.27 on epoch=39
05/21/2022 06:46:04 - INFO - __main__ - Step 570 Global step 570 Train loss 1.12 on epoch=40
05/21/2022 06:46:06 - INFO - __main__ - Step 580 Global step 580 Train loss 1.23 on epoch=41
05/21/2022 06:46:07 - INFO - __main__ - Step 590 Global step 590 Train loss 1.22 on epoch=42
05/21/2022 06:46:08 - INFO - __main__ - Step 600 Global step 600 Train loss 1.18 on epoch=42
05/21/2022 06:46:10 - INFO - __main__ - Global step 600 Train loss 1.20 Classification-F1 0.10234874238173597 on epoch=42
05/21/2022 06:46:10 - INFO - __main__ - Saving model with best Classification-F1: 0.10223891234602155 -> 0.10234874238173597 on epoch=42, global_step=600
05/21/2022 06:46:11 - INFO - __main__ - Step 610 Global step 610 Train loss 1.10 on epoch=43
05/21/2022 06:46:12 - INFO - __main__ - Step 620 Global step 620 Train loss 1.25 on epoch=44
05/21/2022 06:46:14 - INFO - __main__ - Step 630 Global step 630 Train loss 1.35 on epoch=44
05/21/2022 06:46:15 - INFO - __main__ - Step 640 Global step 640 Train loss 1.15 on epoch=45
05/21/2022 06:46:16 - INFO - __main__ - Step 650 Global step 650 Train loss 1.22 on epoch=46
05/21/2022 06:46:18 - INFO - __main__ - Global step 650 Train loss 1.21 Classification-F1 0.23007386622212758 on epoch=46
05/21/2022 06:46:18 - INFO - __main__ - Saving model with best Classification-F1: 0.10234874238173597 -> 0.23007386622212758 on epoch=46, global_step=650
05/21/2022 06:46:20 - INFO - __main__ - Step 660 Global step 660 Train loss 1.10 on epoch=47
05/21/2022 06:46:21 - INFO - __main__ - Step 670 Global step 670 Train loss 1.22 on epoch=47
05/21/2022 06:46:22 - INFO - __main__ - Step 680 Global step 680 Train loss 1.05 on epoch=48
05/21/2022 06:46:23 - INFO - __main__ - Step 690 Global step 690 Train loss 1.23 on epoch=49
05/21/2022 06:46:25 - INFO - __main__ - Step 700 Global step 700 Train loss 1.21 on epoch=49
05/21/2022 06:46:27 - INFO - __main__ - Global step 700 Train loss 1.16 Classification-F1 0.31285486893968034 on epoch=49
05/21/2022 06:46:27 - INFO - __main__ - Saving model with best Classification-F1: 0.23007386622212758 -> 0.31285486893968034 on epoch=49, global_step=700
05/21/2022 06:46:29 - INFO - __main__ - Step 710 Global step 710 Train loss 1.04 on epoch=50
05/21/2022 06:46:30 - INFO - __main__ - Step 720 Global step 720 Train loss 1.19 on epoch=51
05/21/2022 06:46:31 - INFO - __main__ - Step 730 Global step 730 Train loss 1.14 on epoch=52
05/21/2022 06:46:32 - INFO - __main__ - Step 740 Global step 740 Train loss 1.15 on epoch=52
05/21/2022 06:46:34 - INFO - __main__ - Step 750 Global step 750 Train loss 1.08 on epoch=53
05/21/2022 06:46:36 - INFO - __main__ - Global step 750 Train loss 1.12 Classification-F1 0.3519659926858258 on epoch=53
05/21/2022 06:46:37 - INFO - __main__ - Saving model with best Classification-F1: 0.31285486893968034 -> 0.3519659926858258 on epoch=53, global_step=750
05/21/2022 06:46:38 - INFO - __main__ - Step 760 Global step 760 Train loss 1.14 on epoch=54
05/21/2022 06:46:39 - INFO - __main__ - Step 770 Global step 770 Train loss 1.12 on epoch=54
05/21/2022 06:46:40 - INFO - __main__ - Step 780 Global step 780 Train loss 1.10 on epoch=55
05/21/2022 06:46:41 - INFO - __main__ - Step 790 Global step 790 Train loss 1.13 on epoch=56
05/21/2022 06:46:43 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/21/2022 06:46:46 - INFO - __main__ - Global step 800 Train loss 1.12 Classification-F1 0.3353294211188876 on epoch=57
05/21/2022 06:46:47 - INFO - __main__ - Step 810 Global step 810 Train loss 1.19 on epoch=57
05/21/2022 06:46:48 - INFO - __main__ - Step 820 Global step 820 Train loss 1.01 on epoch=58
05/21/2022 06:46:50 - INFO - __main__ - Step 830 Global step 830 Train loss 1.06 on epoch=59
05/21/2022 06:46:51 - INFO - __main__ - Step 840 Global step 840 Train loss 1.17 on epoch=59
05/21/2022 06:46:52 - INFO - __main__ - Step 850 Global step 850 Train loss 1.02 on epoch=60
05/21/2022 06:46:55 - INFO - __main__ - Global step 850 Train loss 1.09 Classification-F1 0.389579839230288 on epoch=60
05/21/2022 06:46:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3519659926858258 -> 0.389579839230288 on epoch=60, global_step=850
05/21/2022 06:46:57 - INFO - __main__ - Step 860 Global step 860 Train loss 1.06 on epoch=61
05/21/2022 06:46:58 - INFO - __main__ - Step 870 Global step 870 Train loss 1.02 on epoch=62
05/21/2022 06:46:59 - INFO - __main__ - Step 880 Global step 880 Train loss 1.02 on epoch=62
05/21/2022 06:47:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.93 on epoch=63
05/21/2022 06:47:02 - INFO - __main__ - Step 900 Global step 900 Train loss 1.02 on epoch=64
05/21/2022 06:47:05 - INFO - __main__ - Global step 900 Train loss 1.01 Classification-F1 0.380121073190359 on epoch=64
05/21/2022 06:47:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.99 on epoch=64
05/21/2022 06:47:08 - INFO - __main__ - Step 920 Global step 920 Train loss 1.02 on epoch=65
05/21/2022 06:47:09 - INFO - __main__ - Step 930 Global step 930 Train loss 1.00 on epoch=66
05/21/2022 06:47:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.93 on epoch=67
05/21/2022 06:47:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.95 on epoch=67
05/21/2022 06:47:15 - INFO - __main__ - Global step 950 Train loss 0.98 Classification-F1 0.34361337212457854 on epoch=67
05/21/2022 06:47:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.96 on epoch=68
05/21/2022 06:47:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.94 on epoch=69
05/21/2022 06:47:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.98 on epoch=69
05/21/2022 06:47:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.86 on epoch=70
05/21/2022 06:47:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.91 on epoch=71
05/21/2022 06:47:24 - INFO - __main__ - Global step 1000 Train loss 0.93 Classification-F1 0.360171074031102 on epoch=71
05/21/2022 06:47:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.95 on epoch=72
05/21/2022 06:47:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.85 on epoch=72
05/21/2022 06:47:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.85 on epoch=73
05/21/2022 06:47:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.82 on epoch=74
05/21/2022 06:47:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.81 on epoch=74
05/21/2022 06:47:34 - INFO - __main__ - Global step 1050 Train loss 0.86 Classification-F1 0.4689939005423435 on epoch=74
05/21/2022 06:47:34 - INFO - __main__ - Saving model with best Classification-F1: 0.389579839230288 -> 0.4689939005423435 on epoch=74, global_step=1050
05/21/2022 06:47:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.86 on epoch=75
05/21/2022 06:47:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.95 on epoch=76
05/21/2022 06:47:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.88 on epoch=77
05/21/2022 06:47:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.83 on epoch=77
05/21/2022 06:47:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.83 on epoch=78
05/21/2022 06:47:44 - INFO - __main__ - Global step 1100 Train loss 0.87 Classification-F1 0.44881895258635673 on epoch=78
05/21/2022 06:47:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.85 on epoch=79
05/21/2022 06:47:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.84 on epoch=79
05/21/2022 06:47:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.86 on epoch=80
05/21/2022 06:47:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.86 on epoch=81
05/21/2022 06:47:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.86 on epoch=82
05/21/2022 06:47:53 - INFO - __main__ - Global step 1150 Train loss 0.86 Classification-F1 0.4365186515405813 on epoch=82
05/21/2022 06:47:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.87 on epoch=82
05/21/2022 06:47:56 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.84 on epoch=83
05/21/2022 06:47:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.93 on epoch=84
05/21/2022 06:47:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.85 on epoch=84
05/21/2022 06:48:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.78 on epoch=85
05/21/2022 06:48:03 - INFO - __main__ - Global step 1200 Train loss 0.85 Classification-F1 0.397994867365328 on epoch=85
05/21/2022 06:48:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.87 on epoch=86
05/21/2022 06:48:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.88 on epoch=87
05/21/2022 06:48:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.84 on epoch=87
05/21/2022 06:48:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.84 on epoch=88
05/21/2022 06:48:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.77 on epoch=89
05/21/2022 06:48:13 - INFO - __main__ - Global step 1250 Train loss 0.84 Classification-F1 0.5318285101191528 on epoch=89
05/21/2022 06:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4689939005423435 -> 0.5318285101191528 on epoch=89, global_step=1250
05/21/2022 06:48:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.81 on epoch=89
05/21/2022 06:48:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.75 on epoch=90
05/21/2022 06:48:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.82 on epoch=91
05/21/2022 06:48:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.85 on epoch=92
05/21/2022 06:48:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.84 on epoch=92
05/21/2022 06:48:23 - INFO - __main__ - Global step 1300 Train loss 0.82 Classification-F1 0.48581846830841646 on epoch=92
05/21/2022 06:48:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.69 on epoch=93
05/21/2022 06:48:25 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.75 on epoch=94
05/21/2022 06:48:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.77 on epoch=94
05/21/2022 06:48:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.80 on epoch=95
05/21/2022 06:48:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.79 on epoch=96
05/21/2022 06:48:33 - INFO - __main__ - Global step 1350 Train loss 0.76 Classification-F1 0.4956556800516716 on epoch=96
05/21/2022 06:48:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.85 on epoch=97
05/21/2022 06:48:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.82 on epoch=97
05/21/2022 06:48:36 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.76 on epoch=98
05/21/2022 06:48:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.80 on epoch=99
05/21/2022 06:48:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.81 on epoch=99
05/21/2022 06:48:42 - INFO - __main__ - Global step 1400 Train loss 0.81 Classification-F1 0.3689093626653603 on epoch=99
05/21/2022 06:48:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/21/2022 06:48:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.78 on epoch=101
05/21/2022 06:48:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.78 on epoch=102
05/21/2022 06:48:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.67 on epoch=102
05/21/2022 06:48:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.72 on epoch=103
05/21/2022 06:48:53 - INFO - __main__ - Global step 1450 Train loss 0.75 Classification-F1 0.3850186630345309 on epoch=103
05/21/2022 06:48:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.79 on epoch=104
05/21/2022 06:48:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.73 on epoch=104
05/21/2022 06:48:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.75 on epoch=105
05/21/2022 06:48:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.73 on epoch=106
05/21/2022 06:48:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.67 on epoch=107
05/21/2022 06:49:03 - INFO - __main__ - Global step 1500 Train loss 0.74 Classification-F1 0.4951428434032429 on epoch=107
05/21/2022 06:49:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.64 on epoch=107
05/21/2022 06:49:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.62 on epoch=108
05/21/2022 06:49:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.70 on epoch=109
05/21/2022 06:49:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.83 on epoch=109
05/21/2022 06:49:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.80 on epoch=110
05/21/2022 06:49:12 - INFO - __main__ - Global step 1550 Train loss 0.72 Classification-F1 0.4969139955083408 on epoch=110
05/21/2022 06:49:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.68 on epoch=111
05/21/2022 06:49:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.75 on epoch=112
05/21/2022 06:49:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.68 on epoch=112
05/21/2022 06:49:17 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.67 on epoch=113
05/21/2022 06:49:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.76 on epoch=114
05/21/2022 06:49:22 - INFO - __main__ - Global step 1600 Train loss 0.71 Classification-F1 0.4972849215162075 on epoch=114
05/21/2022 06:49:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.66 on epoch=114
05/21/2022 06:49:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.66 on epoch=115
05/21/2022 06:49:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.74 on epoch=116
05/21/2022 06:49:27 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.70 on epoch=117
05/21/2022 06:49:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.64 on epoch=117
05/21/2022 06:49:32 - INFO - __main__ - Global step 1650 Train loss 0.68 Classification-F1 0.47656793296257294 on epoch=117
05/21/2022 06:49:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.70 on epoch=118
05/21/2022 06:49:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.67 on epoch=119
05/21/2022 06:49:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.72 on epoch=119
05/21/2022 06:49:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.63 on epoch=120
05/21/2022 06:49:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.76 on epoch=121
05/21/2022 06:49:42 - INFO - __main__ - Global step 1700 Train loss 0.70 Classification-F1 0.42720131655890164 on epoch=121
05/21/2022 06:49:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.63 on epoch=122
05/21/2022 06:49:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.71 on epoch=122
05/21/2022 06:49:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.62 on epoch=123
05/21/2022 06:49:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.63 on epoch=124
05/21/2022 06:49:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.62 on epoch=124
05/21/2022 06:49:52 - INFO - __main__ - Global step 1750 Train loss 0.64 Classification-F1 0.46405691572143504 on epoch=124
05/21/2022 06:49:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.61 on epoch=125
05/21/2022 06:49:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.65 on epoch=126
05/21/2022 06:49:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.68 on epoch=127
05/21/2022 06:49:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.69 on epoch=127
05/21/2022 06:49:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.65 on epoch=128
05/21/2022 06:50:02 - INFO - __main__ - Global step 1800 Train loss 0.66 Classification-F1 0.4460508552749933 on epoch=128
05/21/2022 06:50:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.66 on epoch=129
05/21/2022 06:50:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.65 on epoch=129
05/21/2022 06:50:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.61 on epoch=130
05/21/2022 06:50:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.63 on epoch=131
05/21/2022 06:50:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.64 on epoch=132
05/21/2022 06:50:12 - INFO - __main__ - Global step 1850 Train loss 0.64 Classification-F1 0.41060495737560615 on epoch=132
05/21/2022 06:50:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.65 on epoch=132
05/21/2022 06:50:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.63 on epoch=133
05/21/2022 06:50:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.63 on epoch=134
05/21/2022 06:50:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.74 on epoch=134
05/21/2022 06:50:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.69 on epoch=135
05/21/2022 06:50:22 - INFO - __main__ - Global step 1900 Train loss 0.67 Classification-F1 0.379192006967777 on epoch=135
05/21/2022 06:50:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.63 on epoch=136
05/21/2022 06:50:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.69 on epoch=137
05/21/2022 06:50:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.64 on epoch=137
05/21/2022 06:50:27 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.65 on epoch=138
05/21/2022 06:50:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.63 on epoch=139
05/21/2022 06:50:32 - INFO - __main__ - Global step 1950 Train loss 0.65 Classification-F1 0.4417859929195246 on epoch=139
05/21/2022 06:50:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.57 on epoch=139
05/21/2022 06:50:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.56 on epoch=140
05/21/2022 06:50:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.68 on epoch=141
05/21/2022 06:50:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.63 on epoch=142
05/21/2022 06:50:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.59 on epoch=142
05/21/2022 06:50:42 - INFO - __main__ - Global step 2000 Train loss 0.60 Classification-F1 0.42149595187136285 on epoch=142
05/21/2022 06:50:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.60 on epoch=143
05/21/2022 06:50:44 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.64 on epoch=144
05/21/2022 06:50:46 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.60 on epoch=144
05/21/2022 06:50:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.63 on epoch=145
05/21/2022 06:50:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.63 on epoch=146
05/21/2022 06:50:52 - INFO - __main__ - Global step 2050 Train loss 0.62 Classification-F1 0.46020787151263287 on epoch=146
05/21/2022 06:50:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.62 on epoch=147
05/21/2022 06:50:54 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.57 on epoch=147
05/21/2022 06:50:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.58 on epoch=148
05/21/2022 06:50:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.61 on epoch=149
05/21/2022 06:50:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.59 on epoch=149
05/21/2022 06:51:02 - INFO - __main__ - Global step 2100 Train loss 0.59 Classification-F1 0.4298916850992941 on epoch=149
05/21/2022 06:51:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.67 on epoch=150
05/21/2022 06:51:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.65 on epoch=151
05/21/2022 06:51:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.54 on epoch=152
05/21/2022 06:51:07 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.61 on epoch=152
05/21/2022 06:51:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.62 on epoch=153
05/21/2022 06:51:12 - INFO - __main__ - Global step 2150 Train loss 0.62 Classification-F1 0.48407982276899697 on epoch=153
05/21/2022 06:51:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.67 on epoch=154
05/21/2022 06:51:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.58 on epoch=154
05/21/2022 06:51:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.59 on epoch=155
05/21/2022 06:51:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.59 on epoch=156
05/21/2022 06:51:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.63 on epoch=157
05/21/2022 06:51:22 - INFO - __main__ - Global step 2200 Train loss 0.61 Classification-F1 0.4976790111884787 on epoch=157
05/21/2022 06:51:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.65 on epoch=157
05/21/2022 06:51:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.55 on epoch=158
05/21/2022 06:51:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.64 on epoch=159
05/21/2022 06:51:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.59 on epoch=159
05/21/2022 06:51:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.58 on epoch=160
05/21/2022 06:51:32 - INFO - __main__ - Global step 2250 Train loss 0.60 Classification-F1 0.5912790143976662 on epoch=160
05/21/2022 06:51:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5318285101191528 -> 0.5912790143976662 on epoch=160, global_step=2250
05/21/2022 06:51:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.62 on epoch=161
05/21/2022 06:51:35 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.61 on epoch=162
05/21/2022 06:51:36 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.57 on epoch=162
05/21/2022 06:51:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.51 on epoch=163
05/21/2022 06:51:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.70 on epoch=164
05/21/2022 06:51:42 - INFO - __main__ - Global step 2300 Train loss 0.60 Classification-F1 0.5167177731314463 on epoch=164
05/21/2022 06:51:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.58 on epoch=164
05/21/2022 06:51:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.49 on epoch=165
05/21/2022 06:51:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.55 on epoch=166
05/21/2022 06:51:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.64 on epoch=167
05/21/2022 06:51:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.60 on epoch=167
05/21/2022 06:51:52 - INFO - __main__ - Global step 2350 Train loss 0.57 Classification-F1 0.48657774856844727 on epoch=167
05/21/2022 06:51:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.60 on epoch=168
05/21/2022 06:51:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/21/2022 06:51:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.60 on epoch=169
05/21/2022 06:51:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.61 on epoch=170
05/21/2022 06:51:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.58 on epoch=171
05/21/2022 06:52:02 - INFO - __main__ - Global step 2400 Train loss 0.60 Classification-F1 0.5558206170028872 on epoch=171
05/21/2022 06:52:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.52 on epoch=172
05/21/2022 06:52:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.49 on epoch=172
05/21/2022 06:52:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.55 on epoch=173
05/21/2022 06:52:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.61 on epoch=174
05/21/2022 06:52:08 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.56 on epoch=174
05/21/2022 06:52:12 - INFO - __main__ - Global step 2450 Train loss 0.55 Classification-F1 0.5338870969811212 on epoch=174
05/21/2022 06:52:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.47 on epoch=175
05/21/2022 06:52:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.53 on epoch=176
05/21/2022 06:52:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.58 on epoch=177
05/21/2022 06:52:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.52 on epoch=177
05/21/2022 06:52:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.60 on epoch=178
05/21/2022 06:52:22 - INFO - __main__ - Global step 2500 Train loss 0.54 Classification-F1 0.46726728095755105 on epoch=178
05/21/2022 06:52:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.64 on epoch=179
05/21/2022 06:52:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.53 on epoch=179
05/21/2022 06:52:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.62 on epoch=180
05/21/2022 06:52:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.51 on epoch=181
05/21/2022 06:52:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.52 on epoch=182
05/21/2022 06:52:32 - INFO - __main__ - Global step 2550 Train loss 0.56 Classification-F1 0.46749946121204383 on epoch=182
05/21/2022 06:52:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.57 on epoch=182
05/21/2022 06:52:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.63 on epoch=183
05/21/2022 06:52:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/21/2022 06:52:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.56 on epoch=184
05/21/2022 06:52:38 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.49 on epoch=185
05/21/2022 06:52:42 - INFO - __main__ - Global step 2600 Train loss 0.58 Classification-F1 0.5550331626731819 on epoch=185
05/21/2022 06:52:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.56 on epoch=186
05/21/2022 06:52:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.63 on epoch=187
05/21/2022 06:52:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.57 on epoch=187
05/21/2022 06:52:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.59 on epoch=188
05/21/2022 06:52:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.59 on epoch=189
05/21/2022 06:52:52 - INFO - __main__ - Global step 2650 Train loss 0.59 Classification-F1 0.5317821295494006 on epoch=189
05/21/2022 06:52:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.55 on epoch=189
05/21/2022 06:52:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.48 on epoch=190
05/21/2022 06:52:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.56 on epoch=191
05/21/2022 06:52:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.49 on epoch=192
05/21/2022 06:52:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/21/2022 06:53:02 - INFO - __main__ - Global step 2700 Train loss 0.53 Classification-F1 0.5402856870943622 on epoch=192
05/21/2022 06:53:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.52 on epoch=193
05/21/2022 06:53:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.53 on epoch=194
05/21/2022 06:53:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.52 on epoch=194
05/21/2022 06:53:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.61 on epoch=195
05/21/2022 06:53:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.54 on epoch=196
05/21/2022 06:53:12 - INFO - __main__ - Global step 2750 Train loss 0.55 Classification-F1 0.47607618925868217 on epoch=196
05/21/2022 06:53:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.56 on epoch=197
05/21/2022 06:53:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.45 on epoch=197
05/21/2022 06:53:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.51 on epoch=198
05/21/2022 06:53:17 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.48 on epoch=199
05/21/2022 06:53:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.51 on epoch=199
05/21/2022 06:53:22 - INFO - __main__ - Global step 2800 Train loss 0.50 Classification-F1 0.4492237220517135 on epoch=199
05/21/2022 06:53:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.56 on epoch=200
05/21/2022 06:53:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.57 on epoch=201
05/21/2022 06:53:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.53 on epoch=202
05/21/2022 06:53:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.50 on epoch=202
05/21/2022 06:53:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.43 on epoch=203
05/21/2022 06:53:33 - INFO - __main__ - Global step 2850 Train loss 0.52 Classification-F1 0.5638059574905889 on epoch=203
05/21/2022 06:53:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.53 on epoch=204
05/21/2022 06:53:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.52 on epoch=204
05/21/2022 06:53:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.53 on epoch=205
05/21/2022 06:53:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.52 on epoch=206
05/21/2022 06:53:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.54 on epoch=207
05/21/2022 06:53:43 - INFO - __main__ - Global step 2900 Train loss 0.53 Classification-F1 0.6164385602380915 on epoch=207
05/21/2022 06:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5912790143976662 -> 0.6164385602380915 on epoch=207, global_step=2900
05/21/2022 06:53:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.49 on epoch=207
05/21/2022 06:53:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.53 on epoch=208
05/21/2022 06:53:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.53 on epoch=209
05/21/2022 06:53:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.53 on epoch=209
05/21/2022 06:53:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.53 on epoch=210
05/21/2022 06:53:53 - INFO - __main__ - Global step 2950 Train loss 0.52 Classification-F1 0.5838923130885606 on epoch=210
05/21/2022 06:53:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.43 on epoch=211
05/21/2022 06:53:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.54 on epoch=212
05/21/2022 06:53:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.50 on epoch=212
05/21/2022 06:53:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.54 on epoch=213
05/21/2022 06:53:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.55 on epoch=214
05/21/2022 06:54:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:54:00 - INFO - __main__ - Printing 3 examples
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:54:00 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:54:00 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:54:00 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:54:00 - INFO - __main__ - Printing 3 examples
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 06:54:00 - INFO - __main__ - ['Film']
05/21/2022 06:54:00 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:54:01 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:54:01 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:54:03 - INFO - __main__ - Global step 3000 Train loss 0.51 Classification-F1 0.6167040112613459 on epoch=214
05/21/2022 06:54:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6164385602380915 -> 0.6167040112613459 on epoch=214, global_step=3000
05/21/2022 06:54:03 - INFO - __main__ - save last model!
05/21/2022 06:54:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 06:54:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 06:54:03 - INFO - __main__ - Printing 3 examples
05/21/2022 06:54:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 06:54:03 - INFO - __main__ - ['Animal']
05/21/2022 06:54:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 06:54:03 - INFO - __main__ - ['Animal']
05/21/2022 06:54:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 06:54:03 - INFO - __main__ - ['Village']
05/21/2022 06:54:03 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:54:05 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:54:06 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:54:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:54:07 - INFO - __main__ - Starting training!
05/21/2022 06:54:08 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 06:55:14 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
05/21/2022 06:55:14 - INFO - __main__ - Classification-F1 on test data: 0.2621
05/21/2022 06:55:15 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.6167040112613459, test_performance=0.2620547890596715
05/21/2022 06:55:15 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
05/21/2022 06:55:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:55:16 - INFO - __main__ - Printing 3 examples
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:55:16 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:55:16 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:55:16 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:55:16 - INFO - __main__ - Printing 3 examples
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 06:55:16 - INFO - __main__ - ['Film']
05/21/2022 06:55:16 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:55:16 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:55:16 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:55:22 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:55:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 06:55:22 - INFO - __main__ - Starting training!
05/21/2022 06:55:23 - INFO - __main__ - Step 10 Global step 10 Train loss 7.61 on epoch=0
05/21/2022 06:55:25 - INFO - __main__ - Step 20 Global step 20 Train loss 7.23 on epoch=1
05/21/2022 06:55:26 - INFO - __main__ - Step 30 Global step 30 Train loss 6.41 on epoch=2
05/21/2022 06:55:27 - INFO - __main__ - Step 40 Global step 40 Train loss 5.86 on epoch=2
05/21/2022 06:55:28 - INFO - __main__ - Step 50 Global step 50 Train loss 5.47 on epoch=3
05/21/2022 06:55:32 - INFO - __main__ - Global step 50 Train loss 6.51 Classification-F1 0.0 on epoch=3
05/21/2022 06:55:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 06:55:33 - INFO - __main__ - Step 60 Global step 60 Train loss 5.09 on epoch=4
05/21/2022 06:55:34 - INFO - __main__ - Step 70 Global step 70 Train loss 4.88 on epoch=4
05/21/2022 06:55:35 - INFO - __main__ - Step 80 Global step 80 Train loss 4.73 on epoch=5
05/21/2022 06:55:37 - INFO - __main__ - Step 90 Global step 90 Train loss 4.43 on epoch=6
05/21/2022 06:55:38 - INFO - __main__ - Step 100 Global step 100 Train loss 4.10 on epoch=7
05/21/2022 06:55:41 - INFO - __main__ - Global step 100 Train loss 4.64 Classification-F1 0.0 on epoch=7
05/21/2022 06:55:43 - INFO - __main__ - Step 110 Global step 110 Train loss 4.02 on epoch=7
05/21/2022 06:55:44 - INFO - __main__ - Step 120 Global step 120 Train loss 3.80 on epoch=8
05/21/2022 06:55:45 - INFO - __main__ - Step 130 Global step 130 Train loss 3.59 on epoch=9
05/21/2022 06:55:46 - INFO - __main__ - Step 140 Global step 140 Train loss 3.46 on epoch=9
05/21/2022 06:55:48 - INFO - __main__ - Step 150 Global step 150 Train loss 3.32 on epoch=10
05/21/2022 06:55:51 - INFO - __main__ - Global step 150 Train loss 3.64 Classification-F1 0.003676470588235294 on epoch=10
05/21/2022 06:55:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.003676470588235294 on epoch=10, global_step=150
05/21/2022 06:55:53 - INFO - __main__ - Step 160 Global step 160 Train loss 3.25 on epoch=11
05/21/2022 06:55:54 - INFO - __main__ - Step 170 Global step 170 Train loss 3.07 on epoch=12
05/21/2022 06:55:55 - INFO - __main__ - Step 180 Global step 180 Train loss 2.92 on epoch=12
05/21/2022 06:55:56 - INFO - __main__ - Step 190 Global step 190 Train loss 2.71 on epoch=13
05/21/2022 06:55:58 - INFO - __main__ - Step 200 Global step 200 Train loss 2.75 on epoch=14
05/21/2022 06:56:00 - INFO - __main__ - Global step 200 Train loss 2.94 Classification-F1 0.00858085808580858 on epoch=14
05/21/2022 06:56:00 - INFO - __main__ - Saving model with best Classification-F1: 0.003676470588235294 -> 0.00858085808580858 on epoch=14, global_step=200
05/21/2022 06:56:01 - INFO - __main__ - Step 210 Global step 210 Train loss 2.68 on epoch=14
05/21/2022 06:56:03 - INFO - __main__ - Step 220 Global step 220 Train loss 2.44 on epoch=15
05/21/2022 06:56:04 - INFO - __main__ - Step 230 Global step 230 Train loss 2.52 on epoch=16
05/21/2022 06:56:05 - INFO - __main__ - Step 240 Global step 240 Train loss 2.33 on epoch=17
05/21/2022 06:56:06 - INFO - __main__ - Step 250 Global step 250 Train loss 2.27 on epoch=17
05/21/2022 06:56:08 - INFO - __main__ - Global step 250 Train loss 2.45 Classification-F1 0.009523809523809523 on epoch=17
05/21/2022 06:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.00858085808580858 -> 0.009523809523809523 on epoch=17, global_step=250
05/21/2022 06:56:10 - INFO - __main__ - Step 260 Global step 260 Train loss 2.30 on epoch=18
05/21/2022 06:56:11 - INFO - __main__ - Step 270 Global step 270 Train loss 2.16 on epoch=19
05/21/2022 06:56:12 - INFO - __main__ - Step 280 Global step 280 Train loss 2.12 on epoch=19
05/21/2022 06:56:13 - INFO - __main__ - Step 290 Global step 290 Train loss 1.95 on epoch=20
05/21/2022 06:56:15 - INFO - __main__ - Step 300 Global step 300 Train loss 2.03 on epoch=21
05/21/2022 06:56:17 - INFO - __main__ - Global step 300 Train loss 2.11 Classification-F1 0.019667128987517334 on epoch=21
05/21/2022 06:56:17 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.019667128987517334 on epoch=21, global_step=300
05/21/2022 06:56:18 - INFO - __main__ - Step 310 Global step 310 Train loss 1.93 on epoch=22
05/21/2022 06:56:20 - INFO - __main__ - Step 320 Global step 320 Train loss 1.90 on epoch=22
05/21/2022 06:56:21 - INFO - __main__ - Step 330 Global step 330 Train loss 1.69 on epoch=23
05/21/2022 06:56:22 - INFO - __main__ - Step 340 Global step 340 Train loss 1.84 on epoch=24
05/21/2022 06:56:23 - INFO - __main__ - Step 350 Global step 350 Train loss 1.79 on epoch=24
05/21/2022 06:56:25 - INFO - __main__ - Global step 350 Train loss 1.83 Classification-F1 0.015154185022026432 on epoch=24
05/21/2022 06:56:27 - INFO - __main__ - Step 360 Global step 360 Train loss 1.67 on epoch=25
05/21/2022 06:56:28 - INFO - __main__ - Step 370 Global step 370 Train loss 1.68 on epoch=26
05/21/2022 06:56:29 - INFO - __main__ - Step 380 Global step 380 Train loss 1.66 on epoch=27
05/21/2022 06:56:31 - INFO - __main__ - Step 390 Global step 390 Train loss 1.62 on epoch=27
05/21/2022 06:56:32 - INFO - __main__ - Step 400 Global step 400 Train loss 1.38 on epoch=28
05/21/2022 06:56:34 - INFO - __main__ - Global step 400 Train loss 1.60 Classification-F1 0.045459506457162964 on epoch=28
05/21/2022 06:56:34 - INFO - __main__ - Saving model with best Classification-F1: 0.019667128987517334 -> 0.045459506457162964 on epoch=28, global_step=400
05/21/2022 06:56:35 - INFO - __main__ - Step 410 Global step 410 Train loss 1.54 on epoch=29
05/21/2022 06:56:37 - INFO - __main__ - Step 420 Global step 420 Train loss 1.56 on epoch=29
05/21/2022 06:56:38 - INFO - __main__ - Step 430 Global step 430 Train loss 1.49 on epoch=30
05/21/2022 06:56:39 - INFO - __main__ - Step 440 Global step 440 Train loss 1.46 on epoch=31
05/21/2022 06:56:40 - INFO - __main__ - Step 450 Global step 450 Train loss 1.50 on epoch=32
05/21/2022 06:56:43 - INFO - __main__ - Global step 450 Train loss 1.51 Classification-F1 0.03774608623006792 on epoch=32
05/21/2022 06:56:44 - INFO - __main__ - Step 460 Global step 460 Train loss 1.50 on epoch=32
05/21/2022 06:56:46 - INFO - __main__ - Step 470 Global step 470 Train loss 1.36 on epoch=33
05/21/2022 06:56:47 - INFO - __main__ - Step 480 Global step 480 Train loss 1.44 on epoch=34
05/21/2022 06:56:48 - INFO - __main__ - Step 490 Global step 490 Train loss 1.43 on epoch=34
05/21/2022 06:56:49 - INFO - __main__ - Step 500 Global step 500 Train loss 1.26 on epoch=35
05/21/2022 06:56:52 - INFO - __main__ - Global step 500 Train loss 1.40 Classification-F1 0.02813282191526838 on epoch=35
05/21/2022 06:56:53 - INFO - __main__ - Step 510 Global step 510 Train loss 1.35 on epoch=36
05/21/2022 06:56:54 - INFO - __main__ - Step 520 Global step 520 Train loss 1.37 on epoch=37
05/21/2022 06:56:56 - INFO - __main__ - Step 530 Global step 530 Train loss 1.34 on epoch=37
05/21/2022 06:56:57 - INFO - __main__ - Step 540 Global step 540 Train loss 1.35 on epoch=38
05/21/2022 06:56:58 - INFO - __main__ - Step 550 Global step 550 Train loss 1.27 on epoch=39
05/21/2022 06:57:00 - INFO - __main__ - Global step 550 Train loss 1.34 Classification-F1 0.04261294261294262 on epoch=39
05/21/2022 06:57:02 - INFO - __main__ - Step 560 Global step 560 Train loss 1.33 on epoch=39
05/21/2022 06:57:03 - INFO - __main__ - Step 570 Global step 570 Train loss 1.21 on epoch=40
05/21/2022 06:57:04 - INFO - __main__ - Step 580 Global step 580 Train loss 1.24 on epoch=41
05/21/2022 06:57:05 - INFO - __main__ - Step 590 Global step 590 Train loss 1.36 on epoch=42
05/21/2022 06:57:07 - INFO - __main__ - Step 600 Global step 600 Train loss 1.26 on epoch=42
05/21/2022 06:57:09 - INFO - __main__ - Global step 600 Train loss 1.28 Classification-F1 0.04870786708131615 on epoch=42
05/21/2022 06:57:09 - INFO - __main__ - Saving model with best Classification-F1: 0.045459506457162964 -> 0.04870786708131615 on epoch=42, global_step=600
05/21/2022 06:57:11 - INFO - __main__ - Step 610 Global step 610 Train loss 1.19 on epoch=43
05/21/2022 06:57:12 - INFO - __main__ - Step 620 Global step 620 Train loss 1.31 on epoch=44
05/21/2022 06:57:13 - INFO - __main__ - Step 630 Global step 630 Train loss 1.24 on epoch=44
05/21/2022 06:57:14 - INFO - __main__ - Step 640 Global step 640 Train loss 1.25 on epoch=45
05/21/2022 06:57:16 - INFO - __main__ - Step 650 Global step 650 Train loss 1.11 on epoch=46
05/21/2022 06:57:18 - INFO - __main__ - Global step 650 Train loss 1.22 Classification-F1 0.07608732619385582 on epoch=46
05/21/2022 06:57:18 - INFO - __main__ - Saving model with best Classification-F1: 0.04870786708131615 -> 0.07608732619385582 on epoch=46, global_step=650
05/21/2022 06:57:19 - INFO - __main__ - Step 660 Global step 660 Train loss 1.14 on epoch=47
05/21/2022 06:57:20 - INFO - __main__ - Step 670 Global step 670 Train loss 1.25 on epoch=47
05/21/2022 06:57:22 - INFO - __main__ - Step 680 Global step 680 Train loss 1.24 on epoch=48
05/21/2022 06:57:23 - INFO - __main__ - Step 690 Global step 690 Train loss 1.26 on epoch=49
05/21/2022 06:57:24 - INFO - __main__ - Step 700 Global step 700 Train loss 1.12 on epoch=49
05/21/2022 06:57:26 - INFO - __main__ - Global step 700 Train loss 1.20 Classification-F1 0.09761790273024754 on epoch=49
05/21/2022 06:57:26 - INFO - __main__ - Saving model with best Classification-F1: 0.07608732619385582 -> 0.09761790273024754 on epoch=49, global_step=700
05/21/2022 06:57:28 - INFO - __main__ - Step 710 Global step 710 Train loss 1.19 on epoch=50
05/21/2022 06:57:29 - INFO - __main__ - Step 720 Global step 720 Train loss 1.22 on epoch=51
05/21/2022 06:57:30 - INFO - __main__ - Step 730 Global step 730 Train loss 1.13 on epoch=52
05/21/2022 06:57:31 - INFO - __main__ - Step 740 Global step 740 Train loss 1.29 on epoch=52
05/21/2022 06:57:33 - INFO - __main__ - Step 750 Global step 750 Train loss 1.08 on epoch=53
05/21/2022 06:57:35 - INFO - __main__ - Global step 750 Train loss 1.18 Classification-F1 0.15153506276785378 on epoch=53
05/21/2022 06:57:35 - INFO - __main__ - Saving model with best Classification-F1: 0.09761790273024754 -> 0.15153506276785378 on epoch=53, global_step=750
05/21/2022 06:57:37 - INFO - __main__ - Step 760 Global step 760 Train loss 1.16 on epoch=54
05/21/2022 06:57:38 - INFO - __main__ - Step 770 Global step 770 Train loss 1.15 on epoch=54
05/21/2022 06:57:39 - INFO - __main__ - Step 780 Global step 780 Train loss 1.13 on epoch=55
05/21/2022 06:57:41 - INFO - __main__ - Step 790 Global step 790 Train loss 1.21 on epoch=56
05/21/2022 06:57:42 - INFO - __main__ - Step 800 Global step 800 Train loss 1.14 on epoch=57
05/21/2022 06:57:45 - INFO - __main__ - Global step 800 Train loss 1.16 Classification-F1 0.20225007727336922 on epoch=57
05/21/2022 06:57:45 - INFO - __main__ - Saving model with best Classification-F1: 0.15153506276785378 -> 0.20225007727336922 on epoch=57, global_step=800
05/21/2022 06:57:46 - INFO - __main__ - Step 810 Global step 810 Train loss 1.12 on epoch=57
05/21/2022 06:57:47 - INFO - __main__ - Step 820 Global step 820 Train loss 1.18 on epoch=58
05/21/2022 06:57:48 - INFO - __main__ - Step 830 Global step 830 Train loss 1.12 on epoch=59
05/21/2022 06:57:50 - INFO - __main__ - Step 840 Global step 840 Train loss 1.22 on epoch=59
05/21/2022 06:57:51 - INFO - __main__ - Step 850 Global step 850 Train loss 1.13 on epoch=60
05/21/2022 06:57:54 - INFO - __main__ - Global step 850 Train loss 1.15 Classification-F1 0.2969762771926456 on epoch=60
05/21/2022 06:57:54 - INFO - __main__ - Saving model with best Classification-F1: 0.20225007727336922 -> 0.2969762771926456 on epoch=60, global_step=850
05/21/2022 06:57:55 - INFO - __main__ - Step 860 Global step 860 Train loss 1.21 on epoch=61
05/21/2022 06:57:57 - INFO - __main__ - Step 870 Global step 870 Train loss 1.16 on epoch=62
05/21/2022 06:57:58 - INFO - __main__ - Step 880 Global step 880 Train loss 1.18 on epoch=62
05/21/2022 06:57:59 - INFO - __main__ - Step 890 Global step 890 Train loss 1.12 on epoch=63
05/21/2022 06:58:01 - INFO - __main__ - Step 900 Global step 900 Train loss 1.12 on epoch=64
05/21/2022 06:58:04 - INFO - __main__ - Global step 900 Train loss 1.16 Classification-F1 0.2935278609879645 on epoch=64
05/21/2022 06:58:05 - INFO - __main__ - Step 910 Global step 910 Train loss 1.16 on epoch=64
05/21/2022 06:58:07 - INFO - __main__ - Step 920 Global step 920 Train loss 1.01 on epoch=65
05/21/2022 06:58:08 - INFO - __main__ - Step 930 Global step 930 Train loss 1.20 on epoch=66
05/21/2022 06:58:09 - INFO - __main__ - Step 940 Global step 940 Train loss 1.05 on epoch=67
05/21/2022 06:58:10 - INFO - __main__ - Step 950 Global step 950 Train loss 1.09 on epoch=67
05/21/2022 06:58:14 - INFO - __main__ - Global step 950 Train loss 1.11 Classification-F1 0.3369390499279126 on epoch=67
05/21/2022 06:58:14 - INFO - __main__ - Saving model with best Classification-F1: 0.2969762771926456 -> 0.3369390499279126 on epoch=67, global_step=950
05/21/2022 06:58:15 - INFO - __main__ - Step 960 Global step 960 Train loss 1.00 on epoch=68
05/21/2022 06:58:16 - INFO - __main__ - Step 970 Global step 970 Train loss 1.03 on epoch=69
05/21/2022 06:58:18 - INFO - __main__ - Step 980 Global step 980 Train loss 1.11 on epoch=69
05/21/2022 06:58:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.98 on epoch=70
05/21/2022 06:58:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.10 on epoch=71
05/21/2022 06:58:23 - INFO - __main__ - Global step 1000 Train loss 1.04 Classification-F1 0.343701780901904 on epoch=71
05/21/2022 06:58:23 - INFO - __main__ - Saving model with best Classification-F1: 0.3369390499279126 -> 0.343701780901904 on epoch=71, global_step=1000
05/21/2022 06:58:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.01 on epoch=72
05/21/2022 06:58:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.15 on epoch=72
05/21/2022 06:58:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.07 on epoch=73
05/21/2022 06:58:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.05 on epoch=74
05/21/2022 06:58:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.10 on epoch=74
05/21/2022 06:58:33 - INFO - __main__ - Global step 1050 Train loss 1.07 Classification-F1 0.37338642031846897 on epoch=74
05/21/2022 06:58:33 - INFO - __main__ - Saving model with best Classification-F1: 0.343701780901904 -> 0.37338642031846897 on epoch=74, global_step=1050
05/21/2022 06:58:35 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.97 on epoch=75
05/21/2022 06:58:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.95 on epoch=76
05/21/2022 06:58:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.02 on epoch=77
05/21/2022 06:58:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.02 on epoch=77
05/21/2022 06:58:40 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.96 on epoch=78
05/21/2022 06:58:43 - INFO - __main__ - Global step 1100 Train loss 0.98 Classification-F1 0.43537165021219787 on epoch=78
05/21/2022 06:58:43 - INFO - __main__ - Saving model with best Classification-F1: 0.37338642031846897 -> 0.43537165021219787 on epoch=78, global_step=1100
05/21/2022 06:58:44 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.92 on epoch=79
05/21/2022 06:58:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.05 on epoch=79
05/21/2022 06:58:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.97 on epoch=80
05/21/2022 06:58:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.08 on epoch=81
05/21/2022 06:58:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.91 on epoch=82
05/21/2022 06:58:53 - INFO - __main__ - Global step 1150 Train loss 0.98 Classification-F1 0.42714428651850433 on epoch=82
05/21/2022 06:58:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.98 on epoch=82
05/21/2022 06:58:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.95 on epoch=83
05/21/2022 06:58:56 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.95 on epoch=84
05/21/2022 06:58:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.02 on epoch=84
05/21/2022 06:58:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.87 on epoch=85
05/21/2022 06:59:03 - INFO - __main__ - Global step 1200 Train loss 0.95 Classification-F1 0.44910829353455417 on epoch=85
05/21/2022 06:59:03 - INFO - __main__ - Saving model with best Classification-F1: 0.43537165021219787 -> 0.44910829353455417 on epoch=85, global_step=1200
05/21/2022 06:59:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.91 on epoch=86
05/21/2022 06:59:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.93 on epoch=87
05/21/2022 06:59:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.91 on epoch=87
05/21/2022 06:59:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.92 on epoch=88
05/21/2022 06:59:09 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.93 on epoch=89
05/21/2022 06:59:13 - INFO - __main__ - Global step 1250 Train loss 0.92 Classification-F1 0.4793966368612367 on epoch=89
05/21/2022 06:59:13 - INFO - __main__ - Saving model with best Classification-F1: 0.44910829353455417 -> 0.4793966368612367 on epoch=89, global_step=1250
05/21/2022 06:59:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.88 on epoch=89
05/21/2022 06:59:15 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.97 on epoch=90
05/21/2022 06:59:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.95 on epoch=91
05/21/2022 06:59:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.84 on epoch=92
05/21/2022 06:59:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.03 on epoch=92
05/21/2022 06:59:23 - INFO - __main__ - Global step 1300 Train loss 0.94 Classification-F1 0.4333580517887195 on epoch=92
05/21/2022 06:59:24 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.90 on epoch=93
05/21/2022 06:59:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.83 on epoch=94
05/21/2022 06:59:27 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.91 on epoch=94
05/21/2022 06:59:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.84 on epoch=95
05/21/2022 06:59:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.83 on epoch=96
05/21/2022 06:59:33 - INFO - __main__ - Global step 1350 Train loss 0.86 Classification-F1 0.4698671162599475 on epoch=96
05/21/2022 06:59:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.76 on epoch=97
05/21/2022 06:59:36 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.87 on epoch=97
05/21/2022 06:59:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.88 on epoch=98
05/21/2022 06:59:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.90 on epoch=99
05/21/2022 06:59:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.88 on epoch=99
05/21/2022 06:59:43 - INFO - __main__ - Global step 1400 Train loss 0.86 Classification-F1 0.47949550970726246 on epoch=99
05/21/2022 06:59:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4793966368612367 -> 0.47949550970726246 on epoch=99, global_step=1400
05/21/2022 06:59:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.78 on epoch=100
05/21/2022 06:59:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.92 on epoch=101
05/21/2022 06:59:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.81 on epoch=102
05/21/2022 06:59:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.86 on epoch=102
05/21/2022 06:59:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.90 on epoch=103
05/21/2022 06:59:53 - INFO - __main__ - Global step 1450 Train loss 0.85 Classification-F1 0.4376252580877085 on epoch=103
05/21/2022 06:59:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.84 on epoch=104
05/21/2022 06:59:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.87 on epoch=104
05/21/2022 06:59:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.83 on epoch=105
05/21/2022 06:59:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.89 on epoch=106
05/21/2022 06:59:59 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.86 on epoch=107
05/21/2022 07:00:03 - INFO - __main__ - Global step 1500 Train loss 0.86 Classification-F1 0.39566403191403193 on epoch=107
05/21/2022 07:00:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.83 on epoch=107
05/21/2022 07:00:05 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.82 on epoch=108
05/21/2022 07:00:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.87 on epoch=109
05/21/2022 07:00:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.86 on epoch=109
05/21/2022 07:00:09 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.79 on epoch=110
05/21/2022 07:00:13 - INFO - __main__ - Global step 1550 Train loss 0.83 Classification-F1 0.44913829129213584 on epoch=110
05/21/2022 07:00:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.75 on epoch=111
05/21/2022 07:00:15 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.80 on epoch=112
05/21/2022 07:00:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.84 on epoch=112
05/21/2022 07:00:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.74 on epoch=113
05/21/2022 07:00:19 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.80 on epoch=114
05/21/2022 07:00:23 - INFO - __main__ - Global step 1600 Train loss 0.79 Classification-F1 0.3892550605805874 on epoch=114
05/21/2022 07:00:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.86 on epoch=114
05/21/2022 07:00:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.73 on epoch=115
05/21/2022 07:00:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.87 on epoch=116
05/21/2022 07:00:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.76 on epoch=117
05/21/2022 07:00:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.81 on epoch=117
05/21/2022 07:00:33 - INFO - __main__ - Global step 1650 Train loss 0.80 Classification-F1 0.5256511978570801 on epoch=117
05/21/2022 07:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.47949550970726246 -> 0.5256511978570801 on epoch=117, global_step=1650
05/21/2022 07:00:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.92 on epoch=118
05/21/2022 07:00:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.80 on epoch=119
05/21/2022 07:00:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.80 on epoch=119
05/21/2022 07:00:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.78 on epoch=120
05/21/2022 07:00:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.89 on epoch=121
05/21/2022 07:00:43 - INFO - __main__ - Global step 1700 Train loss 0.84 Classification-F1 0.48472201758971517 on epoch=121
05/21/2022 07:00:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.74 on epoch=122
05/21/2022 07:00:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.80 on epoch=122
05/21/2022 07:00:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.79 on epoch=123
05/21/2022 07:00:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.75 on epoch=124
05/21/2022 07:00:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.81 on epoch=124
05/21/2022 07:00:53 - INFO - __main__ - Global step 1750 Train loss 0.78 Classification-F1 0.5199893182018138 on epoch=124
05/21/2022 07:00:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.70 on epoch=125
05/21/2022 07:00:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.71 on epoch=126
05/21/2022 07:00:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.73 on epoch=127
05/21/2022 07:00:58 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.88 on epoch=127
05/21/2022 07:01:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.82 on epoch=128
05/21/2022 07:01:04 - INFO - __main__ - Global step 1800 Train loss 0.77 Classification-F1 0.4781458076091719 on epoch=128
05/21/2022 07:01:05 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.75 on epoch=129
05/21/2022 07:01:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.77 on epoch=129
05/21/2022 07:01:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.78 on epoch=130
05/21/2022 07:01:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.80 on epoch=131
05/21/2022 07:01:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.77 on epoch=132
05/21/2022 07:01:14 - INFO - __main__ - Global step 1850 Train loss 0.77 Classification-F1 0.47460890910184605 on epoch=132
05/21/2022 07:01:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.84 on epoch=132
05/21/2022 07:01:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.88 on epoch=133
05/21/2022 07:01:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.82 on epoch=134
05/21/2022 07:01:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.88 on epoch=134
05/21/2022 07:01:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.73 on epoch=135
05/21/2022 07:01:23 - INFO - __main__ - Global step 1900 Train loss 0.83 Classification-F1 0.5647611932600957 on epoch=135
05/21/2022 07:01:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5256511978570801 -> 0.5647611932600957 on epoch=135, global_step=1900
05/21/2022 07:01:25 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.80 on epoch=136
05/21/2022 07:01:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.87 on epoch=137
05/21/2022 07:01:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.78 on epoch=137
05/21/2022 07:01:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.71 on epoch=138
05/21/2022 07:01:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.80 on epoch=139
05/21/2022 07:01:33 - INFO - __main__ - Global step 1950 Train loss 0.79 Classification-F1 0.46234085215238024 on epoch=139
05/21/2022 07:01:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.77 on epoch=139
05/21/2022 07:01:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.78 on epoch=140
05/21/2022 07:01:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.73 on epoch=141
05/21/2022 07:01:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.78 on epoch=142
05/21/2022 07:01:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.77 on epoch=142
05/21/2022 07:01:43 - INFO - __main__ - Global step 2000 Train loss 0.77 Classification-F1 0.45560669923554 on epoch=142
05/21/2022 07:01:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.73 on epoch=143
05/21/2022 07:01:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.75 on epoch=144
05/21/2022 07:01:47 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.72 on epoch=144
05/21/2022 07:01:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.77 on epoch=145
05/21/2022 07:01:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.80 on epoch=146
05/21/2022 07:01:53 - INFO - __main__ - Global step 2050 Train loss 0.76 Classification-F1 0.42438872272077643 on epoch=146
05/21/2022 07:01:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.76 on epoch=147
05/21/2022 07:01:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.70 on epoch=147
05/21/2022 07:01:57 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.77 on epoch=148
05/21/2022 07:01:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.73 on epoch=149
05/21/2022 07:01:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.69 on epoch=149
05/21/2022 07:02:03 - INFO - __main__ - Global step 2100 Train loss 0.73 Classification-F1 0.48867141173513723 on epoch=149
05/21/2022 07:02:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.71 on epoch=150
05/21/2022 07:02:05 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.75 on epoch=151
05/21/2022 07:02:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.65 on epoch=152
05/21/2022 07:02:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.75 on epoch=152
05/21/2022 07:02:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.68 on epoch=153
05/21/2022 07:02:13 - INFO - __main__ - Global step 2150 Train loss 0.71 Classification-F1 0.4390922082556436 on epoch=153
05/21/2022 07:02:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.66 on epoch=154
05/21/2022 07:02:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.67 on epoch=154
05/21/2022 07:02:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.59 on epoch=155
05/21/2022 07:02:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.70 on epoch=156
05/21/2022 07:02:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.69 on epoch=157
05/21/2022 07:02:23 - INFO - __main__ - Global step 2200 Train loss 0.66 Classification-F1 0.46170984109300167 on epoch=157
05/21/2022 07:02:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.61 on epoch=157
05/21/2022 07:02:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.62 on epoch=158
05/21/2022 07:02:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.63 on epoch=159
05/21/2022 07:02:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.71 on epoch=159
05/21/2022 07:02:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.63 on epoch=160
05/21/2022 07:02:33 - INFO - __main__ - Global step 2250 Train loss 0.64 Classification-F1 0.5376867394258699 on epoch=160
05/21/2022 07:02:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.66 on epoch=161
05/21/2022 07:02:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.68 on epoch=162
05/21/2022 07:02:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.72 on epoch=162
05/21/2022 07:02:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.64 on epoch=163
05/21/2022 07:02:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.69 on epoch=164
05/21/2022 07:02:43 - INFO - __main__ - Global step 2300 Train loss 0.68 Classification-F1 0.47831554988338665 on epoch=164
05/21/2022 07:02:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.70 on epoch=164
05/21/2022 07:02:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.74 on epoch=165
05/21/2022 07:02:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.62 on epoch=166
05/21/2022 07:02:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.73 on epoch=167
05/21/2022 07:02:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.75 on epoch=167
05/21/2022 07:02:53 - INFO - __main__ - Global step 2350 Train loss 0.71 Classification-F1 0.44206180315157395 on epoch=167
05/21/2022 07:02:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.64 on epoch=168
05/21/2022 07:02:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.63 on epoch=169
05/21/2022 07:02:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.69 on epoch=169
05/21/2022 07:02:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.57 on epoch=170
05/21/2022 07:02:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.70 on epoch=171
05/21/2022 07:03:03 - INFO - __main__ - Global step 2400 Train loss 0.65 Classification-F1 0.5401854202975299 on epoch=171
05/21/2022 07:03:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.70 on epoch=172
05/21/2022 07:03:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.67 on epoch=172
05/21/2022 07:03:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.74 on epoch=173
05/21/2022 07:03:08 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.65 on epoch=174
05/21/2022 07:03:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.66 on epoch=174
05/21/2022 07:03:13 - INFO - __main__ - Global step 2450 Train loss 0.68 Classification-F1 0.5159776904014176 on epoch=174
05/21/2022 07:03:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.63 on epoch=175
05/21/2022 07:03:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.53 on epoch=176
05/21/2022 07:03:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.66 on epoch=177
05/21/2022 07:03:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.61 on epoch=177
05/21/2022 07:03:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.63 on epoch=178
05/21/2022 07:03:23 - INFO - __main__ - Global step 2500 Train loss 0.61 Classification-F1 0.5942302463655917 on epoch=178
05/21/2022 07:03:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5647611932600957 -> 0.5942302463655917 on epoch=178, global_step=2500
05/21/2022 07:03:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.74 on epoch=179
05/21/2022 07:03:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.62 on epoch=179
05/21/2022 07:03:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.69 on epoch=180
05/21/2022 07:03:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.74 on epoch=181
05/21/2022 07:03:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.63 on epoch=182
05/21/2022 07:03:33 - INFO - __main__ - Global step 2550 Train loss 0.68 Classification-F1 0.5189331602634396 on epoch=182
05/21/2022 07:03:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.73 on epoch=182
05/21/2022 07:03:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.69 on epoch=183
05/21/2022 07:03:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.78 on epoch=184
05/21/2022 07:03:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.62 on epoch=184
05/21/2022 07:03:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.67 on epoch=185
05/21/2022 07:03:43 - INFO - __main__ - Global step 2600 Train loss 0.70 Classification-F1 0.5579912725102983 on epoch=185
05/21/2022 07:03:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.65 on epoch=186
05/21/2022 07:03:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.64 on epoch=187
05/21/2022 07:03:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.79 on epoch=187
05/21/2022 07:03:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.61 on epoch=188
05/21/2022 07:03:49 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.67 on epoch=189
05/21/2022 07:03:53 - INFO - __main__ - Global step 2650 Train loss 0.67 Classification-F1 0.4393120527914262 on epoch=189
05/21/2022 07:03:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.61 on epoch=189
05/21/2022 07:03:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.71 on epoch=190
05/21/2022 07:03:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.78 on epoch=191
05/21/2022 07:03:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.63 on epoch=192
05/21/2022 07:03:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.79 on epoch=192
05/21/2022 07:04:03 - INFO - __main__ - Global step 2700 Train loss 0.70 Classification-F1 0.4350582028086985 on epoch=192
05/21/2022 07:04:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.66 on epoch=193
05/21/2022 07:04:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.68 on epoch=194
05/21/2022 07:04:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.70 on epoch=194
05/21/2022 07:04:08 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.65 on epoch=195
05/21/2022 07:04:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.70 on epoch=196
05/21/2022 07:04:13 - INFO - __main__ - Global step 2750 Train loss 0.68 Classification-F1 0.4604540222613731 on epoch=196
05/21/2022 07:04:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.60 on epoch=197
05/21/2022 07:04:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.69 on epoch=197
05/21/2022 07:04:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.61 on epoch=198
05/21/2022 07:04:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.67 on epoch=199
05/21/2022 07:04:20 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.62 on epoch=199
05/21/2022 07:04:24 - INFO - __main__ - Global step 2800 Train loss 0.64 Classification-F1 0.5558195734033811 on epoch=199
05/21/2022 07:04:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.61 on epoch=200
05/21/2022 07:04:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.59 on epoch=201
05/21/2022 07:04:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.67 on epoch=202
05/21/2022 07:04:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.60 on epoch=202
05/21/2022 07:04:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.71 on epoch=203
05/21/2022 07:04:34 - INFO - __main__ - Global step 2850 Train loss 0.64 Classification-F1 0.5020855956079081 on epoch=203
05/21/2022 07:04:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.61 on epoch=204
05/21/2022 07:04:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.66 on epoch=204
05/21/2022 07:04:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.59 on epoch=205
05/21/2022 07:04:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.63 on epoch=206
05/21/2022 07:04:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.68 on epoch=207
05/21/2022 07:04:44 - INFO - __main__ - Global step 2900 Train loss 0.63 Classification-F1 0.5640058238034101 on epoch=207
05/21/2022 07:04:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.67 on epoch=207
05/21/2022 07:04:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.59 on epoch=208
05/21/2022 07:04:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.68 on epoch=209
05/21/2022 07:04:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.68 on epoch=209
05/21/2022 07:04:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.62 on epoch=210
05/21/2022 07:04:54 - INFO - __main__ - Global step 2950 Train loss 0.65 Classification-F1 0.5270329856558985 on epoch=210
05/21/2022 07:04:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.60 on epoch=211
05/21/2022 07:04:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.54 on epoch=212
05/21/2022 07:04:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.54 on epoch=212
05/21/2022 07:04:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.56 on epoch=213
05/21/2022 07:05:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.56 on epoch=214
05/21/2022 07:05:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:05:01 - INFO - __main__ - Printing 3 examples
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:05:01 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:05:01 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 07:05:01 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:05:01 - INFO - __main__ - Printing 3 examples
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 07:05:01 - INFO - __main__ - ['Film']
05/21/2022 07:05:01 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:05:02 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:05:02 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 07:05:04 - INFO - __main__ - Global step 3000 Train loss 0.56 Classification-F1 0.445837100382555 on epoch=214
05/21/2022 07:05:04 - INFO - __main__ - save last model!
05/21/2022 07:05:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 07:05:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 07:05:04 - INFO - __main__ - Printing 3 examples
05/21/2022 07:05:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 07:05:04 - INFO - __main__ - ['Animal']
05/21/2022 07:05:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 07:05:04 - INFO - __main__ - ['Animal']
05/21/2022 07:05:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 07:05:04 - INFO - __main__ - ['Village']
05/21/2022 07:05:04 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:05:06 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:05:07 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 07:05:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 07:05:07 - INFO - __main__ - Starting training!
05/21/2022 07:05:09 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 07:06:17 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
05/21/2022 07:06:17 - INFO - __main__ - Classification-F1 on test data: 0.2031
05/21/2022 07:06:18 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.5942302463655917, test_performance=0.2031005213820054
05/21/2022 07:06:18 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
05/21/2022 07:06:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:06:19 - INFO - __main__ - Printing 3 examples
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:06:19 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:06:19 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 07:06:19 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:06:19 - INFO - __main__ - Printing 3 examples
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 07:06:19 - INFO - __main__ - ['Film']
05/21/2022 07:06:19 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:06:19 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:06:20 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 07:06:26 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 07:06:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 07:06:26 - INFO - __main__ - Starting training!
05/21/2022 07:06:27 - INFO - __main__ - Step 10 Global step 10 Train loss 7.30 on epoch=0
05/21/2022 07:06:29 - INFO - __main__ - Step 20 Global step 20 Train loss 6.96 on epoch=1
05/21/2022 07:06:30 - INFO - __main__ - Step 30 Global step 30 Train loss 6.45 on epoch=2
05/21/2022 07:06:31 - INFO - __main__ - Step 40 Global step 40 Train loss 6.13 on epoch=2
05/21/2022 07:06:33 - INFO - __main__ - Step 50 Global step 50 Train loss 5.73 on epoch=3
05/21/2022 07:06:35 - INFO - __main__ - Global step 50 Train loss 6.51 Classification-F1 0.0 on epoch=3
05/21/2022 07:06:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 07:06:37 - INFO - __main__ - Step 60 Global step 60 Train loss 5.37 on epoch=4
05/21/2022 07:06:38 - INFO - __main__ - Step 70 Global step 70 Train loss 5.34 on epoch=4
05/21/2022 07:06:39 - INFO - __main__ - Step 80 Global step 80 Train loss 5.06 on epoch=5
05/21/2022 07:06:40 - INFO - __main__ - Step 90 Global step 90 Train loss 5.01 on epoch=6
05/21/2022 07:06:42 - INFO - __main__ - Step 100 Global step 100 Train loss 4.60 on epoch=7
05/21/2022 07:06:45 - INFO - __main__ - Global step 100 Train loss 5.07 Classification-F1 0.0 on epoch=7
05/21/2022 07:06:46 - INFO - __main__ - Step 110 Global step 110 Train loss 4.61 on epoch=7
05/21/2022 07:06:47 - INFO - __main__ - Step 120 Global step 120 Train loss 4.39 on epoch=8
05/21/2022 07:06:49 - INFO - __main__ - Step 130 Global step 130 Train loss 3.99 on epoch=9
05/21/2022 07:06:50 - INFO - __main__ - Step 140 Global step 140 Train loss 3.89 on epoch=9
05/21/2022 07:06:51 - INFO - __main__ - Step 150 Global step 150 Train loss 3.74 on epoch=10
05/21/2022 07:06:54 - INFO - __main__ - Global step 150 Train loss 4.12 Classification-F1 0.0 on epoch=10
05/21/2022 07:06:56 - INFO - __main__ - Step 160 Global step 160 Train loss 3.62 on epoch=11
05/21/2022 07:06:57 - INFO - __main__ - Step 170 Global step 170 Train loss 3.47 on epoch=12
05/21/2022 07:06:58 - INFO - __main__ - Step 180 Global step 180 Train loss 3.44 on epoch=12
05/21/2022 07:07:00 - INFO - __main__ - Step 190 Global step 190 Train loss 3.37 on epoch=13
05/21/2022 07:07:01 - INFO - __main__ - Step 200 Global step 200 Train loss 3.24 on epoch=14
05/21/2022 07:07:04 - INFO - __main__ - Global step 200 Train loss 3.43 Classification-F1 0.0017301038062283738 on epoch=14
05/21/2022 07:07:04 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0017301038062283738 on epoch=14, global_step=200
05/21/2022 07:07:05 - INFO - __main__ - Step 210 Global step 210 Train loss 3.21 on epoch=14
05/21/2022 07:07:07 - INFO - __main__ - Step 220 Global step 220 Train loss 2.97 on epoch=15
05/21/2022 07:07:08 - INFO - __main__ - Step 230 Global step 230 Train loss 2.88 on epoch=16
05/21/2022 07:07:09 - INFO - __main__ - Step 240 Global step 240 Train loss 2.78 on epoch=17
05/21/2022 07:07:10 - INFO - __main__ - Step 250 Global step 250 Train loss 2.71 on epoch=17
05/21/2022 07:07:13 - INFO - __main__ - Global step 250 Train loss 2.91 Classification-F1 0.007575757575757575 on epoch=17
05/21/2022 07:07:13 - INFO - __main__ - Saving model with best Classification-F1: 0.0017301038062283738 -> 0.007575757575757575 on epoch=17, global_step=250
05/21/2022 07:07:14 - INFO - __main__ - Step 260 Global step 260 Train loss 2.60 on epoch=18
05/21/2022 07:07:15 - INFO - __main__ - Step 270 Global step 270 Train loss 2.60 on epoch=19
05/21/2022 07:07:17 - INFO - __main__ - Step 280 Global step 280 Train loss 2.60 on epoch=19
05/21/2022 07:07:18 - INFO - __main__ - Step 290 Global step 290 Train loss 2.51 on epoch=20
05/21/2022 07:07:19 - INFO - __main__ - Step 300 Global step 300 Train loss 2.53 on epoch=21
05/21/2022 07:07:21 - INFO - __main__ - Global step 300 Train loss 2.57 Classification-F1 0.009523809523809523 on epoch=21
05/21/2022 07:07:21 - INFO - __main__ - Saving model with best Classification-F1: 0.007575757575757575 -> 0.009523809523809523 on epoch=21, global_step=300
05/21/2022 07:07:22 - INFO - __main__ - Step 310 Global step 310 Train loss 2.35 on epoch=22
05/21/2022 07:07:24 - INFO - __main__ - Step 320 Global step 320 Train loss 2.34 on epoch=22
05/21/2022 07:07:25 - INFO - __main__ - Step 330 Global step 330 Train loss 2.20 on epoch=23
05/21/2022 07:07:26 - INFO - __main__ - Step 340 Global step 340 Train loss 2.16 on epoch=24
05/21/2022 07:07:27 - INFO - __main__ - Step 350 Global step 350 Train loss 2.16 on epoch=24
05/21/2022 07:07:29 - INFO - __main__ - Global step 350 Train loss 2.24 Classification-F1 0.009523809523809523 on epoch=24
05/21/2022 07:07:31 - INFO - __main__ - Step 360 Global step 360 Train loss 2.03 on epoch=25
05/21/2022 07:07:32 - INFO - __main__ - Step 370 Global step 370 Train loss 2.13 on epoch=26
05/21/2022 07:07:33 - INFO - __main__ - Step 380 Global step 380 Train loss 1.93 on epoch=27
05/21/2022 07:07:34 - INFO - __main__ - Step 390 Global step 390 Train loss 2.03 on epoch=27
05/21/2022 07:07:36 - INFO - __main__ - Step 400 Global step 400 Train loss 1.93 on epoch=28
05/21/2022 07:07:38 - INFO - __main__ - Global step 400 Train loss 2.01 Classification-F1 0.02304109329928595 on epoch=28
05/21/2022 07:07:38 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.02304109329928595 on epoch=28, global_step=400
05/21/2022 07:07:39 - INFO - __main__ - Step 410 Global step 410 Train loss 1.92 on epoch=29
05/21/2022 07:07:40 - INFO - __main__ - Step 420 Global step 420 Train loss 1.87 on epoch=29
05/21/2022 07:07:42 - INFO - __main__ - Step 430 Global step 430 Train loss 1.88 on epoch=30
05/21/2022 07:07:43 - INFO - __main__ - Step 440 Global step 440 Train loss 1.99 on epoch=31
05/21/2022 07:07:44 - INFO - __main__ - Step 450 Global step 450 Train loss 1.73 on epoch=32
05/21/2022 07:07:46 - INFO - __main__ - Global step 450 Train loss 1.88 Classification-F1 0.027753299029894773 on epoch=32
05/21/2022 07:07:46 - INFO - __main__ - Saving model with best Classification-F1: 0.02304109329928595 -> 0.027753299029894773 on epoch=32, global_step=450
05/21/2022 07:07:47 - INFO - __main__ - Step 460 Global step 460 Train loss 1.78 on epoch=32
05/21/2022 07:07:49 - INFO - __main__ - Step 470 Global step 470 Train loss 1.72 on epoch=33
05/21/2022 07:07:50 - INFO - __main__ - Step 480 Global step 480 Train loss 1.76 on epoch=34
05/21/2022 07:07:51 - INFO - __main__ - Step 490 Global step 490 Train loss 1.81 on epoch=34
05/21/2022 07:07:52 - INFO - __main__ - Step 500 Global step 500 Train loss 1.66 on epoch=35
05/21/2022 07:07:55 - INFO - __main__ - Global step 500 Train loss 1.75 Classification-F1 0.03974396776254362 on epoch=35
05/21/2022 07:07:55 - INFO - __main__ - Saving model with best Classification-F1: 0.027753299029894773 -> 0.03974396776254362 on epoch=35, global_step=500
05/21/2022 07:07:56 - INFO - __main__ - Step 510 Global step 510 Train loss 1.74 on epoch=36
05/21/2022 07:07:57 - INFO - __main__ - Step 520 Global step 520 Train loss 1.60 on epoch=37
05/21/2022 07:07:59 - INFO - __main__ - Step 530 Global step 530 Train loss 1.74 on epoch=37
05/21/2022 07:08:00 - INFO - __main__ - Step 540 Global step 540 Train loss 1.61 on epoch=38
05/21/2022 07:08:01 - INFO - __main__ - Step 550 Global step 550 Train loss 1.59 on epoch=39
05/21/2022 07:08:03 - INFO - __main__ - Global step 550 Train loss 1.66 Classification-F1 0.03481850585013458 on epoch=39
05/21/2022 07:08:04 - INFO - __main__ - Step 560 Global step 560 Train loss 1.59 on epoch=39
05/21/2022 07:08:06 - INFO - __main__ - Step 570 Global step 570 Train loss 1.54 on epoch=40
05/21/2022 07:08:07 - INFO - __main__ - Step 580 Global step 580 Train loss 1.56 on epoch=41
05/21/2022 07:08:08 - INFO - __main__ - Step 590 Global step 590 Train loss 1.47 on epoch=42
05/21/2022 07:08:10 - INFO - __main__ - Step 600 Global step 600 Train loss 1.49 on epoch=42
05/21/2022 07:08:12 - INFO - __main__ - Global step 600 Train loss 1.53 Classification-F1 0.048030173356859045 on epoch=42
05/21/2022 07:08:12 - INFO - __main__ - Saving model with best Classification-F1: 0.03974396776254362 -> 0.048030173356859045 on epoch=42, global_step=600
05/21/2022 07:08:13 - INFO - __main__ - Step 610 Global step 610 Train loss 1.46 on epoch=43
05/21/2022 07:08:15 - INFO - __main__ - Step 620 Global step 620 Train loss 1.51 on epoch=44
05/21/2022 07:08:16 - INFO - __main__ - Step 630 Global step 630 Train loss 1.55 on epoch=44
05/21/2022 07:08:17 - INFO - __main__ - Step 640 Global step 640 Train loss 1.41 on epoch=45
05/21/2022 07:08:18 - INFO - __main__ - Step 650 Global step 650 Train loss 1.40 on epoch=46
05/21/2022 07:08:21 - INFO - __main__ - Global step 650 Train loss 1.47 Classification-F1 0.057636993927316506 on epoch=46
05/21/2022 07:08:21 - INFO - __main__ - Saving model with best Classification-F1: 0.048030173356859045 -> 0.057636993927316506 on epoch=46, global_step=650
05/21/2022 07:08:22 - INFO - __main__ - Step 660 Global step 660 Train loss 1.30 on epoch=47
05/21/2022 07:08:24 - INFO - __main__ - Step 670 Global step 670 Train loss 1.46 on epoch=47
05/21/2022 07:08:25 - INFO - __main__ - Step 680 Global step 680 Train loss 1.42 on epoch=48
05/21/2022 07:08:26 - INFO - __main__ - Step 690 Global step 690 Train loss 1.39 on epoch=49
05/21/2022 07:08:27 - INFO - __main__ - Step 700 Global step 700 Train loss 1.28 on epoch=49
05/21/2022 07:08:30 - INFO - __main__ - Global step 700 Train loss 1.37 Classification-F1 0.05262563152634075 on epoch=49
05/21/2022 07:08:31 - INFO - __main__ - Step 710 Global step 710 Train loss 1.29 on epoch=50
05/21/2022 07:08:32 - INFO - __main__ - Step 720 Global step 720 Train loss 1.38 on epoch=51
05/21/2022 07:08:34 - INFO - __main__ - Step 730 Global step 730 Train loss 1.25 on epoch=52
05/21/2022 07:08:35 - INFO - __main__ - Step 740 Global step 740 Train loss 1.40 on epoch=52
05/21/2022 07:08:36 - INFO - __main__ - Step 750 Global step 750 Train loss 1.28 on epoch=53
05/21/2022 07:08:39 - INFO - __main__ - Global step 750 Train loss 1.32 Classification-F1 0.05135118601078841 on epoch=53
05/21/2022 07:08:40 - INFO - __main__ - Step 760 Global step 760 Train loss 1.30 on epoch=54
05/21/2022 07:08:41 - INFO - __main__ - Step 770 Global step 770 Train loss 1.39 on epoch=54
05/21/2022 07:08:43 - INFO - __main__ - Step 780 Global step 780 Train loss 1.25 on epoch=55
05/21/2022 07:08:44 - INFO - __main__ - Step 790 Global step 790 Train loss 1.37 on epoch=56
05/21/2022 07:08:45 - INFO - __main__ - Step 800 Global step 800 Train loss 1.32 on epoch=57
05/21/2022 07:08:47 - INFO - __main__ - Global step 800 Train loss 1.33 Classification-F1 0.05428010428010427 on epoch=57
05/21/2022 07:08:49 - INFO - __main__ - Step 810 Global step 810 Train loss 1.26 on epoch=57
05/21/2022 07:08:50 - INFO - __main__ - Step 820 Global step 820 Train loss 1.31 on epoch=58
05/21/2022 07:08:51 - INFO - __main__ - Step 830 Global step 830 Train loss 1.31 on epoch=59
05/21/2022 07:08:52 - INFO - __main__ - Step 840 Global step 840 Train loss 1.26 on epoch=59
05/21/2022 07:08:54 - INFO - __main__ - Step 850 Global step 850 Train loss 1.19 on epoch=60
05/21/2022 07:08:56 - INFO - __main__ - Global step 850 Train loss 1.26 Classification-F1 0.059070269561291334 on epoch=60
05/21/2022 07:08:56 - INFO - __main__ - Saving model with best Classification-F1: 0.057636993927316506 -> 0.059070269561291334 on epoch=60, global_step=850
05/21/2022 07:08:58 - INFO - __main__ - Step 860 Global step 860 Train loss 1.31 on epoch=61
05/21/2022 07:08:59 - INFO - __main__ - Step 870 Global step 870 Train loss 1.15 on epoch=62
05/21/2022 07:09:00 - INFO - __main__ - Step 880 Global step 880 Train loss 1.25 on epoch=62
05/21/2022 07:09:01 - INFO - __main__ - Step 890 Global step 890 Train loss 1.17 on epoch=63
05/21/2022 07:09:03 - INFO - __main__ - Step 900 Global step 900 Train loss 1.33 on epoch=64
05/21/2022 07:09:05 - INFO - __main__ - Global step 900 Train loss 1.24 Classification-F1 0.09585680572520053 on epoch=64
05/21/2022 07:09:05 - INFO - __main__ - Saving model with best Classification-F1: 0.059070269561291334 -> 0.09585680572520053 on epoch=64, global_step=900
05/21/2022 07:09:06 - INFO - __main__ - Step 910 Global step 910 Train loss 1.20 on epoch=64
05/21/2022 07:09:08 - INFO - __main__ - Step 920 Global step 920 Train loss 1.22 on epoch=65
05/21/2022 07:09:09 - INFO - __main__ - Step 930 Global step 930 Train loss 1.24 on epoch=66
05/21/2022 07:09:10 - INFO - __main__ - Step 940 Global step 940 Train loss 1.22 on epoch=67
05/21/2022 07:09:12 - INFO - __main__ - Step 950 Global step 950 Train loss 1.31 on epoch=67
05/21/2022 07:09:14 - INFO - __main__ - Global step 950 Train loss 1.24 Classification-F1 0.07377961950330371 on epoch=67
05/21/2022 07:09:15 - INFO - __main__ - Step 960 Global step 960 Train loss 1.15 on epoch=68
05/21/2022 07:09:17 - INFO - __main__ - Step 970 Global step 970 Train loss 1.18 on epoch=69
05/21/2022 07:09:18 - INFO - __main__ - Step 980 Global step 980 Train loss 1.26 on epoch=69
05/21/2022 07:09:19 - INFO - __main__ - Step 990 Global step 990 Train loss 1.22 on epoch=70
05/21/2022 07:09:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.25 on epoch=71
05/21/2022 07:09:23 - INFO - __main__ - Global step 1000 Train loss 1.21 Classification-F1 0.09379222996192248 on epoch=71
05/21/2022 07:09:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.28 on epoch=72
05/21/2022 07:09:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.22 on epoch=72
05/21/2022 07:09:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.15 on epoch=73
05/21/2022 07:09:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.16 on epoch=74
05/21/2022 07:09:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.21 on epoch=74
05/21/2022 07:09:32 - INFO - __main__ - Global step 1050 Train loss 1.20 Classification-F1 0.1362566752082024 on epoch=74
05/21/2022 07:09:32 - INFO - __main__ - Saving model with best Classification-F1: 0.09585680572520053 -> 0.1362566752082024 on epoch=74, global_step=1050
05/21/2022 07:09:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.06 on epoch=75
05/21/2022 07:09:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.17 on epoch=76
05/21/2022 07:09:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.18 on epoch=77
05/21/2022 07:09:37 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.19 on epoch=77
05/21/2022 07:09:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.10 on epoch=78
05/21/2022 07:09:41 - INFO - __main__ - Global step 1100 Train loss 1.14 Classification-F1 0.15215247135586243 on epoch=78
05/21/2022 07:09:41 - INFO - __main__ - Saving model with best Classification-F1: 0.1362566752082024 -> 0.15215247135586243 on epoch=78, global_step=1100
05/21/2022 07:09:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.22 on epoch=79
05/21/2022 07:09:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.16 on epoch=79
05/21/2022 07:09:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.19 on epoch=80
05/21/2022 07:09:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.23 on epoch=81
05/21/2022 07:09:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.10 on epoch=82
05/21/2022 07:09:50 - INFO - __main__ - Global step 1150 Train loss 1.18 Classification-F1 0.17560138854070878 on epoch=82
05/21/2022 07:09:50 - INFO - __main__ - Saving model with best Classification-F1: 0.15215247135586243 -> 0.17560138854070878 on epoch=82, global_step=1150
05/21/2022 07:09:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.17 on epoch=82
05/21/2022 07:09:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.03 on epoch=83
05/21/2022 07:09:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.17 on epoch=84
05/21/2022 07:09:56 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.15 on epoch=84
05/21/2022 07:09:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.05 on epoch=85
05/21/2022 07:10:00 - INFO - __main__ - Global step 1200 Train loss 1.12 Classification-F1 0.1806111300281909 on epoch=85
05/21/2022 07:10:00 - INFO - __main__ - Saving model with best Classification-F1: 0.17560138854070878 -> 0.1806111300281909 on epoch=85, global_step=1200
05/21/2022 07:10:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.13 on epoch=86
05/21/2022 07:10:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.09 on epoch=87
05/21/2022 07:10:04 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.14 on epoch=87
05/21/2022 07:10:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.09 on epoch=88
05/21/2022 07:10:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.14 on epoch=89
05/21/2022 07:10:09 - INFO - __main__ - Global step 1250 Train loss 1.12 Classification-F1 0.2620690422783464 on epoch=89
05/21/2022 07:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1806111300281909 -> 0.2620690422783464 on epoch=89, global_step=1250
05/21/2022 07:10:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.17 on epoch=89
05/21/2022 07:10:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.02 on epoch=90
05/21/2022 07:10:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.11 on epoch=91
05/21/2022 07:10:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.03 on epoch=92
05/21/2022 07:10:16 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.11 on epoch=92
05/21/2022 07:10:19 - INFO - __main__ - Global step 1300 Train loss 1.09 Classification-F1 0.24170885057410127 on epoch=92
05/21/2022 07:10:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.04 on epoch=93
05/21/2022 07:10:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.10 on epoch=94
05/21/2022 07:10:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.18 on epoch=94
05/21/2022 07:10:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.08 on epoch=95
05/21/2022 07:10:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.22 on epoch=96
05/21/2022 07:10:28 - INFO - __main__ - Global step 1350 Train loss 1.12 Classification-F1 0.33113408155366825 on epoch=96
05/21/2022 07:10:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2620690422783464 -> 0.33113408155366825 on epoch=96, global_step=1350
05/21/2022 07:10:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.99 on epoch=97
05/21/2022 07:10:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.22 on epoch=97
05/21/2022 07:10:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.99 on epoch=98
05/21/2022 07:10:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.04 on epoch=99
05/21/2022 07:10:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.11 on epoch=99
05/21/2022 07:10:38 - INFO - __main__ - Global step 1400 Train loss 1.07 Classification-F1 0.2539671291675433 on epoch=99
05/21/2022 07:10:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.03 on epoch=100
05/21/2022 07:10:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.09 on epoch=101
05/21/2022 07:10:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.03 on epoch=102
05/21/2022 07:10:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.00 on epoch=102
05/21/2022 07:10:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.01 on epoch=103
05/21/2022 07:10:47 - INFO - __main__ - Global step 1450 Train loss 1.03 Classification-F1 0.25018028116388774 on epoch=103
05/21/2022 07:10:49 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.08 on epoch=104
05/21/2022 07:10:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.04 on epoch=104
05/21/2022 07:10:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.92 on epoch=105
05/21/2022 07:10:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.13 on epoch=106
05/21/2022 07:10:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.02 on epoch=107
05/21/2022 07:10:58 - INFO - __main__ - Global step 1500 Train loss 1.04 Classification-F1 0.31932222825817097 on epoch=107
05/21/2022 07:10:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.02 on epoch=107
05/21/2022 07:11:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.00 on epoch=108
05/21/2022 07:11:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.08 on epoch=109
05/21/2022 07:11:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.04 on epoch=109
05/21/2022 07:11:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.01 on epoch=110
05/21/2022 07:11:07 - INFO - __main__ - Global step 1550 Train loss 1.03 Classification-F1 0.34736894011029806 on epoch=110
05/21/2022 07:11:07 - INFO - __main__ - Saving model with best Classification-F1: 0.33113408155366825 -> 0.34736894011029806 on epoch=110, global_step=1550
05/21/2022 07:11:09 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.08 on epoch=111
05/21/2022 07:11:10 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.01 on epoch=112
05/21/2022 07:11:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.96 on epoch=112
05/21/2022 07:11:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.97 on epoch=113
05/21/2022 07:11:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.04 on epoch=114
05/21/2022 07:11:17 - INFO - __main__ - Global step 1600 Train loss 1.01 Classification-F1 0.388241032306253 on epoch=114
05/21/2022 07:11:17 - INFO - __main__ - Saving model with best Classification-F1: 0.34736894011029806 -> 0.388241032306253 on epoch=114, global_step=1600
05/21/2022 07:11:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.08 on epoch=114
05/21/2022 07:11:20 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.86 on epoch=115
05/21/2022 07:11:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.02 on epoch=116
05/21/2022 07:11:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.95 on epoch=117
05/21/2022 07:11:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.95 on epoch=117
05/21/2022 07:11:27 - INFO - __main__ - Global step 1650 Train loss 0.97 Classification-F1 0.40042318597145965 on epoch=117
05/21/2022 07:11:27 - INFO - __main__ - Saving model with best Classification-F1: 0.388241032306253 -> 0.40042318597145965 on epoch=117, global_step=1650
05/21/2022 07:11:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.97 on epoch=118
05/21/2022 07:11:29 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.93 on epoch=119
05/21/2022 07:11:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.94 on epoch=119
05/21/2022 07:11:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.95 on epoch=120
05/21/2022 07:11:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.90 on epoch=121
05/21/2022 07:11:36 - INFO - __main__ - Global step 1700 Train loss 0.94 Classification-F1 0.3589553836125061 on epoch=121
05/21/2022 07:11:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.93 on epoch=122
05/21/2022 07:11:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.92 on epoch=122
05/21/2022 07:11:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.94 on epoch=123
05/21/2022 07:11:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.96 on epoch=124
05/21/2022 07:11:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.97 on epoch=124
05/21/2022 07:11:46 - INFO - __main__ - Global step 1750 Train loss 0.94 Classification-F1 0.38650011996489697 on epoch=124
05/21/2022 07:11:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.90 on epoch=125
05/21/2022 07:11:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.96 on epoch=126
05/21/2022 07:11:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.94 on epoch=127
05/21/2022 07:11:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.89 on epoch=127
05/21/2022 07:11:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.94 on epoch=128
05/21/2022 07:11:56 - INFO - __main__ - Global step 1800 Train loss 0.93 Classification-F1 0.4448951395646479 on epoch=128
05/21/2022 07:11:56 - INFO - __main__ - Saving model with best Classification-F1: 0.40042318597145965 -> 0.4448951395646479 on epoch=128, global_step=1800
05/21/2022 07:11:57 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.87 on epoch=129
05/21/2022 07:11:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.91 on epoch=129
05/21/2022 07:12:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.94 on epoch=130
05/21/2022 07:12:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.93 on epoch=131
05/21/2022 07:12:02 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.90 on epoch=132
05/21/2022 07:12:06 - INFO - __main__ - Global step 1850 Train loss 0.91 Classification-F1 0.3529172826035289 on epoch=132
05/21/2022 07:12:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.95 on epoch=132
05/21/2022 07:12:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.91 on epoch=133
05/21/2022 07:12:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.90 on epoch=134
05/21/2022 07:12:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.89 on epoch=134
05/21/2022 07:12:12 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.86 on epoch=135
05/21/2022 07:12:16 - INFO - __main__ - Global step 1900 Train loss 0.90 Classification-F1 0.4214078358246112 on epoch=135
05/21/2022 07:12:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.89 on epoch=136
05/21/2022 07:12:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.95 on epoch=137
05/21/2022 07:12:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.89 on epoch=137
05/21/2022 07:12:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.91 on epoch=138
05/21/2022 07:12:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.89 on epoch=139
05/21/2022 07:12:26 - INFO - __main__ - Global step 1950 Train loss 0.90 Classification-F1 0.4092242837347885 on epoch=139
05/21/2022 07:12:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.88 on epoch=139
05/21/2022 07:12:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.94 on epoch=140
05/21/2022 07:12:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.88 on epoch=141
05/21/2022 07:12:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.85 on epoch=142
05/21/2022 07:12:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.90 on epoch=142
05/21/2022 07:12:36 - INFO - __main__ - Global step 2000 Train loss 0.89 Classification-F1 0.46606218974640024 on epoch=142
05/21/2022 07:12:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4448951395646479 -> 0.46606218974640024 on epoch=142, global_step=2000
05/21/2022 07:12:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.77 on epoch=143
05/21/2022 07:12:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.84 on epoch=144
05/21/2022 07:12:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.89 on epoch=144
05/21/2022 07:12:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.82 on epoch=145
05/21/2022 07:12:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.84 on epoch=146
05/21/2022 07:12:46 - INFO - __main__ - Global step 2050 Train loss 0.83 Classification-F1 0.4580743754507347 on epoch=146
05/21/2022 07:12:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.79 on epoch=147
05/21/2022 07:12:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.86 on epoch=147
05/21/2022 07:12:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.74 on epoch=148
05/21/2022 07:12:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.86 on epoch=149
05/21/2022 07:12:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.79 on epoch=149
05/21/2022 07:12:56 - INFO - __main__ - Global step 2100 Train loss 0.81 Classification-F1 0.4861286218604532 on epoch=149
05/21/2022 07:12:56 - INFO - __main__ - Saving model with best Classification-F1: 0.46606218974640024 -> 0.4861286218604532 on epoch=149, global_step=2100
05/21/2022 07:12:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.75 on epoch=150
05/21/2022 07:12:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.89 on epoch=151
05/21/2022 07:13:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.86 on epoch=152
05/21/2022 07:13:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.75 on epoch=152
05/21/2022 07:13:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.72 on epoch=153
05/21/2022 07:13:06 - INFO - __main__ - Global step 2150 Train loss 0.80 Classification-F1 0.5860190904529009 on epoch=153
05/21/2022 07:13:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4861286218604532 -> 0.5860190904529009 on epoch=153, global_step=2150
05/21/2022 07:13:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.73 on epoch=154
05/21/2022 07:13:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.72 on epoch=154
05/21/2022 07:13:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.72 on epoch=155
05/21/2022 07:13:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.79 on epoch=156
05/21/2022 07:13:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.81 on epoch=157
05/21/2022 07:13:16 - INFO - __main__ - Global step 2200 Train loss 0.76 Classification-F1 0.476107576930033 on epoch=157
05/21/2022 07:13:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.81 on epoch=157
05/21/2022 07:13:19 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.76 on epoch=158
05/21/2022 07:13:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.79 on epoch=159
05/21/2022 07:13:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.77 on epoch=159
05/21/2022 07:13:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.72 on epoch=160
05/21/2022 07:13:26 - INFO - __main__ - Global step 2250 Train loss 0.77 Classification-F1 0.5202854285352209 on epoch=160
05/21/2022 07:13:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.76 on epoch=161
05/21/2022 07:13:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.83 on epoch=162
05/21/2022 07:13:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.70 on epoch=162
05/21/2022 07:13:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.81 on epoch=163
05/21/2022 07:13:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.74 on epoch=164
05/21/2022 07:13:36 - INFO - __main__ - Global step 2300 Train loss 0.77 Classification-F1 0.5037744445567344 on epoch=164
05/21/2022 07:13:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.73 on epoch=164
05/21/2022 07:13:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.73 on epoch=165
05/21/2022 07:13:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.76 on epoch=166
05/21/2022 07:13:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.74 on epoch=167
05/21/2022 07:13:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.70 on epoch=167
05/21/2022 07:13:46 - INFO - __main__ - Global step 2350 Train loss 0.73 Classification-F1 0.49828951435561625 on epoch=167
05/21/2022 07:13:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.70 on epoch=168
05/21/2022 07:13:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.75 on epoch=169
05/21/2022 07:13:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.70 on epoch=169
05/21/2022 07:13:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.80 on epoch=170
05/21/2022 07:13:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.72 on epoch=171
05/21/2022 07:13:57 - INFO - __main__ - Global step 2400 Train loss 0.73 Classification-F1 0.598816013291626 on epoch=171
05/21/2022 07:13:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5860190904529009 -> 0.598816013291626 on epoch=171, global_step=2400
05/21/2022 07:13:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.75 on epoch=172
05/21/2022 07:13:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.70 on epoch=172
05/21/2022 07:14:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.72 on epoch=173
05/21/2022 07:14:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.73 on epoch=174
05/21/2022 07:14:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.71 on epoch=174
05/21/2022 07:14:07 - INFO - __main__ - Global step 2450 Train loss 0.72 Classification-F1 0.5893520678947957 on epoch=174
05/21/2022 07:14:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.58 on epoch=175
05/21/2022 07:14:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.74 on epoch=176
05/21/2022 07:14:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.68 on epoch=177
05/21/2022 07:14:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.81 on epoch=177
05/21/2022 07:14:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.80 on epoch=178
05/21/2022 07:14:17 - INFO - __main__ - Global step 2500 Train loss 0.72 Classification-F1 0.6349946706553868 on epoch=178
05/21/2022 07:14:17 - INFO - __main__ - Saving model with best Classification-F1: 0.598816013291626 -> 0.6349946706553868 on epoch=178, global_step=2500
05/21/2022 07:14:18 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.71 on epoch=179
05/21/2022 07:14:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.72 on epoch=179
05/21/2022 07:14:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.67 on epoch=180
05/21/2022 07:14:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.67 on epoch=181
05/21/2022 07:14:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.65 on epoch=182
05/21/2022 07:14:27 - INFO - __main__ - Global step 2550 Train loss 0.69 Classification-F1 0.5581696493248975 on epoch=182
05/21/2022 07:14:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.64 on epoch=182
05/21/2022 07:14:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.71 on epoch=183
05/21/2022 07:14:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.64 on epoch=184
05/21/2022 07:14:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.68 on epoch=184
05/21/2022 07:14:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.72 on epoch=185
05/21/2022 07:14:38 - INFO - __main__ - Global step 2600 Train loss 0.68 Classification-F1 0.6163699205961763 on epoch=185
05/21/2022 07:14:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.60 on epoch=186
05/21/2022 07:14:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.66 on epoch=187
05/21/2022 07:14:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.58 on epoch=187
05/21/2022 07:14:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.62 on epoch=188
05/21/2022 07:14:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.72 on epoch=189
05/21/2022 07:14:48 - INFO - __main__ - Global step 2650 Train loss 0.64 Classification-F1 0.5371730456213174 on epoch=189
05/21/2022 07:14:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.66 on epoch=189
05/21/2022 07:14:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.62 on epoch=190
05/21/2022 07:14:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.72 on epoch=191
05/21/2022 07:14:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.63 on epoch=192
05/21/2022 07:14:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.57 on epoch=192
05/21/2022 07:14:58 - INFO - __main__ - Global step 2700 Train loss 0.64 Classification-F1 0.6710159704729729 on epoch=192
05/21/2022 07:14:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6349946706553868 -> 0.6710159704729729 on epoch=192, global_step=2700
05/21/2022 07:14:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.57 on epoch=193
05/21/2022 07:15:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.62 on epoch=194
05/21/2022 07:15:02 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.63 on epoch=194
05/21/2022 07:15:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.69 on epoch=195
05/21/2022 07:15:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.61 on epoch=196
05/21/2022 07:15:08 - INFO - __main__ - Global step 2750 Train loss 0.63 Classification-F1 0.6251866270983918 on epoch=196
05/21/2022 07:15:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.63 on epoch=197
05/21/2022 07:15:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.61 on epoch=197
05/21/2022 07:15:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.64 on epoch=198
05/21/2022 07:15:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.69 on epoch=199
05/21/2022 07:15:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.52 on epoch=199
05/21/2022 07:15:18 - INFO - __main__ - Global step 2800 Train loss 0.62 Classification-F1 0.574254708410971 on epoch=199
05/21/2022 07:15:19 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.65 on epoch=200
05/21/2022 07:15:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.70 on epoch=201
05/21/2022 07:15:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.72 on epoch=202
05/21/2022 07:15:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.61 on epoch=202
05/21/2022 07:15:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.62 on epoch=203
05/21/2022 07:15:28 - INFO - __main__ - Global step 2850 Train loss 0.66 Classification-F1 0.612535760926478 on epoch=203
05/21/2022 07:15:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.58 on epoch=204
05/21/2022 07:15:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.63 on epoch=204
05/21/2022 07:15:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.61 on epoch=205
05/21/2022 07:15:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.65 on epoch=206
05/21/2022 07:15:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.59 on epoch=207
05/21/2022 07:15:38 - INFO - __main__ - Global step 2900 Train loss 0.61 Classification-F1 0.5208521246696618 on epoch=207
05/21/2022 07:15:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.54 on epoch=207
05/21/2022 07:15:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.68 on epoch=208
05/21/2022 07:15:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.63 on epoch=209
05/21/2022 07:15:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.68 on epoch=209
05/21/2022 07:15:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.66 on epoch=210
05/21/2022 07:15:49 - INFO - __main__ - Global step 2950 Train loss 0.64 Classification-F1 0.5399057975094226 on epoch=210
05/21/2022 07:15:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.63 on epoch=211
05/21/2022 07:15:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.63 on epoch=212
05/21/2022 07:15:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.62 on epoch=212
05/21/2022 07:15:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.57 on epoch=213
05/21/2022 07:15:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.58 on epoch=214
05/21/2022 07:15:56 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:15:56 - INFO - __main__ - Printing 3 examples
05/21/2022 07:15:56 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 07:15:56 - INFO - __main__ - ['Film']
05/21/2022 07:15:56 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 07:15:56 - INFO - __main__ - ['Film']
05/21/2022 07:15:56 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 07:15:56 - INFO - __main__ - ['Film']
05/21/2022 07:15:56 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:15:56 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:15:57 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 07:15:57 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:15:57 - INFO - __main__ - Printing 3 examples
05/21/2022 07:15:57 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 07:15:57 - INFO - __main__ - ['Film']
05/21/2022 07:15:57 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 07:15:57 - INFO - __main__ - ['Film']
05/21/2022 07:15:57 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 07:15:57 - INFO - __main__ - ['Film']
05/21/2022 07:15:57 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:15:57 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:15:57 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 07:15:59 - INFO - __main__ - Global step 3000 Train loss 0.61 Classification-F1 0.5181899906104177 on epoch=214
05/21/2022 07:15:59 - INFO - __main__ - save last model!
05/21/2022 07:15:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 07:15:59 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 07:15:59 - INFO - __main__ - Printing 3 examples
05/21/2022 07:15:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 07:15:59 - INFO - __main__ - ['Animal']
05/21/2022 07:15:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 07:15:59 - INFO - __main__ - ['Animal']
05/21/2022 07:15:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 07:15:59 - INFO - __main__ - ['Village']
05/21/2022 07:15:59 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:16:01 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:16:02 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 07:16:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 07:16:03 - INFO - __main__ - Starting training!
05/21/2022 07:16:04 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 07:17:12 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
05/21/2022 07:17:12 - INFO - __main__ - Classification-F1 on test data: 0.1677
05/21/2022 07:17:12 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.6710159704729729, test_performance=0.16766593739159386
05/21/2022 07:17:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
05/21/2022 07:17:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:17:13 - INFO - __main__ - Printing 3 examples
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Aib The Movie ( -- ! 42.195km ) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aib.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shjo ( lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:17:13 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:17:13 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 07:17:13 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 07:17:13 - INFO - __main__ - Printing 3 examples
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres  Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres  Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between Franois a French actor and Kay an American woman.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
05/21/2022 07:17:13 - INFO - __main__ - ['Film']
05/21/2022 07:17:13 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:17:13 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:17:14 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 07:17:19 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 07:17:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 236.18M parameters
05/21/2022 07:17:19 - INFO - __main__ - Starting training!
05/21/2022 07:17:21 - INFO - __main__ - Step 10 Global step 10 Train loss 7.51 on epoch=0
05/21/2022 07:17:23 - INFO - __main__ - Step 20 Global step 20 Train loss 7.22 on epoch=1
05/21/2022 07:17:24 - INFO - __main__ - Step 30 Global step 30 Train loss 6.83 on epoch=2
05/21/2022 07:17:25 - INFO - __main__ - Step 40 Global step 40 Train loss 6.55 on epoch=2
05/21/2022 07:17:26 - INFO - __main__ - Step 50 Global step 50 Train loss 6.27 on epoch=3
05/21/2022 07:17:29 - INFO - __main__ - Global step 50 Train loss 6.88 Classification-F1 0.0 on epoch=3
05/21/2022 07:17:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=3, global_step=50
05/21/2022 07:17:31 - INFO - __main__ - Step 60 Global step 60 Train loss 5.98 on epoch=4
05/21/2022 07:17:32 - INFO - __main__ - Step 70 Global step 70 Train loss 5.81 on epoch=4
05/21/2022 07:17:33 - INFO - __main__ - Step 80 Global step 80 Train loss 5.51 on epoch=5
05/21/2022 07:17:34 - INFO - __main__ - Step 90 Global step 90 Train loss 5.45 on epoch=6
05/21/2022 07:17:35 - INFO - __main__ - Step 100 Global step 100 Train loss 5.13 on epoch=7
05/21/2022 07:17:39 - INFO - __main__ - Global step 100 Train loss 5.58 Classification-F1 0.0 on epoch=7
05/21/2022 07:17:40 - INFO - __main__ - Step 110 Global step 110 Train loss 4.81 on epoch=7
05/21/2022 07:17:41 - INFO - __main__ - Step 120 Global step 120 Train loss 4.85 on epoch=8
05/21/2022 07:17:42 - INFO - __main__ - Step 130 Global step 130 Train loss 4.65 on epoch=9
05/21/2022 07:17:43 - INFO - __main__ - Step 140 Global step 140 Train loss 4.69 on epoch=9
05/21/2022 07:17:45 - INFO - __main__ - Step 150 Global step 150 Train loss 4.38 on epoch=10
05/21/2022 07:17:48 - INFO - __main__ - Global step 150 Train loss 4.67 Classification-F1 0.0 on epoch=10
05/21/2022 07:17:49 - INFO - __main__ - Step 160 Global step 160 Train loss 4.46 on epoch=11
05/21/2022 07:17:50 - INFO - __main__ - Step 170 Global step 170 Train loss 4.13 on epoch=12
05/21/2022 07:17:51 - INFO - __main__ - Step 180 Global step 180 Train loss 4.05 on epoch=12
05/21/2022 07:17:53 - INFO - __main__ - Step 190 Global step 190 Train loss 4.04 on epoch=13
05/21/2022 07:17:54 - INFO - __main__ - Step 200 Global step 200 Train loss 3.66 on epoch=14
05/21/2022 07:17:57 - INFO - __main__ - Global step 200 Train loss 4.07 Classification-F1 0.0 on epoch=14
05/21/2022 07:17:58 - INFO - __main__ - Step 210 Global step 210 Train loss 3.89 on epoch=14
05/21/2022 07:17:59 - INFO - __main__ - Step 220 Global step 220 Train loss 3.61 on epoch=15
05/21/2022 07:18:01 - INFO - __main__ - Step 230 Global step 230 Train loss 3.71 on epoch=16
05/21/2022 07:18:02 - INFO - __main__ - Step 240 Global step 240 Train loss 3.58 on epoch=17
05/21/2022 07:18:03 - INFO - __main__ - Step 250 Global step 250 Train loss 3.44 on epoch=17
05/21/2022 07:18:06 - INFO - __main__ - Global step 250 Train loss 3.64 Classification-F1 0.0 on epoch=17
05/21/2022 07:18:07 - INFO - __main__ - Step 260 Global step 260 Train loss 3.43 on epoch=18
05/21/2022 07:18:08 - INFO - __main__ - Step 270 Global step 270 Train loss 3.35 on epoch=19
05/21/2022 07:18:09 - INFO - __main__ - Step 280 Global step 280 Train loss 3.22 on epoch=19
05/21/2022 07:18:11 - INFO - __main__ - Step 290 Global step 290 Train loss 3.15 on epoch=20
05/21/2022 07:18:12 - INFO - __main__ - Step 300 Global step 300 Train loss 3.24 on epoch=21
05/21/2022 07:18:14 - INFO - __main__ - Global step 300 Train loss 3.28 Classification-F1 0.0035398230088495575 on epoch=21
05/21/2022 07:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.0035398230088495575 on epoch=21, global_step=300
05/21/2022 07:18:16 - INFO - __main__ - Step 310 Global step 310 Train loss 3.03 on epoch=22
05/21/2022 07:18:17 - INFO - __main__ - Step 320 Global step 320 Train loss 2.94 on epoch=22
05/21/2022 07:18:18 - INFO - __main__ - Step 330 Global step 330 Train loss 2.96 on epoch=23
05/21/2022 07:18:19 - INFO - __main__ - Step 340 Global step 340 Train loss 2.78 on epoch=24
05/21/2022 07:18:21 - INFO - __main__ - Step 350 Global step 350 Train loss 2.85 on epoch=24
05/21/2022 07:18:23 - INFO - __main__ - Global step 350 Train loss 2.91 Classification-F1 0.007246376811594203 on epoch=24
05/21/2022 07:18:23 - INFO - __main__ - Saving model with best Classification-F1: 0.0035398230088495575 -> 0.007246376811594203 on epoch=24, global_step=350
05/21/2022 07:18:24 - INFO - __main__ - Step 360 Global step 360 Train loss 2.72 on epoch=25
05/21/2022 07:18:25 - INFO - __main__ - Step 370 Global step 370 Train loss 2.73 on epoch=26
05/21/2022 07:18:27 - INFO - __main__ - Step 380 Global step 380 Train loss 2.65 on epoch=27
05/21/2022 07:18:28 - INFO - __main__ - Step 390 Global step 390 Train loss 2.61 on epoch=27
05/21/2022 07:18:29 - INFO - __main__ - Step 400 Global step 400 Train loss 2.59 on epoch=28
05/21/2022 07:18:31 - INFO - __main__ - Global step 400 Train loss 2.66 Classification-F1 0.008849557522123895 on epoch=28
05/21/2022 07:18:31 - INFO - __main__ - Saving model with best Classification-F1: 0.007246376811594203 -> 0.008849557522123895 on epoch=28, global_step=400
05/21/2022 07:18:33 - INFO - __main__ - Step 410 Global step 410 Train loss 2.53 on epoch=29
05/21/2022 07:18:34 - INFO - __main__ - Step 420 Global step 420 Train loss 2.56 on epoch=29
05/21/2022 07:18:35 - INFO - __main__ - Step 430 Global step 430 Train loss 2.44 on epoch=30
05/21/2022 07:18:36 - INFO - __main__ - Step 440 Global step 440 Train loss 2.51 on epoch=31
05/21/2022 07:18:38 - INFO - __main__ - Step 450 Global step 450 Train loss 2.36 on epoch=32
05/21/2022 07:18:39 - INFO - __main__ - Global step 450 Train loss 2.48 Classification-F1 0.009523809523809523 on epoch=32
05/21/2022 07:18:39 - INFO - __main__ - Saving model with best Classification-F1: 0.008849557522123895 -> 0.009523809523809523 on epoch=32, global_step=450
05/21/2022 07:18:41 - INFO - __main__ - Step 460 Global step 460 Train loss 2.36 on epoch=32
05/21/2022 07:18:42 - INFO - __main__ - Step 470 Global step 470 Train loss 2.29 on epoch=33
05/21/2022 07:18:43 - INFO - __main__ - Step 480 Global step 480 Train loss 2.19 on epoch=34
05/21/2022 07:18:44 - INFO - __main__ - Step 490 Global step 490 Train loss 2.19 on epoch=34
05/21/2022 07:18:46 - INFO - __main__ - Step 500 Global step 500 Train loss 2.08 on epoch=35
05/21/2022 07:18:48 - INFO - __main__ - Global step 500 Train loss 2.22 Classification-F1 0.009523809523809523 on epoch=35
05/21/2022 07:18:49 - INFO - __main__ - Step 510 Global step 510 Train loss 2.21 on epoch=36
05/21/2022 07:18:50 - INFO - __main__ - Step 520 Global step 520 Train loss 2.06 on epoch=37
05/21/2022 07:18:51 - INFO - __main__ - Step 530 Global step 530 Train loss 2.14 on epoch=37
05/21/2022 07:18:53 - INFO - __main__ - Step 540 Global step 540 Train loss 2.05 on epoch=38
05/21/2022 07:18:54 - INFO - __main__ - Step 550 Global step 550 Train loss 1.94 on epoch=39
05/21/2022 07:18:56 - INFO - __main__ - Global step 550 Train loss 2.08 Classification-F1 0.023599577762139338 on epoch=39
05/21/2022 07:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.009523809523809523 -> 0.023599577762139338 on epoch=39, global_step=550
05/21/2022 07:18:57 - INFO - __main__ - Step 560 Global step 560 Train loss 2.09 on epoch=39
05/21/2022 07:18:58 - INFO - __main__ - Step 570 Global step 570 Train loss 1.89 on epoch=40
05/21/2022 07:18:59 - INFO - __main__ - Step 580 Global step 580 Train loss 2.09 on epoch=41
05/21/2022 07:19:01 - INFO - __main__ - Step 590 Global step 590 Train loss 1.92 on epoch=42
05/21/2022 07:19:02 - INFO - __main__ - Step 600 Global step 600 Train loss 1.97 on epoch=42
05/21/2022 07:19:04 - INFO - __main__ - Global step 600 Train loss 1.99 Classification-F1 0.01793847011804071 on epoch=42
05/21/2022 07:19:05 - INFO - __main__ - Step 610 Global step 610 Train loss 1.86 on epoch=43
05/21/2022 07:19:06 - INFO - __main__ - Step 620 Global step 620 Train loss 1.85 on epoch=44
05/21/2022 07:19:07 - INFO - __main__ - Step 630 Global step 630 Train loss 1.85 on epoch=44
05/21/2022 07:19:09 - INFO - __main__ - Step 640 Global step 640 Train loss 1.79 on epoch=45
05/21/2022 07:19:10 - INFO - __main__ - Step 650 Global step 650 Train loss 1.80 on epoch=46
05/21/2022 07:19:12 - INFO - __main__ - Global step 650 Train loss 1.83 Classification-F1 0.016573159430302287 on epoch=46
05/21/2022 07:19:13 - INFO - __main__ - Step 660 Global step 660 Train loss 1.77 on epoch=47
05/21/2022 07:19:14 - INFO - __main__ - Step 670 Global step 670 Train loss 1.72 on epoch=47
05/21/2022 07:19:15 - INFO - __main__ - Step 680 Global step 680 Train loss 1.72 on epoch=48
05/21/2022 07:19:17 - INFO - __main__ - Step 690 Global step 690 Train loss 1.74 on epoch=49
05/21/2022 07:19:18 - INFO - __main__ - Step 700 Global step 700 Train loss 1.84 on epoch=49
05/21/2022 07:19:20 - INFO - __main__ - Global step 700 Train loss 1.76 Classification-F1 0.03067956349206349 on epoch=49
05/21/2022 07:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.023599577762139338 -> 0.03067956349206349 on epoch=49, global_step=700
05/21/2022 07:19:21 - INFO - __main__ - Step 710 Global step 710 Train loss 1.67 on epoch=50
05/21/2022 07:19:22 - INFO - __main__ - Step 720 Global step 720 Train loss 1.81 on epoch=51
05/21/2022 07:19:23 - INFO - __main__ - Step 730 Global step 730 Train loss 1.63 on epoch=52
05/21/2022 07:19:25 - INFO - __main__ - Step 740 Global step 740 Train loss 1.76 on epoch=52
05/21/2022 07:19:26 - INFO - __main__ - Step 750 Global step 750 Train loss 1.53 on epoch=53
05/21/2022 07:19:28 - INFO - __main__ - Global step 750 Train loss 1.68 Classification-F1 0.018032069970845478 on epoch=53
05/21/2022 07:19:29 - INFO - __main__ - Step 760 Global step 760 Train loss 1.64 on epoch=54
05/21/2022 07:19:31 - INFO - __main__ - Step 770 Global step 770 Train loss 1.77 on epoch=54
05/21/2022 07:19:32 - INFO - __main__ - Step 780 Global step 780 Train loss 1.56 on epoch=55
05/21/2022 07:19:33 - INFO - __main__ - Step 790 Global step 790 Train loss 1.61 on epoch=56
05/21/2022 07:19:34 - INFO - __main__ - Step 800 Global step 800 Train loss 1.55 on epoch=57
05/21/2022 07:19:36 - INFO - __main__ - Global step 800 Train loss 1.63 Classification-F1 0.02225726654298083 on epoch=57
05/21/2022 07:19:38 - INFO - __main__ - Step 810 Global step 810 Train loss 1.59 on epoch=57
05/21/2022 07:19:39 - INFO - __main__ - Step 820 Global step 820 Train loss 1.46 on epoch=58
05/21/2022 07:19:40 - INFO - __main__ - Step 830 Global step 830 Train loss 1.55 on epoch=59
05/21/2022 07:19:41 - INFO - __main__ - Step 840 Global step 840 Train loss 1.57 on epoch=59
05/21/2022 07:19:42 - INFO - __main__ - Step 850 Global step 850 Train loss 1.40 on epoch=60
05/21/2022 07:19:45 - INFO - __main__ - Global step 850 Train loss 1.51 Classification-F1 0.014767025089605737 on epoch=60
05/21/2022 07:19:46 - INFO - __main__ - Step 860 Global step 860 Train loss 1.50 on epoch=61
05/21/2022 07:19:47 - INFO - __main__ - Step 870 Global step 870 Train loss 1.47 on epoch=62
05/21/2022 07:19:49 - INFO - __main__ - Step 880 Global step 880 Train loss 1.47 on epoch=62
05/21/2022 07:19:50 - INFO - __main__ - Step 890 Global step 890 Train loss 1.45 on epoch=63
05/21/2022 07:19:51 - INFO - __main__ - Step 900 Global step 900 Train loss 1.42 on epoch=64
05/21/2022 07:19:53 - INFO - __main__ - Global step 900 Train loss 1.46 Classification-F1 0.017969687875150058 on epoch=64
05/21/2022 07:19:54 - INFO - __main__ - Step 910 Global step 910 Train loss 1.56 on epoch=64
05/21/2022 07:19:56 - INFO - __main__ - Step 920 Global step 920 Train loss 1.40 on epoch=65
05/21/2022 07:19:57 - INFO - __main__ - Step 930 Global step 930 Train loss 1.45 on epoch=66
05/21/2022 07:19:58 - INFO - __main__ - Step 940 Global step 940 Train loss 1.48 on epoch=67
05/21/2022 07:19:59 - INFO - __main__ - Step 950 Global step 950 Train loss 1.41 on epoch=67
05/21/2022 07:20:02 - INFO - __main__ - Global step 950 Train loss 1.46 Classification-F1 0.04792123861973869 on epoch=67
05/21/2022 07:20:02 - INFO - __main__ - Saving model with best Classification-F1: 0.03067956349206349 -> 0.04792123861973869 on epoch=67, global_step=950
05/21/2022 07:20:03 - INFO - __main__ - Step 960 Global step 960 Train loss 1.38 on epoch=68
05/21/2022 07:20:05 - INFO - __main__ - Step 970 Global step 970 Train loss 1.45 on epoch=69
05/21/2022 07:20:06 - INFO - __main__ - Step 980 Global step 980 Train loss 1.45 on epoch=69
05/21/2022 07:20:07 - INFO - __main__ - Step 990 Global step 990 Train loss 1.39 on epoch=70
05/21/2022 07:20:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 1.37 on epoch=71
05/21/2022 07:20:11 - INFO - __main__ - Global step 1000 Train loss 1.41 Classification-F1 0.04939476108307277 on epoch=71
05/21/2022 07:20:11 - INFO - __main__ - Saving model with best Classification-F1: 0.04792123861973869 -> 0.04939476108307277 on epoch=71, global_step=1000
05/21/2022 07:20:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 1.33 on epoch=72
05/21/2022 07:20:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 1.44 on epoch=72
05/21/2022 07:20:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 1.34 on epoch=73
05/21/2022 07:20:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 1.40 on epoch=74
05/21/2022 07:20:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 1.43 on epoch=74
05/21/2022 07:20:20 - INFO - __main__ - Global step 1050 Train loss 1.39 Classification-F1 0.04803276025050218 on epoch=74
05/21/2022 07:20:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 1.31 on epoch=75
05/21/2022 07:20:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 1.44 on epoch=76
05/21/2022 07:20:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 1.38 on epoch=77
05/21/2022 07:20:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 1.35 on epoch=77
05/21/2022 07:20:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 1.29 on epoch=78
05/21/2022 07:20:29 - INFO - __main__ - Global step 1100 Train loss 1.36 Classification-F1 0.05794213277951318 on epoch=78
05/21/2022 07:20:29 - INFO - __main__ - Saving model with best Classification-F1: 0.04939476108307277 -> 0.05794213277951318 on epoch=78, global_step=1100
05/21/2022 07:20:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 1.36 on epoch=79
05/21/2022 07:20:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 1.31 on epoch=79
05/21/2022 07:20:33 - INFO - __main__ - Step 1130 Global step 1130 Train loss 1.32 on epoch=80
05/21/2022 07:20:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 1.32 on epoch=81
05/21/2022 07:20:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 1.25 on epoch=82
05/21/2022 07:20:38 - INFO - __main__ - Global step 1150 Train loss 1.31 Classification-F1 0.0499343256511021 on epoch=82
05/21/2022 07:20:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 1.42 on epoch=82
05/21/2022 07:20:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 1.31 on epoch=83
05/21/2022 07:20:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 1.21 on epoch=84
05/21/2022 07:20:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 1.28 on epoch=84
05/21/2022 07:20:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 1.18 on epoch=85
05/21/2022 07:20:46 - INFO - __main__ - Global step 1200 Train loss 1.28 Classification-F1 0.04756870136893395 on epoch=85
05/21/2022 07:20:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 1.27 on epoch=86
05/21/2022 07:20:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 1.27 on epoch=87
05/21/2022 07:20:50 - INFO - __main__ - Step 1230 Global step 1230 Train loss 1.26 on epoch=87
05/21/2022 07:20:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 1.24 on epoch=88
05/21/2022 07:20:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 1.32 on epoch=89
05/21/2022 07:20:55 - INFO - __main__ - Global step 1250 Train loss 1.27 Classification-F1 0.06915534078324777 on epoch=89
05/21/2022 07:20:55 - INFO - __main__ - Saving model with best Classification-F1: 0.05794213277951318 -> 0.06915534078324777 on epoch=89, global_step=1250
05/21/2022 07:20:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 1.34 on epoch=89
05/21/2022 07:20:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 1.20 on epoch=90
05/21/2022 07:20:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 1.25 on epoch=91
05/21/2022 07:21:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 1.27 on epoch=92
05/21/2022 07:21:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 1.27 on epoch=92
05/21/2022 07:21:04 - INFO - __main__ - Global step 1300 Train loss 1.27 Classification-F1 0.05924928960982092 on epoch=92
05/21/2022 07:21:06 - INFO - __main__ - Step 1310 Global step 1310 Train loss 1.22 on epoch=93
05/21/2022 07:21:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 1.25 on epoch=94
05/21/2022 07:21:08 - INFO - __main__ - Step 1330 Global step 1330 Train loss 1.26 on epoch=94
05/21/2022 07:21:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 1.10 on epoch=95
05/21/2022 07:21:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 1.33 on epoch=96
05/21/2022 07:21:13 - INFO - __main__ - Global step 1350 Train loss 1.23 Classification-F1 0.08458773777922714 on epoch=96
05/21/2022 07:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.06915534078324777 -> 0.08458773777922714 on epoch=96, global_step=1350
05/21/2022 07:21:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 1.22 on epoch=97
05/21/2022 07:21:15 - INFO - __main__ - Step 1370 Global step 1370 Train loss 1.34 on epoch=97
05/21/2022 07:21:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 1.20 on epoch=98
05/21/2022 07:21:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 1.29 on epoch=99
05/21/2022 07:21:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 1.14 on epoch=99
05/21/2022 07:21:21 - INFO - __main__ - Global step 1400 Train loss 1.24 Classification-F1 0.0685863675720869 on epoch=99
05/21/2022 07:21:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 1.21 on epoch=100
05/21/2022 07:21:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 1.25 on epoch=101
05/21/2022 07:21:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 1.16 on epoch=102
05/21/2022 07:21:26 - INFO - __main__ - Step 1440 Global step 1440 Train loss 1.30 on epoch=102
05/21/2022 07:21:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 1.17 on epoch=103
05/21/2022 07:21:30 - INFO - __main__ - Global step 1450 Train loss 1.22 Classification-F1 0.04411696518919155 on epoch=103
05/21/2022 07:21:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 1.22 on epoch=104
05/21/2022 07:21:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 1.26 on epoch=104
05/21/2022 07:21:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 1.11 on epoch=105
05/21/2022 07:21:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 1.22 on epoch=106
05/21/2022 07:21:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 1.16 on epoch=107
05/21/2022 07:21:39 - INFO - __main__ - Global step 1500 Train loss 1.19 Classification-F1 0.07713626989595815 on epoch=107
05/21/2022 07:21:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 1.23 on epoch=107
05/21/2022 07:21:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 1.24 on epoch=108
05/21/2022 07:21:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 1.18 on epoch=109
05/21/2022 07:21:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 1.22 on epoch=109
05/21/2022 07:21:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 1.21 on epoch=110
05/21/2022 07:21:48 - INFO - __main__ - Global step 1550 Train loss 1.22 Classification-F1 0.11540874584352845 on epoch=110
05/21/2022 07:21:48 - INFO - __main__ - Saving model with best Classification-F1: 0.08458773777922714 -> 0.11540874584352845 on epoch=110, global_step=1550
05/21/2022 07:21:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 1.20 on epoch=111
05/21/2022 07:21:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 1.16 on epoch=112
05/21/2022 07:21:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 1.22 on epoch=112
05/21/2022 07:21:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 1.16 on epoch=113
05/21/2022 07:21:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 1.13 on epoch=114
05/21/2022 07:21:56 - INFO - __main__ - Global step 1600 Train loss 1.18 Classification-F1 0.11527548082169933 on epoch=114
05/21/2022 07:21:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 1.19 on epoch=114
05/21/2022 07:21:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 1.14 on epoch=115
05/21/2022 07:22:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 1.17 on epoch=116
05/21/2022 07:22:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 1.20 on epoch=117
05/21/2022 07:22:03 - INFO - __main__ - Step 1650 Global step 1650 Train loss 1.25 on epoch=117
05/21/2022 07:22:05 - INFO - __main__ - Global step 1650 Train loss 1.19 Classification-F1 0.13881061059158104 on epoch=117
05/21/2022 07:22:05 - INFO - __main__ - Saving model with best Classification-F1: 0.11540874584352845 -> 0.13881061059158104 on epoch=117, global_step=1650
05/21/2022 07:22:07 - INFO - __main__ - Step 1660 Global step 1660 Train loss 1.16 on epoch=118
05/21/2022 07:22:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 1.13 on epoch=119
05/21/2022 07:22:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 1.19 on epoch=119
05/21/2022 07:22:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 1.02 on epoch=120
05/21/2022 07:22:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 1.18 on epoch=121
05/21/2022 07:22:14 - INFO - __main__ - Global step 1700 Train loss 1.14 Classification-F1 0.14096341239198382 on epoch=121
05/21/2022 07:22:14 - INFO - __main__ - Saving model with best Classification-F1: 0.13881061059158104 -> 0.14096341239198382 on epoch=121, global_step=1700
05/21/2022 07:22:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 1.16 on epoch=122
05/21/2022 07:22:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 1.14 on epoch=122
05/21/2022 07:22:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 1.19 on epoch=123
05/21/2022 07:22:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 1.18 on epoch=124
05/21/2022 07:22:21 - INFO - __main__ - Step 1750 Global step 1750 Train loss 1.26 on epoch=124
05/21/2022 07:22:23 - INFO - __main__ - Global step 1750 Train loss 1.19 Classification-F1 0.16674048691517346 on epoch=124
05/21/2022 07:22:23 - INFO - __main__ - Saving model with best Classification-F1: 0.14096341239198382 -> 0.16674048691517346 on epoch=124, global_step=1750
05/21/2022 07:22:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 1.07 on epoch=125
05/21/2022 07:22:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 1.18 on epoch=126
05/21/2022 07:22:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 1.12 on epoch=127
05/21/2022 07:22:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 1.21 on epoch=127
05/21/2022 07:22:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 1.08 on epoch=128
05/21/2022 07:22:32 - INFO - __main__ - Global step 1800 Train loss 1.13 Classification-F1 0.16225704664983603 on epoch=128
05/21/2022 07:22:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 1.19 on epoch=129
05/21/2022 07:22:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 1.23 on epoch=129
05/21/2022 07:22:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 1.09 on epoch=130
05/21/2022 07:22:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 1.21 on epoch=131
05/21/2022 07:22:39 - INFO - __main__ - Step 1850 Global step 1850 Train loss 1.08 on epoch=132
05/21/2022 07:22:41 - INFO - __main__ - Global step 1850 Train loss 1.16 Classification-F1 0.14134748102139408 on epoch=132
05/21/2022 07:22:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 1.16 on epoch=132
05/21/2022 07:22:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 1.12 on epoch=133
05/21/2022 07:22:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 1.15 on epoch=134
05/21/2022 07:22:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 1.15 on epoch=134
05/21/2022 07:22:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 1.00 on epoch=135
05/21/2022 07:22:50 - INFO - __main__ - Global step 1900 Train loss 1.12 Classification-F1 0.2222517003742705 on epoch=135
05/21/2022 07:22:51 - INFO - __main__ - Saving model with best Classification-F1: 0.16674048691517346 -> 0.2222517003742705 on epoch=135, global_step=1900
05/21/2022 07:22:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 1.15 on epoch=136
05/21/2022 07:22:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 1.13 on epoch=137
05/21/2022 07:22:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 1.16 on epoch=137
05/21/2022 07:22:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 1.08 on epoch=138
05/21/2022 07:22:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 1.10 on epoch=139
05/21/2022 07:23:00 - INFO - __main__ - Global step 1950 Train loss 1.12 Classification-F1 0.24056229689712377 on epoch=139
05/21/2022 07:23:00 - INFO - __main__ - Saving model with best Classification-F1: 0.2222517003742705 -> 0.24056229689712377 on epoch=139, global_step=1950
05/21/2022 07:23:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 1.11 on epoch=139
05/21/2022 07:23:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.95 on epoch=140
05/21/2022 07:23:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 1.06 on epoch=141
05/21/2022 07:23:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 1.09 on epoch=142
05/21/2022 07:23:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 1.09 on epoch=142
05/21/2022 07:23:09 - INFO - __main__ - Global step 2000 Train loss 1.06 Classification-F1 0.19641073100925074 on epoch=142
05/21/2022 07:23:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 1.07 on epoch=143
05/21/2022 07:23:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 1.12 on epoch=144
05/21/2022 07:23:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 1.14 on epoch=144
05/21/2022 07:23:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 1.05 on epoch=145
05/21/2022 07:23:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 1.12 on epoch=146
05/21/2022 07:23:19 - INFO - __main__ - Global step 2050 Train loss 1.10 Classification-F1 0.2943865559866793 on epoch=146
05/21/2022 07:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.24056229689712377 -> 0.2943865559866793 on epoch=146, global_step=2050
05/21/2022 07:23:20 - INFO - __main__ - Step 2060 Global step 2060 Train loss 1.09 on epoch=147
05/21/2022 07:23:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 1.13 on epoch=147
05/21/2022 07:23:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 1.00 on epoch=148
05/21/2022 07:23:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 1.08 on epoch=149
05/21/2022 07:23:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 1.12 on epoch=149
05/21/2022 07:23:28 - INFO - __main__ - Global step 2100 Train loss 1.08 Classification-F1 0.26983418179367963 on epoch=149
05/21/2022 07:23:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 1.02 on epoch=150
05/21/2022 07:23:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 1.06 on epoch=151
05/21/2022 07:23:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 1.03 on epoch=152
05/21/2022 07:23:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 1.09 on epoch=152
05/21/2022 07:23:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 1.05 on epoch=153
05/21/2022 07:23:38 - INFO - __main__ - Global step 2150 Train loss 1.05 Classification-F1 0.2373113189565783 on epoch=153
05/21/2022 07:23:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 1.07 on epoch=154
05/21/2022 07:23:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 1.13 on epoch=154
05/21/2022 07:23:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 1.08 on epoch=155
05/21/2022 07:23:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 1.05 on epoch=156
05/21/2022 07:23:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 1.05 on epoch=157
05/21/2022 07:23:47 - INFO - __main__ - Global step 2200 Train loss 1.07 Classification-F1 0.2748616907286598 on epoch=157
05/21/2022 07:23:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 1.09 on epoch=157
05/21/2022 07:23:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 1.02 on epoch=158
05/21/2022 07:23:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 1.03 on epoch=159
05/21/2022 07:23:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 1.14 on epoch=159
05/21/2022 07:23:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.92 on epoch=160
05/21/2022 07:23:57 - INFO - __main__ - Global step 2250 Train loss 1.04 Classification-F1 0.3158445048094584 on epoch=160
05/21/2022 07:23:57 - INFO - __main__ - Saving model with best Classification-F1: 0.2943865559866793 -> 0.3158445048094584 on epoch=160, global_step=2250
05/21/2022 07:23:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 1.08 on epoch=161
05/21/2022 07:23:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 1.01 on epoch=162
05/21/2022 07:24:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 1.13 on epoch=162
05/21/2022 07:24:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.98 on epoch=163
05/21/2022 07:24:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.95 on epoch=164
05/21/2022 07:24:07 - INFO - __main__ - Global step 2300 Train loss 1.03 Classification-F1 0.3075308699899804 on epoch=164
05/21/2022 07:24:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 1.04 on epoch=164
05/21/2022 07:24:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 1.03 on epoch=165
05/21/2022 07:24:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 1.00 on epoch=166
05/21/2022 07:24:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 1.00 on epoch=167
05/21/2022 07:24:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 1.06 on epoch=167
05/21/2022 07:24:17 - INFO - __main__ - Global step 2350 Train loss 1.03 Classification-F1 0.346450658435821 on epoch=167
05/21/2022 07:24:17 - INFO - __main__ - Saving model with best Classification-F1: 0.3158445048094584 -> 0.346450658435821 on epoch=167, global_step=2350
05/21/2022 07:24:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 1.04 on epoch=168
05/21/2022 07:24:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 1.01 on epoch=169
05/21/2022 07:24:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.99 on epoch=169
05/21/2022 07:24:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 1.05 on epoch=170
05/21/2022 07:24:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 1.01 on epoch=171
05/21/2022 07:24:27 - INFO - __main__ - Global step 2400 Train loss 1.02 Classification-F1 0.2524536469599495 on epoch=171
05/21/2022 07:24:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.98 on epoch=172
05/21/2022 07:24:29 - INFO - __main__ - Step 2420 Global step 2420 Train loss 1.04 on epoch=172
05/21/2022 07:24:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 1.07 on epoch=173
05/21/2022 07:24:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.96 on epoch=174
05/21/2022 07:24:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 1.08 on epoch=174
05/21/2022 07:24:36 - INFO - __main__ - Global step 2450 Train loss 1.03 Classification-F1 0.36388517439658935 on epoch=174
05/21/2022 07:24:36 - INFO - __main__ - Saving model with best Classification-F1: 0.346450658435821 -> 0.36388517439658935 on epoch=174, global_step=2450
05/21/2022 07:24:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.90 on epoch=175
05/21/2022 07:24:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 1.03 on epoch=176
05/21/2022 07:24:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 1.03 on epoch=177
05/21/2022 07:24:42 - INFO - __main__ - Step 2490 Global step 2490 Train loss 1.01 on epoch=177
05/21/2022 07:24:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.95 on epoch=178
05/21/2022 07:24:46 - INFO - __main__ - Global step 2500 Train loss 0.99 Classification-F1 0.3478209128492417 on epoch=178
05/21/2022 07:24:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.93 on epoch=179
05/21/2022 07:24:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 1.07 on epoch=179
05/21/2022 07:24:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.93 on epoch=180
05/21/2022 07:24:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 1.02 on epoch=181
05/21/2022 07:24:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.98 on epoch=182
05/21/2022 07:24:56 - INFO - __main__ - Global step 2550 Train loss 0.99 Classification-F1 0.35018783751025967 on epoch=182
05/21/2022 07:24:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 1.04 on epoch=182
05/21/2022 07:24:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 1.06 on epoch=183
05/21/2022 07:25:00 - INFO - __main__ - Step 2580 Global step 2580 Train loss 1.02 on epoch=184
05/21/2022 07:25:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 1.01 on epoch=184
05/21/2022 07:25:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 1.00 on epoch=185
05/21/2022 07:25:05 - INFO - __main__ - Global step 2600 Train loss 1.03 Classification-F1 0.3277174796744894 on epoch=185
05/21/2022 07:25:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 1.01 on epoch=186
05/21/2022 07:25:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.98 on epoch=187
05/21/2022 07:25:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.97 on epoch=187
05/21/2022 07:25:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.91 on epoch=188
05/21/2022 07:25:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.95 on epoch=189
05/21/2022 07:25:15 - INFO - __main__ - Global step 2650 Train loss 0.97 Classification-F1 0.39138654601867057 on epoch=189
05/21/2022 07:25:15 - INFO - __main__ - Saving model with best Classification-F1: 0.36388517439658935 -> 0.39138654601867057 on epoch=189, global_step=2650
05/21/2022 07:25:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.98 on epoch=189
05/21/2022 07:25:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.90 on epoch=190
05/21/2022 07:25:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.97 on epoch=191
05/21/2022 07:25:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.94 on epoch=192
05/21/2022 07:25:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.95 on epoch=192
05/21/2022 07:25:25 - INFO - __main__ - Global step 2700 Train loss 0.95 Classification-F1 0.37441539461634454 on epoch=192
05/21/2022 07:25:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.82 on epoch=193
05/21/2022 07:25:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 1.04 on epoch=194
05/21/2022 07:25:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 1.02 on epoch=194
05/21/2022 07:25:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.97 on epoch=195
05/21/2022 07:25:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 1.00 on epoch=196
05/21/2022 07:25:35 - INFO - __main__ - Global step 2750 Train loss 0.97 Classification-F1 0.4095379807471741 on epoch=196
05/21/2022 07:25:35 - INFO - __main__ - Saving model with best Classification-F1: 0.39138654601867057 -> 0.4095379807471741 on epoch=196, global_step=2750
05/21/2022 07:25:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.95 on epoch=197
05/21/2022 07:25:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.96 on epoch=197
05/21/2022 07:25:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.96 on epoch=198
05/21/2022 07:25:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.98 on epoch=199
05/21/2022 07:25:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 1.04 on epoch=199
05/21/2022 07:25:45 - INFO - __main__ - Global step 2800 Train loss 0.98 Classification-F1 0.46417910590680617 on epoch=199
05/21/2022 07:25:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4095379807471741 -> 0.46417910590680617 on epoch=199, global_step=2800
05/21/2022 07:25:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.90 on epoch=200
05/21/2022 07:25:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.97 on epoch=201
05/21/2022 07:25:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.97 on epoch=202
05/21/2022 07:25:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.91 on epoch=202
05/21/2022 07:25:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.87 on epoch=203
05/21/2022 07:25:54 - INFO - __main__ - Global step 2850 Train loss 0.92 Classification-F1 0.4684274225952281 on epoch=203
05/21/2022 07:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.46417910590680617 -> 0.4684274225952281 on epoch=203, global_step=2850
05/21/2022 07:25:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.96 on epoch=204
05/21/2022 07:25:57 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.99 on epoch=204
05/21/2022 07:25:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 1.01 on epoch=205
05/21/2022 07:25:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 1.05 on epoch=206
05/21/2022 07:26:01 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.92 on epoch=207
05/21/2022 07:26:04 - INFO - __main__ - Global step 2900 Train loss 0.99 Classification-F1 0.4571062386029635 on epoch=207
05/21/2022 07:26:05 - INFO - __main__ - Step 2910 Global step 2910 Train loss 1.08 on epoch=207
05/21/2022 07:26:07 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.96 on epoch=208
05/21/2022 07:26:08 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.92 on epoch=209
05/21/2022 07:26:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.90 on epoch=209
05/21/2022 07:26:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.85 on epoch=210
05/21/2022 07:26:14 - INFO - __main__ - Global step 2950 Train loss 0.94 Classification-F1 0.45229996661549016 on epoch=210
05/21/2022 07:26:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.94 on epoch=211
05/21/2022 07:26:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.85 on epoch=212
05/21/2022 07:26:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 1.02 on epoch=212
05/21/2022 07:26:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.99 on epoch=213
05/21/2022 07:26:20 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.94 on epoch=214
05/21/2022 07:26:24 - INFO - __main__ - Global step 3000 Train loss 0.95 Classification-F1 0.4312321683226501 on epoch=214
05/21/2022 07:26:24 - INFO - __main__ - save last model!
05/21/2022 07:26:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/21/2022 07:26:24 - INFO - __main__ - Start tokenizing ... 3500 instances
05/21/2022 07:26:24 - INFO - __main__ - Printing 3 examples
05/21/2022 07:26:24 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)
05/21/2022 07:26:24 - INFO - __main__ - ['Animal']
05/21/2022 07:26:24 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/21/2022 07:26:24 - INFO - __main__ - ['Animal']
05/21/2022 07:26:24 - INFO - __main__ -  [dbpedia_14] Strzeczonka [sttnka] is a village in the administrative district of Gmina Debrzno within Czuchw County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Czuchw and 130 km (81 mi) south-west of the regional capital Gdask.For details of the history of the region see History of Pomerania.
05/21/2022 07:26:24 - INFO - __main__ - ['Village']
05/21/2022 07:26:24 - INFO - __main__ - Tokenizing Input ...
05/21/2022 07:26:26 - INFO - __main__ - Tokenizing Output ...
05/21/2022 07:26:29 - INFO - __main__ - Loaded 3500 examples from test data
05/21/2022 07:27:26 - INFO - __main__ - Saved prediction in models/T5-base-multitask-cls2cls-5e-1-4-20/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
05/21/2022 07:27:27 - INFO - __main__ - Classification-F1 on test data: 0.2797
05/21/2022 07:27:27 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.4684274225952281, test_performance=0.27969846356523553
