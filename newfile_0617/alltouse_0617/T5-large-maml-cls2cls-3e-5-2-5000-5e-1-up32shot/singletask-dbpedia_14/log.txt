05/21/2022 06:26:38 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:26:38 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14
05/21/2022 06:26:38 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:26:38 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14
05/21/2022 06:26:40 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 06:26:40 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 06:26:40 - INFO - __main__ - args.device: cuda:0
05/21/2022 06:26:40 - INFO - __main__ - Using 2 gpus
05/21/2022 06:26:40 - INFO - __main__ - args.device: cuda:1
05/21/2022 06:26:40 - INFO - __main__ - Using 2 gpus
05/21/2022 06:26:40 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 06:26:40 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
05/21/2022 06:26:44 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
05/21/2022 06:26:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:26:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:26:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:26:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:26:45 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:26:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:26:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:26:45 - INFO - __main__ - Loaded 224 examples from train data
05/21/2022 06:26:45 - INFO - __main__ - Start tokenizing ... 224 instances
05/21/2022 06:26:45 - INFO - __main__ - Printing 3 examples
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
05/21/2022 06:26:45 - INFO - __main__ - ['Animal']
05/21/2022 06:26:45 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:26:46 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:26:46 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:26:46 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:26:46 - INFO - __main__ - Loaded 224 examples from dev data
05/21/2022 06:27:03 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:27:04 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 07:49:11 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/01/2022 07:49:11 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14
06/01/2022 07:49:11 - INFO - __main__ - Namespace(task_dir='data/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/01/2022 07:49:11 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14
06/01/2022 07:49:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 07:49:12 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 07:49:12 - INFO - __main__ - args.device: cuda:0
06/01/2022 07:49:12 - INFO - __main__ - Using 2 gpus
06/01/2022 07:49:12 - INFO - __main__ - args.device: cuda:1
06/01/2022 07:49:12 - INFO - __main__ - Using 2 gpus
06/01/2022 07:49:12 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/01/2022 07:49:12 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_16_100', 'dbpedia_14_16_13', 'dbpedia_14_16_21', 'dbpedia_14_16_42', 'dbpedia_14_16_87']
06/01/2022 07:49:17 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.5, bsz=8 ...
06/01/2022 07:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 07:49:18 - INFO - __main__ - Printing 3 examples
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 07:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 07:49:18 - INFO - __main__ - Printing 3 examples
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 07:49:18 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 07:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 07:49:18 - INFO - __main__ - Printing 3 examples
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 07:49:18 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 07:49:18 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 07:49:18 - INFO - __main__ - Printing 3 examples
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 07:49:18 - INFO - __main__ - ['Animal']
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 07:49:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 07:49:18 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 07:49:18 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 07:49:36 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 07:49:37 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 07:49:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 07:49:37 - INFO - __main__ - Starting training!
06/01/2022 07:49:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 07:49:42 - INFO - __main__ - Starting training!
06/01/2022 07:49:46 - INFO - __main__ - Step 10 Global step 10 Train loss 5.19 on epoch=0
06/01/2022 07:49:49 - INFO - __main__ - Step 20 Global step 20 Train loss 3.52 on epoch=1
06/01/2022 07:49:51 - INFO - __main__ - Step 30 Global step 30 Train loss 2.68 on epoch=2
06/01/2022 07:49:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=2
06/01/2022 07:49:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.65 on epoch=3
06/01/2022 07:50:03 - INFO - __main__ - Global step 50 Train loss 3.01 Classification-F1 0.10517304092022145 on epoch=3
06/01/2022 07:50:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10517304092022145 on epoch=3, global_step=50
06/01/2022 07:50:06 - INFO - __main__ - Step 60 Global step 60 Train loss 1.51 on epoch=4
06/01/2022 07:50:09 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=4
06/01/2022 07:50:12 - INFO - __main__ - Step 80 Global step 80 Train loss 1.03 on epoch=5
06/01/2022 07:50:14 - INFO - __main__ - Step 90 Global step 90 Train loss 1.05 on epoch=6
06/01/2022 07:50:17 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=7
06/01/2022 07:50:24 - INFO - __main__ - Global step 100 Train loss 1.09 Classification-F1 0.4268132254280262 on epoch=7
06/01/2022 07:50:24 - INFO - __main__ - Saving model with best Classification-F1: 0.10517304092022145 -> 0.4268132254280262 on epoch=7, global_step=100
06/01/2022 07:50:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.67 on epoch=7
06/01/2022 07:50:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.73 on epoch=8
06/01/2022 07:50:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=9
06/01/2022 07:50:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=9
06/01/2022 07:50:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.59 on epoch=10
06/01/2022 07:50:45 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.4944447861798005 on epoch=10
06/01/2022 07:50:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4268132254280262 -> 0.4944447861798005 on epoch=10, global_step=150
06/01/2022 07:50:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.62 on epoch=11
06/01/2022 07:50:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=12
06/01/2022 07:50:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.46 on epoch=12
06/01/2022 07:50:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.49 on epoch=13
06/01/2022 07:50:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.46 on epoch=14
06/01/2022 07:51:06 - INFO - __main__ - Global step 200 Train loss 0.52 Classification-F1 0.6775268701865343 on epoch=14
06/01/2022 07:51:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4944447861798005 -> 0.6775268701865343 on epoch=14, global_step=200
06/01/2022 07:51:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.36 on epoch=14
06/01/2022 07:51:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=15
06/01/2022 07:51:14 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=16
06/01/2022 07:51:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=17
06/01/2022 07:51:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=17
06/01/2022 07:51:26 - INFO - __main__ - Global step 250 Train loss 0.39 Classification-F1 0.7096186892168943 on epoch=17
06/01/2022 07:51:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6775268701865343 -> 0.7096186892168943 on epoch=17, global_step=250
06/01/2022 07:51:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
06/01/2022 07:51:32 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=19
06/01/2022 07:51:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
06/01/2022 07:51:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=20
06/01/2022 07:51:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=21
06/01/2022 07:51:46 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.7016991424486682 on epoch=21
06/01/2022 07:51:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/01/2022 07:51:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=22
06/01/2022 07:51:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.35 on epoch=23
06/01/2022 07:51:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.25 on epoch=24
06/01/2022 07:52:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=24
06/01/2022 07:52:07 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.7638889385709724 on epoch=24
06/01/2022 07:52:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7096186892168943 -> 0.7638889385709724 on epoch=24, global_step=350
06/01/2022 07:52:09 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/01/2022 07:52:12 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
06/01/2022 07:52:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=27
06/01/2022 07:52:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=27
06/01/2022 07:52:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=28
06/01/2022 07:52:27 - INFO - __main__ - Global step 400 Train loss 0.27 Classification-F1 0.7224883750026064 on epoch=28
06/01/2022 07:52:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=29
06/01/2022 07:52:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.18 on epoch=29
06/01/2022 07:52:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=30
06/01/2022 07:52:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=31
06/01/2022 07:52:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=32
06/01/2022 07:52:47 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.7318916848551853 on epoch=32
06/01/2022 07:52:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/01/2022 07:52:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=33
06/01/2022 07:52:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=34
06/01/2022 07:52:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=34
06/01/2022 07:53:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
06/01/2022 07:53:07 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.7093372449990096 on epoch=35
06/01/2022 07:53:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/01/2022 07:53:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/01/2022 07:53:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=37
06/01/2022 07:53:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/01/2022 07:53:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=39
06/01/2022 07:53:27 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.7011932952395359 on epoch=39
06/01/2022 07:53:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/01/2022 07:53:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/01/2022 07:53:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=41
06/01/2022 07:53:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=42
06/01/2022 07:53:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
06/01/2022 07:53:47 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.7473799682693456 on epoch=42
06/01/2022 07:53:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/01/2022 07:53:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=44
06/01/2022 07:53:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=44
06/01/2022 07:53:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
06/01/2022 07:54:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/01/2022 07:54:06 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.8223784030752558 on epoch=46
06/01/2022 07:54:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7638889385709724 -> 0.8223784030752558 on epoch=46, global_step=650
06/01/2022 07:54:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=47
06/01/2022 07:54:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/01/2022 07:54:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/01/2022 07:54:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=49
06/01/2022 07:54:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=49
06/01/2022 07:54:26 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.82631879456328 on epoch=49
06/01/2022 07:54:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8223784030752558 -> 0.82631879456328 on epoch=49, global_step=700
06/01/2022 07:54:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/01/2022 07:54:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
06/01/2022 07:54:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=52
06/01/2022 07:54:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=52
06/01/2022 07:54:39 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/01/2022 07:54:46 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.8929245833230651 on epoch=53
06/01/2022 07:54:46 - INFO - __main__ - Saving model with best Classification-F1: 0.82631879456328 -> 0.8929245833230651 on epoch=53, global_step=750
06/01/2022 07:54:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=54
06/01/2022 07:54:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
06/01/2022 07:54:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=55
06/01/2022 07:54:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/01/2022 07:54:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=57
06/01/2022 07:55:05 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.9504346910166637 on epoch=57
06/01/2022 07:55:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8929245833230651 -> 0.9504346910166637 on epoch=57, global_step=800
06/01/2022 07:55:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
06/01/2022 07:55:10 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=58
06/01/2022 07:55:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=59
06/01/2022 07:55:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=59
06/01/2022 07:55:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=60
06/01/2022 07:55:25 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.9640068078500487 on epoch=60
06/01/2022 07:55:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9504346910166637 -> 0.9640068078500487 on epoch=60, global_step=850
06/01/2022 07:55:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/01/2022 07:55:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=62
06/01/2022 07:55:33 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=62
06/01/2022 07:55:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/01/2022 07:55:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=64
06/01/2022 07:55:45 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9645736520414617 on epoch=64
06/01/2022 07:55:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9640068078500487 -> 0.9645736520414617 on epoch=64, global_step=900
06/01/2022 07:55:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/01/2022 07:55:50 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/01/2022 07:55:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 07:55:55 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/01/2022 07:55:58 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/01/2022 07:56:04 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8300911570639986 on epoch=67
06/01/2022 07:56:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
06/01/2022 07:56:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/01/2022 07:56:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=69
06/01/2022 07:56:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=70
06/01/2022 07:56:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=71
06/01/2022 07:56:24 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.8376114081996435 on epoch=71
06/01/2022 07:56:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=72
06/01/2022 07:56:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=72
06/01/2022 07:56:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/01/2022 07:56:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/01/2022 07:56:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=74
06/01/2022 07:56:44 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.8892272478479375 on epoch=74
06/01/2022 07:56:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/01/2022 07:56:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/01/2022 07:56:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
06/01/2022 07:56:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=77
06/01/2022 07:56:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/01/2022 07:57:04 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.9598073833639028 on epoch=78
06/01/2022 07:57:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/01/2022 07:57:09 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/01/2022 07:57:12 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/01/2022 07:57:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/01/2022 07:57:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/01/2022 07:57:24 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.8891884169651952 on epoch=82
06/01/2022 07:57:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=82
06/01/2022 07:57:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/01/2022 07:57:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/01/2022 07:57:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=84
06/01/2022 07:57:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/01/2022 07:57:44 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.9599733148391322 on epoch=85
06/01/2022 07:57:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=86
06/01/2022 07:57:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=87
06/01/2022 07:57:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=87
06/01/2022 07:57:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/01/2022 07:57:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=89
06/01/2022 07:58:04 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.973170543877375 on epoch=89
06/01/2022 07:58:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9645736520414617 -> 0.973170543877375 on epoch=89, global_step=1250
06/01/2022 07:58:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/01/2022 07:58:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=90
06/01/2022 07:58:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/01/2022 07:58:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/01/2022 07:58:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/01/2022 07:58:24 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9777884394226899 on epoch=92
06/01/2022 07:58:24 - INFO - __main__ - Saving model with best Classification-F1: 0.973170543877375 -> 0.9777884394226899 on epoch=92, global_step=1300
06/01/2022 07:58:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/01/2022 07:58:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/01/2022 07:58:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=94
06/01/2022 07:58:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/01/2022 07:58:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/01/2022 07:58:45 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.9687920182735851 on epoch=96
06/01/2022 07:58:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/01/2022 07:58:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/01/2022 07:58:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 07:58:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/01/2022 07:58:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/01/2022 07:59:04 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9058404003391897 on epoch=99
06/01/2022 07:59:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/01/2022 07:59:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/01/2022 07:59:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/01/2022 07:59:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/01/2022 07:59:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/01/2022 07:59:24 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.9685395565850975 on epoch=103
06/01/2022 07:59:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/01/2022 07:59:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/01/2022 07:59:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/01/2022 07:59:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/01/2022 07:59:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/01/2022 07:59:43 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9122100032583904 on epoch=107
06/01/2022 07:59:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=107
06/01/2022 07:59:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/01/2022 07:59:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/01/2022 07:59:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/01/2022 07:59:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/01/2022 08:00:03 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9643858230925094 on epoch=110
06/01/2022 08:00:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/01/2022 08:00:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/01/2022 08:00:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/01/2022 08:00:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/01/2022 08:00:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=114
06/01/2022 08:00:23 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9052292715717765 on epoch=114
06/01/2022 08:00:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/01/2022 08:00:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/01/2022 08:00:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 08:00:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/01/2022 08:00:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/01/2022 08:00:43 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8422082792264838 on epoch=117
06/01/2022 08:00:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/01/2022 08:00:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/01/2022 08:00:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/01/2022 08:00:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/01/2022 08:00:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/01/2022 08:01:02 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9731478515159729 on epoch=121
06/01/2022 08:01:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/01/2022 08:01:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/01/2022 08:01:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/01/2022 08:01:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/01/2022 08:01:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/01/2022 08:01:22 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=124
06/01/2022 08:01:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9777884394226899 -> 0.9821297653958945 on epoch=124, global_step=1750
06/01/2022 08:01:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/01/2022 08:01:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=126
06/01/2022 08:01:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=127
06/01/2022 08:01:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/01/2022 08:01:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/01/2022 08:01:41 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.9777884394226899 on epoch=128
06/01/2022 08:01:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/01/2022 08:01:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/01/2022 08:01:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 08:01:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/01/2022 08:01:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/01/2022 08:02:01 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9777884394226899 on epoch=132
06/01/2022 08:02:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/01/2022 08:02:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/01/2022 08:02:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/01/2022 08:02:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/01/2022 08:02:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/01/2022 08:02:21 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9777884394226899 on epoch=135
06/01/2022 08:02:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/01/2022 08:02:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/01/2022 08:02:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/01/2022 08:02:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 08:02:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/01/2022 08:02:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9146227454813792 on epoch=139
06/01/2022 08:02:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 08:02:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 08:02:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/01/2022 08:02:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/01/2022 08:02:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/01/2022 08:03:01 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9821297653958945 on epoch=142
06/01/2022 08:03:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=143
06/01/2022 08:03:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/01/2022 08:03:09 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/01/2022 08:03:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/01/2022 08:03:14 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
06/01/2022 08:03:21 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9105361215845087 on epoch=146
06/01/2022 08:03:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 08:03:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/01/2022 08:03:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/01/2022 08:03:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=149
06/01/2022 08:03:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/01/2022 08:03:40 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=149
06/01/2022 08:03:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 08:03:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/01/2022 08:03:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/01/2022 08:03:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/01/2022 08:03:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 08:04:00 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.973139893787427 on epoch=153
06/01/2022 08:04:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/01/2022 08:04:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 08:04:08 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 08:04:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/01/2022 08:04:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/01/2022 08:04:20 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9776348295916607 on epoch=157
06/01/2022 08:04:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/01/2022 08:04:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/01/2022 08:04:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/01/2022 08:04:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/01/2022 08:04:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/01/2022 08:04:39 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7893360457862635 on epoch=160
06/01/2022 08:04:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 08:04:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/01/2022 08:04:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/01/2022 08:04:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 08:04:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/01/2022 08:04:59 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9055340158107941 on epoch=164
06/01/2022 08:05:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/01/2022 08:05:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/01/2022 08:05:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 08:05:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 08:05:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=167
06/01/2022 08:05:18 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8471277798142718 on epoch=167
06/01/2022 08:05:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 08:05:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 08:05:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/01/2022 08:05:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 08:05:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/01/2022 08:05:38 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8508857168739676 on epoch=171
06/01/2022 08:05:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 08:05:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/01/2022 08:05:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/01/2022 08:05:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/01/2022 08:05:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 08:05:57 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9145079830563703 on epoch=174
06/01/2022 08:06:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 08:06:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/01/2022 08:06:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 08:06:08 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 08:06:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/01/2022 08:06:17 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=178
06/01/2022 08:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958945 -> 0.9865940511101802 on epoch=178, global_step=2500
06/01/2022 08:06:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=179
06/01/2022 08:06:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/01/2022 08:06:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 08:06:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=181
06/01/2022 08:06:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/01/2022 08:06:37 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=182
06/01/2022 08:06:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=182
06/01/2022 08:06:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 08:06:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 08:06:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 08:06:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 08:06:56 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9776348295916607 on epoch=185
06/01/2022 08:06:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=186
06/01/2022 08:07:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/01/2022 08:07:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/01/2022 08:07:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/01/2022 08:07:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/01/2022 08:07:16 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.973139893787427 on epoch=189
06/01/2022 08:07:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/01/2022 08:07:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 08:07:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 08:07:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/01/2022 08:07:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/01/2022 08:07:36 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=192
06/01/2022 08:07:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/01/2022 08:07:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/01/2022 08:07:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 08:07:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/01/2022 08:07:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/01/2022 08:07:56 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.9776427873202066 on epoch=196
06/01/2022 08:07:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.17 on epoch=197
06/01/2022 08:08:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/01/2022 08:08:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/01/2022 08:08:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 08:08:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/01/2022 08:08:15 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9777884394226899 on epoch=199
06/01/2022 08:08:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/01/2022 08:08:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/01/2022 08:08:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/01/2022 08:08:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/01/2022 08:08:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 08:08:35 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9777884394226899 on epoch=203
06/01/2022 08:08:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/01/2022 08:08:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/01/2022 08:08:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=205
06/01/2022 08:08:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/01/2022 08:08:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 08:08:55 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.9776348295916607 on epoch=207
06/01/2022 08:08:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/01/2022 08:09:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/01/2022 08:09:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 08:09:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/01/2022 08:09:08 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 08:09:14 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9777884394226899 on epoch=210
06/01/2022 08:09:17 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/01/2022 08:09:19 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/01/2022 08:09:22 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/01/2022 08:09:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 08:09:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/01/2022 08:09:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:09:29 - INFO - __main__ - Printing 3 examples
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:09:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:09:29 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:09:29 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:09:29 - INFO - __main__ - Printing 3 examples
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:09:29 - INFO - __main__ - ['Animal']
06/01/2022 08:09:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:09:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:09:30 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:09:34 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9777884394226899 on epoch=214
06/01/2022 08:09:34 - INFO - __main__ - save last model!
06/01/2022 08:09:34 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 08:09:34 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 08:09:34 - INFO - __main__ - Printing 3 examples
06/01/2022 08:09:34 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 08:09:34 - INFO - __main__ - ['Animal']
06/01/2022 08:09:34 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 08:09:34 - INFO - __main__ - ['Animal']
06/01/2022 08:09:34 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 08:09:34 - INFO - __main__ - ['Village']
06/01/2022 08:09:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:09:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:09:40 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 08:09:48 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:09:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:09:49 - INFO - __main__ - Starting training!
06/01/2022 08:11:50 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_100_0.5_8_predictions.txt
06/01/2022 08:11:50 - INFO - __main__ - Classification-F1 on test data: 0.6499
06/01/2022 08:11:51 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.5, bsz=8, dev_performance=0.9865940511101802, test_performance=0.6499354119160997
06/01/2022 08:11:51 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.4, bsz=8 ...
06/01/2022 08:11:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:11:52 - INFO - __main__ - Printing 3 examples
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:11:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:11:52 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:11:52 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:11:52 - INFO - __main__ - Printing 3 examples
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:11:52 - INFO - __main__ - ['Animal']
06/01/2022 08:11:52 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:11:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:11:52 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:12:08 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:12:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:12:08 - INFO - __main__ - Starting training!
06/01/2022 08:12:12 - INFO - __main__ - Step 10 Global step 10 Train loss 5.19 on epoch=0
06/01/2022 08:12:15 - INFO - __main__ - Step 20 Global step 20 Train loss 3.82 on epoch=1
06/01/2022 08:12:18 - INFO - __main__ - Step 30 Global step 30 Train loss 2.95 on epoch=2
06/01/2022 08:12:20 - INFO - __main__ - Step 40 Global step 40 Train loss 2.29 on epoch=2
06/01/2022 08:12:23 - INFO - __main__ - Step 50 Global step 50 Train loss 2.09 on epoch=3
06/01/2022 08:12:29 - INFO - __main__ - Global step 50 Train loss 3.27 Classification-F1 0.06952632031409954 on epoch=3
06/01/2022 08:12:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06952632031409954 on epoch=3, global_step=50
06/01/2022 08:12:31 - INFO - __main__ - Step 60 Global step 60 Train loss 1.84 on epoch=4
06/01/2022 08:12:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.29 on epoch=4
06/01/2022 08:12:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.22 on epoch=5
06/01/2022 08:12:39 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=6
06/01/2022 08:12:42 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=7
06/01/2022 08:12:49 - INFO - __main__ - Global step 100 Train loss 1.27 Classification-F1 0.4101023613108189 on epoch=7
06/01/2022 08:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.06952632031409954 -> 0.4101023613108189 on epoch=7, global_step=100
06/01/2022 08:12:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=7
06/01/2022 08:12:54 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=8
06/01/2022 08:12:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.83 on epoch=9
06/01/2022 08:13:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=9
06/01/2022 08:13:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=10
06/01/2022 08:13:09 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.5940036213477257 on epoch=10
06/01/2022 08:13:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4101023613108189 -> 0.5940036213477257 on epoch=10, global_step=150
06/01/2022 08:13:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=11
06/01/2022 08:13:15 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=12
06/01/2022 08:13:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=12
06/01/2022 08:13:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.53 on epoch=13
06/01/2022 08:13:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=14
06/01/2022 08:13:29 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.5953748118643755 on epoch=14
06/01/2022 08:13:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5940036213477257 -> 0.5953748118643755 on epoch=14, global_step=200
06/01/2022 08:13:32 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=14
06/01/2022 08:13:35 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
06/01/2022 08:13:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=16
06/01/2022 08:13:40 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=17
06/01/2022 08:13:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.33 on epoch=17
06/01/2022 08:13:50 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.5727906745521347 on epoch=17
06/01/2022 08:13:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
06/01/2022 08:13:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=19
06/01/2022 08:13:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.36 on epoch=19
06/01/2022 08:14:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=20
06/01/2022 08:14:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=21
06/01/2022 08:14:11 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.6251253982878303 on epoch=21
06/01/2022 08:14:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5953748118643755 -> 0.6251253982878303 on epoch=21, global_step=300
06/01/2022 08:14:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=22
06/01/2022 08:14:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=22
06/01/2022 08:14:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
06/01/2022 08:14:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=24
06/01/2022 08:14:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=24
06/01/2022 08:14:31 - INFO - __main__ - Global step 350 Train loss 0.29 Classification-F1 0.5863477387467628 on epoch=24
06/01/2022 08:14:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=25
06/01/2022 08:14:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=26
06/01/2022 08:14:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=27
06/01/2022 08:14:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.26 on epoch=27
06/01/2022 08:14:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/01/2022 08:14:51 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.637114437976584 on epoch=28
06/01/2022 08:14:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6251253982878303 -> 0.637114437976584 on epoch=28, global_step=400
06/01/2022 08:14:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=29
06/01/2022 08:14:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=29
06/01/2022 08:14:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=30
06/01/2022 08:15:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=31
06/01/2022 08:15:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=32
06/01/2022 08:15:12 - INFO - __main__ - Global step 450 Train loss 0.22 Classification-F1 0.5842522492868115 on epoch=32
06/01/2022 08:15:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.14 on epoch=32
06/01/2022 08:15:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=33
06/01/2022 08:15:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=34
06/01/2022 08:15:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=34
06/01/2022 08:15:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/01/2022 08:15:33 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.706655740398771 on epoch=35
06/01/2022 08:15:33 - INFO - __main__ - Saving model with best Classification-F1: 0.637114437976584 -> 0.706655740398771 on epoch=35, global_step=500
06/01/2022 08:15:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=36
06/01/2022 08:15:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=37
06/01/2022 08:15:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=37
06/01/2022 08:15:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/01/2022 08:15:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/01/2022 08:15:54 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.6712683830967991 on epoch=39
06/01/2022 08:15:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=39
06/01/2022 08:15:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
06/01/2022 08:16:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=41
06/01/2022 08:16:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=42
06/01/2022 08:16:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/01/2022 08:16:14 - INFO - __main__ - Global step 600 Train loss 0.13 Classification-F1 0.608440593796872 on epoch=42
06/01/2022 08:16:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=43
06/01/2022 08:16:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/01/2022 08:16:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
06/01/2022 08:16:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=45
06/01/2022 08:16:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=46
06/01/2022 08:16:34 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.7915644536710427 on epoch=46
06/01/2022 08:16:34 - INFO - __main__ - Saving model with best Classification-F1: 0.706655740398771 -> 0.7915644536710427 on epoch=46, global_step=650
06/01/2022 08:16:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=47
06/01/2022 08:16:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
06/01/2022 08:16:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=48
06/01/2022 08:16:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/01/2022 08:16:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=49
06/01/2022 08:16:55 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.7723238368622899 on epoch=49
06/01/2022 08:16:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/01/2022 08:17:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
06/01/2022 08:17:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
06/01/2022 08:17:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.07 on epoch=52
06/01/2022 08:17:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
06/01/2022 08:17:15 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6478864754517442 on epoch=53
06/01/2022 08:17:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=54
06/01/2022 08:17:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/01/2022 08:17:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/01/2022 08:17:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=56
06/01/2022 08:17:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/01/2022 08:17:35 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.8800416386597109 on epoch=57
06/01/2022 08:17:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7915644536710427 -> 0.8800416386597109 on epoch=57, global_step=800
06/01/2022 08:17:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
06/01/2022 08:17:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/01/2022 08:17:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=59
06/01/2022 08:17:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/01/2022 08:17:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/01/2022 08:17:55 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.8194874606254388 on epoch=60
06/01/2022 08:17:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/01/2022 08:18:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=62
06/01/2022 08:18:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=62
06/01/2022 08:18:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/01/2022 08:18:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=64
06/01/2022 08:18:15 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.721195892418002 on epoch=64
06/01/2022 08:18:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/01/2022 08:18:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=65
06/01/2022 08:18:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=66
06/01/2022 08:18:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/01/2022 08:18:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/01/2022 08:18:34 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6977784133419739 on epoch=67
06/01/2022 08:18:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/01/2022 08:18:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/01/2022 08:18:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/01/2022 08:18:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=70
06/01/2022 08:18:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=71
06/01/2022 08:18:54 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.881730495144092 on epoch=71
06/01/2022 08:18:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8800416386597109 -> 0.881730495144092 on epoch=71, global_step=1000
06/01/2022 08:18:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/01/2022 08:19:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/01/2022 08:19:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=73
06/01/2022 08:19:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/01/2022 08:19:08 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/01/2022 08:19:14 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.831675124829232 on epoch=74
06/01/2022 08:19:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=75
06/01/2022 08:19:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/01/2022 08:19:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=77
06/01/2022 08:19:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=77
06/01/2022 08:19:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=78
06/01/2022 08:19:34 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8215356630694548 on epoch=78
06/01/2022 08:19:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/01/2022 08:19:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/01/2022 08:19:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/01/2022 08:19:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/01/2022 08:19:47 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/01/2022 08:19:54 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.8971954256884681 on epoch=82
06/01/2022 08:19:54 - INFO - __main__ - Saving model with best Classification-F1: 0.881730495144092 -> 0.8971954256884681 on epoch=82, global_step=1150
06/01/2022 08:19:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/01/2022 08:19:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
06/01/2022 08:20:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=84
06/01/2022 08:20:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/01/2022 08:20:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/01/2022 08:20:14 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.8973387948640954 on epoch=85
06/01/2022 08:20:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8971954256884681 -> 0.8973387948640954 on epoch=85, global_step=1200
06/01/2022 08:20:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/01/2022 08:20:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 08:20:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=87
06/01/2022 08:20:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/01/2022 08:20:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/01/2022 08:20:34 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.9821297653958945 on epoch=89
06/01/2022 08:20:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8973387948640954 -> 0.9821297653958945 on epoch=89, global_step=1250
06/01/2022 08:20:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/01/2022 08:20:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=90
06/01/2022 08:20:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/01/2022 08:20:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/01/2022 08:20:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/01/2022 08:20:54 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.912223036819811 on epoch=92
06/01/2022 08:20:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/01/2022 08:20:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/01/2022 08:21:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/01/2022 08:21:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=95
06/01/2022 08:21:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
06/01/2022 08:21:13 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7858094814312506 on epoch=96
06/01/2022 08:21:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/01/2022 08:21:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/01/2022 08:21:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 08:21:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/01/2022 08:21:26 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=99
06/01/2022 08:21:33 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.8193074003795067 on epoch=99
06/01/2022 08:21:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/01/2022 08:21:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/01/2022 08:21:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/01/2022 08:21:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/01/2022 08:21:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/01/2022 08:21:54 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.89690689005047 on epoch=103
06/01/2022 08:21:56 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/01/2022 08:21:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/01/2022 08:22:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/01/2022 08:22:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/01/2022 08:22:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/01/2022 08:22:13 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8431846250736112 on epoch=107
06/01/2022 08:22:16 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 08:22:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/01/2022 08:22:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=109
06/01/2022 08:22:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/01/2022 08:22:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/01/2022 08:22:33 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7704819973530209 on epoch=110
06/01/2022 08:22:36 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/01/2022 08:22:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/01/2022 08:22:41 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/01/2022 08:22:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/01/2022 08:22:46 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/01/2022 08:22:53 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9036980086806691 on epoch=114
06/01/2022 08:22:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/01/2022 08:22:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/01/2022 08:23:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 08:23:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/01/2022 08:23:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=117
06/01/2022 08:23:12 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9123288386713433 on epoch=117
06/01/2022 08:23:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/01/2022 08:23:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/01/2022 08:23:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/01/2022 08:23:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=120
06/01/2022 08:23:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/01/2022 08:23:32 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.847361377652234 on epoch=121
06/01/2022 08:23:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/01/2022 08:23:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/01/2022 08:23:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/01/2022 08:23:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/01/2022 08:23:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/01/2022 08:23:52 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9165281850765723 on epoch=124
06/01/2022 08:23:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/01/2022 08:23:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/01/2022 08:24:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/01/2022 08:24:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/01/2022 08:24:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/01/2022 08:24:12 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8984671284497888 on epoch=128
06/01/2022 08:24:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/01/2022 08:24:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/01/2022 08:24:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 08:24:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/01/2022 08:24:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/01/2022 08:24:32 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9684834152085344 on epoch=132
06/01/2022 08:24:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/01/2022 08:24:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/01/2022 08:24:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/01/2022 08:24:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/01/2022 08:24:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/01/2022 08:24:52 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.905868265194641 on epoch=135
06/01/2022 08:24:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/01/2022 08:24:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/01/2022 08:25:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/01/2022 08:25:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/01/2022 08:25:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/01/2022 08:25:11 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7929227556125089 on epoch=139
06/01/2022 08:25:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 08:25:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/01/2022 08:25:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/01/2022 08:25:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/01/2022 08:25:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/01/2022 08:25:31 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.903665328942107 on epoch=142
06/01/2022 08:25:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/01/2022 08:25:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.15 on epoch=144
06/01/2022 08:25:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/01/2022 08:25:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
06/01/2022 08:25:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/01/2022 08:25:50 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8470748376835819 on epoch=146
06/01/2022 08:25:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 08:25:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/01/2022 08:25:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 08:26:00 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/01/2022 08:26:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/01/2022 08:26:10 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8471786090308304 on epoch=149
06/01/2022 08:26:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/01/2022 08:26:15 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/01/2022 08:26:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/01/2022 08:26:20 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 08:26:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/01/2022 08:26:29 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8942677820445603 on epoch=153
06/01/2022 08:26:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/01/2022 08:26:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 08:26:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 08:26:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/01/2022 08:26:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/01/2022 08:26:50 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8932086040672379 on epoch=157
06/01/2022 08:26:52 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=157
06/01/2022 08:26:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/01/2022 08:26:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/01/2022 08:27:00 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/01/2022 08:27:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/01/2022 08:27:10 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8374564599585353 on epoch=160
06/01/2022 08:27:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=161
06/01/2022 08:27:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 08:27:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 08:27:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/01/2022 08:27:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 08:27:30 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9036436428483147 on epoch=164
06/01/2022 08:27:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/01/2022 08:27:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 08:27:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/01/2022 08:27:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 08:27:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 08:27:49 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.897336763489515 on epoch=167
06/01/2022 08:27:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/01/2022 08:27:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 08:27:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 08:28:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/01/2022 08:28:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/01/2022 08:28:09 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8888707033694928 on epoch=171
06/01/2022 08:28:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 08:28:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/01/2022 08:28:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/01/2022 08:28:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/01/2022 08:28:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 08:28:29 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9061174362218005 on epoch=174
06/01/2022 08:28:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 08:28:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/01/2022 08:28:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 08:28:40 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 08:28:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 08:28:49 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8299759304381578 on epoch=178
06/01/2022 08:28:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 08:28:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 08:28:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 08:29:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/01/2022 08:29:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 08:29:09 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8227259057178975 on epoch=182
06/01/2022 08:29:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 08:29:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/01/2022 08:29:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 08:29:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/01/2022 08:29:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/01/2022 08:29:28 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8888690215540311 on epoch=185
06/01/2022 08:29:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 08:29:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/01/2022 08:29:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 08:29:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=188
06/01/2022 08:29:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 08:29:48 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8791366381515566 on epoch=189
06/01/2022 08:29:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/01/2022 08:29:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 08:29:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/01/2022 08:29:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 08:30:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/01/2022 08:30:08 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8838415900623909 on epoch=192
06/01/2022 08:30:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=193
06/01/2022 08:30:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 08:30:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 08:30:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 08:30:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 08:30:28 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8922571540835297 on epoch=196
06/01/2022 08:30:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/01/2022 08:30:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 08:30:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 08:30:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/01/2022 08:30:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/01/2022 08:30:48 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.8804644369966951 on epoch=199
06/01/2022 08:30:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/01/2022 08:30:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 08:30:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 08:30:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 08:31:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 08:31:07 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8177106436416208 on epoch=203
06/01/2022 08:31:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 08:31:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 08:31:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 08:31:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 08:31:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=207
06/01/2022 08:31:27 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8974981791348015 on epoch=207
06/01/2022 08:31:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/01/2022 08:31:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 08:31:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/01/2022 08:31:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 08:31:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/01/2022 08:31:47 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8890016097449194 on epoch=210
06/01/2022 08:31:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 08:31:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/01/2022 08:31:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 08:31:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 08:32:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/01/2022 08:32:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:32:01 - INFO - __main__ - Printing 3 examples
06/01/2022 08:32:01 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:32:01 - INFO - __main__ - ['Animal']
06/01/2022 08:32:01 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:32:01 - INFO - __main__ - ['Animal']
06/01/2022 08:32:01 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:32:01 - INFO - __main__ - ['Animal']
06/01/2022 08:32:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:32:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:32:02 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:32:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:32:02 - INFO - __main__ - Printing 3 examples
06/01/2022 08:32:02 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:32:02 - INFO - __main__ - ['Animal']
06/01/2022 08:32:02 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:32:02 - INFO - __main__ - ['Animal']
06/01/2022 08:32:02 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:32:02 - INFO - __main__ - ['Animal']
06/01/2022 08:32:02 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:32:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:32:02 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:32:07 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8888129833117728 on epoch=214
06/01/2022 08:32:07 - INFO - __main__ - save last model!
06/01/2022 08:32:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 08:32:07 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 08:32:07 - INFO - __main__ - Printing 3 examples
06/01/2022 08:32:07 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 08:32:07 - INFO - __main__ - ['Animal']
06/01/2022 08:32:07 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 08:32:07 - INFO - __main__ - ['Animal']
06/01/2022 08:32:07 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 08:32:07 - INFO - __main__ - ['Village']
06/01/2022 08:32:07 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:32:09 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:32:13 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 08:32:18 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:32:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:32:19 - INFO - __main__ - Starting training!
06/01/2022 08:34:26 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_100_0.4_8_predictions.txt
06/01/2022 08:34:27 - INFO - __main__ - Classification-F1 on test data: 0.7529
06/01/2022 08:34:27 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.4, bsz=8, dev_performance=0.9821297653958945, test_performance=0.752854332147398
06/01/2022 08:34:27 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.3, bsz=8 ...
06/01/2022 08:34:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:34:28 - INFO - __main__ - Printing 3 examples
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:34:28 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:34:28 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:34:28 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:34:28 - INFO - __main__ - Printing 3 examples
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:34:28 - INFO - __main__ - ['Animal']
06/01/2022 08:34:28 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:34:28 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:34:29 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:34:44 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:34:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:34:44 - INFO - __main__ - Starting training!
06/01/2022 08:34:48 - INFO - __main__ - Step 10 Global step 10 Train loss 5.53 on epoch=0
06/01/2022 08:34:51 - INFO - __main__ - Step 20 Global step 20 Train loss 4.45 on epoch=1
06/01/2022 08:34:53 - INFO - __main__ - Step 30 Global step 30 Train loss 3.45 on epoch=2
06/01/2022 08:34:56 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=2
06/01/2022 08:34:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.55 on epoch=3
06/01/2022 08:35:04 - INFO - __main__ - Global step 50 Train loss 3.77 Classification-F1 0.0459965261361653 on epoch=3
06/01/2022 08:35:04 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0459965261361653 on epoch=3, global_step=50
06/01/2022 08:35:07 - INFO - __main__ - Step 60 Global step 60 Train loss 2.35 on epoch=4
06/01/2022 08:35:10 - INFO - __main__ - Step 70 Global step 70 Train loss 1.86 on epoch=4
06/01/2022 08:35:12 - INFO - __main__ - Step 80 Global step 80 Train loss 1.70 on epoch=5
06/01/2022 08:35:15 - INFO - __main__ - Step 90 Global step 90 Train loss 1.49 on epoch=6
06/01/2022 08:35:17 - INFO - __main__ - Step 100 Global step 100 Train loss 1.34 on epoch=7
06/01/2022 08:35:24 - INFO - __main__ - Global step 100 Train loss 1.75 Classification-F1 0.1978972384476219 on epoch=7
06/01/2022 08:35:24 - INFO - __main__ - Saving model with best Classification-F1: 0.0459965261361653 -> 0.1978972384476219 on epoch=7, global_step=100
06/01/2022 08:35:26 - INFO - __main__ - Step 110 Global step 110 Train loss 1.17 on epoch=7
06/01/2022 08:35:29 - INFO - __main__ - Step 120 Global step 120 Train loss 1.10 on epoch=8
06/01/2022 08:35:32 - INFO - __main__ - Step 130 Global step 130 Train loss 1.05 on epoch=9
06/01/2022 08:35:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=9
06/01/2022 08:35:37 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=10
06/01/2022 08:35:44 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.4517781766132206 on epoch=10
06/01/2022 08:35:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1978972384476219 -> 0.4517781766132206 on epoch=10, global_step=150
06/01/2022 08:35:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=11
06/01/2022 08:35:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=12
06/01/2022 08:35:52 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=12
06/01/2022 08:35:54 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=13
06/01/2022 08:35:57 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=14
06/01/2022 08:36:05 - INFO - __main__ - Global step 200 Train loss 0.75 Classification-F1 0.6468250093250094 on epoch=14
06/01/2022 08:36:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4517781766132206 -> 0.6468250093250094 on epoch=14, global_step=200
06/01/2022 08:36:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=14
06/01/2022 08:36:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=15
06/01/2022 08:36:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=16
06/01/2022 08:36:15 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=17
06/01/2022 08:36:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=17
06/01/2022 08:36:25 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.5814046501373691 on epoch=17
06/01/2022 08:36:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=18
06/01/2022 08:36:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=19
06/01/2022 08:36:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=19
06/01/2022 08:36:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=20
06/01/2022 08:36:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=21
06/01/2022 08:36:46 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.6006744966909039 on epoch=21
06/01/2022 08:36:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=22
06/01/2022 08:36:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=22
06/01/2022 08:36:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
06/01/2022 08:36:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/01/2022 08:36:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
06/01/2022 08:37:06 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.6387209562007906 on epoch=24
06/01/2022 08:37:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=25
06/01/2022 08:37:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=26
06/01/2022 08:37:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=27
06/01/2022 08:37:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=27
06/01/2022 08:37:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=28
06/01/2022 08:37:26 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.7132432991052815 on epoch=28
06/01/2022 08:37:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6468250093250094 -> 0.7132432991052815 on epoch=28, global_step=400
06/01/2022 08:37:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=29
06/01/2022 08:37:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
06/01/2022 08:37:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=30
06/01/2022 08:37:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.42 on epoch=31
06/01/2022 08:37:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=32
06/01/2022 08:37:46 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.7652211746694352 on epoch=32
06/01/2022 08:37:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7132432991052815 -> 0.7652211746694352 on epoch=32, global_step=450
06/01/2022 08:37:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=32
06/01/2022 08:37:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/01/2022 08:37:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=34
06/01/2022 08:37:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=34
06/01/2022 08:37:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=35
06/01/2022 08:38:06 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.7081137170061975 on epoch=35
06/01/2022 08:38:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=36
06/01/2022 08:38:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=37
06/01/2022 08:38:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/01/2022 08:38:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=38
06/01/2022 08:38:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=39
06/01/2022 08:38:27 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.7173505523698549 on epoch=39
06/01/2022 08:38:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=39
06/01/2022 08:38:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=40
06/01/2022 08:38:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/01/2022 08:38:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=42
06/01/2022 08:38:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/01/2022 08:38:48 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.7217741014901258 on epoch=42
06/01/2022 08:38:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=43
06/01/2022 08:38:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=44
06/01/2022 08:38:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/01/2022 08:38:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=45
06/01/2022 08:39:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=46
06/01/2022 08:39:08 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.7685649822836056 on epoch=46
06/01/2022 08:39:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7652211746694352 -> 0.7685649822836056 on epoch=46, global_step=650
06/01/2022 08:39:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/01/2022 08:39:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=47
06/01/2022 08:39:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=48
06/01/2022 08:39:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
06/01/2022 08:39:21 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=49
06/01/2022 08:39:28 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6787784721252463 on epoch=49
06/01/2022 08:39:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=50
06/01/2022 08:39:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/01/2022 08:39:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/01/2022 08:39:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/01/2022 08:39:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=53
06/01/2022 08:39:48 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.7334375174007183 on epoch=53
06/01/2022 08:39:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=54
06/01/2022 08:39:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
06/01/2022 08:39:56 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=55
06/01/2022 08:39:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/01/2022 08:40:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=57
06/01/2022 08:40:07 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.6535976789659933 on epoch=57
06/01/2022 08:40:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/01/2022 08:40:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=58
06/01/2022 08:40:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/01/2022 08:40:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=59
06/01/2022 08:40:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/01/2022 08:40:27 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7275948669489724 on epoch=60
06/01/2022 08:40:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/01/2022 08:40:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/01/2022 08:40:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/01/2022 08:40:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/01/2022 08:40:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/01/2022 08:40:47 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7852836562570881 on epoch=64
06/01/2022 08:40:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7685649822836056 -> 0.7852836562570881 on epoch=64, global_step=900
06/01/2022 08:40:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
06/01/2022 08:40:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/01/2022 08:40:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=66
06/01/2022 08:40:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/01/2022 08:41:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=67
06/01/2022 08:41:08 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.8064286125007187 on epoch=67
06/01/2022 08:41:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7852836562570881 -> 0.8064286125007187 on epoch=67, global_step=950
06/01/2022 08:41:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=68
06/01/2022 08:41:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
06/01/2022 08:41:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/01/2022 08:41:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/01/2022 08:41:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/01/2022 08:41:28 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.7801398711977461 on epoch=71
06/01/2022 08:41:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.15 on epoch=72
06/01/2022 08:41:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/01/2022 08:41:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/01/2022 08:41:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/01/2022 08:41:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/01/2022 08:41:48 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7869393651888908 on epoch=74
06/01/2022 08:41:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/01/2022 08:41:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/01/2022 08:41:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=77
06/01/2022 08:41:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/01/2022 08:42:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/01/2022 08:42:08 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8910116343702683 on epoch=78
06/01/2022 08:42:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8064286125007187 -> 0.8910116343702683 on epoch=78, global_step=1100
06/01/2022 08:42:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/01/2022 08:42:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/01/2022 08:42:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/01/2022 08:42:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=81
06/01/2022 08:42:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=82
06/01/2022 08:42:28 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7431800151321024 on epoch=82
06/01/2022 08:42:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/01/2022 08:42:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/01/2022 08:42:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=84
06/01/2022 08:42:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=84
06/01/2022 08:42:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=85
06/01/2022 08:42:48 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8389950883635656 on epoch=85
06/01/2022 08:42:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/01/2022 08:42:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/01/2022 08:42:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/01/2022 08:42:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=88
06/01/2022 08:43:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=89
06/01/2022 08:43:08 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7752655543662255 on epoch=89
06/01/2022 08:43:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/01/2022 08:43:13 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=90
06/01/2022 08:43:16 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=91
06/01/2022 08:43:18 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/01/2022 08:43:21 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/01/2022 08:43:29 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.881852648195153 on epoch=92
06/01/2022 08:43:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/01/2022 08:43:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=94
06/01/2022 08:43:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/01/2022 08:43:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=95
06/01/2022 08:43:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/01/2022 08:43:48 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8689733355055935 on epoch=96
06/01/2022 08:43:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/01/2022 08:43:54 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/01/2022 08:43:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/01/2022 08:43:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/01/2022 08:44:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/01/2022 08:44:09 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.8947382308357064 on epoch=99
06/01/2022 08:44:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8910116343702683 -> 0.8947382308357064 on epoch=99, global_step=1400
06/01/2022 08:44:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/01/2022 08:44:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=101
06/01/2022 08:44:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/01/2022 08:44:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/01/2022 08:44:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=103
06/01/2022 08:44:29 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.8859045524368104 on epoch=103
06/01/2022 08:44:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/01/2022 08:44:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/01/2022 08:44:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=105
06/01/2022 08:44:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=106
06/01/2022 08:44:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/01/2022 08:44:49 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8782591091177427 on epoch=107
06/01/2022 08:44:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/01/2022 08:44:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/01/2022 08:44:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 08:44:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=109
06/01/2022 08:45:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/01/2022 08:45:09 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8766373411534703 on epoch=110
06/01/2022 08:45:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/01/2022 08:45:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/01/2022 08:45:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/01/2022 08:45:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/01/2022 08:45:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/01/2022 08:45:29 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8867905917520224 on epoch=114
06/01/2022 08:45:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/01/2022 08:45:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/01/2022 08:45:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 08:45:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/01/2022 08:45:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/01/2022 08:45:49 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8820078160891626 on epoch=117
06/01/2022 08:45:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/01/2022 08:45:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/01/2022 08:45:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/01/2022 08:45:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/01/2022 08:46:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/01/2022 08:46:08 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.8863157461577416 on epoch=121
06/01/2022 08:46:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/01/2022 08:46:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/01/2022 08:46:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/01/2022 08:46:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/01/2022 08:46:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/01/2022 08:46:28 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8905221570544152 on epoch=124
06/01/2022 08:46:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/01/2022 08:46:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=126
06/01/2022 08:46:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/01/2022 08:46:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/01/2022 08:46:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/01/2022 08:46:48 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8905221570544152 on epoch=128
06/01/2022 08:46:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/01/2022 08:46:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/01/2022 08:46:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 08:46:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/01/2022 08:47:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/01/2022 08:47:08 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9084795083450996 on epoch=132
06/01/2022 08:47:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8947382308357064 -> 0.9084795083450996 on epoch=132, global_step=1850
06/01/2022 08:47:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=132
06/01/2022 08:47:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/01/2022 08:47:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=134
06/01/2022 08:47:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=134
06/01/2022 08:47:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/01/2022 08:47:28 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9028788931556714 on epoch=135
06/01/2022 08:47:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/01/2022 08:47:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/01/2022 08:47:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/01/2022 08:47:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 08:47:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/01/2022 08:47:48 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9028788931556714 on epoch=139
06/01/2022 08:47:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/01/2022 08:47:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 08:47:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/01/2022 08:47:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=142
06/01/2022 08:48:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/01/2022 08:48:08 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.9777884394226899 on epoch=142
06/01/2022 08:48:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9084795083450996 -> 0.9777884394226899 on epoch=142, global_step=2000
06/01/2022 08:48:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/01/2022 08:48:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.14 on epoch=144
06/01/2022 08:48:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/01/2022 08:48:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 08:48:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/01/2022 08:48:27 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9084795083450996 on epoch=146
06/01/2022 08:48:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 08:48:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/01/2022 08:48:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/01/2022 08:48:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 08:48:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/01/2022 08:48:47 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8859045524368104 on epoch=149
06/01/2022 08:48:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 08:48:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/01/2022 08:48:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/01/2022 08:48:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 08:49:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 08:49:06 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8484028068705488 on epoch=153
06/01/2022 08:49:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/01/2022 08:49:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 08:49:14 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 08:49:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/01/2022 08:49:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/01/2022 08:49:26 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9097407894293322 on epoch=157
06/01/2022 08:49:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/01/2022 08:49:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/01/2022 08:49:34 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/01/2022 08:49:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/01/2022 08:49:39 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 08:49:45 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=160
06/01/2022 08:49:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9777884394226899 -> 0.9865984150258343 on epoch=160, global_step=2250
06/01/2022 08:49:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/01/2022 08:49:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 08:49:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/01/2022 08:49:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 08:49:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 08:50:05 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=164
06/01/2022 08:50:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/01/2022 08:50:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/01/2022 08:50:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 08:50:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 08:50:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/01/2022 08:50:25 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=167
06/01/2022 08:50:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 08:50:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/01/2022 08:50:33 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 08:50:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 08:50:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/01/2022 08:50:45 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9186746497230369 on epoch=171
06/01/2022 08:50:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=172
06/01/2022 08:50:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/01/2022 08:50:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/01/2022 08:50:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/01/2022 08:50:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/01/2022 08:51:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.916380742913001 on epoch=174
06/01/2022 08:51:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/01/2022 08:51:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/01/2022 08:51:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 08:51:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 08:51:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 08:51:25 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8979706744868036 on epoch=178
06/01/2022 08:51:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/01/2022 08:51:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 08:51:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/01/2022 08:51:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/01/2022 08:51:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/01/2022 08:51:45 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9097407894293322 on epoch=182
06/01/2022 08:51:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/01/2022 08:51:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/01/2022 08:51:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/01/2022 08:51:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/01/2022 08:51:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/01/2022 08:52:05 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9139286356333076 on epoch=185
06/01/2022 08:52:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 08:52:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 08:52:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/01/2022 08:52:16 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 08:52:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/01/2022 08:52:25 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9022770664690335 on epoch=189
06/01/2022 08:52:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/01/2022 08:52:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/01/2022 08:52:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/01/2022 08:52:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/01/2022 08:52:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/01/2022 08:52:45 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9139286356333076 on epoch=192
06/01/2022 08:52:48 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/01/2022 08:52:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 08:52:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 08:52:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 08:52:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 08:53:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.912223036819811 on epoch=196
06/01/2022 08:53:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/01/2022 08:53:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/01/2022 08:53:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=198
06/01/2022 08:53:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/01/2022 08:53:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 08:53:25 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8817167062328353 on epoch=199
06/01/2022 08:53:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 08:53:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 08:53:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/01/2022 08:53:36 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/01/2022 08:53:39 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 08:53:45 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8734301635171884 on epoch=203
06/01/2022 08:53:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 08:53:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 08:53:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 08:53:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/01/2022 08:53:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 08:54:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8864984803900735 on epoch=207
06/01/2022 08:54:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/01/2022 08:54:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/01/2022 08:54:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/01/2022 08:54:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 08:54:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 08:54:25 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8863113104479329 on epoch=210
06/01/2022 08:54:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 08:54:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 08:54:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 08:54:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 08:54:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 08:54:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:54:40 - INFO - __main__ - Printing 3 examples
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:54:40 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:54:40 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:54:40 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:54:40 - INFO - __main__ - Printing 3 examples
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:54:40 - INFO - __main__ - ['Animal']
06/01/2022 08:54:40 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:54:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:54:41 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:54:45 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8979706744868036 on epoch=214
06/01/2022 08:54:45 - INFO - __main__ - save last model!
06/01/2022 08:54:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 08:54:45 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 08:54:45 - INFO - __main__ - Printing 3 examples
06/01/2022 08:54:45 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 08:54:45 - INFO - __main__ - ['Animal']
06/01/2022 08:54:45 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 08:54:45 - INFO - __main__ - ['Animal']
06/01/2022 08:54:45 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 08:54:45 - INFO - __main__ - ['Village']
06/01/2022 08:54:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:54:47 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:54:51 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 08:54:59 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:55:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:55:00 - INFO - __main__ - Starting training!
06/01/2022 08:56:57 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_100_0.3_8_predictions.txt
06/01/2022 08:56:57 - INFO - __main__ - Classification-F1 on test data: 0.6730
06/01/2022 08:56:57 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.3, bsz=8, dev_performance=0.9865984150258343, test_performance=0.6730076408874761
06/01/2022 08:56:57 - INFO - __main__ - Running ... prefix=dbpedia_14_16_100, lr=0.2, bsz=8 ...
06/01/2022 08:56:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:56:58 - INFO - __main__ - Printing 3 examples
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:56:58 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:56:58 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 08:56:58 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 08:56:58 - INFO - __main__ - Printing 3 examples
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Mesoscincus is a genus comprising three species of skink native to Mexico and Central America. They were formerly included in the genus Eumeces.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Oxynoemacheilus leontinae is a species of stone loach found in Israel Jordan Lebanon and Syria.Its natural habitat is rivers.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ -  [dbpedia_14] Syrmoptera homeyerii is a butterfly in the Lycaenidae family. It is found in the Democratic Republic of Congo (Uele Sankuru Lualaba Lomani Tanganika and Maniema) and Angola.
06/01/2022 08:56:58 - INFO - __main__ - ['Animal']
06/01/2022 08:56:58 - INFO - __main__ - Tokenizing Input ...
06/01/2022 08:56:59 - INFO - __main__ - Tokenizing Output ...
06/01/2022 08:56:59 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 08:57:15 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 08:57:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 08:57:15 - INFO - __main__ - Starting training!
06/01/2022 08:57:19 - INFO - __main__ - Step 10 Global step 10 Train loss 5.86 on epoch=0
06/01/2022 08:57:22 - INFO - __main__ - Step 20 Global step 20 Train loss 4.87 on epoch=1
06/01/2022 08:57:24 - INFO - __main__ - Step 30 Global step 30 Train loss 4.10 on epoch=2
06/01/2022 08:57:27 - INFO - __main__ - Step 40 Global step 40 Train loss 3.46 on epoch=2
06/01/2022 08:57:29 - INFO - __main__ - Step 50 Global step 50 Train loss 3.16 on epoch=3
06/01/2022 08:57:35 - INFO - __main__ - Global step 50 Train loss 4.29 Classification-F1 0.03780846164807884 on epoch=3
06/01/2022 08:57:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03780846164807884 on epoch=3, global_step=50
06/01/2022 08:57:38 - INFO - __main__ - Step 60 Global step 60 Train loss 2.93 on epoch=4
06/01/2022 08:57:41 - INFO - __main__ - Step 70 Global step 70 Train loss 2.47 on epoch=4
06/01/2022 08:57:43 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=5
06/01/2022 08:57:46 - INFO - __main__ - Step 90 Global step 90 Train loss 2.09 on epoch=6
06/01/2022 08:57:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.85 on epoch=7
06/01/2022 08:57:54 - INFO - __main__ - Global step 100 Train loss 2.36 Classification-F1 0.08909592440909474 on epoch=7
06/01/2022 08:57:54 - INFO - __main__ - Saving model with best Classification-F1: 0.03780846164807884 -> 0.08909592440909474 on epoch=7, global_step=100
06/01/2022 08:57:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.71 on epoch=7
06/01/2022 08:58:00 - INFO - __main__ - Step 120 Global step 120 Train loss 1.59 on epoch=8
06/01/2022 08:58:02 - INFO - __main__ - Step 130 Global step 130 Train loss 1.53 on epoch=9
06/01/2022 08:58:05 - INFO - __main__ - Step 140 Global step 140 Train loss 1.16 on epoch=9
06/01/2022 08:58:07 - INFO - __main__ - Step 150 Global step 150 Train loss 1.31 on epoch=10
06/01/2022 08:58:14 - INFO - __main__ - Global step 150 Train loss 1.46 Classification-F1 0.23562440696203044 on epoch=10
06/01/2022 08:58:14 - INFO - __main__ - Saving model with best Classification-F1: 0.08909592440909474 -> 0.23562440696203044 on epoch=10, global_step=150
06/01/2022 08:58:17 - INFO - __main__ - Step 160 Global step 160 Train loss 1.23 on epoch=11
06/01/2022 08:58:20 - INFO - __main__ - Step 170 Global step 170 Train loss 1.04 on epoch=12
06/01/2022 08:58:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=12
06/01/2022 08:58:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.94 on epoch=13
06/01/2022 08:58:27 - INFO - __main__ - Step 200 Global step 200 Train loss 1.00 on epoch=14
06/01/2022 08:58:35 - INFO - __main__ - Global step 200 Train loss 1.03 Classification-F1 0.3766351429438193 on epoch=14
06/01/2022 08:58:35 - INFO - __main__ - Saving model with best Classification-F1: 0.23562440696203044 -> 0.3766351429438193 on epoch=14, global_step=200
06/01/2022 08:58:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=14
06/01/2022 08:58:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=15
06/01/2022 08:58:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=16
06/01/2022 08:58:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.87 on epoch=17
06/01/2022 08:58:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.68 on epoch=17
06/01/2022 08:58:56 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.48425303966581235 on epoch=17
06/01/2022 08:58:56 - INFO - __main__ - Saving model with best Classification-F1: 0.3766351429438193 -> 0.48425303966581235 on epoch=17, global_step=250
06/01/2022 08:58:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=18
06/01/2022 08:59:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=19
06/01/2022 08:59:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=19
06/01/2022 08:59:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=20
06/01/2022 08:59:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=21
06/01/2022 08:59:16 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.5316329992008282 on epoch=21
06/01/2022 08:59:16 - INFO - __main__ - Saving model with best Classification-F1: 0.48425303966581235 -> 0.5316329992008282 on epoch=21, global_step=300
06/01/2022 08:59:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=22
06/01/2022 08:59:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=22
06/01/2022 08:59:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.62 on epoch=23
06/01/2022 08:59:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=24
06/01/2022 08:59:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=24
06/01/2022 08:59:36 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.5443915359322099 on epoch=24
06/01/2022 08:59:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5316329992008282 -> 0.5443915359322099 on epoch=24, global_step=350
06/01/2022 08:59:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=25
06/01/2022 08:59:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=26
06/01/2022 08:59:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=27
06/01/2022 08:59:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
06/01/2022 08:59:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.51 on epoch=28
06/01/2022 08:59:57 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5559661148818529 on epoch=28
06/01/2022 08:59:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5443915359322099 -> 0.5559661148818529 on epoch=28, global_step=400
06/01/2022 08:59:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=29
06/01/2022 09:00:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=29
06/01/2022 09:00:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=30
06/01/2022 09:00:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.46 on epoch=31
06/01/2022 09:00:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=32
06/01/2022 09:00:17 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.6581163168653458 on epoch=32
06/01/2022 09:00:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5559661148818529 -> 0.6581163168653458 on epoch=32, global_step=450
06/01/2022 09:00:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=32
06/01/2022 09:00:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.46 on epoch=33
06/01/2022 09:00:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=34
06/01/2022 09:00:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=34
06/01/2022 09:00:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
06/01/2022 09:00:38 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.6992100749292584 on epoch=35
06/01/2022 09:00:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6581163168653458 -> 0.6992100749292584 on epoch=35, global_step=500
06/01/2022 09:00:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=36
06/01/2022 09:00:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=37
06/01/2022 09:00:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/01/2022 09:00:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
06/01/2022 09:00:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=39
06/01/2022 09:00:58 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.7052564026235753 on epoch=39
06/01/2022 09:00:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6992100749292584 -> 0.7052564026235753 on epoch=39, global_step=550
06/01/2022 09:01:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=39
06/01/2022 09:01:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=40
06/01/2022 09:01:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.45 on epoch=41
06/01/2022 09:01:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
06/01/2022 09:01:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=42
06/01/2022 09:01:19 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.7069666690397242 on epoch=42
06/01/2022 09:01:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7052564026235753 -> 0.7069666690397242 on epoch=42, global_step=600
06/01/2022 09:01:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=43
06/01/2022 09:01:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=44
06/01/2022 09:01:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/01/2022 09:01:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.28 on epoch=45
06/01/2022 09:01:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.32 on epoch=46
06/01/2022 09:01:39 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.667444224958605 on epoch=46
06/01/2022 09:01:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=47
06/01/2022 09:01:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=47
06/01/2022 09:01:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=48
06/01/2022 09:01:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=49
06/01/2022 09:01:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=49
06/01/2022 09:01:59 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.7072036160118458 on epoch=49
06/01/2022 09:01:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7069666690397242 -> 0.7072036160118458 on epoch=49, global_step=700
06/01/2022 09:02:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=50
06/01/2022 09:02:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.28 on epoch=51
06/01/2022 09:02:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/01/2022 09:02:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=52
06/01/2022 09:02:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=53
06/01/2022 09:02:19 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.7052468046041946 on epoch=53
06/01/2022 09:02:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=54
06/01/2022 09:02:25 - INFO - __main__ - Step 770 Global step 770 Train loss 0.30 on epoch=54
06/01/2022 09:02:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=55
06/01/2022 09:02:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=56
06/01/2022 09:02:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=57
06/01/2022 09:02:40 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.7221729985117539 on epoch=57
06/01/2022 09:02:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7072036160118458 -> 0.7221729985117539 on epoch=57, global_step=800
06/01/2022 09:02:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=57
06/01/2022 09:02:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=58
06/01/2022 09:02:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=59
06/01/2022 09:02:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
06/01/2022 09:02:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=60
06/01/2022 09:03:00 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.6775811307187559 on epoch=60
06/01/2022 09:03:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=61
06/01/2022 09:03:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=62
06/01/2022 09:03:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/01/2022 09:03:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=63
06/01/2022 09:03:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=64
06/01/2022 09:03:20 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.6479281708254642 on epoch=64
06/01/2022 09:03:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=64
06/01/2022 09:03:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
06/01/2022 09:03:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.18 on epoch=66
06/01/2022 09:03:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=67
06/01/2022 09:03:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=67
06/01/2022 09:03:40 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6513592603046481 on epoch=67
06/01/2022 09:03:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
06/01/2022 09:03:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=69
06/01/2022 09:03:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=69
06/01/2022 09:03:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/01/2022 09:03:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=71
06/01/2022 09:04:00 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.6481899088386518 on epoch=71
06/01/2022 09:04:02 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.25 on epoch=72
06/01/2022 09:04:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=72
06/01/2022 09:04:07 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=73
06/01/2022 09:04:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=74
06/01/2022 09:04:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
06/01/2022 09:04:19 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.622705410555309 on epoch=74
06/01/2022 09:04:22 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
06/01/2022 09:04:25 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
06/01/2022 09:04:27 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=77
06/01/2022 09:04:30 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=77
06/01/2022 09:04:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=78
06/01/2022 09:04:39 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6997623291740939 on epoch=78
06/01/2022 09:04:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/01/2022 09:04:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
06/01/2022 09:04:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=80
06/01/2022 09:04:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=81
06/01/2022 09:04:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/01/2022 09:04:58 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.658071397763591 on epoch=82
06/01/2022 09:05:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/01/2022 09:05:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/01/2022 09:05:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/01/2022 09:05:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=84
06/01/2022 09:05:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=85
06/01/2022 09:05:18 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.7258478510784996 on epoch=85
06/01/2022 09:05:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7221729985117539 -> 0.7258478510784996 on epoch=85, global_step=1200
06/01/2022 09:05:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=86
06/01/2022 09:05:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=87
06/01/2022 09:05:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=87
06/01/2022 09:05:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
06/01/2022 09:05:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=89
06/01/2022 09:05:37 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.8150043039287023 on epoch=89
06/01/2022 09:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7258478510784996 -> 0.8150043039287023 on epoch=89, global_step=1250
06/01/2022 09:05:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/01/2022 09:05:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/01/2022 09:05:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=91
06/01/2022 09:05:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=92
06/01/2022 09:05:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=92
06/01/2022 09:05:57 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.796847125352077 on epoch=92
06/01/2022 09:05:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/01/2022 09:06:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=94
06/01/2022 09:06:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/01/2022 09:06:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/01/2022 09:06:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/01/2022 09:06:17 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.9733364753526043 on epoch=96
06/01/2022 09:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8150043039287023 -> 0.9733364753526043 on epoch=96, global_step=1350
06/01/2022 09:06:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/01/2022 09:06:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=97
06/01/2022 09:06:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=98
06/01/2022 09:06:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/01/2022 09:06:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=99
06/01/2022 09:06:37 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.740796396035696 on epoch=99
06/01/2022 09:06:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=100
06/01/2022 09:06:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
06/01/2022 09:06:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=102
06/01/2022 09:06:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/01/2022 09:06:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/01/2022 09:06:56 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.8999178420146163 on epoch=103
06/01/2022 09:06:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/01/2022 09:07:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/01/2022 09:07:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=105
06/01/2022 09:07:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/01/2022 09:07:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=107
06/01/2022 09:07:16 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.8376001518642647 on epoch=107
06/01/2022 09:07:18 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=107
06/01/2022 09:07:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=108
06/01/2022 09:07:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/01/2022 09:07:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=109
06/01/2022 09:07:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/01/2022 09:07:35 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.793333187164809 on epoch=110
06/01/2022 09:07:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=111
06/01/2022 09:07:41 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=112
06/01/2022 09:07:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/01/2022 09:07:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
06/01/2022 09:07:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/01/2022 09:07:55 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.7953429421157404 on epoch=114
06/01/2022 09:07:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
06/01/2022 09:08:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=115
06/01/2022 09:08:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/01/2022 09:08:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/01/2022 09:08:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
06/01/2022 09:08:15 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.8449174673958237 on epoch=117
06/01/2022 09:08:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/01/2022 09:08:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/01/2022 09:08:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/01/2022 09:08:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=120
06/01/2022 09:08:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/01/2022 09:08:34 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.8311872212786044 on epoch=121
06/01/2022 09:08:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/01/2022 09:08:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/01/2022 09:08:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/01/2022 09:08:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/01/2022 09:08:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/01/2022 09:08:54 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8491254905554597 on epoch=124
06/01/2022 09:08:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/01/2022 09:08:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/01/2022 09:09:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/01/2022 09:09:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/01/2022 09:09:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
06/01/2022 09:09:13 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7822377543392723 on epoch=128
06/01/2022 09:09:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=129
06/01/2022 09:09:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/01/2022 09:09:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/01/2022 09:09:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=131
06/01/2022 09:09:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.15 on epoch=132
06/01/2022 09:09:33 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7953429421157404 on epoch=132
06/01/2022 09:09:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=132
06/01/2022 09:09:38 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/01/2022 09:09:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/01/2022 09:09:43 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/01/2022 09:09:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=135
06/01/2022 09:09:53 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8305981845281537 on epoch=135
06/01/2022 09:09:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=136
06/01/2022 09:09:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/01/2022 09:10:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/01/2022 09:10:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/01/2022 09:10:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/01/2022 09:10:13 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7924470145139305 on epoch=139
06/01/2022 09:10:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=139
06/01/2022 09:10:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=140
06/01/2022 09:10:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/01/2022 09:10:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=142
06/01/2022 09:10:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/01/2022 09:10:32 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8146625020364939 on epoch=142
06/01/2022 09:10:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=143
06/01/2022 09:10:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/01/2022 09:10:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/01/2022 09:10:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 09:10:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=146
06/01/2022 09:10:52 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.8774048084531956 on epoch=146
06/01/2022 09:10:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=147
06/01/2022 09:10:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/01/2022 09:11:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/01/2022 09:11:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=149
06/01/2022 09:11:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/01/2022 09:11:12 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8218635447214075 on epoch=149
06/01/2022 09:11:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 09:11:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/01/2022 09:11:20 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=152
06/01/2022 09:11:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=152
06/01/2022 09:11:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/01/2022 09:11:32 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8865361215845087 on epoch=153
06/01/2022 09:11:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/01/2022 09:11:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/01/2022 09:11:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=155
06/01/2022 09:11:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/01/2022 09:11:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=157
06/01/2022 09:11:52 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8900233010716881 on epoch=157
06/01/2022 09:11:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=157
06/01/2022 09:11:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/01/2022 09:12:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/01/2022 09:12:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/01/2022 09:12:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/01/2022 09:12:12 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8491782257763556 on epoch=160
06/01/2022 09:12:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/01/2022 09:12:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 09:12:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 09:12:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=163
06/01/2022 09:12:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/01/2022 09:12:32 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.8514770763510683 on epoch=164
06/01/2022 09:12:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/01/2022 09:12:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/01/2022 09:12:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/01/2022 09:12:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/01/2022 09:12:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/01/2022 09:12:51 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9016472326956197 on epoch=167
06/01/2022 09:12:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 09:12:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/01/2022 09:12:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/01/2022 09:13:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/01/2022 09:13:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/01/2022 09:13:11 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7444671686328266 on epoch=171
06/01/2022 09:13:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=172
06/01/2022 09:13:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/01/2022 09:13:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=173
06/01/2022 09:13:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/01/2022 09:13:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/01/2022 09:13:30 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8547919668739676 on epoch=174
06/01/2022 09:13:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/01/2022 09:13:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/01/2022 09:13:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/01/2022 09:13:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 09:13:44 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 09:13:50 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8430376513793852 on epoch=178
06/01/2022 09:13:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/01/2022 09:13:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/01/2022 09:13:58 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/01/2022 09:14:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=181
06/01/2022 09:14:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 09:14:10 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7779919753438485 on epoch=182
06/01/2022 09:14:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 09:14:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/01/2022 09:14:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/01/2022 09:14:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 09:14:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/01/2022 09:14:29 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.782179634834786 on epoch=185
06/01/2022 09:14:32 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
06/01/2022 09:14:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 09:14:37 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/01/2022 09:14:40 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/01/2022 09:14:42 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 09:14:49 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8424402798142717 on epoch=189
06/01/2022 09:14:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/01/2022 09:14:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 09:14:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/01/2022 09:14:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/01/2022 09:15:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/01/2022 09:15:08 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7838756645153055 on epoch=192
06/01/2022 09:15:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/01/2022 09:15:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 09:15:16 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 09:15:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 09:15:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/01/2022 09:15:28 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7997020329800215 on epoch=196
06/01/2022 09:15:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 09:15:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/01/2022 09:15:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 09:15:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/01/2022 09:15:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=199
06/01/2022 09:15:48 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7904229790933106 on epoch=199
06/01/2022 09:15:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 09:15:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/01/2022 09:15:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 09:15:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 09:16:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 09:16:08 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7384154274783142 on epoch=203
06/01/2022 09:16:10 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=204
06/01/2022 09:16:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/01/2022 09:16:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 09:16:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/01/2022 09:16:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/01/2022 09:16:27 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7487838991564537 on epoch=207
06/01/2022 09:16:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=207
06/01/2022 09:16:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 09:16:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/01/2022 09:16:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=209
06/01/2022 09:16:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/01/2022 09:16:47 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8827386875103649 on epoch=210
06/01/2022 09:16:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 09:16:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 09:16:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/01/2022 09:16:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/01/2022 09:17:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 09:17:01 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:17:01 - INFO - __main__ - Printing 3 examples
06/01/2022 09:17:01 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 09:17:01 - INFO - __main__ - ['Animal']
06/01/2022 09:17:01 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 09:17:01 - INFO - __main__ - ['Animal']
06/01/2022 09:17:01 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 09:17:01 - INFO - __main__ - ['Animal']
06/01/2022 09:17:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:17:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:17:02 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 09:17:02 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:17:02 - INFO - __main__ - Printing 3 examples
06/01/2022 09:17:02 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 09:17:02 - INFO - __main__ - ['Animal']
06/01/2022 09:17:02 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 09:17:02 - INFO - __main__ - ['Animal']
06/01/2022 09:17:02 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 09:17:02 - INFO - __main__ - ['Animal']
06/01/2022 09:17:02 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:17:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:17:02 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 09:17:07 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.832246307120299 on epoch=214
06/01/2022 09:17:07 - INFO - __main__ - save last model!
06/01/2022 09:17:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 09:17:07 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 09:17:07 - INFO - __main__ - Printing 3 examples
06/01/2022 09:17:07 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 09:17:07 - INFO - __main__ - ['Animal']
06/01/2022 09:17:07 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 09:17:07 - INFO - __main__ - ['Animal']
06/01/2022 09:17:07 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 09:17:07 - INFO - __main__ - ['Village']
06/01/2022 09:17:07 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:17:08 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:17:12 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 09:17:18 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 09:17:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 09:17:19 - INFO - __main__ - Starting training!
06/01/2022 09:19:21 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_100_0.2_8_predictions.txt
06/01/2022 09:19:21 - INFO - __main__ - Classification-F1 on test data: 0.6122
06/01/2022 09:19:21 - INFO - __main__ - prefix=dbpedia_14_16_100, lr=0.2, bsz=8, dev_performance=0.9733364753526043, test_performance=0.6121581630439296
06/01/2022 09:19:21 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.5, bsz=8 ...
06/01/2022 09:19:22 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:19:22 - INFO - __main__ - Printing 3 examples
06/01/2022 09:19:22 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 09:19:22 - INFO - __main__ - ['Animal']
06/01/2022 09:19:22 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 09:19:22 - INFO - __main__ - ['Animal']
06/01/2022 09:19:22 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 09:19:22 - INFO - __main__ - ['Animal']
06/01/2022 09:19:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:19:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:19:23 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 09:19:23 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:19:23 - INFO - __main__ - Printing 3 examples
06/01/2022 09:19:23 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 09:19:23 - INFO - __main__ - ['Animal']
06/01/2022 09:19:23 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 09:19:23 - INFO - __main__ - ['Animal']
06/01/2022 09:19:23 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 09:19:23 - INFO - __main__ - ['Animal']
06/01/2022 09:19:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:19:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:19:23 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 09:19:38 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 09:19:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 09:19:38 - INFO - __main__ - Starting training!
06/01/2022 09:19:42 - INFO - __main__ - Step 10 Global step 10 Train loss 4.94 on epoch=0
06/01/2022 09:19:45 - INFO - __main__ - Step 20 Global step 20 Train loss 3.45 on epoch=1
06/01/2022 09:19:47 - INFO - __main__ - Step 30 Global step 30 Train loss 2.64 on epoch=2
06/01/2022 09:19:50 - INFO - __main__ - Step 40 Global step 40 Train loss 2.09 on epoch=2
06/01/2022 09:19:53 - INFO - __main__ - Step 50 Global step 50 Train loss 1.71 on epoch=3
06/01/2022 09:19:59 - INFO - __main__ - Global step 50 Train loss 2.97 Classification-F1 0.10641714429221355 on epoch=3
06/01/2022 09:19:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10641714429221355 on epoch=3, global_step=50
06/01/2022 09:20:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.48 on epoch=4
06/01/2022 09:20:04 - INFO - __main__ - Step 70 Global step 70 Train loss 1.18 on epoch=4
06/01/2022 09:20:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=5
06/01/2022 09:20:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=6
06/01/2022 09:20:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=7
06/01/2022 09:20:18 - INFO - __main__ - Global step 100 Train loss 1.07 Classification-F1 0.37432552408625597 on epoch=7
06/01/2022 09:20:18 - INFO - __main__ - Saving model with best Classification-F1: 0.10641714429221355 -> 0.37432552408625597 on epoch=7, global_step=100
06/01/2022 09:20:21 - INFO - __main__ - Step 110 Global step 110 Train loss 0.74 on epoch=7
06/01/2022 09:20:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=8
06/01/2022 09:20:26 - INFO - __main__ - Step 130 Global step 130 Train loss 0.67 on epoch=9
06/01/2022 09:20:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.51 on epoch=9
06/01/2022 09:20:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.57 on epoch=10
06/01/2022 09:20:39 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.4160619257197154 on epoch=10
06/01/2022 09:20:39 - INFO - __main__ - Saving model with best Classification-F1: 0.37432552408625597 -> 0.4160619257197154 on epoch=10, global_step=150
06/01/2022 09:20:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=11
06/01/2022 09:20:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.46 on epoch=12
06/01/2022 09:20:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.49 on epoch=12
06/01/2022 09:20:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.39 on epoch=13
06/01/2022 09:20:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.41 on epoch=14
06/01/2022 09:20:59 - INFO - __main__ - Global step 200 Train loss 0.46 Classification-F1 0.6515323952739795 on epoch=14
06/01/2022 09:20:59 - INFO - __main__ - Saving model with best Classification-F1: 0.4160619257197154 -> 0.6515323952739795 on epoch=14, global_step=200
06/01/2022 09:21:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.34 on epoch=14
06/01/2022 09:21:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=15
06/01/2022 09:21:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.43 on epoch=16
06/01/2022 09:21:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=17
06/01/2022 09:21:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=17
06/01/2022 09:21:18 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.60080062776274 on epoch=17
06/01/2022 09:21:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=18
06/01/2022 09:21:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.32 on epoch=19
06/01/2022 09:21:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=19
06/01/2022 09:21:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=20
06/01/2022 09:21:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.21 on epoch=21
06/01/2022 09:21:39 - INFO - __main__ - Global step 300 Train loss 0.31 Classification-F1 0.7016591700044819 on epoch=21
06/01/2022 09:21:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6515323952739795 -> 0.7016591700044819 on epoch=21, global_step=300
06/01/2022 09:21:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=22
06/01/2022 09:21:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=22
06/01/2022 09:21:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=23
06/01/2022 09:21:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.34 on epoch=24
06/01/2022 09:21:52 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=24
06/01/2022 09:21:59 - INFO - __main__ - Global step 350 Train loss 0.31 Classification-F1 0.7011674265798798 on epoch=24
06/01/2022 09:22:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.25 on epoch=25
06/01/2022 09:22:04 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=26
06/01/2022 09:22:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=27
06/01/2022 09:22:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=27
06/01/2022 09:22:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.21 on epoch=28
06/01/2022 09:22:19 - INFO - __main__ - Global step 400 Train loss 0.23 Classification-F1 0.8473511408762949 on epoch=28
06/01/2022 09:22:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7016591700044819 -> 0.8473511408762949 on epoch=28, global_step=400
06/01/2022 09:22:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=29
06/01/2022 09:22:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=29
06/01/2022 09:22:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.19 on epoch=30
06/01/2022 09:22:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.18 on epoch=31
06/01/2022 09:22:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=32
06/01/2022 09:22:39 - INFO - __main__ - Global step 450 Train loss 0.18 Classification-F1 0.6043859826722731 on epoch=32
06/01/2022 09:22:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
06/01/2022 09:22:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=33
06/01/2022 09:22:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
06/01/2022 09:22:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=34
06/01/2022 09:22:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=35
06/01/2022 09:22:59 - INFO - __main__ - Global step 500 Train loss 0.20 Classification-F1 0.5923315532435376 on epoch=35
06/01/2022 09:23:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/01/2022 09:23:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=37
06/01/2022 09:23:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=37
06/01/2022 09:23:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=38
06/01/2022 09:23:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/01/2022 09:23:19 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.5092429758256372 on epoch=39
06/01/2022 09:23:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/01/2022 09:23:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=40
06/01/2022 09:23:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=41
06/01/2022 09:23:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=42
06/01/2022 09:23:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=42
06/01/2022 09:23:39 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.537825859828995 on epoch=42
06/01/2022 09:23:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=43
06/01/2022 09:23:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=44
06/01/2022 09:23:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=44
06/01/2022 09:23:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=45
06/01/2022 09:23:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=46
06/01/2022 09:23:58 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.5562536982192416 on epoch=46
06/01/2022 09:24:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=47
06/01/2022 09:24:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=47
06/01/2022 09:24:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=48
06/01/2022 09:24:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
06/01/2022 09:24:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
06/01/2022 09:24:18 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.607088596886984 on epoch=49
06/01/2022 09:24:20 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=50
06/01/2022 09:24:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/01/2022 09:24:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=52
06/01/2022 09:24:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/01/2022 09:24:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
06/01/2022 09:24:37 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6570788666634236 on epoch=53
06/01/2022 09:24:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=54
06/01/2022 09:24:43 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=54
06/01/2022 09:24:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=55
06/01/2022 09:24:48 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/01/2022 09:24:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/01/2022 09:24:57 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6838526928001345 on epoch=57
06/01/2022 09:25:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=57
06/01/2022 09:25:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=58
06/01/2022 09:25:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=59
06/01/2022 09:25:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/01/2022 09:25:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/01/2022 09:25:16 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.6106200431678286 on epoch=60
06/01/2022 09:25:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
06/01/2022 09:25:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/01/2022 09:25:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=62
06/01/2022 09:25:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
06/01/2022 09:25:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/01/2022 09:25:36 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7407099091145861 on epoch=64
06/01/2022 09:25:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=64
06/01/2022 09:25:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/01/2022 09:25:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/01/2022 09:25:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/01/2022 09:25:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/01/2022 09:25:55 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6177917577099266 on epoch=67
06/01/2022 09:25:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
06/01/2022 09:26:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/01/2022 09:26:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/01/2022 09:26:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/01/2022 09:26:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=71
06/01/2022 09:26:14 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.65138573933141 on epoch=71
06/01/2022 09:26:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/01/2022 09:26:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/01/2022 09:26:22 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/01/2022 09:26:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/01/2022 09:26:27 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=74
06/01/2022 09:26:34 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.7087069986026342 on epoch=74
06/01/2022 09:26:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/01/2022 09:26:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=76
06/01/2022 09:26:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=77
06/01/2022 09:26:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/01/2022 09:26:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/01/2022 09:26:54 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8358064855544695 on epoch=78
06/01/2022 09:26:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=79
06/01/2022 09:26:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=79
06/01/2022 09:27:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/01/2022 09:27:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/01/2022 09:27:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/01/2022 09:27:13 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.8986171829435586 on epoch=82
06/01/2022 09:27:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8473511408762949 -> 0.8986171829435586 on epoch=82, global_step=1150
06/01/2022 09:27:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=82
06/01/2022 09:27:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/01/2022 09:27:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/01/2022 09:27:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/01/2022 09:27:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=85
06/01/2022 09:27:33 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.8956805510300133 on epoch=85
06/01/2022 09:27:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/01/2022 09:27:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=87
06/01/2022 09:27:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/01/2022 09:27:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=88
06/01/2022 09:27:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=89
06/01/2022 09:27:53 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.7312645542537416 on epoch=89
06/01/2022 09:27:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/01/2022 09:27:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/01/2022 09:28:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=91
06/01/2022 09:28:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=92
06/01/2022 09:28:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/01/2022 09:28:12 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8304742956250657 on epoch=92
06/01/2022 09:28:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/01/2022 09:28:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/01/2022 09:28:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/01/2022 09:28:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=95
06/01/2022 09:28:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/01/2022 09:28:32 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.9684338939337491 on epoch=96
06/01/2022 09:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8986171829435586 -> 0.9684338939337491 on epoch=96, global_step=1350
06/01/2022 09:28:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/01/2022 09:28:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/01/2022 09:28:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 09:28:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=99
06/01/2022 09:28:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/01/2022 09:28:51 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.9036965480229237 on epoch=99
06/01/2022 09:28:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/01/2022 09:28:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/01/2022 09:28:59 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/01/2022 09:29:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/01/2022 09:29:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=103
06/01/2022 09:29:10 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9019426235792458 on epoch=103
06/01/2022 09:29:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/01/2022 09:29:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/01/2022 09:29:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/01/2022 09:29:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=106
06/01/2022 09:29:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/01/2022 09:29:29 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8970948806259282 on epoch=107
06/01/2022 09:29:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 09:29:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=108
06/01/2022 09:29:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=109
06/01/2022 09:29:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/01/2022 09:29:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/01/2022 09:29:49 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.973139893787427 on epoch=110
06/01/2022 09:29:49 - INFO - __main__ - Saving model with best Classification-F1: 0.9684338939337491 -> 0.973139893787427 on epoch=110, global_step=1550
06/01/2022 09:29:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/01/2022 09:29:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/01/2022 09:29:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/01/2022 09:29:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/01/2022 09:30:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/01/2022 09:30:08 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8968909668562878 on epoch=114
06/01/2022 09:30:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/01/2022 09:30:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/01/2022 09:30:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/01/2022 09:30:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/01/2022 09:30:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=117
06/01/2022 09:30:27 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9035988921472793 on epoch=117
06/01/2022 09:30:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/01/2022 09:30:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=119
06/01/2022 09:30:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=119
06/01/2022 09:30:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/01/2022 09:30:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/01/2022 09:30:47 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8398081063640837 on epoch=121
06/01/2022 09:30:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/01/2022 09:30:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/01/2022 09:30:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/01/2022 09:30:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/01/2022 09:31:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/01/2022 09:31:06 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8968727545324635 on epoch=124
06/01/2022 09:31:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/01/2022 09:31:11 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/01/2022 09:31:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/01/2022 09:31:16 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/01/2022 09:31:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/01/2022 09:31:25 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.972812419537539 on epoch=128
06/01/2022 09:31:28 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/01/2022 09:31:31 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/01/2022 09:31:33 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/01/2022 09:31:36 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/01/2022 09:31:38 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/01/2022 09:31:45 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9027879225981692 on epoch=132
06/01/2022 09:31:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/01/2022 09:31:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=133
06/01/2022 09:31:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/01/2022 09:31:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/01/2022 09:31:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/01/2022 09:32:04 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7768140928577362 on epoch=135
06/01/2022 09:32:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/01/2022 09:32:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/01/2022 09:32:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=137
06/01/2022 09:32:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/01/2022 09:32:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/01/2022 09:32:23 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8994849099514414 on epoch=139
06/01/2022 09:32:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/01/2022 09:32:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 09:32:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/01/2022 09:32:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/01/2022 09:32:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=142
06/01/2022 09:32:42 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.834786299050412 on epoch=142
06/01/2022 09:32:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/01/2022 09:32:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/01/2022 09:32:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 09:32:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/01/2022 09:32:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/01/2022 09:33:02 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8890099995571762 on epoch=146
06/01/2022 09:33:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 09:33:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/01/2022 09:33:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/01/2022 09:33:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 09:33:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/01/2022 09:33:22 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9035178867785358 on epoch=149
06/01/2022 09:33:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/01/2022 09:33:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/01/2022 09:33:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/01/2022 09:33:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/01/2022 09:33:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/01/2022 09:33:41 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8936499679590042 on epoch=153
06/01/2022 09:33:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/01/2022 09:33:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/01/2022 09:33:49 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 09:33:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/01/2022 09:33:54 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/01/2022 09:34:01 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.973026534660785 on epoch=157
06/01/2022 09:34:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 09:34:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=158
06/01/2022 09:34:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/01/2022 09:34:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/01/2022 09:34:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 09:34:20 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.9101652674755142 on epoch=160
06/01/2022 09:34:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 09:34:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/01/2022 09:34:28 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/01/2022 09:34:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 09:34:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 09:34:39 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.972812419537539 on epoch=164
06/01/2022 09:34:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/01/2022 09:34:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/01/2022 09:34:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/01/2022 09:34:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=167
06/01/2022 09:34:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/01/2022 09:34:59 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.9728167834531932 on epoch=167
06/01/2022 09:35:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/01/2022 09:35:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/01/2022 09:35:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/01/2022 09:35:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/01/2022 09:35:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/01/2022 09:35:18 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9684754574799886 on epoch=171
06/01/2022 09:35:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 09:35:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/01/2022 09:35:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/01/2022 09:35:28 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/01/2022 09:35:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/01/2022 09:35:38 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9686895726032348 on epoch=174
06/01/2022 09:35:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/01/2022 09:35:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/01/2022 09:35:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 09:35:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 09:35:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 09:35:58 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9686895726032348 on epoch=178
06/01/2022 09:36:00 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 09:36:03 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/01/2022 09:36:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/01/2022 09:36:08 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/01/2022 09:36:11 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 09:36:17 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9643110469994449 on epoch=182
06/01/2022 09:36:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 09:36:22 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=183
06/01/2022 09:36:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/01/2022 09:36:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 09:36:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/01/2022 09:36:37 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9683524977389075 on epoch=185
06/01/2022 09:36:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 09:36:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 09:36:44 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=187
06/01/2022 09:36:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 09:36:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/01/2022 09:36:56 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9683524977389075 on epoch=189
06/01/2022 09:36:59 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 09:37:02 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 09:37:04 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 09:37:07 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/01/2022 09:37:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/01/2022 09:37:16 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9642376085331493 on epoch=192
06/01/2022 09:37:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/01/2022 09:37:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/01/2022 09:37:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 09:37:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/01/2022 09:37:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/01/2022 09:37:36 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9730308985764394 on epoch=196
06/01/2022 09:37:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 09:37:41 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 09:37:44 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 09:37:46 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/01/2022 09:37:49 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/01/2022 09:37:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9688155834181179 on epoch=199
06/01/2022 09:37:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 09:38:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 09:38:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/01/2022 09:38:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/01/2022 09:38:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 09:38:15 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9552593572569084 on epoch=203
06/01/2022 09:38:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/01/2022 09:38:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 09:38:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 09:38:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/01/2022 09:38:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/01/2022 09:38:34 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.973026534660785 on epoch=207
06/01/2022 09:38:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/01/2022 09:38:40 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/01/2022 09:38:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 09:38:45 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 09:38:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 09:38:54 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9019597301286107 on epoch=210
06/01/2022 09:38:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/01/2022 09:38:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/01/2022 09:39:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/01/2022 09:39:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 09:39:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/01/2022 09:39:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:39:09 - INFO - __main__ - Printing 3 examples
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:39:09 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:39:09 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 09:39:09 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:39:09 - INFO - __main__ - Printing 3 examples
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 09:39:09 - INFO - __main__ - ['Animal']
06/01/2022 09:39:09 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:39:09 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:39:09 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 09:39:14 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9773678606339897 on epoch=214
06/01/2022 09:39:14 - INFO - __main__ - Saving model with best Classification-F1: 0.973139893787427 -> 0.9773678606339897 on epoch=214, global_step=3000
06/01/2022 09:39:14 - INFO - __main__ - save last model!
06/01/2022 09:39:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 09:39:14 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 09:39:14 - INFO - __main__ - Printing 3 examples
06/01/2022 09:39:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 09:39:14 - INFO - __main__ - ['Animal']
06/01/2022 09:39:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 09:39:14 - INFO - __main__ - ['Animal']
06/01/2022 09:39:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 09:39:14 - INFO - __main__ - ['Village']
06/01/2022 09:39:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:39:16 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:39:19 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 09:39:28 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 09:39:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 09:39:29 - INFO - __main__ - Starting training!
06/01/2022 09:41:30 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_13_0.5_8_predictions.txt
06/01/2022 09:41:30 - INFO - __main__ - Classification-F1 on test data: 0.7631
06/01/2022 09:41:30 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.5, bsz=8, dev_performance=0.9773678606339897, test_performance=0.7631306285675925
06/01/2022 09:41:30 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.4, bsz=8 ...
06/01/2022 09:41:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:41:31 - INFO - __main__ - Printing 3 examples
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:41:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:41:31 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 09:41:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 09:41:31 - INFO - __main__ - Printing 3 examples
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 09:41:31 - INFO - __main__ - ['Animal']
06/01/2022 09:41:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 09:41:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 09:41:32 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 09:41:50 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 09:41:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 09:41:51 - INFO - __main__ - Starting training!
06/01/2022 09:41:55 - INFO - __main__ - Step 10 Global step 10 Train loss 5.27 on epoch=0
06/01/2022 09:41:57 - INFO - __main__ - Step 20 Global step 20 Train loss 3.95 on epoch=1
06/01/2022 09:42:00 - INFO - __main__ - Step 30 Global step 30 Train loss 3.09 on epoch=2
06/01/2022 09:42:03 - INFO - __main__ - Step 40 Global step 40 Train loss 2.50 on epoch=2
06/01/2022 09:42:05 - INFO - __main__ - Step 50 Global step 50 Train loss 2.08 on epoch=3
06/01/2022 09:42:11 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.07625736703481521 on epoch=3
06/01/2022 09:42:11 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07625736703481521 on epoch=3, global_step=50
06/01/2022 09:42:14 - INFO - __main__ - Step 60 Global step 60 Train loss 1.75 on epoch=4
06/01/2022 09:42:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.37 on epoch=4
06/01/2022 09:42:19 - INFO - __main__ - Step 80 Global step 80 Train loss 1.12 on epoch=5
06/01/2022 09:42:22 - INFO - __main__ - Step 90 Global step 90 Train loss 1.03 on epoch=6
06/01/2022 09:42:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=7
06/01/2022 09:42:31 - INFO - __main__ - Global step 100 Train loss 1.23 Classification-F1 0.3457047229104304 on epoch=7
06/01/2022 09:42:31 - INFO - __main__ - Saving model with best Classification-F1: 0.07625736703481521 -> 0.3457047229104304 on epoch=7, global_step=100
06/01/2022 09:42:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=7
06/01/2022 09:42:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=8
06/01/2022 09:42:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.70 on epoch=9
06/01/2022 09:42:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.60 on epoch=9
06/01/2022 09:42:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.57 on epoch=10
06/01/2022 09:42:52 - INFO - __main__ - Global step 150 Train loss 0.70 Classification-F1 0.5109513958795201 on epoch=10
06/01/2022 09:42:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3457047229104304 -> 0.5109513958795201 on epoch=10, global_step=150
06/01/2022 09:42:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=11
06/01/2022 09:42:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=12
06/01/2022 09:42:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=12
06/01/2022 09:43:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=13
06/01/2022 09:43:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=14
06/01/2022 09:43:12 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.641155046935792 on epoch=14
06/01/2022 09:43:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5109513958795201 -> 0.641155046935792 on epoch=14, global_step=200
06/01/2022 09:43:14 - INFO - __main__ - Step 210 Global step 210 Train loss 0.44 on epoch=14
06/01/2022 09:43:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=15
06/01/2022 09:43:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=16
06/01/2022 09:43:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=17
06/01/2022 09:43:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.41 on epoch=17
06/01/2022 09:43:31 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.6247344696538211 on epoch=17
06/01/2022 09:43:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/01/2022 09:43:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=19
06/01/2022 09:43:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
06/01/2022 09:43:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=20
06/01/2022 09:43:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=21
06/01/2022 09:43:51 - INFO - __main__ - Global step 300 Train loss 0.40 Classification-F1 0.5941544477028348 on epoch=21
06/01/2022 09:43:54 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=22
06/01/2022 09:43:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=22
06/01/2022 09:43:59 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
06/01/2022 09:44:02 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=24
06/01/2022 09:44:04 - INFO - __main__ - Step 350 Global step 350 Train loss 0.35 on epoch=24
06/01/2022 09:44:11 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.7157191769739386 on epoch=24
06/01/2022 09:44:11 - INFO - __main__ - Saving model with best Classification-F1: 0.641155046935792 -> 0.7157191769739386 on epoch=24, global_step=350
06/01/2022 09:44:14 - INFO - __main__ - Step 360 Global step 360 Train loss 0.27 on epoch=25
06/01/2022 09:44:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=26
06/01/2022 09:44:19 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
06/01/2022 09:44:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=27
06/01/2022 09:44:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=28
06/01/2022 09:44:31 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.7835753982551551 on epoch=28
06/01/2022 09:44:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7157191769739386 -> 0.7835753982551551 on epoch=28, global_step=400
06/01/2022 09:44:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/01/2022 09:44:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=29
06/01/2022 09:44:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/01/2022 09:44:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=31
06/01/2022 09:44:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=32
06/01/2022 09:44:51 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.8081353807950898 on epoch=32
06/01/2022 09:44:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7835753982551551 -> 0.8081353807950898 on epoch=32, global_step=450
06/01/2022 09:44:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.19 on epoch=32
06/01/2022 09:44:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=33
06/01/2022 09:44:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
06/01/2022 09:45:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
06/01/2022 09:45:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/01/2022 09:45:11 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.7081807482382323 on epoch=35
06/01/2022 09:45:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=36
06/01/2022 09:45:16 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=37
06/01/2022 09:45:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=37
06/01/2022 09:45:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=38
06/01/2022 09:45:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=39
06/01/2022 09:45:31 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.6451037859619634 on epoch=39
06/01/2022 09:45:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.17 on epoch=39
06/01/2022 09:45:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=40
06/01/2022 09:45:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=41
06/01/2022 09:45:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/01/2022 09:45:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/01/2022 09:45:51 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.6397138808533995 on epoch=42
06/01/2022 09:45:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/01/2022 09:45:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=44
06/01/2022 09:45:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/01/2022 09:46:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
06/01/2022 09:46:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=46
06/01/2022 09:46:11 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7197471233524365 on epoch=46
06/01/2022 09:46:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/01/2022 09:46:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=47
06/01/2022 09:46:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=48
06/01/2022 09:46:21 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
06/01/2022 09:46:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
06/01/2022 09:46:31 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.7332529152593504 on epoch=49
06/01/2022 09:46:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=50
06/01/2022 09:46:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=51
06/01/2022 09:46:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
06/01/2022 09:46:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=52
06/01/2022 09:46:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=53
06/01/2022 09:46:51 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.8182033099058041 on epoch=53
06/01/2022 09:46:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8081353807950898 -> 0.8182033099058041 on epoch=53, global_step=750
06/01/2022 09:46:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/01/2022 09:46:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=54
06/01/2022 09:46:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=55
06/01/2022 09:47:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=56
06/01/2022 09:47:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/01/2022 09:47:10 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.9035383475532661 on epoch=57
06/01/2022 09:47:10 - INFO - __main__ - Saving model with best Classification-F1: 0.8182033099058041 -> 0.9035383475532661 on epoch=57, global_step=800
06/01/2022 09:47:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=57
06/01/2022 09:47:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=58
06/01/2022 09:47:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=59
06/01/2022 09:47:21 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/01/2022 09:47:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/01/2022 09:47:30 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.7822187383676312 on epoch=60
06/01/2022 09:47:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=61
06/01/2022 09:47:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/01/2022 09:47:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
06/01/2022 09:47:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=63
06/01/2022 09:47:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=64
06/01/2022 09:47:50 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.750484613640475 on epoch=64
06/01/2022 09:47:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
06/01/2022 09:47:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=65
06/01/2022 09:47:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=66
06/01/2022 09:48:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=67
06/01/2022 09:48:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/01/2022 09:48:09 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.8433130821976885 on epoch=67
06/01/2022 09:48:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=68
06/01/2022 09:48:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=69
06/01/2022 09:48:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=69
06/01/2022 09:48:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/01/2022 09:48:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
06/01/2022 09:48:29 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.9016369809460171 on epoch=71
06/01/2022 09:48:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/01/2022 09:48:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=72
06/01/2022 09:48:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/01/2022 09:48:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=74
06/01/2022 09:48:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/01/2022 09:48:48 - INFO - __main__ - Global step 1050 Train loss 0.06 Classification-F1 0.9018319341421808 on epoch=74
06/01/2022 09:48:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=75
06/01/2022 09:48:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/01/2022 09:48:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/01/2022 09:48:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=77
06/01/2022 09:49:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/01/2022 09:49:08 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.7778553258936595 on epoch=78
06/01/2022 09:49:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/01/2022 09:49:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/01/2022 09:49:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/01/2022 09:49:19 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/01/2022 09:49:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=82
06/01/2022 09:49:28 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7673115476275398 on epoch=82
06/01/2022 09:49:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/01/2022 09:49:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=83
06/01/2022 09:49:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/01/2022 09:49:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/01/2022 09:49:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/01/2022 09:49:47 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8108938311900754 on epoch=85
06/01/2022 09:49:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/01/2022 09:49:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 09:49:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/01/2022 09:49:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/01/2022 09:50:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/01/2022 09:50:06 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.9640068078500487 on epoch=89
06/01/2022 09:50:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9035383475532661 -> 0.9640068078500487 on epoch=89, global_step=1250
06/01/2022 09:50:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/01/2022 09:50:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/01/2022 09:50:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/01/2022 09:50:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/01/2022 09:50:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/01/2022 09:50:26 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.9017558163589702 on epoch=92
06/01/2022 09:50:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/01/2022 09:50:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=94
06/01/2022 09:50:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/01/2022 09:50:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/01/2022 09:50:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/01/2022 09:50:45 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8736527308049731 on epoch=96
06/01/2022 09:50:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/01/2022 09:50:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=97
06/01/2022 09:50:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=98
06/01/2022 09:50:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=99
06/01/2022 09:50:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/01/2022 09:51:04 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.8167411701256496 on epoch=99
06/01/2022 09:51:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/01/2022 09:51:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/01/2022 09:51:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/01/2022 09:51:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/01/2022 09:51:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=103
06/01/2022 09:51:23 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8581734834927064 on epoch=103
06/01/2022 09:51:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=104
06/01/2022 09:51:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/01/2022 09:51:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/01/2022 09:51:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/01/2022 09:51:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/01/2022 09:51:42 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7688276679096449 on epoch=107
06/01/2022 09:51:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/01/2022 09:51:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/01/2022 09:51:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 09:51:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/01/2022 09:51:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/01/2022 09:52:02 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8928431356025742 on epoch=110
06/01/2022 09:52:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=111
06/01/2022 09:52:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/01/2022 09:52:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=112
06/01/2022 09:52:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/01/2022 09:52:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/01/2022 09:52:21 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8886879691371611 on epoch=114
06/01/2022 09:52:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/01/2022 09:52:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/01/2022 09:52:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 09:52:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/01/2022 09:52:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/01/2022 09:52:40 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9019426235792458 on epoch=117
06/01/2022 09:52:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/01/2022 09:52:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/01/2022 09:52:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/01/2022 09:52:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/01/2022 09:52:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/01/2022 09:53:00 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8342093790001085 on epoch=121
06/01/2022 09:53:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/01/2022 09:53:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=122
06/01/2022 09:53:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=123
06/01/2022 09:53:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/01/2022 09:53:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=124
06/01/2022 09:53:19 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.8859825536376278 on epoch=124
06/01/2022 09:53:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=125
06/01/2022 09:53:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/01/2022 09:53:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=127
06/01/2022 09:53:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/01/2022 09:53:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=128
06/01/2022 09:53:39 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8356424889009604 on epoch=128
06/01/2022 09:53:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/01/2022 09:53:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=129
06/01/2022 09:53:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/01/2022 09:53:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/01/2022 09:53:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/01/2022 09:53:58 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9683481338232534 on epoch=132
06/01/2022 09:53:58 - INFO - __main__ - Saving model with best Classification-F1: 0.9640068078500487 -> 0.9683481338232534 on epoch=132, global_step=1850
06/01/2022 09:54:01 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/01/2022 09:54:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/01/2022 09:54:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/01/2022 09:54:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/01/2022 09:54:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/01/2022 09:54:17 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.959842397369505 on epoch=135
06/01/2022 09:54:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/01/2022 09:54:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/01/2022 09:54:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/01/2022 09:54:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 09:54:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/01/2022 09:54:37 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9058077206006276 on epoch=139
06/01/2022 09:54:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 09:54:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/01/2022 09:54:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/01/2022 09:54:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/01/2022 09:54:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/01/2022 09:54:56 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8979096467521515 on epoch=142
06/01/2022 09:54:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/01/2022 09:55:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/01/2022 09:55:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 09:55:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 09:55:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/01/2022 09:55:15 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9059945278209035 on epoch=146
06/01/2022 09:55:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 09:55:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/01/2022 09:55:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 09:55:26 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/01/2022 09:55:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/01/2022 09:55:35 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9685622489464993 on epoch=149
06/01/2022 09:55:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9683481338232534 -> 0.9685622489464993 on epoch=149, global_step=2100
06/01/2022 09:55:38 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 09:55:40 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/01/2022 09:55:43 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/01/2022 09:55:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 09:55:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/01/2022 09:55:55 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8934115552379308 on epoch=153
06/01/2022 09:55:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/01/2022 09:56:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=154
06/01/2022 09:56:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 09:56:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/01/2022 09:56:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/01/2022 09:56:14 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9016369809460171 on epoch=157
06/01/2022 09:56:17 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 09:56:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/01/2022 09:56:22 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/01/2022 09:56:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/01/2022 09:56:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/01/2022 09:56:34 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8358064855544695 on epoch=160
06/01/2022 09:56:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/01/2022 09:56:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 09:56:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/01/2022 09:56:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/01/2022 09:56:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 09:56:54 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7761608352631827 on epoch=164
06/01/2022 09:56:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/01/2022 09:56:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/01/2022 09:57:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/01/2022 09:57:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/01/2022 09:57:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 09:57:13 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9035948191593351 on epoch=167
06/01/2022 09:57:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=168
06/01/2022 09:57:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 09:57:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/01/2022 09:57:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/01/2022 09:57:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/01/2022 09:57:33 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.892728373177565 on epoch=171
06/01/2022 09:57:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/01/2022 09:57:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/01/2022 09:57:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/01/2022 09:57:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/01/2022 09:57:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 09:57:52 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8953026700955772 on epoch=174
06/01/2022 09:57:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 09:57:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/01/2022 09:58:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/01/2022 09:58:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 09:58:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/01/2022 09:58:11 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9009428710979451 on epoch=178
06/01/2022 09:58:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 09:58:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/01/2022 09:58:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/01/2022 09:58:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/01/2022 09:58:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/01/2022 09:58:31 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8968909668562878 on epoch=182
06/01/2022 09:58:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 09:58:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 09:58:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 09:58:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 09:58:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/01/2022 09:58:50 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7668271742024393 on epoch=185
06/01/2022 09:58:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 09:58:55 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 09:58:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 09:59:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/01/2022 09:59:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/01/2022 09:59:10 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8190494351296622 on epoch=189
06/01/2022 09:59:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 09:59:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 09:59:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/01/2022 09:59:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 09:59:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/01/2022 09:59:29 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7892361377878734 on epoch=192
06/01/2022 09:59:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/01/2022 09:59:34 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=194
06/01/2022 09:59:37 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/01/2022 09:59:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 09:59:42 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/01/2022 09:59:48 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7776104019320338 on epoch=196
06/01/2022 09:59:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.10 on epoch=197
06/01/2022 09:59:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 09:59:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 09:59:59 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 10:00:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 10:00:08 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8191291960890565 on epoch=199
06/01/2022 10:00:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 10:00:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 10:00:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 10:00:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 10:00:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 10:00:27 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8225981200764763 on epoch=203
06/01/2022 10:00:30 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 10:00:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/01/2022 10:00:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 10:00:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/01/2022 10:00:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 10:00:46 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7742676607951751 on epoch=207
06/01/2022 10:00:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/01/2022 10:00:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/01/2022 10:00:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 10:00:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 10:01:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 10:01:06 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.899347147123925 on epoch=210
06/01/2022 10:01:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/01/2022 10:01:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/01/2022 10:01:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 10:01:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 10:01:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 10:01:20 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:01:20 - INFO - __main__ - Printing 3 examples
06/01/2022 10:01:20 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 10:01:20 - INFO - __main__ - ['Animal']
06/01/2022 10:01:20 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 10:01:20 - INFO - __main__ - ['Animal']
06/01/2022 10:01:20 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 10:01:20 - INFO - __main__ - ['Animal']
06/01/2022 10:01:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:01:20 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:01:21 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:01:21 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:01:21 - INFO - __main__ - Printing 3 examples
06/01/2022 10:01:21 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 10:01:21 - INFO - __main__ - ['Animal']
06/01/2022 10:01:21 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 10:01:21 - INFO - __main__ - ['Animal']
06/01/2022 10:01:21 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 10:01:21 - INFO - __main__ - ['Animal']
06/01/2022 10:01:21 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:01:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:01:21 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:01:25 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9640068078500487 on epoch=214
06/01/2022 10:01:25 - INFO - __main__ - save last model!
06/01/2022 10:01:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 10:01:25 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 10:01:25 - INFO - __main__ - Printing 3 examples
06/01/2022 10:01:25 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 10:01:25 - INFO - __main__ - ['Animal']
06/01/2022 10:01:25 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 10:01:25 - INFO - __main__ - ['Animal']
06/01/2022 10:01:25 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 10:01:25 - INFO - __main__ - ['Village']
06/01/2022 10:01:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:01:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:01:30 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 10:01:36 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:01:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:01:37 - INFO - __main__ - Starting training!
06/01/2022 10:03:41 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_13_0.4_8_predictions.txt
06/01/2022 10:03:41 - INFO - __main__ - Classification-F1 on test data: 0.6830
06/01/2022 10:03:42 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.4, bsz=8, dev_performance=0.9685622489464993, test_performance=0.6829954087155515
06/01/2022 10:03:42 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.3, bsz=8 ...
06/01/2022 10:03:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:03:43 - INFO - __main__ - Printing 3 examples
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:03:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:03:43 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:03:43 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:03:43 - INFO - __main__ - Printing 3 examples
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 10:03:43 - INFO - __main__ - ['Animal']
06/01/2022 10:03:43 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:03:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:03:43 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:04:02 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:04:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:04:03 - INFO - __main__ - Starting training!
06/01/2022 10:04:06 - INFO - __main__ - Step 10 Global step 10 Train loss 5.42 on epoch=0
06/01/2022 10:04:09 - INFO - __main__ - Step 20 Global step 20 Train loss 4.44 on epoch=1
06/01/2022 10:04:12 - INFO - __main__ - Step 30 Global step 30 Train loss 3.59 on epoch=2
06/01/2022 10:04:14 - INFO - __main__ - Step 40 Global step 40 Train loss 3.02 on epoch=2
06/01/2022 10:04:17 - INFO - __main__ - Step 50 Global step 50 Train loss 2.61 on epoch=3
06/01/2022 10:04:23 - INFO - __main__ - Global step 50 Train loss 3.81 Classification-F1 0.04709469556521837 on epoch=3
06/01/2022 10:04:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04709469556521837 on epoch=3, global_step=50
06/01/2022 10:04:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.28 on epoch=4
06/01/2022 10:04:28 - INFO - __main__ - Step 70 Global step 70 Train loss 1.87 on epoch=4
06/01/2022 10:04:31 - INFO - __main__ - Step 80 Global step 80 Train loss 1.62 on epoch=5
06/01/2022 10:04:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.40 on epoch=6
06/01/2022 10:04:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.35 on epoch=7
06/01/2022 10:04:42 - INFO - __main__ - Global step 100 Train loss 1.71 Classification-F1 0.20779842264771528 on epoch=7
06/01/2022 10:04:42 - INFO - __main__ - Saving model with best Classification-F1: 0.04709469556521837 -> 0.20779842264771528 on epoch=7, global_step=100
06/01/2022 10:04:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.19 on epoch=7
06/01/2022 10:04:48 - INFO - __main__ - Step 120 Global step 120 Train loss 0.98 on epoch=8
06/01/2022 10:04:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=9
06/01/2022 10:04:53 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=9
06/01/2022 10:04:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=10
06/01/2022 10:05:02 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.3662652394691825 on epoch=10
06/01/2022 10:05:02 - INFO - __main__ - Saving model with best Classification-F1: 0.20779842264771528 -> 0.3662652394691825 on epoch=10, global_step=150
06/01/2022 10:05:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=11
06/01/2022 10:05:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=12
06/01/2022 10:05:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=12
06/01/2022 10:05:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=13
06/01/2022 10:05:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=14
06/01/2022 10:05:23 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.46695821346897914 on epoch=14
06/01/2022 10:05:23 - INFO - __main__ - Saving model with best Classification-F1: 0.3662652394691825 -> 0.46695821346897914 on epoch=14, global_step=200
06/01/2022 10:05:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.56 on epoch=14
06/01/2022 10:05:28 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=15
06/01/2022 10:05:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
06/01/2022 10:05:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=17
06/01/2022 10:05:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=17
06/01/2022 10:05:42 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.516681197093363 on epoch=17
06/01/2022 10:05:42 - INFO - __main__ - Saving model with best Classification-F1: 0.46695821346897914 -> 0.516681197093363 on epoch=17, global_step=250
06/01/2022 10:05:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=18
06/01/2022 10:05:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=19
06/01/2022 10:05:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=19
06/01/2022 10:05:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.46 on epoch=20
06/01/2022 10:05:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=21
06/01/2022 10:06:03 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.7403061388243098 on epoch=21
06/01/2022 10:06:03 - INFO - __main__ - Saving model with best Classification-F1: 0.516681197093363 -> 0.7403061388243098 on epoch=21, global_step=300
06/01/2022 10:06:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=22
06/01/2022 10:06:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=22
06/01/2022 10:06:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/01/2022 10:06:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=24
06/01/2022 10:06:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=24
06/01/2022 10:06:23 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.7342126980829178 on epoch=24
06/01/2022 10:06:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=25
06/01/2022 10:06:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=26
06/01/2022 10:06:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=27
06/01/2022 10:06:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/01/2022 10:06:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=28
06/01/2022 10:06:44 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.7840129956959967 on epoch=28
06/01/2022 10:06:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7403061388243098 -> 0.7840129956959967 on epoch=28, global_step=400
06/01/2022 10:06:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=29
06/01/2022 10:06:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=29
06/01/2022 10:06:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/01/2022 10:06:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=31
06/01/2022 10:06:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/01/2022 10:07:04 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.7071444784374087 on epoch=32
06/01/2022 10:07:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=32
06/01/2022 10:07:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
06/01/2022 10:07:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=34
06/01/2022 10:07:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.26 on epoch=34
06/01/2022 10:07:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=35
06/01/2022 10:07:24 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.848597613107039 on epoch=35
06/01/2022 10:07:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7840129956959967 -> 0.848597613107039 on epoch=35, global_step=500
06/01/2022 10:07:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/01/2022 10:07:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=37
06/01/2022 10:07:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=37
06/01/2022 10:07:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=38
06/01/2022 10:07:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/01/2022 10:07:44 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.7478986893405692 on epoch=39
06/01/2022 10:07:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=39
06/01/2022 10:07:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=40
06/01/2022 10:07:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=41
06/01/2022 10:07:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/01/2022 10:07:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=42
06/01/2022 10:08:04 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7518477823361909 on epoch=42
06/01/2022 10:08:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=43
06/01/2022 10:08:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=44
06/01/2022 10:08:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=44
06/01/2022 10:08:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=45
06/01/2022 10:08:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=46
06/01/2022 10:08:24 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.8038837433998725 on epoch=46
06/01/2022 10:08:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/01/2022 10:08:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
06/01/2022 10:08:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=48
06/01/2022 10:08:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=49
06/01/2022 10:08:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=49
06/01/2022 10:08:44 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.7339710811010621 on epoch=49
06/01/2022 10:08:46 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=50
06/01/2022 10:08:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=51
06/01/2022 10:08:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=52
06/01/2022 10:08:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=52
06/01/2022 10:08:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
06/01/2022 10:09:04 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.7255167146346113 on epoch=53
06/01/2022 10:09:07 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=54
06/01/2022 10:09:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/01/2022 10:09:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/01/2022 10:09:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=56
06/01/2022 10:09:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/01/2022 10:09:24 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.729964163788501 on epoch=57
06/01/2022 10:09:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/01/2022 10:09:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/01/2022 10:09:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=59
06/01/2022 10:09:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=59
06/01/2022 10:09:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=60
06/01/2022 10:09:44 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.544160989541143 on epoch=60
06/01/2022 10:09:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=61
06/01/2022 10:09:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/01/2022 10:09:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=62
06/01/2022 10:09:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/01/2022 10:09:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=64
06/01/2022 10:10:03 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.688763432442275 on epoch=64
06/01/2022 10:10:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=64
06/01/2022 10:10:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/01/2022 10:10:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 10:10:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=67
06/01/2022 10:10:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/01/2022 10:10:23 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7048090179375759 on epoch=67
06/01/2022 10:10:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=68
06/01/2022 10:10:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=69
06/01/2022 10:10:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/01/2022 10:10:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/01/2022 10:10:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
06/01/2022 10:10:42 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.7206778641469793 on epoch=71
06/01/2022 10:10:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=72
06/01/2022 10:10:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/01/2022 10:10:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/01/2022 10:10:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/01/2022 10:10:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=74
06/01/2022 10:11:02 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7365725566864086 on epoch=74
06/01/2022 10:11:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=75
06/01/2022 10:11:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=76
06/01/2022 10:11:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=77
06/01/2022 10:11:13 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/01/2022 10:11:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/01/2022 10:11:22 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8316535017599416 on epoch=78
06/01/2022 10:11:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=79
06/01/2022 10:11:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/01/2022 10:11:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/01/2022 10:11:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/01/2022 10:11:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/01/2022 10:11:41 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7990569834972113 on epoch=82
06/01/2022 10:11:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/01/2022 10:11:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/01/2022 10:11:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=84
06/01/2022 10:11:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/01/2022 10:11:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/01/2022 10:12:01 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9062179397663267 on epoch=85
06/01/2022 10:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.848597613107039 -> 0.9062179397663267 on epoch=85, global_step=1200
06/01/2022 10:12:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=86
06/01/2022 10:12:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=87
06/01/2022 10:12:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/01/2022 10:12:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/01/2022 10:12:14 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=89
06/01/2022 10:12:20 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.74550576584495 on epoch=89
06/01/2022 10:12:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=89
06/01/2022 10:12:25 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=90
06/01/2022 10:12:28 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/01/2022 10:12:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/01/2022 10:12:33 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=92
06/01/2022 10:12:40 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.9773538961038959 on epoch=92
06/01/2022 10:12:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9062179397663267 -> 0.9773538961038959 on epoch=92, global_step=1300
06/01/2022 10:12:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/01/2022 10:12:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/01/2022 10:12:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=94
06/01/2022 10:12:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/01/2022 10:12:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=96
06/01/2022 10:12:59 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8005734238280204 on epoch=96
06/01/2022 10:13:02 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=97
06/01/2022 10:13:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=97
06/01/2022 10:13:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 10:13:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/01/2022 10:13:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/01/2022 10:13:18 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9143319341421808 on epoch=99
06/01/2022 10:13:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=100
06/01/2022 10:13:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=101
06/01/2022 10:13:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=102
06/01/2022 10:13:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/01/2022 10:13:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/01/2022 10:13:38 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.9685482844164058 on epoch=103
06/01/2022 10:13:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=104
06/01/2022 10:13:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/01/2022 10:13:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/01/2022 10:13:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/01/2022 10:13:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/01/2022 10:13:58 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9641842660817991 on epoch=107
06/01/2022 10:14:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/01/2022 10:14:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/01/2022 10:14:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/01/2022 10:14:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/01/2022 10:14:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=110
06/01/2022 10:14:17 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8904200490175245 on epoch=110
06/01/2022 10:14:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/01/2022 10:14:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/01/2022 10:14:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/01/2022 10:14:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/01/2022 10:14:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/01/2022 10:14:36 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9019168644975096 on epoch=114
06/01/2022 10:14:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/01/2022 10:14:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/01/2022 10:14:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=116
06/01/2022 10:14:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=117
06/01/2022 10:14:50 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/01/2022 10:14:56 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8967762044312785 on epoch=117
06/01/2022 10:14:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/01/2022 10:15:01 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/01/2022 10:15:04 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/01/2022 10:15:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/01/2022 10:15:09 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/01/2022 10:15:15 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9639356255698759 on epoch=121
06/01/2022 10:15:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/01/2022 10:15:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/01/2022 10:15:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=123
06/01/2022 10:15:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/01/2022 10:15:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/01/2022 10:15:34 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.899533954344201 on epoch=124
06/01/2022 10:15:37 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/01/2022 10:15:39 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/01/2022 10:15:42 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=127
06/01/2022 10:15:44 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/01/2022 10:15:47 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/01/2022 10:15:53 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.9774812197606314 on epoch=128
06/01/2022 10:15:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9773538961038959 -> 0.9774812197606314 on epoch=128, global_step=1800
06/01/2022 10:15:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=129
06/01/2022 10:15:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/01/2022 10:16:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/01/2022 10:16:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/01/2022 10:16:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/01/2022 10:16:12 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8415906375583795 on epoch=132
06/01/2022 10:16:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=132
06/01/2022 10:16:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/01/2022 10:16:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/01/2022 10:16:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/01/2022 10:16:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/01/2022 10:16:31 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9078713606654782 on epoch=135
06/01/2022 10:16:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/01/2022 10:16:36 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/01/2022 10:16:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/01/2022 10:16:41 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/01/2022 10:16:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 10:16:50 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.892454807437468 on epoch=139
06/01/2022 10:16:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/01/2022 10:16:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/01/2022 10:16:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/01/2022 10:17:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/01/2022 10:17:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/01/2022 10:17:09 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9100423590746171 on epoch=142
06/01/2022 10:17:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/01/2022 10:17:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/01/2022 10:17:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 10:17:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 10:17:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/01/2022 10:17:28 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9100423590746171 on epoch=146
06/01/2022 10:17:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 10:17:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/01/2022 10:17:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/01/2022 10:17:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/01/2022 10:17:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 10:17:47 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9058601192187531 on epoch=149
06/01/2022 10:17:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/01/2022 10:17:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/01/2022 10:17:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/01/2022 10:17:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/01/2022 10:18:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 10:18:07 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8996229576874737 on epoch=153
06/01/2022 10:18:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/01/2022 10:18:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/01/2022 10:18:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 10:18:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/01/2022 10:18:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/01/2022 10:18:27 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.847353740799839 on epoch=157
06/01/2022 10:18:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 10:18:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/01/2022 10:18:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=159
06/01/2022 10:18:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/01/2022 10:18:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/01/2022 10:18:47 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8434848484848485 on epoch=160
06/01/2022 10:18:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 10:18:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/01/2022 10:18:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/01/2022 10:18:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/01/2022 10:19:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/01/2022 10:19:07 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8852335744221171 on epoch=164
06/01/2022 10:19:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/01/2022 10:19:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/01/2022 10:19:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 10:19:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/01/2022 10:19:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/01/2022 10:19:26 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8732285035226213 on epoch=167
06/01/2022 10:19:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=168
06/01/2022 10:19:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.10 on epoch=169
06/01/2022 10:19:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 10:19:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 10:19:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/01/2022 10:19:45 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8318698698320971 on epoch=171
06/01/2022 10:19:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 10:19:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/01/2022 10:19:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/01/2022 10:19:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=174
06/01/2022 10:19:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/01/2022 10:20:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8943487874133034 on epoch=174
06/01/2022 10:20:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/01/2022 10:20:10 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/01/2022 10:20:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/01/2022 10:20:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 10:20:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/01/2022 10:20:25 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8433337016991548 on epoch=178
06/01/2022 10:20:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 10:20:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 10:20:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/01/2022 10:20:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/01/2022 10:20:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/01/2022 10:20:44 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8511646199902249 on epoch=182
06/01/2022 10:20:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 10:20:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/01/2022 10:20:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/01/2022 10:20:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/01/2022 10:20:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 10:21:03 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8985195270679143 on epoch=185
06/01/2022 10:21:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 10:21:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/01/2022 10:21:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 10:21:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 10:21:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 10:21:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9053134515342525 on epoch=189
06/01/2022 10:21:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 10:21:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/01/2022 10:21:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/01/2022 10:21:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 10:21:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/01/2022 10:21:41 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.900979020979021 on epoch=192
06/01/2022 10:21:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/01/2022 10:21:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 10:21:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 10:21:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 10:21:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 10:22:00 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8901665475574393 on epoch=196
06/01/2022 10:22:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 10:22:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=197
06/01/2022 10:22:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 10:22:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 10:22:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 10:22:19 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9011467848675856 on epoch=199
06/01/2022 10:22:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 10:22:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 10:22:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 10:22:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=202
06/01/2022 10:22:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 10:22:39 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9686480090569951 on epoch=203
06/01/2022 10:22:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 10:22:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 10:22:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=205
06/01/2022 10:22:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 10:22:52 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=207
06/01/2022 10:22:58 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8424696463996155 on epoch=207
06/01/2022 10:23:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/01/2022 10:23:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 10:23:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 10:23:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 10:23:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 10:23:17 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9773538961038961 on epoch=210
06/01/2022 10:23:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/01/2022 10:23:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/01/2022 10:23:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/01/2022 10:23:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 10:23:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/01/2022 10:23:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:23:32 - INFO - __main__ - Printing 3 examples
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:23:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:23:32 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:23:32 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:23:32 - INFO - __main__ - Printing 3 examples
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 10:23:32 - INFO - __main__ - ['Animal']
06/01/2022 10:23:32 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:23:32 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:23:32 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:23:36 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9054151803978409 on epoch=214
06/01/2022 10:23:36 - INFO - __main__ - save last model!
06/01/2022 10:23:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 10:23:36 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 10:23:36 - INFO - __main__ - Printing 3 examples
06/01/2022 10:23:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 10:23:36 - INFO - __main__ - ['Animal']
06/01/2022 10:23:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 10:23:36 - INFO - __main__ - ['Animal']
06/01/2022 10:23:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 10:23:36 - INFO - __main__ - ['Village']
06/01/2022 10:23:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:23:38 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:23:41 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 10:23:48 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:23:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:23:48 - INFO - __main__ - Starting training!
06/01/2022 10:25:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_13_0.3_8_predictions.txt
06/01/2022 10:25:49 - INFO - __main__ - Classification-F1 on test data: 0.6201
06/01/2022 10:25:49 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.3, bsz=8, dev_performance=0.9774812197606314, test_performance=0.6201277454960225
06/01/2022 10:25:49 - INFO - __main__ - Running ... prefix=dbpedia_14_16_13, lr=0.2, bsz=8 ...
06/01/2022 10:25:50 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:25:50 - INFO - __main__ - Printing 3 examples
06/01/2022 10:25:50 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
06/01/2022 10:25:50 - INFO - __main__ - ['Animal']
06/01/2022 10:25:50 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
06/01/2022 10:25:50 - INFO - __main__ - ['Animal']
06/01/2022 10:25:50 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
06/01/2022 10:25:50 - INFO - __main__ - ['Animal']
06/01/2022 10:25:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:25:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:25:51 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:25:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:25:51 - INFO - __main__ - Printing 3 examples
06/01/2022 10:25:51 - INFO - __main__ -  [dbpedia_14] Nemadactylus is a genus of morwongs.
06/01/2022 10:25:51 - INFO - __main__ - ['Animal']
06/01/2022 10:25:51 - INFO - __main__ -  [dbpedia_14] Coleophora isomoera is a moth of the Coleophoridae family. It is found in Spain and Morocco Turkey Uzbekistan Mongolia and China.
06/01/2022 10:25:51 - INFO - __main__ - ['Animal']
06/01/2022 10:25:51 - INFO - __main__ -  [dbpedia_14] Bredana is a genus of jumping spiders that occurs in the USA.
06/01/2022 10:25:51 - INFO - __main__ - ['Animal']
06/01/2022 10:25:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:25:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:25:51 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:26:10 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:26:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:26:10 - INFO - __main__ - Starting training!
06/01/2022 10:26:14 - INFO - __main__ - Step 10 Global step 10 Train loss 5.80 on epoch=0
06/01/2022 10:26:17 - INFO - __main__ - Step 20 Global step 20 Train loss 4.70 on epoch=1
06/01/2022 10:26:19 - INFO - __main__ - Step 30 Global step 30 Train loss 4.13 on epoch=2
06/01/2022 10:26:22 - INFO - __main__ - Step 40 Global step 40 Train loss 3.50 on epoch=2
06/01/2022 10:26:25 - INFO - __main__ - Step 50 Global step 50 Train loss 3.14 on epoch=3
06/01/2022 10:26:31 - INFO - __main__ - Global step 50 Train loss 4.25 Classification-F1 0.030331335798376477 on epoch=3
06/01/2022 10:26:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.030331335798376477 on epoch=3, global_step=50
06/01/2022 10:26:33 - INFO - __main__ - Step 60 Global step 60 Train loss 2.79 on epoch=4
06/01/2022 10:26:36 - INFO - __main__ - Step 70 Global step 70 Train loss 2.54 on epoch=4
06/01/2022 10:26:39 - INFO - __main__ - Step 80 Global step 80 Train loss 2.27 on epoch=5
06/01/2022 10:26:41 - INFO - __main__ - Step 90 Global step 90 Train loss 2.05 on epoch=6
06/01/2022 10:26:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.91 on epoch=7
06/01/2022 10:26:50 - INFO - __main__ - Global step 100 Train loss 2.31 Classification-F1 0.08660178459091503 on epoch=7
06/01/2022 10:26:50 - INFO - __main__ - Saving model with best Classification-F1: 0.030331335798376477 -> 0.08660178459091503 on epoch=7, global_step=100
06/01/2022 10:26:53 - INFO - __main__ - Step 110 Global step 110 Train loss 1.67 on epoch=7
06/01/2022 10:26:55 - INFO - __main__ - Step 120 Global step 120 Train loss 1.60 on epoch=8
06/01/2022 10:26:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.34 on epoch=9
06/01/2022 10:27:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.31 on epoch=9
06/01/2022 10:27:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.13 on epoch=10
06/01/2022 10:27:10 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.167435699843917 on epoch=10
06/01/2022 10:27:10 - INFO - __main__ - Saving model with best Classification-F1: 0.08660178459091503 -> 0.167435699843917 on epoch=10, global_step=150
06/01/2022 10:27:13 - INFO - __main__ - Step 160 Global step 160 Train loss 1.10 on epoch=11
06/01/2022 10:27:15 - INFO - __main__ - Step 170 Global step 170 Train loss 1.03 on epoch=12
06/01/2022 10:27:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.05 on epoch=12
06/01/2022 10:27:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=13
06/01/2022 10:27:23 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=14
06/01/2022 10:27:30 - INFO - __main__ - Global step 200 Train loss 0.97 Classification-F1 0.27654956045157747 on epoch=14
06/01/2022 10:27:30 - INFO - __main__ - Saving model with best Classification-F1: 0.167435699843917 -> 0.27654956045157747 on epoch=14, global_step=200
06/01/2022 10:27:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.90 on epoch=14
06/01/2022 10:27:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=15
06/01/2022 10:27:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=16
06/01/2022 10:27:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=17
06/01/2022 10:27:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=17
06/01/2022 10:27:51 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4070290362483412 on epoch=17
06/01/2022 10:27:51 - INFO - __main__ - Saving model with best Classification-F1: 0.27654956045157747 -> 0.4070290362483412 on epoch=17, global_step=250
06/01/2022 10:27:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.58 on epoch=18
06/01/2022 10:27:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=19
06/01/2022 10:27:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.65 on epoch=19
06/01/2022 10:28:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.64 on epoch=20
06/01/2022 10:28:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=21
06/01/2022 10:28:11 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.452220041352316 on epoch=21
06/01/2022 10:28:12 - INFO - __main__ - Saving model with best Classification-F1: 0.4070290362483412 -> 0.452220041352316 on epoch=21, global_step=300
06/01/2022 10:28:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=22
06/01/2022 10:28:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=22
06/01/2022 10:28:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=23
06/01/2022 10:28:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=24
06/01/2022 10:28:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=24
06/01/2022 10:28:32 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6792778471729669 on epoch=24
06/01/2022 10:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.452220041352316 -> 0.6792778471729669 on epoch=24, global_step=350
06/01/2022 10:28:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=25
06/01/2022 10:28:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=26
06/01/2022 10:28:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=27
06/01/2022 10:28:42 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=27
06/01/2022 10:28:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=28
06/01/2022 10:28:52 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6441749716603518 on epoch=28
06/01/2022 10:28:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=29
06/01/2022 10:28:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=29
06/01/2022 10:29:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=30
06/01/2022 10:29:03 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=31
06/01/2022 10:29:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.45 on epoch=32
06/01/2022 10:29:13 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.6577296179922764 on epoch=32
06/01/2022 10:29:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=32
06/01/2022 10:29:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/01/2022 10:29:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.46 on epoch=34
06/01/2022 10:29:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=34
06/01/2022 10:29:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=35
06/01/2022 10:29:33 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.6671283962022251 on epoch=35
06/01/2022 10:29:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=36
06/01/2022 10:29:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.41 on epoch=37
06/01/2022 10:29:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=37
06/01/2022 10:29:44 - INFO - __main__ - Step 540 Global step 540 Train loss 0.35 on epoch=38
06/01/2022 10:29:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=39
06/01/2022 10:29:54 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.699397411199171 on epoch=39
06/01/2022 10:29:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6792778471729669 -> 0.699397411199171 on epoch=39, global_step=550
06/01/2022 10:29:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=39
06/01/2022 10:29:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=40
06/01/2022 10:30:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=41
06/01/2022 10:30:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=42
06/01/2022 10:30:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=42
06/01/2022 10:30:14 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.7016103060486626 on epoch=42
06/01/2022 10:30:14 - INFO - __main__ - Saving model with best Classification-F1: 0.699397411199171 -> 0.7016103060486626 on epoch=42, global_step=600
06/01/2022 10:30:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=43
06/01/2022 10:30:19 - INFO - __main__ - Step 620 Global step 620 Train loss 0.45 on epoch=44
06/01/2022 10:30:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=44
06/01/2022 10:30:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=45
06/01/2022 10:30:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=46
06/01/2022 10:30:34 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.6314635480333436 on epoch=46
06/01/2022 10:30:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=47
06/01/2022 10:30:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=47
06/01/2022 10:30:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=48
06/01/2022 10:30:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=49
06/01/2022 10:30:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=49
06/01/2022 10:30:54 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.6758992257978059 on epoch=49
06/01/2022 10:30:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=50
06/01/2022 10:30:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=51
06/01/2022 10:31:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=52
06/01/2022 10:31:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=52
06/01/2022 10:31:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
06/01/2022 10:31:14 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.6437045388894312 on epoch=53
06/01/2022 10:31:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=54
06/01/2022 10:31:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=54
06/01/2022 10:31:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=55
06/01/2022 10:31:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
06/01/2022 10:31:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=57
06/01/2022 10:31:34 - INFO - __main__ - Global step 800 Train loss 0.26 Classification-F1 0.5631537010544301 on epoch=57
06/01/2022 10:31:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=57
06/01/2022 10:31:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=58
06/01/2022 10:31:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=59
06/01/2022 10:31:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=59
06/01/2022 10:31:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=60
06/01/2022 10:31:54 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.642538780382807 on epoch=60
06/01/2022 10:31:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/01/2022 10:31:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=62
06/01/2022 10:32:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=62
06/01/2022 10:32:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/01/2022 10:32:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=64
06/01/2022 10:32:14 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7047947624797719 on epoch=64
06/01/2022 10:32:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7016103060486626 -> 0.7047947624797719 on epoch=64, global_step=900
06/01/2022 10:32:16 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=64
06/01/2022 10:32:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.24 on epoch=65
06/01/2022 10:32:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=66
06/01/2022 10:32:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=67
06/01/2022 10:32:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=67
06/01/2022 10:32:33 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.6459634545797535 on epoch=67
06/01/2022 10:32:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=68
06/01/2022 10:32:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=69
06/01/2022 10:32:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=69
06/01/2022 10:32:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
06/01/2022 10:32:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=71
06/01/2022 10:32:53 - INFO - __main__ - Global step 1000 Train loss 0.21 Classification-F1 0.7308109678840229 on epoch=71
06/01/2022 10:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7047947624797719 -> 0.7308109678840229 on epoch=71, global_step=1000
06/01/2022 10:32:56 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=72
06/01/2022 10:32:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=72
06/01/2022 10:33:01 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=73
06/01/2022 10:33:04 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=74
06/01/2022 10:33:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=74
06/01/2022 10:33:14 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7355670783062234 on epoch=74
06/01/2022 10:33:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7308109678840229 -> 0.7355670783062234 on epoch=74, global_step=1050
06/01/2022 10:33:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=75
06/01/2022 10:33:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
06/01/2022 10:33:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=77
06/01/2022 10:33:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/01/2022 10:33:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=78
06/01/2022 10:33:34 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.64606048752783 on epoch=78
06/01/2022 10:33:37 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/01/2022 10:33:40 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/01/2022 10:33:42 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/01/2022 10:33:45 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=81
06/01/2022 10:33:48 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
06/01/2022 10:33:54 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.730510337885603 on epoch=82
06/01/2022 10:33:57 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=82
06/01/2022 10:34:00 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/01/2022 10:34:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/01/2022 10:34:05 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/01/2022 10:34:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=85
06/01/2022 10:34:15 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.7029121065174196 on epoch=85
06/01/2022 10:34:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
06/01/2022 10:34:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=87
06/01/2022 10:34:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.18 on epoch=87
06/01/2022 10:34:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=88
06/01/2022 10:34:28 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=89
06/01/2022 10:34:34 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.681768530155627 on epoch=89
06/01/2022 10:34:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=89
06/01/2022 10:34:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/01/2022 10:34:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/01/2022 10:34:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.14 on epoch=92
06/01/2022 10:34:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=92
06/01/2022 10:34:54 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6525348240469209 on epoch=92
06/01/2022 10:34:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=93
06/01/2022 10:34:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=94
06/01/2022 10:35:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=94
06/01/2022 10:35:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/01/2022 10:35:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/01/2022 10:35:14 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.7015069389871731 on epoch=96
06/01/2022 10:35:16 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=97
06/01/2022 10:35:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=97
06/01/2022 10:35:21 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=98
06/01/2022 10:35:24 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.19 on epoch=99
06/01/2022 10:35:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/01/2022 10:35:33 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.6356726539589443 on epoch=99
06/01/2022 10:35:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=100
06/01/2022 10:35:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
06/01/2022 10:35:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/01/2022 10:35:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/01/2022 10:35:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/01/2022 10:35:53 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7351678984243336 on epoch=103
06/01/2022 10:35:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=104
06/01/2022 10:35:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=104
06/01/2022 10:36:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=105
06/01/2022 10:36:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=106
06/01/2022 10:36:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/01/2022 10:36:13 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7744616468288195 on epoch=107
06/01/2022 10:36:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7355670783062234 -> 0.7744616468288195 on epoch=107, global_step=1500
06/01/2022 10:36:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=107
06/01/2022 10:36:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=108
06/01/2022 10:36:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
06/01/2022 10:36:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/01/2022 10:36:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=110
06/01/2022 10:36:32 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.8368515137416348 on epoch=110
06/01/2022 10:36:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7744616468288195 -> 0.8368515137416348 on epoch=110, global_step=1550
06/01/2022 10:36:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=111
06/01/2022 10:36:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=112
06/01/2022 10:36:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/01/2022 10:36:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/01/2022 10:36:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=114
06/01/2022 10:36:52 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.9011223901546482 on epoch=114
06/01/2022 10:36:52 - INFO - __main__ - Saving model with best Classification-F1: 0.8368515137416348 -> 0.9011223901546482 on epoch=114, global_step=1600
06/01/2022 10:36:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/01/2022 10:36:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/01/2022 10:37:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=116
06/01/2022 10:37:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.11 on epoch=117
06/01/2022 10:37:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=117
06/01/2022 10:37:12 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.8173428464685633 on epoch=117
06/01/2022 10:37:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/01/2022 10:37:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/01/2022 10:37:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=119
06/01/2022 10:37:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=120
06/01/2022 10:37:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/01/2022 10:37:32 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.9035531788472966 on epoch=121
06/01/2022 10:37:33 - INFO - __main__ - Saving model with best Classification-F1: 0.9011223901546482 -> 0.9035531788472966 on epoch=121, global_step=1700
06/01/2022 10:37:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/01/2022 10:37:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=122
06/01/2022 10:37:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=123
06/01/2022 10:37:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=124
06/01/2022 10:37:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/01/2022 10:37:53 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.9035817855979145 on epoch=124
06/01/2022 10:37:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9035531788472966 -> 0.9035817855979145 on epoch=124, global_step=1750
06/01/2022 10:37:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=125
06/01/2022 10:37:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=126
06/01/2022 10:38:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.22 on epoch=127
06/01/2022 10:38:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=127
06/01/2022 10:38:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/01/2022 10:38:13 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.8462522692361403 on epoch=128
06/01/2022 10:38:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
06/01/2022 10:38:18 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/01/2022 10:38:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
06/01/2022 10:38:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/01/2022 10:38:26 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=132
06/01/2022 10:38:33 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.9100423590746171 on epoch=132
06/01/2022 10:38:33 - INFO - __main__ - Saving model with best Classification-F1: 0.9035817855979145 -> 0.9100423590746171 on epoch=132, global_step=1850
06/01/2022 10:38:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/01/2022 10:38:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/01/2022 10:38:41 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/01/2022 10:38:44 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/01/2022 10:38:46 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/01/2022 10:38:53 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.9730125701306915 on epoch=135
06/01/2022 10:38:53 - INFO - __main__ - Saving model with best Classification-F1: 0.9100423590746171 -> 0.9730125701306915 on epoch=135, global_step=1900
06/01/2022 10:38:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/01/2022 10:38:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=137
06/01/2022 10:39:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=137
06/01/2022 10:39:04 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/01/2022 10:39:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/01/2022 10:39:13 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.9059945278209035 on epoch=139
06/01/2022 10:39:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=139
06/01/2022 10:39:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/01/2022 10:39:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=141
06/01/2022 10:39:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/01/2022 10:39:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/01/2022 10:39:33 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.9728852464739559 on epoch=142
06/01/2022 10:39:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
06/01/2022 10:39:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=144
06/01/2022 10:39:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/01/2022 10:39:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=145
06/01/2022 10:39:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=146
06/01/2022 10:39:52 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.9730082062150373 on epoch=146
06/01/2022 10:39:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=147
06/01/2022 10:39:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/01/2022 10:40:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=148
06/01/2022 10:40:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=149
06/01/2022 10:40:05 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=149
06/01/2022 10:40:12 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.905888725969371 on epoch=149
06/01/2022 10:40:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/01/2022 10:40:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/01/2022 10:40:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=152
06/01/2022 10:40:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/01/2022 10:40:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=153
06/01/2022 10:40:31 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8978649602558522 on epoch=153
06/01/2022 10:40:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/01/2022 10:40:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/01/2022 10:40:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 10:40:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/01/2022 10:40:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=157
06/01/2022 10:40:51 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.795485367685111 on epoch=157
06/01/2022 10:40:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/01/2022 10:40:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=158
06/01/2022 10:40:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/01/2022 10:41:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/01/2022 10:41:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=160
06/01/2022 10:41:10 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7990222496236482 on epoch=160
06/01/2022 10:41:12 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/01/2022 10:41:15 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=162
06/01/2022 10:41:18 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=162
06/01/2022 10:41:20 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/01/2022 10:41:23 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/01/2022 10:41:29 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.9683437699075991 on epoch=164
06/01/2022 10:41:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/01/2022 10:41:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/01/2022 10:41:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/01/2022 10:41:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=167
06/01/2022 10:41:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/01/2022 10:41:49 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9730082062150373 on epoch=167
06/01/2022 10:41:51 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/01/2022 10:41:54 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=169
06/01/2022 10:41:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/01/2022 10:41:59 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/01/2022 10:42:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=171
06/01/2022 10:42:08 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7933217436147932 on epoch=171
06/01/2022 10:42:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/01/2022 10:42:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/01/2022 10:42:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=173
06/01/2022 10:42:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/01/2022 10:42:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=174
06/01/2022 10:42:28 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8411395658475748 on epoch=174
06/01/2022 10:42:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=175
06/01/2022 10:42:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=176
06/01/2022 10:42:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 10:42:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=177
06/01/2022 10:42:41 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=178
06/01/2022 10:42:48 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9685482844164058 on epoch=178
06/01/2022 10:42:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/01/2022 10:42:53 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/01/2022 10:42:56 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/01/2022 10:42:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=181
06/01/2022 10:43:01 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/01/2022 10:43:07 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.9685622489464993 on epoch=182
06/01/2022 10:43:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/01/2022 10:43:12 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/01/2022 10:43:15 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/01/2022 10:43:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/01/2022 10:43:20 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
06/01/2022 10:43:27 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8977889904740001 on epoch=185
06/01/2022 10:43:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=186
06/01/2022 10:43:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 10:43:35 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/01/2022 10:43:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/01/2022 10:43:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/01/2022 10:43:46 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9730125701306915 on epoch=189
06/01/2022 10:43:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/01/2022 10:43:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=190
06/01/2022 10:43:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/01/2022 10:43:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=192
06/01/2022 10:43:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/01/2022 10:44:06 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8977948843271423 on epoch=192
06/01/2022 10:44:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/01/2022 10:44:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/01/2022 10:44:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/01/2022 10:44:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/01/2022 10:44:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/01/2022 10:44:25 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9686712441574868 on epoch=196
06/01/2022 10:44:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/01/2022 10:44:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/01/2022 10:44:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=198
06/01/2022 10:44:35 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/01/2022 10:44:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=199
06/01/2022 10:44:44 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9686712441574868 on epoch=199
06/01/2022 10:44:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/01/2022 10:44:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/01/2022 10:44:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=202
06/01/2022 10:44:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/01/2022 10:44:57 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 10:45:04 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9058756924079503 on epoch=203
06/01/2022 10:45:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/01/2022 10:45:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/01/2022 10:45:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=205
06/01/2022 10:45:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/01/2022 10:45:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 10:45:23 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9018408947156575 on epoch=207
06/01/2022 10:45:25 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/01/2022 10:45:28 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/01/2022 10:45:31 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/01/2022 10:45:33 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/01/2022 10:45:36 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 10:45:42 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8413053537030648 on epoch=210
06/01/2022 10:45:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/01/2022 10:45:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/01/2022 10:45:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/01/2022 10:45:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/01/2022 10:45:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=214
06/01/2022 10:45:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:45:56 - INFO - __main__ - Printing 3 examples
06/01/2022 10:45:56 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 10:45:56 - INFO - __main__ - ['Plant']
06/01/2022 10:45:56 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 10:45:56 - INFO - __main__ - ['Plant']
06/01/2022 10:45:56 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 10:45:56 - INFO - __main__ - ['Plant']
06/01/2022 10:45:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:45:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:45:57 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:45:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:45:57 - INFO - __main__ - Printing 3 examples
06/01/2022 10:45:57 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 10:45:57 - INFO - __main__ - ['Plant']
06/01/2022 10:45:57 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 10:45:57 - INFO - __main__ - ['Plant']
06/01/2022 10:45:57 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 10:45:57 - INFO - __main__ - ['Plant']
06/01/2022 10:45:57 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:45:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:45:57 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:46:01 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9685578850308451 on epoch=214
06/01/2022 10:46:01 - INFO - __main__ - save last model!
06/01/2022 10:46:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 10:46:01 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 10:46:01 - INFO - __main__ - Printing 3 examples
06/01/2022 10:46:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 10:46:01 - INFO - __main__ - ['Animal']
06/01/2022 10:46:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 10:46:01 - INFO - __main__ - ['Animal']
06/01/2022 10:46:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 10:46:01 - INFO - __main__ - ['Village']
06/01/2022 10:46:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:46:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:46:06 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 10:46:16 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:46:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:46:17 - INFO - __main__ - Starting training!
06/01/2022 10:48:15 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_13_0.2_8_predictions.txt
06/01/2022 10:48:15 - INFO - __main__ - Classification-F1 on test data: 0.6539
06/01/2022 10:48:15 - INFO - __main__ - prefix=dbpedia_14_16_13, lr=0.2, bsz=8, dev_performance=0.9730125701306915, test_performance=0.6539352629920812
06/01/2022 10:48:15 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.5, bsz=8 ...
06/01/2022 10:48:16 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:48:16 - INFO - __main__ - Printing 3 examples
06/01/2022 10:48:16 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 10:48:16 - INFO - __main__ - ['Plant']
06/01/2022 10:48:16 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 10:48:16 - INFO - __main__ - ['Plant']
06/01/2022 10:48:16 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 10:48:16 - INFO - __main__ - ['Plant']
06/01/2022 10:48:16 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:48:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:48:17 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 10:48:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 10:48:17 - INFO - __main__ - Printing 3 examples
06/01/2022 10:48:17 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 10:48:17 - INFO - __main__ - ['Plant']
06/01/2022 10:48:17 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 10:48:17 - INFO - __main__ - ['Plant']
06/01/2022 10:48:17 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 10:48:17 - INFO - __main__ - ['Plant']
06/01/2022 10:48:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 10:48:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 10:48:17 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 10:48:33 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 10:48:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 10:48:33 - INFO - __main__ - Starting training!
06/01/2022 10:48:37 - INFO - __main__ - Step 10 Global step 10 Train loss 4.91 on epoch=0
06/01/2022 10:48:39 - INFO - __main__ - Step 20 Global step 20 Train loss 3.37 on epoch=1
06/01/2022 10:48:42 - INFO - __main__ - Step 30 Global step 30 Train loss 2.45 on epoch=2
06/01/2022 10:48:45 - INFO - __main__ - Step 40 Global step 40 Train loss 1.96 on epoch=2
06/01/2022 10:48:47 - INFO - __main__ - Step 50 Global step 50 Train loss 1.56 on epoch=3
06/01/2022 10:48:53 - INFO - __main__ - Global step 50 Train loss 2.85 Classification-F1 0.16328264495685307 on epoch=3
06/01/2022 10:48:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16328264495685307 on epoch=3, global_step=50
06/01/2022 10:48:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.33 on epoch=4
06/01/2022 10:48:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.20 on epoch=4
06/01/2022 10:49:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=5
06/01/2022 10:49:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.75 on epoch=6
06/01/2022 10:49:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.64 on epoch=7
06/01/2022 10:49:14 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.47791274411565526 on epoch=7
06/01/2022 10:49:14 - INFO - __main__ - Saving model with best Classification-F1: 0.16328264495685307 -> 0.47791274411565526 on epoch=7, global_step=100
06/01/2022 10:49:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.53 on epoch=7
06/01/2022 10:49:19 - INFO - __main__ - Step 120 Global step 120 Train loss 0.59 on epoch=8
06/01/2022 10:49:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=9
06/01/2022 10:49:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=9
06/01/2022 10:49:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.49 on epoch=10
06/01/2022 10:49:34 - INFO - __main__ - Global step 150 Train loss 0.56 Classification-F1 0.566985746618898 on epoch=10
06/01/2022 10:49:34 - INFO - __main__ - Saving model with best Classification-F1: 0.47791274411565526 -> 0.566985746618898 on epoch=10, global_step=150
06/01/2022 10:49:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.49 on epoch=11
06/01/2022 10:49:39 - INFO - __main__ - Step 170 Global step 170 Train loss 0.47 on epoch=12
06/01/2022 10:49:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.38 on epoch=12
06/01/2022 10:49:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.42 on epoch=13
06/01/2022 10:49:47 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=14
06/01/2022 10:49:54 - INFO - __main__ - Global step 200 Train loss 0.45 Classification-F1 0.6594884133190585 on epoch=14
06/01/2022 10:49:54 - INFO - __main__ - Saving model with best Classification-F1: 0.566985746618898 -> 0.6594884133190585 on epoch=14, global_step=200
06/01/2022 10:49:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.40 on epoch=14
06/01/2022 10:50:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.30 on epoch=15
06/01/2022 10:50:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.38 on epoch=16
06/01/2022 10:50:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.26 on epoch=17
06/01/2022 10:50:08 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=17
06/01/2022 10:50:15 - INFO - __main__ - Global step 250 Train loss 0.33 Classification-F1 0.632352139473112 on epoch=17
06/01/2022 10:50:17 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=18
06/01/2022 10:50:20 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=19
06/01/2022 10:50:22 - INFO - __main__ - Step 280 Global step 280 Train loss 0.29 on epoch=19
06/01/2022 10:50:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=20
06/01/2022 10:50:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=21
06/01/2022 10:50:35 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.6593626176203309 on epoch=21
06/01/2022 10:50:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.21 on epoch=22
06/01/2022 10:50:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.22 on epoch=22
06/01/2022 10:50:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=23
06/01/2022 10:50:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.22 on epoch=24
06/01/2022 10:50:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.20 on epoch=24
06/01/2022 10:50:55 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.7244999960518063 on epoch=24
06/01/2022 10:50:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6594884133190585 -> 0.7244999960518063 on epoch=24, global_step=350
06/01/2022 10:50:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.24 on epoch=25
06/01/2022 10:51:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
06/01/2022 10:51:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.13 on epoch=27
06/01/2022 10:51:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=27
06/01/2022 10:51:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=28
06/01/2022 10:51:15 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.6538582834935509 on epoch=28
06/01/2022 10:51:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.14 on epoch=29
06/01/2022 10:51:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=29
06/01/2022 10:51:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.21 on epoch=30
06/01/2022 10:51:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=31
06/01/2022 10:51:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=32
06/01/2022 10:51:34 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.6119895162281719 on epoch=32
06/01/2022 10:51:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=32
06/01/2022 10:51:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=33
06/01/2022 10:51:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=34
06/01/2022 10:51:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=34
06/01/2022 10:51:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/01/2022 10:51:55 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.6319524271100949 on epoch=35
06/01/2022 10:51:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=36
06/01/2022 10:52:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.11 on epoch=37
06/01/2022 10:52:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=37
06/01/2022 10:52:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=38
06/01/2022 10:52:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=39
06/01/2022 10:52:15 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.7692157292350317 on epoch=39
06/01/2022 10:52:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7244999960518063 -> 0.7692157292350317 on epoch=39, global_step=550
06/01/2022 10:52:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.08 on epoch=39
06/01/2022 10:52:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=40
06/01/2022 10:52:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=41
06/01/2022 10:52:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.10 on epoch=42
06/01/2022 10:52:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/01/2022 10:52:35 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.9019377591263018 on epoch=42
06/01/2022 10:52:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7692157292350317 -> 0.9019377591263018 on epoch=42, global_step=600
06/01/2022 10:52:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=43
06/01/2022 10:52:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=44
06/01/2022 10:52:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=44
06/01/2022 10:52:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/01/2022 10:52:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=46
06/01/2022 10:52:54 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7370330928519765 on epoch=46
06/01/2022 10:52:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=47
06/01/2022 10:52:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=47
06/01/2022 10:53:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/01/2022 10:53:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/01/2022 10:53:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=49
06/01/2022 10:53:14 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.7949032769814031 on epoch=49
06/01/2022 10:53:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=50
06/01/2022 10:53:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
06/01/2022 10:53:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=52
06/01/2022 10:53:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=52
06/01/2022 10:53:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=53
06/01/2022 10:53:34 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7986016141837105 on epoch=53
06/01/2022 10:53:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
06/01/2022 10:53:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/01/2022 10:53:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=55
06/01/2022 10:53:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=56
06/01/2022 10:53:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=57
06/01/2022 10:53:53 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.7504694168765358 on epoch=57
06/01/2022 10:53:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=57
06/01/2022 10:53:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/01/2022 10:54:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
06/01/2022 10:54:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/01/2022 10:54:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=60
06/01/2022 10:54:12 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7450484627178455 on epoch=60
06/01/2022 10:54:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=61
06/01/2022 10:54:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=62
06/01/2022 10:54:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/01/2022 10:54:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/01/2022 10:54:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/01/2022 10:54:32 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.6572855571847507 on epoch=64
06/01/2022 10:54:35 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=64
06/01/2022 10:54:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=65
06/01/2022 10:54:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=66
06/01/2022 10:54:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=67
06/01/2022 10:54:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/01/2022 10:54:52 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.7787322944818201 on epoch=67
06/01/2022 10:54:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=68
06/01/2022 10:54:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=69
06/01/2022 10:55:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/01/2022 10:55:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/01/2022 10:55:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
06/01/2022 10:55:11 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7633923789744752 on epoch=71
06/01/2022 10:55:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=72
06/01/2022 10:55:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/01/2022 10:55:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/01/2022 10:55:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=74
06/01/2022 10:55:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=74
06/01/2022 10:55:31 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9143319341421808 on epoch=74
06/01/2022 10:55:31 - INFO - __main__ - Saving model with best Classification-F1: 0.9019377591263018 -> 0.9143319341421808 on epoch=74, global_step=1050
06/01/2022 10:55:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/01/2022 10:55:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=76
06/01/2022 10:55:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/01/2022 10:55:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=77
06/01/2022 10:55:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=78
06/01/2022 10:55:50 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.9775075059349252 on epoch=78
06/01/2022 10:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9143319341421808 -> 0.9775075059349252 on epoch=78, global_step=1100
06/01/2022 10:55:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/01/2022 10:55:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/01/2022 10:55:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=80
06/01/2022 10:56:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=81
06/01/2022 10:56:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/01/2022 10:56:10 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.9101652674755142 on epoch=82
06/01/2022 10:56:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=82
06/01/2022 10:56:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=83
06/01/2022 10:56:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=84
06/01/2022 10:56:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=84
06/01/2022 10:56:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/01/2022 10:56:30 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.9100070670058567 on epoch=85
06/01/2022 10:56:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=86
06/01/2022 10:56:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 10:56:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/01/2022 10:56:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=88
06/01/2022 10:56:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/01/2022 10:56:49 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8027023140247753 on epoch=89
06/01/2022 10:56:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/01/2022 10:56:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=90
06/01/2022 10:56:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/01/2022 10:57:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=92
06/01/2022 10:57:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=92
06/01/2022 10:57:09 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.8434881414720125 on epoch=92
06/01/2022 10:57:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=93
06/01/2022 10:57:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/01/2022 10:57:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=94
06/01/2022 10:57:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/01/2022 10:57:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=96
06/01/2022 10:57:29 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8950584298686766 on epoch=96
06/01/2022 10:57:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=97
06/01/2022 10:57:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=97
06/01/2022 10:57:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=98
06/01/2022 10:57:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/01/2022 10:57:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/01/2022 10:57:48 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7986052079966022 on epoch=99
06/01/2022 10:57:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=100
06/01/2022 10:57:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/01/2022 10:57:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=102
06/01/2022 10:57:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/01/2022 10:58:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/01/2022 10:58:08 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7787262232464321 on epoch=103
06/01/2022 10:58:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=104
06/01/2022 10:58:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/01/2022 10:58:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/01/2022 10:58:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/01/2022 10:58:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=107
06/01/2022 10:58:27 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8714447470092632 on epoch=107
06/01/2022 10:58:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=107
06/01/2022 10:58:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=108
06/01/2022 10:58:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 10:58:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/01/2022 10:58:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=110
06/01/2022 10:58:47 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9056426653312083 on epoch=110
06/01/2022 10:58:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/01/2022 10:58:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/01/2022 10:58:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/01/2022 10:58:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/01/2022 10:59:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/01/2022 10:59:06 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9117609914495343 on epoch=114
06/01/2022 10:59:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/01/2022 10:59:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/01/2022 10:59:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=116
06/01/2022 10:59:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/01/2022 10:59:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/01/2022 10:59:27 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.8490399987480077 on epoch=117
06/01/2022 10:59:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/01/2022 10:59:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/01/2022 10:59:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=119
06/01/2022 10:59:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/01/2022 10:59:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=121
06/01/2022 10:59:46 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.9732659046023101 on epoch=121
06/01/2022 10:59:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=122
06/01/2022 10:59:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/01/2022 10:59:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/01/2022 10:59:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/01/2022 11:00:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/01/2022 11:00:06 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.90640165091778 on epoch=124
06/01/2022 11:00:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/01/2022 11:00:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=126
06/01/2022 11:00:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/01/2022 11:00:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/01/2022 11:00:20 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/01/2022 11:00:26 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9732519400722166 on epoch=128
06/01/2022 11:00:29 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/01/2022 11:00:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=129
06/01/2022 11:00:34 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/01/2022 11:00:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/01/2022 11:00:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/01/2022 11:00:46 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9732519400722166 on epoch=132
06/01/2022 11:00:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/01/2022 11:00:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/01/2022 11:00:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/01/2022 11:00:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/01/2022 11:00:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/01/2022 11:01:06 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.9776348295916607 on epoch=135
06/01/2022 11:01:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9775075059349252 -> 0.9776348295916607 on epoch=135, global_step=1900
06/01/2022 11:01:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/01/2022 11:01:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/01/2022 11:01:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=137
06/01/2022 11:01:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=138
06/01/2022 11:01:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/01/2022 11:01:25 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9029483983231612 on epoch=139
06/01/2022 11:01:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 11:01:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 11:01:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/01/2022 11:01:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/01/2022 11:01:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/01/2022 11:01:45 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.9732659046023101 on epoch=142
06/01/2022 11:01:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/01/2022 11:01:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=144
06/01/2022 11:01:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 11:01:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/01/2022 11:01:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=146
06/01/2022 11:02:05 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9732659046023101 on epoch=146
06/01/2022 11:02:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 11:02:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/01/2022 11:02:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/01/2022 11:02:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 11:02:18 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/01/2022 11:02:25 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9080947726109017 on epoch=149
06/01/2022 11:02:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=150
06/01/2022 11:02:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/01/2022 11:02:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/01/2022 11:02:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=152
06/01/2022 11:02:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 11:02:45 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9777205897021565 on epoch=153
06/01/2022 11:02:45 - INFO - __main__ - Saving model with best Classification-F1: 0.9776348295916607 -> 0.9777205897021565 on epoch=153, global_step=2150
06/01/2022 11:02:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/01/2022 11:02:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/01/2022 11:02:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 11:02:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/01/2022 11:02:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=157
06/01/2022 11:03:04 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9820991153059465 on epoch=157
06/01/2022 11:03:04 - INFO - __main__ - Saving model with best Classification-F1: 0.9777205897021565 -> 0.9820991153059465 on epoch=157, global_step=2200
06/01/2022 11:03:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/01/2022 11:03:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/01/2022 11:03:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=159
06/01/2022 11:03:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/01/2022 11:03:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 11:03:24 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9820991153059465 on epoch=160
06/01/2022 11:03:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 11:03:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/01/2022 11:03:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/01/2022 11:03:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 11:03:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=164
06/01/2022 11:03:43 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9732702685179644 on epoch=164
06/01/2022 11:03:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=164
06/01/2022 11:03:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=165
06/01/2022 11:03:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=166
06/01/2022 11:03:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=167
06/01/2022 11:03:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/01/2022 11:04:03 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9864404412791509 on epoch=167
06/01/2022 11:04:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9820991153059465 -> 0.9864404412791509 on epoch=167, global_step=2350
06/01/2022 11:04:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 11:04:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 11:04:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 11:04:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/01/2022 11:04:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/01/2022 11:04:22 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9687693259121831 on epoch=171
06/01/2022 11:04:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/01/2022 11:04:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.12 on epoch=172
06/01/2022 11:04:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/01/2022 11:04:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/01/2022 11:04:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=174
06/01/2022 11:04:42 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9732702685179644 on epoch=174
06/01/2022 11:04:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/01/2022 11:04:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/01/2022 11:04:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=177
06/01/2022 11:04:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/01/2022 11:04:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 11:05:01 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9020683796490249 on epoch=178
06/01/2022 11:05:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=179
06/01/2022 11:05:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/01/2022 11:05:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/01/2022 11:05:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/01/2022 11:05:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 11:05:21 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9062350463156915 on epoch=182
06/01/2022 11:05:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=182
06/01/2022 11:05:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 11:05:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 11:05:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/01/2022 11:05:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/01/2022 11:05:41 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9731845084074686 on epoch=185
06/01/2022 11:05:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/01/2022 11:05:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/01/2022 11:05:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 11:05:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/01/2022 11:05:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=189
06/01/2022 11:06:01 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9121813965077723 on epoch=189
06/01/2022 11:06:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/01/2022 11:06:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=190
06/01/2022 11:06:09 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/01/2022 11:06:12 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/01/2022 11:06:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/01/2022 11:06:21 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9776487941217543 on epoch=192
06/01/2022 11:06:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=193
06/01/2022 11:06:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/01/2022 11:06:29 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/01/2022 11:06:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 11:06:34 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=196
06/01/2022 11:06:40 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9732702685179644 on epoch=196
06/01/2022 11:06:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/01/2022 11:06:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 11:06:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/01/2022 11:06:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/01/2022 11:06:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/01/2022 11:07:00 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9823428491631258 on epoch=199
06/01/2022 11:07:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/01/2022 11:07:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/01/2022 11:07:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/01/2022 11:07:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 11:07:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/01/2022 11:07:20 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9867213747669155 on epoch=203
06/01/2022 11:07:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9864404412791509 -> 0.9867213747669155 on epoch=203, global_step=2850
06/01/2022 11:07:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=204
06/01/2022 11:07:25 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=204
06/01/2022 11:07:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 11:07:30 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 11:07:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/01/2022 11:07:39 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=207
06/01/2022 11:07:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/01/2022 11:07:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/01/2022 11:07:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/01/2022 11:07:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/01/2022 11:07:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 11:07:59 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.9820991153059465 on epoch=210
06/01/2022 11:08:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/01/2022 11:08:04 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/01/2022 11:08:07 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 11:08:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 11:08:12 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=214
06/01/2022 11:08:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:08:14 - INFO - __main__ - Printing 3 examples
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:08:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:08:14 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:08:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:08:14 - INFO - __main__ - Printing 3 examples
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:08:14 - INFO - __main__ - ['Plant']
06/01/2022 11:08:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:08:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:08:14 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:08:18 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9819901200949587 on epoch=214
06/01/2022 11:08:18 - INFO - __main__ - save last model!
06/01/2022 11:08:18 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 11:08:18 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 11:08:18 - INFO - __main__ - Printing 3 examples
06/01/2022 11:08:18 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 11:08:18 - INFO - __main__ - ['Animal']
06/01/2022 11:08:18 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 11:08:18 - INFO - __main__ - ['Animal']
06/01/2022 11:08:18 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 11:08:18 - INFO - __main__ - ['Village']
06/01/2022 11:08:18 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:08:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:08:24 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 11:08:33 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:08:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:08:34 - INFO - __main__ - Starting training!
06/01/2022 11:10:32 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_21_0.5_8_predictions.txt
06/01/2022 11:10:32 - INFO - __main__ - Classification-F1 on test data: 0.6217
06/01/2022 11:10:33 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.5, bsz=8, dev_performance=0.9867213747669155, test_performance=0.6217348347176302
06/01/2022 11:10:33 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.4, bsz=8 ...
06/01/2022 11:10:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:10:34 - INFO - __main__ - Printing 3 examples
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:10:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:10:34 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:10:34 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:10:34 - INFO - __main__ - Printing 3 examples
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:10:34 - INFO - __main__ - ['Plant']
06/01/2022 11:10:34 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:10:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:10:34 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:10:53 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:10:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:10:54 - INFO - __main__ - Starting training!
06/01/2022 11:10:57 - INFO - __main__ - Step 10 Global step 10 Train loss 5.16 on epoch=0
06/01/2022 11:11:00 - INFO - __main__ - Step 20 Global step 20 Train loss 3.68 on epoch=1
06/01/2022 11:11:03 - INFO - __main__ - Step 30 Global step 30 Train loss 2.96 on epoch=2
06/01/2022 11:11:06 - INFO - __main__ - Step 40 Global step 40 Train loss 2.24 on epoch=2
06/01/2022 11:11:09 - INFO - __main__ - Step 50 Global step 50 Train loss 1.96 on epoch=3
06/01/2022 11:11:15 - INFO - __main__ - Global step 50 Train loss 3.20 Classification-F1 0.08200836069776513 on epoch=3
06/01/2022 11:11:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08200836069776513 on epoch=3, global_step=50
06/01/2022 11:11:18 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=4
06/01/2022 11:11:21 - INFO - __main__ - Step 70 Global step 70 Train loss 1.36 on epoch=4
06/01/2022 11:11:24 - INFO - __main__ - Step 80 Global step 80 Train loss 1.10 on epoch=5
06/01/2022 11:11:26 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=6
06/01/2022 11:11:29 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=7
06/01/2022 11:11:36 - INFO - __main__ - Global step 100 Train loss 1.13 Classification-F1 0.4806667741666819 on epoch=7
06/01/2022 11:11:36 - INFO - __main__ - Saving model with best Classification-F1: 0.08200836069776513 -> 0.4806667741666819 on epoch=7, global_step=100
06/01/2022 11:11:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=7
06/01/2022 11:11:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.65 on epoch=8
06/01/2022 11:11:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=9
06/01/2022 11:11:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.65 on epoch=9
06/01/2022 11:11:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=10
06/01/2022 11:11:56 - INFO - __main__ - Global step 150 Train loss 0.70 Classification-F1 0.5575108534854112 on epoch=10
06/01/2022 11:11:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4806667741666819 -> 0.5575108534854112 on epoch=10, global_step=150
06/01/2022 11:11:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=11
06/01/2022 11:12:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.45 on epoch=12
06/01/2022 11:12:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.54 on epoch=12
06/01/2022 11:12:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.52 on epoch=13
06/01/2022 11:12:09 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=14
06/01/2022 11:12:16 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.556506535188731 on epoch=14
06/01/2022 11:12:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.40 on epoch=14
06/01/2022 11:12:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.47 on epoch=15
06/01/2022 11:12:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=16
06/01/2022 11:12:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=17
06/01/2022 11:12:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.40 on epoch=17
06/01/2022 11:12:36 - INFO - __main__ - Global step 250 Train loss 0.41 Classification-F1 0.7073329412067957 on epoch=17
06/01/2022 11:12:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5575108534854112 -> 0.7073329412067957 on epoch=17, global_step=250
06/01/2022 11:12:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=18
06/01/2022 11:12:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.33 on epoch=19
06/01/2022 11:12:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.31 on epoch=19
06/01/2022 11:12:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=20
06/01/2022 11:12:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.39 on epoch=21
06/01/2022 11:12:57 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.6561676322592358 on epoch=21
06/01/2022 11:12:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.23 on epoch=22
06/01/2022 11:13:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=22
06/01/2022 11:13:04 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=23
06/01/2022 11:13:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=24
06/01/2022 11:13:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
06/01/2022 11:13:17 - INFO - __main__ - Global step 350 Train loss 0.30 Classification-F1 0.6420271689297817 on epoch=24
06/01/2022 11:13:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=25
06/01/2022 11:13:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=26
06/01/2022 11:13:24 - INFO - __main__ - Step 380 Global step 380 Train loss 0.22 on epoch=27
06/01/2022 11:13:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.27 on epoch=27
06/01/2022 11:13:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/01/2022 11:13:36 - INFO - __main__ - Global step 400 Train loss 0.24 Classification-F1 0.6642739206671431 on epoch=28
06/01/2022 11:13:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.27 on epoch=29
06/01/2022 11:13:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.14 on epoch=29
06/01/2022 11:13:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=30
06/01/2022 11:13:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.15 on epoch=31
06/01/2022 11:13:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=32
06/01/2022 11:13:56 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.530781226006824 on epoch=32
06/01/2022 11:13:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=32
06/01/2022 11:14:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=33
06/01/2022 11:14:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=34
06/01/2022 11:14:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=34
06/01/2022 11:14:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=35
06/01/2022 11:14:16 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6435898633562704 on epoch=35
06/01/2022 11:14:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=36
06/01/2022 11:14:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=37
06/01/2022 11:14:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=37
06/01/2022 11:14:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.12 on epoch=38
06/01/2022 11:14:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=39
06/01/2022 11:14:35 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.5171624074849881 on epoch=39
06/01/2022 11:14:38 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=39
06/01/2022 11:14:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=40
06/01/2022 11:14:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
06/01/2022 11:14:46 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=42
06/01/2022 11:14:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=42
06/01/2022 11:14:55 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.7601266920719907 on epoch=42
06/01/2022 11:14:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7073329412067957 -> 0.7601266920719907 on epoch=42, global_step=600
06/01/2022 11:14:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=43
06/01/2022 11:15:00 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=44
06/01/2022 11:15:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=44
06/01/2022 11:15:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=45
06/01/2022 11:15:08 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/01/2022 11:15:15 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6483894709082999 on epoch=46
06/01/2022 11:15:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=47
06/01/2022 11:15:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=47
06/01/2022 11:15:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=48
06/01/2022 11:15:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.08 on epoch=49
06/01/2022 11:15:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=49
06/01/2022 11:15:35 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7890731659232608 on epoch=49
06/01/2022 11:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7601266920719907 -> 0.7890731659232608 on epoch=49, global_step=700
06/01/2022 11:15:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=50
06/01/2022 11:15:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.08 on epoch=51
06/01/2022 11:15:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=52
06/01/2022 11:15:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=52
06/01/2022 11:15:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=53
06/01/2022 11:15:54 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.9063694549178419 on epoch=53
06/01/2022 11:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7890731659232608 -> 0.9063694549178419 on epoch=53, global_step=750
06/01/2022 11:15:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=54
06/01/2022 11:16:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=54
06/01/2022 11:16:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=55
06/01/2022 11:16:05 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/01/2022 11:16:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=57
06/01/2022 11:16:15 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.6675848957682573 on epoch=57
06/01/2022 11:16:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=57
06/01/2022 11:16:20 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/01/2022 11:16:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=59
06/01/2022 11:16:25 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=59
06/01/2022 11:16:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/01/2022 11:16:35 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.7091874577081739 on epoch=60
06/01/2022 11:16:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=61
06/01/2022 11:16:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/01/2022 11:16:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
06/01/2022 11:16:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=63
06/01/2022 11:16:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=64
06/01/2022 11:16:55 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8609970674486804 on epoch=64
06/01/2022 11:16:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=64
06/01/2022 11:17:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/01/2022 11:17:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 11:17:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=67
06/01/2022 11:17:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/01/2022 11:17:15 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.8523020938580711 on epoch=67
06/01/2022 11:17:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/01/2022 11:17:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=69
06/01/2022 11:17:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=69
06/01/2022 11:17:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=70
06/01/2022 11:17:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=71
06/01/2022 11:17:34 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7518643182714373 on epoch=71
06/01/2022 11:17:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=72
06/01/2022 11:17:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=72
06/01/2022 11:17:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=73
06/01/2022 11:17:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/01/2022 11:17:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/01/2022 11:17:54 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9103216702125622 on epoch=74
06/01/2022 11:17:54 - INFO - __main__ - Saving model with best Classification-F1: 0.9063694549178419 -> 0.9103216702125622 on epoch=74, global_step=1050
06/01/2022 11:17:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=75
06/01/2022 11:17:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=76
06/01/2022 11:18:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=77
06/01/2022 11:18:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/01/2022 11:18:07 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=78
06/01/2022 11:18:14 - INFO - __main__ - Global step 1100 Train loss 0.06 Classification-F1 0.91649550533801 on epoch=78
06/01/2022 11:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9103216702125622 -> 0.91649550533801 on epoch=78, global_step=1100
06/01/2022 11:18:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/01/2022 11:18:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=79
06/01/2022 11:18:22 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=80
06/01/2022 11:18:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=81
06/01/2022 11:18:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=82
06/01/2022 11:18:34 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7182433639539403 on epoch=82
06/01/2022 11:18:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/01/2022 11:18:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=83
06/01/2022 11:18:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/01/2022 11:18:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=84
06/01/2022 11:18:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/01/2022 11:18:54 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7061481824469938 on epoch=85
06/01/2022 11:18:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/01/2022 11:19:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/01/2022 11:19:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/01/2022 11:19:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=88
06/01/2022 11:19:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/01/2022 11:19:14 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.6368131612371244 on epoch=89
06/01/2022 11:19:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=89
06/01/2022 11:19:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/01/2022 11:19:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=91
06/01/2022 11:19:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/01/2022 11:19:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/01/2022 11:19:34 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7121928310258913 on epoch=92
06/01/2022 11:19:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/01/2022 11:19:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=94
06/01/2022 11:19:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/01/2022 11:19:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/01/2022 11:19:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=96
06/01/2022 11:19:54 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8630254154447703 on epoch=96
06/01/2022 11:19:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=97
06/01/2022 11:19:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/01/2022 11:20:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 11:20:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/01/2022 11:20:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=99
06/01/2022 11:20:13 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.9145079830563699 on epoch=99
06/01/2022 11:20:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=100
06/01/2022 11:20:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/01/2022 11:20:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/01/2022 11:20:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=102
06/01/2022 11:20:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/01/2022 11:20:33 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8002691433654711 on epoch=103
06/01/2022 11:20:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/01/2022 11:20:38 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=104
06/01/2022 11:20:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=105
06/01/2022 11:20:43 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=106
06/01/2022 11:20:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=107
06/01/2022 11:20:52 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7449306816242299 on epoch=107
06/01/2022 11:20:55 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 11:20:57 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=108
06/01/2022 11:21:00 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/01/2022 11:21:03 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=109
06/01/2022 11:21:05 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/01/2022 11:21:12 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8009169459108069 on epoch=110
06/01/2022 11:21:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/01/2022 11:21:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/01/2022 11:21:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/01/2022 11:21:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=113
06/01/2022 11:21:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/01/2022 11:21:31 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.8588242249384839 on epoch=114
06/01/2022 11:21:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=114
06/01/2022 11:21:37 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=115
06/01/2022 11:21:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 11:21:42 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/01/2022 11:21:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=117
06/01/2022 11:21:51 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=117
06/01/2022 11:21:51 - INFO - __main__ - Saving model with best Classification-F1: 0.91649550533801 -> 0.9865940511101802 on epoch=117, global_step=1650
06/01/2022 11:21:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=118
06/01/2022 11:21:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/01/2022 11:21:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=119
06/01/2022 11:22:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/01/2022 11:22:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=121
06/01/2022 11:22:11 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.848619257086999 on epoch=121
06/01/2022 11:22:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/01/2022 11:22:16 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/01/2022 11:22:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/01/2022 11:22:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/01/2022 11:22:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/01/2022 11:22:30 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.859103128054741 on epoch=124
06/01/2022 11:22:33 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/01/2022 11:22:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=126
06/01/2022 11:22:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/01/2022 11:22:41 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/01/2022 11:22:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/01/2022 11:22:50 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=128
06/01/2022 11:22:50 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9865984150258343 on epoch=128, global_step=1800
06/01/2022 11:22:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/01/2022 11:22:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/01/2022 11:22:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/01/2022 11:23:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=131
06/01/2022 11:23:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/01/2022 11:23:09 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9100505050505049 on epoch=132
06/01/2022 11:23:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=132
06/01/2022 11:23:14 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/01/2022 11:23:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/01/2022 11:23:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/01/2022 11:23:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/01/2022 11:23:29 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9819717916492109 on epoch=135
06/01/2022 11:23:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/01/2022 11:23:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=137
06/01/2022 11:23:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/01/2022 11:23:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/01/2022 11:23:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 11:23:48 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7951115851258166 on epoch=139
06/01/2022 11:23:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/01/2022 11:23:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=140
06/01/2022 11:23:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/01/2022 11:23:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/01/2022 11:24:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/01/2022 11:24:07 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9819717916492109 on epoch=142
06/01/2022 11:24:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/01/2022 11:24:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/01/2022 11:24:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 11:24:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/01/2022 11:24:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/01/2022 11:24:27 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9728430696274868 on epoch=146
06/01/2022 11:24:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 11:24:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/01/2022 11:24:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/01/2022 11:24:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 11:24:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 11:24:46 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.910046432062561 on epoch=149
06/01/2022 11:24:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 11:24:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=151
06/01/2022 11:24:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/01/2022 11:24:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=152
06/01/2022 11:24:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/01/2022 11:25:05 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9819717916492109 on epoch=153
06/01/2022 11:25:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/01/2022 11:25:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 11:25:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 11:25:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/01/2022 11:25:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/01/2022 11:25:25 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9186705767350927 on epoch=157
06/01/2022 11:25:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 11:25:30 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/01/2022 11:25:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/01/2022 11:25:35 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/01/2022 11:25:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 11:25:44 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9186746497230369 on epoch=160
06/01/2022 11:25:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/01/2022 11:25:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/01/2022 11:25:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 11:25:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/01/2022 11:25:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/01/2022 11:26:04 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9865984150258343 on epoch=164
06/01/2022 11:26:06 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/01/2022 11:26:09 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 11:26:12 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=166
06/01/2022 11:26:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/01/2022 11:26:17 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=167
06/01/2022 11:26:23 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=167
06/01/2022 11:26:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 11:26:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 11:26:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/01/2022 11:26:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 11:26:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/01/2022 11:26:43 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8100840902646831 on epoch=171
06/01/2022 11:26:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/01/2022 11:26:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=172
06/01/2022 11:26:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/01/2022 11:26:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/01/2022 11:26:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/01/2022 11:27:02 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=174
06/01/2022 11:27:05 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 11:27:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=176
06/01/2022 11:27:10 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 11:27:13 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 11:27:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/01/2022 11:27:22 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=178
06/01/2022 11:27:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 11:27:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=179
06/01/2022 11:27:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 11:27:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/01/2022 11:27:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=182
06/01/2022 11:27:42 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9821297653958945 on epoch=182
06/01/2022 11:27:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 11:27:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 11:27:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 11:27:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=184
06/01/2022 11:27:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 11:28:02 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9775075059349252 on epoch=185
06/01/2022 11:28:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 11:28:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/01/2022 11:28:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/01/2022 11:28:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=188
06/01/2022 11:28:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 11:28:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9186746497230369 on epoch=189
06/01/2022 11:28:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/01/2022 11:28:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 11:28:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 11:28:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/01/2022 11:28:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/01/2022 11:28:41 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9228453893776475 on epoch=192
06/01/2022 11:28:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/01/2022 11:28:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 11:28:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/01/2022 11:28:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 11:28:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 11:29:00 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=196
06/01/2022 11:29:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=197
06/01/2022 11:29:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 11:29:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/01/2022 11:29:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 11:29:14 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/01/2022 11:29:20 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.9819717916492109 on epoch=199
06/01/2022 11:29:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 11:29:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/01/2022 11:29:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/01/2022 11:29:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 11:29:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/01/2022 11:29:39 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9819717916492109 on epoch=203
06/01/2022 11:29:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 11:29:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 11:29:47 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 11:29:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=206
06/01/2022 11:29:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 11:29:59 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9864404412791509 on epoch=207
06/01/2022 11:30:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/01/2022 11:30:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=208
06/01/2022 11:30:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=209
06/01/2022 11:30:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 11:30:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/01/2022 11:30:19 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9100029940179124 on epoch=210
06/01/2022 11:30:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 11:30:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 11:30:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/01/2022 11:30:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/01/2022 11:30:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 11:30:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:30:33 - INFO - __main__ - Printing 3 examples
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:30:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:30:33 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:30:33 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:30:33 - INFO - __main__ - Printing 3 examples
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:30:33 - INFO - __main__ - ['Plant']
06/01/2022 11:30:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:30:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:30:34 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:30:38 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9072886821496388 on epoch=214
06/01/2022 11:30:38 - INFO - __main__ - save last model!
06/01/2022 11:30:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 11:30:38 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 11:30:38 - INFO - __main__ - Printing 3 examples
06/01/2022 11:30:38 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 11:30:38 - INFO - __main__ - ['Animal']
06/01/2022 11:30:38 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 11:30:38 - INFO - __main__ - ['Animal']
06/01/2022 11:30:38 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 11:30:38 - INFO - __main__ - ['Village']
06/01/2022 11:30:38 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:30:40 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:30:44 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 11:30:49 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:30:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:30:50 - INFO - __main__ - Starting training!
06/01/2022 11:32:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_21_0.4_8_predictions.txt
06/01/2022 11:32:55 - INFO - __main__ - Classification-F1 on test data: 0.6098
06/01/2022 11:32:55 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.4, bsz=8, dev_performance=0.9865984150258343, test_performance=0.6098437897365323
06/01/2022 11:32:55 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.3, bsz=8 ...
06/01/2022 11:32:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:32:56 - INFO - __main__ - Printing 3 examples
06/01/2022 11:32:56 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:32:56 - INFO - __main__ - ['Plant']
06/01/2022 11:32:56 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:32:56 - INFO - __main__ - ['Plant']
06/01/2022 11:32:56 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:32:56 - INFO - __main__ - ['Plant']
06/01/2022 11:32:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:32:56 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:32:57 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:32:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:32:57 - INFO - __main__ - Printing 3 examples
06/01/2022 11:32:57 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:32:57 - INFO - __main__ - ['Plant']
06/01/2022 11:32:57 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:32:57 - INFO - __main__ - ['Plant']
06/01/2022 11:32:57 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:32:57 - INFO - __main__ - ['Plant']
06/01/2022 11:32:57 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:32:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:32:57 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:33:16 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:33:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:33:17 - INFO - __main__ - Starting training!
06/01/2022 11:33:20 - INFO - __main__ - Step 10 Global step 10 Train loss 5.36 on epoch=0
06/01/2022 11:33:23 - INFO - __main__ - Step 20 Global step 20 Train loss 4.27 on epoch=1
06/01/2022 11:33:25 - INFO - __main__ - Step 30 Global step 30 Train loss 3.51 on epoch=2
06/01/2022 11:33:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.83 on epoch=2
06/01/2022 11:33:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.59 on epoch=3
06/01/2022 11:33:36 - INFO - __main__ - Global step 50 Train loss 3.71 Classification-F1 0.0766088751764844 on epoch=3
06/01/2022 11:33:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0766088751764844 on epoch=3, global_step=50
06/01/2022 11:33:39 - INFO - __main__ - Step 60 Global step 60 Train loss 2.01 on epoch=4
06/01/2022 11:33:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.85 on epoch=4
06/01/2022 11:33:44 - INFO - __main__ - Step 80 Global step 80 Train loss 1.47 on epoch=5
06/01/2022 11:33:47 - INFO - __main__ - Step 90 Global step 90 Train loss 1.35 on epoch=6
06/01/2022 11:33:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.22 on epoch=7
06/01/2022 11:33:55 - INFO - __main__ - Global step 100 Train loss 1.58 Classification-F1 0.21325318728071202 on epoch=7
06/01/2022 11:33:55 - INFO - __main__ - Saving model with best Classification-F1: 0.0766088751764844 -> 0.21325318728071202 on epoch=7, global_step=100
06/01/2022 11:33:58 - INFO - __main__ - Step 110 Global step 110 Train loss 1.09 on epoch=7
06/01/2022 11:34:01 - INFO - __main__ - Step 120 Global step 120 Train loss 1.05 on epoch=8
06/01/2022 11:34:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=9
06/01/2022 11:34:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=9
06/01/2022 11:34:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=10
06/01/2022 11:34:15 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.37916246631126765 on epoch=10
06/01/2022 11:34:15 - INFO - __main__ - Saving model with best Classification-F1: 0.21325318728071202 -> 0.37916246631126765 on epoch=10, global_step=150
06/01/2022 11:34:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=11
06/01/2022 11:34:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=12
06/01/2022 11:34:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=12
06/01/2022 11:34:26 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=13
06/01/2022 11:34:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=14
06/01/2022 11:34:35 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.5749214458916295 on epoch=14
06/01/2022 11:34:35 - INFO - __main__ - Saving model with best Classification-F1: 0.37916246631126765 -> 0.5749214458916295 on epoch=14, global_step=200
06/01/2022 11:34:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=14
06/01/2022 11:34:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=15
06/01/2022 11:34:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=16
06/01/2022 11:34:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=17
06/01/2022 11:34:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=17
06/01/2022 11:34:55 - INFO - __main__ - Global step 250 Train loss 0.48 Classification-F1 0.6601894846611198 on epoch=17
06/01/2022 11:34:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5749214458916295 -> 0.6601894846611198 on epoch=17, global_step=250
06/01/2022 11:34:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=18
06/01/2022 11:35:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=19
06/01/2022 11:35:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
06/01/2022 11:35:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=20
06/01/2022 11:35:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=21
06/01/2022 11:35:15 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.6496306376264195 on epoch=21
06/01/2022 11:35:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=22
06/01/2022 11:35:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=22
06/01/2022 11:35:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=23
06/01/2022 11:35:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=24
06/01/2022 11:35:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=24
06/01/2022 11:35:35 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.7370490014391224 on epoch=24
06/01/2022 11:35:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6601894846611198 -> 0.7370490014391224 on epoch=24, global_step=350
06/01/2022 11:35:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=25
06/01/2022 11:35:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=26
06/01/2022 11:35:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
06/01/2022 11:35:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/01/2022 11:35:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=28
06/01/2022 11:35:56 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.7941138680415414 on epoch=28
06/01/2022 11:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.7370490014391224 -> 0.7941138680415414 on epoch=28, global_step=400
06/01/2022 11:35:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=29
06/01/2022 11:36:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=29
06/01/2022 11:36:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=30
06/01/2022 11:36:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/01/2022 11:36:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.27 on epoch=32
06/01/2022 11:36:16 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7512888699484918 on epoch=32
06/01/2022 11:36:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=32
06/01/2022 11:36:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/01/2022 11:36:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=34
06/01/2022 11:36:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=34
06/01/2022 11:36:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=35
06/01/2022 11:36:36 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.7588863109235924 on epoch=35
06/01/2022 11:36:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/01/2022 11:36:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=37
06/01/2022 11:36:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
06/01/2022 11:36:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=38
06/01/2022 11:36:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=39
06/01/2022 11:36:56 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.7344090125751532 on epoch=39
06/01/2022 11:36:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=39
06/01/2022 11:37:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=40
06/01/2022 11:37:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=41
06/01/2022 11:37:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=42
06/01/2022 11:37:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/01/2022 11:37:16 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7096397462817668 on epoch=42
06/01/2022 11:37:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/01/2022 11:37:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=44
06/01/2022 11:37:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=44
06/01/2022 11:37:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/01/2022 11:37:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=46
06/01/2022 11:37:36 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6469948995579324 on epoch=46
06/01/2022 11:37:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=47
06/01/2022 11:37:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/01/2022 11:37:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=48
06/01/2022 11:37:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=49
06/01/2022 11:37:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
06/01/2022 11:37:56 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6474505557573 on epoch=49
06/01/2022 11:37:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=50
06/01/2022 11:38:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=51
06/01/2022 11:38:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/01/2022 11:38:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/01/2022 11:38:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=53
06/01/2022 11:38:16 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.6033038791904504 on epoch=53
06/01/2022 11:38:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/01/2022 11:38:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=54
06/01/2022 11:38:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/01/2022 11:38:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/01/2022 11:38:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=57
06/01/2022 11:38:36 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5523296606400308 on epoch=57
06/01/2022 11:38:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=57
06/01/2022 11:38:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=58
06/01/2022 11:38:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=59
06/01/2022 11:38:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=59
06/01/2022 11:38:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=60
06/01/2022 11:38:56 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.5309944462489632 on epoch=60
06/01/2022 11:38:59 - INFO - __main__ - Step 860 Global step 860 Train loss 0.19 on epoch=61
06/01/2022 11:39:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=62
06/01/2022 11:39:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/01/2022 11:39:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=63
06/01/2022 11:39:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=64
06/01/2022 11:39:16 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.6585039920523792 on epoch=64
06/01/2022 11:39:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
06/01/2022 11:39:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/01/2022 11:39:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 11:39:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/01/2022 11:39:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=67
06/01/2022 11:39:36 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7870622735897879 on epoch=67
06/01/2022 11:39:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=68
06/01/2022 11:39:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/01/2022 11:39:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=69
06/01/2022 11:39:47 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=70
06/01/2022 11:39:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=71
06/01/2022 11:39:56 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7331337569240794 on epoch=71
06/01/2022 11:39:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=72
06/01/2022 11:40:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/01/2022 11:40:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=73
06/01/2022 11:40:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=74
06/01/2022 11:40:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=74
06/01/2022 11:40:17 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.8468673631476051 on epoch=74
06/01/2022 11:40:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7941138680415414 -> 0.8468673631476051 on epoch=74, global_step=1050
06/01/2022 11:40:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/01/2022 11:40:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/01/2022 11:40:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/01/2022 11:40:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/01/2022 11:40:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/01/2022 11:40:37 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.8546798631476051 on epoch=78
06/01/2022 11:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.8468673631476051 -> 0.8546798631476051 on epoch=78, global_step=1100
06/01/2022 11:40:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/01/2022 11:40:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=79
06/01/2022 11:40:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=80
06/01/2022 11:40:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/01/2022 11:40:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=82
06/01/2022 11:40:57 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.8009732045310793 on epoch=82
06/01/2022 11:40:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/01/2022 11:41:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=83
06/01/2022 11:41:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=84
06/01/2022 11:41:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/01/2022 11:41:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=85
06/01/2022 11:41:17 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7051407433286422 on epoch=85
06/01/2022 11:41:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=86
06/01/2022 11:41:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=87
06/01/2022 11:41:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=87
06/01/2022 11:41:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=88
06/01/2022 11:41:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/01/2022 11:41:36 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.832386884739233 on epoch=89
06/01/2022 11:41:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/01/2022 11:41:41 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/01/2022 11:41:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/01/2022 11:41:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=92
06/01/2022 11:41:49 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=92
06/01/2022 11:41:56 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7353521202074335 on epoch=92
06/01/2022 11:41:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/01/2022 11:42:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/01/2022 11:42:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/01/2022 11:42:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=95
06/01/2022 11:42:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=96
06/01/2022 11:42:16 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.828919142803749 on epoch=96
06/01/2022 11:42:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/01/2022 11:42:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=97
06/01/2022 11:42:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 11:42:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/01/2022 11:42:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/01/2022 11:42:35 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7201884047851789 on epoch=99
06/01/2022 11:42:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=100
06/01/2022 11:42:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/01/2022 11:42:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/01/2022 11:42:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/01/2022 11:42:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=103
06/01/2022 11:42:55 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8363681748359167 on epoch=103
06/01/2022 11:42:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/01/2022 11:43:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=104
06/01/2022 11:43:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=105
06/01/2022 11:43:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/01/2022 11:43:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/01/2022 11:43:14 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8428173823187379 on epoch=107
06/01/2022 11:43:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/01/2022 11:43:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/01/2022 11:43:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=109
06/01/2022 11:43:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/01/2022 11:43:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=110
06/01/2022 11:43:34 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7822018444270293 on epoch=110
06/01/2022 11:43:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/01/2022 11:43:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/01/2022 11:43:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/01/2022 11:43:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/01/2022 11:43:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/01/2022 11:43:54 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.9080221570544151 on epoch=114
06/01/2022 11:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8546798631476051 -> 0.9080221570544151 on epoch=114, global_step=1600
06/01/2022 11:43:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=114
06/01/2022 11:44:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=115
06/01/2022 11:44:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/01/2022 11:44:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/01/2022 11:44:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=117
06/01/2022 11:44:14 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.849083329863445 on epoch=117
06/01/2022 11:44:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/01/2022 11:44:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/01/2022 11:44:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/01/2022 11:44:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=120
06/01/2022 11:44:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/01/2022 11:44:34 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9821114369501467 on epoch=121
06/01/2022 11:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.9080221570544151 -> 0.9821114369501467 on epoch=121, global_step=1700
06/01/2022 11:44:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/01/2022 11:44:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=122
06/01/2022 11:44:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/01/2022 11:44:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/01/2022 11:44:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=124
06/01/2022 11:44:54 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.9141852338737766 on epoch=124
06/01/2022 11:44:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=125
06/01/2022 11:44:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/01/2022 11:45:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/01/2022 11:45:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=127
06/01/2022 11:45:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/01/2022 11:45:14 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.752455720802495 on epoch=128
06/01/2022 11:45:16 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/01/2022 11:45:19 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/01/2022 11:45:21 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 11:45:24 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/01/2022 11:45:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=132
06/01/2022 11:45:33 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9059666629654525 on epoch=132
06/01/2022 11:45:36 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=132
06/01/2022 11:45:39 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=133
06/01/2022 11:45:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=134
06/01/2022 11:45:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=134
06/01/2022 11:45:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/01/2022 11:45:54 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8429532693854163 on epoch=135
06/01/2022 11:45:57 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/01/2022 11:46:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=137
06/01/2022 11:46:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/01/2022 11:46:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 11:46:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/01/2022 11:46:15 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9034194479355772 on epoch=139
06/01/2022 11:46:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/01/2022 11:46:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/01/2022 11:46:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/01/2022 11:46:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=142
06/01/2022 11:46:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=142
06/01/2022 11:46:35 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.9118018898664059 on epoch=142
06/01/2022 11:46:38 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=143
06/01/2022 11:46:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=144
06/01/2022 11:46:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/01/2022 11:46:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=145
06/01/2022 11:46:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=146
06/01/2022 11:46:56 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9141852338737766 on epoch=146
06/01/2022 11:46:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 11:47:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=147
06/01/2022 11:47:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 11:47:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=149
06/01/2022 11:47:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 11:47:16 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9822570890526298 on epoch=149
06/01/2022 11:47:16 - INFO - __main__ - Saving model with best Classification-F1: 0.9821114369501467 -> 0.9822570890526298 on epoch=149, global_step=2100
06/01/2022 11:47:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/01/2022 11:47:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=151
06/01/2022 11:47:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=152
06/01/2022 11:47:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/01/2022 11:47:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 11:47:37 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.9776487941217543 on epoch=153
06/01/2022 11:47:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/01/2022 11:47:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=154
06/01/2022 11:47:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=155
06/01/2022 11:47:48 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=156
06/01/2022 11:47:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/01/2022 11:47:57 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9823428491631258 on epoch=157
06/01/2022 11:47:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9822570890526298 -> 0.9823428491631258 on epoch=157, global_step=2200
06/01/2022 11:48:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/01/2022 11:48:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/01/2022 11:48:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/01/2022 11:48:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=159
06/01/2022 11:48:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 11:48:17 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.9733915853731523 on epoch=160
06/01/2022 11:48:20 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=161
06/01/2022 11:48:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/01/2022 11:48:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 11:48:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/01/2022 11:48:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/01/2022 11:48:38 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=164
06/01/2022 11:48:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/01/2022 11:48:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/01/2022 11:48:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=166
06/01/2022 11:48:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 11:48:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=167
06/01/2022 11:48:58 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9144753033178081 on epoch=167
06/01/2022 11:49:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=168
06/01/2022 11:49:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=169
06/01/2022 11:49:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/01/2022 11:49:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/01/2022 11:49:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/01/2022 11:49:18 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.973026534660785 on epoch=171
06/01/2022 11:49:21 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 11:49:23 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/01/2022 11:49:26 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=173
06/01/2022 11:49:29 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/01/2022 11:49:31 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=174
06/01/2022 11:49:38 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9082422147744728 on epoch=174
06/01/2022 11:49:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 11:49:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/01/2022 11:49:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=177
06/01/2022 11:49:49 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/01/2022 11:49:52 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/01/2022 11:49:58 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8528712086513238 on epoch=178
06/01/2022 11:50:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 11:50:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 11:50:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=180
06/01/2022 11:50:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/01/2022 11:50:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/01/2022 11:50:19 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9820991153059465 on epoch=182
06/01/2022 11:50:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=182
06/01/2022 11:50:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/01/2022 11:50:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/01/2022 11:50:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 11:50:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 11:50:39 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=185
06/01/2022 11:50:42 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
06/01/2022 11:50:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=187
06/01/2022 11:50:47 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/01/2022 11:50:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/01/2022 11:50:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 11:50:59 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.9103216702125622 on epoch=189
06/01/2022 11:51:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/01/2022 11:51:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/01/2022 11:51:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/01/2022 11:51:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 11:51:13 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=192
06/01/2022 11:51:19 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9080277634025262 on epoch=192
06/01/2022 11:51:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/01/2022 11:51:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=194
06/01/2022 11:51:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 11:51:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/01/2022 11:51:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/01/2022 11:51:40 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8551700592260365 on epoch=196
06/01/2022 11:51:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 11:51:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=197
06/01/2022 11:51:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 11:51:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=199
06/01/2022 11:51:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 11:52:00 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.9081409924673681 on epoch=199
06/01/2022 11:52:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 11:52:06 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 11:52:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/01/2022 11:52:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/01/2022 11:52:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/01/2022 11:52:21 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9146227454813792 on epoch=203
06/01/2022 11:52:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=204
06/01/2022 11:52:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=204
06/01/2022 11:52:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 11:52:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 11:52:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 11:52:42 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8973223655592956 on epoch=207
06/01/2022 11:52:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/01/2022 11:52:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/01/2022 11:52:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/01/2022 11:52:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/01/2022 11:52:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=210
06/01/2022 11:53:02 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.9056888851876747 on epoch=210
06/01/2022 11:53:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=211
06/01/2022 11:53:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 11:53:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/01/2022 11:53:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 11:53:16 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 11:53:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:53:17 - INFO - __main__ - Printing 3 examples
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:53:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:53:17 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:53:17 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:53:17 - INFO - __main__ - Printing 3 examples
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:53:17 - INFO - __main__ - ['Plant']
06/01/2022 11:53:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:53:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:53:18 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:53:22 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9080947726109017 on epoch=214
06/01/2022 11:53:22 - INFO - __main__ - save last model!
06/01/2022 11:53:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 11:53:22 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 11:53:22 - INFO - __main__ - Printing 3 examples
06/01/2022 11:53:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 11:53:22 - INFO - __main__ - ['Animal']
06/01/2022 11:53:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 11:53:22 - INFO - __main__ - ['Animal']
06/01/2022 11:53:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 11:53:22 - INFO - __main__ - ['Village']
06/01/2022 11:53:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:53:24 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:53:28 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 11:53:37 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:53:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:53:38 - INFO - __main__ - Starting training!
06/01/2022 11:55:36 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_21_0.3_8_predictions.txt
06/01/2022 11:55:36 - INFO - __main__ - Classification-F1 on test data: 0.4848
06/01/2022 11:55:36 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.3, bsz=8, dev_performance=0.9823428491631258, test_performance=0.48478038757585024
06/01/2022 11:55:36 - INFO - __main__ - Running ... prefix=dbpedia_14_16_21, lr=0.2, bsz=8 ...
06/01/2022 11:55:37 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:55:37 - INFO - __main__ - Printing 3 examples
06/01/2022 11:55:37 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
06/01/2022 11:55:37 - INFO - __main__ - ['Plant']
06/01/2022 11:55:37 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
06/01/2022 11:55:37 - INFO - __main__ - ['Plant']
06/01/2022 11:55:37 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
06/01/2022 11:55:37 - INFO - __main__ - ['Plant']
06/01/2022 11:55:37 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:55:37 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:55:38 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 11:55:38 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 11:55:38 - INFO - __main__ - Printing 3 examples
06/01/2022 11:55:38 - INFO - __main__ -  [dbpedia_14] Bellis annua or the annual daisy is a species of the genus Bellis.
06/01/2022 11:55:38 - INFO - __main__ - ['Plant']
06/01/2022 11:55:38 - INFO - __main__ -  [dbpedia_14] Carduus acanthoides known as the spiny plumeless thistle welted thistle and plumeless thistle is a biennial plant species of thistle in the Asteraceae—sunflower family. The plant is native to Europe and Asia.
06/01/2022 11:55:38 - INFO - __main__ - ['Plant']
06/01/2022 11:55:38 - INFO - __main__ -  [dbpedia_14] 'Gympie Gold' is a hybrid cultivar of the genus Aechmea in the Bromeliad family.
06/01/2022 11:55:38 - INFO - __main__ - ['Plant']
06/01/2022 11:55:38 - INFO - __main__ - Tokenizing Input ...
06/01/2022 11:55:38 - INFO - __main__ - Tokenizing Output ...
06/01/2022 11:55:38 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 11:55:57 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 11:55:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 11:55:58 - INFO - __main__ - Starting training!
06/01/2022 11:56:01 - INFO - __main__ - Step 10 Global step 10 Train loss 5.52 on epoch=0
06/01/2022 11:56:04 - INFO - __main__ - Step 20 Global step 20 Train loss 4.69 on epoch=1
06/01/2022 11:56:06 - INFO - __main__ - Step 30 Global step 30 Train loss 4.18 on epoch=2
06/01/2022 11:56:09 - INFO - __main__ - Step 40 Global step 40 Train loss 3.52 on epoch=2
06/01/2022 11:56:11 - INFO - __main__ - Step 50 Global step 50 Train loss 3.18 on epoch=3
06/01/2022 11:56:17 - INFO - __main__ - Global step 50 Train loss 4.22 Classification-F1 0.04434209152479613 on epoch=3
06/01/2022 11:56:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04434209152479613 on epoch=3, global_step=50
06/01/2022 11:56:20 - INFO - __main__ - Step 60 Global step 60 Train loss 2.70 on epoch=4
06/01/2022 11:56:23 - INFO - __main__ - Step 70 Global step 70 Train loss 2.49 on epoch=4
06/01/2022 11:56:25 - INFO - __main__ - Step 80 Global step 80 Train loss 2.19 on epoch=5
06/01/2022 11:56:28 - INFO - __main__ - Step 90 Global step 90 Train loss 1.85 on epoch=6
06/01/2022 11:56:30 - INFO - __main__ - Step 100 Global step 100 Train loss 1.93 on epoch=7
06/01/2022 11:56:37 - INFO - __main__ - Global step 100 Train loss 2.23 Classification-F1 0.0800491124480095 on epoch=7
06/01/2022 11:56:37 - INFO - __main__ - Saving model with best Classification-F1: 0.04434209152479613 -> 0.0800491124480095 on epoch=7, global_step=100
06/01/2022 11:56:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.61 on epoch=7
06/01/2022 11:56:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.41 on epoch=8
06/01/2022 11:56:45 - INFO - __main__ - Step 130 Global step 130 Train loss 1.28 on epoch=9
06/01/2022 11:56:47 - INFO - __main__ - Step 140 Global step 140 Train loss 1.30 on epoch=9
06/01/2022 11:56:50 - INFO - __main__ - Step 150 Global step 150 Train loss 1.13 on epoch=10
06/01/2022 11:56:56 - INFO - __main__ - Global step 150 Train loss 1.35 Classification-F1 0.2120239213843865 on epoch=10
06/01/2022 11:56:56 - INFO - __main__ - Saving model with best Classification-F1: 0.0800491124480095 -> 0.2120239213843865 on epoch=10, global_step=150
06/01/2022 11:56:59 - INFO - __main__ - Step 160 Global step 160 Train loss 1.07 on epoch=11
06/01/2022 11:57:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.96 on epoch=12
06/01/2022 11:57:04 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=12
06/01/2022 11:57:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=13
06/01/2022 11:57:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.86 on epoch=14
06/01/2022 11:57:17 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.3627720134670043 on epoch=14
06/01/2022 11:57:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2120239213843865 -> 0.3627720134670043 on epoch=14, global_step=200
06/01/2022 11:57:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.83 on epoch=14
06/01/2022 11:57:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=15
06/01/2022 11:57:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=16
06/01/2022 11:57:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=17
06/01/2022 11:57:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=17
06/01/2022 11:57:37 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.5479810929810929 on epoch=17
06/01/2022 11:57:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3627720134670043 -> 0.5479810929810929 on epoch=17, global_step=250
06/01/2022 11:57:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=18
06/01/2022 11:57:42 - INFO - __main__ - Step 270 Global step 270 Train loss 0.62 on epoch=19
06/01/2022 11:57:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=19
06/01/2022 11:57:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.64 on epoch=20
06/01/2022 11:57:50 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=21
06/01/2022 11:57:57 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.6497886641313978 on epoch=21
06/01/2022 11:57:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5479810929810929 -> 0.6497886641313978 on epoch=21, global_step=300
06/01/2022 11:58:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=22
06/01/2022 11:58:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=22
06/01/2022 11:58:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=23
06/01/2022 11:58:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=24
06/01/2022 11:58:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=24
06/01/2022 11:58:17 - INFO - __main__ - Global step 350 Train loss 0.49 Classification-F1 0.7924453365463218 on epoch=24
06/01/2022 11:58:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6497886641313978 -> 0.7924453365463218 on epoch=24, global_step=350
06/01/2022 11:58:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=25
06/01/2022 11:58:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=26
06/01/2022 11:58:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=27
06/01/2022 11:58:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=27
06/01/2022 11:58:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=28
06/01/2022 11:58:38 - INFO - __main__ - Global step 400 Train loss 0.45 Classification-F1 0.742184445259042 on epoch=28
06/01/2022 11:58:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=29
06/01/2022 11:58:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.44 on epoch=29
06/01/2022 11:58:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=30
06/01/2022 11:58:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=31
06/01/2022 11:58:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=32
06/01/2022 11:58:58 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.6998867855363402 on epoch=32
06/01/2022 11:59:00 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=32
06/01/2022 11:59:03 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=33
06/01/2022 11:59:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=34
06/01/2022 11:59:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=34
06/01/2022 11:59:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.40 on epoch=35
06/01/2022 11:59:18 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.7089001948780789 on epoch=35
06/01/2022 11:59:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=36
06/01/2022 11:59:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=37
06/01/2022 11:59:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=37
06/01/2022 11:59:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=38
06/01/2022 11:59:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.33 on epoch=39
06/01/2022 11:59:38 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.7479842244804522 on epoch=39
06/01/2022 11:59:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.38 on epoch=39
06/01/2022 11:59:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=40
06/01/2022 11:59:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=41
06/01/2022 11:59:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
06/01/2022 11:59:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
06/01/2022 11:59:58 - INFO - __main__ - Global step 600 Train loss 0.36 Classification-F1 0.7089001948780789 on epoch=42
06/01/2022 12:00:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=43
06/01/2022 12:00:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=44
06/01/2022 12:00:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=44
06/01/2022 12:00:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.34 on epoch=45
06/01/2022 12:00:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=46
06/01/2022 12:00:18 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.6743415908612671 on epoch=46
06/01/2022 12:00:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=47
06/01/2022 12:00:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/01/2022 12:00:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=48
06/01/2022 12:00:28 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=49
06/01/2022 12:00:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=49
06/01/2022 12:00:38 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.6099258104832926 on epoch=49
06/01/2022 12:00:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=50
06/01/2022 12:00:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=51
06/01/2022 12:00:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=52
06/01/2022 12:00:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=52
06/01/2022 12:00:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.27 on epoch=53
06/01/2022 12:00:58 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.6720537092157735 on epoch=53
06/01/2022 12:01:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=54
06/01/2022 12:01:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=54
06/01/2022 12:01:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=55
06/01/2022 12:01:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=56
06/01/2022 12:01:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=57
06/01/2022 12:01:19 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.611192521713239 on epoch=57
06/01/2022 12:01:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=57
06/01/2022 12:01:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/01/2022 12:01:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=59
06/01/2022 12:01:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=59
06/01/2022 12:01:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=60
06/01/2022 12:01:38 - INFO - __main__ - Global step 850 Train loss 0.22 Classification-F1 0.5043451438830496 on epoch=60
06/01/2022 12:01:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=61
06/01/2022 12:01:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=62
06/01/2022 12:01:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=62
06/01/2022 12:01:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=63
06/01/2022 12:01:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=64
06/01/2022 12:01:59 - INFO - __main__ - Global step 900 Train loss 0.23 Classification-F1 0.5343303212239712 on epoch=64
06/01/2022 12:02:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=64
06/01/2022 12:02:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=65
06/01/2022 12:02:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
06/01/2022 12:02:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=67
06/01/2022 12:02:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=67
06/01/2022 12:02:19 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.5153701532269631 on epoch=67
06/01/2022 12:02:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=68
06/01/2022 12:02:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=69
06/01/2022 12:02:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=69
06/01/2022 12:02:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/01/2022 12:02:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=71
06/01/2022 12:02:39 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5787241899383615 on epoch=71
06/01/2022 12:02:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=72
06/01/2022 12:02:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=72
06/01/2022 12:02:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=73
06/01/2022 12:02:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.20 on epoch=74
06/01/2022 12:02:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=74
06/01/2022 12:02:59 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.5670100984865458 on epoch=74
06/01/2022 12:03:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/01/2022 12:03:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
06/01/2022 12:03:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=77
06/01/2022 12:03:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=77
06/01/2022 12:03:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=78
06/01/2022 12:03:19 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.538412248107199 on epoch=78
06/01/2022 12:03:21 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=79
06/01/2022 12:03:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=79
06/01/2022 12:03:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=80
06/01/2022 12:03:29 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=81
06/01/2022 12:03:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/01/2022 12:03:39 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.5957383800701773 on epoch=82
06/01/2022 12:03:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/01/2022 12:03:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=83
06/01/2022 12:03:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=84
06/01/2022 12:03:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=84
06/01/2022 12:03:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=85
06/01/2022 12:03:58 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6959409936995326 on epoch=85
06/01/2022 12:04:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=86
06/01/2022 12:04:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/01/2022 12:04:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=87
06/01/2022 12:04:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/01/2022 12:04:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=89
06/01/2022 12:04:18 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.656962114474848 on epoch=89
06/01/2022 12:04:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=89
06/01/2022 12:04:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=90
06/01/2022 12:04:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=91
06/01/2022 12:04:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=92
06/01/2022 12:04:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=92
06/01/2022 12:04:38 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.5751349640095974 on epoch=92
06/01/2022 12:04:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/01/2022 12:04:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
06/01/2022 12:04:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=94
06/01/2022 12:04:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/01/2022 12:04:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/01/2022 12:04:58 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.8416069464809384 on epoch=96
06/01/2022 12:04:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7924453365463218 -> 0.8416069464809384 on epoch=96, global_step=1350
06/01/2022 12:05:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/01/2022 12:05:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=97
06/01/2022 12:05:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/01/2022 12:05:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=99
06/01/2022 12:05:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/01/2022 12:05:18 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.6558779325513197 on epoch=99
06/01/2022 12:05:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=100
06/01/2022 12:05:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
06/01/2022 12:05:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=102
06/01/2022 12:05:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=102
06/01/2022 12:05:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=103
06/01/2022 12:05:38 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.6933259652062708 on epoch=103
06/01/2022 12:05:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/01/2022 12:05:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/01/2022 12:05:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=105
06/01/2022 12:05:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=106
06/01/2022 12:05:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=107
06/01/2022 12:05:59 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.8029030360248053 on epoch=107
06/01/2022 12:06:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
06/01/2022 12:06:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=108
06/01/2022 12:06:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=109
06/01/2022 12:06:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=109
06/01/2022 12:06:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=110
06/01/2022 12:06:19 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.8424402798142718 on epoch=110
06/01/2022 12:06:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8416069464809384 -> 0.8424402798142718 on epoch=110, global_step=1550
06/01/2022 12:06:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=111
06/01/2022 12:06:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=112
06/01/2022 12:06:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=112
06/01/2022 12:06:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=113
06/01/2022 12:06:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
06/01/2022 12:06:39 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.645759013552944 on epoch=114
06/01/2022 12:06:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=114
06/01/2022 12:06:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=115
06/01/2022 12:06:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=116
06/01/2022 12:06:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=117
06/01/2022 12:06:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/01/2022 12:06:59 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.8229056477796397 on epoch=117
06/01/2022 12:07:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=118
06/01/2022 12:07:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=119
06/01/2022 12:07:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/01/2022 12:07:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
06/01/2022 12:07:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=121
06/01/2022 12:07:19 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.7451418172927271 on epoch=121
06/01/2022 12:07:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=122
06/01/2022 12:07:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=122
06/01/2022 12:07:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/01/2022 12:07:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=124
06/01/2022 12:07:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=124
06/01/2022 12:07:39 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8348840225797702 on epoch=124
06/01/2022 12:07:42 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=125
06/01/2022 12:07:44 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=126
06/01/2022 12:07:47 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/01/2022 12:07:50 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/01/2022 12:07:52 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=128
06/01/2022 12:07:59 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.8410303993721333 on epoch=128
06/01/2022 12:08:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=129
06/01/2022 12:08:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=129
06/01/2022 12:08:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/01/2022 12:08:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=131
06/01/2022 12:08:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/01/2022 12:08:19 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8457467943189005 on epoch=132
06/01/2022 12:08:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8424402798142718 -> 0.8457467943189005 on epoch=132, global_step=1850
06/01/2022 12:08:22 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/01/2022 12:08:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=133
06/01/2022 12:08:27 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=134
06/01/2022 12:08:30 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=134
06/01/2022 12:08:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/01/2022 12:08:39 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.918095302299974 on epoch=135
06/01/2022 12:08:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8457467943189005 -> 0.918095302299974 on epoch=135, global_step=1900
06/01/2022 12:08:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.15 on epoch=136
06/01/2022 12:08:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/01/2022 12:08:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/01/2022 12:08:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=138
06/01/2022 12:08:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=139
06/01/2022 12:08:59 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7785737902199004 on epoch=139
06/01/2022 12:09:02 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/01/2022 12:09:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=140
06/01/2022 12:09:07 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=141
06/01/2022 12:09:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=142
06/01/2022 12:09:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.18 on epoch=142
06/01/2022 12:09:19 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.918095302299974 on epoch=142
06/01/2022 12:09:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/01/2022 12:09:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=144
06/01/2022 12:09:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/01/2022 12:09:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=145
06/01/2022 12:09:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=146
06/01/2022 12:09:39 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.9823428491631258 on epoch=146
06/01/2022 12:09:39 - INFO - __main__ - Saving model with best Classification-F1: 0.918095302299974 -> 0.9823428491631258 on epoch=146, global_step=2050
06/01/2022 12:09:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 12:09:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=147
06/01/2022 12:09:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=148
06/01/2022 12:09:50 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/01/2022 12:09:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 12:09:59 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.9163521361623829 on epoch=149
06/01/2022 12:10:02 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=150
06/01/2022 12:10:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=151
06/01/2022 12:10:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/01/2022 12:10:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/01/2022 12:10:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=153
06/01/2022 12:10:19 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.8058719822239747 on epoch=153
06/01/2022 12:10:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=154
06/01/2022 12:10:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/01/2022 12:10:27 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.17 on epoch=155
06/01/2022 12:10:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/01/2022 12:10:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=157
06/01/2022 12:10:39 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.842049993017735 on epoch=157
06/01/2022 12:10:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=157
06/01/2022 12:10:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=158
06/01/2022 12:10:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=159
06/01/2022 12:10:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/01/2022 12:10:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/01/2022 12:10:59 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.9045076468732383 on epoch=160
06/01/2022 12:11:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=161
06/01/2022 12:11:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/01/2022 12:11:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=162
06/01/2022 12:11:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.14 on epoch=163
06/01/2022 12:11:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=164
06/01/2022 12:11:20 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7799015500628405 on epoch=164
06/01/2022 12:11:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/01/2022 12:11:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/01/2022 12:11:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=166
06/01/2022 12:11:31 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/01/2022 12:11:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=167
06/01/2022 12:11:40 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7768421884882986 on epoch=167
06/01/2022 12:11:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=168
06/01/2022 12:11:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=169
06/01/2022 12:11:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=169
06/01/2022 12:11:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=170
06/01/2022 12:11:54 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=171
06/01/2022 12:12:00 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9186575431736723 on epoch=171
06/01/2022 12:12:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/01/2022 12:12:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/01/2022 12:12:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/01/2022 12:12:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/01/2022 12:12:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/01/2022 12:12:21 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.911301377833636 on epoch=174
06/01/2022 12:12:23 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/01/2022 12:12:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/01/2022 12:12:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/01/2022 12:12:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=177
06/01/2022 12:12:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=178
06/01/2022 12:12:40 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7787397216951296 on epoch=178
06/01/2022 12:12:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/01/2022 12:12:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=179
06/01/2022 12:12:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=180
06/01/2022 12:12:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=181
06/01/2022 12:12:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=182
06/01/2022 12:13:01 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9733181469068565 on epoch=182
06/01/2022 12:13:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/01/2022 12:13:06 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/01/2022 12:13:09 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=184
06/01/2022 12:13:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/01/2022 12:13:14 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
06/01/2022 12:13:21 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9686975303317809 on epoch=185
06/01/2022 12:13:23 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=186
06/01/2022 12:13:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 12:13:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=187
06/01/2022 12:13:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/01/2022 12:13:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=189
06/01/2022 12:13:40 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.9020900657428171 on epoch=189
06/01/2022 12:13:43 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=189
06/01/2022 12:13:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=190
06/01/2022 12:13:48 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
06/01/2022 12:13:51 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=192
06/01/2022 12:13:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=192
06/01/2022 12:14:01 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.9733181469068565 on epoch=192
06/01/2022 12:14:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/01/2022 12:14:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=194
06/01/2022 12:14:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/01/2022 12:14:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/01/2022 12:14:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/01/2022 12:14:21 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9910627007401202 on epoch=196
06/01/2022 12:14:21 - INFO - __main__ - Saving model with best Classification-F1: 0.9823428491631258 -> 0.9910627007401202 on epoch=196, global_step=2750
06/01/2022 12:14:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/01/2022 12:14:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/01/2022 12:14:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/01/2022 12:14:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 12:14:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/01/2022 12:14:40 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=199
06/01/2022 12:14:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=200
06/01/2022 12:14:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=201
06/01/2022 12:14:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 12:14:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=202
06/01/2022 12:14:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 12:15:00 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9910670646557743 on epoch=203
06/01/2022 12:15:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.9910670646557743 on epoch=203, global_step=2850
06/01/2022 12:15:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 12:15:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/01/2022 12:15:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 12:15:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/01/2022 12:15:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/01/2022 12:15:20 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.9776427873202067 on epoch=207
06/01/2022 12:15:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=207
06/01/2022 12:15:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/01/2022 12:15:28 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=209
06/01/2022 12:15:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/01/2022 12:15:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/01/2022 12:15:39 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.9866027789414886 on epoch=210
06/01/2022 12:15:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/01/2022 12:15:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/01/2022 12:15:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=212
06/01/2022 12:15:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/01/2022 12:15:53 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=214
06/01/2022 12:15:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:15:54 - INFO - __main__ - Printing 3 examples
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:15:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:15:54 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 12:15:54 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:15:54 - INFO - __main__ - Printing 3 examples
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 12:15:54 - INFO - __main__ - ['Company']
06/01/2022 12:15:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:15:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:15:55 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 12:15:59 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.9103886794209376 on epoch=214
06/01/2022 12:15:59 - INFO - __main__ - save last model!
06/01/2022 12:15:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 12:15:59 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 12:15:59 - INFO - __main__ - Printing 3 examples
06/01/2022 12:15:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 12:15:59 - INFO - __main__ - ['Animal']
06/01/2022 12:15:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 12:15:59 - INFO - __main__ - ['Animal']
06/01/2022 12:15:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 12:15:59 - INFO - __main__ - ['Village']
06/01/2022 12:15:59 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:16:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:16:05 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 12:16:12 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 12:16:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 12:16:13 - INFO - __main__ - Starting training!
06/01/2022 12:18:12 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_21_0.2_8_predictions.txt
06/01/2022 12:18:12 - INFO - __main__ - Classification-F1 on test data: 0.6787
06/01/2022 12:18:12 - INFO - __main__ - prefix=dbpedia_14_16_21, lr=0.2, bsz=8, dev_performance=0.9910670646557743, test_performance=0.6787157941135364
06/01/2022 12:18:12 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.5, bsz=8 ...
06/01/2022 12:18:13 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:18:13 - INFO - __main__ - Printing 3 examples
06/01/2022 12:18:13 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 12:18:13 - INFO - __main__ - ['Company']
06/01/2022 12:18:13 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 12:18:13 - INFO - __main__ - ['Company']
06/01/2022 12:18:13 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 12:18:13 - INFO - __main__ - ['Company']
06/01/2022 12:18:13 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:18:13 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:18:14 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 12:18:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:18:14 - INFO - __main__ - Printing 3 examples
06/01/2022 12:18:14 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 12:18:14 - INFO - __main__ - ['Company']
06/01/2022 12:18:14 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 12:18:14 - INFO - __main__ - ['Company']
06/01/2022 12:18:14 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 12:18:14 - INFO - __main__ - ['Company']
06/01/2022 12:18:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:18:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:18:14 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 12:18:30 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 12:18:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 12:18:30 - INFO - __main__ - Starting training!
06/01/2022 12:18:34 - INFO - __main__ - Step 10 Global step 10 Train loss 5.50 on epoch=0
06/01/2022 12:18:36 - INFO - __main__ - Step 20 Global step 20 Train loss 3.94 on epoch=1
06/01/2022 12:18:39 - INFO - __main__ - Step 30 Global step 30 Train loss 2.95 on epoch=2
06/01/2022 12:18:42 - INFO - __main__ - Step 40 Global step 40 Train loss 2.16 on epoch=2
06/01/2022 12:18:44 - INFO - __main__ - Step 50 Global step 50 Train loss 1.75 on epoch=3
06/01/2022 12:18:51 - INFO - __main__ - Global step 50 Train loss 3.26 Classification-F1 0.13184703607542378 on epoch=3
06/01/2022 12:18:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13184703607542378 on epoch=3, global_step=50
06/01/2022 12:18:54 - INFO - __main__ - Step 60 Global step 60 Train loss 1.50 on epoch=4
06/01/2022 12:18:56 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=4
06/01/2022 12:18:59 - INFO - __main__ - Step 80 Global step 80 Train loss 1.26 on epoch=5
06/01/2022 12:19:02 - INFO - __main__ - Step 90 Global step 90 Train loss 0.99 on epoch=6
06/01/2022 12:19:04 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=7
06/01/2022 12:19:11 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.3442945996136918 on epoch=7
06/01/2022 12:19:11 - INFO - __main__ - Saving model with best Classification-F1: 0.13184703607542378 -> 0.3442945996136918 on epoch=7, global_step=100
06/01/2022 12:19:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=7
06/01/2022 12:19:17 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=8
06/01/2022 12:19:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=9
06/01/2022 12:19:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.67 on epoch=9
06/01/2022 12:19:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.58 on epoch=10
06/01/2022 12:19:33 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.5526549323109962 on epoch=10
06/01/2022 12:19:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3442945996136918 -> 0.5526549323109962 on epoch=10, global_step=150
06/01/2022 12:19:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.63 on epoch=11
06/01/2022 12:19:38 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=12
06/01/2022 12:19:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=12
06/01/2022 12:19:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.48 on epoch=13
06/01/2022 12:19:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=14
06/01/2022 12:19:54 - INFO - __main__ - Global step 200 Train loss 0.53 Classification-F1 0.5945899979973788 on epoch=14
06/01/2022 12:19:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5526549323109962 -> 0.5945899979973788 on epoch=14, global_step=200
06/01/2022 12:19:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=14
06/01/2022 12:19:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.39 on epoch=15
06/01/2022 12:20:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=16
06/01/2022 12:20:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.43 on epoch=17
06/01/2022 12:20:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=17
06/01/2022 12:20:15 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.627977714282673 on epoch=17
06/01/2022 12:20:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5945899979973788 -> 0.627977714282673 on epoch=17, global_step=250
06/01/2022 12:20:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.37 on epoch=18
06/01/2022 12:20:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=19
06/01/2022 12:20:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=19
06/01/2022 12:20:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=20
06/01/2022 12:20:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=21
06/01/2022 12:20:36 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.5954069254959132 on epoch=21
06/01/2022 12:20:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=22
06/01/2022 12:20:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=22
06/01/2022 12:20:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=23
06/01/2022 12:20:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=24
06/01/2022 12:20:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=24
06/01/2022 12:20:56 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.6166301016470795 on epoch=24
06/01/2022 12:20:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=25
06/01/2022 12:21:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=26
06/01/2022 12:21:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.29 on epoch=27
06/01/2022 12:21:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=27
06/01/2022 12:21:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.22 on epoch=28
06/01/2022 12:21:18 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.7916538219306001 on epoch=28
06/01/2022 12:21:18 - INFO - __main__ - Saving model with best Classification-F1: 0.627977714282673 -> 0.7916538219306001 on epoch=28, global_step=400
06/01/2022 12:21:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=29
06/01/2022 12:21:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=29
06/01/2022 12:21:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=30
06/01/2022 12:21:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=31
06/01/2022 12:21:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.30 on epoch=32
06/01/2022 12:21:39 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.7862970227697375 on epoch=32
06/01/2022 12:21:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=32
06/01/2022 12:21:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=33
06/01/2022 12:21:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
06/01/2022 12:21:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=34
06/01/2022 12:21:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=35
06/01/2022 12:21:59 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.7841204918454494 on epoch=35
06/01/2022 12:22:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=36
06/01/2022 12:22:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/01/2022 12:22:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=37
06/01/2022 12:22:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=38
06/01/2022 12:22:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=39
06/01/2022 12:22:20 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7310265846318978 on epoch=39
06/01/2022 12:22:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=39
06/01/2022 12:22:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=40
06/01/2022 12:22:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=41
06/01/2022 12:22:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=42
06/01/2022 12:22:33 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=42
06/01/2022 12:22:40 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.7390573461528279 on epoch=42
06/01/2022 12:22:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=43
06/01/2022 12:22:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=44
06/01/2022 12:22:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=44
06/01/2022 12:22:50 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=45
06/01/2022 12:22:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=46
06/01/2022 12:23:00 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.7497326203208556 on epoch=46
06/01/2022 12:23:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/01/2022 12:23:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=47
06/01/2022 12:23:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/01/2022 12:23:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/01/2022 12:23:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=49
06/01/2022 12:23:20 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7730961006103322 on epoch=49
06/01/2022 12:23:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
06/01/2022 12:23:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=51
06/01/2022 12:23:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=52
06/01/2022 12:23:31 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=52
06/01/2022 12:23:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=53
06/01/2022 12:23:41 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.8565476792395592 on epoch=53
06/01/2022 12:23:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7916538219306001 -> 0.8565476792395592 on epoch=53, global_step=750
06/01/2022 12:23:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=54
06/01/2022 12:23:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=54
06/01/2022 12:23:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/01/2022 12:23:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=56
06/01/2022 12:23:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/01/2022 12:24:01 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7832968790949786 on epoch=57
06/01/2022 12:24:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=57
06/01/2022 12:24:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=58
06/01/2022 12:24:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/01/2022 12:24:12 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=59
06/01/2022 12:24:15 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=60
06/01/2022 12:24:22 - INFO - __main__ - Global step 850 Train loss 0.11 Classification-F1 0.7028512209489982 on epoch=60
06/01/2022 12:24:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=61
06/01/2022 12:24:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=62
06/01/2022 12:24:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/01/2022 12:24:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=63
06/01/2022 12:24:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=64
06/01/2022 12:24:42 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7573162099302255 on epoch=64
06/01/2022 12:24:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=64
06/01/2022 12:24:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=65
06/01/2022 12:24:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 12:24:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=67
06/01/2022 12:24:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=67
06/01/2022 12:25:04 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.8609740670461734 on epoch=67
06/01/2022 12:25:04 - INFO - __main__ - Saving model with best Classification-F1: 0.8565476792395592 -> 0.8609740670461734 on epoch=67, global_step=950
06/01/2022 12:25:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=68
06/01/2022 12:25:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/01/2022 12:25:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=69
06/01/2022 12:25:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/01/2022 12:25:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=71
06/01/2022 12:25:24 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.8630131964809384 on epoch=71
06/01/2022 12:25:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8609740670461734 -> 0.8630131964809384 on epoch=71, global_step=1000
06/01/2022 12:25:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=72
06/01/2022 12:25:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=72
06/01/2022 12:25:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=73
06/01/2022 12:25:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/01/2022 12:25:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/01/2022 12:25:44 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.749964603795249 on epoch=74
06/01/2022 12:25:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=75
06/01/2022 12:25:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/01/2022 12:25:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=77
06/01/2022 12:25:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=77
06/01/2022 12:25:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/01/2022 12:26:05 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.9226979472140762 on epoch=78
06/01/2022 12:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8630131964809384 -> 0.9226979472140762 on epoch=78, global_step=1100
06/01/2022 12:26:07 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/01/2022 12:26:10 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=79
06/01/2022 12:26:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=80
06/01/2022 12:26:15 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=81
06/01/2022 12:26:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=82
06/01/2022 12:26:25 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.7568347754727683 on epoch=82
06/01/2022 12:26:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=82
06/01/2022 12:26:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=83
06/01/2022 12:26:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=84
06/01/2022 12:26:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=84
06/01/2022 12:26:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=85
06/01/2022 12:26:45 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7946675004312574 on epoch=85
06/01/2022 12:26:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=86
06/01/2022 12:26:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/01/2022 12:26:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=87
06/01/2022 12:26:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/01/2022 12:26:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=89
06/01/2022 12:27:06 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.9143319341421808 on epoch=89
06/01/2022 12:27:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=89
06/01/2022 12:27:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/01/2022 12:27:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=91
06/01/2022 12:27:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/01/2022 12:27:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=92
06/01/2022 12:27:26 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8630131964809384 on epoch=92
06/01/2022 12:27:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=93
06/01/2022 12:27:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/01/2022 12:27:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=94
06/01/2022 12:27:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=95
06/01/2022 12:27:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/01/2022 12:27:47 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7616304170739655 on epoch=96
06/01/2022 12:27:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=97
06/01/2022 12:27:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/01/2022 12:27:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=98
06/01/2022 12:27:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=99
06/01/2022 12:28:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=99
06/01/2022 12:28:07 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7437966914538104 on epoch=99
06/01/2022 12:28:10 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/01/2022 12:28:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=101
06/01/2022 12:28:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/01/2022 12:28:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=102
06/01/2022 12:28:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=103
06/01/2022 12:28:28 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.914360540892799 on epoch=103
06/01/2022 12:28:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=104
06/01/2022 12:28:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=104
06/01/2022 12:28:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/01/2022 12:28:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/01/2022 12:28:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=107
06/01/2022 12:28:48 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7832094729000557 on epoch=107
06/01/2022 12:28:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 12:28:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=108
06/01/2022 12:28:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 12:28:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/01/2022 12:29:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/01/2022 12:29:09 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8511562194525905 on epoch=110
06/01/2022 12:29:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=111
06/01/2022 12:29:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=112
06/01/2022 12:29:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=112
06/01/2022 12:29:20 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/01/2022 12:29:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=114
06/01/2022 12:29:29 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.7088380408499254 on epoch=114
06/01/2022 12:29:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=114
06/01/2022 12:29:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/01/2022 12:29:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/01/2022 12:29:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=117
06/01/2022 12:29:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/01/2022 12:29:50 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7029330954840293 on epoch=117
06/01/2022 12:29:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/01/2022 12:29:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/01/2022 12:29:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=119
06/01/2022 12:30:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/01/2022 12:30:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=121
06/01/2022 12:30:10 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7313273867709351 on epoch=121
06/01/2022 12:30:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/01/2022 12:30:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/01/2022 12:30:18 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/01/2022 12:30:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=124
06/01/2022 12:30:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=124
06/01/2022 12:30:30 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.859241355083089 on epoch=124
06/01/2022 12:30:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/01/2022 12:30:35 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/01/2022 12:30:38 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=127
06/01/2022 12:30:40 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/01/2022 12:30:43 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=128
06/01/2022 12:30:50 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.8140302455292968 on epoch=128
06/01/2022 12:30:52 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=129
06/01/2022 12:30:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/01/2022 12:30:57 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=130
06/01/2022 12:31:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/01/2022 12:31:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/01/2022 12:31:09 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8006782786041555 on epoch=132
06/01/2022 12:31:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=132
06/01/2022 12:31:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=133
06/01/2022 12:31:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/01/2022 12:31:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/01/2022 12:31:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=135
06/01/2022 12:31:29 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8009811109194411 on epoch=135
06/01/2022 12:31:32 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=136
06/01/2022 12:31:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=137
06/01/2022 12:31:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/01/2022 12:31:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 12:31:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=139
06/01/2022 12:31:49 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.9143319341421808 on epoch=139
06/01/2022 12:31:52 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 12:31:55 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 12:31:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/01/2022 12:32:00 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/01/2022 12:32:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/01/2022 12:32:09 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8530585593841642 on epoch=142
06/01/2022 12:32:12 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=143
06/01/2022 12:32:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/01/2022 12:32:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/01/2022 12:32:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 12:32:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/01/2022 12:32:29 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7578796536985375 on epoch=146
06/01/2022 12:32:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 12:32:34 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/01/2022 12:32:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=148
06/01/2022 12:32:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=149
06/01/2022 12:32:42 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/01/2022 12:32:49 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8569648093841642 on epoch=149
06/01/2022 12:32:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=150
06/01/2022 12:32:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=151
06/01/2022 12:32:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=152
06/01/2022 12:33:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 12:33:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 12:33:09 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8530317405554597 on epoch=153
06/01/2022 12:33:12 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/01/2022 12:33:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 12:33:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 12:33:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=156
06/01/2022 12:33:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/01/2022 12:33:29 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.9185272075594656 on epoch=157
06/01/2022 12:33:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/01/2022 12:33:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=158
06/01/2022 12:33:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/01/2022 12:33:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/01/2022 12:33:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 12:33:49 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=160
06/01/2022 12:33:52 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/01/2022 12:33:55 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/01/2022 12:33:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/01/2022 12:34:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/01/2022 12:34:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 12:34:09 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9101742280489908 on epoch=164
06/01/2022 12:34:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=164
06/01/2022 12:34:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 12:34:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 12:34:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=167
06/01/2022 12:34:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 12:34:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.914360540892799 on epoch=167
06/01/2022 12:34:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/01/2022 12:34:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/01/2022 12:34:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/01/2022 12:34:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 12:34:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=171
06/01/2022 12:34:50 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.9098596248422853 on epoch=171
06/01/2022 12:34:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=172
06/01/2022 12:34:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=172
06/01/2022 12:34:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/01/2022 12:35:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/01/2022 12:35:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/01/2022 12:35:10 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.914360540892799 on epoch=174
06/01/2022 12:35:13 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/01/2022 12:35:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=176
06/01/2022 12:35:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 12:35:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 12:35:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/01/2022 12:35:30 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7504531453821515 on epoch=178
06/01/2022 12:35:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/01/2022 12:35:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 12:35:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/01/2022 12:35:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=181
06/01/2022 12:35:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 12:35:50 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7126636939376929 on epoch=182
06/01/2022 12:35:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 12:35:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 12:35:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=184
06/01/2022 12:36:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/01/2022 12:36:04 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 12:36:10 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8551822781898684 on epoch=185
06/01/2022 12:36:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/01/2022 12:36:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 12:36:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 12:36:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 12:36:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/01/2022 12:36:31 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9080236904145823 on epoch=189
06/01/2022 12:36:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/01/2022 12:36:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 12:36:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/01/2022 12:36:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/01/2022 12:36:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=192
06/01/2022 12:36:51 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8512760281898684 on epoch=192
06/01/2022 12:36:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/01/2022 12:36:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/01/2022 12:36:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 12:37:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/01/2022 12:37:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/01/2022 12:37:11 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8445362426116164 on epoch=196
06/01/2022 12:37:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 12:37:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/01/2022 12:37:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 12:37:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=199
06/01/2022 12:37:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/01/2022 12:37:31 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9060034883943803 on epoch=199
06/01/2022 12:37:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/01/2022 12:37:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/01/2022 12:37:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 12:37:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 12:37:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/01/2022 12:37:51 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8551822781898684 on epoch=203
06/01/2022 12:37:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 12:37:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 12:37:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 12:38:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=206
06/01/2022 12:38:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 12:38:11 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8551822781898684 on epoch=207
06/01/2022 12:38:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/01/2022 12:38:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 12:38:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 12:38:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 12:38:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 12:38:30 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9100178253119429 on epoch=210
06/01/2022 12:38:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 12:38:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 12:38:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 12:38:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=213
06/01/2022 12:38:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 12:38:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:38:45 - INFO - __main__ - Printing 3 examples
06/01/2022 12:38:45 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 12:38:45 - INFO - __main__ - ['Company']
06/01/2022 12:38:45 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 12:38:45 - INFO - __main__ - ['Company']
06/01/2022 12:38:45 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 12:38:45 - INFO - __main__ - ['Company']
06/01/2022 12:38:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:38:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:38:46 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 12:38:46 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:38:46 - INFO - __main__ - Printing 3 examples
06/01/2022 12:38:46 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 12:38:46 - INFO - __main__ - ['Company']
06/01/2022 12:38:46 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 12:38:46 - INFO - __main__ - ['Company']
06/01/2022 12:38:46 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 12:38:46 - INFO - __main__ - ['Company']
06/01/2022 12:38:46 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:38:46 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:38:46 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 12:38:50 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8630131964809384 on epoch=214
06/01/2022 12:38:50 - INFO - __main__ - save last model!
06/01/2022 12:38:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 12:38:50 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 12:38:50 - INFO - __main__ - Printing 3 examples
06/01/2022 12:38:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 12:38:50 - INFO - __main__ - ['Animal']
06/01/2022 12:38:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 12:38:50 - INFO - __main__ - ['Animal']
06/01/2022 12:38:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 12:38:50 - INFO - __main__ - ['Village']
06/01/2022 12:38:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:38:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:38:56 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 12:39:02 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 12:39:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 12:39:02 - INFO - __main__ - Starting training!
06/01/2022 12:41:05 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_42_0.5_8_predictions.txt
06/01/2022 12:41:05 - INFO - __main__ - Classification-F1 on test data: 0.7204
06/01/2022 12:41:06 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.5, bsz=8, dev_performance=0.9226979472140762, test_performance=0.7204009362513734
06/01/2022 12:41:06 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.4, bsz=8 ...
06/01/2022 12:41:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:41:07 - INFO - __main__ - Printing 3 examples
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:41:07 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:41:07 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 12:41:07 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 12:41:07 - INFO - __main__ - Printing 3 examples
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 12:41:07 - INFO - __main__ - ['Company']
06/01/2022 12:41:07 - INFO - __main__ - Tokenizing Input ...
06/01/2022 12:41:08 - INFO - __main__ - Tokenizing Output ...
06/01/2022 12:41:08 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 12:41:26 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 12:41:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 12:41:27 - INFO - __main__ - Starting training!
06/01/2022 12:41:31 - INFO - __main__ - Step 10 Global step 10 Train loss 5.28 on epoch=0
06/01/2022 12:41:33 - INFO - __main__ - Step 20 Global step 20 Train loss 4.05 on epoch=1
06/01/2022 12:41:36 - INFO - __main__ - Step 30 Global step 30 Train loss 3.16 on epoch=2
06/01/2022 12:41:39 - INFO - __main__ - Step 40 Global step 40 Train loss 2.61 on epoch=2
06/01/2022 12:41:41 - INFO - __main__ - Step 50 Global step 50 Train loss 2.07 on epoch=3
06/01/2022 12:41:48 - INFO - __main__ - Global step 50 Train loss 3.44 Classification-F1 0.07773407746937158 on epoch=3
06/01/2022 12:41:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07773407746937158 on epoch=3, global_step=50
06/01/2022 12:41:50 - INFO - __main__ - Step 60 Global step 60 Train loss 1.85 on epoch=4
06/01/2022 12:41:53 - INFO - __main__ - Step 70 Global step 70 Train loss 1.39 on epoch=4
06/01/2022 12:41:56 - INFO - __main__ - Step 80 Global step 80 Train loss 1.26 on epoch=5
06/01/2022 12:41:58 - INFO - __main__ - Step 90 Global step 90 Train loss 1.16 on epoch=6
06/01/2022 12:42:01 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=7
06/01/2022 12:42:08 - INFO - __main__ - Global step 100 Train loss 1.32 Classification-F1 0.3301725520116324 on epoch=7
06/01/2022 12:42:08 - INFO - __main__ - Saving model with best Classification-F1: 0.07773407746937158 -> 0.3301725520116324 on epoch=7, global_step=100
06/01/2022 12:42:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.87 on epoch=7
06/01/2022 12:42:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=8
06/01/2022 12:42:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=9
06/01/2022 12:42:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=9
06/01/2022 12:42:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=10
06/01/2022 12:42:29 - INFO - __main__ - Global step 150 Train loss 0.75 Classification-F1 0.42184963441817813 on epoch=10
06/01/2022 12:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3301725520116324 -> 0.42184963441817813 on epoch=10, global_step=150
06/01/2022 12:42:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=11
06/01/2022 12:42:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=12
06/01/2022 12:42:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=12
06/01/2022 12:42:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=13
06/01/2022 12:42:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.52 on epoch=14
06/01/2022 12:42:49 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.611382037428549 on epoch=14
06/01/2022 12:42:49 - INFO - __main__ - Saving model with best Classification-F1: 0.42184963441817813 -> 0.611382037428549 on epoch=14, global_step=200
06/01/2022 12:42:52 - INFO - __main__ - Step 210 Global step 210 Train loss 0.48 on epoch=14
06/01/2022 12:42:54 - INFO - __main__ - Step 220 Global step 220 Train loss 0.42 on epoch=15
06/01/2022 12:42:57 - INFO - __main__ - Step 230 Global step 230 Train loss 0.44 on epoch=16
06/01/2022 12:43:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=17
06/01/2022 12:43:02 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=17
06/01/2022 12:43:09 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.6427176556613522 on epoch=17
06/01/2022 12:43:09 - INFO - __main__ - Saving model with best Classification-F1: 0.611382037428549 -> 0.6427176556613522 on epoch=17, global_step=250
06/01/2022 12:43:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.40 on epoch=18
06/01/2022 12:43:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=19
06/01/2022 12:43:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=19
06/01/2022 12:43:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.42 on epoch=20
06/01/2022 12:43:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=21
06/01/2022 12:43:30 - INFO - __main__ - Global step 300 Train loss 0.41 Classification-F1 0.6429502253131535 on epoch=21
06/01/2022 12:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6427176556613522 -> 0.6429502253131535 on epoch=21, global_step=300
06/01/2022 12:43:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=22
06/01/2022 12:43:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=22
06/01/2022 12:43:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=23
06/01/2022 12:43:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=24
06/01/2022 12:43:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=24
06/01/2022 12:43:50 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.6414342974143409 on epoch=24
06/01/2022 12:43:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=25
06/01/2022 12:43:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=26
06/01/2022 12:43:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=27
06/01/2022 12:44:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=27
06/01/2022 12:44:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/01/2022 12:44:11 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.6517028007889888 on epoch=28
06/01/2022 12:44:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6429502253131535 -> 0.6517028007889888 on epoch=28, global_step=400
06/01/2022 12:44:14 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=29
06/01/2022 12:44:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=29
06/01/2022 12:44:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=30
06/01/2022 12:44:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.25 on epoch=31
06/01/2022 12:44:24 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=32
06/01/2022 12:44:31 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.646648287849769 on epoch=32
06/01/2022 12:44:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=32
06/01/2022 12:44:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=33
06/01/2022 12:44:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.24 on epoch=34
06/01/2022 12:44:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=34
06/01/2022 12:44:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=35
06/01/2022 12:44:52 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.6047575674770946 on epoch=35
06/01/2022 12:44:54 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=36
06/01/2022 12:44:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=37
06/01/2022 12:45:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=37
06/01/2022 12:45:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/01/2022 12:45:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=39
06/01/2022 12:45:12 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6261238793686611 on epoch=39
06/01/2022 12:45:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
06/01/2022 12:45:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=40
06/01/2022 12:45:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=41
06/01/2022 12:45:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=42
06/01/2022 12:45:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=42
06/01/2022 12:45:32 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6183693010271153 on epoch=42
06/01/2022 12:45:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=43
06/01/2022 12:45:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/01/2022 12:45:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=44
06/01/2022 12:45:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=45
06/01/2022 12:45:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/01/2022 12:45:52 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.6242856890571383 on epoch=46
06/01/2022 12:45:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/01/2022 12:45:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=47
06/01/2022 12:46:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=48
06/01/2022 12:46:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/01/2022 12:46:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=49
06/01/2022 12:46:13 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.7242974609198518 on epoch=49
06/01/2022 12:46:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6517028007889888 -> 0.7242974609198518 on epoch=49, global_step=700
06/01/2022 12:46:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=50
06/01/2022 12:46:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=51
06/01/2022 12:46:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
06/01/2022 12:46:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=52
06/01/2022 12:46:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=53
06/01/2022 12:46:33 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.6705169282818338 on epoch=53
06/01/2022 12:46:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=54
06/01/2022 12:46:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=54
06/01/2022 12:46:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=55
06/01/2022 12:46:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=56
06/01/2022 12:46:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=57
06/01/2022 12:46:54 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.7132866781823137 on epoch=57
06/01/2022 12:46:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=57
06/01/2022 12:46:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=58
06/01/2022 12:47:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=59
06/01/2022 12:47:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=59
06/01/2022 12:47:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=60
06/01/2022 12:47:14 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.68185715172008 on epoch=60
06/01/2022 12:47:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=61
06/01/2022 12:47:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=62
06/01/2022 12:47:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=62
06/01/2022 12:47:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=63
06/01/2022 12:47:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/01/2022 12:47:34 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.8084968329051021 on epoch=64
06/01/2022 12:47:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7242974609198518 -> 0.8084968329051021 on epoch=64, global_step=900
06/01/2022 12:47:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=64
06/01/2022 12:47:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=65
06/01/2022 12:47:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=66
06/01/2022 12:47:45 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/01/2022 12:47:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=67
06/01/2022 12:47:54 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.9228413163897036 on epoch=67
06/01/2022 12:47:54 - INFO - __main__ - Saving model with best Classification-F1: 0.8084968329051021 -> 0.9228413163897036 on epoch=67, global_step=950
06/01/2022 12:47:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/01/2022 12:48:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/01/2022 12:48:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/01/2022 12:48:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=70
06/01/2022 12:48:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=71
06/01/2022 12:48:15 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8532653383934219 on epoch=71
06/01/2022 12:48:17 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=72
06/01/2022 12:48:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=72
06/01/2022 12:48:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/01/2022 12:48:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/01/2022 12:48:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=74
06/01/2022 12:48:34 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7418737102204844 on epoch=74
06/01/2022 12:48:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/01/2022 12:48:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=76
06/01/2022 12:48:42 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/01/2022 12:48:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=77
06/01/2022 12:48:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=78
06/01/2022 12:48:54 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7993625602733763 on epoch=78
06/01/2022 12:48:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/01/2022 12:48:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=79
06/01/2022 12:49:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=80
06/01/2022 12:49:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/01/2022 12:49:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=82
06/01/2022 12:49:15 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.9142261322906483 on epoch=82
06/01/2022 12:49:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=82
06/01/2022 12:49:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=83
06/01/2022 12:49:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=84
06/01/2022 12:49:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/01/2022 12:49:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=85
06/01/2022 12:49:35 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.9910627007401202 on epoch=85
06/01/2022 12:49:35 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9910627007401202 on epoch=85, global_step=1200
06/01/2022 12:49:38 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/01/2022 12:49:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 12:49:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/01/2022 12:49:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/01/2022 12:49:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=89
06/01/2022 12:49:55 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.9163766699250571 on epoch=89
06/01/2022 12:49:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=89
06/01/2022 12:50:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=90
06/01/2022 12:50:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/01/2022 12:50:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=92
06/01/2022 12:50:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/01/2022 12:50:15 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.914360540892799 on epoch=92
06/01/2022 12:50:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=93
06/01/2022 12:50:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=94
06/01/2022 12:50:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=94
06/01/2022 12:50:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=95
06/01/2022 12:50:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
06/01/2022 12:50:35 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.9865940511101802 on epoch=96
06/01/2022 12:50:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=97
06/01/2022 12:50:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/01/2022 12:50:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/01/2022 12:50:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/01/2022 12:50:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=99
06/01/2022 12:50:55 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7561961520150358 on epoch=99
06/01/2022 12:50:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=100
06/01/2022 12:51:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=101
06/01/2022 12:51:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/01/2022 12:51:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=102
06/01/2022 12:51:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=103
06/01/2022 12:51:15 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.7575028316963801 on epoch=103
06/01/2022 12:51:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/01/2022 12:51:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=104
06/01/2022 12:51:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=105
06/01/2022 12:51:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=106
06/01/2022 12:51:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/01/2022 12:51:35 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9821297653958945 on epoch=107
06/01/2022 12:51:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=107
06/01/2022 12:51:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/01/2022 12:51:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 12:51:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/01/2022 12:51:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/01/2022 12:51:54 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8586982168739677 on epoch=110
06/01/2022 12:51:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/01/2022 12:52:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/01/2022 12:52:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/01/2022 12:52:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=113
06/01/2022 12:52:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/01/2022 12:52:14 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8046575815076764 on epoch=114
06/01/2022 12:52:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/01/2022 12:52:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/01/2022 12:52:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=116
06/01/2022 12:52:25 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=117
06/01/2022 12:52:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=117
06/01/2022 12:52:34 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.9120755946562398 on epoch=117
06/01/2022 12:52:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=118
06/01/2022 12:52:39 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=119
06/01/2022 12:52:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/01/2022 12:52:44 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=120
06/01/2022 12:52:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=121
06/01/2022 12:52:54 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9819717916492109 on epoch=121
06/01/2022 12:52:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=122
06/01/2022 12:52:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=122
06/01/2022 12:53:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=123
06/01/2022 12:53:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/01/2022 12:53:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/01/2022 12:53:14 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9185272075594656 on epoch=124
06/01/2022 12:53:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/01/2022 12:53:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/01/2022 12:53:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=127
06/01/2022 12:53:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=127
06/01/2022 12:53:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/01/2022 12:53:35 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.9111539356700646 on epoch=128
06/01/2022 12:53:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=129
06/01/2022 12:53:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=129
06/01/2022 12:53:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 12:53:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/01/2022 12:53:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=132
06/01/2022 12:53:55 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8523128752967463 on epoch=132
06/01/2022 12:53:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/01/2022 12:54:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=133
06/01/2022 12:54:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/01/2022 12:54:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/01/2022 12:54:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/01/2022 12:54:15 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9026177804672426 on epoch=135
06/01/2022 12:54:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=136
06/01/2022 12:54:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/01/2022 12:54:23 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=137
06/01/2022 12:54:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=138
06/01/2022 12:54:28 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 12:54:34 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7048684451998076 on epoch=139
06/01/2022 12:54:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=139
06/01/2022 12:54:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 12:54:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/01/2022 12:54:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=142
06/01/2022 12:54:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/01/2022 12:54:54 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7467750383162569 on epoch=142
06/01/2022 12:54:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=143
06/01/2022 12:54:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=144
06/01/2022 12:55:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/01/2022 12:55:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=145
06/01/2022 12:55:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=146
06/01/2022 12:55:14 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8507436112274822 on epoch=146
06/01/2022 12:55:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=147
06/01/2022 12:55:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/01/2022 12:55:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 12:55:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 12:55:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 12:55:33 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9077131601958205 on epoch=149
06/01/2022 12:55:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/01/2022 12:55:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/01/2022 12:55:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=152
06/01/2022 12:55:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=152
06/01/2022 12:55:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=153
06/01/2022 12:55:53 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9776348295916607 on epoch=153
06/01/2022 12:55:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=154
06/01/2022 12:55:58 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=154
06/01/2022 12:56:01 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=155
06/01/2022 12:56:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=156
06/01/2022 12:56:06 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=157
06/01/2022 12:56:13 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.9144753033178081 on epoch=157
06/01/2022 12:56:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 12:56:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/01/2022 12:56:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/01/2022 12:56:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/01/2022 12:56:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/01/2022 12:56:33 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9144753033178079 on epoch=160
06/01/2022 12:56:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=161
06/01/2022 12:56:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=162
06/01/2022 12:56:41 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 12:56:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=163
06/01/2022 12:56:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 12:56:53 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.855304467828187 on epoch=164
06/01/2022 12:56:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=164
06/01/2022 12:56:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=165
06/01/2022 12:57:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 12:57:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=167
06/01/2022 12:57:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 12:57:13 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.9864404412791509 on epoch=167
06/01/2022 12:57:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 12:57:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/01/2022 12:57:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/01/2022 12:57:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/01/2022 12:57:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=171
06/01/2022 12:57:33 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9226979472140762 on epoch=171
06/01/2022 12:57:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=172
06/01/2022 12:57:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/01/2022 12:57:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/01/2022 12:57:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/01/2022 12:57:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 12:57:53 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9137811934697361 on epoch=174
06/01/2022 12:57:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/01/2022 12:57:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=176
06/01/2022 12:58:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/01/2022 12:58:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/01/2022 12:58:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/01/2022 12:58:13 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.9091337336498626 on epoch=178
06/01/2022 12:58:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/01/2022 12:58:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 12:58:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 12:58:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/01/2022 12:58:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/01/2022 12:58:33 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8437414467253177 on epoch=182
06/01/2022 12:58:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 12:58:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=183
06/01/2022 12:58:41 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 12:58:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/01/2022 12:58:46 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/01/2022 12:58:53 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8237414467253177 on epoch=185
06/01/2022 12:58:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/01/2022 12:58:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 12:59:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/01/2022 12:59:04 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 12:59:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/01/2022 12:59:13 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9142130987292276 on epoch=189
06/01/2022 12:59:16 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 12:59:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 12:59:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 12:59:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 12:59:27 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/01/2022 12:59:33 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9029443253352173 on epoch=192
06/01/2022 12:59:36 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/01/2022 12:59:39 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/01/2022 12:59:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=194
06/01/2022 12:59:44 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=195
06/01/2022 12:59:47 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=196
06/01/2022 12:59:53 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9864404412791509 on epoch=196
06/01/2022 12:59:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 12:59:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/01/2022 13:00:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 13:00:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=199
06/01/2022 13:00:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/01/2022 13:00:13 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9775171065493645 on epoch=199
06/01/2022 13:00:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 13:00:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 13:00:21 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=202
06/01/2022 13:00:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/01/2022 13:00:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=203
06/01/2022 13:00:32 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=203
06/01/2022 13:00:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 13:00:38 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=204
06/01/2022 13:00:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 13:00:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 13:00:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/01/2022 13:00:52 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.99553135037006 on epoch=207
06/01/2022 13:00:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9910627007401202 -> 0.99553135037006 on epoch=207, global_step=2900
06/01/2022 13:00:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=207
06/01/2022 13:00:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=208
06/01/2022 13:01:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/01/2022 13:01:03 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=209
06/01/2022 13:01:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 13:01:12 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.863147605083089 on epoch=210
06/01/2022 13:01:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 13:01:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=212
06/01/2022 13:01:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=212
06/01/2022 13:01:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/01/2022 13:01:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 13:01:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:01:26 - INFO - __main__ - Printing 3 examples
06/01/2022 13:01:26 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 13:01:26 - INFO - __main__ - ['Company']
06/01/2022 13:01:26 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 13:01:26 - INFO - __main__ - ['Company']
06/01/2022 13:01:26 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 13:01:26 - INFO - __main__ - ['Company']
06/01/2022 13:01:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:01:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:01:27 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:01:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:01:27 - INFO - __main__ - Printing 3 examples
06/01/2022 13:01:27 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 13:01:27 - INFO - __main__ - ['Company']
06/01/2022 13:01:27 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 13:01:27 - INFO - __main__ - ['Company']
06/01/2022 13:01:27 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 13:01:27 - INFO - __main__ - ['Company']
06/01/2022 13:01:27 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:01:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:01:27 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:01:32 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9202458399343828 on epoch=214
06/01/2022 13:01:32 - INFO - __main__ - save last model!
06/01/2022 13:01:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 13:01:32 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 13:01:32 - INFO - __main__ - Printing 3 examples
06/01/2022 13:01:32 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 13:01:32 - INFO - __main__ - ['Animal']
06/01/2022 13:01:32 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 13:01:32 - INFO - __main__ - ['Animal']
06/01/2022 13:01:32 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 13:01:32 - INFO - __main__ - ['Village']
06/01/2022 13:01:32 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:01:34 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:01:38 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 13:01:42 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:01:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:01:43 - INFO - __main__ - Starting training!
06/01/2022 13:03:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_42_0.4_8_predictions.txt
06/01/2022 13:03:49 - INFO - __main__ - Classification-F1 on test data: 0.5223
06/01/2022 13:03:50 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.4, bsz=8, dev_performance=0.99553135037006, test_performance=0.522285674591244
06/01/2022 13:03:50 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.3, bsz=8 ...
06/01/2022 13:03:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:03:51 - INFO - __main__ - Printing 3 examples
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:03:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:03:51 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:03:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:03:51 - INFO - __main__ - Printing 3 examples
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 13:03:51 - INFO - __main__ - ['Company']
06/01/2022 13:03:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:03:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:03:51 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:04:09 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:04:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:04:09 - INFO - __main__ - Starting training!
06/01/2022 13:04:13 - INFO - __main__ - Step 10 Global step 10 Train loss 5.39 on epoch=0
06/01/2022 13:04:16 - INFO - __main__ - Step 20 Global step 20 Train loss 4.09 on epoch=1
06/01/2022 13:04:19 - INFO - __main__ - Step 30 Global step 30 Train loss 3.32 on epoch=2
06/01/2022 13:04:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.88 on epoch=2
06/01/2022 13:04:24 - INFO - __main__ - Step 50 Global step 50 Train loss 2.45 on epoch=3
06/01/2022 13:04:31 - INFO - __main__ - Global step 50 Train loss 3.63 Classification-F1 0.06359991549067179 on epoch=3
06/01/2022 13:04:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06359991549067179 on epoch=3, global_step=50
06/01/2022 13:04:33 - INFO - __main__ - Step 60 Global step 60 Train loss 2.17 on epoch=4
06/01/2022 13:04:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.77 on epoch=4
06/01/2022 13:04:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.56 on epoch=5
06/01/2022 13:04:41 - INFO - __main__ - Step 90 Global step 90 Train loss 1.43 on epoch=6
06/01/2022 13:04:44 - INFO - __main__ - Step 100 Global step 100 Train loss 1.24 on epoch=7
06/01/2022 13:04:51 - INFO - __main__ - Global step 100 Train loss 1.64 Classification-F1 0.2037041910203742 on epoch=7
06/01/2022 13:04:51 - INFO - __main__ - Saving model with best Classification-F1: 0.06359991549067179 -> 0.2037041910203742 on epoch=7, global_step=100
06/01/2022 13:04:54 - INFO - __main__ - Step 110 Global step 110 Train loss 1.10 on epoch=7
06/01/2022 13:04:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=8
06/01/2022 13:04:59 - INFO - __main__ - Step 130 Global step 130 Train loss 0.97 on epoch=9
06/01/2022 13:05:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=9
06/01/2022 13:05:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=10
06/01/2022 13:05:13 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.422366846181713 on epoch=10
06/01/2022 13:05:13 - INFO - __main__ - Saving model with best Classification-F1: 0.2037041910203742 -> 0.422366846181713 on epoch=10, global_step=150
06/01/2022 13:05:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=11
06/01/2022 13:05:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=12
06/01/2022 13:05:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.68 on epoch=12
06/01/2022 13:05:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=13
06/01/2022 13:05:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=14
06/01/2022 13:05:34 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.4484843223050068 on epoch=14
06/01/2022 13:05:34 - INFO - __main__ - Saving model with best Classification-F1: 0.422366846181713 -> 0.4484843223050068 on epoch=14, global_step=200
06/01/2022 13:05:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=14
06/01/2022 13:05:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=15
06/01/2022 13:05:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=16
06/01/2022 13:05:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=17
06/01/2022 13:05:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=17
06/01/2022 13:05:56 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.4834214924157998 on epoch=17
06/01/2022 13:05:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4484843223050068 -> 0.4834214924157998 on epoch=17, global_step=250
06/01/2022 13:05:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=18
06/01/2022 13:06:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=19
06/01/2022 13:06:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=19
06/01/2022 13:06:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=20
06/01/2022 13:06:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=21
06/01/2022 13:06:16 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.49564480471738537 on epoch=21
06/01/2022 13:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4834214924157998 -> 0.49564480471738537 on epoch=21, global_step=300
06/01/2022 13:06:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=22
06/01/2022 13:06:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=22
06/01/2022 13:06:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=23
06/01/2022 13:06:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=24
06/01/2022 13:06:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.50 on epoch=24
06/01/2022 13:06:37 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.5974526776602612 on epoch=24
06/01/2022 13:06:37 - INFO - __main__ - Saving model with best Classification-F1: 0.49564480471738537 -> 0.5974526776602612 on epoch=24, global_step=350
06/01/2022 13:06:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=25
06/01/2022 13:06:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/01/2022 13:06:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=27
06/01/2022 13:06:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/01/2022 13:06:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=28
06/01/2022 13:06:57 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.6600793356748117 on epoch=28
06/01/2022 13:06:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5974526776602612 -> 0.6600793356748117 on epoch=28, global_step=400
06/01/2022 13:07:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=29
06/01/2022 13:07:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=29
06/01/2022 13:07:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=30
06/01/2022 13:07:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=31
06/01/2022 13:07:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=32
06/01/2022 13:07:18 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.5082236535865569 on epoch=32
06/01/2022 13:07:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=32
06/01/2022 13:07:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=33
06/01/2022 13:07:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=34
06/01/2022 13:07:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=34
06/01/2022 13:07:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=35
06/01/2022 13:07:38 - INFO - __main__ - Global step 500 Train loss 0.31 Classification-F1 0.6598157982384575 on epoch=35
06/01/2022 13:07:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=36
06/01/2022 13:07:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=37
06/01/2022 13:07:46 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=37
06/01/2022 13:07:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=38
06/01/2022 13:07:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=39
06/01/2022 13:07:58 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.7730441122563395 on epoch=39
06/01/2022 13:07:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6600793356748117 -> 0.7730441122563395 on epoch=39, global_step=550
06/01/2022 13:08:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=39
06/01/2022 13:08:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=40
06/01/2022 13:08:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=41
06/01/2022 13:08:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=42
06/01/2022 13:08:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
06/01/2022 13:08:19 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.6852173165345208 on epoch=42
06/01/2022 13:08:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=43
06/01/2022 13:08:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=44
06/01/2022 13:08:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=44
06/01/2022 13:08:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.26 on epoch=45
06/01/2022 13:08:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=46
06/01/2022 13:08:39 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.7099611573715826 on epoch=46
06/01/2022 13:08:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=47
06/01/2022 13:08:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=47
06/01/2022 13:08:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=48
06/01/2022 13:08:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/01/2022 13:08:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=49
06/01/2022 13:08:58 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.6846528301087376 on epoch=49
06/01/2022 13:09:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=50
06/01/2022 13:09:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.27 on epoch=51
06/01/2022 13:09:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=52
06/01/2022 13:09:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/01/2022 13:09:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=53
06/01/2022 13:09:19 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.6757468969992689 on epoch=53
06/01/2022 13:09:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
06/01/2022 13:09:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=54
06/01/2022 13:09:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=55
06/01/2022 13:09:29 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/01/2022 13:09:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=57
06/01/2022 13:09:39 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.5641069494578224 on epoch=57
06/01/2022 13:09:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=57
06/01/2022 13:09:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=58
06/01/2022 13:09:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=59
06/01/2022 13:09:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=59
06/01/2022 13:09:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=60
06/01/2022 13:09:59 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.6290797374668342 on epoch=60
06/01/2022 13:10:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=61
06/01/2022 13:10:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=62
06/01/2022 13:10:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.20 on epoch=62
06/01/2022 13:10:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=63
06/01/2022 13:10:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/01/2022 13:10:19 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6304182188053156 on epoch=64
06/01/2022 13:10:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=64
06/01/2022 13:10:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/01/2022 13:10:27 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=66
06/01/2022 13:10:30 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=67
06/01/2022 13:10:32 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=67
06/01/2022 13:10:39 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.7078874210159789 on epoch=67
06/01/2022 13:10:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/01/2022 13:10:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=69
06/01/2022 13:10:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=69
06/01/2022 13:10:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
06/01/2022 13:10:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=71
06/01/2022 13:10:58 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5048112816974297 on epoch=71
06/01/2022 13:11:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/01/2022 13:11:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=72
06/01/2022 13:11:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=73
06/01/2022 13:11:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/01/2022 13:11:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=74
06/01/2022 13:11:18 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7592293061207004 on epoch=74
06/01/2022 13:11:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=75
06/01/2022 13:11:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=76
06/01/2022 13:11:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=77
06/01/2022 13:11:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=77
06/01/2022 13:11:32 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=78
06/01/2022 13:11:39 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.620512785038901 on epoch=78
06/01/2022 13:11:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=79
06/01/2022 13:11:44 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=79
06/01/2022 13:11:47 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=80
06/01/2022 13:11:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=81
06/01/2022 13:11:52 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=82
06/01/2022 13:11:59 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6794900251606533 on epoch=82
06/01/2022 13:12:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/01/2022 13:12:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=83
06/01/2022 13:12:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=84
06/01/2022 13:12:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=84
06/01/2022 13:12:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/01/2022 13:12:18 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6545773524720893 on epoch=85
06/01/2022 13:12:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=86
06/01/2022 13:12:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=87
06/01/2022 13:12:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=87
06/01/2022 13:12:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=88
06/01/2022 13:12:32 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=89
06/01/2022 13:12:39 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.7931906030577757 on epoch=89
06/01/2022 13:12:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7730441122563395 -> 0.7931906030577757 on epoch=89, global_step=1250
06/01/2022 13:12:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=89
06/01/2022 13:12:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=90
06/01/2022 13:12:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=91
06/01/2022 13:12:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=92
06/01/2022 13:12:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=92
06/01/2022 13:12:58 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.8125290909696183 on epoch=92
06/01/2022 13:12:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7931906030577757 -> 0.8125290909696183 on epoch=92, global_step=1300
06/01/2022 13:13:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=93
06/01/2022 13:13:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=94
06/01/2022 13:13:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=94
06/01/2022 13:13:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=95
06/01/2022 13:13:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=96
06/01/2022 13:13:18 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.846889461113599 on epoch=96
06/01/2022 13:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.8125290909696183 -> 0.846889461113599 on epoch=96, global_step=1350
06/01/2022 13:13:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=97
06/01/2022 13:13:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=97
06/01/2022 13:13:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/01/2022 13:13:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=99
06/01/2022 13:13:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=99
06/01/2022 13:13:38 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7461574106958636 on epoch=99
06/01/2022 13:13:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/01/2022 13:13:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=101
06/01/2022 13:13:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/01/2022 13:13:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=102
06/01/2022 13:13:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/01/2022 13:13:58 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8369715298142717 on epoch=103
06/01/2022 13:14:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=104
06/01/2022 13:14:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/01/2022 13:14:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=105
06/01/2022 13:14:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=106
06/01/2022 13:14:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=107
06/01/2022 13:14:19 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.9226979472140762 on epoch=107
06/01/2022 13:14:19 - INFO - __main__ - Saving model with best Classification-F1: 0.846889461113599 -> 0.9226979472140762 on epoch=107, global_step=1500
06/01/2022 13:14:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=107
06/01/2022 13:14:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=108
06/01/2022 13:14:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=109
06/01/2022 13:14:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/01/2022 13:14:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=110
06/01/2022 13:14:39 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7919240698499468 on epoch=110
06/01/2022 13:14:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/01/2022 13:14:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=112
06/01/2022 13:14:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=112
06/01/2022 13:14:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=113
06/01/2022 13:14:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/01/2022 13:14:59 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.723257439991311 on epoch=114
06/01/2022 13:15:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=114
06/01/2022 13:15:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=115
06/01/2022 13:15:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=116
06/01/2022 13:15:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/01/2022 13:15:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=117
06/01/2022 13:15:19 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7994454347395523 on epoch=117
06/01/2022 13:15:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/01/2022 13:15:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/01/2022 13:15:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=119
06/01/2022 13:15:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=120
06/01/2022 13:15:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/01/2022 13:15:38 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7957653703384253 on epoch=121
06/01/2022 13:15:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=122
06/01/2022 13:15:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/01/2022 13:15:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/01/2022 13:15:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=124
06/01/2022 13:15:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=124
06/01/2022 13:15:59 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8042534882291474 on epoch=124
06/01/2022 13:16:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=125
06/01/2022 13:16:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/01/2022 13:16:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/01/2022 13:16:09 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/01/2022 13:16:12 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/01/2022 13:16:19 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8080600548440633 on epoch=128
06/01/2022 13:16:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=129
06/01/2022 13:16:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=129
06/01/2022 13:16:27 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=130
06/01/2022 13:16:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=131
06/01/2022 13:16:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=132
06/01/2022 13:16:39 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.8551930596285435 on epoch=132
06/01/2022 13:16:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=132
06/01/2022 13:16:44 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/01/2022 13:16:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/01/2022 13:16:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/01/2022 13:16:52 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=135
06/01/2022 13:16:58 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8046575815076764 on epoch=135
06/01/2022 13:17:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/01/2022 13:17:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/01/2022 13:17:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=137
06/01/2022 13:17:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=138
06/01/2022 13:17:11 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 13:17:18 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.8066737105399345 on epoch=139
06/01/2022 13:17:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=139
06/01/2022 13:17:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 13:17:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/01/2022 13:17:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=142
06/01/2022 13:17:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=142
06/01/2022 13:17:38 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7986988910236964 on epoch=142
06/01/2022 13:17:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=143
06/01/2022 13:17:43 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=144
06/01/2022 13:17:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 13:17:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 13:17:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=146
06/01/2022 13:17:57 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9143564679048549 on epoch=146
06/01/2022 13:18:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 13:18:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=147
06/01/2022 13:18:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=148
06/01/2022 13:18:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=149
06/01/2022 13:18:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 13:18:17 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.859103128054741 on epoch=149
06/01/2022 13:18:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 13:18:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=151
06/01/2022 13:18:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/01/2022 13:18:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=152
06/01/2022 13:18:30 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 13:18:37 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9603498692269004 on epoch=153
06/01/2022 13:18:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9226979472140762 -> 0.9603498692269004 on epoch=153, global_step=2150
06/01/2022 13:18:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=154
06/01/2022 13:18:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=154
06/01/2022 13:18:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=155
06/01/2022 13:18:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/01/2022 13:18:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/01/2022 13:18:56 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7874472803274057 on epoch=157
06/01/2022 13:18:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=157
06/01/2022 13:19:01 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=158
06/01/2022 13:19:04 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/01/2022 13:19:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=159
06/01/2022 13:19:09 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=160
06/01/2022 13:19:16 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7968905225072208 on epoch=160
06/01/2022 13:19:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/01/2022 13:19:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 13:19:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=162
06/01/2022 13:19:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=163
06/01/2022 13:19:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/01/2022 13:19:35 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7837672159262787 on epoch=164
06/01/2022 13:19:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=164
06/01/2022 13:19:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=165
06/01/2022 13:19:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 13:19:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=167
06/01/2022 13:19:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 13:19:54 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8608626588465298 on epoch=167
06/01/2022 13:19:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=168
06/01/2022 13:20:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/01/2022 13:20:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 13:20:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=170
06/01/2022 13:20:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/01/2022 13:20:14 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7958918725522142 on epoch=171
06/01/2022 13:20:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 13:20:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/01/2022 13:20:22 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/01/2022 13:20:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=174
06/01/2022 13:20:27 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=174
06/01/2022 13:20:33 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7061562047730573 on epoch=174
06/01/2022 13:20:36 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=175
06/01/2022 13:20:39 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=176
06/01/2022 13:20:41 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=177
06/01/2022 13:20:44 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/01/2022 13:20:47 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 13:20:53 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7968905225072208 on epoch=178
06/01/2022 13:20:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=179
06/01/2022 13:20:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 13:21:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 13:21:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/01/2022 13:21:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/01/2022 13:21:12 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9185272075594656 on epoch=182
06/01/2022 13:21:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=182
06/01/2022 13:21:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=183
06/01/2022 13:21:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=184
06/01/2022 13:21:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=184
06/01/2022 13:21:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 13:21:32 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.844386586196062 on epoch=185
06/01/2022 13:21:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=186
06/01/2022 13:21:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=187
06/01/2022 13:21:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=187
06/01/2022 13:21:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 13:21:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/01/2022 13:21:51 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.914360540892799 on epoch=189
06/01/2022 13:21:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 13:21:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=190
06/01/2022 13:21:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=191
06/01/2022 13:22:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/01/2022 13:22:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/01/2022 13:22:11 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=192
06/01/2022 13:22:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/01/2022 13:22:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=194
06/01/2022 13:22:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=194
06/01/2022 13:22:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=195
06/01/2022 13:22:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/01/2022 13:22:31 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.9143564679048549 on epoch=196
06/01/2022 13:22:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/01/2022 13:22:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=197
06/01/2022 13:22:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 13:22:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 13:22:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=199
06/01/2022 13:22:50 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9143564679048549 on epoch=199
06/01/2022 13:22:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 13:22:56 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/01/2022 13:22:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=202
06/01/2022 13:23:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 13:23:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 13:23:10 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9185272075594656 on epoch=203
06/01/2022 13:23:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/01/2022 13:23:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/01/2022 13:23:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 13:23:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/01/2022 13:23:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/01/2022 13:23:29 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9100423590746171 on epoch=207
06/01/2022 13:23:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/01/2022 13:23:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 13:23:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/01/2022 13:23:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 13:23:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=210
06/01/2022 13:23:49 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.855196878054741 on epoch=210
06/01/2022 13:23:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 13:23:54 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 13:23:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 13:23:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 13:24:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=214
06/01/2022 13:24:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:24:04 - INFO - __main__ - Printing 3 examples
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:24:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:24:04 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:24:04 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:24:04 - INFO - __main__ - Printing 3 examples
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 13:24:04 - INFO - __main__ - ['Company']
06/01/2022 13:24:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:24:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:24:04 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:24:09 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9101898012381883 on epoch=214
06/01/2022 13:24:09 - INFO - __main__ - save last model!
06/01/2022 13:24:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 13:24:09 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 13:24:09 - INFO - __main__ - Printing 3 examples
06/01/2022 13:24:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 13:24:09 - INFO - __main__ - ['Animal']
06/01/2022 13:24:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 13:24:09 - INFO - __main__ - ['Animal']
06/01/2022 13:24:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 13:24:09 - INFO - __main__ - ['Village']
06/01/2022 13:24:09 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:24:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:24:14 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 13:24:20 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:24:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:24:20 - INFO - __main__ - Starting training!
06/01/2022 13:26:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_42_0.3_8_predictions.txt
06/01/2022 13:26:24 - INFO - __main__ - Classification-F1 on test data: 0.4871
06/01/2022 13:26:24 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.3, bsz=8, dev_performance=0.9603498692269004, test_performance=0.4871081058896567
06/01/2022 13:26:24 - INFO - __main__ - Running ... prefix=dbpedia_14_16_42, lr=0.2, bsz=8 ...
06/01/2022 13:26:25 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:26:25 - INFO - __main__ - Printing 3 examples
06/01/2022 13:26:25 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
06/01/2022 13:26:25 - INFO - __main__ - ['Company']
06/01/2022 13:26:25 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
06/01/2022 13:26:25 - INFO - __main__ - ['Company']
06/01/2022 13:26:25 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
06/01/2022 13:26:25 - INFO - __main__ - ['Company']
06/01/2022 13:26:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:26:25 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:26:26 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:26:26 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:26:26 - INFO - __main__ - Printing 3 examples
06/01/2022 13:26:26 - INFO - __main__ -  [dbpedia_14] Speedball is an American company that manufactures art materials and other stationery items. The company first successful with its dip pens expanded its product line to other art areas such as painting sculpture and printing press.
06/01/2022 13:26:26 - INFO - __main__ - ['Company']
06/01/2022 13:26:26 - INFO - __main__ -  [dbpedia_14] Newag S.A. is a Polish company based in Nowy Sącz specialising in the production maintenance and modernisation of railway rolling stock. The company's products include the 14WE 19WE 35WE types electric multiple units; it has also developed the Nevelo tram.
06/01/2022 13:26:26 - INFO - __main__ - ['Company']
06/01/2022 13:26:26 - INFO - __main__ -  [dbpedia_14] McMullens is a regional brewery founded in 1827 in Hertford England.
06/01/2022 13:26:26 - INFO - __main__ - ['Company']
06/01/2022 13:26:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:26:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:26:26 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:26:41 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:26:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:26:42 - INFO - __main__ - Starting training!
06/01/2022 13:26:45 - INFO - __main__ - Step 10 Global step 10 Train loss 5.80 on epoch=0
06/01/2022 13:26:48 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/01/2022 13:26:51 - INFO - __main__ - Step 30 Global step 30 Train loss 4.26 on epoch=2
06/01/2022 13:26:53 - INFO - __main__ - Step 40 Global step 40 Train loss 3.52 on epoch=2
06/01/2022 13:26:56 - INFO - __main__ - Step 50 Global step 50 Train loss 3.21 on epoch=3
06/01/2022 13:27:02 - INFO - __main__ - Global step 50 Train loss 4.33 Classification-F1 0.0383940716215281 on epoch=3
06/01/2022 13:27:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0383940716215281 on epoch=3, global_step=50
06/01/2022 13:27:05 - INFO - __main__ - Step 60 Global step 60 Train loss 2.84 on epoch=4
06/01/2022 13:27:07 - INFO - __main__ - Step 70 Global step 70 Train loss 2.60 on epoch=4
06/01/2022 13:27:10 - INFO - __main__ - Step 80 Global step 80 Train loss 2.26 on epoch=5
06/01/2022 13:27:12 - INFO - __main__ - Step 90 Global step 90 Train loss 2.08 on epoch=6
06/01/2022 13:27:15 - INFO - __main__ - Step 100 Global step 100 Train loss 1.95 on epoch=7
06/01/2022 13:27:21 - INFO - __main__ - Global step 100 Train loss 2.35 Classification-F1 0.0778228591054678 on epoch=7
06/01/2022 13:27:21 - INFO - __main__ - Saving model with best Classification-F1: 0.0383940716215281 -> 0.0778228591054678 on epoch=7, global_step=100
06/01/2022 13:27:24 - INFO - __main__ - Step 110 Global step 110 Train loss 1.67 on epoch=7
06/01/2022 13:27:26 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=8
06/01/2022 13:27:29 - INFO - __main__ - Step 130 Global step 130 Train loss 1.44 on epoch=9
06/01/2022 13:27:32 - INFO - __main__ - Step 140 Global step 140 Train loss 1.31 on epoch=9
06/01/2022 13:27:34 - INFO - __main__ - Step 150 Global step 150 Train loss 1.23 on epoch=10
06/01/2022 13:27:41 - INFO - __main__ - Global step 150 Train loss 1.45 Classification-F1 0.188585233031521 on epoch=10
06/01/2022 13:27:41 - INFO - __main__ - Saving model with best Classification-F1: 0.0778228591054678 -> 0.188585233031521 on epoch=10, global_step=150
06/01/2022 13:27:44 - INFO - __main__ - Step 160 Global step 160 Train loss 1.18 on epoch=11
06/01/2022 13:27:46 - INFO - __main__ - Step 170 Global step 170 Train loss 1.08 on epoch=12
06/01/2022 13:27:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.99 on epoch=12
06/01/2022 13:27:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=13
06/01/2022 13:27:54 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=14
06/01/2022 13:28:01 - INFO - __main__ - Global step 200 Train loss 1.01 Classification-F1 0.27017975185750126 on epoch=14
06/01/2022 13:28:01 - INFO - __main__ - Saving model with best Classification-F1: 0.188585233031521 -> 0.27017975185750126 on epoch=14, global_step=200
06/01/2022 13:28:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.82 on epoch=14
06/01/2022 13:28:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=15
06/01/2022 13:28:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.79 on epoch=16
06/01/2022 13:28:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=17
06/01/2022 13:28:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=17
06/01/2022 13:28:22 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.32987774009864645 on epoch=17
06/01/2022 13:28:22 - INFO - __main__ - Saving model with best Classification-F1: 0.27017975185750126 -> 0.32987774009864645 on epoch=17, global_step=250
06/01/2022 13:28:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.73 on epoch=18
06/01/2022 13:28:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.76 on epoch=19
06/01/2022 13:28:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=19
06/01/2022 13:28:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=20
06/01/2022 13:28:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=21
06/01/2022 13:28:43 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.4450067852814914 on epoch=21
06/01/2022 13:28:43 - INFO - __main__ - Saving model with best Classification-F1: 0.32987774009864645 -> 0.4450067852814914 on epoch=21, global_step=300
06/01/2022 13:28:46 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=22
06/01/2022 13:28:49 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=22
06/01/2022 13:28:52 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=23
06/01/2022 13:28:54 - INFO - __main__ - Step 340 Global step 340 Train loss 0.68 on epoch=24
06/01/2022 13:28:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=24
06/01/2022 13:29:04 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.4999703633315747 on epoch=24
06/01/2022 13:29:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4450067852814914 -> 0.4999703633315747 on epoch=24, global_step=350
06/01/2022 13:29:07 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=25
06/01/2022 13:29:10 - INFO - __main__ - Step 370 Global step 370 Train loss 0.53 on epoch=26
06/01/2022 13:29:13 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=27
06/01/2022 13:29:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=27
06/01/2022 13:29:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=28
06/01/2022 13:29:26 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5691825269992918 on epoch=28
06/01/2022 13:29:26 - INFO - __main__ - Saving model with best Classification-F1: 0.4999703633315747 -> 0.5691825269992918 on epoch=28, global_step=400
06/01/2022 13:29:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=29
06/01/2022 13:29:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=29
06/01/2022 13:29:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=30
06/01/2022 13:29:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=31
06/01/2022 13:29:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.59 on epoch=32
06/01/2022 13:29:47 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.5847374498524879 on epoch=32
06/01/2022 13:29:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5691825269992918 -> 0.5847374498524879 on epoch=32, global_step=450
06/01/2022 13:29:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=32
06/01/2022 13:29:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=33
06/01/2022 13:29:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=34
06/01/2022 13:29:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.52 on epoch=34
06/01/2022 13:30:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.41 on epoch=35
06/01/2022 13:30:07 - INFO - __main__ - Global step 500 Train loss 0.46 Classification-F1 0.5612676133587557 on epoch=35
06/01/2022 13:30:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=36
06/01/2022 13:30:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=37
06/01/2022 13:30:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.46 on epoch=37
06/01/2022 13:30:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=38
06/01/2022 13:30:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.46 on epoch=39
06/01/2022 13:30:28 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.6638282299190935 on epoch=39
06/01/2022 13:30:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5847374498524879 -> 0.6638282299190935 on epoch=39, global_step=550
06/01/2022 13:30:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=39
06/01/2022 13:30:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.42 on epoch=40
06/01/2022 13:30:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.38 on epoch=41
06/01/2022 13:30:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=42
06/01/2022 13:30:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=42
06/01/2022 13:30:48 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.7522809594057058 on epoch=42
06/01/2022 13:30:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6638282299190935 -> 0.7522809594057058 on epoch=42, global_step=600
06/01/2022 13:30:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=43
06/01/2022 13:30:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=44
06/01/2022 13:30:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=44
06/01/2022 13:30:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=45
06/01/2022 13:31:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=46
06/01/2022 13:31:09 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6748850743092711 on epoch=46
06/01/2022 13:31:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=47
06/01/2022 13:31:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=47
06/01/2022 13:31:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=48
06/01/2022 13:31:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.44 on epoch=49
06/01/2022 13:31:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=49
06/01/2022 13:31:29 - INFO - __main__ - Global step 700 Train loss 0.39 Classification-F1 0.6727885735076388 on epoch=49
06/01/2022 13:31:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=50
06/01/2022 13:31:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=51
06/01/2022 13:31:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=52
06/01/2022 13:31:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.39 on epoch=52
06/01/2022 13:31:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=53
06/01/2022 13:31:49 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.6357453658359432 on epoch=53
06/01/2022 13:31:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=54
06/01/2022 13:31:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=54
06/01/2022 13:31:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=55
06/01/2022 13:31:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.30 on epoch=56
06/01/2022 13:32:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=57
06/01/2022 13:32:09 - INFO - __main__ - Global step 800 Train loss 0.36 Classification-F1 0.6495731496683917 on epoch=57
06/01/2022 13:32:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.29 on epoch=57
06/01/2022 13:32:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=58
06/01/2022 13:32:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=59
06/01/2022 13:32:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=59
06/01/2022 13:32:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=60
06/01/2022 13:32:29 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.7203775532983592 on epoch=60
06/01/2022 13:32:31 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=61
06/01/2022 13:32:34 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=62
06/01/2022 13:32:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=62
06/01/2022 13:32:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=63
06/01/2022 13:32:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.34 on epoch=64
06/01/2022 13:32:49 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.6738282439922474 on epoch=64
06/01/2022 13:32:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=64
06/01/2022 13:32:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=65
06/01/2022 13:32:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=66
06/01/2022 13:32:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.24 on epoch=67
06/01/2022 13:33:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=67
06/01/2022 13:33:08 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.6251051060569311 on epoch=67
06/01/2022 13:33:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=68
06/01/2022 13:33:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=69
06/01/2022 13:33:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=69
06/01/2022 13:33:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=70
06/01/2022 13:33:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.27 on epoch=71
06/01/2022 13:33:28 - INFO - __main__ - Global step 1000 Train loss 0.23 Classification-F1 0.6905123643896572 on epoch=71
06/01/2022 13:33:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=72
06/01/2022 13:33:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=72
06/01/2022 13:33:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/01/2022 13:33:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=74
06/01/2022 13:33:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=74
06/01/2022 13:33:48 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.6568186898157936 on epoch=74
06/01/2022 13:33:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=75
06/01/2022 13:33:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=76
06/01/2022 13:33:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=77
06/01/2022 13:33:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=77
06/01/2022 13:34:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.21 on epoch=78
06/01/2022 13:34:08 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.6535382952378359 on epoch=78
06/01/2022 13:34:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=79
06/01/2022 13:34:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=79
06/01/2022 13:34:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=80
06/01/2022 13:34:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.22 on epoch=81
06/01/2022 13:34:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=82
06/01/2022 13:34:27 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.6860666094795059 on epoch=82
06/01/2022 13:34:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=82
06/01/2022 13:34:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=83
06/01/2022 13:34:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
06/01/2022 13:34:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=84
06/01/2022 13:34:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=85
06/01/2022 13:34:47 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.6663295291878134 on epoch=85
06/01/2022 13:34:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
06/01/2022 13:34:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=87
06/01/2022 13:34:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=87
06/01/2022 13:34:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=88
06/01/2022 13:35:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=89
06/01/2022 13:35:07 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.572703749588345 on epoch=89
06/01/2022 13:35:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=89
06/01/2022 13:35:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=90
06/01/2022 13:35:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=91
06/01/2022 13:35:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=92
06/01/2022 13:35:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=92
06/01/2022 13:35:26 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.6492637241139189 on epoch=92
06/01/2022 13:35:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=93
06/01/2022 13:35:32 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=94
06/01/2022 13:35:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=94
06/01/2022 13:35:37 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=95
06/01/2022 13:35:40 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=96
06/01/2022 13:35:46 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.5818544139863356 on epoch=96
06/01/2022 13:35:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=97
06/01/2022 13:35:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=97
06/01/2022 13:35:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.10 on epoch=98
06/01/2022 13:35:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=99
06/01/2022 13:36:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=99
06/01/2022 13:36:07 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.5755647231957437 on epoch=99
06/01/2022 13:36:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/01/2022 13:36:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=101
06/01/2022 13:36:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=102
06/01/2022 13:36:18 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=102
06/01/2022 13:36:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=103
06/01/2022 13:36:27 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5927626641043042 on epoch=103
06/01/2022 13:36:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.15 on epoch=104
06/01/2022 13:36:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=104
06/01/2022 13:36:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=105
06/01/2022 13:36:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=106
06/01/2022 13:36:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=107
06/01/2022 13:36:47 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.5346283559962299 on epoch=107
06/01/2022 13:36:50 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=107
06/01/2022 13:36:52 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=108
06/01/2022 13:36:55 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=109
06/01/2022 13:36:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.12 on epoch=109
06/01/2022 13:37:00 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=110
06/01/2022 13:37:07 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.6685946331420146 on epoch=110
06/01/2022 13:37:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=111
06/01/2022 13:37:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=112
06/01/2022 13:37:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=112
06/01/2022 13:37:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=113
06/01/2022 13:37:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=114
06/01/2022 13:37:27 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.600413381383834 on epoch=114
06/01/2022 13:37:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=114
06/01/2022 13:37:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=115
06/01/2022 13:37:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=116
06/01/2022 13:37:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=117
06/01/2022 13:37:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/01/2022 13:37:47 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.6322108951023022 on epoch=117
06/01/2022 13:37:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=118
06/01/2022 13:37:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=119
06/01/2022 13:37:55 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=119
06/01/2022 13:37:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=120
06/01/2022 13:38:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=121
06/01/2022 13:38:07 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.69218943403878 on epoch=121
06/01/2022 13:38:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=122
06/01/2022 13:38:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=122
06/01/2022 13:38:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=123
06/01/2022 13:38:18 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=124
06/01/2022 13:38:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/01/2022 13:38:27 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6960948676855928 on epoch=124
06/01/2022 13:38:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/01/2022 13:38:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/01/2022 13:38:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=127
06/01/2022 13:38:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=127
06/01/2022 13:38:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/01/2022 13:38:47 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.7919240698499469 on epoch=128
06/01/2022 13:38:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7522809594057058 -> 0.7919240698499469 on epoch=128, global_step=1800
06/01/2022 13:38:50 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=129
06/01/2022 13:38:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=129
06/01/2022 13:38:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=130
06/01/2022 13:38:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=131
06/01/2022 13:39:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=132
06/01/2022 13:39:07 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.7401193739640443 on epoch=132
06/01/2022 13:39:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=132
06/01/2022 13:39:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=133
06/01/2022 13:39:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=134
06/01/2022 13:39:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=134
06/01/2022 13:39:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=135
06/01/2022 13:39:27 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.8531845674486804 on epoch=135
06/01/2022 13:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7919240698499469 -> 0.8531845674486804 on epoch=135, global_step=1900
06/01/2022 13:39:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=136
06/01/2022 13:39:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=137
06/01/2022 13:39:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=137
06/01/2022 13:39:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=138
06/01/2022 13:39:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=139
06/01/2022 13:39:47 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.857086999022483 on epoch=139
06/01/2022 13:39:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8531845674486804 -> 0.857086999022483 on epoch=139, global_step=1950
06/01/2022 13:39:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/01/2022 13:39:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=140
06/01/2022 13:39:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=141
06/01/2022 13:39:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=142
06/01/2022 13:40:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/01/2022 13:40:08 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7838937181400674 on epoch=142
06/01/2022 13:40:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=143
06/01/2022 13:40:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/01/2022 13:40:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=144
06/01/2022 13:40:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=145
06/01/2022 13:40:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=146
06/01/2022 13:40:28 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8586982168739676 on epoch=146
06/01/2022 13:40:28 - INFO - __main__ - Saving model with best Classification-F1: 0.857086999022483 -> 0.8586982168739676 on epoch=146, global_step=2050
06/01/2022 13:40:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=147
06/01/2022 13:40:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=147
06/01/2022 13:40:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=148
06/01/2022 13:40:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=149
06/01/2022 13:40:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=149
06/01/2022 13:40:48 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.8626082853001651 on epoch=149
06/01/2022 13:40:48 - INFO - __main__ - Saving model with best Classification-F1: 0.8586982168739676 -> 0.8626082853001651 on epoch=149, global_step=2100
06/01/2022 13:40:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=150
06/01/2022 13:40:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=151
06/01/2022 13:40:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=152
06/01/2022 13:40:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/01/2022 13:41:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/01/2022 13:41:08 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.8412206660946581 on epoch=153
06/01/2022 13:41:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/01/2022 13:41:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/01/2022 13:41:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=155
06/01/2022 13:41:19 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=156
06/01/2022 13:41:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
06/01/2022 13:41:28 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7941246909320913 on epoch=157
06/01/2022 13:41:31 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=157
06/01/2022 13:41:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=158
06/01/2022 13:41:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=159
06/01/2022 13:41:39 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=159
06/01/2022 13:41:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=160
06/01/2022 13:41:48 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8423020527859237 on epoch=160
06/01/2022 13:41:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=161
06/01/2022 13:41:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=162
06/01/2022 13:41:56 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=162
06/01/2022 13:41:59 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/01/2022 13:42:02 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=164
06/01/2022 13:42:09 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.9139286356333074 on epoch=164
06/01/2022 13:42:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8626082853001651 -> 0.9139286356333074 on epoch=164, global_step=2300
06/01/2022 13:42:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
06/01/2022 13:42:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=165
06/01/2022 13:42:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/01/2022 13:42:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=167
06/01/2022 13:42:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=167
06/01/2022 13:42:29 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.9205474095796676 on epoch=167
06/01/2022 13:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9139286356333074 -> 0.9205474095796676 on epoch=167, global_step=2350
06/01/2022 13:42:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=168
06/01/2022 13:42:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/01/2022 13:42:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=169
06/01/2022 13:42:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=170
06/01/2022 13:42:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=171
06/01/2022 13:42:49 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8591069464809384 on epoch=171
06/01/2022 13:42:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=172
06/01/2022 13:42:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=172
06/01/2022 13:42:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=173
06/01/2022 13:43:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=174
06/01/2022 13:43:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=174
06/01/2022 13:43:10 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.9101938742261323 on epoch=174
06/01/2022 13:43:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=175
06/01/2022 13:43:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=176
06/01/2022 13:43:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=177
06/01/2022 13:43:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=177
06/01/2022 13:43:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/01/2022 13:43:30 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9228413163897033 on epoch=178
06/01/2022 13:43:30 - INFO - __main__ - Saving model with best Classification-F1: 0.9205474095796676 -> 0.9228413163897033 on epoch=178, global_step=2500
06/01/2022 13:43:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/01/2022 13:43:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/01/2022 13:43:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=180
06/01/2022 13:43:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=181
06/01/2022 13:43:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=182
06/01/2022 13:43:50 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.9144793763057522 on epoch=182
06/01/2022 13:43:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 13:43:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=183
06/01/2022 13:43:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=184
06/01/2022 13:44:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=184
06/01/2022 13:44:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=185
06/01/2022 13:44:09 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8591069464809384 on epoch=185
06/01/2022 13:44:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=186
06/01/2022 13:44:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.14 on epoch=187
06/01/2022 13:44:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=187
06/01/2022 13:44:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=188
06/01/2022 13:44:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=189
06/01/2022 13:44:29 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.9185312805474095 on epoch=189
06/01/2022 13:44:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=189
06/01/2022 13:44:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=190
06/01/2022 13:44:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.09 on epoch=191
06/01/2022 13:44:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=192
06/01/2022 13:44:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=192
06/01/2022 13:44:49 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.9142391658520689 on epoch=192
06/01/2022 13:44:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=193
06/01/2022 13:44:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=194
06/01/2022 13:44:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/01/2022 13:45:00 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/01/2022 13:45:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=196
06/01/2022 13:45:09 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7988305732850326 on epoch=196
06/01/2022 13:45:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=197
06/01/2022 13:45:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=197
06/01/2022 13:45:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=198
06/01/2022 13:45:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=199
06/01/2022 13:45:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=199
06/01/2022 13:45:29 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.8509080217497555 on epoch=199
06/01/2022 13:45:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=200
06/01/2022 13:45:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/01/2022 13:45:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=202
06/01/2022 13:45:40 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=202
06/01/2022 13:45:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=203
06/01/2022 13:45:49 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.914503910068426 on epoch=203
06/01/2022 13:45:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=204
06/01/2022 13:45:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=204
06/01/2022 13:45:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 13:46:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=206
06/01/2022 13:46:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=207
06/01/2022 13:46:10 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8631514235092864 on epoch=207
06/01/2022 13:46:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=207
06/01/2022 13:46:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=208
06/01/2022 13:46:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=209
06/01/2022 13:46:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=209
06/01/2022 13:46:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=210
06/01/2022 13:46:30 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8104802771548502 on epoch=210
06/01/2022 13:46:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=211
06/01/2022 13:46:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=212
06/01/2022 13:46:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/01/2022 13:46:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=213
06/01/2022 13:46:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/01/2022 13:46:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:46:45 - INFO - __main__ - Printing 3 examples
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:46:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:46:45 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:46:45 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:46:45 - INFO - __main__ - Printing 3 examples
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 13:46:45 - INFO - __main__ - ['Film']
06/01/2022 13:46:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:46:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:46:46 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:46:50 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8031237421654879 on epoch=214
06/01/2022 13:46:50 - INFO - __main__ - save last model!
06/01/2022 13:46:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 13:46:50 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 13:46:50 - INFO - __main__ - Printing 3 examples
06/01/2022 13:46:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 13:46:50 - INFO - __main__ - ['Animal']
06/01/2022 13:46:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 13:46:50 - INFO - __main__ - ['Animal']
06/01/2022 13:46:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 13:46:50 - INFO - __main__ - ['Village']
06/01/2022 13:46:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:46:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:46:56 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 13:47:05 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:47:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:47:05 - INFO - __main__ - Starting training!
06/01/2022 13:49:04 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_42_0.2_8_predictions.txt
06/01/2022 13:49:04 - INFO - __main__ - Classification-F1 on test data: 0.6213
06/01/2022 13:49:05 - INFO - __main__ - prefix=dbpedia_14_16_42, lr=0.2, bsz=8, dev_performance=0.9228413163897033, test_performance=0.6213423656549792
06/01/2022 13:49:05 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.5, bsz=8 ...
06/01/2022 13:49:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:49:06 - INFO - __main__ - Printing 3 examples
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:49:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:49:06 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 13:49:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 13:49:06 - INFO - __main__ - Printing 3 examples
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 13:49:06 - INFO - __main__ - ['Film']
06/01/2022 13:49:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 13:49:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 13:49:06 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 13:49:25 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 13:49:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 13:49:26 - INFO - __main__ - Starting training!
06/01/2022 13:49:30 - INFO - __main__ - Step 10 Global step 10 Train loss 5.19 on epoch=0
06/01/2022 13:49:33 - INFO - __main__ - Step 20 Global step 20 Train loss 3.52 on epoch=1
06/01/2022 13:49:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.56 on epoch=2
06/01/2022 13:49:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.89 on epoch=2
06/01/2022 13:49:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.67 on epoch=3
06/01/2022 13:49:47 - INFO - __main__ - Global step 50 Train loss 2.97 Classification-F1 0.1141285440244311 on epoch=3
06/01/2022 13:49:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1141285440244311 on epoch=3, global_step=50
06/01/2022 13:49:50 - INFO - __main__ - Step 60 Global step 60 Train loss 1.41 on epoch=4
06/01/2022 13:49:52 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=4
06/01/2022 13:49:55 - INFO - __main__ - Step 80 Global step 80 Train loss 1.00 on epoch=5
06/01/2022 13:49:57 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=6
06/01/2022 13:50:00 - INFO - __main__ - Step 100 Global step 100 Train loss 0.70 on epoch=7
06/01/2022 13:50:07 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.5812063064065643 on epoch=7
06/01/2022 13:50:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1141285440244311 -> 0.5812063064065643 on epoch=7, global_step=100
06/01/2022 13:50:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.61 on epoch=7
06/01/2022 13:50:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.66 on epoch=8
06/01/2022 13:50:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.57 on epoch=9
06/01/2022 13:50:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.56 on epoch=9
06/01/2022 13:50:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.55 on epoch=10
06/01/2022 13:50:27 - INFO - __main__ - Global step 150 Train loss 0.59 Classification-F1 0.5624398386578136 on epoch=10
06/01/2022 13:50:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=11
06/01/2022 13:50:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=12
06/01/2022 13:50:35 - INFO - __main__ - Step 180 Global step 180 Train loss 0.46 on epoch=12
06/01/2022 13:50:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=13
06/01/2022 13:50:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=14
06/01/2022 13:50:46 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.6751795555052397 on epoch=14
06/01/2022 13:50:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5812063064065643 -> 0.6751795555052397 on epoch=14, global_step=200
06/01/2022 13:50:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.37 on epoch=14
06/01/2022 13:50:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=15
06/01/2022 13:50:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.42 on epoch=16
06/01/2022 13:50:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.39 on epoch=17
06/01/2022 13:51:00 - INFO - __main__ - Step 250 Global step 250 Train loss 0.35 on epoch=17
06/01/2022 13:51:07 - INFO - __main__ - Global step 250 Train loss 0.38 Classification-F1 0.7832482781092348 on epoch=17
06/01/2022 13:51:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6751795555052397 -> 0.7832482781092348 on epoch=17, global_step=250
06/01/2022 13:51:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=18
06/01/2022 13:51:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
06/01/2022 13:51:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=19
06/01/2022 13:51:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.29 on epoch=20
06/01/2022 13:51:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=21
06/01/2022 13:51:26 - INFO - __main__ - Global step 300 Train loss 0.35 Classification-F1 0.8047928788160739 on epoch=21
06/01/2022 13:51:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7832482781092348 -> 0.8047928788160739 on epoch=21, global_step=300
06/01/2022 13:51:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=22
06/01/2022 13:51:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=22
06/01/2022 13:51:34 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=23
06/01/2022 13:51:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.26 on epoch=24
06/01/2022 13:51:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
06/01/2022 13:51:46 - INFO - __main__ - Global step 350 Train loss 0.29 Classification-F1 0.7449040866379576 on epoch=24
06/01/2022 13:51:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.19 on epoch=25
06/01/2022 13:51:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.20 on epoch=26
06/01/2022 13:51:54 - INFO - __main__ - Step 380 Global step 380 Train loss 0.20 on epoch=27
06/01/2022 13:51:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.20 on epoch=27
06/01/2022 13:51:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=28
06/01/2022 13:52:06 - INFO - __main__ - Global step 400 Train loss 0.21 Classification-F1 0.6284620277729861 on epoch=28
06/01/2022 13:52:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=29
06/01/2022 13:52:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=29
06/01/2022 13:52:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=30
06/01/2022 13:52:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=31
06/01/2022 13:52:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=32
06/01/2022 13:52:26 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.4997257489506067 on epoch=32
06/01/2022 13:52:29 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=32
06/01/2022 13:52:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.23 on epoch=33
06/01/2022 13:52:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=34
06/01/2022 13:52:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=34
06/01/2022 13:52:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.13 on epoch=35
06/01/2022 13:52:46 - INFO - __main__ - Global step 500 Train loss 0.17 Classification-F1 0.773143590280687 on epoch=35
06/01/2022 13:52:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=36
06/01/2022 13:52:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=37
06/01/2022 13:52:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=37
06/01/2022 13:52:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=38
06/01/2022 13:53:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=39
06/01/2022 13:53:06 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.705852963537973 on epoch=39
06/01/2022 13:53:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.14 on epoch=39
06/01/2022 13:53:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=40
06/01/2022 13:53:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.08 on epoch=41
06/01/2022 13:53:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=42
06/01/2022 13:53:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=42
06/01/2022 13:53:25 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.8449243000491733 on epoch=42
06/01/2022 13:53:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8047928788160739 -> 0.8449243000491733 on epoch=42, global_step=600
06/01/2022 13:53:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=43
06/01/2022 13:53:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/01/2022 13:53:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=44
06/01/2022 13:53:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=45
06/01/2022 13:53:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=46
06/01/2022 13:53:45 - INFO - __main__ - Global step 650 Train loss 0.11 Classification-F1 0.8108312899170318 on epoch=46
06/01/2022 13:53:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=47
06/01/2022 13:53:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.06 on epoch=47
06/01/2022 13:53:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=48
06/01/2022 13:53:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=49
06/01/2022 13:53:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=49
06/01/2022 13:54:05 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.9101611944875702 on epoch=49
06/01/2022 13:54:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8449243000491733 -> 0.9101611944875702 on epoch=49, global_step=700
06/01/2022 13:54:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=50
06/01/2022 13:54:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=51
06/01/2022 13:54:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=52
06/01/2022 13:54:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=52
06/01/2022 13:54:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=53
06/01/2022 13:54:25 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.7618198554617239 on epoch=53
06/01/2022 13:54:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=54
06/01/2022 13:54:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=54
06/01/2022 13:54:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=55
06/01/2022 13:54:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=56
06/01/2022 13:54:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=57
06/01/2022 13:54:44 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.785384597171627 on epoch=57
06/01/2022 13:54:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=57
06/01/2022 13:54:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=58
06/01/2022 13:54:52 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=59
06/01/2022 13:54:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=59
06/01/2022 13:54:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=60
06/01/2022 13:55:04 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.8531539301937784 on epoch=60
06/01/2022 13:55:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=61
06/01/2022 13:55:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=62
06/01/2022 13:55:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=62
06/01/2022 13:55:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=63
06/01/2022 13:55:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=64
06/01/2022 13:55:24 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.9822264389626818 on epoch=64
06/01/2022 13:55:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9101611944875702 -> 0.9822264389626818 on epoch=64, global_step=900
06/01/2022 13:55:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=64
06/01/2022 13:55:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=65
06/01/2022 13:55:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=66
06/01/2022 13:55:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=67
06/01/2022 13:55:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=67
06/01/2022 13:55:44 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.8505425630662823 on epoch=67
06/01/2022 13:55:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=68
06/01/2022 13:55:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=69
06/01/2022 13:55:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=69
06/01/2022 13:55:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=70
06/01/2022 13:55:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=71
06/01/2022 13:56:03 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.8405833438580711 on epoch=71
06/01/2022 13:56:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=72
06/01/2022 13:56:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=72
06/01/2022 13:56:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.05 on epoch=73
06/01/2022 13:56:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=74
06/01/2022 13:56:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=74
06/01/2022 13:56:23 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.9777928033383441 on epoch=74
06/01/2022 13:56:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=75
06/01/2022 13:56:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=76
06/01/2022 13:56:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=77
06/01/2022 13:56:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=77
06/01/2022 13:56:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/01/2022 13:56:43 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.9100070670058565 on epoch=78
06/01/2022 13:56:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=79
06/01/2022 13:56:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=79
06/01/2022 13:56:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=80
06/01/2022 13:56:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=81
06/01/2022 13:56:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=82
06/01/2022 13:57:03 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.9910627007401202 on epoch=82
06/01/2022 13:57:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9822264389626818 -> 0.9910627007401202 on epoch=82, global_step=1150
06/01/2022 13:57:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=82
06/01/2022 13:57:08 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=83
06/01/2022 13:57:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/01/2022 13:57:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=84
06/01/2022 13:57:16 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=85
06/01/2022 13:57:22 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.859103128054741 on epoch=85
06/01/2022 13:57:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=86
06/01/2022 13:57:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 13:57:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=87
06/01/2022 13:57:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/01/2022 13:57:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=89
06/01/2022 13:57:42 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.8632590132827325 on epoch=89
06/01/2022 13:57:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=89
06/01/2022 13:57:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=90
06/01/2022 13:57:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=91
06/01/2022 13:57:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=92
06/01/2022 13:57:55 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=92
06/01/2022 13:58:02 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.9910627007401202 on epoch=92
06/01/2022 13:58:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=93
06/01/2022 13:58:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=94
06/01/2022 13:58:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/01/2022 13:58:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=95
06/01/2022 13:58:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=96
06/01/2022 13:58:21 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7988993412227513 on epoch=96
06/01/2022 13:58:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=97
06/01/2022 13:58:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=97
06/01/2022 13:58:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=98
06/01/2022 13:58:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=99
06/01/2022 13:58:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=99
06/01/2022 13:58:40 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.9821254014802402 on epoch=99
06/01/2022 13:58:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=100
06/01/2022 13:58:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=101
06/01/2022 13:58:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=102
06/01/2022 13:58:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=102
06/01/2022 13:58:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=103
06/01/2022 13:59:00 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=103
06/01/2022 13:59:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=104
06/01/2022 13:59:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=104
06/01/2022 13:59:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/01/2022 13:59:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=106
06/01/2022 13:59:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/01/2022 13:59:19 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=107
06/01/2022 13:59:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 13:59:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/01/2022 13:59:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/01/2022 13:59:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=109
06/01/2022 13:59:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=110
06/01/2022 13:59:39 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.9820991153059465 on epoch=110
06/01/2022 13:59:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=111
06/01/2022 13:59:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=112
06/01/2022 13:59:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=112
06/01/2022 13:59:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=113
06/01/2022 13:59:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=114
06/01/2022 13:59:59 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.9145079830563703 on epoch=114
06/01/2022 14:00:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=114
06/01/2022 14:00:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=115
06/01/2022 14:00:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=116
06/01/2022 14:00:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=117
06/01/2022 14:00:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=117
06/01/2022 14:00:18 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.851290628054741 on epoch=117
06/01/2022 14:00:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=118
06/01/2022 14:00:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=119
06/01/2022 14:00:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/01/2022 14:00:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=120
06/01/2022 14:00:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=121
06/01/2022 14:00:38 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.857086999022483 on epoch=121
06/01/2022 14:00:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/01/2022 14:00:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=122
06/01/2022 14:00:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=123
06/01/2022 14:00:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=124
06/01/2022 14:00:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/01/2022 14:00:57 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.9104560788147128 on epoch=124
06/01/2022 14:01:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=125
06/01/2022 14:01:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=126
06/01/2022 14:01:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=127
06/01/2022 14:01:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=127
06/01/2022 14:01:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=128
06/01/2022 14:01:16 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=128
06/01/2022 14:01:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/01/2022 14:01:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/01/2022 14:01:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=130
06/01/2022 14:01:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=131
06/01/2022 14:01:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/01/2022 14:01:36 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.9103372434017596 on epoch=132
06/01/2022 14:01:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=132
06/01/2022 14:01:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=133
06/01/2022 14:01:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=134
06/01/2022 14:01:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=134
06/01/2022 14:01:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/01/2022 14:01:55 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=135
06/01/2022 14:01:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=136
06/01/2022 14:02:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=137
06/01/2022 14:02:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=137
06/01/2022 14:02:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/01/2022 14:02:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=139
06/01/2022 14:02:15 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.7564679048550017 on epoch=139
06/01/2022 14:02:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=139
06/01/2022 14:02:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=140
06/01/2022 14:02:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=141
06/01/2022 14:02:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/01/2022 14:02:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=142
06/01/2022 14:02:34 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.98225708905263 on epoch=142
06/01/2022 14:02:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/01/2022 14:02:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/01/2022 14:02:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=144
06/01/2022 14:02:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/01/2022 14:02:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/01/2022 14:02:54 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9146186724934355 on epoch=146
06/01/2022 14:02:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=147
06/01/2022 14:02:59 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/01/2022 14:03:02 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 14:03:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=149
06/01/2022 14:03:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=149
06/01/2022 14:03:14 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9101857282502446 on epoch=149
06/01/2022 14:03:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=150
06/01/2022 14:03:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/01/2022 14:03:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=152
06/01/2022 14:03:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 14:03:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=153
06/01/2022 14:03:33 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.8551930596285435 on epoch=153
06/01/2022 14:03:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=154
06/01/2022 14:03:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=154
06/01/2022 14:03:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=155
06/01/2022 14:03:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/01/2022 14:03:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=157
06/01/2022 14:03:53 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.9061419699844748 on epoch=157
06/01/2022 14:03:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=157
06/01/2022 14:03:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/01/2022 14:04:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/01/2022 14:04:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=159
06/01/2022 14:04:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/01/2022 14:04:12 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7916693084471779 on epoch=160
06/01/2022 14:04:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 14:04:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=162
06/01/2022 14:04:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=162
06/01/2022 14:04:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 14:04:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=164
06/01/2022 14:04:32 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9146186724934355 on epoch=164
06/01/2022 14:04:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/01/2022 14:04:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 14:04:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=166
06/01/2022 14:04:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 14:04:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 14:04:52 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.97778843942269 on epoch=167
06/01/2022 14:04:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/01/2022 14:04:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=169
06/01/2022 14:05:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=169
06/01/2022 14:05:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=170
06/01/2022 14:05:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=171
06/01/2022 14:05:12 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.9776611157659547 on epoch=171
06/01/2022 14:05:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=172
06/01/2022 14:05:17 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=172
06/01/2022 14:05:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=173
06/01/2022 14:05:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=174
06/01/2022 14:05:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 14:05:32 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8821806777451939 on epoch=174
06/01/2022 14:05:35 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=175
06/01/2022 14:05:37 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/01/2022 14:05:40 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 14:05:43 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 14:05:45 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 14:05:52 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9029598985244149 on epoch=178
06/01/2022 14:05:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=179
06/01/2022 14:05:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 14:06:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=180
06/01/2022 14:06:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/01/2022 14:06:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 14:06:12 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9072454006040346 on epoch=182
06/01/2022 14:06:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 14:06:17 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 14:06:20 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=184
06/01/2022 14:06:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=184
06/01/2022 14:06:25 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=185
06/01/2022 14:06:31 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.9012657593302755 on epoch=185
06/01/2022 14:06:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 14:06:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=187
06/01/2022 14:06:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=187
06/01/2022 14:06:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=188
06/01/2022 14:06:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 14:06:51 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9776611157659547 on epoch=189
06/01/2022 14:06:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=189
06/01/2022 14:06:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 14:06:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 14:07:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/01/2022 14:07:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=192
06/01/2022 14:07:11 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9821254014802404 on epoch=192
06/01/2022 14:07:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/01/2022 14:07:16 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=194
06/01/2022 14:07:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 14:07:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 14:07:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=196
06/01/2022 14:07:31 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9143564679048553 on epoch=196
06/01/2022 14:07:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 14:07:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=197
06/01/2022 14:07:38 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=198
06/01/2022 14:07:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 14:07:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 14:07:50 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9101857282502446 on epoch=199
06/01/2022 14:07:53 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=200
06/01/2022 14:07:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=201
06/01/2022 14:07:58 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/01/2022 14:08:01 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 14:08:03 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=203
06/01/2022 14:08:10 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9143564679048553 on epoch=203
06/01/2022 14:08:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 14:08:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 14:08:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=205
06/01/2022 14:08:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/01/2022 14:08:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/01/2022 14:08:30 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9730344923893313 on epoch=207
06/01/2022 14:08:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=207
06/01/2022 14:08:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 14:08:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=209
06/01/2022 14:08:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=209
06/01/2022 14:08:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 14:08:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9144753033178081 on epoch=210
06/01/2022 14:08:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=211
06/01/2022 14:08:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=212
06/01/2022 14:08:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=212
06/01/2022 14:09:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 14:09:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 14:09:05 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:09:05 - INFO - __main__ - Printing 3 examples
06/01/2022 14:09:05 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:09:05 - INFO - __main__ - ['Film']
06/01/2022 14:09:05 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:09:05 - INFO - __main__ - ['Film']
06/01/2022 14:09:05 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:09:05 - INFO - __main__ - ['Film']
06/01/2022 14:09:05 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:09:05 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:09:06 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:09:06 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:09:06 - INFO - __main__ - Printing 3 examples
06/01/2022 14:09:06 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:09:06 - INFO - __main__ - ['Film']
06/01/2022 14:09:06 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:09:06 - INFO - __main__ - ['Film']
06/01/2022 14:09:06 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:09:06 - INFO - __main__ - ['Film']
06/01/2022 14:09:06 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:09:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:09:06 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:09:10 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9776611157659547 on epoch=214
06/01/2022 14:09:10 - INFO - __main__ - save last model!
06/01/2022 14:09:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 14:09:10 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 14:09:10 - INFO - __main__ - Printing 3 examples
06/01/2022 14:09:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 14:09:10 - INFO - __main__ - ['Animal']
06/01/2022 14:09:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 14:09:10 - INFO - __main__ - ['Animal']
06/01/2022 14:09:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 14:09:10 - INFO - __main__ - ['Village']
06/01/2022 14:09:10 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:09:12 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:09:15 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 14:09:21 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:09:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:09:22 - INFO - __main__ - Starting training!
06/01/2022 14:11:25 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_87_0.5_8_predictions.txt
06/01/2022 14:11:25 - INFO - __main__ - Classification-F1 on test data: 0.7201
06/01/2022 14:11:26 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.5, bsz=8, dev_performance=0.9910627007401202, test_performance=0.720113199785626
06/01/2022 14:11:26 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.4, bsz=8 ...
06/01/2022 14:11:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:11:27 - INFO - __main__ - Printing 3 examples
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:11:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:11:27 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:11:27 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:11:27 - INFO - __main__ - Printing 3 examples
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:11:27 - INFO - __main__ - ['Film']
06/01/2022 14:11:27 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:11:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:11:28 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:11:46 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:11:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:11:47 - INFO - __main__ - Starting training!
06/01/2022 14:11:51 - INFO - __main__ - Step 10 Global step 10 Train loss 5.47 on epoch=0
06/01/2022 14:11:54 - INFO - __main__ - Step 20 Global step 20 Train loss 4.02 on epoch=1
06/01/2022 14:11:56 - INFO - __main__ - Step 30 Global step 30 Train loss 3.00 on epoch=2
06/01/2022 14:11:59 - INFO - __main__ - Step 40 Global step 40 Train loss 2.35 on epoch=2
06/01/2022 14:12:01 - INFO - __main__ - Step 50 Global step 50 Train loss 2.06 on epoch=3
06/01/2022 14:12:08 - INFO - __main__ - Global step 50 Train loss 3.38 Classification-F1 0.07838853498388602 on epoch=3
06/01/2022 14:12:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07838853498388602 on epoch=3, global_step=50
06/01/2022 14:12:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.71 on epoch=4
06/01/2022 14:12:13 - INFO - __main__ - Step 70 Global step 70 Train loss 1.30 on epoch=4
06/01/2022 14:12:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.15 on epoch=5
06/01/2022 14:12:18 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=6
06/01/2022 14:12:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=7
06/01/2022 14:12:27 - INFO - __main__ - Global step 100 Train loss 1.20 Classification-F1 0.35509037727320164 on epoch=7
06/01/2022 14:12:27 - INFO - __main__ - Saving model with best Classification-F1: 0.07838853498388602 -> 0.35509037727320164 on epoch=7, global_step=100
06/01/2022 14:12:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=7
06/01/2022 14:12:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=8
06/01/2022 14:12:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=9
06/01/2022 14:12:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.57 on epoch=9
06/01/2022 14:12:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.66 on epoch=10
06/01/2022 14:12:48 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.4842009113615549 on epoch=10
06/01/2022 14:12:48 - INFO - __main__ - Saving model with best Classification-F1: 0.35509037727320164 -> 0.4842009113615549 on epoch=10, global_step=150
06/01/2022 14:12:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=11
06/01/2022 14:12:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.54 on epoch=12
06/01/2022 14:12:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.50 on epoch=12
06/01/2022 14:12:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=13
06/01/2022 14:13:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.58 on epoch=14
06/01/2022 14:13:08 - INFO - __main__ - Global step 200 Train loss 0.58 Classification-F1 0.6527517513244157 on epoch=14
06/01/2022 14:13:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4842009113615549 -> 0.6527517513244157 on epoch=14, global_step=200
06/01/2022 14:13:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=14
06/01/2022 14:13:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=15
06/01/2022 14:13:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=16
06/01/2022 14:13:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=17
06/01/2022 14:13:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=17
06/01/2022 14:13:28 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.6591315206646641 on epoch=17
06/01/2022 14:13:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6527517513244157 -> 0.6591315206646641 on epoch=17, global_step=250
06/01/2022 14:13:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=18
06/01/2022 14:13:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=19
06/01/2022 14:13:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=19
06/01/2022 14:13:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=20
06/01/2022 14:13:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=21
06/01/2022 14:13:48 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.8321542635208793 on epoch=21
06/01/2022 14:13:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6591315206646641 -> 0.8321542635208793 on epoch=21, global_step=300
06/01/2022 14:13:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=22
06/01/2022 14:13:54 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=22
06/01/2022 14:13:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=23
06/01/2022 14:13:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=24
06/01/2022 14:14:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.28 on epoch=24
06/01/2022 14:14:08 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.7574907429517128 on epoch=24
06/01/2022 14:14:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=25
06/01/2022 14:14:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.27 on epoch=26
06/01/2022 14:14:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=27
06/01/2022 14:14:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=27
06/01/2022 14:14:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=28
06/01/2022 14:14:28 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.7075624298654695 on epoch=28
06/01/2022 14:14:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=29
06/01/2022 14:14:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=29
06/01/2022 14:14:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=30
06/01/2022 14:14:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.22 on epoch=31
06/01/2022 14:14:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=32
06/01/2022 14:14:48 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.7573255040685662 on epoch=32
06/01/2022 14:14:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
06/01/2022 14:14:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=33
06/01/2022 14:14:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=34
06/01/2022 14:14:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.22 on epoch=34
06/01/2022 14:15:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=35
06/01/2022 14:15:07 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.7038354758789999 on epoch=35
06/01/2022 14:15:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=36
06/01/2022 14:15:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=37
06/01/2022 14:15:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=37
06/01/2022 14:15:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=38
06/01/2022 14:15:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=39
06/01/2022 14:15:26 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.7842827498182107 on epoch=39
06/01/2022 14:15:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=39
06/01/2022 14:15:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=40
06/01/2022 14:15:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=41
06/01/2022 14:15:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=42
06/01/2022 14:15:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=42
06/01/2022 14:15:46 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7753077651515152 on epoch=42
06/01/2022 14:15:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=43
06/01/2022 14:15:52 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=44
06/01/2022 14:15:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=44
06/01/2022 14:15:57 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=45
06/01/2022 14:16:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=46
06/01/2022 14:16:06 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.7014634804720195 on epoch=46
06/01/2022 14:16:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.17 on epoch=47
06/01/2022 14:16:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=47
06/01/2022 14:16:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
06/01/2022 14:16:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=49
06/01/2022 14:16:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=49
06/01/2022 14:16:26 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6520195607182524 on epoch=49
06/01/2022 14:16:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=50
06/01/2022 14:16:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=51
06/01/2022 14:16:34 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=52
06/01/2022 14:16:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=52
06/01/2022 14:16:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=53
06/01/2022 14:16:47 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.8379266574665056 on epoch=53
06/01/2022 14:16:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8321542635208793 -> 0.8379266574665056 on epoch=53, global_step=750
06/01/2022 14:16:50 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=54
06/01/2022 14:16:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=54
06/01/2022 14:16:55 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=55
06/01/2022 14:16:58 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=56
06/01/2022 14:17:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=57
06/01/2022 14:17:07 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.6875841750841751 on epoch=57
06/01/2022 14:17:09 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=57
06/01/2022 14:17:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/01/2022 14:17:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/01/2022 14:17:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=59
06/01/2022 14:17:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/01/2022 14:17:27 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7189510310478053 on epoch=60
06/01/2022 14:17:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=61
06/01/2022 14:17:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=62
06/01/2022 14:17:35 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=62
06/01/2022 14:17:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=63
06/01/2022 14:17:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=64
06/01/2022 14:17:47 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.6709533792937868 on epoch=64
06/01/2022 14:17:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=64
06/01/2022 14:17:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=65
06/01/2022 14:17:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=66
06/01/2022 14:17:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=67
06/01/2022 14:18:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=67
06/01/2022 14:18:07 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7921006555114714 on epoch=67
06/01/2022 14:18:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=68
06/01/2022 14:18:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=69
06/01/2022 14:18:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=69
06/01/2022 14:18:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=70
06/01/2022 14:18:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=71
06/01/2022 14:18:26 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.8551930596285435 on epoch=71
06/01/2022 14:18:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8379266574665056 -> 0.8551930596285435 on epoch=71, global_step=1000
06/01/2022 14:18:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=72
06/01/2022 14:18:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.08 on epoch=72
06/01/2022 14:18:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=73
06/01/2022 14:18:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=74
06/01/2022 14:18:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=74
06/01/2022 14:18:46 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6691639883303221 on epoch=74
06/01/2022 14:18:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=75
06/01/2022 14:18:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=76
06/01/2022 14:18:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=77
06/01/2022 14:18:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=77
06/01/2022 14:19:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=78
06/01/2022 14:19:06 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.9186705767350929 on epoch=78
06/01/2022 14:19:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8551930596285435 -> 0.9186705767350929 on epoch=78, global_step=1100
06/01/2022 14:19:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=79
06/01/2022 14:19:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=79
06/01/2022 14:19:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=80
06/01/2022 14:19:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=81
06/01/2022 14:19:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
06/01/2022 14:19:26 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7976779975594018 on epoch=82
06/01/2022 14:19:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=82
06/01/2022 14:19:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=83
06/01/2022 14:19:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=84
06/01/2022 14:19:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=84
06/01/2022 14:19:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=85
06/01/2022 14:19:46 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8551930596285435 on epoch=85
06/01/2022 14:19:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=86
06/01/2022 14:19:51 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=87
06/01/2022 14:19:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=87
06/01/2022 14:19:56 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=88
06/01/2022 14:19:59 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=89
06/01/2022 14:20:05 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.8008431085043989 on epoch=89
06/01/2022 14:20:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=89
06/01/2022 14:20:11 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/01/2022 14:20:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/01/2022 14:20:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=92
06/01/2022 14:20:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=92
06/01/2022 14:20:25 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.8067966189408314 on epoch=92
06/01/2022 14:20:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=93
06/01/2022 14:20:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/01/2022 14:20:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=94
06/01/2022 14:20:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=95
06/01/2022 14:20:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=96
06/01/2022 14:20:45 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.855196878054741 on epoch=96
06/01/2022 14:20:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/01/2022 14:20:50 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=97
06/01/2022 14:20:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=98
06/01/2022 14:20:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=99
06/01/2022 14:20:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/01/2022 14:21:05 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.855196878054741 on epoch=99
06/01/2022 14:21:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=100
06/01/2022 14:21:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=101
06/01/2022 14:21:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=102
06/01/2022 14:21:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=102
06/01/2022 14:21:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=103
06/01/2022 14:21:24 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8029936461388075 on epoch=103
06/01/2022 14:21:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=104
06/01/2022 14:21:29 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=104
06/01/2022 14:21:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=105
06/01/2022 14:21:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/01/2022 14:21:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=107
06/01/2022 14:21:44 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8553312866568915 on epoch=107
06/01/2022 14:21:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=107
06/01/2022 14:21:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=108
06/01/2022 14:21:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=109
06/01/2022 14:21:55 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=109
06/01/2022 14:21:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=110
06/01/2022 14:22:04 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9144998370804823 on epoch=110
06/01/2022 14:22:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=111
06/01/2022 14:22:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=112
06/01/2022 14:22:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/01/2022 14:22:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=113
06/01/2022 14:22:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=114
06/01/2022 14:22:23 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8513943994019896 on epoch=114
06/01/2022 14:22:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=114
06/01/2022 14:22:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/01/2022 14:22:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=116
06/01/2022 14:22:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=117
06/01/2022 14:22:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/01/2022 14:22:43 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.8475290539806669 on epoch=117
06/01/2022 14:22:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=118
06/01/2022 14:22:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=119
06/01/2022 14:22:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=119
06/01/2022 14:22:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=120
06/01/2022 14:22:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/01/2022 14:23:03 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8166929103525322 on epoch=121
06/01/2022 14:23:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=122
06/01/2022 14:23:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=122
06/01/2022 14:23:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=123
06/01/2022 14:23:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=124
06/01/2022 14:23:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=124
06/01/2022 14:23:22 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.857086999022483 on epoch=124
06/01/2022 14:23:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=125
06/01/2022 14:23:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=126
06/01/2022 14:23:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/01/2022 14:23:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=127
06/01/2022 14:23:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=128
06/01/2022 14:23:42 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8496795916150754 on epoch=128
06/01/2022 14:23:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=129
06/01/2022 14:23:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=129
06/01/2022 14:23:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=130
06/01/2022 14:23:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=131
06/01/2022 14:23:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=132
06/01/2022 14:24:01 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=132
06/01/2022 14:24:01 - INFO - __main__ - Saving model with best Classification-F1: 0.9186705767350929 -> 0.9228413163897036 on epoch=132, global_step=1850
06/01/2022 14:24:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/01/2022 14:24:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=133
06/01/2022 14:24:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=134
06/01/2022 14:24:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/01/2022 14:24:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=135
06/01/2022 14:24:21 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8551930596285435 on epoch=135
06/01/2022 14:24:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=136
06/01/2022 14:24:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=137
06/01/2022 14:24:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=137
06/01/2022 14:24:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/01/2022 14:24:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=139
06/01/2022 14:24:40 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9819717916492111 on epoch=139
06/01/2022 14:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.9228413163897036 -> 0.9819717916492111 on epoch=139, global_step=1950
06/01/2022 14:24:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=139
06/01/2022 14:24:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=140
06/01/2022 14:24:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=141
06/01/2022 14:24:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=142
06/01/2022 14:24:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=142
06/01/2022 14:25:00 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9865940511101802 on epoch=142
06/01/2022 14:25:00 - INFO - __main__ - Saving model with best Classification-F1: 0.9819717916492111 -> 0.9865940511101802 on epoch=142, global_step=2000
06/01/2022 14:25:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=143
06/01/2022 14:25:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=144
06/01/2022 14:25:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=144
06/01/2022 14:25:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=145
06/01/2022 14:25:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=146
06/01/2022 14:25:19 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.9821341293115486 on epoch=146
06/01/2022 14:25:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=147
06/01/2022 14:25:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=147
06/01/2022 14:25:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=148
06/01/2022 14:25:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=149
06/01/2022 14:25:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/01/2022 14:25:39 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.9821341293115486 on epoch=149
06/01/2022 14:25:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 14:25:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=151
06/01/2022 14:25:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/01/2022 14:25:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=152
06/01/2022 14:25:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=153
06/01/2022 14:25:58 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.9186787227109808 on epoch=153
06/01/2022 14:26:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=154
06/01/2022 14:26:04 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=154
06/01/2022 14:26:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 14:26:09 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=156
06/01/2022 14:26:12 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=157
06/01/2022 14:26:18 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.9821254014802402 on epoch=157
06/01/2022 14:26:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=157
06/01/2022 14:26:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=158
06/01/2022 14:26:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=159
06/01/2022 14:26:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=159
06/01/2022 14:26:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=160
06/01/2022 14:26:38 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=160
06/01/2022 14:26:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=161
06/01/2022 14:26:43 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=162
06/01/2022 14:26:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 14:26:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=163
06/01/2022 14:26:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=164
06/01/2022 14:26:58 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9821341293115486 on epoch=164
06/01/2022 14:27:00 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=164
06/01/2022 14:27:03 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 14:27:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 14:27:08 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 14:27:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 14:27:17 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.9186705767350927 on epoch=167
06/01/2022 14:27:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=168
06/01/2022 14:27:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=169
06/01/2022 14:27:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=169
06/01/2022 14:27:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 14:27:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=171
06/01/2022 14:27:37 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9865940511101802 on epoch=171
06/01/2022 14:27:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 14:27:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=172
06/01/2022 14:27:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=173
06/01/2022 14:27:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=174
06/01/2022 14:27:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 14:27:56 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=174
06/01/2022 14:27:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9865940511101802 -> 0.9910627007401202 on epoch=174, global_step=2450
06/01/2022 14:27:59 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=175
06/01/2022 14:28:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=176
06/01/2022 14:28:04 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=177
06/01/2022 14:28:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=177
06/01/2022 14:28:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=178
06/01/2022 14:28:16 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9821254014802402 on epoch=178
06/01/2022 14:28:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=179
06/01/2022 14:28:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=179
06/01/2022 14:28:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=180
06/01/2022 14:28:27 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=181
06/01/2022 14:28:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=182
06/01/2022 14:28:35 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.9821254014802402 on epoch=182
06/01/2022 14:28:38 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 14:28:41 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 14:28:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 14:28:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 14:28:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 14:28:56 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9186705767350929 on epoch=185
06/01/2022 14:28:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=186
06/01/2022 14:29:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=187
06/01/2022 14:29:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 14:29:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/01/2022 14:29:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=189
06/01/2022 14:29:17 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=189
06/01/2022 14:29:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 14:29:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 14:29:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=191
06/01/2022 14:29:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=192
06/01/2022 14:29:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/01/2022 14:29:36 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=192
06/01/2022 14:29:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=193
06/01/2022 14:29:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/01/2022 14:29:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=194
06/01/2022 14:29:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=195
06/01/2022 14:29:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 14:29:56 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9228413163897036 on epoch=196
06/01/2022 14:29:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=197
06/01/2022 14:30:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 14:30:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 14:30:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=199
06/01/2022 14:30:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=199
06/01/2022 14:30:15 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9910627007401202 on epoch=199
06/01/2022 14:30:18 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=200
06/01/2022 14:30:21 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=201
06/01/2022 14:30:23 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=202
06/01/2022 14:30:26 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=202
06/01/2022 14:30:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=203
06/01/2022 14:30:35 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9821341293115486 on epoch=203
06/01/2022 14:30:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=204
06/01/2022 14:30:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=204
06/01/2022 14:30:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 14:30:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=206
06/01/2022 14:30:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=207
06/01/2022 14:30:55 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=207
06/01/2022 14:30:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=207
06/01/2022 14:31:00 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=208
06/01/2022 14:31:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/01/2022 14:31:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 14:31:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 14:31:15 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.9776654796816088 on epoch=210
06/01/2022 14:31:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=211
06/01/2022 14:31:21 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/01/2022 14:31:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=212
06/01/2022 14:31:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=213
06/01/2022 14:31:29 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=214
06/01/2022 14:31:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:31:31 - INFO - __main__ - Printing 3 examples
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:31:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:31:31 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:31:31 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:31:31 - INFO - __main__ - Printing 3 examples
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:31:31 - INFO - __main__ - ['Film']
06/01/2022 14:31:31 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:31:31 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:31:31 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:31:35 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9865940511101802 on epoch=214
06/01/2022 14:31:35 - INFO - __main__ - save last model!
06/01/2022 14:31:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 14:31:36 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 14:31:36 - INFO - __main__ - Printing 3 examples
06/01/2022 14:31:36 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 14:31:36 - INFO - __main__ - ['Animal']
06/01/2022 14:31:36 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 14:31:36 - INFO - __main__ - ['Animal']
06/01/2022 14:31:36 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 14:31:36 - INFO - __main__ - ['Village']
06/01/2022 14:31:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:31:38 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:31:41 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 14:31:47 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:31:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:31:47 - INFO - __main__ - Starting training!
06/01/2022 14:33:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_87_0.4_8_predictions.txt
06/01/2022 14:33:55 - INFO - __main__ - Classification-F1 on test data: 0.8076
06/01/2022 14:33:55 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.4, bsz=8, dev_performance=0.9910627007401202, test_performance=0.8075894028549859
06/01/2022 14:33:55 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.3, bsz=8 ...
06/01/2022 14:33:56 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:33:56 - INFO - __main__ - Printing 3 examples
06/01/2022 14:33:56 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:33:56 - INFO - __main__ - ['Film']
06/01/2022 14:33:56 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:33:56 - INFO - __main__ - ['Film']
06/01/2022 14:33:56 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:33:56 - INFO - __main__ - ['Film']
06/01/2022 14:33:56 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:33:56 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:33:57 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:33:57 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:33:57 - INFO - __main__ - Printing 3 examples
06/01/2022 14:33:57 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:33:57 - INFO - __main__ - ['Film']
06/01/2022 14:33:57 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:33:57 - INFO - __main__ - ['Film']
06/01/2022 14:33:57 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:33:57 - INFO - __main__ - ['Film']
06/01/2022 14:33:57 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:33:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:33:57 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:34:12 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:34:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:34:13 - INFO - __main__ - Starting training!
06/01/2022 14:34:17 - INFO - __main__ - Step 10 Global step 10 Train loss 5.66 on epoch=0
06/01/2022 14:34:20 - INFO - __main__ - Step 20 Global step 20 Train loss 4.47 on epoch=1
06/01/2022 14:34:23 - INFO - __main__ - Step 30 Global step 30 Train loss 3.41 on epoch=2
06/01/2022 14:34:25 - INFO - __main__ - Step 40 Global step 40 Train loss 2.94 on epoch=2
06/01/2022 14:34:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.68 on epoch=3
06/01/2022 14:34:34 - INFO - __main__ - Global step 50 Train loss 3.83 Classification-F1 0.06279282770510841 on epoch=3
06/01/2022 14:34:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06279282770510841 on epoch=3, global_step=50
06/01/2022 14:34:36 - INFO - __main__ - Step 60 Global step 60 Train loss 2.21 on epoch=4
06/01/2022 14:34:39 - INFO - __main__ - Step 70 Global step 70 Train loss 1.69 on epoch=4
06/01/2022 14:34:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.69 on epoch=5
06/01/2022 14:34:44 - INFO - __main__ - Step 90 Global step 90 Train loss 1.47 on epoch=6
06/01/2022 14:34:47 - INFO - __main__ - Step 100 Global step 100 Train loss 1.22 on epoch=7
06/01/2022 14:34:53 - INFO - __main__ - Global step 100 Train loss 1.66 Classification-F1 0.2483010519006445 on epoch=7
06/01/2022 14:34:53 - INFO - __main__ - Saving model with best Classification-F1: 0.06279282770510841 -> 0.2483010519006445 on epoch=7, global_step=100
06/01/2022 14:34:56 - INFO - __main__ - Step 110 Global step 110 Train loss 1.08 on epoch=7
06/01/2022 14:34:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=8
06/01/2022 14:35:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=9
06/01/2022 14:35:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=9
06/01/2022 14:35:06 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=10
06/01/2022 14:35:13 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.4000103120673971 on epoch=10
06/01/2022 14:35:13 - INFO - __main__ - Saving model with best Classification-F1: 0.2483010519006445 -> 0.4000103120673971 on epoch=10, global_step=150
06/01/2022 14:35:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=11
06/01/2022 14:35:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=12
06/01/2022 14:35:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=12
06/01/2022 14:35:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=13
06/01/2022 14:35:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.53 on epoch=14
06/01/2022 14:35:34 - INFO - __main__ - Global step 200 Train loss 0.60 Classification-F1 0.5794724440318544 on epoch=14
06/01/2022 14:35:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4000103120673971 -> 0.5794724440318544 on epoch=14, global_step=200
06/01/2022 14:35:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.52 on epoch=14
06/01/2022 14:35:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=15
06/01/2022 14:35:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=16
06/01/2022 14:35:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=17
06/01/2022 14:35:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=17
06/01/2022 14:35:54 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.7601040814039463 on epoch=17
06/01/2022 14:35:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5794724440318544 -> 0.7601040814039463 on epoch=17, global_step=250
06/01/2022 14:35:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=18
06/01/2022 14:36:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.43 on epoch=19
06/01/2022 14:36:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=19
06/01/2022 14:36:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=20
06/01/2022 14:36:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=21
06/01/2022 14:36:15 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.8341150134699591 on epoch=21
06/01/2022 14:36:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7601040814039463 -> 0.8341150134699591 on epoch=21, global_step=300
06/01/2022 14:36:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=22
06/01/2022 14:36:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=22
06/01/2022 14:36:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=23
06/01/2022 14:36:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=24
06/01/2022 14:36:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=24
06/01/2022 14:36:35 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.7742155134882349 on epoch=24
06/01/2022 14:36:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.36 on epoch=25
06/01/2022 14:36:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=26
06/01/2022 14:36:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=27
06/01/2022 14:36:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=27
06/01/2022 14:36:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=28
06/01/2022 14:36:56 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.6632260440669506 on epoch=28
06/01/2022 14:36:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=29
06/01/2022 14:37:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=29
06/01/2022 14:37:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=30
06/01/2022 14:37:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=31
06/01/2022 14:37:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=32
06/01/2022 14:37:16 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.7359982108996618 on epoch=32
06/01/2022 14:37:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=32
06/01/2022 14:37:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=33
06/01/2022 14:37:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=34
06/01/2022 14:37:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=34
06/01/2022 14:37:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=35
06/01/2022 14:37:36 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.8043582871177257 on epoch=35
06/01/2022 14:37:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=36
06/01/2022 14:37:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=37
06/01/2022 14:37:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=37
06/01/2022 14:37:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=38
06/01/2022 14:37:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=39
06/01/2022 14:37:56 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.7939125808379657 on epoch=39
06/01/2022 14:37:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=39
06/01/2022 14:38:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=40
06/01/2022 14:38:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=41
06/01/2022 14:38:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=42
06/01/2022 14:38:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=42
06/01/2022 14:38:16 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.796419157094417 on epoch=42
06/01/2022 14:38:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=43
06/01/2022 14:38:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=44
06/01/2022 14:38:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.29 on epoch=44
06/01/2022 14:38:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=45
06/01/2022 14:38:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=46
06/01/2022 14:38:36 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.789424324285281 on epoch=46
06/01/2022 14:38:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=47
06/01/2022 14:38:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=47
06/01/2022 14:38:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=48
06/01/2022 14:38:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=49
06/01/2022 14:38:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=49
06/01/2022 14:38:57 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.7745316106647938 on epoch=49
06/01/2022 14:38:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=50
06/01/2022 14:39:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=51
06/01/2022 14:39:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=52
06/01/2022 14:39:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=52
06/01/2022 14:39:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=53
06/01/2022 14:39:17 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.7761666631967784 on epoch=53
06/01/2022 14:39:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=54
06/01/2022 14:39:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.20 on epoch=54
06/01/2022 14:39:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=55
06/01/2022 14:39:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=56
06/01/2022 14:39:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=57
06/01/2022 14:39:37 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.822038422117579 on epoch=57
06/01/2022 14:39:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=57
06/01/2022 14:39:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=58
06/01/2022 14:39:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=59
06/01/2022 14:39:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=59
06/01/2022 14:39:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=60
06/01/2022 14:39:57 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.851741705479846 on epoch=60
06/01/2022 14:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8341150134699591 -> 0.851741705479846 on epoch=60, global_step=850
06/01/2022 14:40:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=61
06/01/2022 14:40:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=62
06/01/2022 14:40:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=62
06/01/2022 14:40:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=63
06/01/2022 14:40:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=64
06/01/2022 14:40:18 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.9001134952732045 on epoch=64
06/01/2022 14:40:18 - INFO - __main__ - Saving model with best Classification-F1: 0.851741705479846 -> 0.9001134952732045 on epoch=64, global_step=900
06/01/2022 14:40:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=64
06/01/2022 14:40:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=65
06/01/2022 14:40:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=66
06/01/2022 14:40:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=67
06/01/2022 14:40:31 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=67
06/01/2022 14:40:38 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.9049514937939986 on epoch=67
06/01/2022 14:40:38 - INFO - __main__ - Saving model with best Classification-F1: 0.9001134952732045 -> 0.9049514937939986 on epoch=67, global_step=950
06/01/2022 14:40:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=68
06/01/2022 14:40:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=69
06/01/2022 14:40:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=69
06/01/2022 14:40:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=70
06/01/2022 14:40:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=71
06/01/2022 14:40:57 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.7890899028232994 on epoch=71
06/01/2022 14:41:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=72
06/01/2022 14:41:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=72
06/01/2022 14:41:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=73
06/01/2022 14:41:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=74
06/01/2022 14:41:11 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=74
06/01/2022 14:41:17 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.863147605083089 on epoch=74
06/01/2022 14:41:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=75
06/01/2022 14:41:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=76
06/01/2022 14:41:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=77
06/01/2022 14:41:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=77
06/01/2022 14:41:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=78
06/01/2022 14:41:37 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.863147605083089 on epoch=78
06/01/2022 14:41:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=79
06/01/2022 14:41:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=79
06/01/2022 14:41:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=80
06/01/2022 14:41:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=81
06/01/2022 14:41:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=82
06/01/2022 14:41:57 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8474186949845668 on epoch=82
06/01/2022 14:41:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=82
06/01/2022 14:42:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=83
06/01/2022 14:42:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=84
06/01/2022 14:42:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=84
06/01/2022 14:42:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=85
06/01/2022 14:42:17 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.9777840755070358 on epoch=85
06/01/2022 14:42:17 - INFO - __main__ - Saving model with best Classification-F1: 0.9049514937939986 -> 0.9777840755070358 on epoch=85, global_step=1200
06/01/2022 14:42:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=86
06/01/2022 14:42:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=87
06/01/2022 14:42:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=87
06/01/2022 14:42:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=88
06/01/2022 14:42:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=89
06/01/2022 14:42:37 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.9821297653958947 on epoch=89
06/01/2022 14:42:37 - INFO - __main__ - Saving model with best Classification-F1: 0.9777840755070358 -> 0.9821297653958947 on epoch=89, global_step=1250
06/01/2022 14:42:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=89
06/01/2022 14:42:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=90
06/01/2022 14:42:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=91
06/01/2022 14:42:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=92
06/01/2022 14:42:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=92
06/01/2022 14:42:57 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.9103045636631976 on epoch=92
06/01/2022 14:43:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=93
06/01/2022 14:43:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=94
06/01/2022 14:43:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=94
06/01/2022 14:43:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=95
06/01/2022 14:43:10 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=96
06/01/2022 14:43:17 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.863147605083089 on epoch=96
06/01/2022 14:43:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=97
06/01/2022 14:43:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=97
06/01/2022 14:43:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=98
06/01/2022 14:43:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=99
06/01/2022 14:43:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=99
06/01/2022 14:43:36 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9186705767350929 on epoch=99
06/01/2022 14:43:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=100
06/01/2022 14:43:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/01/2022 14:43:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=102
06/01/2022 14:43:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=102
06/01/2022 14:43:49 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=103
06/01/2022 14:43:56 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.9821297653958947 on epoch=103
06/01/2022 14:43:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=104
06/01/2022 14:44:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=104
06/01/2022 14:44:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=105
06/01/2022 14:44:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=106
06/01/2022 14:44:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=107
06/01/2022 14:44:15 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.9821297653958947 on epoch=107
06/01/2022 14:44:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=107
06/01/2022 14:44:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=108
06/01/2022 14:44:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=109
06/01/2022 14:44:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/01/2022 14:44:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=110
06/01/2022 14:44:34 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.9143564679048553 on epoch=110
06/01/2022 14:44:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=111
06/01/2022 14:44:39 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=112
06/01/2022 14:44:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=112
06/01/2022 14:44:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=113
06/01/2022 14:44:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=114
06/01/2022 14:44:54 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.9143564679048549 on epoch=114
06/01/2022 14:44:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=114
06/01/2022 14:44:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=115
06/01/2022 14:45:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=116
06/01/2022 14:45:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=117
06/01/2022 14:45:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=117
06/01/2022 14:45:13 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9144998370804823 on epoch=117
06/01/2022 14:45:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=118
06/01/2022 14:45:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=119
06/01/2022 14:45:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=119
06/01/2022 14:45:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=120
06/01/2022 14:45:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=121
06/01/2022 14:45:33 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.9061338240085869 on epoch=121
06/01/2022 14:45:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=122
06/01/2022 14:45:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=122
06/01/2022 14:45:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=123
06/01/2022 14:45:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=124
06/01/2022 14:45:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=124
06/01/2022 14:45:52 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.855327468230694 on epoch=124
06/01/2022 14:45:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=125
06/01/2022 14:45:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=126
06/01/2022 14:46:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=127
06/01/2022 14:46:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=127
06/01/2022 14:46:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=128
06/01/2022 14:46:11 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.859103128054741 on epoch=128
06/01/2022 14:46:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=129
06/01/2022 14:46:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=129
06/01/2022 14:46:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=130
06/01/2022 14:46:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=131
06/01/2022 14:46:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=132
06/01/2022 14:46:30 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9775075059349252 on epoch=132
06/01/2022 14:46:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=132
06/01/2022 14:46:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=133
06/01/2022 14:46:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=134
06/01/2022 14:46:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=134
06/01/2022 14:46:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=135
06/01/2022 14:46:49 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.9103331704138157 on epoch=135
06/01/2022 14:46:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=136
06/01/2022 14:46:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=137
06/01/2022 14:46:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=137
06/01/2022 14:47:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=138
06/01/2022 14:47:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 14:47:09 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9145039100684262 on epoch=139
06/01/2022 14:47:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=139
06/01/2022 14:47:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=140
06/01/2022 14:47:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=141
06/01/2022 14:47:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=142
06/01/2022 14:47:21 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=142
06/01/2022 14:47:28 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8066701167270428 on epoch=142
06/01/2022 14:47:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=143
06/01/2022 14:47:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=144
06/01/2022 14:47:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=144
06/01/2022 14:47:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=145
06/01/2022 14:47:41 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=146
06/01/2022 14:47:47 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9186705767350929 on epoch=146
06/01/2022 14:47:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/01/2022 14:47:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=147
06/01/2022 14:47:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=148
06/01/2022 14:47:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=149
06/01/2022 14:48:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=149
06/01/2022 14:48:06 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.9143564679048553 on epoch=149
06/01/2022 14:48:09 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=150
06/01/2022 14:48:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=151
06/01/2022 14:48:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=152
06/01/2022 14:48:17 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=152
06/01/2022 14:48:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=153
06/01/2022 14:48:26 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.90803926360378 on epoch=153
06/01/2022 14:48:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=154
06/01/2022 14:48:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=154
06/01/2022 14:48:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=155
06/01/2022 14:48:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=156
06/01/2022 14:48:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=157
06/01/2022 14:48:45 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.855196878054741 on epoch=157
06/01/2022 14:48:47 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=157
06/01/2022 14:48:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/01/2022 14:48:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=159
06/01/2022 14:48:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=159
06/01/2022 14:48:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=160
06/01/2022 14:49:04 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9097578959786969 on epoch=160
06/01/2022 14:49:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=161
06/01/2022 14:49:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=162
06/01/2022 14:49:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=162
06/01/2022 14:49:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=163
06/01/2022 14:49:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=164
06/01/2022 14:49:23 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.9186746497230369 on epoch=164
06/01/2022 14:49:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=164
06/01/2022 14:49:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=165
06/01/2022 14:49:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=166
06/01/2022 14:49:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=167
06/01/2022 14:49:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=167
06/01/2022 14:49:43 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7990474908741938 on epoch=167
06/01/2022 14:49:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=168
06/01/2022 14:49:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=169
06/01/2022 14:49:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=169
06/01/2022 14:49:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=170
06/01/2022 14:49:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=171
06/01/2022 14:50:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7928849692369617 on epoch=171
06/01/2022 14:50:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=172
06/01/2022 14:50:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=172
06/01/2022 14:50:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=173
06/01/2022 14:50:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=174
06/01/2022 14:50:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=174
06/01/2022 14:50:21 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.9145039100684262 on epoch=174
06/01/2022 14:50:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=175
06/01/2022 14:50:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/01/2022 14:50:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=177
06/01/2022 14:50:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=177
06/01/2022 14:50:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=178
06/01/2022 14:50:41 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9865984150258343 on epoch=178
06/01/2022 14:50:41 - INFO - __main__ - Saving model with best Classification-F1: 0.9821297653958947 -> 0.9865984150258343 on epoch=178, global_step=2500
06/01/2022 14:50:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/01/2022 14:50:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=179
06/01/2022 14:50:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=180
06/01/2022 14:50:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=181
06/01/2022 14:50:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=182
06/01/2022 14:51:00 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9821297653958947 on epoch=182
06/01/2022 14:51:03 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=182
06/01/2022 14:51:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=183
06/01/2022 14:51:08 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=184
06/01/2022 14:51:11 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=184
06/01/2022 14:51:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=185
06/01/2022 14:51:19 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9730388563049855 on epoch=185
06/01/2022 14:51:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=186
06/01/2022 14:51:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=187
06/01/2022 14:51:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=187
06/01/2022 14:51:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=188
06/01/2022 14:51:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=189
06/01/2022 14:51:39 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9776611157659545 on epoch=189
06/01/2022 14:51:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=189
06/01/2022 14:51:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=190
06/01/2022 14:51:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=191
06/01/2022 14:51:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=192
06/01/2022 14:51:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=192
06/01/2022 14:51:58 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.9185272075594656 on epoch=192
06/01/2022 14:52:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=193
06/01/2022 14:52:03 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/01/2022 14:52:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=194
06/01/2022 14:52:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=195
06/01/2022 14:52:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=196
06/01/2022 14:52:17 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9228413163897036 on epoch=196
06/01/2022 14:52:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=197
06/01/2022 14:52:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=197
06/01/2022 14:52:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=198
06/01/2022 14:52:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=199
06/01/2022 14:52:30 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=199
06/01/2022 14:52:37 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.9144998370804825 on epoch=199
06/01/2022 14:52:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=200
06/01/2022 14:52:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=201
06/01/2022 14:52:44 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=202
06/01/2022 14:52:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=202
06/01/2022 14:52:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 14:52:56 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9186705767350929 on epoch=203
06/01/2022 14:52:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/01/2022 14:53:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=204
06/01/2022 14:53:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=205
06/01/2022 14:53:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=206
06/01/2022 14:53:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=207
06/01/2022 14:53:16 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.863147605083089 on epoch=207
06/01/2022 14:53:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=207
06/01/2022 14:53:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=208
06/01/2022 14:53:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=209
06/01/2022 14:53:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=209
06/01/2022 14:53:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=210
06/01/2022 14:53:36 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9270120560443141 on epoch=210
06/01/2022 14:53:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=211
06/01/2022 14:53:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=212
06/01/2022 14:53:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=212
06/01/2022 14:53:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=213
06/01/2022 14:53:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/01/2022 14:53:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:53:51 - INFO - __main__ - Printing 3 examples
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:53:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:53:51 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:53:51 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:53:51 - INFO - __main__ - Printing 3 examples
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:53:51 - INFO - __main__ - ['Film']
06/01/2022 14:53:51 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:53:51 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:53:51 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:53:55 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9186746497230369 on epoch=214
06/01/2022 14:53:55 - INFO - __main__ - save last model!
06/01/2022 14:53:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 14:53:55 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 14:53:55 - INFO - __main__ - Printing 3 examples
06/01/2022 14:53:55 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 14:53:55 - INFO - __main__ - ['Animal']
06/01/2022 14:53:55 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 14:53:55 - INFO - __main__ - ['Animal']
06/01/2022 14:53:55 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 14:53:55 - INFO - __main__ - ['Village']
06/01/2022 14:53:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:53:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:54:01 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 14:54:10 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:54:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:54:11 - INFO - __main__ - Starting training!
06/01/2022 14:56:13 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_87_0.3_8_predictions.txt
06/01/2022 14:56:13 - INFO - __main__ - Classification-F1 on test data: 0.8042
06/01/2022 14:56:13 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.3, bsz=8, dev_performance=0.9865984150258343, test_performance=0.8041793744644955
06/01/2022 14:56:13 - INFO - __main__ - Running ... prefix=dbpedia_14_16_87, lr=0.2, bsz=8 ...
06/01/2022 14:56:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:56:14 - INFO - __main__ - Printing 3 examples
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:56:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:56:14 - INFO - __main__ - Loaded 224 examples from train data
06/01/2022 14:56:14 - INFO - __main__ - Start tokenizing ... 224 instances
06/01/2022 14:56:14 - INFO - __main__ - Printing 3 examples
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Spartacus is a 1960 American epic historical drama film directed by Stanley Kubrick and starring Kirk Douglas as the rebellious slave of the title. The screenplay by Dalton Trumbo was based on the novel Spartacus by Howard Fast.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Three Rooms in Manhattan (French: Trois chambres à Manhattan) is a 1965 French drama film filmed in New York City. It is based on the 1946 novel Trois Chambres à Manhattan (which has been translated into English as Three Bedrooms in Manhattan) by Belgian writer Georges Simenon about a romance between François a French actor and Kay an American woman.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ -  [dbpedia_14] Return Home is a 1990 Australian drama film directed by Ray Argall. Argall won the AFI Award for Best Director in 1990 and Frankie J. Holden was nominated for Best Actor in a Lead Role.
06/01/2022 14:56:14 - INFO - __main__ - ['Film']
06/01/2022 14:56:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 14:56:15 - INFO - __main__ - Tokenizing Output ...
06/01/2022 14:56:15 - INFO - __main__ - Loaded 224 examples from dev data
06/01/2022 14:56:30 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 14:56:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 14:56:30 - INFO - __main__ - Starting training!
06/01/2022 14:56:34 - INFO - __main__ - Step 10 Global step 10 Train loss 5.81 on epoch=0
06/01/2022 14:56:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.84 on epoch=1
06/01/2022 14:56:40 - INFO - __main__ - Step 30 Global step 30 Train loss 4.16 on epoch=2
06/01/2022 14:56:42 - INFO - __main__ - Step 40 Global step 40 Train loss 3.47 on epoch=2
06/01/2022 14:56:45 - INFO - __main__ - Step 50 Global step 50 Train loss 3.32 on epoch=3
06/01/2022 14:56:51 - INFO - __main__ - Global step 50 Train loss 4.32 Classification-F1 0.04047845524542219 on epoch=3
06/01/2022 14:56:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04047845524542219 on epoch=3, global_step=50
06/01/2022 14:56:54 - INFO - __main__ - Step 60 Global step 60 Train loss 2.92 on epoch=4
06/01/2022 14:56:56 - INFO - __main__ - Step 70 Global step 70 Train loss 2.29 on epoch=4
06/01/2022 14:56:59 - INFO - __main__ - Step 80 Global step 80 Train loss 2.39 on epoch=5
06/01/2022 14:57:02 - INFO - __main__ - Step 90 Global step 90 Train loss 2.08 on epoch=6
06/01/2022 14:57:04 - INFO - __main__ - Step 100 Global step 100 Train loss 1.81 on epoch=7
06/01/2022 14:57:10 - INFO - __main__ - Global step 100 Train loss 2.30 Classification-F1 0.0802700469463304 on epoch=7
06/01/2022 14:57:10 - INFO - __main__ - Saving model with best Classification-F1: 0.04047845524542219 -> 0.0802700469463304 on epoch=7, global_step=100
06/01/2022 14:57:13 - INFO - __main__ - Step 110 Global step 110 Train loss 1.57 on epoch=7
06/01/2022 14:57:16 - INFO - __main__ - Step 120 Global step 120 Train loss 1.55 on epoch=8
06/01/2022 14:57:18 - INFO - __main__ - Step 130 Global step 130 Train loss 1.47 on epoch=9
06/01/2022 14:57:21 - INFO - __main__ - Step 140 Global step 140 Train loss 1.24 on epoch=9
06/01/2022 14:57:24 - INFO - __main__ - Step 150 Global step 150 Train loss 1.24 on epoch=10
06/01/2022 14:57:30 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.22900042124942513 on epoch=10
06/01/2022 14:57:30 - INFO - __main__ - Saving model with best Classification-F1: 0.0802700469463304 -> 0.22900042124942513 on epoch=10, global_step=150
06/01/2022 14:57:33 - INFO - __main__ - Step 160 Global step 160 Train loss 1.15 on epoch=11
06/01/2022 14:57:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=12
06/01/2022 14:57:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.81 on epoch=12
06/01/2022 14:57:41 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=13
06/01/2022 14:57:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=14
06/01/2022 14:57:51 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.3832178870930993 on epoch=14
06/01/2022 14:57:51 - INFO - __main__ - Saving model with best Classification-F1: 0.22900042124942513 -> 0.3832178870930993 on epoch=14, global_step=200
06/01/2022 14:57:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=14
06/01/2022 14:57:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=15
06/01/2022 14:57:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=16
06/01/2022 14:58:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=17
06/01/2022 14:58:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=17
06/01/2022 14:58:11 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.43120592059609164 on epoch=17
06/01/2022 14:58:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3832178870930993 -> 0.43120592059609164 on epoch=17, global_step=250
06/01/2022 14:58:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=18
06/01/2022 14:58:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=19
06/01/2022 14:58:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=19
06/01/2022 14:58:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=20
06/01/2022 14:58:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=21
06/01/2022 14:58:31 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.5431876130347142 on epoch=21
06/01/2022 14:58:31 - INFO - __main__ - Saving model with best Classification-F1: 0.43120592059609164 -> 0.5431876130347142 on epoch=21, global_step=300
06/01/2022 14:58:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.56 on epoch=22
06/01/2022 14:58:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=22
06/01/2022 14:58:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.52 on epoch=23
06/01/2022 14:58:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=24
06/01/2022 14:58:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=24
06/01/2022 14:58:52 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.592768453193349 on epoch=24
06/01/2022 14:58:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5431876130347142 -> 0.592768453193349 on epoch=24, global_step=350
06/01/2022 14:58:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=25
06/01/2022 14:58:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=26
06/01/2022 14:58:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=27
06/01/2022 14:59:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=27
06/01/2022 14:59:05 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=28
06/01/2022 14:59:12 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.6731393707822226 on epoch=28
06/01/2022 14:59:12 - INFO - __main__ - Saving model with best Classification-F1: 0.592768453193349 -> 0.6731393707822226 on epoch=28, global_step=400
06/01/2022 14:59:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.58 on epoch=29
06/01/2022 14:59:18 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=29
06/01/2022 14:59:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=30
06/01/2022 14:59:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.46 on epoch=31
06/01/2022 14:59:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=32
06/01/2022 14:59:34 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.7313833540629654 on epoch=32
06/01/2022 14:59:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6731393707822226 -> 0.7313833540629654 on epoch=32, global_step=450
06/01/2022 14:59:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=32
06/01/2022 14:59:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=33
06/01/2022 14:59:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.44 on epoch=34
06/01/2022 14:59:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=34
06/01/2022 14:59:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.49 on epoch=35
06/01/2022 14:59:54 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.6994564708079533 on epoch=35
06/01/2022 14:59:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=36
06/01/2022 15:00:00 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=37
06/01/2022 15:00:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=37
06/01/2022 15:00:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=38
06/01/2022 15:00:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=39
06/01/2022 15:00:15 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.7423852885405791 on epoch=39
06/01/2022 15:00:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7313833540629654 -> 0.7423852885405791 on epoch=39, global_step=550
06/01/2022 15:00:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=39
06/01/2022 15:00:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=40
06/01/2022 15:00:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=41
06/01/2022 15:00:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=42
06/01/2022 15:00:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=42
06/01/2022 15:00:35 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.8459519783913836 on epoch=42
06/01/2022 15:00:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7423852885405791 -> 0.8459519783913836 on epoch=42, global_step=600
06/01/2022 15:00:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=43
06/01/2022 15:00:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=44
06/01/2022 15:00:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=44
06/01/2022 15:00:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=45
06/01/2022 15:00:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.37 on epoch=46
06/01/2022 15:00:55 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.8451062242289835 on epoch=46
06/01/2022 15:00:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=47
06/01/2022 15:01:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=47
06/01/2022 15:01:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=48
06/01/2022 15:01:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=49
06/01/2022 15:01:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=49
06/01/2022 15:01:16 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.755986796579285 on epoch=49
06/01/2022 15:01:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=50
06/01/2022 15:01:21 - INFO - __main__ - Step 720 Global step 720 Train loss 0.23 on epoch=51
06/01/2022 15:01:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=52
06/01/2022 15:01:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=52
06/01/2022 15:01:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=53
06/01/2022 15:01:36 - INFO - __main__ - Global step 750 Train loss 0.27 Classification-F1 0.8496115307504191 on epoch=53
06/01/2022 15:01:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8459519783913836 -> 0.8496115307504191 on epoch=53, global_step=750
06/01/2022 15:01:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=54
06/01/2022 15:01:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=54
06/01/2022 15:01:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=55
06/01/2022 15:01:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=56
06/01/2022 15:01:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=57
06/01/2022 15:01:56 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.8023935022037489 on epoch=57
06/01/2022 15:01:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=57
06/01/2022 15:02:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=58
06/01/2022 15:02:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=59
06/01/2022 15:02:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=59
06/01/2022 15:02:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=60
06/01/2022 15:02:17 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.7479233613337044 on epoch=60
06/01/2022 15:02:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=61
06/01/2022 15:02:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=62
06/01/2022 15:02:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=62
06/01/2022 15:02:28 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=63
06/01/2022 15:02:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=64
06/01/2022 15:02:37 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7071959472710302 on epoch=64
06/01/2022 15:02:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=64
06/01/2022 15:02:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=65
06/01/2022 15:02:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=66
06/01/2022 15:02:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=67
06/01/2022 15:02:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=67
06/01/2022 15:02:57 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6841754883535053 on epoch=67
06/01/2022 15:03:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=68
06/01/2022 15:03:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=69
06/01/2022 15:03:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=69
06/01/2022 15:03:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=70
06/01/2022 15:03:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.24 on epoch=71
06/01/2022 15:03:17 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.6954768175870326 on epoch=71
06/01/2022 15:03:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=72
06/01/2022 15:03:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=72
06/01/2022 15:03:26 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=73
06/01/2022 15:03:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=74
06/01/2022 15:03:31 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=74
06/01/2022 15:03:37 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.6479166855814714 on epoch=74
06/01/2022 15:03:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=75
06/01/2022 15:03:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=76
06/01/2022 15:03:45 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.27 on epoch=77
06/01/2022 15:03:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=77
06/01/2022 15:03:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=78
06/01/2022 15:03:57 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.6388815810655781 on epoch=78
06/01/2022 15:04:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=79
06/01/2022 15:04:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=79
06/01/2022 15:04:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=80
06/01/2022 15:04:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=81
06/01/2022 15:04:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=82
06/01/2022 15:04:18 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.5809119607438935 on epoch=82
06/01/2022 15:04:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=82
06/01/2022 15:04:23 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=83
06/01/2022 15:04:26 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=84
06/01/2022 15:04:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=84
06/01/2022 15:04:31 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=85
06/01/2022 15:04:38 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.7236687188244282 on epoch=85
06/01/2022 15:04:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=86
06/01/2022 15:04:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=87
06/01/2022 15:04:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=87
06/01/2022 15:04:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=88
06/01/2022 15:04:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=89
06/01/2022 15:04:58 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.47597488889273876 on epoch=89
06/01/2022 15:05:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=89
06/01/2022 15:05:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=90
06/01/2022 15:05:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=91
06/01/2022 15:05:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=92
06/01/2022 15:05:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=92
06/01/2022 15:05:18 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.61637066141217 on epoch=92
06/01/2022 15:05:21 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=93
06/01/2022 15:05:24 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=94
06/01/2022 15:05:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=94
06/01/2022 15:05:29 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.18 on epoch=95
06/01/2022 15:05:32 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=96
06/01/2022 15:05:39 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.6671079112305518 on epoch=96
06/01/2022 15:05:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.16 on epoch=97
06/01/2022 15:05:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=97
06/01/2022 15:05:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=98
06/01/2022 15:05:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=99
06/01/2022 15:05:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=99
06/01/2022 15:05:59 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.6982847263484518 on epoch=99
06/01/2022 15:06:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=100
06/01/2022 15:06:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=101
06/01/2022 15:06:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=102
06/01/2022 15:06:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=102
06/01/2022 15:06:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=103
06/01/2022 15:06:20 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.8274152818507657 on epoch=103
06/01/2022 15:06:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=104
06/01/2022 15:06:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=104
06/01/2022 15:06:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=105
06/01/2022 15:06:31 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=106
06/01/2022 15:06:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=107
06/01/2022 15:06:40 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6067411144972814 on epoch=107
06/01/2022 15:06:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=107
06/01/2022 15:06:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=108
06/01/2022 15:06:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=109
06/01/2022 15:06:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=109
06/01/2022 15:06:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=110
06/01/2022 15:07:00 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7231237102204845 on epoch=110
06/01/2022 15:07:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=111
06/01/2022 15:07:06 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=112
06/01/2022 15:07:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=112
06/01/2022 15:07:11 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=113
06/01/2022 15:07:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=114
06/01/2022 15:07:20 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.6385600846083254 on epoch=114
06/01/2022 15:07:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.17 on epoch=114
06/01/2022 15:07:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=115
06/01/2022 15:07:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=116
06/01/2022 15:07:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=117
06/01/2022 15:07:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=117
06/01/2022 15:07:40 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.6345068467269606 on epoch=117
06/01/2022 15:07:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=118
06/01/2022 15:07:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=119
06/01/2022 15:07:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=119
06/01/2022 15:07:51 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=120
06/01/2022 15:07:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=121
06/01/2022 15:08:00 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.6871032075614576 on epoch=121
06/01/2022 15:08:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=122
06/01/2022 15:08:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=122
06/01/2022 15:08:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=123
06/01/2022 15:08:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=124
06/01/2022 15:08:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=124
06/01/2022 15:08:20 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.7238434143357743 on epoch=124
06/01/2022 15:08:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=125
06/01/2022 15:08:26 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=126
06/01/2022 15:08:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=127
06/01/2022 15:08:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=127
06/01/2022 15:08:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=128
06/01/2022 15:08:41 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.8062890238510209 on epoch=128
06/01/2022 15:08:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=129
06/01/2022 15:08:46 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=129
06/01/2022 15:08:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=130
06/01/2022 15:08:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=131
06/01/2022 15:08:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=132
06/01/2022 15:09:00 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7149547339300661 on epoch=132
06/01/2022 15:09:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=132
06/01/2022 15:09:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=133
06/01/2022 15:09:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=134
06/01/2022 15:09:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=134
06/01/2022 15:09:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=135
06/01/2022 15:09:20 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.6678441132588242 on epoch=135
06/01/2022 15:09:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=136
06/01/2022 15:09:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=137
06/01/2022 15:09:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=137
06/01/2022 15:09:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=138
06/01/2022 15:09:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=139
06/01/2022 15:09:40 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7094589155310218 on epoch=139
06/01/2022 15:09:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=139
06/01/2022 15:09:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=140
06/01/2022 15:09:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=141
06/01/2022 15:09:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=142
06/01/2022 15:09:53 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=142
06/01/2022 15:10:00 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8263650328166458 on epoch=142
06/01/2022 15:10:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=143
06/01/2022 15:10:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=144
06/01/2022 15:10:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=144
06/01/2022 15:10:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=145
06/01/2022 15:10:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=146
06/01/2022 15:10:20 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.6783095493644823 on epoch=146
06/01/2022 15:10:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=147
06/01/2022 15:10:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=147
06/01/2022 15:10:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=148
06/01/2022 15:10:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=149
06/01/2022 15:10:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=149
06/01/2022 15:10:40 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6403193222548061 on epoch=149
06/01/2022 15:10:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=150
06/01/2022 15:10:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=151
06/01/2022 15:10:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=152
06/01/2022 15:10:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=152
06/01/2022 15:10:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=153
06/01/2022 15:11:01 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7452481807320517 on epoch=153
06/01/2022 15:11:04 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=154
06/01/2022 15:11:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=154
06/01/2022 15:11:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=155
06/01/2022 15:11:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=156
06/01/2022 15:11:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=157
06/01/2022 15:11:21 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8147700918099401 on epoch=157
06/01/2022 15:11:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=157
06/01/2022 15:11:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=158
06/01/2022 15:11:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=159
06/01/2022 15:11:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=159
06/01/2022 15:11:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=160
06/01/2022 15:11:42 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7896352484811018 on epoch=160
06/01/2022 15:11:45 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.13 on epoch=161
06/01/2022 15:11:48 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=162
06/01/2022 15:11:50 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=162
06/01/2022 15:11:53 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=163
06/01/2022 15:11:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=164
06/01/2022 15:12:03 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7913129248992627 on epoch=164
06/01/2022 15:12:05 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=164
06/01/2022 15:12:08 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=165
06/01/2022 15:12:11 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=166
06/01/2022 15:12:14 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=167
06/01/2022 15:12:16 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=167
06/01/2022 15:12:23 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.8518071288469771 on epoch=167
06/01/2022 15:12:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8496115307504191 -> 0.8518071288469771 on epoch=167, global_step=2350
06/01/2022 15:12:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=168
06/01/2022 15:12:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=169
06/01/2022 15:12:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=169
06/01/2022 15:12:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=170
06/01/2022 15:12:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.13 on epoch=171
06/01/2022 15:12:43 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7069074445644904 on epoch=171
06/01/2022 15:12:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=172
06/01/2022 15:12:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=172
06/01/2022 15:12:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=173
06/01/2022 15:12:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=174
06/01/2022 15:12:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=174
06/01/2022 15:13:04 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.7103130912978112 on epoch=174
06/01/2022 15:13:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=175
06/01/2022 15:13:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=176
06/01/2022 15:13:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=177
06/01/2022 15:13:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=177
06/01/2022 15:13:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=178
06/01/2022 15:13:24 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7839985729162026 on epoch=178
06/01/2022 15:13:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=179
06/01/2022 15:13:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=179
06/01/2022 15:13:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=180
06/01/2022 15:13:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=181
06/01/2022 15:13:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=182
06/01/2022 15:13:44 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6352590047856201 on epoch=182
06/01/2022 15:13:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=182
06/01/2022 15:13:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=183
06/01/2022 15:13:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=184
06/01/2022 15:13:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=184
06/01/2022 15:13:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=185
06/01/2022 15:14:04 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7914177796753977 on epoch=185
06/01/2022 15:14:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=186
06/01/2022 15:14:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=187
06/01/2022 15:14:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=187
06/01/2022 15:14:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=188
06/01/2022 15:14:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=189
06/01/2022 15:14:24 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8046460813064229 on epoch=189
06/01/2022 15:14:26 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=189
06/01/2022 15:14:29 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=190
06/01/2022 15:14:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=191
06/01/2022 15:14:34 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=192
06/01/2022 15:14:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=192
06/01/2022 15:14:43 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7966387687646603 on epoch=192
06/01/2022 15:14:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=193
06/01/2022 15:14:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=194
06/01/2022 15:14:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=194
06/01/2022 15:14:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=195
06/01/2022 15:14:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=196
06/01/2022 15:15:03 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7430852836859512 on epoch=196
06/01/2022 15:15:05 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=197
06/01/2022 15:15:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=197
06/01/2022 15:15:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=198
06/01/2022 15:15:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=199
06/01/2022 15:15:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=199
06/01/2022 15:15:22 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7913129248992627 on epoch=199
06/01/2022 15:15:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=200
06/01/2022 15:15:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=201
06/01/2022 15:15:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=202
06/01/2022 15:15:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=202
06/01/2022 15:15:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=203
06/01/2022 15:15:42 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8582512917190337 on epoch=203
06/01/2022 15:15:42 - INFO - __main__ - Saving model with best Classification-F1: 0.8518071288469771 -> 0.8582512917190337 on epoch=203, global_step=2850
06/01/2022 15:15:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=204
06/01/2022 15:15:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=204
06/01/2022 15:15:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=205
06/01/2022 15:15:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=206
06/01/2022 15:15:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=207
06/01/2022 15:16:01 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7984866121711753 on epoch=207
06/01/2022 15:16:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=207
06/01/2022 15:16:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=208
06/01/2022 15:16:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=209
06/01/2022 15:16:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=209
06/01/2022 15:16:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=210
06/01/2022 15:16:21 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7120111128260533 on epoch=210
06/01/2022 15:16:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=211
06/01/2022 15:16:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=212
06/01/2022 15:16:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=212
06/01/2022 15:16:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=213
06/01/2022 15:16:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=214
06/01/2022 15:16:40 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7580195728137886 on epoch=214
06/01/2022 15:16:40 - INFO - __main__ - save last model!
06/01/2022 15:16:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 15:16:41 - INFO - __main__ - Start tokenizing ... 3500 instances
06/01/2022 15:16:41 - INFO - __main__ - Printing 3 examples
06/01/2022 15:16:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
06/01/2022 15:16:41 - INFO - __main__ - ['Animal']
06/01/2022 15:16:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
06/01/2022 15:16:41 - INFO - __main__ - ['Animal']
06/01/2022 15:16:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
06/01/2022 15:16:41 - INFO - __main__ - ['Village']
06/01/2022 15:16:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 15:16:42 - INFO - __main__ - Tokenizing Output ...
06/01/2022 15:16:46 - INFO - __main__ - Loaded 3500 examples from test data
06/01/2022 15:18:55 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-dbpedia_14/dbpedia_14_16_87_0.2_8_predictions.txt
06/01/2022 15:18:55 - INFO - __main__ - Classification-F1 on test data: 0.5660
06/01/2022 15:18:55 - INFO - __main__ - prefix=dbpedia_14_16_87, lr=0.2, bsz=8, dev_performance=0.8582512917190337, test_performance=0.5660477710117272
