05/21/2022 06:27:36 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:27:36 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo
05/21/2022 06:27:36 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
05/21/2022 06:27:36 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo
05/21/2022 06:27:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 06:27:37 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 06:27:37 - INFO - __main__ - args.device: cuda:0
05/21/2022 06:27:37 - INFO - __main__ - Using 2 gpus
05/21/2022 06:27:37 - INFO - __main__ - args.device: cuda:1
05/21/2022 06:27:37 - INFO - __main__ - Using 2 gpus
05/21/2022 06:27:37 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 06:27:37 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
05/21/2022 06:27:41 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
05/21/2022 06:27:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:27:42 - INFO - __main__ - Printing 3 examples
05/21/2022 06:27:42 - INFO - __main__ -  [emo] how cause yes am listening
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:27:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:27:42 - INFO - __main__ - Printing 3 examples
05/21/2022 06:27:42 - INFO - __main__ -  [emo] how cause yes am listening
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:27:42 - INFO - __main__ - Loaded 64 examples from train data
05/21/2022 06:27:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:27:42 - INFO - __main__ - Printing 3 examples
05/21/2022 06:27:42 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:27:42 - INFO - __main__ - Loaded 64 examples from train data
05/21/2022 06:27:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/21/2022 06:27:42 - INFO - __main__ - Printing 3 examples
05/21/2022 06:27:42 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
05/21/2022 06:27:42 - INFO - __main__ - ['others']
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Input ...
05/21/2022 06:27:42 - INFO - __main__ - Tokenizing Output ...
05/21/2022 06:27:42 - INFO - __main__ - Loaded 64 examples from dev data
05/21/2022 06:27:42 - INFO - __main__ - Loaded 64 examples from dev data
05/21/2022 06:28:00 - INFO - __main__ - load prompt embedding from ckpt
05/21/2022 06:28:00 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 18:51:23 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/01/2022 18:51:23 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo
06/01/2022 18:51:23 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-32shot/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0,1')
06/01/2022 18:51:23 - INFO - __main__ - models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo
06/01/2022 18:51:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/01/2022 18:51:25 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/01/2022 18:51:25 - INFO - __main__ - args.device: cuda:0
06/01/2022 18:51:25 - INFO - __main__ - args.device: cuda:1
06/01/2022 18:51:25 - INFO - __main__ - Using 2 gpus
06/01/2022 18:51:25 - INFO - __main__ - Using 2 gpus
06/01/2022 18:51:25 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 18:51:25 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/01/2022 18:51:29 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/01/2022 18:51:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 18:51:30 - INFO - __main__ - Printing 3 examples
06/01/2022 18:51:30 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 18:51:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 18:51:30 - INFO - __main__ - Printing 3 examples
06/01/2022 18:51:30 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 18:51:30 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 18:51:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 18:51:30 - INFO - __main__ - Printing 3 examples
06/01/2022 18:51:30 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 18:51:30 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 18:51:30 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 18:51:30 - INFO - __main__ - Printing 3 examples
06/01/2022 18:51:30 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 18:51:30 - INFO - __main__ - ['others']
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Input ...
06/01/2022 18:51:30 - INFO - __main__ - Tokenizing Output ...
06/01/2022 18:51:30 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 18:51:31 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 18:51:48 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 18:51:49 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 18:51:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 18:51:49 - INFO - __main__ - Starting training!
06/01/2022 18:51:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 18:51:53 - INFO - __main__ - Starting training!
06/01/2022 18:51:57 - INFO - __main__ - Step 10 Global step 10 Train loss 3.55 on epoch=2
06/01/2022 18:51:59 - INFO - __main__ - Step 20 Global step 20 Train loss 1.67 on epoch=4
06/01/2022 18:52:02 - INFO - __main__ - Step 30 Global step 30 Train loss 1.14 on epoch=7
06/01/2022 18:52:04 - INFO - __main__ - Step 40 Global step 40 Train loss 1.02 on epoch=9
06/01/2022 18:52:06 - INFO - __main__ - Step 50 Global step 50 Train loss 0.85 on epoch=12
06/01/2022 18:52:07 - INFO - __main__ - Global step 50 Train loss 1.65 Classification-F1 0.1 on epoch=12
06/01/2022 18:52:07 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 18:52:10 - INFO - __main__ - Step 60 Global step 60 Train loss 0.89 on epoch=14
06/01/2022 18:52:12 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/01/2022 18:52:15 - INFO - __main__ - Step 80 Global step 80 Train loss 0.84 on epoch=19
06/01/2022 18:52:17 - INFO - __main__ - Step 90 Global step 90 Train loss 0.79 on epoch=22
06/01/2022 18:52:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=24
06/01/2022 18:52:21 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.2923109816702494 on epoch=24
06/01/2022 18:52:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.2923109816702494 on epoch=24, global_step=100
06/01/2022 18:52:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=27
06/01/2022 18:52:25 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=29
06/01/2022 18:52:28 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/01/2022 18:52:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/01/2022 18:52:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.79 on epoch=37
06/01/2022 18:52:34 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.2326299536798765 on epoch=37
06/01/2022 18:52:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=39
06/01/2022 18:52:38 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=42
06/01/2022 18:52:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=44
06/01/2022 18:52:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=47
06/01/2022 18:52:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.71 on epoch=49
06/01/2022 18:52:47 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.4412792216272692 on epoch=49
06/01/2022 18:52:47 - INFO - __main__ - Saving model with best Classification-F1: 0.2923109816702494 -> 0.4412792216272692 on epoch=49, global_step=200
06/01/2022 18:52:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.68 on epoch=52
06/01/2022 18:52:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=54
06/01/2022 18:52:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=57
06/01/2022 18:52:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=59
06/01/2022 18:52:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=62
06/01/2022 18:53:00 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.5481072316178699 on epoch=62
06/01/2022 18:53:00 - INFO - __main__ - Saving model with best Classification-F1: 0.4412792216272692 -> 0.5481072316178699 on epoch=62, global_step=250
06/01/2022 18:53:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=64
06/01/2022 18:53:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=67
06/01/2022 18:53:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=69
06/01/2022 18:53:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=72
06/01/2022 18:53:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/01/2022 18:53:13 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.6256754465730623 on epoch=74
06/01/2022 18:53:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5481072316178699 -> 0.6256754465730623 on epoch=74, global_step=300
06/01/2022 18:53:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=77
06/01/2022 18:53:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=79
06/01/2022 18:53:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/01/2022 18:53:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=84
06/01/2022 18:53:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
06/01/2022 18:53:26 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.6117060023310023 on epoch=87
06/01/2022 18:53:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/01/2022 18:53:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.43 on epoch=92
06/01/2022 18:53:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=94
06/01/2022 18:53:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=97
06/01/2022 18:53:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=99
06/01/2022 18:53:39 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.564809070857458 on epoch=99
06/01/2022 18:53:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=102
06/01/2022 18:53:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=104
06/01/2022 18:53:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=107
06/01/2022 18:53:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=109
06/01/2022 18:53:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=112
06/01/2022 18:53:52 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6547812086711517 on epoch=112
06/01/2022 18:53:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6256754465730623 -> 0.6547812086711517 on epoch=112, global_step=450
06/01/2022 18:53:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/01/2022 18:53:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=117
06/01/2022 18:53:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/01/2022 18:54:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=122
06/01/2022 18:54:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=124
06/01/2022 18:54:05 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.7179040791944017 on epoch=124
06/01/2022 18:54:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6547812086711517 -> 0.7179040791944017 on epoch=124, global_step=500
06/01/2022 18:54:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/01/2022 18:54:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=129
06/01/2022 18:54:12 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=132
06/01/2022 18:54:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=134
06/01/2022 18:54:17 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=137
06/01/2022 18:54:18 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.6259549274255156 on epoch=137
06/01/2022 18:54:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=139
06/01/2022 18:54:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=142
06/01/2022 18:54:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.26 on epoch=144
06/01/2022 18:54:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=147
06/01/2022 18:54:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
06/01/2022 18:54:31 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.6943859649122808 on epoch=149
06/01/2022 18:54:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/01/2022 18:54:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=154
06/01/2022 18:54:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/01/2022 18:54:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
06/01/2022 18:54:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/01/2022 18:54:45 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.7064008295625942 on epoch=162
06/01/2022 18:54:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=164
06/01/2022 18:54:49 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/01/2022 18:54:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
06/01/2022 18:54:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
06/01/2022 18:54:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/01/2022 18:54:58 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.7361641814228022 on epoch=174
06/01/2022 18:54:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7179040791944017 -> 0.7361641814228022 on epoch=174, global_step=700
06/01/2022 18:55:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/01/2022 18:55:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/01/2022 18:55:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.09 on epoch=182
06/01/2022 18:55:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/01/2022 18:55:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/01/2022 18:55:11 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.7362985900249527 on epoch=187
06/01/2022 18:55:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7361641814228022 -> 0.7362985900249527 on epoch=187, global_step=750
06/01/2022 18:55:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
06/01/2022 18:55:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/01/2022 18:55:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/01/2022 18:55:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/01/2022 18:55:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/01/2022 18:55:25 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.7512591150661229 on epoch=199
06/01/2022 18:55:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7362985900249527 -> 0.7512591150661229 on epoch=199, global_step=800
06/01/2022 18:55:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/01/2022 18:55:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/01/2022 18:55:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=207
06/01/2022 18:55:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/01/2022 18:55:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.05 on epoch=212
06/01/2022 18:55:38 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.7362985900249527 on epoch=212
06/01/2022 18:55:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/01/2022 18:55:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/01/2022 18:55:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=219
06/01/2022 18:55:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/01/2022 18:55:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/01/2022 18:55:51 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.7492307071731514 on epoch=224
06/01/2022 18:55:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/01/2022 18:55:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/01/2022 18:55:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/01/2022 18:56:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/01/2022 18:56:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 18:56:04 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.7532467532467532 on epoch=237
06/01/2022 18:56:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7512591150661229 -> 0.7532467532467532 on epoch=237, global_step=950
06/01/2022 18:56:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/01/2022 18:56:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 18:56:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/01/2022 18:56:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/01/2022 18:56:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/01/2022 18:56:18 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.7325066699005578 on epoch=249
06/01/2022 18:56:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 18:56:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/01/2022 18:56:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 18:56:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/01/2022 18:56:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=262
06/01/2022 18:56:31 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.7205752327456181 on epoch=262
06/01/2022 18:56:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/01/2022 18:56:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/01/2022 18:56:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/01/2022 18:56:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 18:56:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/01/2022 18:56:44 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.7314102564102565 on epoch=274
06/01/2022 18:56:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/01/2022 18:56:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/01/2022 18:56:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/01/2022 18:56:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/01/2022 18:56:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/01/2022 18:56:58 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6711842239225606 on epoch=287
06/01/2022 18:57:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=289
06/01/2022 18:57:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/01/2022 18:57:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 18:57:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/01/2022 18:57:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 18:57:11 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7525140977443608 on epoch=299
06/01/2022 18:57:13 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 18:57:16 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 18:57:18 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 18:57:21 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/01/2022 18:57:23 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/01/2022 18:57:24 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7355126728110599 on epoch=312
06/01/2022 18:57:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 18:57:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/01/2022 18:57:32 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 18:57:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 18:57:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/01/2022 18:57:38 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.703609022556391 on epoch=324
06/01/2022 18:57:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/01/2022 18:57:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/01/2022 18:57:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/01/2022 18:57:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/01/2022 18:57:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/01/2022 18:57:51 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7676470588235293 on epoch=337
06/01/2022 18:57:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7532467532467532 -> 0.7676470588235293 on epoch=337, global_step=1350
06/01/2022 18:57:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 18:57:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/01/2022 18:57:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=344
06/01/2022 18:58:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 18:58:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=349
06/01/2022 18:58:04 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7190126050420168 on epoch=349
06/01/2022 18:58:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 18:58:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/01/2022 18:58:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 18:58:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/01/2022 18:58:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 18:58:18 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7363479262672811 on epoch=362
06/01/2022 18:58:20 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=364
06/01/2022 18:58:22 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/01/2022 18:58:25 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 18:58:27 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/01/2022 18:58:30 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/01/2022 18:58:31 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.7505954576187842 on epoch=374
06/01/2022 18:58:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/01/2022 18:58:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/01/2022 18:58:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/01/2022 18:58:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/01/2022 18:58:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/01/2022 18:58:44 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7483151213766931 on epoch=387
06/01/2022 18:58:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/01/2022 18:58:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/01/2022 18:58:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/01/2022 18:58:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/01/2022 18:58:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 18:58:57 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7823876728110599 on epoch=399
06/01/2022 18:58:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7676470588235293 -> 0.7823876728110599 on epoch=399, global_step=1600
06/01/2022 18:59:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 18:59:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=404
06/01/2022 18:59:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 18:59:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 18:59:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/01/2022 18:59:10 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7666923624288426 on epoch=412
06/01/2022 18:59:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/01/2022 18:59:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/01/2022 18:59:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 18:59:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 18:59:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 18:59:24 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7192012288786483 on epoch=424
06/01/2022 18:59:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/01/2022 18:59:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 18:59:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 18:59:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 18:59:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 18:59:37 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7654233870967742 on epoch=437
06/01/2022 18:59:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=439
06/01/2022 18:59:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/01/2022 18:59:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/01/2022 18:59:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/01/2022 18:59:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/01/2022 18:59:51 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.765686274509804 on epoch=449
06/01/2022 18:59:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 18:59:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 18:59:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=457
06/01/2022 19:00:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 19:00:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 19:00:04 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.765991568914956 on epoch=462
06/01/2022 19:00:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/01/2022 19:00:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 19:00:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 19:00:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 19:00:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/01/2022 19:00:18 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7805572660098522 on epoch=474
06/01/2022 19:00:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 19:00:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=479
06/01/2022 19:00:25 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 19:00:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/01/2022 19:00:30 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 19:00:31 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6870912720870276 on epoch=487
06/01/2022 19:00:33 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/01/2022 19:00:36 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/01/2022 19:00:38 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 19:00:41 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=497
06/01/2022 19:00:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=499
06/01/2022 19:00:44 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7675408094272193 on epoch=499
06/01/2022 19:00:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/01/2022 19:00:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/01/2022 19:00:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 19:00:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 19:00:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/01/2022 19:00:58 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7495030680148649 on epoch=512
06/01/2022 19:01:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/01/2022 19:01:03 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 19:01:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/01/2022 19:01:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 19:01:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 19:01:11 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7990196078431373 on epoch=524
06/01/2022 19:01:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7823876728110599 -> 0.7990196078431373 on epoch=524, global_step=2100
06/01/2022 19:01:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/01/2022 19:01:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 19:01:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 19:01:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 19:01:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/01/2022 19:01:25 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7484256289699838 on epoch=537
06/01/2022 19:01:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 19:01:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=542
06/01/2022 19:01:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/01/2022 19:01:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 19:01:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 19:01:39 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7677308601669002 on epoch=549
06/01/2022 19:01:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/01/2022 19:01:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/01/2022 19:01:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 19:01:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 19:01:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 19:01:53 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7341991341991342 on epoch=562
06/01/2022 19:01:55 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 19:01:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 19:02:00 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 19:02:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 19:02:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/01/2022 19:02:06 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7353622431208638 on epoch=574
06/01/2022 19:02:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=577
06/01/2022 19:02:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 19:02:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 19:02:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 19:02:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 19:02:20 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7340331114524662 on epoch=587
06/01/2022 19:02:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 19:02:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 19:02:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/01/2022 19:02:30 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 19:02:33 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/01/2022 19:02:34 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.766884115066123 on epoch=599
06/01/2022 19:02:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 19:02:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 19:02:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 19:02:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 19:02:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 19:02:48 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7351704904835835 on epoch=612
06/01/2022 19:02:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 19:02:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 19:02:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/01/2022 19:02:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 19:03:00 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 19:03:01 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7507360270430348 on epoch=624
06/01/2022 19:03:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 19:03:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 19:03:09 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 19:03:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=634
06/01/2022 19:03:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=637
06/01/2022 19:03:15 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.735634115066123 on epoch=637
06/01/2022 19:03:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/01/2022 19:03:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 19:03:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 19:03:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 19:03:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 19:03:29 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7480901451489687 on epoch=649
06/01/2022 19:03:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 19:03:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 19:03:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 19:03:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 19:03:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/01/2022 19:03:42 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7179320003863615 on epoch=662
06/01/2022 19:03:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 19:03:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 19:03:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 19:03:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/01/2022 19:03:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 19:03:56 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7329084455098653 on epoch=674
06/01/2022 19:03:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 19:04:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 19:04:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 19:04:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/01/2022 19:04:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 19:04:10 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.7341991341991342 on epoch=687
06/01/2022 19:04:13 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 19:04:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 19:04:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/01/2022 19:04:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 19:04:23 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 19:04:24 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7518648018648018 on epoch=699
06/01/2022 19:04:26 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 19:04:29 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 19:04:31 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 19:04:34 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 19:04:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=712
06/01/2022 19:04:38 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7161531279178338 on epoch=712
06/01/2022 19:04:40 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 19:04:43 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/01/2022 19:04:45 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 19:04:48 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 19:04:50 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 19:04:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7823319400905608 on epoch=724
06/01/2022 19:04:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 19:04:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 19:04:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/01/2022 19:05:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 19:05:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 19:05:06 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7296037296037297 on epoch=737
06/01/2022 19:05:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 19:05:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 19:05:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 19:05:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 19:05:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 19:05:20 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7496427357557781 on epoch=749
06/01/2022 19:05:20 - INFO - __main__ - save last model!
06/01/2022 19:05:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:05:20 - INFO - __main__ - Printing 3 examples
06/01/2022 19:05:20 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:05:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 19:05:20 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:05:20 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 19:05:20 - INFO - __main__ - Printing 3 examples
06/01/2022 19:05:20 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:05:20 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:05:20 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:05:20 - INFO - __main__ - Printing 3 examples
06/01/2022 19:05:20 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:05:20 - INFO - __main__ - ['others']
06/01/2022 19:05:20 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:05:20 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:05:20 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:05:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:05:27 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 19:05:35 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:05:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:05:35 - INFO - __main__ - Starting training!
06/01/2022 19:07:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/01/2022 19:07:22 - INFO - __main__ - Classification-F1 on test data: 0.3460
06/01/2022 19:07:22 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.7990196078431373, test_performance=0.34600874729893366
06/01/2022 19:07:22 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/01/2022 19:07:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:07:23 - INFO - __main__ - Printing 3 examples
06/01/2022 19:07:23 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:07:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:07:23 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:07:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:07:23 - INFO - __main__ - Printing 3 examples
06/01/2022 19:07:23 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:07:23 - INFO - __main__ - ['others']
06/01/2022 19:07:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:07:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:07:24 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:07:42 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:07:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:07:43 - INFO - __main__ - Starting training!
06/01/2022 19:07:46 - INFO - __main__ - Step 10 Global step 10 Train loss 3.90 on epoch=2
06/01/2022 19:07:49 - INFO - __main__ - Step 20 Global step 20 Train loss 1.98 on epoch=4
06/01/2022 19:07:51 - INFO - __main__ - Step 30 Global step 30 Train loss 1.44 on epoch=7
06/01/2022 19:07:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.06 on epoch=9
06/01/2022 19:07:56 - INFO - __main__ - Step 50 Global step 50 Train loss 0.91 on epoch=12
06/01/2022 19:07:57 - INFO - __main__ - Global step 50 Train loss 1.86 Classification-F1 0.1 on epoch=12
06/01/2022 19:07:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 19:08:00 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=14
06/01/2022 19:08:03 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=17
06/01/2022 19:08:05 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/01/2022 19:08:08 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=22
06/01/2022 19:08:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=24
06/01/2022 19:08:11 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.21107843137254903 on epoch=24
06/01/2022 19:08:11 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.21107843137254903 on epoch=24, global_step=100
06/01/2022 19:08:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/01/2022 19:08:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.82 on epoch=29
06/01/2022 19:08:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.80 on epoch=32
06/01/2022 19:08:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
06/01/2022 19:08:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=37
06/01/2022 19:08:25 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.3569794584500467 on epoch=37
06/01/2022 19:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.21107843137254903 -> 0.3569794584500467 on epoch=37, global_step=150
06/01/2022 19:08:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.85 on epoch=39
06/01/2022 19:08:30 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=42
06/01/2022 19:08:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=44
06/01/2022 19:08:35 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/01/2022 19:08:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=49
06/01/2022 19:08:38 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.5016820857863751 on epoch=49
06/01/2022 19:08:38 - INFO - __main__ - Saving model with best Classification-F1: 0.3569794584500467 -> 0.5016820857863751 on epoch=49, global_step=200
06/01/2022 19:08:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/01/2022 19:08:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=54
06/01/2022 19:08:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=57
06/01/2022 19:08:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.73 on epoch=59
06/01/2022 19:08:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=62
06/01/2022 19:08:52 - INFO - __main__ - Global step 250 Train loss 0.75 Classification-F1 0.5501409651193285 on epoch=62
06/01/2022 19:08:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5016820857863751 -> 0.5501409651193285 on epoch=62, global_step=250
06/01/2022 19:08:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.67 on epoch=64
06/01/2022 19:08:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.67 on epoch=67
06/01/2022 19:09:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.60 on epoch=69
06/01/2022 19:09:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=72
06/01/2022 19:09:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.62 on epoch=74
06/01/2022 19:09:06 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.5254874690358562 on epoch=74
06/01/2022 19:09:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.61 on epoch=77
06/01/2022 19:09:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.50 on epoch=79
06/01/2022 19:09:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=82
06/01/2022 19:09:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.49 on epoch=84
06/01/2022 19:09:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=87
06/01/2022 19:09:19 - INFO - __main__ - Global step 350 Train loss 0.53 Classification-F1 0.5031114718614719 on epoch=87
06/01/2022 19:09:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=89
06/01/2022 19:09:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=92
06/01/2022 19:09:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/01/2022 19:09:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=97
06/01/2022 19:09:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
06/01/2022 19:09:33 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.6015300059417706 on epoch=99
06/01/2022 19:09:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5501409651193285 -> 0.6015300059417706 on epoch=99, global_step=400
06/01/2022 19:09:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=102
06/01/2022 19:09:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=104
06/01/2022 19:09:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=107
06/01/2022 19:09:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=109
06/01/2022 19:09:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=112
06/01/2022 19:09:47 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.5729742621686356 on epoch=112
06/01/2022 19:09:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=114
06/01/2022 19:09:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=117
06/01/2022 19:09:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=119
06/01/2022 19:09:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=122
06/01/2022 19:09:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=124
06/01/2022 19:10:00 - INFO - __main__ - Global step 500 Train loss 0.27 Classification-F1 0.595343137254902 on epoch=124
06/01/2022 19:10:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/01/2022 19:10:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=129
06/01/2022 19:10:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/01/2022 19:10:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/01/2022 19:10:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=137
06/01/2022 19:10:14 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.5818574741724647 on epoch=137
06/01/2022 19:10:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/01/2022 19:10:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=142
06/01/2022 19:10:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/01/2022 19:10:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=147
06/01/2022 19:10:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=149
06/01/2022 19:10:28 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.6155286168521462 on epoch=149
06/01/2022 19:10:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6015300059417706 -> 0.6155286168521462 on epoch=149, global_step=600
06/01/2022 19:10:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
06/01/2022 19:10:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=154
06/01/2022 19:10:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=157
06/01/2022 19:10:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/01/2022 19:10:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=162
06/01/2022 19:10:41 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.6600023815194094 on epoch=162
06/01/2022 19:10:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6155286168521462 -> 0.6600023815194094 on epoch=162, global_step=650
06/01/2022 19:10:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/01/2022 19:10:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=167
06/01/2022 19:10:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=169
06/01/2022 19:10:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=172
06/01/2022 19:10:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/01/2022 19:10:55 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.599626365477311 on epoch=174
06/01/2022 19:10:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/01/2022 19:11:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=179
06/01/2022 19:11:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=182
06/01/2022 19:11:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=184
06/01/2022 19:11:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=187
06/01/2022 19:11:09 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6277201417004048 on epoch=187
06/01/2022 19:11:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/01/2022 19:11:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/01/2022 19:11:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/01/2022 19:11:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=197
06/01/2022 19:11:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/01/2022 19:11:23 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.6421685015435016 on epoch=199
06/01/2022 19:11:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=202
06/01/2022 19:11:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.07 on epoch=204
06/01/2022 19:11:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/01/2022 19:11:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=209
06/01/2022 19:11:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/01/2022 19:11:36 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6299501424501425 on epoch=212
06/01/2022 19:11:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/01/2022 19:11:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/01/2022 19:11:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/01/2022 19:11:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=222
06/01/2022 19:11:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=224
06/01/2022 19:11:50 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6096336584146037 on epoch=224
06/01/2022 19:11:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/01/2022 19:11:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=229
06/01/2022 19:11:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/01/2022 19:12:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/01/2022 19:12:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/01/2022 19:12:04 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6492369983223643 on epoch=237
06/01/2022 19:12:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/01/2022 19:12:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/01/2022 19:12:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/01/2022 19:12:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/01/2022 19:12:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/01/2022 19:12:18 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6290451819685691 on epoch=249
06/01/2022 19:12:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/01/2022 19:12:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/01/2022 19:12:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/01/2022 19:12:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=259
06/01/2022 19:12:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/01/2022 19:12:31 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.6504166666666666 on epoch=262
06/01/2022 19:12:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=264
06/01/2022 19:12:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/01/2022 19:12:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/01/2022 19:12:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 19:12:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/01/2022 19:12:45 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6459401709401709 on epoch=274
06/01/2022 19:12:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=277
06/01/2022 19:12:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 19:12:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/01/2022 19:12:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/01/2022 19:12:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/01/2022 19:12:59 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6170199253790585 on epoch=287
06/01/2022 19:13:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/01/2022 19:13:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/01/2022 19:13:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 19:13:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/01/2022 19:13:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/01/2022 19:13:13 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.5990282879228113 on epoch=299
06/01/2022 19:13:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=302
06/01/2022 19:13:18 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 19:13:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/01/2022 19:13:23 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/01/2022 19:13:26 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/01/2022 19:13:27 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6464433416046318 on epoch=312
06/01/2022 19:13:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/01/2022 19:13:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 19:13:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 19:13:37 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 19:13:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 19:13:41 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6477990034866097 on epoch=324
06/01/2022 19:13:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/01/2022 19:13:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 19:13:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=332
06/01/2022 19:13:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=334
06/01/2022 19:13:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/01/2022 19:13:55 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6500542350499906 on epoch=337
06/01/2022 19:13:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/01/2022 19:14:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/01/2022 19:14:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/01/2022 19:14:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/01/2022 19:14:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/01/2022 19:14:09 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6445161160678402 on epoch=349
06/01/2022 19:14:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=352
06/01/2022 19:14:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/01/2022 19:14:17 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/01/2022 19:14:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/01/2022 19:14:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 19:14:23 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6273167889021548 on epoch=362
06/01/2022 19:14:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/01/2022 19:14:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 19:14:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/01/2022 19:14:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/01/2022 19:14:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/01/2022 19:14:37 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6752809274548405 on epoch=374
06/01/2022 19:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6600023815194094 -> 0.6752809274548405 on epoch=374, global_step=1500
06/01/2022 19:14:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/01/2022 19:14:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 19:14:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 19:14:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/01/2022 19:14:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 19:14:51 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7016619773604659 on epoch=387
06/01/2022 19:14:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6752809274548405 -> 0.7016619773604659 on epoch=387, global_step=1550
06/01/2022 19:14:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/01/2022 19:14:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=392
06/01/2022 19:14:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/01/2022 19:15:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/01/2022 19:15:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 19:15:04 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.663102146263911 on epoch=399
06/01/2022 19:15:07 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 19:15:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/01/2022 19:15:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/01/2022 19:15:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/01/2022 19:15:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 19:15:18 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6325004430267589 on epoch=412
06/01/2022 19:15:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/01/2022 19:15:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/01/2022 19:15:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 19:15:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 19:15:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 19:15:32 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6681226565861453 on epoch=424
06/01/2022 19:15:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 19:15:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/01/2022 19:15:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/01/2022 19:15:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/01/2022 19:15:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/01/2022 19:15:46 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6782407407407407 on epoch=437
06/01/2022 19:15:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/01/2022 19:15:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 19:15:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 19:15:56 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=447
06/01/2022 19:15:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 19:16:00 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6551044721407624 on epoch=449
06/01/2022 19:16:02 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 19:16:05 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/01/2022 19:16:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/01/2022 19:16:10 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/01/2022 19:16:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 19:16:13 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6625225225225225 on epoch=462
06/01/2022 19:16:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 19:16:19 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/01/2022 19:16:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 19:16:24 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/01/2022 19:16:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/01/2022 19:16:27 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6826866452921546 on epoch=474
06/01/2022 19:16:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 19:16:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 19:16:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/01/2022 19:16:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/01/2022 19:16:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/01/2022 19:16:41 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.663400356827081 on epoch=487
06/01/2022 19:16:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/01/2022 19:16:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 19:16:49 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/01/2022 19:16:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 19:16:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/01/2022 19:16:55 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6645891690009338 on epoch=499
06/01/2022 19:16:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/01/2022 19:17:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/01/2022 19:17:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=507
06/01/2022 19:17:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 19:17:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=512
06/01/2022 19:17:09 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6318407585262357 on epoch=512
06/01/2022 19:17:12 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 19:17:14 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=517
06/01/2022 19:17:17 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 19:17:19 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 19:17:22 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/01/2022 19:17:23 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.6479433878814684 on epoch=524
06/01/2022 19:17:26 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/01/2022 19:17:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/01/2022 19:17:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/01/2022 19:17:33 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 19:17:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 19:17:37 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6493212669683258 on epoch=537
06/01/2022 19:17:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=539
06/01/2022 19:17:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/01/2022 19:17:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 19:17:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=547
06/01/2022 19:17:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 19:17:51 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.5984848484848484 on epoch=549
06/01/2022 19:17:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 19:17:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.17 on epoch=554
06/01/2022 19:17:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/01/2022 19:18:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/01/2022 19:18:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/01/2022 19:18:05 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.64940424295263 on epoch=562
06/01/2022 19:18:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 19:18:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 19:18:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 19:18:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=572
06/01/2022 19:18:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 19:18:19 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6805975274725274 on epoch=574
06/01/2022 19:18:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/01/2022 19:18:24 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 19:18:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 19:18:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 19:18:32 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/01/2022 19:18:33 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6478697772815419 on epoch=587
06/01/2022 19:18:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 19:18:38 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/01/2022 19:18:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 19:18:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 19:18:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 19:18:47 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6785287081339714 on epoch=599
06/01/2022 19:18:49 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 19:18:52 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 19:18:54 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 19:18:57 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=609
06/01/2022 19:18:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 19:19:01 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6453030303030304 on epoch=612
06/01/2022 19:19:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 19:19:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 19:19:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 19:19:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 19:19:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 19:19:15 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6444564694564695 on epoch=624
06/01/2022 19:19:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.10 on epoch=627
06/01/2022 19:19:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 19:19:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 19:19:25 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 19:19:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/01/2022 19:19:28 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6479225023342671 on epoch=637
06/01/2022 19:19:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=639
06/01/2022 19:19:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 19:19:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/01/2022 19:19:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 19:19:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 19:19:42 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6520269104709332 on epoch=649
06/01/2022 19:19:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/01/2022 19:19:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 19:19:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 19:19:52 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 19:19:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 19:19:56 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6982352941176471 on epoch=662
06/01/2022 19:19:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=664
06/01/2022 19:20:01 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.17 on epoch=667
06/01/2022 19:20:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 19:20:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/01/2022 19:20:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 19:20:10 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6301778201159005 on epoch=674
06/01/2022 19:20:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 19:20:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 19:20:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/01/2022 19:20:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 19:20:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 19:20:23 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6450239516096293 on epoch=687
06/01/2022 19:20:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 19:20:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/01/2022 19:20:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 19:20:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 19:20:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 19:20:37 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6655812324929972 on epoch=699
06/01/2022 19:20:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/01/2022 19:20:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 19:20:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/01/2022 19:20:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 19:20:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 19:20:51 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6475804114749348 on epoch=712
06/01/2022 19:20:54 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/01/2022 19:20:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/01/2022 19:20:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 19:21:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 19:21:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 19:21:05 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6520269104709332 on epoch=724
06/01/2022 19:21:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 19:21:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/01/2022 19:21:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 19:21:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/01/2022 19:21:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 19:21:19 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6826866452921546 on epoch=737
06/01/2022 19:21:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 19:21:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 19:21:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/01/2022 19:21:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/01/2022 19:21:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/01/2022 19:21:33 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6676587301587301 on epoch=749
06/01/2022 19:21:33 - INFO - __main__ - save last model!
06/01/2022 19:21:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 19:21:33 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 19:21:33 - INFO - __main__ - Printing 3 examples
06/01/2022 19:21:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:21:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:21:33 - INFO - __main__ - Printing 3 examples
06/01/2022 19:21:33 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:21:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:21:33 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:21:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:21:33 - INFO - __main__ - Printing 3 examples
06/01/2022 19:21:33 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:21:33 - INFO - __main__ - ['others']
06/01/2022 19:21:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:21:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:21:33 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:21:35 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:21:40 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 19:21:52 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:21:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:21:53 - INFO - __main__ - Starting training!
06/01/2022 19:23:16 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/01/2022 19:23:16 - INFO - __main__ - Classification-F1 on test data: 0.3918
06/01/2022 19:23:16 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.7016619773604659, test_performance=0.39180521130872425
06/01/2022 19:23:16 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/01/2022 19:23:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:23:17 - INFO - __main__ - Printing 3 examples
06/01/2022 19:23:17 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:23:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:23:17 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:23:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:23:17 - INFO - __main__ - Printing 3 examples
06/01/2022 19:23:17 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:23:17 - INFO - __main__ - ['others']
06/01/2022 19:23:17 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:23:17 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:23:17 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:23:36 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:23:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:23:37 - INFO - __main__ - Starting training!
06/01/2022 19:23:40 - INFO - __main__ - Step 10 Global step 10 Train loss 4.15 on epoch=2
06/01/2022 19:23:42 - INFO - __main__ - Step 20 Global step 20 Train loss 2.50 on epoch=4
06/01/2022 19:23:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.86 on epoch=7
06/01/2022 19:23:47 - INFO - __main__ - Step 40 Global step 40 Train loss 1.34 on epoch=9
06/01/2022 19:23:50 - INFO - __main__ - Step 50 Global step 50 Train loss 1.15 on epoch=12
06/01/2022 19:23:51 - INFO - __main__ - Global step 50 Train loss 2.20 Classification-F1 0.13197586726998492 on epoch=12
06/01/2022 19:23:51 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13197586726998492 on epoch=12, global_step=50
06/01/2022 19:23:53 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=14
06/01/2022 19:23:56 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=17
06/01/2022 19:23:58 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
06/01/2022 19:24:01 - INFO - __main__ - Step 90 Global step 90 Train loss 0.89 on epoch=22
06/01/2022 19:24:03 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/01/2022 19:24:04 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.13034188034188032 on epoch=24
06/01/2022 19:24:07 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/01/2022 19:24:09 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/01/2022 19:24:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
06/01/2022 19:24:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=34
06/01/2022 19:24:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=37
06/01/2022 19:24:18 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.21416083916083917 on epoch=37
06/01/2022 19:24:18 - INFO - __main__ - Saving model with best Classification-F1: 0.13197586726998492 -> 0.21416083916083917 on epoch=37, global_step=150
06/01/2022 19:24:20 - INFO - __main__ - Step 160 Global step 160 Train loss 0.86 on epoch=39
06/01/2022 19:24:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=42
06/01/2022 19:24:25 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=44
06/01/2022 19:24:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/01/2022 19:24:30 - INFO - __main__ - Step 200 Global step 200 Train loss 0.72 on epoch=49
06/01/2022 19:24:31 - INFO - __main__ - Global step 200 Train loss 0.79 Classification-F1 0.3996957403651116 on epoch=49
06/01/2022 19:24:31 - INFO - __main__ - Saving model with best Classification-F1: 0.21416083916083917 -> 0.3996957403651116 on epoch=49, global_step=200
06/01/2022 19:24:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=52
06/01/2022 19:24:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.80 on epoch=54
06/01/2022 19:24:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.84 on epoch=57
06/01/2022 19:24:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.77 on epoch=59
06/01/2022 19:24:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.74 on epoch=62
06/01/2022 19:24:45 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.5049719887955182 on epoch=62
06/01/2022 19:24:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3996957403651116 -> 0.5049719887955182 on epoch=62, global_step=250
06/01/2022 19:24:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=64
06/01/2022 19:24:50 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=67
06/01/2022 19:24:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.78 on epoch=69
06/01/2022 19:24:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=72
06/01/2022 19:24:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.70 on epoch=74
06/01/2022 19:24:58 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.3822138680033417 on epoch=74
06/01/2022 19:25:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=77
06/01/2022 19:25:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=79
06/01/2022 19:25:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=82
06/01/2022 19:25:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=84
06/01/2022 19:25:11 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=87
06/01/2022 19:25:12 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.4971097784441113 on epoch=87
06/01/2022 19:25:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=89
06/01/2022 19:25:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.65 on epoch=92
06/01/2022 19:25:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=94
06/01/2022 19:25:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=97
06/01/2022 19:25:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.59 on epoch=99
06/01/2022 19:25:26 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.519296788482835 on epoch=99
06/01/2022 19:25:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5049719887955182 -> 0.519296788482835 on epoch=99, global_step=400
06/01/2022 19:25:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=102
06/01/2022 19:25:31 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=104
06/01/2022 19:25:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=107
06/01/2022 19:25:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=109
06/01/2022 19:25:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=112
06/01/2022 19:25:39 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.5797647527910685 on epoch=112
06/01/2022 19:25:39 - INFO - __main__ - Saving model with best Classification-F1: 0.519296788482835 -> 0.5797647527910685 on epoch=112, global_step=450
06/01/2022 19:25:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=114
06/01/2022 19:25:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=117
06/01/2022 19:25:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=119
06/01/2022 19:25:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=122
06/01/2022 19:25:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=124
06/01/2022 19:25:53 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.6294952210274791 on epoch=124
06/01/2022 19:25:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5797647527910685 -> 0.6294952210274791 on epoch=124, global_step=500
06/01/2022 19:25:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=127
06/01/2022 19:25:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=129
06/01/2022 19:26:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=132
06/01/2022 19:26:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=134
06/01/2022 19:26:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=137
06/01/2022 19:26:07 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.652162533533992 on epoch=137
06/01/2022 19:26:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6294952210274791 -> 0.652162533533992 on epoch=137, global_step=550
06/01/2022 19:26:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=139
06/01/2022 19:26:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/01/2022 19:26:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.34 on epoch=144
06/01/2022 19:26:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=147
06/01/2022 19:26:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.37 on epoch=149
06/01/2022 19:26:20 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6669323282226507 on epoch=149
06/01/2022 19:26:20 - INFO - __main__ - Saving model with best Classification-F1: 0.652162533533992 -> 0.6669323282226507 on epoch=149, global_step=600
06/01/2022 19:26:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=152
06/01/2022 19:26:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=154
06/01/2022 19:26:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=157
06/01/2022 19:26:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=159
06/01/2022 19:26:33 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=162
06/01/2022 19:26:34 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.6440212639109698 on epoch=162
06/01/2022 19:26:37 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/01/2022 19:26:39 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=167
06/01/2022 19:26:42 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/01/2022 19:26:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=172
06/01/2022 19:26:47 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=174
06/01/2022 19:26:48 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.5918637439301739 on epoch=174
06/01/2022 19:26:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=177
06/01/2022 19:26:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=179
06/01/2022 19:26:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=182
06/01/2022 19:26:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=184
06/01/2022 19:27:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=187
06/01/2022 19:27:01 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.6337787892934952 on epoch=187
06/01/2022 19:27:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=189
06/01/2022 19:27:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/01/2022 19:27:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/01/2022 19:27:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=197
06/01/2022 19:27:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=199
06/01/2022 19:27:15 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.6535539215686275 on epoch=199
06/01/2022 19:27:18 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=202
06/01/2022 19:27:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/01/2022 19:27:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=207
06/01/2022 19:27:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=209
06/01/2022 19:27:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=212
06/01/2022 19:27:29 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6331018518518519 on epoch=212
06/01/2022 19:27:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/01/2022 19:27:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/01/2022 19:27:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=219
06/01/2022 19:27:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=222
06/01/2022 19:27:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=224
06/01/2022 19:27:43 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6486772486772487 on epoch=224
06/01/2022 19:27:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/01/2022 19:27:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/01/2022 19:27:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/01/2022 19:27:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=234
06/01/2022 19:27:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=237
06/01/2022 19:27:57 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.6513888888888889 on epoch=237
06/01/2022 19:28:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/01/2022 19:28:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/01/2022 19:28:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/01/2022 19:28:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=247
06/01/2022 19:28:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=249
06/01/2022 19:28:11 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.6299983138218432 on epoch=249
06/01/2022 19:28:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/01/2022 19:28:17 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=254
06/01/2022 19:28:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=257
06/01/2022 19:28:22 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/01/2022 19:28:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/01/2022 19:28:26 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.6880222401961532 on epoch=262
06/01/2022 19:28:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6669323282226507 -> 0.6880222401961532 on epoch=262, global_step=1050
06/01/2022 19:28:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/01/2022 19:28:31 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=267
06/01/2022 19:28:34 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=269
06/01/2022 19:28:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/01/2022 19:28:39 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/01/2022 19:28:40 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.6486772486772487 on epoch=274
06/01/2022 19:28:42 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/01/2022 19:28:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=279
06/01/2022 19:28:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/01/2022 19:28:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/01/2022 19:28:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/01/2022 19:28:54 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6629119324365504 on epoch=287
06/01/2022 19:28:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/01/2022 19:28:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
06/01/2022 19:29:02 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/01/2022 19:29:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/01/2022 19:29:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/01/2022 19:29:08 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.661794816206581 on epoch=299
06/01/2022 19:29:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=302
06/01/2022 19:29:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/01/2022 19:29:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/01/2022 19:29:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/01/2022 19:29:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/01/2022 19:29:22 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6793451758969 on epoch=312
06/01/2022 19:29:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/01/2022 19:29:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/01/2022 19:29:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/01/2022 19:29:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/01/2022 19:29:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 19:29:36 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6820553539019963 on epoch=324
06/01/2022 19:29:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/01/2022 19:29:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 19:29:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/01/2022 19:29:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=334
06/01/2022 19:29:49 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=337
06/01/2022 19:29:50 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6680059523809523 on epoch=337
06/01/2022 19:29:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/01/2022 19:29:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=342
06/01/2022 19:29:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/01/2022 19:30:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/01/2022 19:30:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/01/2022 19:30:04 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6413116970926301 on epoch=349
06/01/2022 19:30:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/01/2022 19:30:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/01/2022 19:30:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/01/2022 19:30:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/01/2022 19:30:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 19:30:19 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6350188481028303 on epoch=362
06/01/2022 19:30:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/01/2022 19:30:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/01/2022 19:30:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/01/2022 19:30:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/01/2022 19:30:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/01/2022 19:30:33 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6572916666666666 on epoch=374
06/01/2022 19:30:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/01/2022 19:30:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/01/2022 19:30:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 19:30:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 19:30:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/01/2022 19:30:47 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6525862068965518 on epoch=387
06/01/2022 19:30:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 19:30:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 19:30:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 19:30:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=397
06/01/2022 19:31:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/01/2022 19:31:01 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6675558312655087 on epoch=399
06/01/2022 19:31:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 19:31:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/01/2022 19:31:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/01/2022 19:31:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/01/2022 19:31:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/01/2022 19:31:15 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6974316801619433 on epoch=412
06/01/2022 19:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6880222401961532 -> 0.6974316801619433 on epoch=412, global_step=1650
06/01/2022 19:31:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/01/2022 19:31:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/01/2022 19:31:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 19:31:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/01/2022 19:31:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 19:31:30 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7141423724915187 on epoch=424
06/01/2022 19:31:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6974316801619433 -> 0.7141423724915187 on epoch=424, global_step=1700
06/01/2022 19:31:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 19:31:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 19:31:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 19:31:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/01/2022 19:31:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/01/2022 19:31:44 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6650167361374258 on epoch=437
06/01/2022 19:31:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 19:31:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/01/2022 19:31:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/01/2022 19:31:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/01/2022 19:31:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/01/2022 19:31:59 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6992831541218638 on epoch=449
06/01/2022 19:32:01 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/01/2022 19:32:04 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/01/2022 19:32:07 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=457
06/01/2022 19:32:09 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 19:32:12 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 19:32:13 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.697303401085381 on epoch=462
06/01/2022 19:32:16 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 19:32:18 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/01/2022 19:32:21 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=469
06/01/2022 19:32:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=472
06/01/2022 19:32:26 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/01/2022 19:32:27 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.72956146560151 on epoch=474
06/01/2022 19:32:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7141423724915187 -> 0.72956146560151 on epoch=474, global_step=1900
06/01/2022 19:32:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/01/2022 19:32:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/01/2022 19:32:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 19:32:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/01/2022 19:32:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 19:32:42 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6983981092436975 on epoch=487
06/01/2022 19:32:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 19:32:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 19:32:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/01/2022 19:32:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/01/2022 19:32:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/01/2022 19:32:56 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7110410830999067 on epoch=499
06/01/2022 19:32:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/01/2022 19:33:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/01/2022 19:33:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 19:33:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/01/2022 19:33:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 19:33:10 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.6650199647865183 on epoch=512
06/01/2022 19:33:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=514
06/01/2022 19:33:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 19:33:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=519
06/01/2022 19:33:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 19:33:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/01/2022 19:33:25 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6383197982035191 on epoch=524
06/01/2022 19:33:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 19:33:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 19:33:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=532
06/01/2022 19:33:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 19:33:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/01/2022 19:33:39 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6936362358563497 on epoch=537
06/01/2022 19:33:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 19:33:44 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 19:33:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=544
06/01/2022 19:33:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 19:33:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/01/2022 19:33:54 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6818447191431063 on epoch=549
06/01/2022 19:33:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=552
06/01/2022 19:33:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/01/2022 19:34:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/01/2022 19:34:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/01/2022 19:34:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 19:34:08 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6583139083139083 on epoch=562
06/01/2022 19:34:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 19:34:13 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/01/2022 19:34:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 19:34:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/01/2022 19:34:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/01/2022 19:34:22 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5859414975268634 on epoch=574
06/01/2022 19:34:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/01/2022 19:34:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 19:34:30 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/01/2022 19:34:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/01/2022 19:34:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 19:34:37 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6 on epoch=587
06/01/2022 19:34:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 19:34:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=592
06/01/2022 19:34:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=594
06/01/2022 19:34:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/01/2022 19:34:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 19:34:51 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6357142857142858 on epoch=599
06/01/2022 19:34:54 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/01/2022 19:34:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=604
06/01/2022 19:34:59 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 19:35:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 19:35:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 19:35:05 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6620209551244034 on epoch=612
06/01/2022 19:35:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 19:35:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 19:35:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 19:35:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/01/2022 19:35:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/01/2022 19:35:19 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6770242707742707 on epoch=624
06/01/2022 19:35:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 19:35:25 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/01/2022 19:35:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=632
06/01/2022 19:35:30 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/01/2022 19:35:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=637
06/01/2022 19:35:34 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6625974107591754 on epoch=637
06/01/2022 19:35:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/01/2022 19:35:39 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 19:35:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/01/2022 19:35:44 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 19:35:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 19:35:48 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6679929266136163 on epoch=649
06/01/2022 19:35:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/01/2022 19:35:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 19:35:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/01/2022 19:35:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/01/2022 19:36:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 19:36:02 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6669679782583009 on epoch=662
06/01/2022 19:36:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=664
06/01/2022 19:36:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 19:36:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/01/2022 19:36:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/01/2022 19:36:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/01/2022 19:36:17 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6848251211154437 on epoch=674
06/01/2022 19:36:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 19:36:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 19:36:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/01/2022 19:36:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 19:36:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 19:36:31 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6599017705554209 on epoch=687
06/01/2022 19:36:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 19:36:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/01/2022 19:36:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 19:36:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/01/2022 19:36:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 19:36:45 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6840065960228714 on epoch=699
06/01/2022 19:36:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/01/2022 19:36:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 19:36:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 19:36:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 19:36:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 19:36:59 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6848251211154437 on epoch=712
06/01/2022 19:37:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 19:37:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/01/2022 19:37:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/01/2022 19:37:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 19:37:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=724
06/01/2022 19:37:13 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7309027777777777 on epoch=724
06/01/2022 19:37:13 - INFO - __main__ - Saving model with best Classification-F1: 0.72956146560151 -> 0.7309027777777777 on epoch=724, global_step=2900
06/01/2022 19:37:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/01/2022 19:37:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 19:37:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=732
06/01/2022 19:37:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 19:37:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=737
06/01/2022 19:37:27 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6955616068519295 on epoch=737
06/01/2022 19:37:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 19:37:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=742
06/01/2022 19:37:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 19:37:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/01/2022 19:37:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 19:37:41 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6955616068519295 on epoch=749
06/01/2022 19:37:41 - INFO - __main__ - save last model!
06/01/2022 19:37:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 19:37:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 19:37:41 - INFO - __main__ - Printing 3 examples
06/01/2022 19:37:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:37:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:37:41 - INFO - __main__ - Printing 3 examples
06/01/2022 19:37:41 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:37:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:37:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:37:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:37:41 - INFO - __main__ - Printing 3 examples
06/01/2022 19:37:41 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:37:41 - INFO - __main__ - ['others']
06/01/2022 19:37:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:37:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:37:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:37:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:37:49 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 19:37:57 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:37:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:37:58 - INFO - __main__ - Starting training!
06/01/2022 19:39:25 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/01/2022 19:39:25 - INFO - __main__ - Classification-F1 on test data: 0.4332
06/01/2022 19:39:25 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.7309027777777777, test_performance=0.43322957542917706
06/01/2022 19:39:25 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/01/2022 19:39:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:39:26 - INFO - __main__ - Printing 3 examples
06/01/2022 19:39:26 - INFO - __main__ -  [emo] how cause yes am listening
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:39:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:39:26 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:39:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:39:26 - INFO - __main__ - Printing 3 examples
06/01/2022 19:39:26 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/01/2022 19:39:26 - INFO - __main__ - ['others']
06/01/2022 19:39:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:39:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:39:26 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:39:45 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:39:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:39:46 - INFO - __main__ - Starting training!
06/01/2022 19:39:49 - INFO - __main__ - Step 10 Global step 10 Train loss 4.11 on epoch=2
06/01/2022 19:39:51 - INFO - __main__ - Step 20 Global step 20 Train loss 2.87 on epoch=4
06/01/2022 19:39:54 - INFO - __main__ - Step 30 Global step 30 Train loss 2.14 on epoch=7
06/01/2022 19:39:57 - INFO - __main__ - Step 40 Global step 40 Train loss 1.59 on epoch=9
06/01/2022 19:39:59 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=12
06/01/2022 19:40:00 - INFO - __main__ - Global step 50 Train loss 2.42 Classification-F1 0.2734375 on epoch=12
06/01/2022 19:40:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2734375 on epoch=12, global_step=50
06/01/2022 19:40:03 - INFO - __main__ - Step 60 Global step 60 Train loss 1.22 on epoch=14
06/01/2022 19:40:06 - INFO - __main__ - Step 70 Global step 70 Train loss 1.10 on epoch=17
06/01/2022 19:40:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/01/2022 19:40:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/01/2022 19:40:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=24
06/01/2022 19:40:15 - INFO - __main__ - Global step 100 Train loss 1.03 Classification-F1 0.13130252100840337 on epoch=24
06/01/2022 19:40:18 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/01/2022 19:40:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.94 on epoch=29
06/01/2022 19:40:23 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/01/2022 19:40:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=34
06/01/2022 19:40:28 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=37
06/01/2022 19:40:29 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.15531756180733164 on epoch=37
06/01/2022 19:40:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=39
06/01/2022 19:40:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.91 on epoch=42
06/01/2022 19:40:36 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=44
06/01/2022 19:40:39 - INFO - __main__ - Step 190 Global step 190 Train loss 0.88 on epoch=47
06/01/2022 19:40:41 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=49
06/01/2022 19:40:42 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.1831081081081081 on epoch=49
06/01/2022 19:40:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=52
06/01/2022 19:40:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=54
06/01/2022 19:40:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.86 on epoch=57
06/01/2022 19:40:52 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=59
06/01/2022 19:40:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=62
06/01/2022 19:40:56 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.3581729079831547 on epoch=62
06/01/2022 19:40:56 - INFO - __main__ - Saving model with best Classification-F1: 0.2734375 -> 0.3581729079831547 on epoch=62, global_step=250
06/01/2022 19:40:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.83 on epoch=64
06/01/2022 19:41:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.86 on epoch=67
06/01/2022 19:41:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=69
06/01/2022 19:41:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=72
06/01/2022 19:41:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.73 on epoch=74
06/01/2022 19:41:09 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.38900634249471455 on epoch=74
06/01/2022 19:41:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3581729079831547 -> 0.38900634249471455 on epoch=74, global_step=300
06/01/2022 19:41:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.76 on epoch=77
06/01/2022 19:41:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.82 on epoch=79
06/01/2022 19:41:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.73 on epoch=82
06/01/2022 19:41:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.71 on epoch=84
06/01/2022 19:41:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.73 on epoch=87
06/01/2022 19:41:23 - INFO - __main__ - Global step 350 Train loss 0.75 Classification-F1 0.4716173361522199 on epoch=87
06/01/2022 19:41:23 - INFO - __main__ - Saving model with best Classification-F1: 0.38900634249471455 -> 0.4716173361522199 on epoch=87, global_step=350
06/01/2022 19:41:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.69 on epoch=89
06/01/2022 19:41:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.67 on epoch=92
06/01/2022 19:41:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=94
06/01/2022 19:41:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.73 on epoch=97
06/01/2022 19:41:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=99
06/01/2022 19:41:37 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.4706164074825333 on epoch=99
06/01/2022 19:41:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.66 on epoch=102
06/01/2022 19:41:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.75 on epoch=104
06/01/2022 19:41:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.66 on epoch=107
06/01/2022 19:41:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=109
06/01/2022 19:41:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=112
06/01/2022 19:41:50 - INFO - __main__ - Global step 450 Train loss 0.64 Classification-F1 0.577391862170088 on epoch=112
06/01/2022 19:41:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4716173361522199 -> 0.577391862170088 on epoch=112, global_step=450
06/01/2022 19:41:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=114
06/01/2022 19:41:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.46 on epoch=117
06/01/2022 19:41:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.54 on epoch=119
06/01/2022 19:42:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.54 on epoch=122
06/01/2022 19:42:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=124
06/01/2022 19:42:03 - INFO - __main__ - Global step 500 Train loss 0.51 Classification-F1 0.5608400608400608 on epoch=124
06/01/2022 19:42:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=127
06/01/2022 19:42:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=129
06/01/2022 19:42:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.60 on epoch=132
06/01/2022 19:42:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.49 on epoch=134
06/01/2022 19:42:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.50 on epoch=137
06/01/2022 19:42:17 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.5510999417249417 on epoch=137
06/01/2022 19:42:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=139
06/01/2022 19:42:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.44 on epoch=142
06/01/2022 19:42:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=144
06/01/2022 19:42:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=147
06/01/2022 19:42:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=149
06/01/2022 19:42:31 - INFO - __main__ - Global step 600 Train loss 0.42 Classification-F1 0.5604285081567875 on epoch=149
06/01/2022 19:42:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=152
06/01/2022 19:42:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=154
06/01/2022 19:42:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.32 on epoch=157
06/01/2022 19:42:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=159
06/01/2022 19:42:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=162
06/01/2022 19:42:45 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.606324068088774 on epoch=162
06/01/2022 19:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.577391862170088 -> 0.606324068088774 on epoch=162, global_step=650
06/01/2022 19:42:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=164
06/01/2022 19:42:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=167
06/01/2022 19:42:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=169
06/01/2022 19:42:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=172
06/01/2022 19:42:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=174
06/01/2022 19:42:58 - INFO - __main__ - Global step 700 Train loss 0.32 Classification-F1 0.5577191913398809 on epoch=174
06/01/2022 19:43:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.27 on epoch=177
06/01/2022 19:43:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.42 on epoch=179
06/01/2022 19:43:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=182
06/01/2022 19:43:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=184
06/01/2022 19:43:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/01/2022 19:43:12 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.519068100358423 on epoch=187
06/01/2022 19:43:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=189
06/01/2022 19:43:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=192
06/01/2022 19:43:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=194
06/01/2022 19:43:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=197
06/01/2022 19:43:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=199
06/01/2022 19:43:25 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.5378689937513467 on epoch=199
06/01/2022 19:43:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=202
06/01/2022 19:43:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=204
06/01/2022 19:43:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=207
06/01/2022 19:43:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=209
06/01/2022 19:43:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=212
06/01/2022 19:43:39 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.5467934589954224 on epoch=212
06/01/2022 19:43:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=214
06/01/2022 19:43:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=217
06/01/2022 19:43:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=219
06/01/2022 19:43:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=222
06/01/2022 19:43:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=224
06/01/2022 19:43:53 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.5673092209856916 on epoch=224
06/01/2022 19:43:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=227
06/01/2022 19:43:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
06/01/2022 19:44:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=232
06/01/2022 19:44:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=234
06/01/2022 19:44:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=237
06/01/2022 19:44:06 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.5697245564892623 on epoch=237
06/01/2022 19:44:09 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=239
06/01/2022 19:44:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=242
06/01/2022 19:44:14 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/01/2022 19:44:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.20 on epoch=247
06/01/2022 19:44:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=249
06/01/2022 19:44:20 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.5889460511679644 on epoch=249
06/01/2022 19:44:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=252
06/01/2022 19:44:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=254
06/01/2022 19:44:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.22 on epoch=257
06/01/2022 19:44:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=259
06/01/2022 19:44:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=262
06/01/2022 19:44:34 - INFO - __main__ - Global step 1050 Train loss 0.18 Classification-F1 0.622384139625519 on epoch=262
06/01/2022 19:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.606324068088774 -> 0.622384139625519 on epoch=262, global_step=1050
06/01/2022 19:44:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/01/2022 19:44:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=267
06/01/2022 19:44:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/01/2022 19:44:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=272
06/01/2022 19:44:46 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=274
06/01/2022 19:44:47 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.5880556225383812 on epoch=274
06/01/2022 19:44:50 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/01/2022 19:44:52 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=279
06/01/2022 19:44:55 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/01/2022 19:44:57 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/01/2022 19:45:00 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=287
06/01/2022 19:45:01 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6209059448770238 on epoch=287
06/01/2022 19:45:03 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/01/2022 19:45:06 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=292
06/01/2022 19:45:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/01/2022 19:45:11 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/01/2022 19:45:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=299
06/01/2022 19:45:14 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.6369659982563208 on epoch=299
06/01/2022 19:45:14 - INFO - __main__ - Saving model with best Classification-F1: 0.622384139625519 -> 0.6369659982563208 on epoch=299, global_step=1200
06/01/2022 19:45:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=302
06/01/2022 19:45:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=304
06/01/2022 19:45:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=307
06/01/2022 19:45:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/01/2022 19:45:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/01/2022 19:45:28 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.6380412670735252 on epoch=312
06/01/2022 19:45:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6369659982563208 -> 0.6380412670735252 on epoch=312, global_step=1250
06/01/2022 19:45:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/01/2022 19:45:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=317
06/01/2022 19:45:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
06/01/2022 19:45:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=322
06/01/2022 19:45:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/01/2022 19:45:42 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.653136200716846 on epoch=324
06/01/2022 19:45:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6380412670735252 -> 0.653136200716846 on epoch=324, global_step=1300
06/01/2022 19:45:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/01/2022 19:45:47 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=329
06/01/2022 19:45:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/01/2022 19:45:52 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/01/2022 19:45:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=337
06/01/2022 19:45:55 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.636904761904762 on epoch=337
06/01/2022 19:45:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/01/2022 19:46:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=342
06/01/2022 19:46:04 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=344
06/01/2022 19:46:07 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/01/2022 19:46:10 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/01/2022 19:46:11 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6197492163009404 on epoch=349
06/01/2022 19:46:14 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/01/2022 19:46:16 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/01/2022 19:46:19 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/01/2022 19:46:22 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=359
06/01/2022 19:46:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=362
06/01/2022 19:46:26 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6548888384754992 on epoch=362
06/01/2022 19:46:26 - INFO - __main__ - Saving model with best Classification-F1: 0.653136200716846 -> 0.6548888384754992 on epoch=362, global_step=1450
06/01/2022 19:46:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/01/2022 19:46:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/01/2022 19:46:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/01/2022 19:46:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/01/2022 19:46:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=374
06/01/2022 19:46:42 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6343915343915343 on epoch=374
06/01/2022 19:46:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/01/2022 19:46:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/01/2022 19:46:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=382
06/01/2022 19:46:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=384
06/01/2022 19:46:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/01/2022 19:46:57 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6187897005444647 on epoch=387
06/01/2022 19:47:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=389
06/01/2022 19:47:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=392
06/01/2022 19:47:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/01/2022 19:47:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/01/2022 19:47:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/01/2022 19:47:12 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6354322262831719 on epoch=399
06/01/2022 19:47:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/01/2022 19:47:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/01/2022 19:47:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=407
06/01/2022 19:47:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=409
06/01/2022 19:47:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/01/2022 19:47:26 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5880601506679093 on epoch=412
06/01/2022 19:47:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=414
06/01/2022 19:47:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/01/2022 19:47:34 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/01/2022 19:47:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=422
06/01/2022 19:47:39 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/01/2022 19:47:40 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6025078369905955 on epoch=424
06/01/2022 19:47:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/01/2022 19:47:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/01/2022 19:47:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 19:47:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=434
06/01/2022 19:47:53 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=437
06/01/2022 19:47:54 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6423814760508308 on epoch=437
06/01/2022 19:47:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=439
06/01/2022 19:48:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/01/2022 19:48:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/01/2022 19:48:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=447
06/01/2022 19:48:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/01/2022 19:48:08 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6197492163009404 on epoch=449
06/01/2022 19:48:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/01/2022 19:48:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/01/2022 19:48:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=457
06/01/2022 19:48:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/01/2022 19:48:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.17 on epoch=462
06/01/2022 19:48:23 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6783245349421819 on epoch=462
06/01/2022 19:48:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6548888384754992 -> 0.6783245349421819 on epoch=462, global_step=1850
06/01/2022 19:48:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 19:48:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/01/2022 19:48:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 19:48:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/01/2022 19:48:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/01/2022 19:48:37 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6490147783251231 on epoch=474
06/01/2022 19:48:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=477
06/01/2022 19:48:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=479
06/01/2022 19:48:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=482
06/01/2022 19:48:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=484
06/01/2022 19:48:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=487
06/01/2022 19:48:50 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6679098453292002 on epoch=487
06/01/2022 19:48:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/01/2022 19:48:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/01/2022 19:48:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/01/2022 19:49:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/01/2022 19:49:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/01/2022 19:49:04 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6516981411134637 on epoch=499
06/01/2022 19:49:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=502
06/01/2022 19:49:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=504
06/01/2022 19:49:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=507
06/01/2022 19:49:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/01/2022 19:49:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/01/2022 19:49:18 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.648003275923187 on epoch=512
06/01/2022 19:49:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/01/2022 19:49:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/01/2022 19:49:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=519
06/01/2022 19:49:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/01/2022 19:49:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/01/2022 19:49:32 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6669323282226507 on epoch=524
06/01/2022 19:49:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/01/2022 19:49:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/01/2022 19:49:40 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.15 on epoch=532
06/01/2022 19:49:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/01/2022 19:49:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/01/2022 19:49:46 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6322847774460677 on epoch=537
06/01/2022 19:49:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 19:49:51 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/01/2022 19:49:54 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/01/2022 19:49:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/01/2022 19:49:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/01/2022 19:50:00 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.618739478114478 on epoch=549
06/01/2022 19:50:03 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/01/2022 19:50:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 19:50:08 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/01/2022 19:50:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/01/2022 19:50:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 19:50:14 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6375095492742552 on epoch=562
06/01/2022 19:50:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 19:50:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 19:50:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 19:50:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=572
06/01/2022 19:50:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=574
06/01/2022 19:50:28 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6375095492742552 on epoch=574
06/01/2022 19:50:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/01/2022 19:50:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 19:50:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/01/2022 19:50:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 19:50:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 19:50:42 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6367288961038962 on epoch=587
06/01/2022 19:50:44 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 19:50:47 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/01/2022 19:50:49 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=594
06/01/2022 19:50:52 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/01/2022 19:50:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 19:50:56 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6856768792252662 on epoch=599
06/01/2022 19:50:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6783245349421819 -> 0.6856768792252662 on epoch=599, global_step=2400
06/01/2022 19:50:58 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/01/2022 19:51:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/01/2022 19:51:03 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/01/2022 19:51:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=609
06/01/2022 19:51:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/01/2022 19:51:10 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6821058112058953 on epoch=612
06/01/2022 19:51:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/01/2022 19:51:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=617
06/01/2022 19:51:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/01/2022 19:51:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=622
06/01/2022 19:51:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=624
06/01/2022 19:51:24 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6846783205619413 on epoch=624
06/01/2022 19:51:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/01/2022 19:51:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 19:51:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 19:51:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=634
06/01/2022 19:51:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/01/2022 19:51:38 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6524681103101571 on epoch=637
06/01/2022 19:51:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 19:51:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 19:51:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/01/2022 19:51:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/01/2022 19:51:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/01/2022 19:51:51 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6523163875777891 on epoch=649
06/01/2022 19:51:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 19:51:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 19:51:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 19:52:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 19:52:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=662
06/01/2022 19:52:05 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6711805555555556 on epoch=662
06/01/2022 19:52:08 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/01/2022 19:52:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/01/2022 19:52:13 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/01/2022 19:52:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 19:52:18 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 19:52:19 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6490232812286556 on epoch=674
06/01/2022 19:52:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/01/2022 19:52:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/01/2022 19:52:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=682
06/01/2022 19:52:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=684
06/01/2022 19:52:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/01/2022 19:52:33 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6344400434917676 on epoch=687
06/01/2022 19:52:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 19:52:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/01/2022 19:52:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=694
06/01/2022 19:52:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 19:52:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/01/2022 19:52:48 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6523163875777891 on epoch=699
06/01/2022 19:52:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 19:52:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/01/2022 19:52:55 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/01/2022 19:52:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=709
06/01/2022 19:53:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 19:53:02 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6344400434917676 on epoch=712
06/01/2022 19:53:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 19:53:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/01/2022 19:53:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/01/2022 19:53:12 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 19:53:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 19:53:16 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6708369659982563 on epoch=724
06/01/2022 19:53:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 19:53:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 19:53:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=732
06/01/2022 19:53:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=734
06/01/2022 19:53:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 19:53:30 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6688460061443933 on epoch=737
06/01/2022 19:53:33 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/01/2022 19:53:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=742
06/01/2022 19:53:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 19:53:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 19:53:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=749
06/01/2022 19:53:45 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6348164627363737 on epoch=749
06/01/2022 19:53:45 - INFO - __main__ - save last model!
06/01/2022 19:53:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 19:53:45 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 19:53:45 - INFO - __main__ - Printing 3 examples
06/01/2022 19:53:45 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:53:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:53:45 - INFO - __main__ - Printing 3 examples
06/01/2022 19:53:45 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:53:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:53:45 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:53:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:53:45 - INFO - __main__ - Printing 3 examples
06/01/2022 19:53:45 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 19:53:45 - INFO - __main__ - ['others']
06/01/2022 19:53:45 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:53:45 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:53:45 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:53:47 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:53:52 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 19:54:02 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:54:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:54:03 - INFO - __main__ - Starting training!
06/01/2022 19:55:27 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/01/2022 19:55:27 - INFO - __main__ - Classification-F1 on test data: 0.2815
06/01/2022 19:55:28 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.6856768792252662, test_performance=0.2814829369595326
06/01/2022 19:55:28 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/01/2022 19:55:29 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:55:29 - INFO - __main__ - Printing 3 examples
06/01/2022 19:55:29 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:55:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:55:29 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 19:55:29 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 19:55:29 - INFO - __main__ - Printing 3 examples
06/01/2022 19:55:29 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 19:55:29 - INFO - __main__ - ['others']
06/01/2022 19:55:29 - INFO - __main__ - Tokenizing Input ...
06/01/2022 19:55:29 - INFO - __main__ - Tokenizing Output ...
06/01/2022 19:55:29 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 19:55:44 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 19:55:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 19:55:45 - INFO - __main__ - Starting training!
06/01/2022 19:55:48 - INFO - __main__ - Step 10 Global step 10 Train loss 3.65 on epoch=2
06/01/2022 19:55:51 - INFO - __main__ - Step 20 Global step 20 Train loss 1.81 on epoch=4
06/01/2022 19:55:53 - INFO - __main__ - Step 30 Global step 30 Train loss 1.29 on epoch=7
06/01/2022 19:55:56 - INFO - __main__ - Step 40 Global step 40 Train loss 1.08 on epoch=9
06/01/2022 19:55:58 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=12
06/01/2022 19:55:59 - INFO - __main__ - Global step 50 Train loss 1.76 Classification-F1 0.1 on epoch=12
06/01/2022 19:55:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 19:56:02 - INFO - __main__ - Step 60 Global step 60 Train loss 0.96 on epoch=14
06/01/2022 19:56:04 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=17
06/01/2022 19:56:07 - INFO - __main__ - Step 80 Global step 80 Train loss 0.89 on epoch=19
06/01/2022 19:56:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.83 on epoch=22
06/01/2022 19:56:12 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=24
06/01/2022 19:56:13 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.24009264024704066 on epoch=24
06/01/2022 19:56:13 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.24009264024704066 on epoch=24, global_step=100
06/01/2022 19:56:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
06/01/2022 19:56:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=29
06/01/2022 19:56:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=32
06/01/2022 19:56:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.72 on epoch=34
06/01/2022 19:56:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.68 on epoch=37
06/01/2022 19:56:26 - INFO - __main__ - Global step 150 Train loss 0.76 Classification-F1 0.4201002506265664 on epoch=37
06/01/2022 19:56:26 - INFO - __main__ - Saving model with best Classification-F1: 0.24009264024704066 -> 0.4201002506265664 on epoch=37, global_step=150
06/01/2022 19:56:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.68 on epoch=39
06/01/2022 19:56:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.69 on epoch=42
06/01/2022 19:56:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.55 on epoch=44
06/01/2022 19:56:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=47
06/01/2022 19:56:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.57 on epoch=49
06/01/2022 19:56:39 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.47916666666666674 on epoch=49
06/01/2022 19:56:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4201002506265664 -> 0.47916666666666674 on epoch=49, global_step=200
06/01/2022 19:56:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=52
06/01/2022 19:56:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.48 on epoch=54
06/01/2022 19:56:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.45 on epoch=57
06/01/2022 19:56:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/01/2022 19:56:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=62
06/01/2022 19:56:53 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.6784552845528454 on epoch=62
06/01/2022 19:56:53 - INFO - __main__ - Saving model with best Classification-F1: 0.47916666666666674 -> 0.6784552845528454 on epoch=62, global_step=250
06/01/2022 19:56:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/01/2022 19:56:58 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/01/2022 19:57:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=69
06/01/2022 19:57:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.30 on epoch=72
06/01/2022 19:57:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=74
06/01/2022 19:57:06 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.589766696152145 on epoch=74
06/01/2022 19:57:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.24 on epoch=77
06/01/2022 19:57:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.32 on epoch=79
06/01/2022 19:57:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.28 on epoch=82
06/01/2022 19:57:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.29 on epoch=84
06/01/2022 19:57:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=87
06/01/2022 19:57:19 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.6868453333970574 on epoch=87
06/01/2022 19:57:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6784552845528454 -> 0.6868453333970574 on epoch=87, global_step=350
06/01/2022 19:57:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/01/2022 19:57:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/01/2022 19:57:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.16 on epoch=94
06/01/2022 19:57:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.15 on epoch=97
06/01/2022 19:57:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/01/2022 19:57:33 - INFO - __main__ - Global step 400 Train loss 0.19 Classification-F1 0.6257810816634346 on epoch=99
06/01/2022 19:57:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.09 on epoch=102
06/01/2022 19:57:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/01/2022 19:57:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.11 on epoch=107
06/01/2022 19:57:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=109
06/01/2022 19:57:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/01/2022 19:57:46 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.7055294795783926 on epoch=112
06/01/2022 19:57:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6868453333970574 -> 0.7055294795783926 on epoch=112, global_step=450
06/01/2022 19:57:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.16 on epoch=114
06/01/2022 19:57:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.10 on epoch=117
06/01/2022 19:57:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.16 on epoch=119
06/01/2022 19:57:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.06 on epoch=122
06/01/2022 19:57:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/01/2022 19:58:00 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.699329017240732 on epoch=124
06/01/2022 19:58:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/01/2022 19:58:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/01/2022 19:58:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/01/2022 19:58:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/01/2022 19:58:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=137
06/01/2022 19:58:13 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.6604710701484895 on epoch=137
06/01/2022 19:58:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=139
06/01/2022 19:58:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/01/2022 19:58:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=144
06/01/2022 19:58:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/01/2022 19:58:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/01/2022 19:58:27 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6472578569352763 on epoch=149
06/01/2022 19:58:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/01/2022 19:58:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/01/2022 19:58:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.08 on epoch=157
06/01/2022 19:58:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.12 on epoch=159
06/01/2022 19:58:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=162
06/01/2022 19:58:40 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7186238018780714 on epoch=162
06/01/2022 19:58:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7055294795783926 -> 0.7186238018780714 on epoch=162, global_step=650
06/01/2022 19:58:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/01/2022 19:58:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/01/2022 19:58:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.10 on epoch=169
06/01/2022 19:58:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/01/2022 19:58:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/01/2022 19:58:54 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.5942857142857143 on epoch=174
06/01/2022 19:58:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/01/2022 19:58:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/01/2022 19:59:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/01/2022 19:59:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/01/2022 19:59:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/01/2022 19:59:07 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.7504063196105932 on epoch=187
06/01/2022 19:59:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7186238018780714 -> 0.7504063196105932 on epoch=187, global_step=750
06/01/2022 19:59:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=189
06/01/2022 19:59:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.03 on epoch=192
06/01/2022 19:59:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/01/2022 19:59:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/01/2022 19:59:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/01/2022 19:59:21 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6703313138095747 on epoch=199
06/01/2022 19:59:23 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/01/2022 19:59:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.05 on epoch=204
06/01/2022 19:59:28 - INFO - __main__ - Step 830 Global step 830 Train loss 0.03 on epoch=207
06/01/2022 19:59:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/01/2022 19:59:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/01/2022 19:59:34 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7269609201773836 on epoch=212
06/01/2022 19:59:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/01/2022 19:59:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/01/2022 19:59:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=219
06/01/2022 19:59:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/01/2022 19:59:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/01/2022 19:59:48 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7586441336441337 on epoch=224
06/01/2022 19:59:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7504063196105932 -> 0.7586441336441337 on epoch=224, global_step=900
06/01/2022 19:59:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/01/2022 19:59:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=229
06/01/2022 19:59:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/01/2022 19:59:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/01/2022 20:00:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/01/2022 20:00:02 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8435316655397791 on epoch=237
06/01/2022 20:00:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7586441336441337 -> 0.8435316655397791 on epoch=237, global_step=950
06/01/2022 20:00:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/01/2022 20:00:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/01/2022 20:00:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/01/2022 20:00:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/01/2022 20:00:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/01/2022 20:00:15 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.5984022225652107 on epoch=249
06/01/2022 20:00:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 20:00:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.14 on epoch=254
06/01/2022 20:00:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/01/2022 20:00:25 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/01/2022 20:00:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/01/2022 20:00:29 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7618489320526672 on epoch=262
06/01/2022 20:00:31 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/01/2022 20:00:34 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 20:00:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/01/2022 20:00:39 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 20:00:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/01/2022 20:00:43 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7776199494949495 on epoch=274
06/01/2022 20:00:45 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/01/2022 20:00:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 20:00:50 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/01/2022 20:00:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/01/2022 20:00:55 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 20:00:56 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.7586441336441337 on epoch=287
06/01/2022 20:00:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=289
06/01/2022 20:01:01 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/01/2022 20:01:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 20:01:06 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=297
06/01/2022 20:01:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 20:01:10 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.5646080368906456 on epoch=299
06/01/2022 20:01:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 20:01:15 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 20:01:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 20:01:20 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/01/2022 20:01:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/01/2022 20:01:24 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6569099378881987 on epoch=312
06/01/2022 20:01:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/01/2022 20:01:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 20:01:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/01/2022 20:01:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 20:01:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 20:01:37 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5765081692501048 on epoch=324
06/01/2022 20:01:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/01/2022 20:01:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/01/2022 20:01:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/01/2022 20:01:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/01/2022 20:01:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 20:01:51 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6852219608965109 on epoch=337
06/01/2022 20:01:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 20:01:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 20:01:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/01/2022 20:02:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/01/2022 20:02:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/01/2022 20:02:05 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.698562834224599 on epoch=349
06/01/2022 20:02:07 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 20:02:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/01/2022 20:02:12 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 20:02:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/01/2022 20:02:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 20:02:18 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.7059791021671826 on epoch=362
06/01/2022 20:02:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/01/2022 20:02:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 20:02:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/01/2022 20:02:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/01/2022 20:02:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/01/2022 20:02:32 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7041408668730651 on epoch=374
06/01/2022 20:02:35 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/01/2022 20:02:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/01/2022 20:02:40 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 20:02:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/01/2022 20:02:45 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 20:02:47 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.699378667927055 on epoch=387
06/01/2022 20:02:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/01/2022 20:02:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/01/2022 20:02:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/01/2022 20:02:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 20:03:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 20:03:01 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7399180999181 on epoch=399
06/01/2022 20:03:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/01/2022 20:03:06 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/01/2022 20:03:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 20:03:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/01/2022 20:03:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 20:03:15 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7443281799899447 on epoch=412
06/01/2022 20:03:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/01/2022 20:03:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 20:03:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 20:03:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 20:03:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 20:03:29 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7586441336441337 on epoch=424
06/01/2022 20:03:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 20:03:35 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/01/2022 20:03:37 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 20:03:40 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 20:03:42 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 20:03:44 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7247665847665848 on epoch=437
06/01/2022 20:03:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 20:03:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/01/2022 20:03:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/01/2022 20:03:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/01/2022 20:03:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 20:03:58 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6925205566097407 on epoch=449
06/01/2022 20:04:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 20:04:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/01/2022 20:04:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 20:04:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/01/2022 20:04:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=462
06/01/2022 20:04:12 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6966737563511757 on epoch=462
06/01/2022 20:04:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=464
06/01/2022 20:04:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/01/2022 20:04:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 20:04:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 20:04:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/01/2022 20:04:26 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7198484326841104 on epoch=474
06/01/2022 20:04:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 20:04:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 20:04:33 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/01/2022 20:04:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/01/2022 20:04:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 20:04:40 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6379909830747879 on epoch=487
06/01/2022 20:04:42 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 20:04:45 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 20:04:47 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 20:04:50 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 20:04:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=499
06/01/2022 20:04:54 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7399180999181 on epoch=499
06/01/2022 20:04:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/01/2022 20:04:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 20:05:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 20:05:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 20:05:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 20:05:07 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.725602146263911 on epoch=512
06/01/2022 20:05:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 20:05:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/01/2022 20:05:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 20:05:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/01/2022 20:05:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/01/2022 20:05:21 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7106814753873578 on epoch=524
06/01/2022 20:05:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 20:05:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=529
06/01/2022 20:05:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 20:05:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 20:05:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 20:05:35 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7399180999181 on epoch=537
06/01/2022 20:05:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 20:05:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 20:05:43 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 20:05:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 20:05:48 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/01/2022 20:05:49 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7542862838915471 on epoch=549
06/01/2022 20:05:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 20:05:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 20:05:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 20:05:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 20:06:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 20:06:03 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7300054112554113 on epoch=562
06/01/2022 20:06:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 20:06:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 20:06:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 20:06:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 20:06:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 20:06:17 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7542862838915471 on epoch=574
06/01/2022 20:06:19 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 20:06:22 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 20:06:25 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/01/2022 20:06:27 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/01/2022 20:06:30 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 20:06:31 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7586441336441337 on epoch=587
06/01/2022 20:06:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=589
06/01/2022 20:06:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 20:06:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 20:06:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 20:06:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/01/2022 20:06:45 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7776199494949495 on epoch=599
06/01/2022 20:06:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=602
06/01/2022 20:06:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 20:06:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 20:06:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 20:06:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/01/2022 20:06:59 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7542862838915471 on epoch=612
06/01/2022 20:07:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 20:07:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 20:07:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/01/2022 20:07:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/01/2022 20:07:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 20:07:13 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7782199878974073 on epoch=624
06/01/2022 20:07:15 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/01/2022 20:07:18 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/01/2022 20:07:20 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 20:07:23 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 20:07:26 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/01/2022 20:07:27 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.60835326953748 on epoch=637
06/01/2022 20:07:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 20:07:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 20:07:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 20:07:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/01/2022 20:07:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 20:07:41 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5966108452950559 on epoch=649
06/01/2022 20:07:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 20:07:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 20:07:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 20:07:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 20:07:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 20:07:55 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5966108452950559 on epoch=662
06/01/2022 20:07:57 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 20:08:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 20:08:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 20:08:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 20:08:08 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 20:08:09 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5805133272524576 on epoch=674
06/01/2022 20:08:11 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 20:08:14 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/01/2022 20:08:17 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 20:08:19 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 20:08:22 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=687
06/01/2022 20:08:23 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8286642516244035 on epoch=687
06/01/2022 20:08:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 20:08:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 20:08:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 20:08:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 20:08:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/01/2022 20:08:37 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5805133272524576 on epoch=699
06/01/2022 20:08:39 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 20:08:42 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 20:08:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 20:08:47 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 20:08:50 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 20:08:51 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5652376514445481 on epoch=712
06/01/2022 20:08:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/01/2022 20:08:56 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 20:08:59 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 20:09:01 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 20:09:04 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 20:09:05 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6118395493395494 on epoch=724
06/01/2022 20:09:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/01/2022 20:09:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 20:09:12 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 20:09:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 20:09:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 20:09:19 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7613588446131141 on epoch=737
06/01/2022 20:09:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 20:09:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 20:09:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 20:09:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 20:09:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 20:09:33 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7480761121652962 on epoch=749
06/01/2022 20:09:33 - INFO - __main__ - save last model!
06/01/2022 20:09:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 20:09:33 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 20:09:33 - INFO - __main__ - Printing 3 examples
06/01/2022 20:09:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:09:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:09:33 - INFO - __main__ - Printing 3 examples
06/01/2022 20:09:33 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:09:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:09:33 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:09:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:09:33 - INFO - __main__ - Printing 3 examples
06/01/2022 20:09:33 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:09:33 - INFO - __main__ - ['others']
06/01/2022 20:09:33 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:09:33 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:09:33 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:09:35 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:09:40 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 20:09:48 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:09:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:09:49 - INFO - __main__ - Starting training!
06/01/2022 20:11:18 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/01/2022 20:11:18 - INFO - __main__ - Classification-F1 on test data: 0.1106
06/01/2022 20:11:18 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.8435316655397791, test_performance=0.11058893144814405
06/01/2022 20:11:18 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/01/2022 20:11:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:11:19 - INFO - __main__ - Printing 3 examples
06/01/2022 20:11:19 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:11:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:11:19 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:11:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:11:19 - INFO - __main__ - Printing 3 examples
06/01/2022 20:11:19 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:11:19 - INFO - __main__ - ['others']
06/01/2022 20:11:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:11:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:11:19 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:11:38 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:11:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:11:39 - INFO - __main__ - Starting training!
06/01/2022 20:11:42 - INFO - __main__ - Step 10 Global step 10 Train loss 3.99 on epoch=2
06/01/2022 20:11:44 - INFO - __main__ - Step 20 Global step 20 Train loss 2.18 on epoch=4
06/01/2022 20:11:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.52 on epoch=7
06/01/2022 20:11:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.13 on epoch=9
06/01/2022 20:11:52 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=12
06/01/2022 20:11:53 - INFO - __main__ - Global step 50 Train loss 1.96 Classification-F1 0.10126582278481013 on epoch=12
06/01/2022 20:11:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10126582278481013 on epoch=12, global_step=50
06/01/2022 20:11:56 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/01/2022 20:11:58 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/01/2022 20:12:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=19
06/01/2022 20:12:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=22
06/01/2022 20:12:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=24
06/01/2022 20:12:06 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.2603826918895412 on epoch=24
06/01/2022 20:12:06 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.2603826918895412 on epoch=24, global_step=100
06/01/2022 20:12:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=27
06/01/2022 20:12:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
06/01/2022 20:12:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=32
06/01/2022 20:12:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.78 on epoch=34
06/01/2022 20:12:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/01/2022 20:12:20 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.5031110237692993 on epoch=37
06/01/2022 20:12:20 - INFO - __main__ - Saving model with best Classification-F1: 0.2603826918895412 -> 0.5031110237692993 on epoch=37, global_step=150
06/01/2022 20:12:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=39
06/01/2022 20:12:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=42
06/01/2022 20:12:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=44
06/01/2022 20:12:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=47
06/01/2022 20:12:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=49
06/01/2022 20:12:34 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.5074882327770647 on epoch=49
06/01/2022 20:12:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5031110237692993 -> 0.5074882327770647 on epoch=49, global_step=200
06/01/2022 20:12:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/01/2022 20:12:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/01/2022 20:12:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=57
06/01/2022 20:12:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.47 on epoch=59
06/01/2022 20:12:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=62
06/01/2022 20:12:47 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.682729700854701 on epoch=62
06/01/2022 20:12:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5074882327770647 -> 0.682729700854701 on epoch=62, global_step=250
06/01/2022 20:12:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=64
06/01/2022 20:12:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=67
06/01/2022 20:12:55 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=69
06/01/2022 20:12:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=72
06/01/2022 20:13:00 - INFO - __main__ - Step 300 Global step 300 Train loss 0.40 on epoch=74
06/01/2022 20:13:00 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.6745655096104389 on epoch=74
06/01/2022 20:13:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.39 on epoch=77
06/01/2022 20:13:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=79
06/01/2022 20:13:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.36 on epoch=82
06/01/2022 20:13:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/01/2022 20:13:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=87
06/01/2022 20:13:14 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.7451786635706914 on epoch=87
06/01/2022 20:13:14 - INFO - __main__ - Saving model with best Classification-F1: 0.682729700854701 -> 0.7451786635706914 on epoch=87, global_step=350
06/01/2022 20:13:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=89
06/01/2022 20:13:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/01/2022 20:13:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/01/2022 20:13:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/01/2022 20:13:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=99
06/01/2022 20:13:28 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.7132467532467532 on epoch=99
06/01/2022 20:13:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.22 on epoch=102
06/01/2022 20:13:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/01/2022 20:13:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/01/2022 20:13:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=109
06/01/2022 20:13:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=112
06/01/2022 20:13:41 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.7962208289794497 on epoch=112
06/01/2022 20:13:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7451786635706914 -> 0.7962208289794497 on epoch=112, global_step=450
06/01/2022 20:13:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/01/2022 20:13:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/01/2022 20:13:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=119
06/01/2022 20:13:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/01/2022 20:13:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.12 on epoch=124
06/01/2022 20:13:54 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.6652146652146652 on epoch=124
06/01/2022 20:13:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.13 on epoch=127
06/01/2022 20:13:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
06/01/2022 20:14:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.06 on epoch=132
06/01/2022 20:14:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/01/2022 20:14:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.13 on epoch=137
06/01/2022 20:14:08 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.708895569765135 on epoch=137
06/01/2022 20:14:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/01/2022 20:14:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
06/01/2022 20:14:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=144
06/01/2022 20:14:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/01/2022 20:14:21 - INFO - __main__ - Step 600 Global step 600 Train loss 0.09 on epoch=149
06/01/2022 20:14:22 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7514610389610389 on epoch=149
06/01/2022 20:14:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/01/2022 20:14:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=154
06/01/2022 20:14:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=157
06/01/2022 20:14:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.03 on epoch=159
06/01/2022 20:14:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/01/2022 20:14:35 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7938483085541909 on epoch=162
06/01/2022 20:14:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/01/2022 20:14:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=167
06/01/2022 20:14:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/01/2022 20:14:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=172
06/01/2022 20:14:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/01/2022 20:14:49 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.8094729344729344 on epoch=174
06/01/2022 20:14:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7962208289794497 -> 0.8094729344729344 on epoch=174, global_step=700
06/01/2022 20:14:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/01/2022 20:14:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/01/2022 20:14:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/01/2022 20:14:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/01/2022 20:15:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/01/2022 20:15:02 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7169669669669669 on epoch=187
06/01/2022 20:15:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/01/2022 20:15:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=192
06/01/2022 20:15:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/01/2022 20:15:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/01/2022 20:15:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/01/2022 20:15:16 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7689562535100293 on epoch=199
06/01/2022 20:15:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/01/2022 20:15:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/01/2022 20:15:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/01/2022 20:15:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=209
06/01/2022 20:15:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/01/2022 20:15:30 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.7732665701415701 on epoch=212
06/01/2022 20:15:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=214
06/01/2022 20:15:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/01/2022 20:15:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/01/2022 20:15:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/01/2022 20:15:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/01/2022 20:15:43 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.7892734049044343 on epoch=224
06/01/2022 20:15:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/01/2022 20:15:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/01/2022 20:15:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/01/2022 20:15:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.04 on epoch=234
06/01/2022 20:15:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 20:15:57 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8591163738222563 on epoch=237
06/01/2022 20:15:57 - INFO - __main__ - Saving model with best Classification-F1: 0.8094729344729344 -> 0.8591163738222563 on epoch=237, global_step=950
06/01/2022 20:16:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/01/2022 20:16:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=242
06/01/2022 20:16:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=244
06/01/2022 20:16:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=247
06/01/2022 20:16:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/01/2022 20:16:11 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.7792042440318302 on epoch=249
06/01/2022 20:16:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/01/2022 20:16:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/01/2022 20:16:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 20:16:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/01/2022 20:16:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/01/2022 20:16:25 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7941092845326716 on epoch=262
06/01/2022 20:16:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/01/2022 20:16:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/01/2022 20:16:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/01/2022 20:16:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/01/2022 20:16:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/01/2022 20:16:38 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.777296494355318 on epoch=274
06/01/2022 20:16:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/01/2022 20:16:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/01/2022 20:16:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/01/2022 20:16:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/01/2022 20:16:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 20:16:52 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.8272669220945083 on epoch=287
06/01/2022 20:16:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/01/2022 20:16:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/01/2022 20:17:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/01/2022 20:17:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/01/2022 20:17:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 20:17:06 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7933520921636372 on epoch=299
06/01/2022 20:17:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 20:17:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/01/2022 20:17:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=307
06/01/2022 20:17:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/01/2022 20:17:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/01/2022 20:17:19 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.8271753175987048 on epoch=312
06/01/2022 20:17:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/01/2022 20:17:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/01/2022 20:17:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/01/2022 20:17:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/01/2022 20:17:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 20:17:33 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.8393419446051026 on epoch=324
06/01/2022 20:17:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/01/2022 20:17:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/01/2022 20:17:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/01/2022 20:17:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=334
06/01/2022 20:17:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/01/2022 20:17:47 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8271002868684504 on epoch=337
06/01/2022 20:17:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/01/2022 20:17:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/01/2022 20:17:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/01/2022 20:17:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=347
06/01/2022 20:17:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=349
06/01/2022 20:18:00 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7622992349394538 on epoch=349
06/01/2022 20:18:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/01/2022 20:18:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/01/2022 20:18:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 20:18:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=359
06/01/2022 20:18:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/01/2022 20:18:14 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.8603107985480943 on epoch=362
06/01/2022 20:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.8591163738222563 -> 0.8603107985480943 on epoch=362, global_step=1450
06/01/2022 20:18:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/01/2022 20:18:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 20:18:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/01/2022 20:18:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=372
06/01/2022 20:18:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/01/2022 20:18:28 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8423868667701685 on epoch=374
06/01/2022 20:18:31 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/01/2022 20:18:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/01/2022 20:18:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 20:18:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 20:18:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/01/2022 20:18:42 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.8284457478005866 on epoch=387
06/01/2022 20:18:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 20:18:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/01/2022 20:18:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/01/2022 20:18:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 20:18:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 20:18:55 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.8124236314760509 on epoch=399
06/01/2022 20:18:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 20:19:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 20:19:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/01/2022 20:19:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/01/2022 20:19:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 20:19:09 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.8275886724162587 on epoch=412
06/01/2022 20:19:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 20:19:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=417
06/01/2022 20:19:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 20:19:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 20:19:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 20:19:23 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.8122887593475828 on epoch=424
06/01/2022 20:19:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 20:19:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 20:19:31 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 20:19:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 20:19:36 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 20:19:37 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.828125 on epoch=437
06/01/2022 20:19:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 20:19:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 20:19:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 20:19:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/01/2022 20:19:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=449
06/01/2022 20:19:51 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7651348039215686 on epoch=449
06/01/2022 20:19:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/01/2022 20:19:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 20:19:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/01/2022 20:20:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 20:20:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 20:20:05 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7791666666666667 on epoch=462
06/01/2022 20:20:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 20:20:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 20:20:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/01/2022 20:20:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=472
06/01/2022 20:20:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 20:20:18 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.8113391984359727 on epoch=474
06/01/2022 20:20:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=477
06/01/2022 20:20:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/01/2022 20:20:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/01/2022 20:20:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/01/2022 20:20:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 20:20:32 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7929936054936055 on epoch=487
06/01/2022 20:20:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 20:20:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 20:20:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/01/2022 20:20:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 20:20:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/01/2022 20:20:46 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7577375762859634 on epoch=499
06/01/2022 20:20:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=502
06/01/2022 20:20:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 20:20:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 20:20:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/01/2022 20:20:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 20:21:00 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7925778719896366 on epoch=512
06/01/2022 20:21:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 20:21:05 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 20:21:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 20:21:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 20:21:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 20:21:14 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7925778719896366 on epoch=524
06/01/2022 20:21:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 20:21:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 20:21:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 20:21:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/01/2022 20:21:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 20:21:28 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7813196607314254 on epoch=537
06/01/2022 20:21:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 20:21:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/01/2022 20:21:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 20:21:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=547
06/01/2022 20:21:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 20:21:41 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8084904056399732 on epoch=549
06/01/2022 20:21:44 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 20:21:47 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/01/2022 20:21:49 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=557
06/01/2022 20:21:52 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 20:21:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 20:21:55 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.781954156954157 on epoch=562
06/01/2022 20:21:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 20:22:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 20:22:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/01/2022 20:22:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 20:22:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 20:22:09 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.8439020182853201 on epoch=574
06/01/2022 20:22:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 20:22:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 20:22:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 20:22:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 20:22:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 20:22:23 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.8432044839879526 on epoch=587
06/01/2022 20:22:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 20:22:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 20:22:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 20:22:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 20:22:36 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 20:22:37 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7955799102857927 on epoch=599
06/01/2022 20:22:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 20:22:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 20:22:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 20:22:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 20:22:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=612
06/01/2022 20:22:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7649534561299267 on epoch=612
06/01/2022 20:22:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=614
06/01/2022 20:22:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 20:22:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 20:23:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 20:23:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 20:23:05 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7951173572877426 on epoch=624
06/01/2022 20:23:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 20:23:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 20:23:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 20:23:15 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=634
06/01/2022 20:23:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 20:23:19 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7105783444198078 on epoch=637
06/01/2022 20:23:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 20:23:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 20:23:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 20:23:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 20:23:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 20:23:33 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7815444359562006 on epoch=649
06/01/2022 20:23:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 20:23:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 20:23:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 20:23:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 20:23:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 20:23:47 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7815444359562006 on epoch=662
06/01/2022 20:23:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/01/2022 20:23:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 20:23:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 20:23:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 20:24:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 20:24:01 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7658371040723982 on epoch=674
06/01/2022 20:24:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 20:24:06 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 20:24:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 20:24:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=684
06/01/2022 20:24:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 20:24:15 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7518824312941961 on epoch=687
06/01/2022 20:24:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 20:24:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 20:24:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 20:24:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=697
06/01/2022 20:24:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 20:24:29 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7794289044289044 on epoch=699
06/01/2022 20:24:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/01/2022 20:24:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 20:24:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=707
06/01/2022 20:24:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/01/2022 20:24:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 20:24:43 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7428229665071769 on epoch=712
06/01/2022 20:24:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 20:24:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 20:24:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 20:24:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 20:24:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 20:24:57 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7802623830399791 on epoch=724
06/01/2022 20:24:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 20:25:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 20:25:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 20:25:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 20:25:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 20:25:11 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8441312008674439 on epoch=737
06/01/2022 20:25:13 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/01/2022 20:25:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 20:25:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 20:25:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=747
06/01/2022 20:25:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/01/2022 20:25:24 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7806915306915306 on epoch=749
06/01/2022 20:25:24 - INFO - __main__ - save last model!
06/01/2022 20:25:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 20:25:24 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 20:25:24 - INFO - __main__ - Printing 3 examples
06/01/2022 20:25:24 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 20:25:24 - INFO - __main__ - ['others']
06/01/2022 20:25:24 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 20:25:24 - INFO - __main__ - ['others']
06/01/2022 20:25:24 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 20:25:24 - INFO - __main__ - ['others']
06/01/2022 20:25:24 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:25:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:25:25 - INFO - __main__ - Printing 3 examples
06/01/2022 20:25:25 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:25:25 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:25:25 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:25:25 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:25:25 - INFO - __main__ - Printing 3 examples
06/01/2022 20:25:25 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:25:25 - INFO - __main__ - ['others']
06/01/2022 20:25:25 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:25:25 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:25:25 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:25:27 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:25:32 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 20:25:40 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:25:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:25:40 - INFO - __main__ - Starting training!
06/01/2022 20:27:09 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/01/2022 20:27:09 - INFO - __main__ - Classification-F1 on test data: 0.1370
06/01/2022 20:27:09 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.8603107985480943, test_performance=0.1370362201303776
06/01/2022 20:27:09 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/01/2022 20:27:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:27:10 - INFO - __main__ - Printing 3 examples
06/01/2022 20:27:10 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:27:10 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:27:10 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:27:10 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:27:10 - INFO - __main__ - Printing 3 examples
06/01/2022 20:27:10 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:27:10 - INFO - __main__ - ['others']
06/01/2022 20:27:10 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:27:10 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:27:10 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:27:26 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:27:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:27:27 - INFO - __main__ - Starting training!
06/01/2022 20:27:30 - INFO - __main__ - Step 10 Global step 10 Train loss 4.25 on epoch=2
06/01/2022 20:27:33 - INFO - __main__ - Step 20 Global step 20 Train loss 2.67 on epoch=4
06/01/2022 20:27:35 - INFO - __main__ - Step 30 Global step 30 Train loss 2.00 on epoch=7
06/01/2022 20:27:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.28 on epoch=9
06/01/2022 20:27:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.04 on epoch=12
06/01/2022 20:27:41 - INFO - __main__ - Global step 50 Train loss 2.25 Classification-F1 0.1 on epoch=12
06/01/2022 20:27:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 20:27:44 - INFO - __main__ - Step 60 Global step 60 Train loss 0.92 on epoch=14
06/01/2022 20:27:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.91 on epoch=17
06/01/2022 20:27:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=19
06/01/2022 20:27:52 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=22
06/01/2022 20:27:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/01/2022 20:27:55 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.13047619047619047 on epoch=24
06/01/2022 20:27:55 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.13047619047619047 on epoch=24, global_step=100
06/01/2022 20:27:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=27
06/01/2022 20:28:00 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=29
06/01/2022 20:28:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/01/2022 20:28:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=34
06/01/2022 20:28:08 - INFO - __main__ - Step 150 Global step 150 Train loss 0.92 on epoch=37
06/01/2022 20:28:09 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.36948836187966627 on epoch=37
06/01/2022 20:28:09 - INFO - __main__ - Saving model with best Classification-F1: 0.13047619047619047 -> 0.36948836187966627 on epoch=37, global_step=150
06/01/2022 20:28:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
06/01/2022 20:28:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=42
06/01/2022 20:28:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=44
06/01/2022 20:28:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.71 on epoch=47
06/01/2022 20:28:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=49
06/01/2022 20:28:22 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.313265931372549 on epoch=49
06/01/2022 20:28:25 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=52
06/01/2022 20:28:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=54
06/01/2022 20:28:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=57
06/01/2022 20:28:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=59
06/01/2022 20:28:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.59 on epoch=62
06/01/2022 20:28:36 - INFO - __main__ - Global step 250 Train loss 0.67 Classification-F1 0.6834664786967418 on epoch=62
06/01/2022 20:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.36948836187966627 -> 0.6834664786967418 on epoch=62, global_step=250
06/01/2022 20:28:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.57 on epoch=64
06/01/2022 20:28:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=67
06/01/2022 20:28:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=69
06/01/2022 20:28:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
06/01/2022 20:28:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=74
06/01/2022 20:28:50 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.4955707867229048 on epoch=74
06/01/2022 20:28:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=77
06/01/2022 20:28:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=79
06/01/2022 20:28:57 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=82
06/01/2022 20:29:00 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
06/01/2022 20:29:02 - INFO - __main__ - Step 350 Global step 350 Train loss 0.52 on epoch=87
06/01/2022 20:29:03 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.5443290043290043 on epoch=87
06/01/2022 20:29:06 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/01/2022 20:29:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=92
06/01/2022 20:29:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=94
06/01/2022 20:29:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.28 on epoch=97
06/01/2022 20:29:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=99
06/01/2022 20:29:17 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6026268880758046 on epoch=99
06/01/2022 20:29:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=102
06/01/2022 20:29:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=104
06/01/2022 20:29:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/01/2022 20:29:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/01/2022 20:29:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.16 on epoch=112
06/01/2022 20:29:30 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.6069144914722125 on epoch=112
06/01/2022 20:29:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=114
06/01/2022 20:29:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=117
06/01/2022 20:29:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=119
06/01/2022 20:29:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/01/2022 20:29:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/01/2022 20:29:44 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6077822539779062 on epoch=124
06/01/2022 20:29:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/01/2022 20:29:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/01/2022 20:29:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=132
06/01/2022 20:29:54 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/01/2022 20:29:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=137
06/01/2022 20:29:57 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.731856684981685 on epoch=137
06/01/2022 20:29:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6834664786967418 -> 0.731856684981685 on epoch=137, global_step=550
06/01/2022 20:30:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/01/2022 20:30:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=142
06/01/2022 20:30:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.13 on epoch=144
06/01/2022 20:30:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=147
06/01/2022 20:30:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=149
06/01/2022 20:30:11 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6247619047619047 on epoch=149
06/01/2022 20:30:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=152
06/01/2022 20:30:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/01/2022 20:30:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/01/2022 20:30:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
06/01/2022 20:30:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=162
06/01/2022 20:30:25 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.6046978021978022 on epoch=162
06/01/2022 20:30:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=164
06/01/2022 20:30:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/01/2022 20:30:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
06/01/2022 20:30:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/01/2022 20:30:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/01/2022 20:30:39 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.5891666666666667 on epoch=174
06/01/2022 20:30:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/01/2022 20:30:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/01/2022 20:30:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/01/2022 20:30:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/01/2022 20:30:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/01/2022 20:30:52 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.6939327485380118 on epoch=187
06/01/2022 20:30:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/01/2022 20:30:57 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=192
06/01/2022 20:31:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.04 on epoch=194
06/01/2022 20:31:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=197
06/01/2022 20:31:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/01/2022 20:31:06 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.5829753507172862 on epoch=199
06/01/2022 20:31:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/01/2022 20:31:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/01/2022 20:31:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/01/2022 20:31:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/01/2022 20:31:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/01/2022 20:31:19 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.601907651172357 on epoch=212
06/01/2022 20:31:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/01/2022 20:31:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=217
06/01/2022 20:31:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/01/2022 20:31:29 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/01/2022 20:31:32 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/01/2022 20:31:33 - INFO - __main__ - Global step 900 Train loss 0.07 Classification-F1 0.8405972474937992 on epoch=224
06/01/2022 20:31:33 - INFO - __main__ - Saving model with best Classification-F1: 0.731856684981685 -> 0.8405972474937992 on epoch=224, global_step=900
06/01/2022 20:31:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/01/2022 20:31:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/01/2022 20:31:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/01/2022 20:31:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/01/2022 20:31:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 20:31:46 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8408910333270734 on epoch=237
06/01/2022 20:31:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8405972474937992 -> 0.8408910333270734 on epoch=237, global_step=950
06/01/2022 20:31:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/01/2022 20:31:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/01/2022 20:31:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/01/2022 20:31:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/01/2022 20:31:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/01/2022 20:32:00 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7877145438121048 on epoch=249
06/01/2022 20:32:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/01/2022 20:32:05 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/01/2022 20:32:08 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/01/2022 20:32:10 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 20:32:13 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/01/2022 20:32:14 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.7937211854237716 on epoch=262
06/01/2022 20:32:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/01/2022 20:32:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 20:32:21 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 20:32:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/01/2022 20:32:26 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/01/2022 20:32:28 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6074074074074074 on epoch=274
06/01/2022 20:32:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/01/2022 20:32:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 20:32:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/01/2022 20:32:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/01/2022 20:32:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 20:32:42 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.8042684766214179 on epoch=287
06/01/2022 20:32:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/01/2022 20:32:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/01/2022 20:32:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=294
06/01/2022 20:32:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/01/2022 20:32:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/01/2022 20:32:55 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7117063492063492 on epoch=299
06/01/2022 20:32:58 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=302
06/01/2022 20:33:00 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 20:33:03 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/01/2022 20:33:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 20:33:08 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/01/2022 20:33:09 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.6023153254806018 on epoch=312
06/01/2022 20:33:12 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/01/2022 20:33:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 20:33:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 20:33:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/01/2022 20:33:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 20:33:23 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6309454796411319 on epoch=324
06/01/2022 20:33:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/01/2022 20:33:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/01/2022 20:33:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/01/2022 20:33:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/01/2022 20:33:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 20:33:37 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.8264930001772106 on epoch=337
06/01/2022 20:33:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/01/2022 20:33:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/01/2022 20:33:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/01/2022 20:33:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 20:33:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/01/2022 20:33:51 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7864159379968204 on epoch=349
06/01/2022 20:33:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/01/2022 20:33:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/01/2022 20:33:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 20:34:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/01/2022 20:34:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 20:34:05 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.8060452804285823 on epoch=362
06/01/2022 20:34:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/01/2022 20:34:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=367
06/01/2022 20:34:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 20:34:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/01/2022 20:34:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/01/2022 20:34:18 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.767884099557108 on epoch=374
06/01/2022 20:34:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/01/2022 20:34:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 20:34:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 20:34:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/01/2022 20:34:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 20:34:32 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7729024244833068 on epoch=387
06/01/2022 20:34:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 20:34:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=392
06/01/2022 20:34:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 20:34:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 20:34:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=399
06/01/2022 20:34:46 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.723853238265003 on epoch=399
06/01/2022 20:34:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 20:34:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/01/2022 20:34:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/01/2022 20:34:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=409
06/01/2022 20:34:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/01/2022 20:35:00 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7729024244833068 on epoch=412
06/01/2022 20:35:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 20:35:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 20:35:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 20:35:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 20:35:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 20:35:14 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.773425925925926 on epoch=424
06/01/2022 20:35:17 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 20:35:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 20:35:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 20:35:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/01/2022 20:35:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 20:35:28 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7926638395388395 on epoch=437
06/01/2022 20:35:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/01/2022 20:35:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 20:35:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=444
06/01/2022 20:35:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/01/2022 20:35:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 20:35:42 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7446774193548388 on epoch=449
06/01/2022 20:35:44 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/01/2022 20:35:47 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 20:35:49 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 20:35:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 20:35:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 20:35:56 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7562485790071998 on epoch=462
06/01/2022 20:35:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/01/2022 20:36:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 20:36:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 20:36:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 20:36:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/01/2022 20:36:10 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7945096842155664 on epoch=474
06/01/2022 20:36:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 20:36:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 20:36:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=482
06/01/2022 20:36:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/01/2022 20:36:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/01/2022 20:36:23 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7766122766122767 on epoch=487
06/01/2022 20:36:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 20:36:28 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 20:36:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 20:36:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/01/2022 20:36:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=499
06/01/2022 20:36:37 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8248380345154539 on epoch=499
06/01/2022 20:36:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 20:36:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 20:36:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 20:36:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 20:36:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/01/2022 20:36:51 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7926573426573427 on epoch=512
06/01/2022 20:36:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 20:36:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 20:36:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/01/2022 20:37:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 20:37:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 20:37:05 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7394868082368082 on epoch=524
06/01/2022 20:37:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/01/2022 20:37:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 20:37:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/01/2022 20:37:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/01/2022 20:37:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/01/2022 20:37:19 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7853174603174603 on epoch=537
06/01/2022 20:37:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/01/2022 20:37:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 20:37:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=544
06/01/2022 20:37:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 20:37:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 20:37:32 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7734316134316135 on epoch=549
06/01/2022 20:37:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/01/2022 20:37:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 20:37:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 20:37:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 20:37:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 20:37:46 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7729024244833068 on epoch=562
06/01/2022 20:37:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 20:37:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/01/2022 20:37:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/01/2022 20:37:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 20:37:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 20:38:00 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8437685334237058 on epoch=574
06/01/2022 20:38:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8408910333270734 -> 0.8437685334237058 on epoch=574, global_step=2300
06/01/2022 20:38:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 20:38:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 20:38:08 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/01/2022 20:38:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 20:38:13 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/01/2022 20:38:14 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.8097680097680098 on epoch=587
06/01/2022 20:38:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 20:38:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 20:38:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 20:38:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 20:38:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 20:38:27 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7734316134316135 on epoch=599
06/01/2022 20:38:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 20:38:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 20:38:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 20:38:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=609
06/01/2022 20:38:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/01/2022 20:38:41 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7189295273534404 on epoch=612
06/01/2022 20:38:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/01/2022 20:38:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=617
06/01/2022 20:38:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 20:38:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 20:38:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 20:38:55 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.8100273569023568 on epoch=624
06/01/2022 20:38:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 20:39:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 20:39:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 20:39:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 20:39:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 20:39:09 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.725602146263911 on epoch=637
06/01/2022 20:39:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 20:39:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 20:39:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/01/2022 20:39:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/01/2022 20:39:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 20:39:23 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.8129751020642861 on epoch=649
06/01/2022 20:39:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 20:39:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 20:39:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/01/2022 20:39:33 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/01/2022 20:39:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/01/2022 20:39:37 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7778756846868302 on epoch=662
06/01/2022 20:39:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 20:39:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 20:39:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=669
06/01/2022 20:39:47 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=672
06/01/2022 20:39:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 20:39:51 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8430445593142708 on epoch=674
06/01/2022 20:39:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 20:39:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 20:39:58 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 20:40:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 20:40:03 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=687
06/01/2022 20:40:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7949626096684919 on epoch=687
06/01/2022 20:40:07 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 20:40:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/01/2022 20:40:12 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 20:40:15 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/01/2022 20:40:17 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 20:40:18 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8114612511671334 on epoch=699
06/01/2022 20:40:21 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/01/2022 20:40:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 20:40:26 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 20:40:29 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 20:40:31 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 20:40:32 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7444097774244833 on epoch=712
06/01/2022 20:40:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=714
06/01/2022 20:40:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 20:40:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 20:40:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 20:40:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 20:40:46 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7783152610738817 on epoch=724
06/01/2022 20:40:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 20:40:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 20:40:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 20:40:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 20:40:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 20:41:00 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.8590535334368352 on epoch=737
06/01/2022 20:41:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8437685334237058 -> 0.8590535334368352 on epoch=737, global_step=2950
06/01/2022 20:41:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 20:41:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 20:41:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 20:41:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 20:41:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/01/2022 20:41:14 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7256308728082922 on epoch=749
06/01/2022 20:41:14 - INFO - __main__ - save last model!
06/01/2022 20:41:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 20:41:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 20:41:14 - INFO - __main__ - Printing 3 examples
06/01/2022 20:41:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:41:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:41:14 - INFO - __main__ - Printing 3 examples
06/01/2022 20:41:14 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:41:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:41:14 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:41:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:41:14 - INFO - __main__ - Printing 3 examples
06/01/2022 20:41:14 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:41:14 - INFO - __main__ - ['others']
06/01/2022 20:41:14 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:41:14 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:41:14 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:41:16 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:41:22 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 20:41:29 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:41:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:41:30 - INFO - __main__ - Starting training!
06/01/2022 20:42:58 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/01/2022 20:42:58 - INFO - __main__ - Classification-F1 on test data: 0.1091
06/01/2022 20:42:59 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.8590535334368352, test_performance=0.10905882356660304
06/01/2022 20:42:59 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/01/2022 20:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:43:00 - INFO - __main__ - Printing 3 examples
06/01/2022 20:43:00 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:43:00 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:43:00 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:43:00 - INFO - __main__ - Printing 3 examples
06/01/2022 20:43:00 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/01/2022 20:43:00 - INFO - __main__ - ['others']
06/01/2022 20:43:00 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:43:00 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:43:00 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:43:19 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:43:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:43:19 - INFO - __main__ - Starting training!
06/01/2022 20:43:23 - INFO - __main__ - Step 10 Global step 10 Train loss 4.30 on epoch=2
06/01/2022 20:43:25 - INFO - __main__ - Step 20 Global step 20 Train loss 3.08 on epoch=4
06/01/2022 20:43:28 - INFO - __main__ - Step 30 Global step 30 Train loss 2.27 on epoch=7
06/01/2022 20:43:30 - INFO - __main__ - Step 40 Global step 40 Train loss 1.81 on epoch=9
06/01/2022 20:43:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.57 on epoch=12
06/01/2022 20:43:34 - INFO - __main__ - Global step 50 Train loss 2.61 Classification-F1 0.1855036855036855 on epoch=12
06/01/2022 20:43:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1855036855036855 on epoch=12, global_step=50
06/01/2022 20:43:37 - INFO - __main__ - Step 60 Global step 60 Train loss 1.26 on epoch=14
06/01/2022 20:43:39 - INFO - __main__ - Step 70 Global step 70 Train loss 1.10 on epoch=17
06/01/2022 20:43:42 - INFO - __main__ - Step 80 Global step 80 Train loss 1.00 on epoch=19
06/01/2022 20:43:44 - INFO - __main__ - Step 90 Global step 90 Train loss 0.94 on epoch=22
06/01/2022 20:43:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=24
06/01/2022 20:43:48 - INFO - __main__ - Global step 100 Train loss 1.04 Classification-F1 0.1 on epoch=24
06/01/2022 20:43:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.93 on epoch=27
06/01/2022 20:43:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/01/2022 20:43:56 - INFO - __main__ - Step 130 Global step 130 Train loss 0.88 on epoch=32
06/01/2022 20:43:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.86 on epoch=34
06/01/2022 20:44:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=37
06/01/2022 20:44:02 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.1 on epoch=37
06/01/2022 20:44:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=39
06/01/2022 20:44:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=42
06/01/2022 20:44:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=44
06/01/2022 20:44:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/01/2022 20:44:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=49
06/01/2022 20:44:15 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.25845047401111476 on epoch=49
06/01/2022 20:44:15 - INFO - __main__ - Saving model with best Classification-F1: 0.1855036855036855 -> 0.25845047401111476 on epoch=49, global_step=200
06/01/2022 20:44:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=52
06/01/2022 20:44:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=54
06/01/2022 20:44:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=57
06/01/2022 20:44:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=59
06/01/2022 20:44:28 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=62
06/01/2022 20:44:29 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.47462606837606836 on epoch=62
06/01/2022 20:44:29 - INFO - __main__ - Saving model with best Classification-F1: 0.25845047401111476 -> 0.47462606837606836 on epoch=62, global_step=250
06/01/2022 20:44:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=64
06/01/2022 20:44:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=67
06/01/2022 20:44:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/01/2022 20:44:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=72
06/01/2022 20:44:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=74
06/01/2022 20:44:42 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.5329372178209387 on epoch=74
06/01/2022 20:44:42 - INFO - __main__ - Saving model with best Classification-F1: 0.47462606837606836 -> 0.5329372178209387 on epoch=74, global_step=300
06/01/2022 20:44:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.63 on epoch=77
06/01/2022 20:44:47 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=79
06/01/2022 20:44:50 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=82
06/01/2022 20:44:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.59 on epoch=84
06/01/2022 20:44:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=87
06/01/2022 20:44:56 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.7271421107628004 on epoch=87
06/01/2022 20:44:56 - INFO - __main__ - Saving model with best Classification-F1: 0.5329372178209387 -> 0.7271421107628004 on epoch=87, global_step=350
06/01/2022 20:44:58 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=89
06/01/2022 20:45:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=92
06/01/2022 20:45:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=94
06/01/2022 20:45:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=97
06/01/2022 20:45:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=99
06/01/2022 20:45:09 - INFO - __main__ - Global step 400 Train loss 0.56 Classification-F1 0.6320906432748539 on epoch=99
06/01/2022 20:45:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=102
06/01/2022 20:45:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=104
06/01/2022 20:45:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=107
06/01/2022 20:45:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=109
06/01/2022 20:45:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.48 on epoch=112
06/01/2022 20:45:23 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.7293181818181818 on epoch=112
06/01/2022 20:45:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7271421107628004 -> 0.7293181818181818 on epoch=112, global_step=450
06/01/2022 20:45:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=114
06/01/2022 20:45:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=117
06/01/2022 20:45:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=119
06/01/2022 20:45:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=122
06/01/2022 20:45:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.46 on epoch=124
06/01/2022 20:45:36 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.7434841628959276 on epoch=124
06/01/2022 20:45:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7293181818181818 -> 0.7434841628959276 on epoch=124, global_step=500
06/01/2022 20:45:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=127
06/01/2022 20:45:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=129
06/01/2022 20:45:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=132
06/01/2022 20:45:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.38 on epoch=134
06/01/2022 20:45:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=137
06/01/2022 20:45:50 - INFO - __main__ - Global step 550 Train loss 0.34 Classification-F1 0.7436805555555556 on epoch=137
06/01/2022 20:45:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7434841628959276 -> 0.7436805555555556 on epoch=137, global_step=550
06/01/2022 20:45:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=139
06/01/2022 20:45:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=142
06/01/2022 20:45:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=144
06/01/2022 20:46:00 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=147
06/01/2022 20:46:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=149
06/01/2022 20:46:03 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.7023615480838482 on epoch=149
06/01/2022 20:46:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=152
06/01/2022 20:46:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=154
06/01/2022 20:46:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=157
06/01/2022 20:46:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/01/2022 20:46:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/01/2022 20:46:16 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.7796296296296295 on epoch=162
06/01/2022 20:46:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7436805555555556 -> 0.7796296296296295 on epoch=162, global_step=650
06/01/2022 20:46:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=164
06/01/2022 20:46:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=167
06/01/2022 20:46:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=169
06/01/2022 20:46:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=172
06/01/2022 20:46:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=174
06/01/2022 20:46:30 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6002402402402401 on epoch=174
06/01/2022 20:46:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
06/01/2022 20:46:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/01/2022 20:46:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=182
06/01/2022 20:46:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=184
06/01/2022 20:46:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/01/2022 20:46:44 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6488433048433049 on epoch=187
06/01/2022 20:46:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/01/2022 20:46:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=192
06/01/2022 20:46:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/01/2022 20:46:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=197
06/01/2022 20:46:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=199
06/01/2022 20:46:57 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.8385686438318017 on epoch=199
06/01/2022 20:46:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7796296296296295 -> 0.8385686438318017 on epoch=199, global_step=800
06/01/2022 20:46:59 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
06/01/2022 20:47:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/01/2022 20:47:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/01/2022 20:47:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/01/2022 20:47:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=212
06/01/2022 20:47:11 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7945350042124236 on epoch=212
06/01/2022 20:47:13 - INFO - __main__ - Step 860 Global step 860 Train loss 0.04 on epoch=214
06/01/2022 20:47:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/01/2022 20:47:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=219
06/01/2022 20:47:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=222
06/01/2022 20:47:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/01/2022 20:47:24 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8254530557162136 on epoch=224
06/01/2022 20:47:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/01/2022 20:47:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/01/2022 20:47:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=232
06/01/2022 20:47:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/01/2022 20:47:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/01/2022 20:47:38 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7966733870967742 on epoch=237
06/01/2022 20:47:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/01/2022 20:47:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=242
06/01/2022 20:47:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=244
06/01/2022 20:47:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/01/2022 20:47:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/01/2022 20:47:51 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7955089197482706 on epoch=249
06/01/2022 20:47:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=252
06/01/2022 20:47:56 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/01/2022 20:47:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
06/01/2022 20:48:01 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=259
06/01/2022 20:48:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=262
06/01/2022 20:48:05 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.8130310684711408 on epoch=262
06/01/2022 20:48:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=264
06/01/2022 20:48:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 20:48:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/01/2022 20:48:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/01/2022 20:48:17 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=274
06/01/2022 20:48:18 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7955840455840455 on epoch=274
06/01/2022 20:48:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/01/2022 20:48:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/01/2022 20:48:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/01/2022 20:48:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/01/2022 20:48:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/01/2022 20:48:32 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.7957115009746589 on epoch=287
06/01/2022 20:48:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=289
06/01/2022 20:48:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/01/2022 20:48:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/01/2022 20:48:42 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/01/2022 20:48:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=299
06/01/2022 20:48:45 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7957115009746589 on epoch=299
06/01/2022 20:48:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=302
06/01/2022 20:48:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=304
06/01/2022 20:48:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/01/2022 20:48:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/01/2022 20:48:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=312
06/01/2022 20:48:59 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6788359788359789 on epoch=312
06/01/2022 20:49:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/01/2022 20:49:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/01/2022 20:49:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/01/2022 20:49:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/01/2022 20:49:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 20:49:12 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.8285714285714285 on epoch=324
06/01/2022 20:49:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/01/2022 20:49:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/01/2022 20:49:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/01/2022 20:49:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/01/2022 20:49:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=337
06/01/2022 20:49:26 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8261840498682604 on epoch=337
06/01/2022 20:49:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/01/2022 20:49:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 20:49:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/01/2022 20:49:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 20:49:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 20:49:39 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.8075147327778908 on epoch=349
06/01/2022 20:49:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/01/2022 20:49:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=354
06/01/2022 20:49:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=357
06/01/2022 20:49:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/01/2022 20:49:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 20:49:53 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7966658885776533 on epoch=362
06/01/2022 20:49:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/01/2022 20:49:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/01/2022 20:50:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=369
06/01/2022 20:50:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/01/2022 20:50:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/01/2022 20:50:07 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.8102402800678663 on epoch=374
06/01/2022 20:50:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/01/2022 20:50:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 20:50:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/01/2022 20:50:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/01/2022 20:50:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/01/2022 20:50:20 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.8117003500763235 on epoch=387
06/01/2022 20:50:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/01/2022 20:50:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 20:50:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 20:50:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/01/2022 20:50:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 20:50:34 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.8124085117918135 on epoch=399
06/01/2022 20:50:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/01/2022 20:50:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/01/2022 20:50:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 20:50:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=409
06/01/2022 20:50:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=412
06/01/2022 20:50:48 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8273809523809524 on epoch=412
06/01/2022 20:50:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=414
06/01/2022 20:50:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/01/2022 20:50:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 20:50:58 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=422
06/01/2022 20:51:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=424
06/01/2022 20:51:02 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6086238931816144 on epoch=424
06/01/2022 20:51:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 20:51:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/01/2022 20:51:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 20:51:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=434
06/01/2022 20:51:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/01/2022 20:51:16 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.8107152703926898 on epoch=437
06/01/2022 20:51:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/01/2022 20:51:21 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=442
06/01/2022 20:51:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/01/2022 20:51:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/01/2022 20:51:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/01/2022 20:51:29 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.8271917962587333 on epoch=449
06/01/2022 20:51:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=452
06/01/2022 20:51:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/01/2022 20:51:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 20:51:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 20:51:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 20:51:43 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8284138027971045 on epoch=462
06/01/2022 20:51:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 20:51:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 20:51:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 20:51:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/01/2022 20:51:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=474
06/01/2022 20:51:57 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.842914342914343 on epoch=474
06/01/2022 20:51:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8385686438318017 -> 0.842914342914343 on epoch=474, global_step=1900
06/01/2022 20:52:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 20:52:03 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/01/2022 20:52:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/01/2022 20:52:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 20:52:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/01/2022 20:52:11 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8272669220945083 on epoch=487
06/01/2022 20:52:14 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/01/2022 20:52:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/01/2022 20:52:19 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/01/2022 20:52:22 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/01/2022 20:52:24 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/01/2022 20:52:25 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8126447876447876 on epoch=499
06/01/2022 20:52:28 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/01/2022 20:52:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/01/2022 20:52:33 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 20:52:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/01/2022 20:52:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/01/2022 20:52:39 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7780681747415619 on epoch=512
06/01/2022 20:52:42 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/01/2022 20:52:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/01/2022 20:52:47 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=519
06/01/2022 20:52:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/01/2022 20:52:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/01/2022 20:52:53 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.8266444508838017 on epoch=524
06/01/2022 20:52:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/01/2022 20:52:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 20:53:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/01/2022 20:53:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/01/2022 20:53:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/01/2022 20:53:07 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8131522770398483 on epoch=537
06/01/2022 20:53:09 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=539
06/01/2022 20:53:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/01/2022 20:53:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 20:53:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 20:53:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/01/2022 20:53:21 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8263409961685823 on epoch=549
06/01/2022 20:53:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/01/2022 20:53:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/01/2022 20:53:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/01/2022 20:53:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/01/2022 20:53:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 20:53:35 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8263409961685823 on epoch=562
06/01/2022 20:53:37 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 20:53:40 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/01/2022 20:53:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/01/2022 20:53:45 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 20:53:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=574
06/01/2022 20:53:49 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.8069532806374912 on epoch=574
06/01/2022 20:53:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=577
06/01/2022 20:53:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 20:53:56 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/01/2022 20:53:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=584
06/01/2022 20:54:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 20:54:03 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6513815172638702 on epoch=587
06/01/2022 20:54:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 20:54:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 20:54:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 20:54:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/01/2022 20:54:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/01/2022 20:54:17 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8423645320197044 on epoch=599
06/01/2022 20:54:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/01/2022 20:54:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 20:54:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/01/2022 20:54:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/01/2022 20:54:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 20:54:31 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.8094276094276094 on epoch=612
06/01/2022 20:54:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 20:54:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/01/2022 20:54:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 20:54:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 20:54:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=624
06/01/2022 20:54:44 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6393730071149426 on epoch=624
06/01/2022 20:54:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/01/2022 20:54:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 20:54:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 20:54:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 20:54:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 20:54:58 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8423645320197044 on epoch=637
06/01/2022 20:55:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 20:55:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/01/2022 20:55:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/01/2022 20:55:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 20:55:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/01/2022 20:55:12 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.666257982120051 on epoch=649
06/01/2022 20:55:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/01/2022 20:55:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=654
06/01/2022 20:55:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 20:55:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/01/2022 20:55:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 20:55:26 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8253566659638767 on epoch=662
06/01/2022 20:55:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/01/2022 20:55:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 20:55:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/01/2022 20:55:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 20:55:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 20:55:40 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8269155270562063 on epoch=674
06/01/2022 20:55:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 20:55:46 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/01/2022 20:55:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/01/2022 20:55:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/01/2022 20:55:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 20:55:55 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.8272669220945083 on epoch=687
06/01/2022 20:55:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 20:56:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 20:56:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=694
06/01/2022 20:56:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 20:56:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 20:56:08 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7896346469622331 on epoch=699
06/01/2022 20:56:11 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/01/2022 20:56:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/01/2022 20:56:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=707
06/01/2022 20:56:19 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 20:56:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/01/2022 20:56:22 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6386463705084394 on epoch=712
06/01/2022 20:56:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 20:56:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 20:56:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 20:56:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 20:56:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 20:56:37 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.8263409961685823 on epoch=724
06/01/2022 20:56:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=727
06/01/2022 20:56:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 20:56:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 20:56:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 20:56:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/01/2022 20:56:50 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8128837393543276 on epoch=737
06/01/2022 20:56:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 20:56:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 20:56:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/01/2022 20:57:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=747
06/01/2022 20:57:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/01/2022 20:57:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8423645320197044 on epoch=749
06/01/2022 20:57:04 - INFO - __main__ - save last model!
06/01/2022 20:57:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 20:57:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 20:57:04 - INFO - __main__ - Printing 3 examples
06/01/2022 20:57:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 20:57:04 - INFO - __main__ - ['others']
06/01/2022 20:57:04 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 20:57:04 - INFO - __main__ - ['others']
06/01/2022 20:57:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 20:57:04 - INFO - __main__ - ['others']
06/01/2022 20:57:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:57:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:57:04 - INFO - __main__ - Printing 3 examples
06/01/2022 20:57:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 20:57:04 - INFO - __main__ - ['sad']
06/01/2022 20:57:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 20:57:04 - INFO - __main__ - ['sad']
06/01/2022 20:57:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 20:57:04 - INFO - __main__ - ['sad']
06/01/2022 20:57:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:57:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:57:05 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:57:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:57:05 - INFO - __main__ - Printing 3 examples
06/01/2022 20:57:05 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 20:57:05 - INFO - __main__ - ['sad']
06/01/2022 20:57:05 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 20:57:05 - INFO - __main__ - ['sad']
06/01/2022 20:57:05 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 20:57:05 - INFO - __main__ - ['sad']
06/01/2022 20:57:05 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:57:05 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:57:05 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:57:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:57:12 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 20:57:24 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:57:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:57:25 - INFO - __main__ - Starting training!
06/01/2022 20:58:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/01/2022 20:58:49 - INFO - __main__ - Classification-F1 on test data: 0.1237
06/01/2022 20:58:49 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.842914342914343, test_performance=0.12373712085121338
06/01/2022 20:58:49 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/01/2022 20:58:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:58:50 - INFO - __main__ - Printing 3 examples
06/01/2022 20:58:50 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:58:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:58:50 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 20:58:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 20:58:50 - INFO - __main__ - Printing 3 examples
06/01/2022 20:58:50 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 20:58:50 - INFO - __main__ - ['sad']
06/01/2022 20:58:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 20:58:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 20:58:50 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 20:59:09 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 20:59:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 20:59:10 - INFO - __main__ - Starting training!
06/01/2022 20:59:13 - INFO - __main__ - Step 10 Global step 10 Train loss 4.16 on epoch=2
06/01/2022 20:59:15 - INFO - __main__ - Step 20 Global step 20 Train loss 2.21 on epoch=4
06/01/2022 20:59:18 - INFO - __main__ - Step 30 Global step 30 Train loss 1.71 on epoch=7
06/01/2022 20:59:20 - INFO - __main__ - Step 40 Global step 40 Train loss 1.09 on epoch=9
06/01/2022 20:59:23 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
06/01/2022 20:59:24 - INFO - __main__ - Global step 50 Train loss 2.03 Classification-F1 0.13067758749069247 on epoch=12
06/01/2022 20:59:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
06/01/2022 20:59:26 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=14
06/01/2022 20:59:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/01/2022 20:59:32 - INFO - __main__ - Step 80 Global step 80 Train loss 0.81 on epoch=19
06/01/2022 20:59:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.72 on epoch=22
06/01/2022 20:59:37 - INFO - __main__ - Step 100 Global step 100 Train loss 0.77 on epoch=24
06/01/2022 20:59:37 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.2903846153846154 on epoch=24
06/01/2022 20:59:37 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.2903846153846154 on epoch=24, global_step=100
06/01/2022 20:59:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.83 on epoch=27
06/01/2022 20:59:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=29
06/01/2022 20:59:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/01/2022 20:59:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.59 on epoch=34
06/01/2022 20:59:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.63 on epoch=37
06/01/2022 20:59:51 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.6358580065476617 on epoch=37
06/01/2022 20:59:51 - INFO - __main__ - Saving model with best Classification-F1: 0.2903846153846154 -> 0.6358580065476617 on epoch=37, global_step=150
06/01/2022 20:59:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.56 on epoch=39
06/01/2022 20:59:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.56 on epoch=42
06/01/2022 20:59:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.48 on epoch=44
06/01/2022 21:00:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.44 on epoch=47
06/01/2022 21:00:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=49
06/01/2022 21:00:04 - INFO - __main__ - Global step 200 Train loss 0.50 Classification-F1 0.5803619821912506 on epoch=49
06/01/2022 21:00:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=52
06/01/2022 21:00:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.40 on epoch=54
06/01/2022 21:00:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.40 on epoch=57
06/01/2022 21:00:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.38 on epoch=59
06/01/2022 21:00:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.32 on epoch=62
06/01/2022 21:00:18 - INFO - __main__ - Global step 250 Train loss 0.40 Classification-F1 0.6509653540903542 on epoch=62
06/01/2022 21:00:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6358580065476617 -> 0.6509653540903542 on epoch=62, global_step=250
06/01/2022 21:00:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=64
06/01/2022 21:00:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.35 on epoch=67
06/01/2022 21:00:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.28 on epoch=69
06/01/2022 21:00:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.27 on epoch=72
06/01/2022 21:00:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=74
06/01/2022 21:00:31 - INFO - __main__ - Global step 300 Train loss 0.33 Classification-F1 0.6710838181426417 on epoch=74
06/01/2022 21:00:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6509653540903542 -> 0.6710838181426417 on epoch=74, global_step=300
06/01/2022 21:00:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.25 on epoch=77
06/01/2022 21:00:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=79
06/01/2022 21:00:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.22 on epoch=82
06/01/2022 21:00:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.16 on epoch=84
06/01/2022 21:00:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.16 on epoch=87
06/01/2022 21:00:45 - INFO - __main__ - Global step 350 Train loss 0.21 Classification-F1 0.6730556026488705 on epoch=87
06/01/2022 21:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6710838181426417 -> 0.6730556026488705 on epoch=87, global_step=350
06/01/2022 21:00:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.17 on epoch=89
06/01/2022 21:00:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.19 on epoch=92
06/01/2022 21:00:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
06/01/2022 21:00:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.16 on epoch=97
06/01/2022 21:00:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.13 on epoch=99
06/01/2022 21:00:59 - INFO - __main__ - Global step 400 Train loss 0.17 Classification-F1 0.6177910901916037 on epoch=99
06/01/2022 21:01:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.16 on epoch=102
06/01/2022 21:01:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=104
06/01/2022 21:01:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.20 on epoch=107
06/01/2022 21:01:09 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/01/2022 21:01:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.09 on epoch=112
06/01/2022 21:01:12 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.7446741854636592 on epoch=112
06/01/2022 21:01:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6730556026488705 -> 0.7446741854636592 on epoch=112, global_step=450
06/01/2022 21:01:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.13 on epoch=114
06/01/2022 21:01:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/01/2022 21:01:20 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/01/2022 21:01:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.10 on epoch=122
06/01/2022 21:01:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=124
06/01/2022 21:01:26 - INFO - __main__ - Global step 500 Train loss 0.10 Classification-F1 0.68246336996337 on epoch=124
06/01/2022 21:01:29 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
06/01/2022 21:01:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.07 on epoch=129
06/01/2022 21:01:34 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/01/2022 21:01:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/01/2022 21:01:39 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/01/2022 21:01:40 - INFO - __main__ - Global step 550 Train loss 0.09 Classification-F1 0.6980601892292388 on epoch=137
06/01/2022 21:01:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/01/2022 21:01:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.04 on epoch=142
06/01/2022 21:01:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.10 on epoch=144
06/01/2022 21:01:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/01/2022 21:01:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/01/2022 21:01:54 - INFO - __main__ - Global step 600 Train loss 0.07 Classification-F1 0.7204831703039165 on epoch=149
06/01/2022 21:01:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/01/2022 21:01:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/01/2022 21:02:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/01/2022 21:02:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=159
06/01/2022 21:02:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/01/2022 21:02:08 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7199493772769634 on epoch=162
06/01/2022 21:02:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
06/01/2022 21:02:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/01/2022 21:02:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/01/2022 21:02:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=172
06/01/2022 21:02:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/01/2022 21:02:22 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.6840807969529276 on epoch=174
06/01/2022 21:02:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/01/2022 21:02:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/01/2022 21:02:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.02 on epoch=182
06/01/2022 21:02:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/01/2022 21:02:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/01/2022 21:02:35 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.6731663929939793 on epoch=187
06/01/2022 21:02:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/01/2022 21:02:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/01/2022 21:02:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/01/2022 21:02:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.02 on epoch=197
06/01/2022 21:02:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.02 on epoch=199
06/01/2022 21:02:49 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.718504738858641 on epoch=199
06/01/2022 21:02:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/01/2022 21:02:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/01/2022 21:02:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/01/2022 21:02:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/01/2022 21:03:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/01/2022 21:03:03 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.6714101083429578 on epoch=212
06/01/2022 21:03:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 21:03:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/01/2022 21:03:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/01/2022 21:03:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/01/2022 21:03:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/01/2022 21:03:17 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.6482884931160794 on epoch=224
06/01/2022 21:03:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/01/2022 21:03:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/01/2022 21:03:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/01/2022 21:03:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=234
06/01/2022 21:03:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/01/2022 21:03:31 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.6197934987948668 on epoch=237
06/01/2022 21:03:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/01/2022 21:03:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 21:03:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/01/2022 21:03:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/01/2022 21:03:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/01/2022 21:03:45 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.667070952724603 on epoch=249
06/01/2022 21:03:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/01/2022 21:03:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/01/2022 21:03:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 21:03:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 21:03:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/01/2022 21:03:59 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.6709196608095113 on epoch=262
06/01/2022 21:04:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/01/2022 21:04:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 21:04:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 21:04:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/01/2022 21:04:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/01/2022 21:04:12 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6903209846001607 on epoch=274
06/01/2022 21:04:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/01/2022 21:04:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 21:04:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=282
06/01/2022 21:04:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/01/2022 21:04:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 21:04:26 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.691939286766873 on epoch=287
06/01/2022 21:04:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/01/2022 21:04:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/01/2022 21:04:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 21:04:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/01/2022 21:04:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/01/2022 21:04:40 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.6968181818181818 on epoch=299
06/01/2022 21:04:42 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 21:04:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/01/2022 21:04:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 21:04:50 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 21:04:53 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/01/2022 21:04:54 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7089545495617603 on epoch=312
06/01/2022 21:04:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/01/2022 21:04:59 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 21:05:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/01/2022 21:05:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/01/2022 21:05:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 21:05:08 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.725369532428356 on epoch=324
06/01/2022 21:05:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/01/2022 21:05:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/01/2022 21:05:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/01/2022 21:05:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/01/2022 21:05:20 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=337
06/01/2022 21:05:22 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.688293131841519 on epoch=337
06/01/2022 21:05:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 21:05:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/01/2022 21:05:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/01/2022 21:05:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/01/2022 21:05:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 21:05:36 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7123936277475298 on epoch=349
06/01/2022 21:05:38 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 21:05:41 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=354
06/01/2022 21:05:43 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 21:05:46 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/01/2022 21:05:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=362
06/01/2022 21:05:50 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7402298850574712 on epoch=362
06/01/2022 21:05:52 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/01/2022 21:05:55 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 21:05:57 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 21:06:00 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/01/2022 21:06:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/01/2022 21:06:03 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7197333916083917 on epoch=374
06/01/2022 21:06:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/01/2022 21:06:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 21:06:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/01/2022 21:06:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/01/2022 21:06:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 21:06:17 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7021820207304078 on epoch=387
06/01/2022 21:06:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 21:06:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/01/2022 21:06:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=394
06/01/2022 21:06:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 21:06:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 21:06:31 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.7038344981136743 on epoch=399
06/01/2022 21:06:34 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 21:06:36 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 21:06:39 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 21:06:41 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 21:06:44 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 21:06:45 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.688293131841519 on epoch=412
06/01/2022 21:06:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 21:06:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 21:06:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 21:06:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 21:06:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/01/2022 21:06:59 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.6967669172932331 on epoch=424
06/01/2022 21:07:02 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 21:07:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/01/2022 21:07:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 21:07:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 21:07:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 21:07:13 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.689766081871345 on epoch=437
06/01/2022 21:07:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/01/2022 21:07:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 21:07:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/01/2022 21:07:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/01/2022 21:07:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 21:07:27 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6764705882352942 on epoch=449
06/01/2022 21:07:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 21:07:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/01/2022 21:07:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 21:07:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/01/2022 21:07:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 21:07:41 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.691939286766873 on epoch=462
06/01/2022 21:07:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/01/2022 21:07:46 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 21:07:49 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 21:07:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/01/2022 21:07:54 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 21:07:55 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.683100233100233 on epoch=474
06/01/2022 21:07:58 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/01/2022 21:08:00 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 21:08:03 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 21:08:05 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 21:08:08 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/01/2022 21:08:09 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6926108374384237 on epoch=487
06/01/2022 21:08:11 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 21:08:14 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 21:08:16 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 21:08:19 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=497
06/01/2022 21:08:22 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 21:08:23 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7120980169256033 on epoch=499
06/01/2022 21:08:25 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/01/2022 21:08:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 21:08:30 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 21:08:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 21:08:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 21:08:37 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.691782753715603 on epoch=512
06/01/2022 21:08:39 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 21:08:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/01/2022 21:08:44 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/01/2022 21:08:47 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 21:08:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=524
06/01/2022 21:08:51 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.691939286766873 on epoch=524
06/01/2022 21:08:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 21:08:56 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 21:08:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 21:09:01 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 21:09:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 21:09:04 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6785047388586409 on epoch=537
06/01/2022 21:09:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 21:09:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 21:09:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=544
06/01/2022 21:09:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 21:09:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 21:09:18 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6712085910361772 on epoch=549
06/01/2022 21:09:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 21:09:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 21:09:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 21:09:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 21:09:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 21:09:33 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6977431675707537 on epoch=562
06/01/2022 21:09:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 21:09:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 21:09:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/01/2022 21:09:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 21:09:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 21:09:47 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.670755059060906 on epoch=574
06/01/2022 21:09:49 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/01/2022 21:09:52 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 21:09:54 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 21:09:57 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 21:10:00 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 21:10:01 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6721846846846846 on epoch=587
06/01/2022 21:10:03 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 21:10:06 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 21:10:08 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 21:10:11 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 21:10:13 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 21:10:15 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7065914786967419 on epoch=599
06/01/2022 21:10:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 21:10:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 21:10:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 21:10:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 21:10:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 21:10:29 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.691939286766873 on epoch=612
06/01/2022 21:10:32 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=614
06/01/2022 21:10:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 21:10:37 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 21:10:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 21:10:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 21:10:43 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6926108374384237 on epoch=624
06/01/2022 21:10:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 21:10:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 21:10:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 21:10:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 21:10:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 21:10:57 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6707550590609062 on epoch=637
06/01/2022 21:11:00 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 21:11:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/01/2022 21:11:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/01/2022 21:11:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 21:11:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 21:11:11 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7102219198993392 on epoch=649
06/01/2022 21:11:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 21:11:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/01/2022 21:11:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 21:11:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 21:11:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 21:11:25 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7132298595713229 on epoch=662
06/01/2022 21:11:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 21:11:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 21:11:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 21:11:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 21:11:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 21:11:39 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6987620343455583 on epoch=674
06/01/2022 21:11:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 21:11:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 21:11:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 21:11:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 21:11:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 21:11:53 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6987620343455583 on epoch=687
06/01/2022 21:11:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 21:11:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 21:12:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/01/2022 21:12:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 21:12:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 21:12:07 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7226425748164879 on epoch=699
06/01/2022 21:12:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/01/2022 21:12:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/01/2022 21:12:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 21:12:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 21:12:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 21:12:21 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6809848484848484 on epoch=712
06/01/2022 21:12:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=714
06/01/2022 21:12:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 21:12:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 21:12:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/01/2022 21:12:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 21:12:35 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7117999117999118 on epoch=724
06/01/2022 21:12:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 21:12:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 21:12:43 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 21:12:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 21:12:48 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 21:12:50 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7308628256904118 on epoch=737
06/01/2022 21:12:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 21:12:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 21:12:57 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=744
06/01/2022 21:13:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 21:13:02 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 21:13:03 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6842685725744196 on epoch=749
06/01/2022 21:13:04 - INFO - __main__ - save last model!
06/01/2022 21:13:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 21:13:04 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 21:13:04 - INFO - __main__ - Printing 3 examples
06/01/2022 21:13:04 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 21:13:04 - INFO - __main__ - ['others']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 21:13:04 - INFO - __main__ - ['others']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 21:13:04 - INFO - __main__ - ['others']
06/01/2022 21:13:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:13:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:13:04 - INFO - __main__ - Printing 3 examples
06/01/2022 21:13:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:13:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:13:04 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:13:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:13:04 - INFO - __main__ - Printing 3 examples
06/01/2022 21:13:04 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:13:04 - INFO - __main__ - ['sad']
06/01/2022 21:13:04 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:13:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:13:04 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:13:06 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:13:11 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 21:13:19 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:13:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:13:20 - INFO - __main__ - Starting training!
06/01/2022 21:14:49 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/01/2022 21:14:49 - INFO - __main__ - Classification-F1 on test data: 0.2330
06/01/2022 21:14:49 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.7446741854636592, test_performance=0.233024832524009
06/01/2022 21:14:49 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/01/2022 21:14:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:14:50 - INFO - __main__ - Printing 3 examples
06/01/2022 21:14:50 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:14:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:14:50 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:14:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:14:50 - INFO - __main__ - Printing 3 examples
06/01/2022 21:14:50 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:14:50 - INFO - __main__ - ['sad']
06/01/2022 21:14:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:14:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:14:50 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:15:09 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:15:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:15:10 - INFO - __main__ - Starting training!
06/01/2022 21:15:13 - INFO - __main__ - Step 10 Global step 10 Train loss 3.98 on epoch=2
06/01/2022 21:15:15 - INFO - __main__ - Step 20 Global step 20 Train loss 2.50 on epoch=4
06/01/2022 21:15:18 - INFO - __main__ - Step 30 Global step 30 Train loss 1.79 on epoch=7
06/01/2022 21:15:20 - INFO - __main__ - Step 40 Global step 40 Train loss 1.17 on epoch=9
06/01/2022 21:15:23 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=12
06/01/2022 21:15:24 - INFO - __main__ - Global step 50 Train loss 2.09 Classification-F1 0.23939393939393938 on epoch=12
06/01/2022 21:15:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23939393939393938 on epoch=12, global_step=50
06/01/2022 21:15:26 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=14
06/01/2022 21:15:29 - INFO - __main__ - Step 70 Global step 70 Train loss 0.91 on epoch=17
06/01/2022 21:15:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.96 on epoch=19
06/01/2022 21:15:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
06/01/2022 21:15:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/01/2022 21:15:37 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.1888634241575418 on epoch=24
06/01/2022 21:15:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/01/2022 21:15:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.85 on epoch=29
06/01/2022 21:15:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/01/2022 21:15:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.81 on epoch=34
06/01/2022 21:15:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=37
06/01/2022 21:15:51 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.458008658008658 on epoch=37
06/01/2022 21:15:51 - INFO - __main__ - Saving model with best Classification-F1: 0.23939393939393938 -> 0.458008658008658 on epoch=37, global_step=150
06/01/2022 21:15:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.76 on epoch=39
06/01/2022 21:15:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=42
06/01/2022 21:15:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=44
06/01/2022 21:16:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.61 on epoch=47
06/01/2022 21:16:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=49
06/01/2022 21:16:04 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.46332101806239734 on epoch=49
06/01/2022 21:16:04 - INFO - __main__ - Saving model with best Classification-F1: 0.458008658008658 -> 0.46332101806239734 on epoch=49, global_step=200
06/01/2022 21:16:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/01/2022 21:16:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/01/2022 21:16:12 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=57
06/01/2022 21:16:14 - INFO - __main__ - Step 240 Global step 240 Train loss 0.65 on epoch=59
06/01/2022 21:16:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=62
06/01/2022 21:16:18 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.6449164899257689 on epoch=62
06/01/2022 21:16:18 - INFO - __main__ - Saving model with best Classification-F1: 0.46332101806239734 -> 0.6449164899257689 on epoch=62, global_step=250
06/01/2022 21:16:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.39 on epoch=64
06/01/2022 21:16:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.45 on epoch=67
06/01/2022 21:16:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=69
06/01/2022 21:16:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=72
06/01/2022 21:16:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.31 on epoch=74
06/01/2022 21:16:31 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.5870059764796607 on epoch=74
06/01/2022 21:16:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=77
06/01/2022 21:16:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=79
06/01/2022 21:16:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/01/2022 21:16:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.27 on epoch=84
06/01/2022 21:16:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=87
06/01/2022 21:16:45 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6791125541125541 on epoch=87
06/01/2022 21:16:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6449164899257689 -> 0.6791125541125541 on epoch=87, global_step=350
06/01/2022 21:16:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/01/2022 21:16:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/01/2022 21:16:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.27 on epoch=94
06/01/2022 21:16:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.17 on epoch=97
06/01/2022 21:16:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=99
06/01/2022 21:16:58 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.6411931818181819 on epoch=99
06/01/2022 21:17:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/01/2022 21:17:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.20 on epoch=104
06/01/2022 21:17:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.16 on epoch=107
06/01/2022 21:17:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=109
06/01/2022 21:17:11 - INFO - __main__ - Step 450 Global step 450 Train loss 0.11 on epoch=112
06/01/2022 21:17:12 - INFO - __main__ - Global step 450 Train loss 0.17 Classification-F1 0.7592886178861789 on epoch=112
06/01/2022 21:17:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6791125541125541 -> 0.7592886178861789 on epoch=112, global_step=450
06/01/2022 21:17:14 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/01/2022 21:17:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=117
06/01/2022 21:17:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/01/2022 21:17:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/01/2022 21:17:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.10 on epoch=124
06/01/2022 21:17:25 - INFO - __main__ - Global step 500 Train loss 0.12 Classification-F1 0.6807623271037906 on epoch=124
06/01/2022 21:17:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
06/01/2022 21:17:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=129
06/01/2022 21:17:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/01/2022 21:17:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/01/2022 21:17:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=137
06/01/2022 21:17:39 - INFO - __main__ - Global step 550 Train loss 0.10 Classification-F1 0.7190851524467823 on epoch=137
06/01/2022 21:17:41 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/01/2022 21:17:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=142
06/01/2022 21:17:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/01/2022 21:17:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/01/2022 21:17:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.08 on epoch=149
06/01/2022 21:17:52 - INFO - __main__ - Global step 600 Train loss 0.08 Classification-F1 0.7174126129718235 on epoch=149
06/01/2022 21:17:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/01/2022 21:17:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=154
06/01/2022 21:18:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=157
06/01/2022 21:18:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
06/01/2022 21:18:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.09 on epoch=162
06/01/2022 21:18:06 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.6812371211269717 on epoch=162
06/01/2022 21:18:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.10 on epoch=164
06/01/2022 21:18:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/01/2022 21:18:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/01/2022 21:18:16 - INFO - __main__ - Step 690 Global step 690 Train loss 0.03 on epoch=172
06/01/2022 21:18:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/01/2022 21:18:20 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.7181436071238703 on epoch=174
06/01/2022 21:18:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.06 on epoch=177
06/01/2022 21:18:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/01/2022 21:18:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/01/2022 21:18:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/01/2022 21:18:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/01/2022 21:18:33 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7089247557997558 on epoch=187
06/01/2022 21:18:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/01/2022 21:18:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/01/2022 21:18:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/01/2022 21:18:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/01/2022 21:18:46 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/01/2022 21:18:47 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.7365559462333656 on epoch=199
06/01/2022 21:18:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/01/2022 21:18:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/01/2022 21:18:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/01/2022 21:18:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/01/2022 21:19:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/01/2022 21:19:01 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7231694828469022 on epoch=212
06/01/2022 21:19:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/01/2022 21:19:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/01/2022 21:19:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/01/2022 21:19:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/01/2022 21:19:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/01/2022 21:19:15 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.7613085132185302 on epoch=224
06/01/2022 21:19:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7592886178861789 -> 0.7613085132185302 on epoch=224, global_step=900
06/01/2022 21:19:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/01/2022 21:19:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/01/2022 21:19:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/01/2022 21:19:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/01/2022 21:19:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 21:19:29 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.7175106143856144 on epoch=237
06/01/2022 21:19:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/01/2022 21:19:34 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 21:19:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/01/2022 21:19:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/01/2022 21:19:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/01/2022 21:19:43 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.739873310420295 on epoch=249
06/01/2022 21:19:45 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 21:19:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/01/2022 21:19:50 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 21:19:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 21:19:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/01/2022 21:19:57 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.7084710408553665 on epoch=262
06/01/2022 21:19:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/01/2022 21:20:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 21:20:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 21:20:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/01/2022 21:20:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.03 on epoch=274
06/01/2022 21:20:10 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7645161290322581 on epoch=274
06/01/2022 21:20:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7613085132185302 -> 0.7645161290322581 on epoch=274, global_step=1100
06/01/2022 21:20:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/01/2022 21:20:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/01/2022 21:20:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/01/2022 21:20:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/01/2022 21:20:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 21:20:24 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7349747474747474 on epoch=287
06/01/2022 21:20:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/01/2022 21:20:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/01/2022 21:20:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 21:20:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/01/2022 21:20:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 21:20:38 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7674201251646904 on epoch=299
06/01/2022 21:20:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7645161290322581 -> 0.7674201251646904 on epoch=299, global_step=1200
06/01/2022 21:20:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 21:20:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/01/2022 21:20:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 21:20:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 21:20:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/01/2022 21:20:52 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7260915607689802 on epoch=312
06/01/2022 21:20:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 21:20:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/01/2022 21:20:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 21:21:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/01/2022 21:21:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 21:21:05 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7171998732974343 on epoch=324
06/01/2022 21:21:08 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/01/2022 21:21:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/01/2022 21:21:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/01/2022 21:21:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/01/2022 21:21:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/01/2022 21:21:19 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7075519232083077 on epoch=337
06/01/2022 21:21:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 21:21:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 21:21:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=344
06/01/2022 21:21:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/01/2022 21:21:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/01/2022 21:21:33 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7497420020639836 on epoch=349
06/01/2022 21:21:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/01/2022 21:21:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/01/2022 21:21:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/01/2022 21:21:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/01/2022 21:21:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 21:21:47 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7088530118255728 on epoch=362
06/01/2022 21:21:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/01/2022 21:21:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 21:21:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 21:21:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/01/2022 21:22:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/01/2022 21:22:02 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7084710408553665 on epoch=374
06/01/2022 21:22:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/01/2022 21:22:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/01/2022 21:22:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 21:22:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 21:22:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 21:22:16 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7658252288329519 on epoch=387
06/01/2022 21:22:18 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/01/2022 21:22:21 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 21:22:23 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/01/2022 21:22:26 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/01/2022 21:22:28 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 21:22:29 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.746041055718475 on epoch=399
06/01/2022 21:22:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 21:22:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 21:22:37 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 21:22:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 21:22:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 21:22:43 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.766997827867393 on epoch=412
06/01/2022 21:22:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 21:22:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 21:22:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 21:22:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 21:22:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 21:22:57 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7592384268030821 on epoch=424
06/01/2022 21:22:59 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 21:23:02 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 21:23:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/01/2022 21:23:07 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 21:23:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 21:23:10 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.7590111642743221 on epoch=437
06/01/2022 21:23:13 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 21:23:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=442
06/01/2022 21:23:18 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/01/2022 21:23:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/01/2022 21:23:23 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 21:23:24 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7472052845528455 on epoch=449
06/01/2022 21:23:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 21:23:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 21:23:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 21:23:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 21:23:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 21:23:38 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.7546687720881269 on epoch=462
06/01/2022 21:23:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/01/2022 21:23:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 21:23:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 21:23:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 21:23:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 21:23:52 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7713782051282051 on epoch=474
06/01/2022 21:23:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7674201251646904 -> 0.7713782051282051 on epoch=474, global_step=1900
06/01/2022 21:23:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 21:23:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 21:23:59 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 21:24:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 21:24:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 21:24:05 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7178806700545831 on epoch=487
06/01/2022 21:24:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 21:24:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 21:24:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 21:24:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 21:24:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 21:24:19 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7602418414918415 on epoch=499
06/01/2022 21:24:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 21:24:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 21:24:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 21:24:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=509
06/01/2022 21:24:34 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 21:24:35 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7481522542498151 on epoch=512
06/01/2022 21:24:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/01/2022 21:24:40 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 21:24:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/01/2022 21:24:45 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 21:24:48 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 21:24:49 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7805899315150786 on epoch=524
06/01/2022 21:24:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7713782051282051 -> 0.7805899315150786 on epoch=524, global_step=2100
06/01/2022 21:24:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=527
06/01/2022 21:24:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 21:24:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/01/2022 21:24:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 21:25:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 21:25:03 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7404977422003285 on epoch=537
06/01/2022 21:25:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 21:25:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/01/2022 21:25:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 21:25:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 21:25:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/01/2022 21:25:17 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7449921773967461 on epoch=549
06/01/2022 21:25:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 21:25:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 21:25:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 21:25:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 21:25:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 21:25:30 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7193798449612403 on epoch=562
06/01/2022 21:25:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 21:25:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 21:25:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 21:25:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 21:25:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 21:25:45 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7445410401002507 on epoch=574
06/01/2022 21:25:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 21:25:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 21:25:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 21:25:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 21:25:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 21:25:59 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7665213107575537 on epoch=587
06/01/2022 21:26:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 21:26:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 21:26:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 21:26:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 21:26:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 21:26:13 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7665213107575537 on epoch=599
06/01/2022 21:26:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 21:26:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/01/2022 21:26:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 21:26:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 21:26:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 21:26:26 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7391443863218057 on epoch=612
06/01/2022 21:26:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 21:26:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 21:26:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 21:26:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 21:26:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 21:26:40 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7469235970250169 on epoch=624
06/01/2022 21:26:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 21:26:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 21:26:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 21:26:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 21:26:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 21:26:54 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7379249815225425 on epoch=637
06/01/2022 21:26:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 21:26:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 21:27:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 21:27:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 21:27:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 21:27:08 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7610047846889952 on epoch=649
06/01/2022 21:27:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 21:27:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.17 on epoch=654
06/01/2022 21:27:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 21:27:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 21:27:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 21:27:22 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7379249815225425 on epoch=662
06/01/2022 21:27:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 21:27:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 21:27:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 21:27:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 21:27:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 21:27:36 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7379249815225425 on epoch=674
06/01/2022 21:27:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 21:27:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/01/2022 21:27:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/01/2022 21:27:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 21:27:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 21:27:50 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7336898777502006 on epoch=687
06/01/2022 21:27:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/01/2022 21:27:55 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 21:27:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 21:28:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 21:28:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 21:28:04 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7736343421461389 on epoch=699
06/01/2022 21:28:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 21:28:09 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 21:28:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 21:28:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 21:28:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 21:28:18 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7934383903133903 on epoch=712
06/01/2022 21:28:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7805899315150786 -> 0.7934383903133903 on epoch=712, global_step=2850
06/01/2022 21:28:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/01/2022 21:28:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 21:28:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 21:28:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 21:28:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/01/2022 21:28:32 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8085139203294975 on epoch=724
06/01/2022 21:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7934383903133903 -> 0.8085139203294975 on epoch=724, global_step=2900
06/01/2022 21:28:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 21:28:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 21:28:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 21:28:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 21:28:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 21:28:45 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7741397150648622 on epoch=737
06/01/2022 21:28:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/01/2022 21:28:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/01/2022 21:28:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 21:28:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 21:28:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 21:28:59 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7779869370525656 on epoch=749
06/01/2022 21:28:59 - INFO - __main__ - save last model!
06/01/2022 21:28:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 21:28:59 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 21:28:59 - INFO - __main__ - Printing 3 examples
06/01/2022 21:28:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 21:28:59 - INFO - __main__ - ['others']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 21:28:59 - INFO - __main__ - ['others']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 21:28:59 - INFO - __main__ - ['others']
06/01/2022 21:28:59 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:28:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:28:59 - INFO - __main__ - Printing 3 examples
06/01/2022 21:28:59 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:28:59 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:28:59 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:28:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:28:59 - INFO - __main__ - Printing 3 examples
06/01/2022 21:28:59 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:28:59 - INFO - __main__ - ['sad']
06/01/2022 21:28:59 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:28:59 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:28:59 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:29:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:29:07 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 21:29:15 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:29:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:29:16 - INFO - __main__ - Starting training!
06/01/2022 21:30:43 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/01/2022 21:30:43 - INFO - __main__ - Classification-F1 on test data: 0.1754
06/01/2022 21:30:43 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.8085139203294975, test_performance=0.17541043143608573
06/01/2022 21:30:43 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/01/2022 21:30:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:30:44 - INFO - __main__ - Printing 3 examples
06/01/2022 21:30:44 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:30:44 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:30:44 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:30:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:30:44 - INFO - __main__ - Printing 3 examples
06/01/2022 21:30:44 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:30:44 - INFO - __main__ - ['sad']
06/01/2022 21:30:44 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:30:44 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:30:44 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:31:00 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:31:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:31:01 - INFO - __main__ - Starting training!
06/01/2022 21:31:04 - INFO - __main__ - Step 10 Global step 10 Train loss 4.21 on epoch=2
06/01/2022 21:31:07 - INFO - __main__ - Step 20 Global step 20 Train loss 2.74 on epoch=4
06/01/2022 21:31:09 - INFO - __main__ - Step 30 Global step 30 Train loss 2.11 on epoch=7
06/01/2022 21:31:12 - INFO - __main__ - Step 40 Global step 40 Train loss 1.62 on epoch=9
06/01/2022 21:31:14 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=12
06/01/2022 21:31:15 - INFO - __main__ - Global step 50 Train loss 2.38 Classification-F1 0.2331745086360929 on epoch=12
06/01/2022 21:31:15 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2331745086360929 on epoch=12, global_step=50
06/01/2022 21:31:18 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=14
06/01/2022 21:31:20 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=17
06/01/2022 21:31:23 - INFO - __main__ - Step 80 Global step 80 Train loss 0.91 on epoch=19
06/01/2022 21:31:25 - INFO - __main__ - Step 90 Global step 90 Train loss 0.92 on epoch=22
06/01/2022 21:31:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=24
06/01/2022 21:31:29 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.38888888888888895 on epoch=24
06/01/2022 21:31:29 - INFO - __main__ - Saving model with best Classification-F1: 0.2331745086360929 -> 0.38888888888888895 on epoch=24, global_step=100
06/01/2022 21:31:31 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=27
06/01/2022 21:31:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.74 on epoch=29
06/01/2022 21:31:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/01/2022 21:31:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=34
06/01/2022 21:31:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=37
06/01/2022 21:31:42 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.4458996328029376 on epoch=37
06/01/2022 21:31:42 - INFO - __main__ - Saving model with best Classification-F1: 0.38888888888888895 -> 0.4458996328029376 on epoch=37, global_step=150
06/01/2022 21:31:45 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=39
06/01/2022 21:31:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.71 on epoch=42
06/01/2022 21:31:50 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=44
06/01/2022 21:31:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=47
06/01/2022 21:31:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.59 on epoch=49
06/01/2022 21:31:56 - INFO - __main__ - Global step 200 Train loss 0.72 Classification-F1 0.4877906976744186 on epoch=49
06/01/2022 21:31:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4458996328029376 -> 0.4877906976744186 on epoch=49, global_step=200
06/01/2022 21:31:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=52
06/01/2022 21:32:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/01/2022 21:32:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=57
06/01/2022 21:32:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.48 on epoch=59
06/01/2022 21:32:08 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/01/2022 21:32:09 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.5402436341637793 on epoch=62
06/01/2022 21:32:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4877906976744186 -> 0.5402436341637793 on epoch=62, global_step=250
06/01/2022 21:32:12 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=64
06/01/2022 21:32:14 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=67
06/01/2022 21:32:17 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=69
06/01/2022 21:32:19 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=72
06/01/2022 21:32:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=74
06/01/2022 21:32:23 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.6046970357454229 on epoch=74
06/01/2022 21:32:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5402436341637793 -> 0.6046970357454229 on epoch=74, global_step=300
06/01/2022 21:32:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=77
06/01/2022 21:32:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=79
06/01/2022 21:32:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/01/2022 21:32:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=84
06/01/2022 21:32:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=87
06/01/2022 21:32:36 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.6513250976665611 on epoch=87
06/01/2022 21:32:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6046970357454229 -> 0.6513250976665611 on epoch=87, global_step=350
06/01/2022 21:32:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=89
06/01/2022 21:32:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/01/2022 21:32:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/01/2022 21:32:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=97
06/01/2022 21:32:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=99
06/01/2022 21:32:50 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.6424053492364687 on epoch=99
06/01/2022 21:32:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=102
06/01/2022 21:32:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=104
06/01/2022 21:32:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=107
06/01/2022 21:33:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/01/2022 21:33:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.18 on epoch=112
06/01/2022 21:33:03 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.6390058217644424 on epoch=112
06/01/2022 21:33:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/01/2022 21:33:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.18 on epoch=117
06/01/2022 21:33:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/01/2022 21:33:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/01/2022 21:33:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=124
06/01/2022 21:33:17 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6433423854476487 on epoch=124
06/01/2022 21:33:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.11 on epoch=127
06/01/2022 21:33:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=129
06/01/2022 21:33:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=132
06/01/2022 21:33:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/01/2022 21:33:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.14 on epoch=137
06/01/2022 21:33:30 - INFO - __main__ - Global step 550 Train loss 0.12 Classification-F1 0.6264200532493216 on epoch=137
06/01/2022 21:33:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/01/2022 21:33:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/01/2022 21:33:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=144
06/01/2022 21:33:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.14 on epoch=147
06/01/2022 21:33:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.07 on epoch=149
06/01/2022 21:33:44 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.6498304941096702 on epoch=149
06/01/2022 21:33:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=152
06/01/2022 21:33:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=154
06/01/2022 21:33:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/01/2022 21:33:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/01/2022 21:33:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/01/2022 21:33:58 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.6801868862844471 on epoch=162
06/01/2022 21:33:58 - INFO - __main__ - Saving model with best Classification-F1: 0.6513250976665611 -> 0.6801868862844471 on epoch=162, global_step=650
06/01/2022 21:34:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.07 on epoch=164
06/01/2022 21:34:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/01/2022 21:34:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
06/01/2022 21:34:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=172
06/01/2022 21:34:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.10 on epoch=174
06/01/2022 21:34:11 - INFO - __main__ - Global step 700 Train loss 0.09 Classification-F1 0.6937014966740576 on epoch=174
06/01/2022 21:34:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6801868862844471 -> 0.6937014966740576 on epoch=174, global_step=700
06/01/2022 21:34:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
06/01/2022 21:34:16 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/01/2022 21:34:19 - INFO - __main__ - Step 730 Global step 730 Train loss 0.06 on epoch=182
06/01/2022 21:34:21 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/01/2022 21:34:24 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/01/2022 21:34:25 - INFO - __main__ - Global step 750 Train loss 0.06 Classification-F1 0.6823215332466803 on epoch=187
06/01/2022 21:34:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/01/2022 21:34:30 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/01/2022 21:34:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/01/2022 21:34:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/01/2022 21:34:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/01/2022 21:34:39 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.7087302292894397 on epoch=199
06/01/2022 21:34:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6937014966740576 -> 0.7087302292894397 on epoch=199, global_step=800
06/01/2022 21:34:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.06 on epoch=202
06/01/2022 21:34:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/01/2022 21:34:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/01/2022 21:34:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/01/2022 21:34:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/01/2022 21:34:53 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6786133221617092 on epoch=212
06/01/2022 21:34:56 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 21:34:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/01/2022 21:35:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/01/2022 21:35:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/01/2022 21:35:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/01/2022 21:35:07 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.6801868862844471 on epoch=224
06/01/2022 21:35:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.04 on epoch=227
06/01/2022 21:35:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/01/2022 21:35:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/01/2022 21:35:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/01/2022 21:35:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/01/2022 21:35:21 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.6824079429342587 on epoch=237
06/01/2022 21:35:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/01/2022 21:35:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/01/2022 21:35:29 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=244
06/01/2022 21:35:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/01/2022 21:35:34 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=249
06/01/2022 21:35:35 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6821427265461346 on epoch=249
06/01/2022 21:35:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 21:35:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/01/2022 21:35:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 21:35:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 21:35:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/01/2022 21:35:49 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.7113917924893535 on epoch=262
06/01/2022 21:35:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7087302292894397 -> 0.7113917924893535 on epoch=262, global_step=1050
06/01/2022 21:35:51 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/01/2022 21:35:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 21:35:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 21:35:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 21:36:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/01/2022 21:36:03 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.6826950775226638 on epoch=274
06/01/2022 21:36:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/01/2022 21:36:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 21:36:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/01/2022 21:36:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/01/2022 21:36:15 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 21:36:17 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6826950775226638 on epoch=287
06/01/2022 21:36:19 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/01/2022 21:36:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/01/2022 21:36:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/01/2022 21:36:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/01/2022 21:36:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/01/2022 21:36:30 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.684918529746116 on epoch=299
06/01/2022 21:36:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/01/2022 21:36:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/01/2022 21:36:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 21:36:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 21:36:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/01/2022 21:36:44 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.6826950775226638 on epoch=312
06/01/2022 21:36:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 21:36:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/01/2022 21:36:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 21:36:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/01/2022 21:36:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 21:36:58 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6681471655727949 on epoch=324
06/01/2022 21:37:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/01/2022 21:37:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 21:37:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/01/2022 21:37:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/01/2022 21:37:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 21:37:12 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6826950775226638 on epoch=337
06/01/2022 21:37:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 21:37:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/01/2022 21:37:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/01/2022 21:37:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/01/2022 21:37:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/01/2022 21:37:26 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.6947423544197737 on epoch=349
06/01/2022 21:37:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 21:37:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 21:37:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 21:37:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/01/2022 21:37:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 21:37:40 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6983125918243887 on epoch=362
06/01/2022 21:37:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/01/2022 21:37:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/01/2022 21:37:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/01/2022 21:37:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/01/2022 21:37:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/01/2022 21:37:54 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6990746096009255 on epoch=374
06/01/2022 21:37:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/01/2022 21:37:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/01/2022 21:38:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 21:38:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 21:38:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/01/2022 21:38:08 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.6843366778149387 on epoch=387
06/01/2022 21:38:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/01/2022 21:38:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 21:38:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/01/2022 21:38:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 21:38:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=399
06/01/2022 21:38:22 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6826950775226638 on epoch=399
06/01/2022 21:38:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 21:38:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/01/2022 21:38:31 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 21:38:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/01/2022 21:38:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/01/2022 21:38:37 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7250530171582803 on epoch=412
06/01/2022 21:38:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7113917924893535 -> 0.7250530171582803 on epoch=412, global_step=1650
06/01/2022 21:38:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/01/2022 21:38:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 21:38:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 21:38:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 21:38:51 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 21:38:52 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6967908902691511 on epoch=424
06/01/2022 21:38:55 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 21:38:58 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/01/2022 21:39:00 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 21:39:03 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 21:39:05 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 21:39:07 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6969548582953861 on epoch=437
06/01/2022 21:39:09 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 21:39:12 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 21:39:14 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 21:39:17 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/01/2022 21:39:19 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 21:39:21 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6934375552022611 on epoch=449
06/01/2022 21:39:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/01/2022 21:39:26 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 21:39:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/01/2022 21:39:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 21:39:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/01/2022 21:39:34 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6828825711884183 on epoch=462
06/01/2022 21:39:37 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 21:39:40 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/01/2022 21:39:42 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 21:39:45 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 21:39:47 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 21:39:48 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6977695675971538 on epoch=474
06/01/2022 21:39:51 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 21:39:53 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 21:39:56 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=482
06/01/2022 21:39:58 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 21:40:01 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 21:40:02 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6969548582953861 on epoch=487
06/01/2022 21:40:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 21:40:07 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 21:40:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 21:40:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/01/2022 21:40:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 21:40:16 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6821427265461346 on epoch=499
06/01/2022 21:40:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 21:40:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 21:40:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 21:40:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 21:40:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 21:40:30 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6969548582953861 on epoch=512
06/01/2022 21:40:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 21:40:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/01/2022 21:40:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 21:40:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 21:40:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 21:40:44 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6910781595899564 on epoch=524
06/01/2022 21:40:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 21:40:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 21:40:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/01/2022 21:40:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 21:40:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 21:40:58 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6823215332466803 on epoch=537
06/01/2022 21:41:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 21:41:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 21:41:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=544
06/01/2022 21:41:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 21:41:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 21:41:12 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7058902913392078 on epoch=549
06/01/2022 21:41:14 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/01/2022 21:41:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 21:41:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 21:41:22 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 21:41:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 21:41:26 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6652298850574712 on epoch=562
06/01/2022 21:41:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=564
06/01/2022 21:41:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/01/2022 21:41:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 21:41:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 21:41:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/01/2022 21:41:40 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6649988848264711 on epoch=574
06/01/2022 21:41:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/01/2022 21:41:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 21:41:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 21:41:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 21:41:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 21:41:53 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.691801188802688 on epoch=587
06/01/2022 21:41:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 21:41:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 21:42:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/01/2022 21:42:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 21:42:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 21:42:07 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.658147144422099 on epoch=599
06/01/2022 21:42:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/01/2022 21:42:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 21:42:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/01/2022 21:42:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/01/2022 21:42:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/01/2022 21:42:22 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6797619047619048 on epoch=612
06/01/2022 21:42:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 21:42:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 21:42:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/01/2022 21:42:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 21:42:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 21:42:35 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6969548582953861 on epoch=624
06/01/2022 21:42:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 21:42:40 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.16 on epoch=629
06/01/2022 21:42:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/01/2022 21:42:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 21:42:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 21:42:49 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6714480597539068 on epoch=637
06/01/2022 21:42:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 21:42:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 21:42:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 21:42:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 21:43:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 21:43:03 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6435124974598658 on epoch=649
06/01/2022 21:43:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 21:43:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 21:43:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 21:43:13 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 21:43:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 21:43:17 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.669039294039294 on epoch=662
06/01/2022 21:43:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 21:43:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 21:43:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 21:43:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 21:43:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/01/2022 21:43:31 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6984064155688869 on epoch=674
06/01/2022 21:43:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 21:43:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 21:43:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 21:43:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 21:43:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 21:43:45 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6987573099415204 on epoch=687
06/01/2022 21:43:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 21:43:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 21:43:53 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/01/2022 21:43:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/01/2022 21:43:58 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 21:43:59 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6845680030797998 on epoch=699
06/01/2022 21:44:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 21:44:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 21:44:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 21:44:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 21:44:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 21:44:13 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.637936753648828 on epoch=712
06/01/2022 21:44:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 21:44:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 21:44:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 21:44:23 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/01/2022 21:44:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 21:44:27 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6854636591478696 on epoch=724
06/01/2022 21:44:29 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 21:44:32 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 21:44:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=732
06/01/2022 21:44:37 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.12 on epoch=734
06/01/2022 21:44:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 21:44:41 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6788877737153599 on epoch=737
06/01/2022 21:44:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/01/2022 21:44:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 21:44:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 21:44:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 21:44:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 21:44:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:44:55 - INFO - __main__ - Printing 3 examples
06/01/2022 21:44:55 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:44:55 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.726036036036036 on epoch=749
06/01/2022 21:44:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:44:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7250530171582803 -> 0.726036036036036 on epoch=749, global_step=3000
06/01/2022 21:44:55 - INFO - __main__ - save last model!
06/01/2022 21:44:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 21:44:55 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 21:44:55 - INFO - __main__ - Printing 3 examples
06/01/2022 21:44:55 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 21:44:55 - INFO - __main__ - ['others']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 21:44:55 - INFO - __main__ - ['others']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 21:44:55 - INFO - __main__ - ['others']
06/01/2022 21:44:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:44:55 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:44:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:44:55 - INFO - __main__ - Printing 3 examples
06/01/2022 21:44:55 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:44:55 - INFO - __main__ - ['sad']
06/01/2022 21:44:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:44:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:44:55 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:44:57 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:45:03 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 21:45:14 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:45:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:45:15 - INFO - __main__ - Starting training!
06/01/2022 21:46:40 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/01/2022 21:46:40 - INFO - __main__ - Classification-F1 on test data: 0.1428
06/01/2022 21:46:40 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.726036036036036, test_performance=0.14283182285319784
06/01/2022 21:46:40 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/01/2022 21:46:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:46:41 - INFO - __main__ - Printing 3 examples
06/01/2022 21:46:41 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/01/2022 21:46:41 - INFO - __main__ - ['sad']
06/01/2022 21:46:41 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/01/2022 21:46:41 - INFO - __main__ - ['sad']
06/01/2022 21:46:41 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/01/2022 21:46:41 - INFO - __main__ - ['sad']
06/01/2022 21:46:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:46:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:46:42 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 21:46:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 21:46:42 - INFO - __main__ - Printing 3 examples
06/01/2022 21:46:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/01/2022 21:46:42 - INFO - __main__ - ['sad']
06/01/2022 21:46:42 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/01/2022 21:46:42 - INFO - __main__ - ['sad']
06/01/2022 21:46:42 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/01/2022 21:46:42 - INFO - __main__ - ['sad']
06/01/2022 21:46:42 - INFO - __main__ - Tokenizing Input ...
06/01/2022 21:46:42 - INFO - __main__ - Tokenizing Output ...
06/01/2022 21:46:42 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 21:46:57 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 21:46:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 21:46:58 - INFO - __main__ - Starting training!
06/01/2022 21:47:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.50 on epoch=2
06/01/2022 21:47:03 - INFO - __main__ - Step 20 Global step 20 Train loss 3.37 on epoch=4
06/01/2022 21:47:06 - INFO - __main__ - Step 30 Global step 30 Train loss 2.74 on epoch=7
06/01/2022 21:47:09 - INFO - __main__ - Step 40 Global step 40 Train loss 2.08 on epoch=9
06/01/2022 21:47:11 - INFO - __main__ - Step 50 Global step 50 Train loss 1.80 on epoch=12
06/01/2022 21:47:12 - INFO - __main__ - Global step 50 Train loss 2.90 Classification-F1 0.13067758749069247 on epoch=12
06/01/2022 21:47:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
06/01/2022 21:47:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=14
06/01/2022 21:47:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.28 on epoch=17
06/01/2022 21:47:20 - INFO - __main__ - Step 80 Global step 80 Train loss 1.04 on epoch=19
06/01/2022 21:47:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=22
06/01/2022 21:47:25 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/01/2022 21:47:26 - INFO - __main__ - Global step 100 Train loss 1.13 Classification-F1 0.14621798689696247 on epoch=24
06/01/2022 21:47:26 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.14621798689696247 on epoch=24, global_step=100
06/01/2022 21:47:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=27
06/01/2022 21:47:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=29
06/01/2022 21:47:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/01/2022 21:47:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=34
06/01/2022 21:47:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=37
06/01/2022 21:47:39 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.23275796805208568 on epoch=37
06/01/2022 21:47:39 - INFO - __main__ - Saving model with best Classification-F1: 0.14621798689696247 -> 0.23275796805208568 on epoch=37, global_step=150
06/01/2022 21:47:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=39
06/01/2022 21:47:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=42
06/01/2022 21:47:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=44
06/01/2022 21:47:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=47
06/01/2022 21:47:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=49
06/01/2022 21:47:53 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.4331168831168831 on epoch=49
06/01/2022 21:47:53 - INFO - __main__ - Saving model with best Classification-F1: 0.23275796805208568 -> 0.4331168831168831 on epoch=49, global_step=200
06/01/2022 21:47:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=52
06/01/2022 21:47:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=54
06/01/2022 21:48:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=57
06/01/2022 21:48:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=59
06/01/2022 21:48:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.81 on epoch=62
06/01/2022 21:48:07 - INFO - __main__ - Global step 250 Train loss 0.81 Classification-F1 0.3995290745290745 on epoch=62
06/01/2022 21:48:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=64
06/01/2022 21:48:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.82 on epoch=67
06/01/2022 21:48:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/01/2022 21:48:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=72
06/01/2022 21:48:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=74
06/01/2022 21:48:20 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.4794117647058823 on epoch=74
06/01/2022 21:48:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4331168831168831 -> 0.4794117647058823 on epoch=74, global_step=300
06/01/2022 21:48:23 - INFO - __main__ - Step 310 Global step 310 Train loss 0.65 on epoch=77
06/01/2022 21:48:26 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=79
06/01/2022 21:48:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=82
06/01/2022 21:48:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.46 on epoch=84
06/01/2022 21:48:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=87
06/01/2022 21:48:34 - INFO - __main__ - Global step 350 Train loss 0.57 Classification-F1 0.5327288810260946 on epoch=87
06/01/2022 21:48:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4794117647058823 -> 0.5327288810260946 on epoch=87, global_step=350
06/01/2022 21:48:37 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=89
06/01/2022 21:48:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=92
06/01/2022 21:48:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=94
06/01/2022 21:48:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.59 on epoch=97
06/01/2022 21:48:47 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=99
06/01/2022 21:48:48 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6163950991537197 on epoch=99
06/01/2022 21:48:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5327288810260946 -> 0.6163950991537197 on epoch=99, global_step=400
06/01/2022 21:48:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=102
06/01/2022 21:48:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=104
06/01/2022 21:48:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=107
06/01/2022 21:48:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=109
06/01/2022 21:49:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=112
06/01/2022 21:49:02 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.6262488992752151 on epoch=112
06/01/2022 21:49:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6163950991537197 -> 0.6262488992752151 on epoch=112, global_step=450
06/01/2022 21:49:04 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=114
06/01/2022 21:49:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=117
06/01/2022 21:49:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=119
06/01/2022 21:49:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=122
06/01/2022 21:49:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=124
06/01/2022 21:49:15 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.5880081300813008 on epoch=124
06/01/2022 21:49:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=127
06/01/2022 21:49:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=129
06/01/2022 21:49:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=132
06/01/2022 21:49:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/01/2022 21:49:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/01/2022 21:49:29 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.6809446192335392 on epoch=137
06/01/2022 21:49:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6262488992752151 -> 0.6809446192335392 on epoch=137, global_step=550
06/01/2022 21:49:32 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/01/2022 21:49:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=142
06/01/2022 21:49:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/01/2022 21:49:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/01/2022 21:49:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=149
06/01/2022 21:49:43 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.6010416666666666 on epoch=149
06/01/2022 21:49:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=152
06/01/2022 21:49:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=154
06/01/2022 21:49:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/01/2022 21:49:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.16 on epoch=159
06/01/2022 21:49:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=162
06/01/2022 21:49:56 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.6530566280566281 on epoch=162
06/01/2022 21:49:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/01/2022 21:50:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/01/2022 21:50:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=169
06/01/2022 21:50:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=172
06/01/2022 21:50:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/01/2022 21:50:10 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6118561489931725 on epoch=174
06/01/2022 21:50:12 - INFO - __main__ - Step 710 Global step 710 Train loss 0.08 on epoch=177
06/01/2022 21:50:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=179
06/01/2022 21:50:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=182
06/01/2022 21:50:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/01/2022 21:50:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=187
06/01/2022 21:50:24 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6927693629730981 on epoch=187
06/01/2022 21:50:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6809446192335392 -> 0.6927693629730981 on epoch=187, global_step=750
06/01/2022 21:50:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=189
06/01/2022 21:50:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/01/2022 21:50:31 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/01/2022 21:50:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/01/2022 21:50:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=199
06/01/2022 21:50:37 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.6420361247947455 on epoch=199
06/01/2022 21:50:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=202
06/01/2022 21:50:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=204
06/01/2022 21:50:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=207
06/01/2022 21:50:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=209
06/01/2022 21:50:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/01/2022 21:50:51 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6789460539460539 on epoch=212
06/01/2022 21:50:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/01/2022 21:50:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/01/2022 21:50:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/01/2022 21:51:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=222
06/01/2022 21:51:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/01/2022 21:51:05 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6571428571428573 on epoch=224
06/01/2022 21:51:07 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/01/2022 21:51:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/01/2022 21:51:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/01/2022 21:51:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/01/2022 21:51:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/01/2022 21:51:18 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.6681515616999488 on epoch=237
06/01/2022 21:51:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/01/2022 21:51:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/01/2022 21:51:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/01/2022 21:51:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/01/2022 21:51:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/01/2022 21:51:32 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6527176527176527 on epoch=249
06/01/2022 21:51:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
06/01/2022 21:51:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=254
06/01/2022 21:51:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=257
06/01/2022 21:51:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/01/2022 21:51:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/01/2022 21:51:46 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6631268172015201 on epoch=262
06/01/2022 21:51:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/01/2022 21:51:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=267
06/01/2022 21:51:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=269
06/01/2022 21:51:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/01/2022 21:51:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/01/2022 21:52:00 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7016963155524972 on epoch=274
06/01/2022 21:52:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6927693629730981 -> 0.7016963155524972 on epoch=274, global_step=1100
06/01/2022 21:52:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=277
06/01/2022 21:52:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/01/2022 21:52:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/01/2022 21:52:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/01/2022 21:52:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/01/2022 21:52:15 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7044191919191919 on epoch=287
06/01/2022 21:52:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7016963155524972 -> 0.7044191919191919 on epoch=287, global_step=1150
06/01/2022 21:52:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/01/2022 21:52:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=292
06/01/2022 21:52:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=294
06/01/2022 21:52:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/01/2022 21:52:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/01/2022 21:52:30 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.6784688995215311 on epoch=299
06/01/2022 21:52:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/01/2022 21:52:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 21:52:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/01/2022 21:52:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/01/2022 21:52:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/01/2022 21:52:44 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6773264742014742 on epoch=312
06/01/2022 21:52:47 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/01/2022 21:52:50 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/01/2022 21:52:52 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/01/2022 21:52:55 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/01/2022 21:52:57 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 21:52:58 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6937999991539012 on epoch=324
06/01/2022 21:53:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/01/2022 21:53:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=329
06/01/2022 21:53:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/01/2022 21:53:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/01/2022 21:53:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/01/2022 21:53:12 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6651924651924652 on epoch=337
06/01/2022 21:53:15 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/01/2022 21:53:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/01/2022 21:53:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/01/2022 21:53:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 21:53:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 21:53:26 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7464264662540525 on epoch=349
06/01/2022 21:53:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7044191919191919 -> 0.7464264662540525 on epoch=349, global_step=1400
06/01/2022 21:53:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/01/2022 21:53:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 21:53:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/01/2022 21:53:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/01/2022 21:53:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/01/2022 21:53:40 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7334494203822697 on epoch=362
06/01/2022 21:53:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=364
06/01/2022 21:53:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=367
06/01/2022 21:53:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=369
06/01/2022 21:53:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/01/2022 21:53:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/01/2022 21:53:54 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6989022202981013 on epoch=374
06/01/2022 21:53:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=377
06/01/2022 21:53:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/01/2022 21:54:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/01/2022 21:54:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=384
06/01/2022 21:54:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/01/2022 21:54:08 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7310786060786061 on epoch=387
06/01/2022 21:54:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/01/2022 21:54:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 21:54:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 21:54:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=397
06/01/2022 21:54:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 21:54:22 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.7314327485380117 on epoch=399
06/01/2022 21:54:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 21:54:27 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 21:54:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/01/2022 21:54:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 21:54:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/01/2022 21:54:36 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7120601150349434 on epoch=412
06/01/2022 21:54:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/01/2022 21:54:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 21:54:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/01/2022 21:54:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/01/2022 21:54:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/01/2022 21:54:50 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.69393586376345 on epoch=424
06/01/2022 21:54:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 21:54:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=429
06/01/2022 21:54:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 21:55:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/01/2022 21:55:03 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=437
06/01/2022 21:55:04 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8036168132942326 on epoch=437
06/01/2022 21:55:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7464264662540525 -> 0.8036168132942326 on epoch=437, global_step=1750
06/01/2022 21:55:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/01/2022 21:55:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/01/2022 21:55:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/01/2022 21:55:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/01/2022 21:55:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/01/2022 21:55:18 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7497447447447447 on epoch=449
06/01/2022 21:55:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/01/2022 21:55:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/01/2022 21:55:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/01/2022 21:55:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/01/2022 21:55:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=462
06/01/2022 21:55:32 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7334494203822697 on epoch=462
06/01/2022 21:55:35 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/01/2022 21:55:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/01/2022 21:55:40 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 21:55:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=472
06/01/2022 21:55:45 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/01/2022 21:55:46 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7122166480862133 on epoch=474
06/01/2022 21:55:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/01/2022 21:55:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/01/2022 21:55:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=482
06/01/2022 21:55:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=484
06/01/2022 21:55:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 21:56:00 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6833333333333333 on epoch=487
06/01/2022 21:56:03 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/01/2022 21:56:05 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/01/2022 21:56:08 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/01/2022 21:56:10 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/01/2022 21:56:13 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/01/2022 21:56:14 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7011757279255111 on epoch=499
06/01/2022 21:56:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/01/2022 21:56:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/01/2022 21:56:21 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 21:56:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/01/2022 21:56:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/01/2022 21:56:28 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7202915256454276 on epoch=512
06/01/2022 21:56:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 21:56:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=517
06/01/2022 21:56:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/01/2022 21:56:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/01/2022 21:56:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/01/2022 21:56:42 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7334494203822697 on epoch=524
06/01/2022 21:56:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 21:56:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/01/2022 21:56:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/01/2022 21:56:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=534
06/01/2022 21:56:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/01/2022 21:56:55 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7446886446886447 on epoch=537
06/01/2022 21:56:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 21:57:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=542
06/01/2022 21:57:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 21:57:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 21:57:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/01/2022 21:57:09 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.725388198757764 on epoch=549
06/01/2022 21:57:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 21:57:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 21:57:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/01/2022 21:57:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/01/2022 21:57:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 21:57:23 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6855072463768115 on epoch=562
06/01/2022 21:57:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 21:57:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 21:57:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 21:57:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/01/2022 21:57:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 21:57:36 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6784688995215311 on epoch=574
06/01/2022 21:57:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 21:57:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=579
06/01/2022 21:57:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 21:57:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 21:57:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/01/2022 21:57:50 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7384723348512257 on epoch=587
06/01/2022 21:57:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 21:57:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/01/2022 21:57:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 21:58:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/01/2022 21:58:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 21:58:04 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7271260203231718 on epoch=599
06/01/2022 21:58:06 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=602
06/01/2022 21:58:09 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/01/2022 21:58:12 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 21:58:14 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 21:58:17 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=612
06/01/2022 21:58:18 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7334869431643626 on epoch=612
06/01/2022 21:58:20 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/01/2022 21:58:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=617
06/01/2022 21:58:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 21:58:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=622
06/01/2022 21:58:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/01/2022 21:58:32 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7736363636363637 on epoch=624
06/01/2022 21:58:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 21:58:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 21:58:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 21:58:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/01/2022 21:58:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 21:58:45 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7733137829912023 on epoch=637
06/01/2022 21:58:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 21:58:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 21:58:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/01/2022 21:58:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 21:58:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 21:58:59 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7143336226623531 on epoch=649
06/01/2022 21:59:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=652
06/01/2022 21:59:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 21:59:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 21:59:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 21:59:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/01/2022 21:59:13 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7782223109957056 on epoch=662
06/01/2022 21:59:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 21:59:18 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 21:59:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 21:59:23 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/01/2022 21:59:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=674
06/01/2022 21:59:27 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7782223109957056 on epoch=674
06/01/2022 21:59:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=677
06/01/2022 21:59:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/01/2022 21:59:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 21:59:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/01/2022 21:59:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 21:59:40 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7917753214527408 on epoch=687
06/01/2022 21:59:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 21:59:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/01/2022 21:59:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 21:59:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 21:59:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/01/2022 21:59:54 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7917753214527408 on epoch=699
06/01/2022 21:59:57 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 21:59:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 22:00:02 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 22:00:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 22:00:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=712
06/01/2022 22:00:08 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7207854406130267 on epoch=712
06/01/2022 22:00:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=714
06/01/2022 22:00:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.10 on epoch=717
06/01/2022 22:00:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/01/2022 22:00:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 22:00:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=724
06/01/2022 22:00:22 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7782223109957056 on epoch=724
06/01/2022 22:00:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 22:00:27 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 22:00:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 22:00:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 22:00:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 22:00:36 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.725388198757764 on epoch=737
06/01/2022 22:00:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 22:00:41 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 22:00:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/01/2022 22:00:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 22:00:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 22:00:49 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.725388198757764 on epoch=749
06/01/2022 22:00:49 - INFO - __main__ - save last model!
06/01/2022 22:00:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 22:00:49 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 22:00:49 - INFO - __main__ - Printing 3 examples
06/01/2022 22:00:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 22:00:49 - INFO - __main__ - ['others']
06/01/2022 22:00:49 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 22:00:49 - INFO - __main__ - ['others']
06/01/2022 22:00:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 22:00:49 - INFO - __main__ - ['others']
06/01/2022 22:00:49 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:00:49 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:00:49 - INFO - __main__ - Printing 3 examples
06/01/2022 22:00:49 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:00:49 - INFO - __main__ - ['happy']
06/01/2022 22:00:49 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:00:49 - INFO - __main__ - ['happy']
06/01/2022 22:00:49 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:00:49 - INFO - __main__ - ['happy']
06/01/2022 22:00:49 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:00:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:00:50 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:00:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:00:50 - INFO - __main__ - Printing 3 examples
06/01/2022 22:00:50 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:00:50 - INFO - __main__ - ['happy']
06/01/2022 22:00:50 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:00:50 - INFO - __main__ - ['happy']
06/01/2022 22:00:50 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:00:50 - INFO - __main__ - ['happy']
06/01/2022 22:00:50 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:00:50 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:00:50 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:00:52 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:00:57 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 22:01:08 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:01:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:01:09 - INFO - __main__ - Starting training!
06/01/2022 22:02:34 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/01/2022 22:02:34 - INFO - __main__ - Classification-F1 on test data: 0.1575
06/01/2022 22:02:35 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.8036168132942326, test_performance=0.15752357992704374
06/01/2022 22:02:35 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/01/2022 22:02:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:02:36 - INFO - __main__ - Printing 3 examples
06/01/2022 22:02:36 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:02:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:02:36 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:02:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:02:36 - INFO - __main__ - Printing 3 examples
06/01/2022 22:02:36 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:02:36 - INFO - __main__ - ['happy']
06/01/2022 22:02:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:02:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:02:36 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:02:51 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:02:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:02:52 - INFO - __main__ - Starting training!
06/01/2022 22:02:55 - INFO - __main__ - Step 10 Global step 10 Train loss 3.52 on epoch=2
06/01/2022 22:02:57 - INFO - __main__ - Step 20 Global step 20 Train loss 1.94 on epoch=4
06/01/2022 22:03:00 - INFO - __main__ - Step 30 Global step 30 Train loss 1.31 on epoch=7
06/01/2022 22:03:02 - INFO - __main__ - Step 40 Global step 40 Train loss 0.99 on epoch=9
06/01/2022 22:03:05 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
06/01/2022 22:03:06 - INFO - __main__ - Global step 50 Train loss 1.75 Classification-F1 0.1 on epoch=12
06/01/2022 22:03:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 22:03:08 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=14
06/01/2022 22:03:11 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=17
06/01/2022 22:03:13 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=19
06/01/2022 22:03:16 - INFO - __main__ - Step 90 Global step 90 Train loss 0.90 on epoch=22
06/01/2022 22:03:18 - INFO - __main__ - Step 100 Global step 100 Train loss 0.85 on epoch=24
06/01/2022 22:03:19 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.29147250698974836 on epoch=24
06/01/2022 22:03:19 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.29147250698974836 on epoch=24, global_step=100
06/01/2022 22:03:22 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=27
06/01/2022 22:03:24 - INFO - __main__ - Step 120 Global step 120 Train loss 0.80 on epoch=29
06/01/2022 22:03:27 - INFO - __main__ - Step 130 Global step 130 Train loss 0.71 on epoch=32
06/01/2022 22:03:29 - INFO - __main__ - Step 140 Global step 140 Train loss 0.83 on epoch=34
06/01/2022 22:03:32 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=37
06/01/2022 22:03:33 - INFO - __main__ - Global step 150 Train loss 0.79 Classification-F1 0.4899694848524161 on epoch=37
06/01/2022 22:03:33 - INFO - __main__ - Saving model with best Classification-F1: 0.29147250698974836 -> 0.4899694848524161 on epoch=37, global_step=150
06/01/2022 22:03:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
06/01/2022 22:03:38 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=42
06/01/2022 22:03:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=44
06/01/2022 22:03:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=47
06/01/2022 22:03:46 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=49
06/01/2022 22:03:46 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.6810345851092879 on epoch=49
06/01/2022 22:03:47 - INFO - __main__ - Saving model with best Classification-F1: 0.4899694848524161 -> 0.6810345851092879 on epoch=49, global_step=200
06/01/2022 22:03:49 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=52
06/01/2022 22:03:52 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=54
06/01/2022 22:03:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=57
06/01/2022 22:03:57 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=59
06/01/2022 22:03:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=62
06/01/2022 22:04:00 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.6919451406293512 on epoch=62
06/01/2022 22:04:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6810345851092879 -> 0.6919451406293512 on epoch=62, global_step=250
06/01/2022 22:04:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=64
06/01/2022 22:04:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=67
06/01/2022 22:04:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=69
06/01/2022 22:04:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.40 on epoch=72
06/01/2022 22:04:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.28 on epoch=74
06/01/2022 22:04:14 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.7635465967119193 on epoch=74
06/01/2022 22:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6919451406293512 -> 0.7635465967119193 on epoch=74, global_step=300
06/01/2022 22:04:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=77
06/01/2022 22:04:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=79
06/01/2022 22:04:21 - INFO - __main__ - Step 330 Global step 330 Train loss 0.37 on epoch=82
06/01/2022 22:04:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=84
06/01/2022 22:04:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=87
06/01/2022 22:04:27 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.6323953823953825 on epoch=87
06/01/2022 22:04:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.36 on epoch=89
06/01/2022 22:04:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.25 on epoch=92
06/01/2022 22:04:35 - INFO - __main__ - Step 380 Global step 380 Train loss 0.31 on epoch=94
06/01/2022 22:04:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=97
06/01/2022 22:04:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=99
06/01/2022 22:04:41 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5879294992667086 on epoch=99
06/01/2022 22:04:43 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=102
06/01/2022 22:04:46 - INFO - __main__ - Step 420 Global step 420 Train loss 0.17 on epoch=104
06/01/2022 22:04:49 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=107
06/01/2022 22:04:51 - INFO - __main__ - Step 440 Global step 440 Train loss 0.19 on epoch=109
06/01/2022 22:04:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.17 on epoch=112
06/01/2022 22:04:54 - INFO - __main__ - Global step 450 Train loss 0.20 Classification-F1 0.6349184782608696 on epoch=112
06/01/2022 22:04:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/01/2022 22:05:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=117
06/01/2022 22:05:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=119
06/01/2022 22:05:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.08 on epoch=122
06/01/2022 22:05:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/01/2022 22:05:08 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.7800067204301075 on epoch=124
06/01/2022 22:05:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7635465967119193 -> 0.7800067204301075 on epoch=124, global_step=500
06/01/2022 22:05:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/01/2022 22:05:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=129
06/01/2022 22:05:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.07 on epoch=132
06/01/2022 22:05:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=134
06/01/2022 22:05:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/01/2022 22:05:22 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.7120237588987589 on epoch=137
06/01/2022 22:05:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=139
06/01/2022 22:05:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/01/2022 22:05:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/01/2022 22:05:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.05 on epoch=147
06/01/2022 22:05:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=149
06/01/2022 22:05:36 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.6799150654413813 on epoch=149
06/01/2022 22:05:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=152
06/01/2022 22:05:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/01/2022 22:05:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
06/01/2022 22:05:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
06/01/2022 22:05:49 - INFO - __main__ - Step 650 Global step 650 Train loss 0.08 on epoch=162
06/01/2022 22:05:50 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.7 on epoch=162
06/01/2022 22:05:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/01/2022 22:05:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/01/2022 22:05:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=169
06/01/2022 22:06:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/01/2022 22:06:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.07 on epoch=174
06/01/2022 22:06:03 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.6309163059163059 on epoch=174
06/01/2022 22:06:06 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/01/2022 22:06:08 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/01/2022 22:06:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/01/2022 22:06:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/01/2022 22:06:16 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/01/2022 22:06:17 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7026785714285714 on epoch=187
06/01/2022 22:06:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/01/2022 22:06:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/01/2022 22:06:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.05 on epoch=194
06/01/2022 22:06:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/01/2022 22:06:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/01/2022 22:06:31 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.701377848436672 on epoch=199
06/01/2022 22:06:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/01/2022 22:06:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/01/2022 22:06:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/01/2022 22:06:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/01/2022 22:06:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/01/2022 22:06:45 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.6713727794290454 on epoch=212
06/01/2022 22:06:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 22:06:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.02 on epoch=217
06/01/2022 22:06:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/01/2022 22:06:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/01/2022 22:06:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/01/2022 22:06:59 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.7167508057385699 on epoch=224
06/01/2022 22:07:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/01/2022 22:07:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/01/2022 22:07:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/01/2022 22:07:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/01/2022 22:07:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 22:07:13 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.6888440860215055 on epoch=237
06/01/2022 22:07:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/01/2022 22:07:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/01/2022 22:07:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/01/2022 22:07:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/01/2022 22:07:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/01/2022 22:07:26 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6502704530087897 on epoch=249
06/01/2022 22:07:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/01/2022 22:07:31 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/01/2022 22:07:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 22:07:36 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/01/2022 22:07:39 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=262
06/01/2022 22:07:40 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6292584227366836 on epoch=262
06/01/2022 22:07:43 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/01/2022 22:07:45 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 22:07:48 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/01/2022 22:07:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/01/2022 22:07:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/01/2022 22:07:54 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.7164215686274509 on epoch=274
06/01/2022 22:07:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/01/2022 22:07:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/01/2022 22:08:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/01/2022 22:08:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/01/2022 22:08:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/01/2022 22:08:08 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.67889482958869 on epoch=287
06/01/2022 22:08:10 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/01/2022 22:08:13 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/01/2022 22:08:15 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/01/2022 22:08:18 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=297
06/01/2022 22:08:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=299
06/01/2022 22:08:22 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7178706966657631 on epoch=299
06/01/2022 22:08:24 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=302
06/01/2022 22:08:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/01/2022 22:08:29 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/01/2022 22:08:32 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 22:08:34 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/01/2022 22:08:35 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6942007797270955 on epoch=312
06/01/2022 22:08:38 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 22:08:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 22:08:43 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/01/2022 22:08:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 22:08:48 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/01/2022 22:08:49 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.7182955429325666 on epoch=324
06/01/2022 22:08:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/01/2022 22:08:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 22:08:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/01/2022 22:08:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/01/2022 22:09:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 22:09:03 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7313218390804597 on epoch=337
06/01/2022 22:09:05 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 22:09:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 22:09:10 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/01/2022 22:09:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/01/2022 22:09:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/01/2022 22:09:16 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7443181818181818 on epoch=349
06/01/2022 22:09:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 22:09:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/01/2022 22:09:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/01/2022 22:09:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/01/2022 22:09:29 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 22:09:30 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.783222926267281 on epoch=362
06/01/2022 22:09:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7800067204301075 -> 0.783222926267281 on epoch=362, global_step=1450
06/01/2022 22:09:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/01/2022 22:09:35 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=367
06/01/2022 22:09:38 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=369
06/01/2022 22:09:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/01/2022 22:09:43 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/01/2022 22:09:44 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.7290411373260739 on epoch=374
06/01/2022 22:09:47 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/01/2022 22:09:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/01/2022 22:09:52 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 22:09:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=384
06/01/2022 22:09:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/01/2022 22:09:58 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7614145658263306 on epoch=387
06/01/2022 22:10:01 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 22:10:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/01/2022 22:10:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 22:10:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/01/2022 22:10:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 22:10:12 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.702338063151682 on epoch=399
06/01/2022 22:10:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 22:10:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 22:10:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 22:10:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 22:10:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/01/2022 22:10:26 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.7636836343732896 on epoch=412
06/01/2022 22:10:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 22:10:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/01/2022 22:10:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 22:10:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 22:10:39 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/01/2022 22:10:40 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7093426537165195 on epoch=424
06/01/2022 22:10:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/01/2022 22:10:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 22:10:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/01/2022 22:10:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 22:10:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 22:10:53 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7596288515406162 on epoch=437
06/01/2022 22:10:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/01/2022 22:10:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/01/2022 22:11:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 22:11:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/01/2022 22:11:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 22:11:07 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7287489744386297 on epoch=449
06/01/2022 22:11:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 22:11:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 22:11:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=457
06/01/2022 22:11:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/01/2022 22:11:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 22:11:21 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6557017543859649 on epoch=462
06/01/2022 22:11:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 22:11:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 22:11:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 22:11:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=472
06/01/2022 22:11:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/01/2022 22:11:35 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.7752538515406162 on epoch=474
06/01/2022 22:11:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 22:11:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 22:11:43 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 22:11:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 22:11:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 22:11:49 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7602150537634409 on epoch=487
06/01/2022 22:11:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/01/2022 22:11:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 22:11:57 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 22:11:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 22:12:02 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 22:12:03 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.778393175451999 on epoch=499
06/01/2022 22:12:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 22:12:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 22:12:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 22:12:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 22:12:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 22:12:17 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.730303970223325 on epoch=512
06/01/2022 22:12:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 22:12:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 22:12:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 22:12:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 22:12:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 22:12:30 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7797152194211018 on epoch=524
06/01/2022 22:12:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/01/2022 22:12:35 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 22:12:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.16 on epoch=532
06/01/2022 22:12:40 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 22:12:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 22:12:44 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7290504487024011 on epoch=537
06/01/2022 22:12:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 22:12:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 22:12:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 22:12:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 22:12:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/01/2022 22:12:58 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7614224137931034 on epoch=549
06/01/2022 22:13:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 22:13:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 22:13:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 22:13:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 22:13:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 22:13:12 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7645021645021645 on epoch=562
06/01/2022 22:13:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 22:13:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 22:13:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 22:13:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/01/2022 22:13:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 22:13:25 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.7602150537634409 on epoch=574
06/01/2022 22:13:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 22:13:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 22:13:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 22:13:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 22:13:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 22:13:39 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7421990320629159 on epoch=587
06/01/2022 22:13:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 22:13:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=592
06/01/2022 22:13:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 22:13:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/01/2022 22:13:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 22:13:52 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7427350427350428 on epoch=599
06/01/2022 22:13:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 22:13:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 22:14:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 22:14:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 22:14:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/01/2022 22:14:06 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7802714047495831 on epoch=612
06/01/2022 22:14:08 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 22:14:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/01/2022 22:14:13 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 22:14:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 22:14:18 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 22:14:19 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7443181818181818 on epoch=624
06/01/2022 22:14:22 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 22:14:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 22:14:27 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 22:14:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/01/2022 22:14:32 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 22:14:33 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7462832290418497 on epoch=637
06/01/2022 22:14:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 22:14:38 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 22:14:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 22:14:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 22:14:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/01/2022 22:14:46 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7749999999999999 on epoch=649
06/01/2022 22:14:48 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 22:14:51 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 22:14:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 22:14:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 22:14:58 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 22:15:00 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.729682880786446 on epoch=662
06/01/2022 22:15:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 22:15:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 22:15:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 22:15:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 22:15:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 22:15:13 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7630485527544352 on epoch=674
06/01/2022 22:15:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 22:15:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 22:15:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 22:15:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 22:15:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 22:15:27 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.778450690621076 on epoch=687
06/01/2022 22:15:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 22:15:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/01/2022 22:15:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 22:15:37 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 22:15:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 22:15:41 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7440860215053763 on epoch=699
06/01/2022 22:15:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 22:15:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 22:15:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 22:15:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 22:15:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 22:15:54 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7614145658263306 on epoch=712
06/01/2022 22:15:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 22:15:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 22:16:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 22:16:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 22:16:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 22:16:08 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7445426446440645 on epoch=724
06/01/2022 22:16:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 22:16:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=729
06/01/2022 22:16:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 22:16:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 22:16:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 22:16:22 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7460842377416349 on epoch=737
06/01/2022 22:16:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 22:16:27 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 22:16:30 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 22:16:33 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 22:16:35 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 22:16:36 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7460842377416349 on epoch=749
06/01/2022 22:16:36 - INFO - __main__ - save last model!
06/01/2022 22:16:36 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 22:16:36 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 22:16:36 - INFO - __main__ - Printing 3 examples
06/01/2022 22:16:36 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 22:16:36 - INFO - __main__ - ['others']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 22:16:36 - INFO - __main__ - ['others']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 22:16:36 - INFO - __main__ - ['others']
06/01/2022 22:16:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:16:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:16:36 - INFO - __main__ - Printing 3 examples
06/01/2022 22:16:36 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:16:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:16:36 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:16:36 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:16:36 - INFO - __main__ - Printing 3 examples
06/01/2022 22:16:36 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:16:36 - INFO - __main__ - ['happy']
06/01/2022 22:16:36 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:16:36 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:16:37 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:16:38 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:16:44 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 22:16:52 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:16:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:16:53 - INFO - __main__ - Starting training!
06/01/2022 22:18:21 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/01/2022 22:18:21 - INFO - __main__ - Classification-F1 on test data: 0.2673
06/01/2022 22:18:21 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.783222926267281, test_performance=0.2673439277185326
06/01/2022 22:18:21 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/01/2022 22:18:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:18:22 - INFO - __main__ - Printing 3 examples
06/01/2022 22:18:22 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:18:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:18:22 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:18:22 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:18:22 - INFO - __main__ - Printing 3 examples
06/01/2022 22:18:22 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:18:22 - INFO - __main__ - ['happy']
06/01/2022 22:18:22 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:18:22 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:18:22 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:18:38 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:18:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:18:39 - INFO - __main__ - Starting training!
06/01/2022 22:18:42 - INFO - __main__ - Step 10 Global step 10 Train loss 3.90 on epoch=2
06/01/2022 22:18:44 - INFO - __main__ - Step 20 Global step 20 Train loss 2.30 on epoch=4
06/01/2022 22:18:47 - INFO - __main__ - Step 30 Global step 30 Train loss 1.55 on epoch=7
06/01/2022 22:18:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.20 on epoch=9
06/01/2022 22:18:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=12
06/01/2022 22:18:53 - INFO - __main__ - Global step 50 Train loss 1.99 Classification-F1 0.10126582278481013 on epoch=12
06/01/2022 22:18:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10126582278481013 on epoch=12, global_step=50
06/01/2022 22:18:55 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/01/2022 22:18:58 - INFO - __main__ - Step 70 Global step 70 Train loss 0.93 on epoch=17
06/01/2022 22:19:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.88 on epoch=19
06/01/2022 22:19:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
06/01/2022 22:19:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/01/2022 22:19:06 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.1 on epoch=24
06/01/2022 22:19:09 - INFO - __main__ - Step 110 Global step 110 Train loss 0.78 on epoch=27
06/01/2022 22:19:11 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=29
06/01/2022 22:19:14 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/01/2022 22:19:16 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/01/2022 22:19:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.83 on epoch=37
06/01/2022 22:19:20 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.4791666666666667 on epoch=37
06/01/2022 22:19:20 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.4791666666666667 on epoch=37, global_step=150
06/01/2022 22:19:22 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=39
06/01/2022 22:19:25 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=42
06/01/2022 22:19:27 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=44
06/01/2022 22:19:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=47
06/01/2022 22:19:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=49
06/01/2022 22:19:33 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.5128205128205129 on epoch=49
06/01/2022 22:19:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4791666666666667 -> 0.5128205128205129 on epoch=49, global_step=200
06/01/2022 22:19:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/01/2022 22:19:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.65 on epoch=54
06/01/2022 22:19:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=57
06/01/2022 22:19:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.71 on epoch=59
06/01/2022 22:19:46 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=62
06/01/2022 22:19:47 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.5726136421323376 on epoch=62
06/01/2022 22:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5128205128205129 -> 0.5726136421323376 on epoch=62, global_step=250
06/01/2022 22:19:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.62 on epoch=64
06/01/2022 22:19:52 - INFO - __main__ - Step 270 Global step 270 Train loss 0.52 on epoch=67
06/01/2022 22:19:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=69
06/01/2022 22:19:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=72
06/01/2022 22:19:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.45 on epoch=74
06/01/2022 22:20:00 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.6675324675324675 on epoch=74
06/01/2022 22:20:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5726136421323376 -> 0.6675324675324675 on epoch=74, global_step=300
06/01/2022 22:20:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=77
06/01/2022 22:20:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=79
06/01/2022 22:20:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.45 on epoch=82
06/01/2022 22:20:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=84
06/01/2022 22:20:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/01/2022 22:20:14 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.5701866558980572 on epoch=87
06/01/2022 22:20:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=89
06/01/2022 22:20:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/01/2022 22:20:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=94
06/01/2022 22:20:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.31 on epoch=97
06/01/2022 22:20:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=99
06/01/2022 22:20:27 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.5884157509157509 on epoch=99
06/01/2022 22:20:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.31 on epoch=102
06/01/2022 22:20:32 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=104
06/01/2022 22:20:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/01/2022 22:20:37 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=109
06/01/2022 22:20:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.24 on epoch=112
06/01/2022 22:20:41 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6585416666666666 on epoch=112
06/01/2022 22:20:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=114
06/01/2022 22:20:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=117
06/01/2022 22:20:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/01/2022 22:20:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=122
06/01/2022 22:20:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=124
06/01/2022 22:20:54 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6676771145521145 on epoch=124
06/01/2022 22:20:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6675324675324675 -> 0.6676771145521145 on epoch=124, global_step=500
06/01/2022 22:20:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.12 on epoch=127
06/01/2022 22:20:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=129
06/01/2022 22:21:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/01/2022 22:21:04 - INFO - __main__ - Step 540 Global step 540 Train loss 0.10 on epoch=134
06/01/2022 22:21:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/01/2022 22:21:08 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.6603174603174603 on epoch=137
06/01/2022 22:21:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.11 on epoch=139
06/01/2022 22:21:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.11 on epoch=142
06/01/2022 22:21:16 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/01/2022 22:21:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=147
06/01/2022 22:21:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/01/2022 22:21:21 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.7195733425334944 on epoch=149
06/01/2022 22:21:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6676771145521145 -> 0.7195733425334944 on epoch=149, global_step=600
06/01/2022 22:21:24 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/01/2022 22:21:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
06/01/2022 22:21:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=157
06/01/2022 22:21:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/01/2022 22:21:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=162
06/01/2022 22:21:35 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.6593241167434716 on epoch=162
06/01/2022 22:21:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/01/2022 22:21:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.09 on epoch=167
06/01/2022 22:21:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/01/2022 22:21:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/01/2022 22:21:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/01/2022 22:21:49 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.6731597774244833 on epoch=174
06/01/2022 22:21:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=177
06/01/2022 22:21:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=179
06/01/2022 22:21:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/01/2022 22:21:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/01/2022 22:22:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/01/2022 22:22:02 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.6829974481449977 on epoch=187
06/01/2022 22:22:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/01/2022 22:22:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
06/01/2022 22:22:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/01/2022 22:22:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/01/2022 22:22:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=199
06/01/2022 22:22:16 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.6826067073170732 on epoch=199
06/01/2022 22:22:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/01/2022 22:22:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/01/2022 22:22:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=207
06/01/2022 22:22:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=209
06/01/2022 22:22:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/01/2022 22:22:30 - INFO - __main__ - Global step 850 Train loss 0.05 Classification-F1 0.6967754467754468 on epoch=212
06/01/2022 22:22:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 22:22:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/01/2022 22:22:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=219
06/01/2022 22:22:40 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/01/2022 22:22:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/01/2022 22:22:43 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6810515873015873 on epoch=224
06/01/2022 22:22:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/01/2022 22:22:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/01/2022 22:22:51 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/01/2022 22:22:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/01/2022 22:22:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/01/2022 22:22:57 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.6786931818181818 on epoch=237
06/01/2022 22:22:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.04 on epoch=239
06/01/2022 22:23:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 22:23:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/01/2022 22:23:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/01/2022 22:23:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/01/2022 22:23:11 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6599195151033387 on epoch=249
06/01/2022 22:23:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/01/2022 22:23:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/01/2022 22:23:18 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/01/2022 22:23:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 22:23:23 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/01/2022 22:23:24 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.681629940377405 on epoch=262
06/01/2022 22:23:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/01/2022 22:23:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/01/2022 22:23:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 22:23:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 22:23:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/01/2022 22:23:38 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.7127039062522933 on epoch=274
06/01/2022 22:23:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/01/2022 22:23:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 22:23:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=282
06/01/2022 22:23:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/01/2022 22:23:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/01/2022 22:23:52 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6936002178649238 on epoch=287
06/01/2022 22:23:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/01/2022 22:23:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/01/2022 22:23:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/01/2022 22:24:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/01/2022 22:24:04 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 22:24:05 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.7138323627560035 on epoch=299
06/01/2022 22:24:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 22:24:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/01/2022 22:24:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/01/2022 22:24:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/01/2022 22:24:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/01/2022 22:24:19 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.7138323627560035 on epoch=312
06/01/2022 22:24:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/01/2022 22:24:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 22:24:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/01/2022 22:24:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 22:24:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/01/2022 22:24:33 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6776945168785775 on epoch=324
06/01/2022 22:24:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=327
06/01/2022 22:24:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/01/2022 22:24:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/01/2022 22:24:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/01/2022 22:24:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/01/2022 22:24:47 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.680528188286809 on epoch=337
06/01/2022 22:24:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=339
06/01/2022 22:24:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/01/2022 22:24:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/01/2022 22:24:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/01/2022 22:24:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 22:25:00 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6777672558922558 on epoch=349
06/01/2022 22:25:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 22:25:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/01/2022 22:25:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=357
06/01/2022 22:25:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/01/2022 22:25:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 22:25:14 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.6781938188188188 on epoch=362
06/01/2022 22:25:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/01/2022 22:25:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/01/2022 22:25:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 22:25:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/01/2022 22:25:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/01/2022 22:25:28 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6779037081339713 on epoch=374
06/01/2022 22:25:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/01/2022 22:25:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/01/2022 22:25:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/01/2022 22:25:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/01/2022 22:25:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 22:25:41 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7135720601237843 on epoch=387
06/01/2022 22:25:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/01/2022 22:25:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/01/2022 22:25:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=394
06/01/2022 22:25:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/01/2022 22:25:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 22:25:55 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6641891891891891 on epoch=399
06/01/2022 22:25:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 22:26:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 22:26:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/01/2022 22:26:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 22:26:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/01/2022 22:26:09 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6865530303030302 on epoch=412
06/01/2022 22:26:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 22:26:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/01/2022 22:26:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 22:26:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/01/2022 22:26:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/01/2022 22:26:23 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6322646103896103 on epoch=424
06/01/2022 22:26:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/01/2022 22:26:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 22:26:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 22:26:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 22:26:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 22:26:36 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6977349560513861 on epoch=437
06/01/2022 22:26:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 22:26:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 22:26:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 22:26:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/01/2022 22:26:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 22:26:50 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6977349560513861 on epoch=449
06/01/2022 22:26:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 22:26:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 22:26:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 22:27:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=459
06/01/2022 22:27:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/01/2022 22:27:04 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6751599079185285 on epoch=462
06/01/2022 22:27:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=464
06/01/2022 22:27:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/01/2022 22:27:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 22:27:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 22:27:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 22:27:18 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6599590373783921 on epoch=474
06/01/2022 22:27:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 22:27:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 22:27:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 22:27:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 22:27:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 22:27:32 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6599590373783921 on epoch=487
06/01/2022 22:27:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 22:27:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 22:27:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 22:27:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/01/2022 22:27:44 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 22:27:46 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6693101506679093 on epoch=499
06/01/2022 22:27:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 22:27:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 22:27:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 22:27:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/01/2022 22:27:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 22:27:59 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7046081294030403 on epoch=512
06/01/2022 22:28:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=514
06/01/2022 22:28:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 22:28:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 22:28:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 22:28:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 22:28:13 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6675324675324675 on epoch=524
06/01/2022 22:28:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 22:28:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=529
06/01/2022 22:28:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=532
06/01/2022 22:28:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 22:28:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/01/2022 22:28:27 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6986453201970444 on epoch=537
06/01/2022 22:28:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 22:28:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 22:28:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/01/2022 22:28:37 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 22:28:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=549
06/01/2022 22:28:41 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6938235491366421 on epoch=549
06/01/2022 22:28:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/01/2022 22:28:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 22:28:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/01/2022 22:28:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=559
06/01/2022 22:28:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 22:28:55 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6985282696489592 on epoch=562
06/01/2022 22:28:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 22:29:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/01/2022 22:29:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/01/2022 22:29:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/01/2022 22:29:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 22:29:08 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7032147311346422 on epoch=574
06/01/2022 22:29:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 22:29:13 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 22:29:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 22:29:18 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/01/2022 22:29:21 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=587
06/01/2022 22:29:22 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7144099504499949 on epoch=587
06/01/2022 22:29:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 22:29:27 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 22:29:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 22:29:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 22:29:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 22:29:35 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6833154510639299 on epoch=599
06/01/2022 22:29:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/01/2022 22:29:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 22:29:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 22:29:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/01/2022 22:29:48 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/01/2022 22:29:49 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.648383794935519 on epoch=612
06/01/2022 22:29:51 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/01/2022 22:29:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 22:29:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=619
06/01/2022 22:29:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 22:30:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 22:30:02 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6856321157495255 on epoch=624
06/01/2022 22:30:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 22:30:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/01/2022 22:30:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 22:30:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 22:30:14 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 22:30:16 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6660448337659126 on epoch=637
06/01/2022 22:30:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 22:30:21 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 22:30:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 22:30:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 22:30:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 22:30:29 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6682598039215686 on epoch=649
06/01/2022 22:30:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 22:30:34 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 22:30:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 22:30:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 22:30:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 22:30:42 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6660448337659126 on epoch=662
06/01/2022 22:30:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 22:30:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=667
06/01/2022 22:30:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 22:30:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 22:30:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 22:30:56 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5988930659983291 on epoch=674
06/01/2022 22:30:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 22:31:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 22:31:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 22:31:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 22:31:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 22:31:09 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6842895779001256 on epoch=687
06/01/2022 22:31:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 22:31:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/01/2022 22:31:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/01/2022 22:31:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 22:31:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 22:31:22 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6842895779001256 on epoch=699
06/01/2022 22:31:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 22:31:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 22:31:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 22:31:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 22:31:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 22:31:36 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6842895779001256 on epoch=712
06/01/2022 22:31:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 22:31:40 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 22:31:43 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 22:31:45 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 22:31:48 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 22:31:49 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.668844696969697 on epoch=724
06/01/2022 22:31:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 22:31:54 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 22:31:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 22:31:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 22:32:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/01/2022 22:32:02 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6488095238095238 on epoch=737
06/01/2022 22:32:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=739
06/01/2022 22:32:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 22:32:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=744
06/01/2022 22:32:12 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=747
06/01/2022 22:32:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/01/2022 22:32:16 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6669240580244638 on epoch=749
06/01/2022 22:32:16 - INFO - __main__ - save last model!
06/01/2022 22:32:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 22:32:16 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 22:32:16 - INFO - __main__ - Printing 3 examples
06/01/2022 22:32:16 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 22:32:16 - INFO - __main__ - ['others']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 22:32:16 - INFO - __main__ - ['others']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 22:32:16 - INFO - __main__ - ['others']
06/01/2022 22:32:16 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:32:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:32:16 - INFO - __main__ - Printing 3 examples
06/01/2022 22:32:16 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:32:16 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:32:16 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:32:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:32:16 - INFO - __main__ - Printing 3 examples
06/01/2022 22:32:16 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:32:16 - INFO - __main__ - ['happy']
06/01/2022 22:32:16 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:32:16 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:32:16 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:32:18 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:32:23 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 22:32:31 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:32:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:32:32 - INFO - __main__ - Starting training!
06/01/2022 22:33:59 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/01/2022 22:33:59 - INFO - __main__ - Classification-F1 on test data: 0.0994
06/01/2022 22:34:00 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.7195733425334944, test_performance=0.099363902583205
06/01/2022 22:34:00 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/01/2022 22:34:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:34:01 - INFO - __main__ - Printing 3 examples
06/01/2022 22:34:01 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:34:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:34:01 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:34:01 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:34:01 - INFO - __main__ - Printing 3 examples
06/01/2022 22:34:01 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:34:01 - INFO - __main__ - ['happy']
06/01/2022 22:34:01 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:34:01 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:34:01 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:34:20 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:34:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:34:20 - INFO - __main__ - Starting training!
06/01/2022 22:34:23 - INFO - __main__ - Step 10 Global step 10 Train loss 4.22 on epoch=2
06/01/2022 22:34:26 - INFO - __main__ - Step 20 Global step 20 Train loss 2.76 on epoch=4
06/01/2022 22:34:28 - INFO - __main__ - Step 30 Global step 30 Train loss 1.88 on epoch=7
06/01/2022 22:34:30 - INFO - __main__ - Step 40 Global step 40 Train loss 1.52 on epoch=9
06/01/2022 22:34:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.07 on epoch=12
06/01/2022 22:34:34 - INFO - __main__ - Global step 50 Train loss 2.29 Classification-F1 0.21071428571428574 on epoch=12
06/01/2022 22:34:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.21071428571428574 on epoch=12, global_step=50
06/01/2022 22:34:36 - INFO - __main__ - Step 60 Global step 60 Train loss 0.88 on epoch=14
06/01/2022 22:34:39 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/01/2022 22:34:41 - INFO - __main__ - Step 80 Global step 80 Train loss 0.92 on epoch=19
06/01/2022 22:34:44 - INFO - __main__ - Step 90 Global step 90 Train loss 0.87 on epoch=22
06/01/2022 22:34:46 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/01/2022 22:34:47 - INFO - __main__ - Global step 100 Train loss 0.90 Classification-F1 0.23275796805208568 on epoch=24
06/01/2022 22:34:47 - INFO - __main__ - Saving model with best Classification-F1: 0.21071428571428574 -> 0.23275796805208568 on epoch=24, global_step=100
06/01/2022 22:34:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/01/2022 22:34:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=29
06/01/2022 22:34:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/01/2022 22:34:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=34
06/01/2022 22:34:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.84 on epoch=37
06/01/2022 22:35:00 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.35889416636219706 on epoch=37
06/01/2022 22:35:00 - INFO - __main__ - Saving model with best Classification-F1: 0.23275796805208568 -> 0.35889416636219706 on epoch=37, global_step=150
06/01/2022 22:35:02 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=39
06/01/2022 22:35:05 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=42
06/01/2022 22:35:07 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=44
06/01/2022 22:35:10 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=47
06/01/2022 22:35:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.81 on epoch=49
06/01/2022 22:35:13 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.3938014798268882 on epoch=49
06/01/2022 22:35:13 - INFO - __main__ - Saving model with best Classification-F1: 0.35889416636219706 -> 0.3938014798268882 on epoch=49, global_step=200
06/01/2022 22:35:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=52
06/01/2022 22:35:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.74 on epoch=54
06/01/2022 22:35:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.74 on epoch=57
06/01/2022 22:35:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=59
06/01/2022 22:35:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.79 on epoch=62
06/01/2022 22:35:26 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.5430591882204785 on epoch=62
06/01/2022 22:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.3938014798268882 -> 0.5430591882204785 on epoch=62, global_step=250
06/01/2022 22:35:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=64
06/01/2022 22:35:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=67
06/01/2022 22:35:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.66 on epoch=69
06/01/2022 22:35:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=72
06/01/2022 22:35:38 - INFO - __main__ - Step 300 Global step 300 Train loss 0.61 on epoch=74
06/01/2022 22:35:39 - INFO - __main__ - Global step 300 Train loss 0.67 Classification-F1 0.5482732732732732 on epoch=74
06/01/2022 22:35:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5430591882204785 -> 0.5482732732732732 on epoch=74, global_step=300
06/01/2022 22:35:41 - INFO - __main__ - Step 310 Global step 310 Train loss 0.74 on epoch=77
06/01/2022 22:35:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=79
06/01/2022 22:35:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=82
06/01/2022 22:35:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=84
06/01/2022 22:35:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=87
06/01/2022 22:35:52 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.5915762407421077 on epoch=87
06/01/2022 22:35:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5482732732732732 -> 0.5915762407421077 on epoch=87, global_step=350
06/01/2022 22:35:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/01/2022 22:35:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.46 on epoch=92
06/01/2022 22:35:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=94
06/01/2022 22:36:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=97
06/01/2022 22:36:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=99
06/01/2022 22:36:05 - INFO - __main__ - Global step 400 Train loss 0.52 Classification-F1 0.5755952380952382 on epoch=99
06/01/2022 22:36:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=102
06/01/2022 22:36:10 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=104
06/01/2022 22:36:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=107
06/01/2022 22:36:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/01/2022 22:36:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=112
06/01/2022 22:36:18 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.6138527526395172 on epoch=112
06/01/2022 22:36:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5915762407421077 -> 0.6138527526395172 on epoch=112, global_step=450
06/01/2022 22:36:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=114
06/01/2022 22:36:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=117
06/01/2022 22:36:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=119
06/01/2022 22:36:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=122
06/01/2022 22:36:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.31 on epoch=124
06/01/2022 22:36:31 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.5997499404620148 on epoch=124
06/01/2022 22:36:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=127
06/01/2022 22:36:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/01/2022 22:36:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=132
06/01/2022 22:36:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=134
06/01/2022 22:36:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=137
06/01/2022 22:36:44 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.5821621621621621 on epoch=137
06/01/2022 22:36:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=139
06/01/2022 22:36:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=142
06/01/2022 22:36:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=144
06/01/2022 22:36:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/01/2022 22:36:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=149
06/01/2022 22:36:57 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.602547268907563 on epoch=149
06/01/2022 22:37:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.12 on epoch=152
06/01/2022 22:37:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=154
06/01/2022 22:37:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=157
06/01/2022 22:37:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=159
06/01/2022 22:37:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=162
06/01/2022 22:37:11 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.6081354280842771 on epoch=162
06/01/2022 22:37:13 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/01/2022 22:37:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=167
06/01/2022 22:37:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/01/2022 22:37:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
06/01/2022 22:37:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/01/2022 22:37:24 - INFO - __main__ - Global step 700 Train loss 0.11 Classification-F1 0.6037825004609995 on epoch=174
06/01/2022 22:37:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=177
06/01/2022 22:37:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/01/2022 22:37:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=182
06/01/2022 22:37:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=184
06/01/2022 22:37:36 - INFO - __main__ - Step 750 Global step 750 Train loss 0.07 on epoch=187
06/01/2022 22:37:37 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6361201354807492 on epoch=187
06/01/2022 22:37:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6138527526395172 -> 0.6361201354807492 on epoch=187, global_step=750
06/01/2022 22:37:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
06/01/2022 22:37:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/01/2022 22:37:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/01/2022 22:37:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=197
06/01/2022 22:37:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=199
06/01/2022 22:37:50 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.6130952380952381 on epoch=199
06/01/2022 22:37:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=202
06/01/2022 22:37:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/01/2022 22:37:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/01/2022 22:38:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/01/2022 22:38:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/01/2022 22:38:04 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.6156468334460221 on epoch=212
06/01/2022 22:38:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 22:38:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/01/2022 22:38:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=219
06/01/2022 22:38:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/01/2022 22:38:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/01/2022 22:38:17 - INFO - __main__ - Global step 900 Train loss 0.06 Classification-F1 0.6308435229487861 on epoch=224
06/01/2022 22:38:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=227
06/01/2022 22:38:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=229
06/01/2022 22:38:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/01/2022 22:38:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/01/2022 22:38:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/01/2022 22:38:30 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.6569223182126408 on epoch=237
06/01/2022 22:38:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6361201354807492 -> 0.6569223182126408 on epoch=237, global_step=950
06/01/2022 22:38:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/01/2022 22:38:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/01/2022 22:38:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/01/2022 22:38:40 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/01/2022 22:38:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/01/2022 22:38:44 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.6153803626713844 on epoch=249
06/01/2022 22:38:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/01/2022 22:38:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/01/2022 22:38:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.04 on epoch=257
06/01/2022 22:38:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 22:38:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/01/2022 22:38:57 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6511989931107578 on epoch=262
06/01/2022 22:39:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/01/2022 22:39:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/01/2022 22:39:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/01/2022 22:39:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 22:39:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/01/2022 22:39:10 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6279368605887735 on epoch=274
06/01/2022 22:39:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/01/2022 22:39:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/01/2022 22:39:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/01/2022 22:39:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/01/2022 22:39:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/01/2022 22:39:24 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6202380952380953 on epoch=287
06/01/2022 22:39:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=289
06/01/2022 22:39:29 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/01/2022 22:39:32 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/01/2022 22:39:34 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=297
06/01/2022 22:39:37 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/01/2022 22:39:38 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.648391120373879 on epoch=299
06/01/2022 22:39:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/01/2022 22:39:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 22:39:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/01/2022 22:39:47 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 22:39:50 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/01/2022 22:39:51 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6329735995050396 on epoch=312
06/01/2022 22:39:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=314
06/01/2022 22:39:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/01/2022 22:39:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/01/2022 22:40:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/01/2022 22:40:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/01/2022 22:40:04 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6666666666666667 on epoch=324
06/01/2022 22:40:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6569223182126408 -> 0.6666666666666667 on epoch=324, global_step=1300
06/01/2022 22:40:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/01/2022 22:40:09 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 22:40:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/01/2022 22:40:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=334
06/01/2022 22:40:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/01/2022 22:40:17 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.6657560688346529 on epoch=337
06/01/2022 22:40:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 22:40:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/01/2022 22:40:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/01/2022 22:40:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 22:40:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 22:40:31 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6475874220656004 on epoch=349
06/01/2022 22:40:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/01/2022 22:40:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 22:40:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/01/2022 22:40:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/01/2022 22:40:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/01/2022 22:40:44 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6629795117698343 on epoch=362
06/01/2022 22:40:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/01/2022 22:40:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 22:40:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 22:40:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/01/2022 22:40:56 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/01/2022 22:40:58 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6456733230926779 on epoch=374
06/01/2022 22:41:00 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/01/2022 22:41:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 22:41:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 22:41:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 22:41:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 22:41:11 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6657560688346529 on epoch=387
06/01/2022 22:41:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=389
06/01/2022 22:41:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/01/2022 22:41:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/01/2022 22:41:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/01/2022 22:41:23 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 22:41:24 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6595959595959595 on epoch=399
06/01/2022 22:41:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 22:41:29 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/01/2022 22:41:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/01/2022 22:41:34 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/01/2022 22:41:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=412
06/01/2022 22:41:38 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6986111111111111 on epoch=412
06/01/2022 22:41:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6666666666666667 -> 0.6986111111111111 on epoch=412, global_step=1650
06/01/2022 22:41:40 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 22:41:43 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=417
06/01/2022 22:41:45 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 22:41:48 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/01/2022 22:41:50 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 22:41:51 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.6716826923076923 on epoch=424
06/01/2022 22:41:54 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 22:41:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=429
06/01/2022 22:41:59 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 22:42:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 22:42:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 22:42:05 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6917073323323324 on epoch=437
06/01/2022 22:42:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/01/2022 22:42:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 22:42:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 22:42:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/01/2022 22:42:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/01/2022 22:42:18 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6812957157784745 on epoch=449
06/01/2022 22:42:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 22:42:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=454
06/01/2022 22:42:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 22:42:28 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/01/2022 22:42:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 22:42:32 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6860047846889952 on epoch=462
06/01/2022 22:42:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/01/2022 22:42:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/01/2022 22:42:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 22:42:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 22:42:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 22:42:45 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6975269940787181 on epoch=474
06/01/2022 22:42:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/01/2022 22:42:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 22:42:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 22:42:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/01/2022 22:42:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/01/2022 22:42:58 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6401117032178725 on epoch=487
06/01/2022 22:43:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/01/2022 22:43:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 22:43:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 22:43:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=497
06/01/2022 22:43:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=499
06/01/2022 22:43:11 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6655323653962493 on epoch=499
06/01/2022 22:43:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 22:43:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 22:43:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 22:43:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 22:43:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 22:43:25 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.684638606175608 on epoch=512
06/01/2022 22:43:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 22:43:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 22:43:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 22:43:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 22:43:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 22:43:38 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6634835440278988 on epoch=524
06/01/2022 22:43:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 22:43:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 22:43:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/01/2022 22:43:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 22:43:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=537
06/01/2022 22:43:52 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6919174055209708 on epoch=537
06/01/2022 22:43:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/01/2022 22:43:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 22:43:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 22:44:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 22:44:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 22:44:05 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6958333333333333 on epoch=549
06/01/2022 22:44:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 22:44:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 22:44:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 22:44:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 22:44:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/01/2022 22:44:19 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.682627688172043 on epoch=562
06/01/2022 22:44:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 22:44:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 22:44:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/01/2022 22:44:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/01/2022 22:44:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 22:44:32 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6843137254901961 on epoch=574
06/01/2022 22:44:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/01/2022 22:44:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 22:44:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 22:44:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 22:44:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 22:44:46 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6657876943881 on epoch=587
06/01/2022 22:44:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 22:44:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 22:44:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/01/2022 22:44:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/01/2022 22:44:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 22:44:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6517874519534862 on epoch=599
06/01/2022 22:45:02 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/01/2022 22:45:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 22:45:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.15 on epoch=607
06/01/2022 22:45:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 22:45:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 22:45:13 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6615100585688821 on epoch=612
06/01/2022 22:45:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 22:45:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/01/2022 22:45:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 22:45:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/01/2022 22:45:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=624
06/01/2022 22:45:26 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6571588041899228 on epoch=624
06/01/2022 22:45:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=627
06/01/2022 22:45:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/01/2022 22:45:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/01/2022 22:45:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=634
06/01/2022 22:45:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 22:45:40 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6592487373737372 on epoch=637
06/01/2022 22:45:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=639
06/01/2022 22:45:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 22:45:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 22:45:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/01/2022 22:45:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=649
06/01/2022 22:45:53 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.6756668692152563 on epoch=649
06/01/2022 22:45:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/01/2022 22:45:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 22:46:01 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 22:46:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=659
06/01/2022 22:46:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 22:46:07 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7033783783783784 on epoch=662
06/01/2022 22:46:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6986111111111111 -> 0.7033783783783784 on epoch=662, global_step=2650
06/01/2022 22:46:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 22:46:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 22:46:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 22:46:17 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/01/2022 22:46:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 22:46:20 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6965909834456586 on epoch=674
06/01/2022 22:46:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/01/2022 22:46:25 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=679
06/01/2022 22:46:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 22:46:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/01/2022 22:46:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 22:46:34 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6965909834456586 on epoch=687
06/01/2022 22:46:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 22:46:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 22:46:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=694
06/01/2022 22:46:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=697
06/01/2022 22:46:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 22:46:47 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6801782682512733 on epoch=699
06/01/2022 22:46:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 22:46:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 22:46:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 22:46:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 22:46:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 22:47:01 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6801782682512733 on epoch=712
06/01/2022 22:47:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 22:47:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 22:47:08 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 22:47:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 22:47:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 22:47:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6801782682512733 on epoch=724
06/01/2022 22:47:16 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 22:47:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 22:47:21 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 22:47:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 22:47:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=737
06/01/2022 22:47:27 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6592487373737372 on epoch=737
06/01/2022 22:47:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/01/2022 22:47:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 22:47:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 22:47:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 22:47:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/01/2022 22:47:41 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6597222222222222 on epoch=749
06/01/2022 22:47:41 - INFO - __main__ - save last model!
06/01/2022 22:47:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 22:47:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 22:47:41 - INFO - __main__ - Printing 3 examples
06/01/2022 22:47:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 22:47:41 - INFO - __main__ - ['others']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 22:47:41 - INFO - __main__ - ['others']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 22:47:41 - INFO - __main__ - ['others']
06/01/2022 22:47:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:47:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:47:41 - INFO - __main__ - Printing 3 examples
06/01/2022 22:47:41 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:47:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:47:41 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:47:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:47:41 - INFO - __main__ - Printing 3 examples
06/01/2022 22:47:41 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:47:41 - INFO - __main__ - ['happy']
06/01/2022 22:47:41 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:47:41 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:47:41 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:47:43 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:47:48 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 22:47:56 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:47:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:47:57 - INFO - __main__ - Starting training!
06/01/2022 22:49:24 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/01/2022 22:49:24 - INFO - __main__ - Classification-F1 on test data: 0.1170
06/01/2022 22:49:25 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.7033783783783784, test_performance=0.11701846513810414
06/01/2022 22:49:25 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/01/2022 22:49:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:49:26 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:26 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:26 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 22:49:26 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 22:49:26 - INFO - __main__ - Printing 3 examples
06/01/2022 22:49:26 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/01/2022 22:49:26 - INFO - __main__ - ['happy']
06/01/2022 22:49:26 - INFO - __main__ - Tokenizing Input ...
06/01/2022 22:49:26 - INFO - __main__ - Tokenizing Output ...
06/01/2022 22:49:26 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 22:49:45 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 22:49:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 22:49:46 - INFO - __main__ - Starting training!
06/01/2022 22:49:49 - INFO - __main__ - Step 10 Global step 10 Train loss 4.44 on epoch=2
06/01/2022 22:49:52 - INFO - __main__ - Step 20 Global step 20 Train loss 3.33 on epoch=4
06/01/2022 22:49:54 - INFO - __main__ - Step 30 Global step 30 Train loss 2.44 on epoch=7
06/01/2022 22:49:57 - INFO - __main__ - Step 40 Global step 40 Train loss 2.00 on epoch=9
06/01/2022 22:49:59 - INFO - __main__ - Step 50 Global step 50 Train loss 1.65 on epoch=12
06/01/2022 22:50:00 - INFO - __main__ - Global step 50 Train loss 2.77 Classification-F1 0.1581196581196581 on epoch=12
06/01/2022 22:50:00 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1581196581196581 on epoch=12, global_step=50
06/01/2022 22:50:03 - INFO - __main__ - Step 60 Global step 60 Train loss 1.42 on epoch=14
06/01/2022 22:50:06 - INFO - __main__ - Step 70 Global step 70 Train loss 1.16 on epoch=17
06/01/2022 22:50:08 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/01/2022 22:50:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=22
06/01/2022 22:50:13 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/01/2022 22:50:14 - INFO - __main__ - Global step 100 Train loss 1.11 Classification-F1 0.20923520923520922 on epoch=24
06/01/2022 22:50:14 - INFO - __main__ - Saving model with best Classification-F1: 0.1581196581196581 -> 0.20923520923520922 on epoch=24, global_step=100
06/01/2022 22:50:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/01/2022 22:50:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.00 on epoch=29
06/01/2022 22:50:22 - INFO - __main__ - Step 130 Global step 130 Train loss 0.97 on epoch=32
06/01/2022 22:50:24 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=34
06/01/2022 22:50:27 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=37
06/01/2022 22:50:28 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.21107843137254903 on epoch=37
06/01/2022 22:50:28 - INFO - __main__ - Saving model with best Classification-F1: 0.20923520923520922 -> 0.21107843137254903 on epoch=37, global_step=150
06/01/2022 22:50:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.93 on epoch=39
06/01/2022 22:50:33 - INFO - __main__ - Step 170 Global step 170 Train loss 0.89 on epoch=42
06/01/2022 22:50:35 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=44
06/01/2022 22:50:38 - INFO - __main__ - Step 190 Global step 190 Train loss 0.93 on epoch=47
06/01/2022 22:50:40 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=49
06/01/2022 22:50:41 - INFO - __main__ - Global step 200 Train loss 0.88 Classification-F1 0.2786148612450445 on epoch=49
06/01/2022 22:50:41 - INFO - __main__ - Saving model with best Classification-F1: 0.21107843137254903 -> 0.2786148612450445 on epoch=49, global_step=200
06/01/2022 22:50:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=52
06/01/2022 22:50:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=54
06/01/2022 22:50:49 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=57
06/01/2022 22:50:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=59
06/01/2022 22:50:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.81 on epoch=62
06/01/2022 22:50:55 - INFO - __main__ - Global step 250 Train loss 0.82 Classification-F1 0.4444444444444444 on epoch=62
06/01/2022 22:50:55 - INFO - __main__ - Saving model with best Classification-F1: 0.2786148612450445 -> 0.4444444444444444 on epoch=62, global_step=250
06/01/2022 22:50:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=64
06/01/2022 22:51:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=67
06/01/2022 22:51:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.85 on epoch=69
06/01/2022 22:51:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.80 on epoch=72
06/01/2022 22:51:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=74
06/01/2022 22:51:08 - INFO - __main__ - Global step 300 Train loss 0.77 Classification-F1 0.49455128205128207 on epoch=74
06/01/2022 22:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4444444444444444 -> 0.49455128205128207 on epoch=74, global_step=300
06/01/2022 22:51:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=77
06/01/2022 22:51:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=79
06/01/2022 22:51:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=82
06/01/2022 22:51:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=84
06/01/2022 22:51:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=87
06/01/2022 22:51:21 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.537281399046105 on epoch=87
06/01/2022 22:51:21 - INFO - __main__ - Saving model with best Classification-F1: 0.49455128205128207 -> 0.537281399046105 on epoch=87, global_step=350
06/01/2022 22:51:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=89
06/01/2022 22:51:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=92
06/01/2022 22:51:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.73 on epoch=94
06/01/2022 22:51:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=97
06/01/2022 22:51:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.64 on epoch=99
06/01/2022 22:51:35 - INFO - __main__ - Global step 400 Train loss 0.68 Classification-F1 0.5843554295167197 on epoch=99
06/01/2022 22:51:35 - INFO - __main__ - Saving model with best Classification-F1: 0.537281399046105 -> 0.5843554295167197 on epoch=99, global_step=400
06/01/2022 22:51:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=102
06/01/2022 22:51:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.60 on epoch=104
06/01/2022 22:51:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.54 on epoch=107
06/01/2022 22:51:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=109
06/01/2022 22:51:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.58 on epoch=112
06/01/2022 22:51:48 - INFO - __main__ - Global step 450 Train loss 0.60 Classification-F1 0.6354276354276354 on epoch=112
06/01/2022 22:51:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5843554295167197 -> 0.6354276354276354 on epoch=112, global_step=450
06/01/2022 22:51:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.58 on epoch=114
06/01/2022 22:51:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.54 on epoch=117
06/01/2022 22:51:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.54 on epoch=119
06/01/2022 22:51:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=122
06/01/2022 22:52:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.53 on epoch=124
06/01/2022 22:52:02 - INFO - __main__ - Global step 500 Train loss 0.52 Classification-F1 0.6448177369419755 on epoch=124
06/01/2022 22:52:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6354276354276354 -> 0.6448177369419755 on epoch=124, global_step=500
06/01/2022 22:52:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.45 on epoch=127
06/01/2022 22:52:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.45 on epoch=129
06/01/2022 22:52:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.51 on epoch=132
06/01/2022 22:52:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=134
06/01/2022 22:52:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.52 on epoch=137
06/01/2022 22:52:15 - INFO - __main__ - Global step 550 Train loss 0.49 Classification-F1 0.6058695507708667 on epoch=137
06/01/2022 22:52:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.43 on epoch=139
06/01/2022 22:52:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.46 on epoch=142
06/01/2022 22:52:23 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=144
06/01/2022 22:52:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=147
06/01/2022 22:52:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.42 on epoch=149
06/01/2022 22:52:29 - INFO - __main__ - Global step 600 Train loss 0.43 Classification-F1 0.6376301716858993 on epoch=149
06/01/2022 22:52:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.35 on epoch=152
06/01/2022 22:52:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=154
06/01/2022 22:52:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=157
06/01/2022 22:52:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.34 on epoch=159
06/01/2022 22:52:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.36 on epoch=162
06/01/2022 22:52:42 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.6765886287625417 on epoch=162
06/01/2022 22:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6448177369419755 -> 0.6765886287625417 on epoch=162, global_step=650
06/01/2022 22:52:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=164
06/01/2022 22:52:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=167
06/01/2022 22:52:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.36 on epoch=169
06/01/2022 22:52:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.27 on epoch=172
06/01/2022 22:52:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=174
06/01/2022 22:52:56 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.6055518834051443 on epoch=174
06/01/2022 22:52:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=177
06/01/2022 22:53:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=179
06/01/2022 22:53:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/01/2022 22:53:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=184
06/01/2022 22:53:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=187
06/01/2022 22:53:09 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6199843022493279 on epoch=187
06/01/2022 22:53:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=189
06/01/2022 22:53:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=192
06/01/2022 22:53:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=194
06/01/2022 22:53:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=197
06/01/2022 22:53:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=199
06/01/2022 22:53:23 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.6094656868850417 on epoch=199
06/01/2022 22:53:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=202
06/01/2022 22:53:28 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=204
06/01/2022 22:53:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=207
06/01/2022 22:53:33 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=209
06/01/2022 22:53:36 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/01/2022 22:53:36 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5597392803275156 on epoch=212
06/01/2022 22:53:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=214
06/01/2022 22:53:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=217
06/01/2022 22:53:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/01/2022 22:53:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.10 on epoch=222
06/01/2022 22:53:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/01/2022 22:53:50 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.6199843022493279 on epoch=224
06/01/2022 22:53:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=227
06/01/2022 22:53:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=229
06/01/2022 22:53:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=232
06/01/2022 22:54:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/01/2022 22:54:03 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/01/2022 22:54:04 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6370343343392866 on epoch=237
06/01/2022 22:54:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/01/2022 22:54:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=242
06/01/2022 22:54:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=244
06/01/2022 22:54:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=247
06/01/2022 22:54:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=249
06/01/2022 22:54:17 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6480283589408304 on epoch=249
06/01/2022 22:54:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=252
06/01/2022 22:54:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=254
06/01/2022 22:54:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=257
06/01/2022 22:54:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=259
06/01/2022 22:54:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/01/2022 22:54:31 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6410119969040248 on epoch=262
06/01/2022 22:54:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/01/2022 22:54:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/01/2022 22:54:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/01/2022 22:54:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/01/2022 22:54:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=274
06/01/2022 22:54:45 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.6964840714840715 on epoch=274
06/01/2022 22:54:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6765886287625417 -> 0.6964840714840715 on epoch=274, global_step=1100
06/01/2022 22:54:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/01/2022 22:54:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/01/2022 22:54:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=282
06/01/2022 22:54:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=284
06/01/2022 22:54:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/01/2022 22:54:58 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6536454532185082 on epoch=287
06/01/2022 22:55:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/01/2022 22:55:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/01/2022 22:55:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=294
06/01/2022 22:55:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=297
06/01/2022 22:55:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/01/2022 22:55:12 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.6735569985569986 on epoch=299
06/01/2022 22:55:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 22:55:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 22:55:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/01/2022 22:55:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/01/2022 22:55:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/01/2022 22:55:26 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6738488843813387 on epoch=312
06/01/2022 22:55:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/01/2022 22:55:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
06/01/2022 22:55:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/01/2022 22:55:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=322
06/01/2022 22:55:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=324
06/01/2022 22:55:39 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.632509180949595 on epoch=324
06/01/2022 22:55:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/01/2022 22:55:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/01/2022 22:55:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/01/2022 22:55:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/01/2022 22:55:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=337
06/01/2022 22:55:52 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.6905677118580344 on epoch=337
06/01/2022 22:55:55 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/01/2022 22:55:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/01/2022 22:56:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=344
06/01/2022 22:56:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 22:56:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=349
06/01/2022 22:56:06 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6693730293475625 on epoch=349
06/01/2022 22:56:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=352
06/01/2022 22:56:11 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 22:56:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/01/2022 22:56:16 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/01/2022 22:56:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/01/2022 22:56:20 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7087412587412587 on epoch=362
06/01/2022 22:56:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6964840714840715 -> 0.7087412587412587 on epoch=362, global_step=1450
06/01/2022 22:56:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/01/2022 22:56:25 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/01/2022 22:56:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/01/2022 22:56:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=372
06/01/2022 22:56:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/01/2022 22:56:33 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.6551293318685708 on epoch=374
06/01/2022 22:56:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=377
06/01/2022 22:56:38 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/01/2022 22:56:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 22:56:43 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/01/2022 22:56:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 22:56:47 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6569604427136709 on epoch=387
06/01/2022 22:56:49 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 22:56:52 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 22:56:54 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/01/2022 22:56:57 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/01/2022 22:56:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 22:57:00 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.657896047307812 on epoch=399
06/01/2022 22:57:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=402
06/01/2022 22:57:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/01/2022 22:57:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/01/2022 22:57:10 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/01/2022 22:57:13 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=412
06/01/2022 22:57:14 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.6913588056680162 on epoch=412
06/01/2022 22:57:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/01/2022 22:57:19 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/01/2022 22:57:22 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 22:57:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/01/2022 22:57:27 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 22:57:28 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6504522570699042 on epoch=424
06/01/2022 22:57:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/01/2022 22:57:33 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/01/2022 22:57:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=432
06/01/2022 22:57:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/01/2022 22:57:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 22:57:42 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.6913588056680162 on epoch=437
06/01/2022 22:57:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/01/2022 22:57:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/01/2022 22:57:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=444
06/01/2022 22:57:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=447
06/01/2022 22:57:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/01/2022 22:57:55 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.6917073323323324 on epoch=449
06/01/2022 22:57:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/01/2022 22:58:00 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=454
06/01/2022 22:58:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 22:58:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/01/2022 22:58:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 22:58:10 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6717804999054999 on epoch=462
06/01/2022 22:58:12 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
06/01/2022 22:58:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/01/2022 22:58:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/01/2022 22:58:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/01/2022 22:58:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/01/2022 22:58:24 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6656575240066701 on epoch=474
06/01/2022 22:58:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=477
06/01/2022 22:58:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/01/2022 22:58:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=482
06/01/2022 22:58:34 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=484
06/01/2022 22:58:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/01/2022 22:58:38 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6942989805893032 on epoch=487
06/01/2022 22:58:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/01/2022 22:58:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/01/2022 22:58:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/01/2022 22:58:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 22:58:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/01/2022 22:58:52 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6757238737789022 on epoch=499
06/01/2022 22:58:55 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/01/2022 22:58:57 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/01/2022 22:59:00 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 22:59:03 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=509
06/01/2022 22:59:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/01/2022 22:59:06 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6627609108159392 on epoch=512
06/01/2022 22:59:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/01/2022 22:59:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 22:59:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/01/2022 22:59:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/01/2022 22:59:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=524
06/01/2022 22:59:20 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6757238737789022 on epoch=524
06/01/2022 22:59:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/01/2022 22:59:25 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 22:59:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/01/2022 22:59:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=534
06/01/2022 22:59:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=537
06/01/2022 22:59:33 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6551293318685708 on epoch=537
06/01/2022 22:59:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=539
06/01/2022 22:59:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/01/2022 22:59:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=544
06/01/2022 22:59:43 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/01/2022 22:59:45 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/01/2022 22:59:47 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6710616028708134 on epoch=549
06/01/2022 22:59:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/01/2022 22:59:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=554
06/01/2022 22:59:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=557
06/01/2022 22:59:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=559
06/01/2022 22:59:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=562
06/01/2022 23:00:00 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6766359321506381 on epoch=562
06/01/2022 23:00:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 23:00:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/01/2022 23:00:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 23:00:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=572
06/01/2022 23:00:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/01/2022 23:00:13 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.6757238737789022 on epoch=574
06/01/2022 23:00:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 23:00:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 23:00:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 23:00:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=584
06/01/2022 23:00:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 23:00:26 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6656575240066701 on epoch=587
06/01/2022 23:00:29 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 23:00:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 23:00:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/01/2022 23:00:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/01/2022 23:00:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/01/2022 23:00:40 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6623485236388462 on epoch=599
06/01/2022 23:00:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 23:00:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 23:00:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/01/2022 23:00:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 23:00:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/01/2022 23:00:53 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6754695872342931 on epoch=612
06/01/2022 23:00:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/01/2022 23:00:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 23:01:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=619
06/01/2022 23:01:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/01/2022 23:01:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/01/2022 23:01:06 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6754695872342931 on epoch=624
06/01/2022 23:01:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 23:01:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=629
06/01/2022 23:01:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=632
06/01/2022 23:01:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 23:01:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 23:01:19 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6948004038521279 on epoch=637
06/01/2022 23:01:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 23:01:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 23:01:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 23:01:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=647
06/01/2022 23:01:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/01/2022 23:01:33 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6782591610177817 on epoch=649
06/01/2022 23:01:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 23:01:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=654
06/01/2022 23:01:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=657
06/01/2022 23:01:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/01/2022 23:01:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 23:01:46 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6946225071225071 on epoch=662
06/01/2022 23:01:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=664
06/01/2022 23:01:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 23:01:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 23:01:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/01/2022 23:01:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=674
06/01/2022 23:01:59 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6955619412515964 on epoch=674
06/01/2022 23:02:02 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 23:02:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 23:02:06 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/01/2022 23:02:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=684
06/01/2022 23:02:11 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/01/2022 23:02:12 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6291044891044891 on epoch=687
06/01/2022 23:02:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/01/2022 23:02:17 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 23:02:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 23:02:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 23:02:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 23:02:26 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6975662084498291 on epoch=699
06/01/2022 23:02:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 23:02:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 23:02:33 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 23:02:35 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 23:02:38 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/01/2022 23:02:39 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6789352413291293 on epoch=712
06/01/2022 23:02:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=714
06/01/2022 23:02:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=717
06/01/2022 23:02:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/01/2022 23:02:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/01/2022 23:02:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 23:02:52 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6799337226548017 on epoch=724
06/01/2022 23:02:55 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/01/2022 23:02:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 23:03:00 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 23:03:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=734
06/01/2022 23:03:05 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/01/2022 23:03:06 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6948004038521279 on epoch=737
06/01/2022 23:03:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=739
06/01/2022 23:03:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 23:03:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 23:03:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 23:03:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/01/2022 23:03:19 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6942989805893032 on epoch=749
06/01/2022 23:03:19 - INFO - __main__ - save last model!
06/01/2022 23:03:19 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 23:03:19 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 23:03:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:03:19 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:03:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:03:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:03:19 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:03:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:03:19 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:03:19 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:03:19 - INFO - __main__ - Printing 3 examples
06/01/2022 23:03:19 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:03:19 - INFO - __main__ - ['others']
06/01/2022 23:03:19 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:03:19 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:03:19 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:03:21 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:03:27 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 23:03:35 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:03:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:03:35 - INFO - __main__ - Starting training!
06/01/2022 23:05:02 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/01/2022 23:05:02 - INFO - __main__ - Classification-F1 on test data: 0.3286
06/01/2022 23:05:02 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.7087412587412587, test_performance=0.32859512226707394
06/01/2022 23:05:02 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/01/2022 23:05:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:05:03 - INFO - __main__ - Printing 3 examples
06/01/2022 23:05:03 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:05:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:05:03 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:05:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:05:03 - INFO - __main__ - Printing 3 examples
06/01/2022 23:05:03 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:05:03 - INFO - __main__ - ['others']
06/01/2022 23:05:03 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:05:03 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:05:03 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:05:19 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:05:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:05:20 - INFO - __main__ - Starting training!
06/01/2022 23:05:23 - INFO - __main__ - Step 10 Global step 10 Train loss 3.49 on epoch=2
06/01/2022 23:05:26 - INFO - __main__ - Step 20 Global step 20 Train loss 1.64 on epoch=4
06/01/2022 23:05:28 - INFO - __main__ - Step 30 Global step 30 Train loss 1.16 on epoch=7
06/01/2022 23:05:31 - INFO - __main__ - Step 40 Global step 40 Train loss 0.96 on epoch=9
06/01/2022 23:05:33 - INFO - __main__ - Step 50 Global step 50 Train loss 1.02 on epoch=12
06/01/2022 23:05:34 - INFO - __main__ - Global step 50 Train loss 1.65 Classification-F1 0.13067758749069247 on epoch=12
06/01/2022 23:05:34 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13067758749069247 on epoch=12, global_step=50
06/01/2022 23:05:37 - INFO - __main__ - Step 60 Global step 60 Train loss 0.98 on epoch=14
06/01/2022 23:05:39 - INFO - __main__ - Step 70 Global step 70 Train loss 0.85 on epoch=17
06/01/2022 23:05:42 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=19
06/01/2022 23:05:44 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=22
06/01/2022 23:05:47 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=24
06/01/2022 23:05:48 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.23055555555555554 on epoch=24
06/01/2022 23:05:48 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.23055555555555554 on epoch=24, global_step=100
06/01/2022 23:05:50 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=27
06/01/2022 23:05:53 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=29
06/01/2022 23:05:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.94 on epoch=32
06/01/2022 23:05:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.82 on epoch=34
06/01/2022 23:06:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.85 on epoch=37
06/01/2022 23:06:01 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.22174447174447173 on epoch=37
06/01/2022 23:06:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=39
06/01/2022 23:06:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=42
06/01/2022 23:06:08 - INFO - __main__ - Step 180 Global step 180 Train loss 0.83 on epoch=44
06/01/2022 23:06:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=47
06/01/2022 23:06:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=49
06/01/2022 23:06:14 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.3948470209339774 on epoch=49
06/01/2022 23:06:14 - INFO - __main__ - Saving model with best Classification-F1: 0.23055555555555554 -> 0.3948470209339774 on epoch=49, global_step=200
06/01/2022 23:06:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=52
06/01/2022 23:06:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.70 on epoch=54
06/01/2022 23:06:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=57
06/01/2022 23:06:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.67 on epoch=59
06/01/2022 23:06:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=62
06/01/2022 23:06:28 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.6914133732629064 on epoch=62
06/01/2022 23:06:28 - INFO - __main__ - Saving model with best Classification-F1: 0.3948470209339774 -> 0.6914133732629064 on epoch=62, global_step=250
06/01/2022 23:06:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=64
06/01/2022 23:06:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=67
06/01/2022 23:06:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=69
06/01/2022 23:06:38 - INFO - __main__ - Step 290 Global step 290 Train loss 0.48 on epoch=72
06/01/2022 23:06:40 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=74
06/01/2022 23:06:41 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.5583333333333333 on epoch=74
06/01/2022 23:06:44 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=77
06/01/2022 23:06:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=79
06/01/2022 23:06:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=82
06/01/2022 23:06:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=84
06/01/2022 23:06:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=87
06/01/2022 23:06:54 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6964925399708007 on epoch=87
06/01/2022 23:06:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6914133732629064 -> 0.6964925399708007 on epoch=87, global_step=350
06/01/2022 23:06:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=89
06/01/2022 23:06:59 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=92
06/01/2022 23:07:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=94
06/01/2022 23:07:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.29 on epoch=97
06/01/2022 23:07:07 - INFO - __main__ - Step 400 Global step 400 Train loss 0.24 on epoch=99
06/01/2022 23:07:08 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.668201754385965 on epoch=99
06/01/2022 23:07:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.21 on epoch=102
06/01/2022 23:07:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=104
06/01/2022 23:07:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=107
06/01/2022 23:07:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/01/2022 23:07:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/01/2022 23:07:21 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.6281615950546341 on epoch=112
06/01/2022 23:07:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=114
06/01/2022 23:07:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.16 on epoch=117
06/01/2022 23:07:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/01/2022 23:07:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/01/2022 23:07:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=124
06/01/2022 23:07:35 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.6578615098351941 on epoch=124
06/01/2022 23:07:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.14 on epoch=127
06/01/2022 23:07:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=129
06/01/2022 23:07:42 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/01/2022 23:07:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.11 on epoch=134
06/01/2022 23:07:47 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/01/2022 23:07:48 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.6801657310879444 on epoch=137
06/01/2022 23:07:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.09 on epoch=139
06/01/2022 23:07:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.12 on epoch=142
06/01/2022 23:07:55 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/01/2022 23:07:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.07 on epoch=147
06/01/2022 23:08:00 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
06/01/2022 23:08:01 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.7711853832442068 on epoch=149
06/01/2022 23:08:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6964925399708007 -> 0.7711853832442068 on epoch=149, global_step=600
06/01/2022 23:08:04 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/01/2022 23:08:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.09 on epoch=154
06/01/2022 23:08:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/01/2022 23:08:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=159
06/01/2022 23:08:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/01/2022 23:08:15 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.7609959893048128 on epoch=162
06/01/2022 23:08:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/01/2022 23:08:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=167
06/01/2022 23:08:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.04 on epoch=169
06/01/2022 23:08:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.06 on epoch=172
06/01/2022 23:08:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/01/2022 23:08:28 - INFO - __main__ - Global step 700 Train loss 0.06 Classification-F1 0.7211455211455212 on epoch=174
06/01/2022 23:08:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/01/2022 23:08:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/01/2022 23:08:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/01/2022 23:08:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/01/2022 23:08:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/01/2022 23:08:42 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.7723665223665224 on epoch=187
06/01/2022 23:08:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7711853832442068 -> 0.7723665223665224 on epoch=187, global_step=750
06/01/2022 23:08:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/01/2022 23:08:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/01/2022 23:08:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=194
06/01/2022 23:08:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=197
06/01/2022 23:08:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/01/2022 23:08:55 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.7370583717357911 on epoch=199
06/01/2022 23:08:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=202
06/01/2022 23:09:01 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/01/2022 23:09:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/01/2022 23:09:06 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/01/2022 23:09:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/01/2022 23:09:09 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7677336853394935 on epoch=212
06/01/2022 23:09:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.05 on epoch=214
06/01/2022 23:09:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/01/2022 23:09:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/01/2022 23:09:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.02 on epoch=222
06/01/2022 23:09:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/01/2022 23:09:23 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.7595657031140903 on epoch=224
06/01/2022 23:09:25 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/01/2022 23:09:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/01/2022 23:09:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/01/2022 23:09:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/01/2022 23:09:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/01/2022 23:09:36 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.8020605264438281 on epoch=237
06/01/2022 23:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7723665223665224 -> 0.8020605264438281 on epoch=237, global_step=950
06/01/2022 23:09:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/01/2022 23:09:41 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/01/2022 23:09:44 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/01/2022 23:09:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/01/2022 23:09:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/01/2022 23:09:50 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.765810276679842 on epoch=249
06/01/2022 23:09:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 23:09:55 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/01/2022 23:09:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/01/2022 23:10:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/01/2022 23:10:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/01/2022 23:10:03 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7856898003956828 on epoch=262
06/01/2022 23:10:06 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=264
06/01/2022 23:10:08 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/01/2022 23:10:11 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/01/2022 23:10:14 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/01/2022 23:10:16 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/01/2022 23:10:17 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.7858912655971481 on epoch=274
06/01/2022 23:10:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/01/2022 23:10:23 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/01/2022 23:10:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=282
06/01/2022 23:10:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=284
06/01/2022 23:10:30 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/01/2022 23:10:31 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7597296494355318 on epoch=287
06/01/2022 23:10:34 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/01/2022 23:10:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/01/2022 23:10:39 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/01/2022 23:10:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/01/2022 23:10:44 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/01/2022 23:10:45 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.7810954816709292 on epoch=299
06/01/2022 23:10:48 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 23:10:50 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 23:10:53 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 23:10:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/01/2022 23:10:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/01/2022 23:10:59 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7509805118500771 on epoch=312
06/01/2022 23:11:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 23:11:04 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/01/2022 23:11:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.02 on epoch=319
06/01/2022 23:11:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/01/2022 23:11:12 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=324
06/01/2022 23:11:13 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7497238222993767 on epoch=324
06/01/2022 23:11:15 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/01/2022 23:11:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/01/2022 23:11:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/01/2022 23:11:23 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/01/2022 23:11:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 23:11:27 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7721233230134159 on epoch=337
06/01/2022 23:11:29 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=339
06/01/2022 23:11:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 23:11:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/01/2022 23:11:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/01/2022 23:11:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/01/2022 23:11:41 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.790214687273511 on epoch=349
06/01/2022 23:11:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 23:11:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 23:11:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/01/2022 23:11:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/01/2022 23:11:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 23:11:55 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.7806753136037025 on epoch=362
06/01/2022 23:11:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/01/2022 23:12:00 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/01/2022 23:12:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/01/2022 23:12:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/01/2022 23:12:08 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/01/2022 23:12:09 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.8014705882352942 on epoch=374
06/01/2022 23:12:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/01/2022 23:12:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/01/2022 23:12:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/01/2022 23:12:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/01/2022 23:12:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 23:12:22 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7360360360360361 on epoch=387
06/01/2022 23:12:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/01/2022 23:12:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/01/2022 23:12:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/01/2022 23:12:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/01/2022 23:12:35 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 23:12:36 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.786927301633184 on epoch=399
06/01/2022 23:12:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 23:12:42 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/01/2022 23:12:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 23:12:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 23:12:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/01/2022 23:12:50 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.806945126945127 on epoch=412
06/01/2022 23:12:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8020605264438281 -> 0.806945126945127 on epoch=412, global_step=1650
06/01/2022 23:12:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/01/2022 23:12:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=417
06/01/2022 23:12:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 23:13:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/01/2022 23:13:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 23:13:05 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.7355783701321459 on epoch=424
06/01/2022 23:13:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/01/2022 23:13:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 23:13:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 23:13:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=434
06/01/2022 23:13:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/01/2022 23:13:19 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7721233230134159 on epoch=437
06/01/2022 23:13:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/01/2022 23:13:24 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/01/2022 23:13:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=444
06/01/2022 23:13:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/01/2022 23:13:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/01/2022 23:13:33 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7718691891017868 on epoch=449
06/01/2022 23:13:35 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/01/2022 23:13:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/01/2022 23:13:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 23:13:43 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=459
06/01/2022 23:13:46 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 23:13:47 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.8014705882352942 on epoch=462
06/01/2022 23:13:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/01/2022 23:13:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/01/2022 23:13:55 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 23:13:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 23:14:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 23:14:01 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.758982683982684 on epoch=474
06/01/2022 23:14:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 23:14:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 23:14:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/01/2022 23:14:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 23:14:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 23:14:15 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7718691891017868 on epoch=487
06/01/2022 23:14:18 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=489
06/01/2022 23:14:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 23:14:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 23:14:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 23:14:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 23:14:29 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.7355783701321459 on epoch=499
06/01/2022 23:14:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 23:14:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/01/2022 23:14:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/01/2022 23:14:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 23:14:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/01/2022 23:14:43 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7509458915531022 on epoch=512
06/01/2022 23:14:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/01/2022 23:14:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 23:14:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 23:14:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/01/2022 23:14:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 23:14:58 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.7953811959566436 on epoch=524
06/01/2022 23:15:00 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 23:15:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 23:15:05 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 23:15:08 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 23:15:10 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=537
06/01/2022 23:15:12 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7220429450030968 on epoch=537
06/01/2022 23:15:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 23:15:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 23:15:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 23:15:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 23:15:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=549
06/01/2022 23:15:26 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7597296494355318 on epoch=549
06/01/2022 23:15:28 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 23:15:31 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 23:15:33 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/01/2022 23:15:36 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 23:15:38 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=562
06/01/2022 23:15:40 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7596545743604567 on epoch=562
06/01/2022 23:15:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/01/2022 23:15:45 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 23:15:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=569
06/01/2022 23:15:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 23:15:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 23:15:54 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6920570657412763 on epoch=574
06/01/2022 23:15:56 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/01/2022 23:15:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/01/2022 23:16:01 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 23:16:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 23:16:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 23:16:07 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7519487512084092 on epoch=587
06/01/2022 23:16:10 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 23:16:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/01/2022 23:16:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 23:16:18 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 23:16:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 23:16:22 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7519487512084092 on epoch=599
06/01/2022 23:16:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 23:16:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 23:16:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 23:16:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 23:16:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 23:16:36 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7557017543859649 on epoch=612
06/01/2022 23:16:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 23:16:41 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 23:16:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/01/2022 23:16:46 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 23:16:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 23:16:50 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7519487512084092 on epoch=624
06/01/2022 23:16:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 23:16:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 23:16:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 23:17:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 23:17:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 23:17:04 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.707172342621259 on epoch=637
06/01/2022 23:17:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 23:17:09 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 23:17:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 23:17:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 23:17:17 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/01/2022 23:17:18 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7519487512084092 on epoch=649
06/01/2022 23:17:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 23:17:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 23:17:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 23:17:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 23:17:31 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/01/2022 23:17:32 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7509805118500771 on epoch=662
06/01/2022 23:17:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 23:17:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 23:17:40 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 23:17:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 23:17:45 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 23:17:46 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.786927301633184 on epoch=674
06/01/2022 23:17:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/01/2022 23:17:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 23:17:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/01/2022 23:17:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=684
06/01/2022 23:17:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 23:18:00 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7721233230134159 on epoch=687
06/01/2022 23:18:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 23:18:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 23:18:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/01/2022 23:18:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 23:18:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 23:18:14 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.8014705882352942 on epoch=699
06/01/2022 23:18:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 23:18:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 23:18:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 23:18:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/01/2022 23:18:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 23:18:28 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7718691891017868 on epoch=712
06/01/2022 23:18:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 23:18:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 23:18:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 23:18:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/01/2022 23:18:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 23:18:42 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.721719070403281 on epoch=724
06/01/2022 23:18:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 23:18:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 23:18:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 23:18:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/01/2022 23:18:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/01/2022 23:18:56 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7557017543859649 on epoch=737
06/01/2022 23:18:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/01/2022 23:19:01 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=742
06/01/2022 23:19:04 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 23:19:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 23:19:09 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 23:19:10 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7557401568437222 on epoch=749
06/01/2022 23:19:10 - INFO - __main__ - save last model!
06/01/2022 23:19:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 23:19:10 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 23:19:10 - INFO - __main__ - Printing 3 examples
06/01/2022 23:19:10 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 23:19:10 - INFO - __main__ - ['others']
06/01/2022 23:19:10 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 23:19:10 - INFO - __main__ - ['others']
06/01/2022 23:19:10 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 23:19:10 - INFO - __main__ - ['others']
06/01/2022 23:19:10 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:19:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:19:11 - INFO - __main__ - Printing 3 examples
06/01/2022 23:19:11 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:19:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:19:11 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:19:11 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:19:11 - INFO - __main__ - Printing 3 examples
06/01/2022 23:19:11 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:19:11 - INFO - __main__ - ['others']
06/01/2022 23:19:11 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:19:11 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:19:11 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:19:12 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:19:18 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 23:19:30 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:19:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:19:31 - INFO - __main__ - Starting training!
06/01/2022 23:20:53 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/01/2022 23:20:53 - INFO - __main__ - Classification-F1 on test data: 0.2293
06/01/2022 23:20:54 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.806945126945127, test_performance=0.22933005552259947
06/01/2022 23:20:54 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/01/2022 23:20:54 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:20:54 - INFO - __main__ - Printing 3 examples
06/01/2022 23:20:54 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:20:54 - INFO - __main__ - ['others']
06/01/2022 23:20:54 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:20:54 - INFO - __main__ - ['others']
06/01/2022 23:20:54 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:20:54 - INFO - __main__ - ['others']
06/01/2022 23:20:54 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:20:54 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:20:55 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:20:55 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:20:55 - INFO - __main__ - Printing 3 examples
06/01/2022 23:20:55 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:20:55 - INFO - __main__ - ['others']
06/01/2022 23:20:55 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:20:55 - INFO - __main__ - ['others']
06/01/2022 23:20:55 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:20:55 - INFO - __main__ - ['others']
06/01/2022 23:20:55 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:20:55 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:20:55 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:21:13 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:21:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:21:14 - INFO - __main__ - Starting training!
06/01/2022 23:21:17 - INFO - __main__ - Step 10 Global step 10 Train loss 3.57 on epoch=2
06/01/2022 23:21:20 - INFO - __main__ - Step 20 Global step 20 Train loss 1.95 on epoch=4
06/01/2022 23:21:23 - INFO - __main__ - Step 30 Global step 30 Train loss 1.41 on epoch=7
06/01/2022 23:21:25 - INFO - __main__ - Step 40 Global step 40 Train loss 1.05 on epoch=9
06/01/2022 23:21:28 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=12
06/01/2022 23:21:29 - INFO - __main__ - Global step 50 Train loss 1.79 Classification-F1 0.1 on epoch=12
06/01/2022 23:21:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/01/2022 23:21:31 - INFO - __main__ - Step 60 Global step 60 Train loss 0.91 on epoch=14
06/01/2022 23:21:34 - INFO - __main__ - Step 70 Global step 70 Train loss 0.87 on epoch=17
06/01/2022 23:21:36 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/01/2022 23:21:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=22
06/01/2022 23:21:41 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/01/2022 23:21:42 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.2212121212121212 on epoch=24
06/01/2022 23:21:42 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.2212121212121212 on epoch=24, global_step=100
06/01/2022 23:21:45 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/01/2022 23:21:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/01/2022 23:21:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
06/01/2022 23:21:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.87 on epoch=34
06/01/2022 23:21:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=37
06/01/2022 23:21:56 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.2874601895552742 on epoch=37
06/01/2022 23:21:56 - INFO - __main__ - Saving model with best Classification-F1: 0.2212121212121212 -> 0.2874601895552742 on epoch=37, global_step=150
06/01/2022 23:21:58 - INFO - __main__ - Step 160 Global step 160 Train loss 0.87 on epoch=39
06/01/2022 23:22:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.78 on epoch=42
06/01/2022 23:22:03 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=44
06/01/2022 23:22:06 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/01/2022 23:22:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=49
06/01/2022 23:22:09 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.33481956612432207 on epoch=49
06/01/2022 23:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.2874601895552742 -> 0.33481956612432207 on epoch=49, global_step=200
06/01/2022 23:22:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=52
06/01/2022 23:22:14 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=54
06/01/2022 23:22:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=57
06/01/2022 23:22:19 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=59
06/01/2022 23:22:22 - INFO - __main__ - Step 250 Global step 250 Train loss 0.51 on epoch=62
06/01/2022 23:22:23 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.6558558558558559 on epoch=62
06/01/2022 23:22:23 - INFO - __main__ - Saving model with best Classification-F1: 0.33481956612432207 -> 0.6558558558558559 on epoch=62, global_step=250
06/01/2022 23:22:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=64
06/01/2022 23:22:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/01/2022 23:22:30 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=69
06/01/2022 23:22:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=72
06/01/2022 23:22:35 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=74
06/01/2022 23:22:36 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.4800595238095238 on epoch=74
06/01/2022 23:22:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=77
06/01/2022 23:22:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.43 on epoch=79
06/01/2022 23:22:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=82
06/01/2022 23:22:47 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=84
06/01/2022 23:22:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=87
06/01/2022 23:22:50 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.5699523052464228 on epoch=87
06/01/2022 23:22:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=89
06/01/2022 23:22:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=92
06/01/2022 23:22:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=94
06/01/2022 23:23:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=97
06/01/2022 23:23:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.25 on epoch=99
06/01/2022 23:23:03 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.6167887969105008 on epoch=99
06/01/2022 23:23:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=102
06/01/2022 23:23:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=104
06/01/2022 23:23:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=107
06/01/2022 23:23:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=109
06/01/2022 23:23:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=112
06/01/2022 23:23:17 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.6856803327391563 on epoch=112
06/01/2022 23:23:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6558558558558559 -> 0.6856803327391563 on epoch=112, global_step=450
06/01/2022 23:23:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=114
06/01/2022 23:23:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=117
06/01/2022 23:23:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/01/2022 23:23:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.17 on epoch=122
06/01/2022 23:23:30 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/01/2022 23:23:31 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.7217621909991919 on epoch=124
06/01/2022 23:23:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6856803327391563 -> 0.7217621909991919 on epoch=124, global_step=500
06/01/2022 23:23:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.19 on epoch=127
06/01/2022 23:23:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.14 on epoch=129
06/01/2022 23:23:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.13 on epoch=132
06/01/2022 23:23:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=134
06/01/2022 23:23:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/01/2022 23:23:45 - INFO - __main__ - Global step 550 Train loss 0.15 Classification-F1 0.706541769041769 on epoch=137
06/01/2022 23:23:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=139
06/01/2022 23:23:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.10 on epoch=142
06/01/2022 23:23:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.11 on epoch=144
06/01/2022 23:23:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=147
06/01/2022 23:23:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/01/2022 23:23:58 - INFO - __main__ - Global step 600 Train loss 0.12 Classification-F1 0.7444419379903251 on epoch=149
06/01/2022 23:23:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7217621909991919 -> 0.7444419379903251 on epoch=149, global_step=600
06/01/2022 23:24:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/01/2022 23:24:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=154
06/01/2022 23:24:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/01/2022 23:24:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
06/01/2022 23:24:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/01/2022 23:24:12 - INFO - __main__ - Global step 650 Train loss 0.10 Classification-F1 0.7458407605466428 on epoch=162
06/01/2022 23:24:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7444419379903251 -> 0.7458407605466428 on epoch=162, global_step=650
06/01/2022 23:24:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=164
06/01/2022 23:24:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/01/2022 23:24:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.08 on epoch=169
06/01/2022 23:24:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=172
06/01/2022 23:24:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.05 on epoch=174
06/01/2022 23:24:26 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.7075906120023767 on epoch=174
06/01/2022 23:24:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.04 on epoch=177
06/01/2022 23:24:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/01/2022 23:24:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.03 on epoch=182
06/01/2022 23:24:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/01/2022 23:24:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/01/2022 23:24:39 - INFO - __main__ - Global step 750 Train loss 0.05 Classification-F1 0.7596545743604567 on epoch=187
06/01/2022 23:24:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7458407605466428 -> 0.7596545743604567 on epoch=187, global_step=750
06/01/2022 23:24:42 - INFO - __main__ - Step 760 Global step 760 Train loss 0.04 on epoch=189
06/01/2022 23:24:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/01/2022 23:24:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.03 on epoch=194
06/01/2022 23:24:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/01/2022 23:24:52 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/01/2022 23:24:53 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.7810954816709292 on epoch=199
06/01/2022 23:24:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7596545743604567 -> 0.7810954816709292 on epoch=199, global_step=800
06/01/2022 23:24:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/01/2022 23:24:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/01/2022 23:25:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/01/2022 23:25:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/01/2022 23:25:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=212
06/01/2022 23:25:07 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.7447204968944099 on epoch=212
06/01/2022 23:25:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/01/2022 23:25:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/01/2022 23:25:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=219
06/01/2022 23:25:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/01/2022 23:25:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/01/2022 23:25:21 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.758982683982684 on epoch=224
06/01/2022 23:25:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/01/2022 23:25:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/01/2022 23:25:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
06/01/2022 23:25:31 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/01/2022 23:25:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/01/2022 23:25:34 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7678336904679616 on epoch=237
06/01/2022 23:25:37 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/01/2022 23:25:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 23:25:42 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
06/01/2022 23:25:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/01/2022 23:25:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.03 on epoch=249
06/01/2022 23:25:48 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.7864705882352941 on epoch=249
06/01/2022 23:25:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7810954816709292 -> 0.7864705882352941 on epoch=249, global_step=1000
06/01/2022 23:25:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/01/2022 23:25:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/01/2022 23:25:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/01/2022 23:25:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/01/2022 23:26:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/01/2022 23:26:02 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.7810954816709292 on epoch=262
06/01/2022 23:26:05 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/01/2022 23:26:07 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=267
06/01/2022 23:26:10 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/01/2022 23:26:12 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/01/2022 23:26:15 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/01/2022 23:26:16 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.8014705882352942 on epoch=274
06/01/2022 23:26:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7864705882352941 -> 0.8014705882352942 on epoch=274, global_step=1100
06/01/2022 23:26:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=277
06/01/2022 23:26:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/01/2022 23:26:24 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/01/2022 23:26:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/01/2022 23:26:29 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/01/2022 23:26:30 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.7408942583136131 on epoch=287
06/01/2022 23:26:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/01/2022 23:26:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/01/2022 23:26:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=294
06/01/2022 23:26:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/01/2022 23:26:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/01/2022 23:26:43 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7360360360360361 on epoch=299
06/01/2022 23:26:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/01/2022 23:26:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/01/2022 23:26:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 23:26:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/01/2022 23:26:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/01/2022 23:26:57 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7864705882352941 on epoch=312
06/01/2022 23:27:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/01/2022 23:27:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/01/2022 23:27:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/01/2022 23:27:07 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/01/2022 23:27:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/01/2022 23:27:11 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.7720023767082591 on epoch=324
06/01/2022 23:27:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/01/2022 23:27:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=329
06/01/2022 23:27:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/01/2022 23:27:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/01/2022 23:27:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/01/2022 23:27:25 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.8010427807486632 on epoch=337
06/01/2022 23:27:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 23:27:30 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/01/2022 23:27:32 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/01/2022 23:27:35 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/01/2022 23:27:37 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/01/2022 23:27:39 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.773940288646171 on epoch=349
06/01/2022 23:27:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/01/2022 23:27:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/01/2022 23:27:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/01/2022 23:27:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/01/2022 23:27:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/01/2022 23:27:53 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=362
06/01/2022 23:27:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/01/2022 23:27:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/01/2022 23:28:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=369
06/01/2022 23:28:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/01/2022 23:28:06 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/01/2022 23:28:07 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7814923070677546 on epoch=374
06/01/2022 23:28:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/01/2022 23:28:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/01/2022 23:28:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/01/2022 23:28:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/01/2022 23:28:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 23:28:21 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.7814923070677546 on epoch=387
06/01/2022 23:28:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 23:28:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/01/2022 23:28:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/01/2022 23:28:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/01/2022 23:28:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/01/2022 23:28:35 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.766809767385215 on epoch=399
06/01/2022 23:28:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/01/2022 23:28:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/01/2022 23:28:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 23:28:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/01/2022 23:28:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=412
06/01/2022 23:28:49 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7812454834513659 on epoch=412
06/01/2022 23:28:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/01/2022 23:28:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/01/2022 23:28:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/01/2022 23:28:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/01/2022 23:29:02 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/01/2022 23:29:03 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.7726670520788168 on epoch=424
06/01/2022 23:29:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 23:29:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/01/2022 23:29:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/01/2022 23:29:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/01/2022 23:29:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/01/2022 23:29:17 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.766809767385215 on epoch=437
06/01/2022 23:29:19 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=439
06/01/2022 23:29:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/01/2022 23:29:24 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/01/2022 23:29:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/01/2022 23:29:29 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/01/2022 23:29:30 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7960530863344163 on epoch=449
06/01/2022 23:29:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/01/2022 23:29:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/01/2022 23:29:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 23:29:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/01/2022 23:29:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/01/2022 23:29:45 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.7084293394777266 on epoch=462
06/01/2022 23:29:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=464
06/01/2022 23:29:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/01/2022 23:29:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 23:29:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 23:29:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/01/2022 23:29:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.766809767385215 on epoch=474
06/01/2022 23:30:01 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/01/2022 23:30:04 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 23:30:06 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 23:30:09 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 23:30:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 23:30:13 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.722718561108654 on epoch=487
06/01/2022 23:30:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/01/2022 23:30:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=492
06/01/2022 23:30:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 23:30:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=497
06/01/2022 23:30:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/01/2022 23:30:27 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.766809767385215 on epoch=499
06/01/2022 23:30:30 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/01/2022 23:30:32 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/01/2022 23:30:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=507
06/01/2022 23:30:37 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 23:30:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 23:30:41 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7867647058823529 on epoch=512
06/01/2022 23:30:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 23:30:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 23:30:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/01/2022 23:30:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/01/2022 23:30:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=524
06/01/2022 23:30:55 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7593795093795094 on epoch=524
06/01/2022 23:30:57 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 23:31:00 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/01/2022 23:31:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 23:31:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/01/2022 23:31:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 23:31:08 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.7593795093795094 on epoch=537
06/01/2022 23:31:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/01/2022 23:31:13 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/01/2022 23:31:16 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 23:31:18 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 23:31:21 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=549
06/01/2022 23:31:22 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7234262125902994 on epoch=549
06/01/2022 23:31:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 23:31:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/01/2022 23:31:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/01/2022 23:31:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 23:31:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 23:31:35 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.7678336904679616 on epoch=562
06/01/2022 23:31:38 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/01/2022 23:31:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/01/2022 23:31:43 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 23:31:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 23:31:48 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 23:31:49 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.74704475091472 on epoch=574
06/01/2022 23:31:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/01/2022 23:31:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 23:31:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 23:31:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/01/2022 23:32:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 23:32:03 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7533177038931514 on epoch=587
06/01/2022 23:32:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/01/2022 23:32:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 23:32:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/01/2022 23:32:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/01/2022 23:32:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 23:32:17 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7533177038931514 on epoch=599
06/01/2022 23:32:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 23:32:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/01/2022 23:32:24 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 23:32:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 23:32:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/01/2022 23:32:31 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.77296918767507 on epoch=612
06/01/2022 23:32:33 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/01/2022 23:32:36 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/01/2022 23:32:38 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/01/2022 23:32:41 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 23:32:43 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/01/2022 23:32:44 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7195374800637959 on epoch=624
06/01/2022 23:32:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/01/2022 23:32:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 23:32:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/01/2022 23:32:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/01/2022 23:32:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/01/2022 23:32:58 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.766809767385215 on epoch=637
06/01/2022 23:33:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 23:33:03 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 23:33:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/01/2022 23:33:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=647
06/01/2022 23:33:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=649
06/01/2022 23:33:12 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7338543809132045 on epoch=649
06/01/2022 23:33:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/01/2022 23:33:17 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 23:33:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/01/2022 23:33:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 23:33:25 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 23:33:26 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7338543809132045 on epoch=662
06/01/2022 23:33:28 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 23:33:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 23:33:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/01/2022 23:33:36 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/01/2022 23:33:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 23:33:39 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7531840140535793 on epoch=674
06/01/2022 23:33:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/01/2022 23:33:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 23:33:47 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=682
06/01/2022 23:33:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/01/2022 23:33:52 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/01/2022 23:33:53 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7466748937337173 on epoch=687
06/01/2022 23:33:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 23:33:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/01/2022 23:34:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=694
06/01/2022 23:34:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/01/2022 23:34:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 23:34:07 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7814923070677546 on epoch=699
06/01/2022 23:34:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=702
06/01/2022 23:34:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 23:34:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/01/2022 23:34:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/01/2022 23:34:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=712
06/01/2022 23:34:21 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7315675552517658 on epoch=712
06/01/2022 23:34:23 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 23:34:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/01/2022 23:34:28 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=719
06/01/2022 23:34:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/01/2022 23:34:33 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 23:34:34 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7613807760866584 on epoch=724
06/01/2022 23:34:37 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/01/2022 23:34:39 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/01/2022 23:34:42 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 23:34:44 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/01/2022 23:34:47 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/01/2022 23:34:48 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7814923070677546 on epoch=737
06/01/2022 23:34:51 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=739
06/01/2022 23:34:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 23:34:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/01/2022 23:34:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 23:35:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 23:35:02 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7814923070677546 on epoch=749
06/01/2022 23:35:02 - INFO - __main__ - save last model!
06/01/2022 23:35:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 23:35:02 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 23:35:02 - INFO - __main__ - Printing 3 examples
06/01/2022 23:35:02 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:35:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:35:02 - INFO - __main__ - Printing 3 examples
06/01/2022 23:35:02 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:35:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:35:02 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:35:02 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:35:02 - INFO - __main__ - Printing 3 examples
06/01/2022 23:35:02 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:35:02 - INFO - __main__ - ['others']
06/01/2022 23:35:02 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:35:02 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:35:02 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:35:04 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:35:09 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 23:35:18 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:35:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:35:18 - INFO - __main__ - Starting training!
06/01/2022 23:36:46 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/01/2022 23:36:46 - INFO - __main__ - Classification-F1 on test data: 0.3450
06/01/2022 23:36:47 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.8014705882352942, test_performance=0.34499330314051907
06/01/2022 23:36:47 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/01/2022 23:36:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:36:48 - INFO - __main__ - Printing 3 examples
06/01/2022 23:36:48 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:36:48 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:36:48 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:36:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:36:48 - INFO - __main__ - Printing 3 examples
06/01/2022 23:36:48 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:36:48 - INFO - __main__ - ['others']
06/01/2022 23:36:48 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:36:48 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:36:48 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:37:03 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:37:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:37:04 - INFO - __main__ - Starting training!
06/01/2022 23:37:07 - INFO - __main__ - Step 10 Global step 10 Train loss 4.05 on epoch=2
06/01/2022 23:37:10 - INFO - __main__ - Step 20 Global step 20 Train loss 2.52 on epoch=4
06/01/2022 23:37:12 - INFO - __main__ - Step 30 Global step 30 Train loss 1.77 on epoch=7
06/01/2022 23:37:15 - INFO - __main__ - Step 40 Global step 40 Train loss 1.33 on epoch=9
06/01/2022 23:37:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/01/2022 23:37:18 - INFO - __main__ - Global step 50 Train loss 2.16 Classification-F1 0.13149768399382397 on epoch=12
06/01/2022 23:37:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13149768399382397 on epoch=12, global_step=50
06/01/2022 23:37:21 - INFO - __main__ - Step 60 Global step 60 Train loss 1.07 on epoch=14
06/01/2022 23:37:23 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=17
06/01/2022 23:37:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
06/01/2022 23:37:28 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/01/2022 23:37:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/01/2022 23:37:32 - INFO - __main__ - Global step 100 Train loss 0.95 Classification-F1 0.1 on epoch=24
06/01/2022 23:37:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/01/2022 23:37:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/01/2022 23:37:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/01/2022 23:37:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=34
06/01/2022 23:37:44 - INFO - __main__ - Step 150 Global step 150 Train loss 0.84 on epoch=37
06/01/2022 23:37:45 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.25267605633802814 on epoch=37
06/01/2022 23:37:45 - INFO - __main__ - Saving model with best Classification-F1: 0.13149768399382397 -> 0.25267605633802814 on epoch=37, global_step=150
06/01/2022 23:37:48 - INFO - __main__ - Step 160 Global step 160 Train loss 0.87 on epoch=39
06/01/2022 23:37:50 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=42
06/01/2022 23:37:53 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=44
06/01/2022 23:37:55 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=47
06/01/2022 23:37:58 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=49
06/01/2022 23:37:59 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.24563380281690142 on epoch=49
06/01/2022 23:38:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=52
06/01/2022 23:38:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=54
06/01/2022 23:38:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=57
06/01/2022 23:38:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.74 on epoch=59
06/01/2022 23:38:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=62
06/01/2022 23:38:12 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.43537108053237084 on epoch=62
06/01/2022 23:38:12 - INFO - __main__ - Saving model with best Classification-F1: 0.25267605633802814 -> 0.43537108053237084 on epoch=62, global_step=250
06/01/2022 23:38:15 - INFO - __main__ - Step 260 Global step 260 Train loss 0.82 on epoch=64
06/01/2022 23:38:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.79 on epoch=67
06/01/2022 23:38:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=69
06/01/2022 23:38:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.68 on epoch=72
06/01/2022 23:38:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=74
06/01/2022 23:38:26 - INFO - __main__ - Global step 300 Train loss 0.74 Classification-F1 0.5971454173067077 on epoch=74
06/01/2022 23:38:26 - INFO - __main__ - Saving model with best Classification-F1: 0.43537108053237084 -> 0.5971454173067077 on epoch=74, global_step=300
06/01/2022 23:38:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=77
06/01/2022 23:38:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=79
06/01/2022 23:38:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=82
06/01/2022 23:38:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=84
06/01/2022 23:38:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=87
06/01/2022 23:38:39 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.6065457203615098 on epoch=87
06/01/2022 23:38:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5971454173067077 -> 0.6065457203615098 on epoch=87, global_step=350
06/01/2022 23:38:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=89
06/01/2022 23:38:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.41 on epoch=92
06/01/2022 23:38:46 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=94
06/01/2022 23:38:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=97
06/01/2022 23:38:51 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=99
06/01/2022 23:38:52 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.6734932088285229 on epoch=99
06/01/2022 23:38:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6065457203615098 -> 0.6734932088285229 on epoch=99, global_step=400
06/01/2022 23:38:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/01/2022 23:38:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=104
06/01/2022 23:39:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=107
06/01/2022 23:39:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.41 on epoch=109
06/01/2022 23:39:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=112
06/01/2022 23:39:06 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.6162104914145866 on epoch=112
06/01/2022 23:39:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=114
06/01/2022 23:39:11 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=117
06/01/2022 23:39:13 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=119
06/01/2022 23:39:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=122
06/01/2022 23:39:18 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=124
06/01/2022 23:39:19 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6794108669108669 on epoch=124
06/01/2022 23:39:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6734932088285229 -> 0.6794108669108669 on epoch=124, global_step=500
06/01/2022 23:39:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=127
06/01/2022 23:39:24 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=129
06/01/2022 23:39:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=132
06/01/2022 23:39:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=134
06/01/2022 23:39:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/01/2022 23:39:32 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.585977421271539 on epoch=137
06/01/2022 23:39:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/01/2022 23:39:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=142
06/01/2022 23:39:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=144
06/01/2022 23:39:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=147
06/01/2022 23:39:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=149
06/01/2022 23:39:46 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.6113562091503267 on epoch=149
06/01/2022 23:39:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/01/2022 23:39:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=154
06/01/2022 23:39:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=157
06/01/2022 23:39:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=159
06/01/2022 23:39:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=162
06/01/2022 23:39:59 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.6837670552091805 on epoch=162
06/01/2022 23:39:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6794108669108669 -> 0.6837670552091805 on epoch=162, global_step=650
06/01/2022 23:40:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=164
06/01/2022 23:40:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/01/2022 23:40:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=169
06/01/2022 23:40:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/01/2022 23:40:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/01/2022 23:40:12 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.7093805990864814 on epoch=174
06/01/2022 23:40:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6837670552091805 -> 0.7093805990864814 on epoch=174, global_step=700
06/01/2022 23:40:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=177
06/01/2022 23:40:17 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=179
06/01/2022 23:40:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/01/2022 23:40:22 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/01/2022 23:40:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/01/2022 23:40:26 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6837084762781357 on epoch=187
06/01/2022 23:40:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.08 on epoch=189
06/01/2022 23:40:31 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/01/2022 23:40:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=194
06/01/2022 23:40:36 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=197
06/01/2022 23:40:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/01/2022 23:40:39 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.760202645651562 on epoch=199
06/01/2022 23:40:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7093805990864814 -> 0.760202645651562 on epoch=199, global_step=800
06/01/2022 23:40:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=202
06/01/2022 23:40:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=204
06/01/2022 23:40:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/01/2022 23:40:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=209
06/01/2022 23:40:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=212
06/01/2022 23:40:53 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.7083333333333334 on epoch=212
06/01/2022 23:40:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/01/2022 23:40:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=217
06/01/2022 23:41:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/01/2022 23:41:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/01/2022 23:41:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=224
06/01/2022 23:41:06 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.7584847075336205 on epoch=224
06/01/2022 23:41:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/01/2022 23:41:11 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/01/2022 23:41:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/01/2022 23:41:16 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=234
06/01/2022 23:41:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=237
06/01/2022 23:41:20 - INFO - __main__ - Global step 950 Train loss 0.07 Classification-F1 0.7361853832442068 on epoch=237
06/01/2022 23:41:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/01/2022 23:41:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/01/2022 23:41:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=244
06/01/2022 23:41:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/01/2022 23:41:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/01/2022 23:41:33 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.7074646074646075 on epoch=249
06/01/2022 23:41:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=252
06/01/2022 23:41:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/01/2022 23:41:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/01/2022 23:41:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/01/2022 23:41:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/01/2022 23:41:47 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7225225225225225 on epoch=262
06/01/2022 23:41:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=264
06/01/2022 23:41:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/01/2022 23:41:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/01/2022 23:41:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/01/2022 23:41:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
06/01/2022 23:42:00 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7214285714285714 on epoch=274
06/01/2022 23:42:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/01/2022 23:42:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/01/2022 23:42:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/01/2022 23:42:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/01/2022 23:42:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/01/2022 23:42:14 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7503217503217504 on epoch=287
06/01/2022 23:42:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/01/2022 23:42:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/01/2022 23:42:21 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=294
06/01/2022 23:42:24 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=297
06/01/2022 23:42:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/01/2022 23:42:27 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.7079092079092079 on epoch=299
06/01/2022 23:42:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/01/2022 23:42:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/01/2022 23:42:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/01/2022 23:42:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/01/2022 23:42:40 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/01/2022 23:42:41 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.7503217503217504 on epoch=312
06/01/2022 23:42:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/01/2022 23:42:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/01/2022 23:42:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/01/2022 23:42:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=322
06/01/2022 23:42:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/01/2022 23:42:54 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7500000000000001 on epoch=324
06/01/2022 23:42:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/01/2022 23:42:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/01/2022 23:43:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=332
06/01/2022 23:43:04 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/01/2022 23:43:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/01/2022 23:43:08 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7503217503217504 on epoch=337
06/01/2022 23:43:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/01/2022 23:43:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/01/2022 23:43:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/01/2022 23:43:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/01/2022 23:43:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/01/2022 23:43:21 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.7500000000000001 on epoch=349
06/01/2022 23:43:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/01/2022 23:43:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=354
06/01/2022 23:43:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/01/2022 23:43:32 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/01/2022 23:43:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/01/2022 23:43:35 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.7357142857142857 on epoch=362
06/01/2022 23:43:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/01/2022 23:43:40 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/01/2022 23:43:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=369
06/01/2022 23:43:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/01/2022 23:43:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/01/2022 23:43:49 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7253217503217504 on epoch=374
06/01/2022 23:43:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/01/2022 23:43:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/01/2022 23:43:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/01/2022 23:43:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=384
06/01/2022 23:44:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/01/2022 23:44:02 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7505411255411256 on epoch=387
06/01/2022 23:44:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/01/2022 23:44:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/01/2022 23:44:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/01/2022 23:44:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/01/2022 23:44:15 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/01/2022 23:44:16 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.773940288646171 on epoch=399
06/01/2022 23:44:16 - INFO - __main__ - Saving model with best Classification-F1: 0.760202645651562 -> 0.773940288646171 on epoch=399, global_step=1600
06/01/2022 23:44:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/01/2022 23:44:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/01/2022 23:44:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/01/2022 23:44:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/01/2022 23:44:28 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/01/2022 23:44:29 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=412
06/01/2022 23:44:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=414
06/01/2022 23:44:35 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/01/2022 23:44:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/01/2022 23:44:40 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/01/2022 23:44:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/01/2022 23:44:43 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.773940288646171 on epoch=424
06/01/2022 23:44:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/01/2022 23:44:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/01/2022 23:44:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/01/2022 23:44:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/01/2022 23:44:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/01/2022 23:44:57 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7365841073271415 on epoch=437
06/01/2022 23:44:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=439
06/01/2022 23:45:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/01/2022 23:45:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=444
06/01/2022 23:45:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/01/2022 23:45:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/01/2022 23:45:10 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7114328614328614 on epoch=449
06/01/2022 23:45:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/01/2022 23:45:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/01/2022 23:45:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/01/2022 23:45:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/01/2022 23:45:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/01/2022 23:45:24 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=462
06/01/2022 23:45:27 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/01/2022 23:45:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/01/2022 23:45:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/01/2022 23:45:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/01/2022 23:45:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=474
06/01/2022 23:45:38 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=474
06/01/2022 23:45:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/01/2022 23:45:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/01/2022 23:45:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/01/2022 23:45:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/01/2022 23:45:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/01/2022 23:45:51 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7503217503217504 on epoch=487
06/01/2022 23:45:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/01/2022 23:45:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/01/2022 23:45:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/01/2022 23:46:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/01/2022 23:46:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/01/2022 23:46:05 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7590062111801241 on epoch=499
06/01/2022 23:46:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/01/2022 23:46:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/01/2022 23:46:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/01/2022 23:46:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/01/2022 23:46:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/01/2022 23:46:18 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=512
06/01/2022 23:46:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/01/2022 23:46:23 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/01/2022 23:46:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/01/2022 23:46:28 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=522
06/01/2022 23:46:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/01/2022 23:46:32 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7361111111111112 on epoch=524
06/01/2022 23:46:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/01/2022 23:46:37 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/01/2022 23:46:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/01/2022 23:46:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/01/2022 23:46:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/01/2022 23:46:45 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7802871148459385 on epoch=537
06/01/2022 23:46:45 - INFO - __main__ - Saving model with best Classification-F1: 0.773940288646171 -> 0.7802871148459385 on epoch=537, global_step=2150
06/01/2022 23:46:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/01/2022 23:46:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/01/2022 23:46:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/01/2022 23:46:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/01/2022 23:46:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/01/2022 23:46:59 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7593795093795094 on epoch=549
06/01/2022 23:47:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/01/2022 23:47:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/01/2022 23:47:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/01/2022 23:47:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/01/2022 23:47:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/01/2022 23:47:13 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7807453416149068 on epoch=562
06/01/2022 23:47:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7802871148459385 -> 0.7807453416149068 on epoch=562, global_step=2250
06/01/2022 23:47:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=564
06/01/2022 23:47:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=567
06/01/2022 23:47:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/01/2022 23:47:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/01/2022 23:47:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/01/2022 23:47:26 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7802871148459385 on epoch=574
06/01/2022 23:47:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=577
06/01/2022 23:47:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/01/2022 23:47:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/01/2022 23:47:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/01/2022 23:47:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/01/2022 23:47:40 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7802871148459385 on epoch=587
06/01/2022 23:47:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/01/2022 23:47:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/01/2022 23:47:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/01/2022 23:47:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/01/2022 23:47:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/01/2022 23:47:54 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7500000000000001 on epoch=599
06/01/2022 23:47:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/01/2022 23:47:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=604
06/01/2022 23:48:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/01/2022 23:48:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/01/2022 23:48:06 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/01/2022 23:48:08 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7874538021596845 on epoch=612
06/01/2022 23:48:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7807453416149068 -> 0.7874538021596845 on epoch=612, global_step=2450
06/01/2022 23:48:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/01/2022 23:48:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/01/2022 23:48:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/01/2022 23:48:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/01/2022 23:48:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/01/2022 23:48:21 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7644478844169247 on epoch=624
06/01/2022 23:48:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=627
06/01/2022 23:48:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/01/2022 23:48:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/01/2022 23:48:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/01/2022 23:48:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/01/2022 23:48:35 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7644478844169247 on epoch=637
06/01/2022 23:48:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/01/2022 23:48:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/01/2022 23:48:43 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=644
06/01/2022 23:48:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/01/2022 23:48:48 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=649
06/01/2022 23:48:49 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7644478844169247 on epoch=649
06/01/2022 23:48:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/01/2022 23:48:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/01/2022 23:48:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.17 on epoch=657
06/01/2022 23:48:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/01/2022 23:49:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/01/2022 23:49:03 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.773940288646171 on epoch=662
06/01/2022 23:49:05 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/01/2022 23:49:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/01/2022 23:49:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/01/2022 23:49:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/01/2022 23:49:15 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/01/2022 23:49:16 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.7732683982683983 on epoch=674
06/01/2022 23:49:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=677
06/01/2022 23:49:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/01/2022 23:49:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/01/2022 23:49:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/01/2022 23:49:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/01/2022 23:49:30 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7880664227413453 on epoch=687
06/01/2022 23:49:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7874538021596845 -> 0.7880664227413453 on epoch=687, global_step=2750
06/01/2022 23:49:32 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/01/2022 23:49:35 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/01/2022 23:49:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=694
06/01/2022 23:49:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/01/2022 23:49:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/01/2022 23:49:44 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7874538021596845 on epoch=699
06/01/2022 23:49:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/01/2022 23:49:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/01/2022 23:49:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/01/2022 23:49:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=709
06/01/2022 23:49:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/01/2022 23:49:57 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7732683982683983 on epoch=712
06/01/2022 23:50:00 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/01/2022 23:50:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/01/2022 23:50:05 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/01/2022 23:50:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/01/2022 23:50:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/01/2022 23:50:11 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.7880664227413453 on epoch=724
06/01/2022 23:50:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=727
06/01/2022 23:50:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/01/2022 23:50:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/01/2022 23:50:21 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=734
06/01/2022 23:50:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=737
06/01/2022 23:50:25 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.773940288646171 on epoch=737
06/01/2022 23:50:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=739
06/01/2022 23:50:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/01/2022 23:50:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/01/2022 23:50:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/01/2022 23:50:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/01/2022 23:50:38 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7878274694131471 on epoch=749
06/01/2022 23:50:38 - INFO - __main__ - save last model!
06/01/2022 23:50:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/01/2022 23:50:38 - INFO - __main__ - Start tokenizing ... 5509 instances
06/01/2022 23:50:38 - INFO - __main__ - Printing 3 examples
06/01/2022 23:50:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ -  [emo] what you like very little things ok
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:50:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:50:38 - INFO - __main__ - Printing 3 examples
06/01/2022 23:50:38 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:50:38 - INFO - __main__ - ['others']
06/01/2022 23:50:38 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:50:39 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:50:39 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:50:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:50:39 - INFO - __main__ - Printing 3 examples
06/01/2022 23:50:39 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:50:39 - INFO - __main__ - ['others']
06/01/2022 23:50:39 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:50:39 - INFO - __main__ - ['others']
06/01/2022 23:50:39 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:50:39 - INFO - __main__ - ['others']
06/01/2022 23:50:39 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:50:39 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:50:39 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:50:40 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:50:46 - INFO - __main__ - Loaded 5509 examples from test data
06/01/2022 23:50:54 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:50:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:50:54 - INFO - __main__ - Starting training!
06/01/2022 23:52:22 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/01/2022 23:52:22 - INFO - __main__ - Classification-F1 on test data: 0.3557
06/01/2022 23:52:22 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.7880664227413453, test_performance=0.3556712966141004
06/01/2022 23:52:22 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/01/2022 23:52:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:52:23 - INFO - __main__ - Printing 3 examples
06/01/2022 23:52:23 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:52:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:52:23 - INFO - __main__ - Loaded 64 examples from train data
06/01/2022 23:52:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/01/2022 23:52:23 - INFO - __main__ - Printing 3 examples
06/01/2022 23:52:23 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/01/2022 23:52:23 - INFO - __main__ - ['others']
06/01/2022 23:52:23 - INFO - __main__ - Tokenizing Input ...
06/01/2022 23:52:23 - INFO - __main__ - Tokenizing Output ...
06/01/2022 23:52:23 - INFO - __main__ - Loaded 64 examples from dev data
06/01/2022 23:52:39 - INFO - __main__ - load prompt embedding from ckpt
06/01/2022 23:52:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
06/01/2022 23:52:40 - INFO - __main__ - Starting training!
06/01/2022 23:52:43 - INFO - __main__ - Step 10 Global step 10 Train loss 4.32 on epoch=2
06/01/2022 23:52:45 - INFO - __main__ - Step 20 Global step 20 Train loss 3.15 on epoch=4
06/01/2022 23:52:48 - INFO - __main__ - Step 30 Global step 30 Train loss 2.46 on epoch=7
06/01/2022 23:52:50 - INFO - __main__ - Step 40 Global step 40 Train loss 1.92 on epoch=9
06/01/2022 23:52:53 - INFO - __main__ - Step 50 Global step 50 Train loss 1.58 on epoch=12
06/01/2022 23:52:54 - INFO - __main__ - Global step 50 Train loss 2.69 Classification-F1 0.1581196581196581 on epoch=12
06/01/2022 23:52:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1581196581196581 on epoch=12, global_step=50
06/01/2022 23:52:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.27 on epoch=14
06/01/2022 23:52:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.11 on epoch=17
06/01/2022 23:53:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.06 on epoch=19
06/01/2022 23:53:04 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=22
06/01/2022 23:53:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.95 on epoch=24
06/01/2022 23:53:07 - INFO - __main__ - Global step 100 Train loss 1.07 Classification-F1 0.1 on epoch=24
06/01/2022 23:53:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=27
06/01/2022 23:53:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/01/2022 23:53:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.91 on epoch=32
06/01/2022 23:53:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=34
06/01/2022 23:53:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/01/2022 23:53:21 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.18836850231600616 on epoch=37
06/01/2022 23:53:21 - INFO - __main__ - Saving model with best Classification-F1: 0.1581196581196581 -> 0.18836850231600616 on epoch=37, global_step=150
06/01/2022 23:53:23 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=39
06/01/2022 23:53:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=42
06/01/2022 23:53:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=44
06/01/2022 23:53:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=47
06/01/2022 23:53:33 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=49
06/01/2022 23:53:34 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.1 on epoch=49
06/01/2022 23:53:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=52
06/01/2022 23:53:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=54
06/01/2022 23:53:42 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=57
06/01/2022 23:53:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=59
06/01/2022 23:53:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.87 on epoch=62
06/01/2022 23:53:48 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.3709096665486118 on epoch=62
06/01/2022 23:53:48 - INFO - __main__ - Saving model with best Classification-F1: 0.18836850231600616 -> 0.3709096665486118 on epoch=62, global_step=250
06/01/2022 23:53:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=64
06/01/2022 23:53:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.79 on epoch=67
06/01/2022 23:53:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.77 on epoch=69
06/01/2022 23:53:58 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=72
06/01/2022 23:54:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=74
06/01/2022 23:54:02 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.46372549019607845 on epoch=74
06/01/2022 23:54:02 - INFO - __main__ - Saving model with best Classification-F1: 0.3709096665486118 -> 0.46372549019607845 on epoch=74, global_step=300
06/01/2022 23:54:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=77
06/01/2022 23:54:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.83 on epoch=79
06/01/2022 23:54:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=82
06/01/2022 23:54:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.73 on epoch=84
06/01/2022 23:54:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=87
06/01/2022 23:54:15 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.5906276386152547 on epoch=87
06/01/2022 23:54:15 - INFO - __main__ - Saving model with best Classification-F1: 0.46372549019607845 -> 0.5906276386152547 on epoch=87, global_step=350
06/01/2022 23:54:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=89
06/01/2022 23:54:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=92
06/01/2022 23:54:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=94
06/01/2022 23:54:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=97
06/01/2022 23:54:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.67 on epoch=99
06/01/2022 23:54:29 - INFO - __main__ - Global step 400 Train loss 0.64 Classification-F1 0.5509169884169884 on epoch=99
06/01/2022 23:54:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=102
06/01/2022 23:54:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=104
06/01/2022 23:54:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=107
06/01/2022 23:54:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.50 on epoch=109
06/01/2022 23:54:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=112
06/01/2022 23:54:42 - INFO - __main__ - Global step 450 Train loss 0.54 Classification-F1 0.56006006006006 on epoch=112
06/01/2022 23:54:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.62 on epoch=114
06/01/2022 23:54:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=117
06/01/2022 23:54:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=119
06/01/2022 23:54:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.42 on epoch=122
06/01/2022 23:54:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=124
06/01/2022 23:54:56 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.5712190567283824 on epoch=124
06/01/2022 23:54:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=127
06/01/2022 23:55:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=129
06/01/2022 23:55:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=132
06/01/2022 23:55:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=134
06/01/2022 23:55:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=137
06/01/2022 23:55:10 - INFO - __main__ - Global step 550 Train loss 0.43 Classification-F1 0.5723684210526316 on epoch=137
06/01/2022 23:55:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=139
06/01/2022 23:55:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=142
06/01/2022 23:55:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.41 on epoch=144
06/01/2022 23:55:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=147
06/01/2022 23:55:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=149
06/01/2022 23:55:23 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.5971064539175994 on epoch=149
06/01/2022 23:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5906276386152547 -> 0.5971064539175994 on epoch=149, global_step=600
06/01/2022 23:55:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.32 on epoch=152
06/01/2022 23:55:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=154
06/01/2022 23:55:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=157
06/01/2022 23:55:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.32 on epoch=159
06/01/2022 23:55:36 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=162
06/01/2022 23:55:37 - INFO - __main__ - Global step 650 Train loss 0.32 Classification-F1 0.5997989766081872 on epoch=162
06/01/2022 23:55:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5971064539175994 -> 0.5997989766081872 on epoch=162, global_step=650
06/01/2022 23:55:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=164
06/01/2022 23:55:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=167
06/01/2022 23:55:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=169
06/01/2022 23:55:47 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=172
06/01/2022 23:55:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=174
06/01/2022 23:55:50 - INFO - __main__ - Global step 700 Train loss 0.30 Classification-F1 0.5942607630717965 on epoch=174
06/01/2022 23:55:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=177
06/01/2022 23:55:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=179
06/01/2022 23:55:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=182
06/01/2022 23:56:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.29 on epoch=184
06/01/2022 23:56:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=187
06/01/2022 23:56:04 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.6559907834101383 on epoch=187
06/01/2022 23:56:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5997989766081872 -> 0.6559907834101383 on epoch=187, global_step=750
06/01/2022 23:56:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=189
06/01/2022 23:56:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.29 on epoch=192
06/01/2022 23:56:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.27 on epoch=194
06/01/2022 23:56:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=197
06/01/2022 23:56:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=199
06/01/2022 23:56:17 - INFO - __main__ - Global step 800 Train loss 0.29 Classification-F1 0.6151715740130375 on epoch=199
06/01/2022 23:56:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=202
06/01/2022 23:56:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=204
06/01/2022 23:56:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=207
06/01/2022 23:56:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=209
06/01/2022 23:56:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=212
06/01/2022 23:56:31 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.705994005994006 on epoch=212
06/01/2022 23:56:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6559907834101383 -> 0.705994005994006 on epoch=212, global_step=850
06/01/2022 23:56:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=214
06/01/2022 23:56:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=217
06/01/2022 23:56:38 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=219
06/01/2022 23:56:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=222
06/01/2022 23:56:43 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=224
06/01/2022 23:56:44 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.550681230913789 on epoch=224
06/01/2022 23:56:47 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=227
06/01/2022 23:56:49 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=229
06/01/2022 23:56:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=232
06/01/2022 23:56:54 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=234
06/01/2022 23:56:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/01/2022 23:56:58 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.7222983930414272 on epoch=237
06/01/2022 23:56:58 - INFO - __main__ - Saving model with best Classification-F1: 0.705994005994006 -> 0.7222983930414272 on epoch=237, global_step=950
06/01/2022 23:57:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=239
06/01/2022 23:57:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/01/2022 23:57:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=244
06/01/2022 23:57:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=247
06/01/2022 23:57:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=249
06/01/2022 23:57:11 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.6973684210526315 on epoch=249
06/01/2022 23:57:14 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=252
06/01/2022 23:57:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=254
06/01/2022 23:57:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=257
06/01/2022 23:57:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/01/2022 23:57:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=262
06/01/2022 23:57:25 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7807453416149068 on epoch=262
06/01/2022 23:57:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7222983930414272 -> 0.7807453416149068 on epoch=262, global_step=1050
06/01/2022 23:57:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=264
06/01/2022 23:57:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=267
06/01/2022 23:57:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/01/2022 23:57:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/01/2022 23:57:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=274
06/01/2022 23:57:38 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6556266793108899 on epoch=274
06/01/2022 23:57:41 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/01/2022 23:57:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=279
06/01/2022 23:57:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/01/2022 23:57:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=284
06/01/2022 23:57:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=287
06/01/2022 23:57:52 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.7212601256718905 on epoch=287
06/01/2022 23:57:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/01/2022 23:57:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.04 on epoch=292
06/01/2022 23:57:59 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/01/2022 23:58:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/01/2022 23:58:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/01/2022 23:58:06 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7953811959566436 on epoch=299
06/01/2022 23:58:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7807453416149068 -> 0.7953811959566436 on epoch=299, global_step=1200
06/01/2022 23:58:08 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/01/2022 23:58:11 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=304
06/01/2022 23:58:13 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/01/2022 23:58:16 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=309
06/01/2022 23:58:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=312
06/01/2022 23:58:19 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7736185383244206 on epoch=312
06/01/2022 23:58:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=314
06/01/2022 23:58:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=317
06/01/2022 23:58:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=319
06/01/2022 23:58:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/01/2022 23:58:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=324
06/01/2022 23:58:33 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.74585326953748 on epoch=324
06/01/2022 23:58:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/01/2022 23:58:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/01/2022 23:58:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=332
06/01/2022 23:58:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/01/2022 23:58:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/01/2022 23:58:46 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.6427099946836788 on epoch=337
06/01/2022 23:58:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=339
06/01/2022 23:58:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=342
06/01/2022 23:58:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/01/2022 23:58:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=347
06/01/2022 23:58:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/01/2022 23:59:00 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7449486920075156 on epoch=349
06/01/2022 23:59:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=352
06/01/2022 23:59:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=354
06/01/2022 23:59:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=357
06/01/2022 23:59:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/01/2022 23:59:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/01/2022 23:59:14 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7871212121212121 on epoch=362
06/01/2022 23:59:16 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=364
06/01/2022 23:59:19 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/01/2022 23:59:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=369
06/01/2022 23:59:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/01/2022 23:59:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=374
06/01/2022 23:59:27 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7714583333333334 on epoch=374
06/01/2022 23:59:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=377
06/01/2022 23:59:32 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=379
06/01/2022 23:59:35 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/01/2022 23:59:37 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/01/2022 23:59:40 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/01/2022 23:59:41 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.6971471471471471 on epoch=387
06/01/2022 23:59:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/01/2022 23:59:46 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/01/2022 23:59:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/01/2022 23:59:51 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/01/2022 23:59:54 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=399
06/01/2022 23:59:55 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6422624317361159 on epoch=399
06/01/2022 23:59:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=402
06/02/2022 00:00:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=404
06/02/2022 00:00:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/02/2022 00:00:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/02/2022 00:00:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/02/2022 00:00:09 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.74585326953748 on epoch=412
06/02/2022 00:00:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/02/2022 00:00:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/02/2022 00:00:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=419
06/02/2022 00:00:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/02/2022 00:00:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/02/2022 00:00:22 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7592344062932298 on epoch=424
06/02/2022 00:00:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/02/2022 00:00:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
06/02/2022 00:00:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/02/2022 00:00:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/02/2022 00:00:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/02/2022 00:00:36 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.74585326953748 on epoch=437
06/02/2022 00:00:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/02/2022 00:00:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/02/2022 00:00:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=444
06/02/2022 00:00:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=447
06/02/2022 00:00:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/02/2022 00:00:50 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7661320270015923 on epoch=449
06/02/2022 00:00:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/02/2022 00:00:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/02/2022 00:00:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/02/2022 00:01:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/02/2022 00:01:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/02/2022 00:01:04 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7731259968102073 on epoch=462
06/02/2022 00:01:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/02/2022 00:01:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=467
06/02/2022 00:01:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=469
06/02/2022 00:01:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/02/2022 00:01:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/02/2022 00:01:18 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7806753136037025 on epoch=474
06/02/2022 00:01:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=477
06/02/2022 00:01:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/02/2022 00:01:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/02/2022 00:01:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/02/2022 00:01:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/02/2022 00:01:32 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.8014705882352942 on epoch=487
06/02/2022 00:01:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7953811959566436 -> 0.8014705882352942 on epoch=487, global_step=1950
06/02/2022 00:01:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/02/2022 00:01:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=492
06/02/2022 00:01:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/02/2022 00:01:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/02/2022 00:01:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/02/2022 00:01:46 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7813472039814752 on epoch=499
06/02/2022 00:01:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=502
06/02/2022 00:01:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/02/2022 00:01:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/02/2022 00:01:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/02/2022 00:01:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/02/2022 00:02:00 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7596545743604567 on epoch=512
06/02/2022 00:02:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/02/2022 00:02:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/02/2022 00:02:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/02/2022 00:02:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=522
06/02/2022 00:02:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/02/2022 00:02:15 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7462292609351433 on epoch=524
06/02/2022 00:02:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/02/2022 00:02:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/02/2022 00:02:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=532
06/02/2022 00:02:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/02/2022 00:02:28 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/02/2022 00:02:29 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7736185383244207 on epoch=537
06/02/2022 00:02:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/02/2022 00:02:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/02/2022 00:02:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/02/2022 00:02:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=547
06/02/2022 00:02:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/02/2022 00:02:43 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7953811959566436 on epoch=549
06/02/2022 00:02:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/02/2022 00:02:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/02/2022 00:02:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/02/2022 00:02:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/02/2022 00:02:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=562
06/02/2022 00:02:57 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7736185383244207 on epoch=562
06/02/2022 00:03:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/02/2022 00:03:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/02/2022 00:03:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/02/2022 00:03:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=572
06/02/2022 00:03:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=574
06/02/2022 00:03:12 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7365742365742366 on epoch=574
06/02/2022 00:03:14 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/02/2022 00:03:17 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/02/2022 00:03:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/02/2022 00:03:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=584
06/02/2022 00:03:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/02/2022 00:03:26 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7506718903777728 on epoch=587
06/02/2022 00:03:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/02/2022 00:03:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/02/2022 00:03:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/02/2022 00:03:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=597
06/02/2022 00:03:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/02/2022 00:03:40 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7602026456515621 on epoch=599
06/02/2022 00:03:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/02/2022 00:03:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=604
06/02/2022 00:03:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/02/2022 00:03:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/02/2022 00:03:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/02/2022 00:03:54 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7370042753943682 on epoch=612
06/02/2022 00:03:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/02/2022 00:03:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/02/2022 00:04:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/02/2022 00:04:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=622
06/02/2022 00:04:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/02/2022 00:04:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8158263305322129 on epoch=624
06/02/2022 00:04:08 - INFO - __main__ - Saving model with best Classification-F1: 0.8014705882352942 -> 0.8158263305322129 on epoch=624, global_step=2500
06/02/2022 00:04:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=627
06/02/2022 00:04:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=629
06/02/2022 00:04:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=632
06/02/2022 00:04:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=634
06/02/2022 00:04:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=637
06/02/2022 00:04:21 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7736185383244207 on epoch=637
06/02/2022 00:04:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/02/2022 00:04:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/02/2022 00:04:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/02/2022 00:04:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/02/2022 00:04:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/02/2022 00:04:35 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7736185383244207 on epoch=649
06/02/2022 00:04:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/02/2022 00:04:40 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/02/2022 00:04:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/02/2022 00:04:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/02/2022 00:04:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/02/2022 00:04:49 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.8354621848739495 on epoch=662
06/02/2022 00:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.8158263305322129 -> 0.8354621848739495 on epoch=662, global_step=2650
06/02/2022 00:04:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/02/2022 00:04:54 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/02/2022 00:04:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/02/2022 00:04:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=672
06/02/2022 00:05:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/02/2022 00:05:03 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8354621848739495 on epoch=674
06/02/2022 00:05:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=677
06/02/2022 00:05:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=679
06/02/2022 00:05:10 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/02/2022 00:05:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.14 on epoch=684
06/02/2022 00:05:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/02/2022 00:05:17 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7953811959566436 on epoch=687
06/02/2022 00:05:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/02/2022 00:05:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=692
06/02/2022 00:05:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/02/2022 00:05:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/02/2022 00:05:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=699
06/02/2022 00:05:30 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7736185383244207 on epoch=699
06/02/2022 00:05:33 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/02/2022 00:05:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/02/2022 00:05:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/02/2022 00:05:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/02/2022 00:05:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=712
06/02/2022 00:05:44 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7736185383244207 on epoch=712
06/02/2022 00:05:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=714
06/02/2022 00:05:49 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/02/2022 00:05:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=719
06/02/2022 00:05:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/02/2022 00:05:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/02/2022 00:05:58 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8354621848739495 on epoch=724
06/02/2022 00:06:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/02/2022 00:06:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/02/2022 00:06:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/02/2022 00:06:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/02/2022 00:06:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/02/2022 00:06:12 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7736185383244207 on epoch=737
06/02/2022 00:06:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/02/2022 00:06:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/02/2022 00:06:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/02/2022 00:06:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/02/2022 00:06:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/02/2022 00:06:26 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7736185383244207 on epoch=749
06/02/2022 00:06:26 - INFO - __main__ - save last model!
06/02/2022 00:06:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/02/2022 00:06:26 - INFO - __main__ - Start tokenizing ... 5509 instances
06/02/2022 00:06:26 - INFO - __main__ - Printing 3 examples
06/02/2022 00:06:26 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/02/2022 00:06:26 - INFO - __main__ - ['others']
06/02/2022 00:06:26 - INFO - __main__ -  [emo] what you like very little things ok
06/02/2022 00:06:26 - INFO - __main__ - ['others']
06/02/2022 00:06:26 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/02/2022 00:06:26 - INFO - __main__ - ['others']
06/02/2022 00:06:26 - INFO - __main__ - Tokenizing Input ...
06/02/2022 00:06:28 - INFO - __main__ - Tokenizing Output ...
06/02/2022 00:06:34 - INFO - __main__ - Loaded 5509 examples from test data
06/02/2022 00:08:09 - INFO - __main__ - Saved prediction in models/T5-large-maml-cls2cls-3e-5-2-5000-5e-1-up32shot/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/02/2022 00:08:09 - INFO - __main__ - Classification-F1 on test data: 0.3555
06/02/2022 00:08:10 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.8354621848739495, test_performance=0.35548116052945977
