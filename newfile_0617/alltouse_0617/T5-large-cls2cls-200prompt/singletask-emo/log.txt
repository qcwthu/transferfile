06/08/2022 03:05:16 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-cls2cls-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-200prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='6,7')
06/08/2022 03:05:16 - INFO - __main__ - models/T5-large-cls2cls-200prompt/singletask-emo
06/08/2022 03:05:16 - INFO - __main__ - Namespace(task_dir='data/emo/', task_name='emo', identifier='T5-large-cls2cls-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-200prompt/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='6,7')
06/08/2022 03:05:16 - INFO - __main__ - models/T5-large-cls2cls-200prompt/singletask-emo
06/08/2022 03:05:17 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/08/2022 03:05:17 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/08/2022 03:05:17 - INFO - __main__ - args.device: cuda:1
06/08/2022 03:05:17 - INFO - __main__ - Using 2 gpus
06/08/2022 03:05:17 - INFO - __main__ - args.device: cuda:0
06/08/2022 03:05:17 - INFO - __main__ - Using 2 gpus
06/08/2022 03:05:17 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/08/2022 03:05:17 - INFO - __main__ - Fine-tuning the following samples: ['emo_16_100', 'emo_16_13', 'emo_16_21', 'emo_16_42', 'emo_16_87']
06/08/2022 03:05:22 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.5, bsz=8 ...
06/08/2022 03:05:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:05:23 - INFO - __main__ - Printing 3 examples
06/08/2022 03:05:23 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:05:23 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:05:23 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:05:23 - INFO - __main__ - Printing 3 examples
06/08/2022 03:05:23 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:05:23 - INFO - __main__ - ['others']
06/08/2022 03:05:23 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:05:23 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:05:24 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:05:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:05:24 - INFO - __main__ - Printing 3 examples
06/08/2022 03:05:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:05:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:05:24 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:05:24 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:05:24 - INFO - __main__ - Printing 3 examples
06/08/2022 03:05:24 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:05:24 - INFO - __main__ - ['others']
06/08/2022 03:05:24 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:05:24 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:05:24 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:05:24 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:05:42 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:05:42 - INFO - __main__ - task name: emo
06/08/2022 03:05:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:05:42 - INFO - __main__ - Starting training!
06/08/2022 03:05:45 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:05:45 - INFO - __main__ - task name: emo
06/08/2022 03:05:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:05:46 - INFO - __main__ - Starting training!
06/08/2022 03:05:49 - INFO - __main__ - Step 10 Global step 10 Train loss 5.71 on epoch=2
06/08/2022 03:05:52 - INFO - __main__ - Step 20 Global step 20 Train loss 1.70 on epoch=4
06/08/2022 03:05:55 - INFO - __main__ - Step 30 Global step 30 Train loss 1.14 on epoch=7
06/08/2022 03:05:57 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
06/08/2022 03:06:00 - INFO - __main__ - Step 50 Global step 50 Train loss 1.08 on epoch=12
06/08/2022 03:06:01 - INFO - __main__ - Global step 50 Train loss 2.15 Classification-F1 0.1 on epoch=12
06/08/2022 03:06:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 03:06:04 - INFO - __main__ - Step 60 Global step 60 Train loss 0.97 on epoch=14
06/08/2022 03:06:07 - INFO - __main__ - Step 70 Global step 70 Train loss 0.90 on epoch=17
06/08/2022 03:06:09 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=19
06/08/2022 03:06:12 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/08/2022 03:06:15 - INFO - __main__ - Step 100 Global step 100 Train loss 0.91 on epoch=24
06/08/2022 03:06:16 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.1 on epoch=24
06/08/2022 03:06:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/08/2022 03:06:22 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/08/2022 03:06:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/08/2022 03:06:27 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=34
06/08/2022 03:06:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/08/2022 03:06:31 - INFO - __main__ - Global step 150 Train loss 0.88 Classification-F1 0.0974025974025974 on epoch=37
06/08/2022 03:06:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=39
06/08/2022 03:06:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=42
06/08/2022 03:06:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=44
06/08/2022 03:06:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=47
06/08/2022 03:06:44 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=49
06/08/2022 03:06:45 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.20023809523809524 on epoch=49
06/08/2022 03:06:45 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.20023809523809524 on epoch=49, global_step=200
06/08/2022 03:06:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/08/2022 03:06:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.73 on epoch=54
06/08/2022 03:06:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.71 on epoch=57
06/08/2022 03:06:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=59
06/08/2022 03:06:59 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=62
06/08/2022 03:07:00 - INFO - __main__ - Global step 250 Train loss 0.69 Classification-F1 0.3437267930427985 on epoch=62
06/08/2022 03:07:01 - INFO - __main__ - Saving model with best Classification-F1: 0.20023809523809524 -> 0.3437267930427985 on epoch=62, global_step=250
06/08/2022 03:07:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=64
06/08/2022 03:07:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=67
06/08/2022 03:07:09 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=69
06/08/2022 03:07:12 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=72
06/08/2022 03:07:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=74
06/08/2022 03:07:15 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.28924847530985637 on epoch=74
06/08/2022 03:07:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.32 on epoch=77
06/08/2022 03:07:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.28 on epoch=79
06/08/2022 03:07:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.27 on epoch=82
06/08/2022 03:07:26 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=84
06/08/2022 03:07:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=87
06/08/2022 03:07:30 - INFO - __main__ - Global step 350 Train loss 0.28 Classification-F1 0.3456709956709957 on epoch=87
06/08/2022 03:07:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3437267930427985 -> 0.3456709956709957 on epoch=87, global_step=350
06/08/2022 03:07:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.21 on epoch=89
06/08/2022 03:07:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.28 on epoch=92
06/08/2022 03:07:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=94
06/08/2022 03:07:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.11 on epoch=97
06/08/2022 03:07:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.17 on epoch=99
06/08/2022 03:07:45 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.5141740847811775 on epoch=99
06/08/2022 03:07:45 - INFO - __main__ - Saving model with best Classification-F1: 0.3456709956709957 -> 0.5141740847811775 on epoch=99, global_step=400
06/08/2022 03:07:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=102
06/08/2022 03:07:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.11 on epoch=104
06/08/2022 03:07:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=107
06/08/2022 03:07:56 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=109
06/08/2022 03:07:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=112
06/08/2022 03:08:00 - INFO - __main__ - Global step 450 Train loss 0.11 Classification-F1 0.5381809263379063 on epoch=112
06/08/2022 03:08:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5141740847811775 -> 0.5381809263379063 on epoch=112, global_step=450
06/08/2022 03:08:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=114
06/08/2022 03:08:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.09 on epoch=117
06/08/2022 03:08:09 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=119
06/08/2022 03:08:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.07 on epoch=122
06/08/2022 03:08:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.06 on epoch=124
06/08/2022 03:08:15 - INFO - __main__ - Global step 500 Train loss 0.07 Classification-F1 0.5074174566851912 on epoch=124
06/08/2022 03:08:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.04 on epoch=127
06/08/2022 03:08:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.10 on epoch=129
06/08/2022 03:08:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/08/2022 03:08:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.07 on epoch=134
06/08/2022 03:08:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.04 on epoch=137
06/08/2022 03:08:30 - INFO - __main__ - Global step 550 Train loss 0.06 Classification-F1 0.5115719406041986 on epoch=137
06/08/2022 03:08:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=139
06/08/2022 03:08:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/08/2022 03:08:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.02 on epoch=144
06/08/2022 03:08:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=147
06/08/2022 03:08:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
06/08/2022 03:08:45 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.5641268928091498 on epoch=149
06/08/2022 03:08:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5381809263379063 -> 0.5641268928091498 on epoch=149, global_step=600
06/08/2022 03:08:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.03 on epoch=152
06/08/2022 03:08:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/08/2022 03:08:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.07 on epoch=157
06/08/2022 03:08:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.06 on epoch=159
06/08/2022 03:08:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/08/2022 03:09:00 - INFO - __main__ - Global step 650 Train loss 0.04 Classification-F1 0.5186773299295986 on epoch=162
06/08/2022 03:09:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.04 on epoch=164
06/08/2022 03:09:05 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=167
06/08/2022 03:09:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=169
06/08/2022 03:09:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/08/2022 03:09:13 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/08/2022 03:09:15 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.5084967320261438 on epoch=174
06/08/2022 03:09:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/08/2022 03:09:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/08/2022 03:09:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.07 on epoch=182
06/08/2022 03:09:26 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/08/2022 03:09:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/08/2022 03:09:30 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.5161447678992919 on epoch=187
06/08/2022 03:09:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/08/2022 03:09:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/08/2022 03:09:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/08/2022 03:09:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/08/2022 03:09:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=199
06/08/2022 03:09:45 - INFO - __main__ - Global step 800 Train loss 0.01 Classification-F1 0.5135772899991915 on epoch=199
06/08/2022 03:09:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/08/2022 03:09:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=204
06/08/2022 03:09:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=207
06/08/2022 03:09:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=209
06/08/2022 03:09:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.02 on epoch=212
06/08/2022 03:09:59 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.4820569136745607 on epoch=212
06/08/2022 03:10:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=214
06/08/2022 03:10:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/08/2022 03:10:08 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 03:10:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/08/2022 03:10:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/08/2022 03:10:15 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.5627209504491452 on epoch=224
06/08/2022 03:10:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=227
06/08/2022 03:10:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/08/2022 03:10:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/08/2022 03:10:26 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=234
06/08/2022 03:10:28 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=237
06/08/2022 03:10:29 - INFO - __main__ - Global step 950 Train loss 0.00 Classification-F1 0.5510989010989011 on epoch=237
06/08/2022 03:10:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/08/2022 03:10:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/08/2022 03:10:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/08/2022 03:10:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/08/2022 03:10:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 03:10:45 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.4856645925157722 on epoch=249
06/08/2022 03:10:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/08/2022 03:10:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/08/2022 03:10:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/08/2022 03:10:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=259
06/08/2022 03:10:59 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/08/2022 03:11:00 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.5925290680281605 on epoch=262
06/08/2022 03:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5641268928091498 -> 0.5925290680281605 on epoch=262, global_step=1050
06/08/2022 03:11:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/08/2022 03:11:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/08/2022 03:11:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 03:11:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 03:11:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 03:11:14 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.5341552782729253 on epoch=274
06/08/2022 03:11:17 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 03:11:20 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/08/2022 03:11:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 03:11:25 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/08/2022 03:11:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 03:11:29 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.4928575375773652 on epoch=287
06/08/2022 03:11:32 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/08/2022 03:11:35 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 03:11:37 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 03:11:40 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 03:11:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 03:11:44 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.5637638926538356 on epoch=299
06/08/2022 03:11:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/08/2022 03:11:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/08/2022 03:11:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 03:11:55 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 03:11:58 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 03:11:59 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.5264219576719577 on epoch=312
06/08/2022 03:12:02 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/08/2022 03:12:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 03:12:07 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 03:12:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 03:12:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=324
06/08/2022 03:12:14 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.5795543345543346 on epoch=324
06/08/2022 03:12:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 03:12:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/08/2022 03:12:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 03:12:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/08/2022 03:12:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/08/2022 03:12:29 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.5602689793866265 on epoch=337
06/08/2022 03:12:32 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 03:12:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 03:12:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 03:12:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 03:12:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 03:12:44 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.5322738001573564 on epoch=349
06/08/2022 03:12:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/08/2022 03:12:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 03:12:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 03:12:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 03:12:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 03:12:59 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.596875 on epoch=362
06/08/2022 03:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5925290680281605 -> 0.596875 on epoch=362, global_step=1450
06/08/2022 03:13:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 03:13:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 03:13:07 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 03:13:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 03:13:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 03:13:14 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.5684210526315789 on epoch=374
06/08/2022 03:13:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 03:13:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 03:13:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 03:13:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 03:13:28 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 03:13:29 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.49132775119617234 on epoch=387
06/08/2022 03:13:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 03:13:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 03:13:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 03:13:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 03:13:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 03:13:44 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.5251792114695341 on epoch=399
06/08/2022 03:13:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/08/2022 03:13:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 03:13:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 03:13:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 03:13:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 03:13:59 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5654761904761905 on epoch=412
06/08/2022 03:14:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 03:14:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 03:14:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 03:14:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 03:14:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 03:14:14 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.5616056397306397 on epoch=424
06/08/2022 03:14:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 03:14:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 03:14:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/08/2022 03:14:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/08/2022 03:14:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 03:14:28 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.594302035330261 on epoch=437
06/08/2022 03:14:31 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 03:14:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/08/2022 03:14:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 03:14:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 03:14:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 03:14:43 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6293110401342109 on epoch=449
06/08/2022 03:14:43 - INFO - __main__ - Saving model with best Classification-F1: 0.596875 -> 0.6293110401342109 on epoch=449, global_step=1800
06/08/2022 03:14:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=452
06/08/2022 03:14:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 03:14:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/08/2022 03:14:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 03:14:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 03:14:58 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.5343567251461988 on epoch=462
06/08/2022 03:15:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 03:15:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 03:15:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 03:15:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 03:15:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 03:15:12 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6164003759398496 on epoch=474
06/08/2022 03:15:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 03:15:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 03:15:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 03:15:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 03:15:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 03:15:27 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.5935107376283847 on epoch=487
06/08/2022 03:15:30 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 03:15:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 03:15:35 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 03:15:38 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 03:15:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 03:15:42 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.577869427869428 on epoch=499
06/08/2022 03:15:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 03:15:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/08/2022 03:15:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 03:15:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 03:15:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=512
06/08/2022 03:15:56 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5310357423850737 on epoch=512
06/08/2022 03:15:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 03:16:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 03:16:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 03:16:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 03:16:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/08/2022 03:16:11 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.5625939849624061 on epoch=524
06/08/2022 03:16:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 03:16:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 03:16:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 03:16:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 03:16:24 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 03:16:26 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.5788210624417521 on epoch=537
06/08/2022 03:16:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 03:16:31 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 03:16:34 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 03:16:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 03:16:39 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 03:16:40 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6125544899738448 on epoch=549
06/08/2022 03:16:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 03:16:46 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 03:16:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 03:16:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 03:16:54 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 03:16:55 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.595646814779184 on epoch=562
06/08/2022 03:16:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 03:17:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 03:17:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 03:17:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 03:17:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 03:17:10 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5792529318367603 on epoch=574
06/08/2022 03:17:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 03:17:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=579
06/08/2022 03:17:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 03:17:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 03:17:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 03:17:25 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.5755639712292938 on epoch=587
06/08/2022 03:17:28 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 03:17:31 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 03:17:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=594
06/08/2022 03:17:36 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 03:17:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 03:17:40 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5780752860820144 on epoch=599
06/08/2022 03:17:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 03:17:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 03:17:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 03:17:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 03:17:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 03:17:55 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5398930794728758 on epoch=612
06/08/2022 03:17:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 03:18:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 03:18:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 03:18:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 03:18:09 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 03:18:10 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5398930794728758 on epoch=624
06/08/2022 03:18:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 03:18:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 03:18:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 03:18:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 03:18:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/08/2022 03:18:25 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5421717171717172 on epoch=637
06/08/2022 03:18:28 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 03:18:30 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 03:18:33 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=644
06/08/2022 03:18:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 03:18:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 03:18:40 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5505555555555556 on epoch=649
06/08/2022 03:18:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 03:18:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 03:18:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/08/2022 03:18:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 03:18:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 03:18:55 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5806626169529395 on epoch=662
06/08/2022 03:18:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 03:19:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 03:19:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 03:19:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 03:19:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 03:19:10 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5963133640552996 on epoch=674
06/08/2022 03:19:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 03:19:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 03:19:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 03:19:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 03:19:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 03:19:25 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6179643593436697 on epoch=687
06/08/2022 03:19:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 03:19:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 03:19:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 03:19:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 03:19:38 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 03:19:40 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6111392832995267 on epoch=699
06/08/2022 03:19:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 03:19:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 03:19:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 03:19:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 03:19:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 03:19:54 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6112490450725745 on epoch=712
06/08/2022 03:19:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 03:20:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 03:20:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 03:20:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 03:20:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 03:20:09 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5397228168598214 on epoch=724
06/08/2022 03:20:12 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 03:20:15 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 03:20:18 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 03:20:20 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 03:20:23 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 03:20:24 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5250807873090482 on epoch=737
06/08/2022 03:20:27 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 03:20:30 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 03:20:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 03:20:35 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 03:20:38 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 03:20:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:20:39 - INFO - __main__ - Printing 3 examples
06/08/2022 03:20:39 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:20:39 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:20:39 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:20:39 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:20:39 - INFO - __main__ - Printing 3 examples
06/08/2022 03:20:39 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:20:39 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:20:39 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5250807873090482 on epoch=749
06/08/2022 03:20:39 - INFO - __main__ - save last model!
06/08/2022 03:20:39 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:20:39 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 03:20:39 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 03:20:39 - INFO - __main__ - Printing 3 examples
06/08/2022 03:20:39 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 03:20:39 - INFO - __main__ - ['others']
06/08/2022 03:20:39 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:20:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:20:48 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 03:20:56 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:20:56 - INFO - __main__ - task name: emo
06/08/2022 03:20:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:20:56 - INFO - __main__ - Starting training!
06/08/2022 03:22:43 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_100_0.5_8_predictions.txt
06/08/2022 03:22:43 - INFO - __main__ - Classification-F1 on test data: 0.2743
06/08/2022 03:22:43 - INFO - __main__ - prefix=emo_16_100, lr=0.5, bsz=8, dev_performance=0.6293110401342109, test_performance=0.2742642871720682
06/08/2022 03:22:43 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.4, bsz=8 ...
06/08/2022 03:22:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:22:44 - INFO - __main__ - Printing 3 examples
06/08/2022 03:22:44 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:22:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:22:44 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:22:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:22:44 - INFO - __main__ - Printing 3 examples
06/08/2022 03:22:44 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:22:44 - INFO - __main__ - ['others']
06/08/2022 03:22:44 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:22:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:22:45 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:23:05 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:23:05 - INFO - __main__ - task name: emo
06/08/2022 03:23:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:23:06 - INFO - __main__ - Starting training!
06/08/2022 03:23:09 - INFO - __main__ - Step 10 Global step 10 Train loss 6.54 on epoch=2
06/08/2022 03:23:12 - INFO - __main__ - Step 20 Global step 20 Train loss 2.21 on epoch=4
06/08/2022 03:23:15 - INFO - __main__ - Step 30 Global step 30 Train loss 1.39 on epoch=7
06/08/2022 03:23:17 - INFO - __main__ - Step 40 Global step 40 Train loss 1.14 on epoch=9
06/08/2022 03:23:20 - INFO - __main__ - Step 50 Global step 50 Train loss 1.11 on epoch=12
06/08/2022 03:23:21 - INFO - __main__ - Global step 50 Train loss 2.48 Classification-F1 0.18579626972740315 on epoch=12
06/08/2022 03:23:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18579626972740315 on epoch=12, global_step=50
06/08/2022 03:23:24 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=14
06/08/2022 03:23:26 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=17
06/08/2022 03:23:29 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/08/2022 03:23:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=22
06/08/2022 03:23:34 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=24
06/08/2022 03:23:35 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.18012422360248448 on epoch=24
06/08/2022 03:23:38 - INFO - __main__ - Step 110 Global step 110 Train loss 0.94 on epoch=27
06/08/2022 03:23:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.95 on epoch=29
06/08/2022 03:23:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=32
06/08/2022 03:23:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=34
06/08/2022 03:23:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.99 on epoch=37
06/08/2022 03:23:50 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.10389610389610389 on epoch=37
06/08/2022 03:23:53 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=39
06/08/2022 03:23:56 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=42
06/08/2022 03:23:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=44
06/08/2022 03:24:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=47
06/08/2022 03:24:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.85 on epoch=49
06/08/2022 03:24:05 - INFO - __main__ - Global step 200 Train loss 0.88 Classification-F1 0.20376771255060727 on epoch=49
06/08/2022 03:24:05 - INFO - __main__ - Saving model with best Classification-F1: 0.18579626972740315 -> 0.20376771255060727 on epoch=49, global_step=200
06/08/2022 03:24:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=52
06/08/2022 03:24:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=54
06/08/2022 03:24:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.78 on epoch=57
06/08/2022 03:24:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.86 on epoch=59
06/08/2022 03:24:19 - INFO - __main__ - Step 250 Global step 250 Train loss 0.72 on epoch=62
06/08/2022 03:24:20 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.22658730158730156 on epoch=62
06/08/2022 03:24:20 - INFO - __main__ - Saving model with best Classification-F1: 0.20376771255060727 -> 0.22658730158730156 on epoch=62, global_step=250
06/08/2022 03:24:22 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=64
06/08/2022 03:24:25 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=67
06/08/2022 03:24:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/08/2022 03:24:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.73 on epoch=72
06/08/2022 03:24:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=74
06/08/2022 03:24:34 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.21366883116883117 on epoch=74
06/08/2022 03:24:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=77
06/08/2022 03:24:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=79
06/08/2022 03:24:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.49 on epoch=82
06/08/2022 03:24:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.52 on epoch=84
06/08/2022 03:24:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=87
06/08/2022 03:24:49 - INFO - __main__ - Global step 350 Train loss 0.52 Classification-F1 0.29339985486211906 on epoch=87
06/08/2022 03:24:49 - INFO - __main__ - Saving model with best Classification-F1: 0.22658730158730156 -> 0.29339985486211906 on epoch=87, global_step=350
06/08/2022 03:24:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=89
06/08/2022 03:24:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=92
06/08/2022 03:24:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=94
06/08/2022 03:25:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=97
06/08/2022 03:25:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=99
06/08/2022 03:25:04 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.35723346828609986 on epoch=99
06/08/2022 03:25:04 - INFO - __main__ - Saving model with best Classification-F1: 0.29339985486211906 -> 0.35723346828609986 on epoch=99, global_step=400
06/08/2022 03:25:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=102
06/08/2022 03:25:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=104
06/08/2022 03:25:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=107
06/08/2022 03:25:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=109
06/08/2022 03:25:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.23 on epoch=112
06/08/2022 03:25:19 - INFO - __main__ - Global step 450 Train loss 0.28 Classification-F1 0.4340130599152251 on epoch=112
06/08/2022 03:25:19 - INFO - __main__ - Saving model with best Classification-F1: 0.35723346828609986 -> 0.4340130599152251 on epoch=112, global_step=450
06/08/2022 03:25:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=114
06/08/2022 03:25:24 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=117
06/08/2022 03:25:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=119
06/08/2022 03:25:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/08/2022 03:25:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/08/2022 03:25:34 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.46259259259259256 on epoch=124
06/08/2022 03:25:34 - INFO - __main__ - Saving model with best Classification-F1: 0.4340130599152251 -> 0.46259259259259256 on epoch=124, global_step=500
06/08/2022 03:25:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
06/08/2022 03:25:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/08/2022 03:25:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.12 on epoch=132
06/08/2022 03:25:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=134
06/08/2022 03:25:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=137
06/08/2022 03:25:50 - INFO - __main__ - Global step 550 Train loss 0.14 Classification-F1 0.3143358876117497 on epoch=137
06/08/2022 03:25:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/08/2022 03:25:55 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/08/2022 03:25:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.09 on epoch=144
06/08/2022 03:26:01 - INFO - __main__ - Step 590 Global step 590 Train loss 0.12 on epoch=147
06/08/2022 03:26:03 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
06/08/2022 03:26:05 - INFO - __main__ - Global step 600 Train loss 0.09 Classification-F1 0.4627958785853523 on epoch=149
06/08/2022 03:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.46259259259259256 -> 0.4627958785853523 on epoch=149, global_step=600
06/08/2022 03:26:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/08/2022 03:26:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/08/2022 03:26:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/08/2022 03:26:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.05 on epoch=159
06/08/2022 03:26:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/08/2022 03:26:20 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.40532312515071134 on epoch=162
06/08/2022 03:26:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.03 on epoch=164
06/08/2022 03:26:26 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/08/2022 03:26:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=169
06/08/2022 03:26:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=172
06/08/2022 03:26:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/08/2022 03:26:35 - INFO - __main__ - Global step 700 Train loss 0.07 Classification-F1 0.40927750410509034 on epoch=174
06/08/2022 03:26:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/08/2022 03:26:41 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/08/2022 03:26:44 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/08/2022 03:26:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/08/2022 03:26:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/08/2022 03:26:50 - INFO - __main__ - Global step 750 Train loss 0.03 Classification-F1 0.41852831533358914 on epoch=187
06/08/2022 03:26:53 - INFO - __main__ - Step 760 Global step 760 Train loss 0.03 on epoch=189
06/08/2022 03:26:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.05 on epoch=192
06/08/2022 03:26:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/08/2022 03:27:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.05 on epoch=197
06/08/2022 03:27:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/08/2022 03:27:05 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.45616246498599433 on epoch=199
06/08/2022 03:27:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.05 on epoch=202
06/08/2022 03:27:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.03 on epoch=204
06/08/2022 03:27:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/08/2022 03:27:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.02 on epoch=209
06/08/2022 03:27:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/08/2022 03:27:21 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.5383190883190883 on epoch=212
06/08/2022 03:27:21 - INFO - __main__ - Saving model with best Classification-F1: 0.4627958785853523 -> 0.5383190883190883 on epoch=212, global_step=850
06/08/2022 03:27:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/08/2022 03:27:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=217
06/08/2022 03:27:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/08/2022 03:27:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/08/2022 03:27:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/08/2022 03:27:36 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.5031339031339032 on epoch=224
06/08/2022 03:27:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/08/2022 03:27:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/08/2022 03:27:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/08/2022 03:27:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/08/2022 03:27:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/08/2022 03:27:51 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.48562625125125125 on epoch=237
06/08/2022 03:27:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/08/2022 03:27:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/08/2022 03:28:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 03:28:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/08/2022 03:28:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/08/2022 03:28:06 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.4583333333333333 on epoch=249
06/08/2022 03:28:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/08/2022 03:28:12 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/08/2022 03:28:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/08/2022 03:28:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 03:28:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 03:28:21 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.5083491461100569 on epoch=262
06/08/2022 03:28:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/08/2022 03:28:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/08/2022 03:28:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 03:28:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/08/2022 03:28:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 03:28:36 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.4917516324894031 on epoch=274
06/08/2022 03:28:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/08/2022 03:28:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.03 on epoch=279
06/08/2022 03:28:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 03:28:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/08/2022 03:28:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/08/2022 03:28:51 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.5319688109161793 on epoch=287
06/08/2022 03:28:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/08/2022 03:28:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/08/2022 03:29:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/08/2022 03:29:02 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/08/2022 03:29:05 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/08/2022 03:29:06 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.5007770007770008 on epoch=299
06/08/2022 03:29:09 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=302
06/08/2022 03:29:12 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/08/2022 03:29:15 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 03:29:17 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/08/2022 03:29:20 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/08/2022 03:29:21 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.48397435897435903 on epoch=312
06/08/2022 03:29:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 03:29:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 03:29:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 03:29:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 03:29:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 03:29:36 - INFO - __main__ - Global step 1300 Train loss 0.00 Classification-F1 0.5103046594982079 on epoch=324
06/08/2022 03:29:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 03:29:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/08/2022 03:29:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 03:29:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/08/2022 03:29:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 03:29:51 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.5490890083632018 on epoch=337
06/08/2022 03:29:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5383190883190883 -> 0.5490890083632018 on epoch=337, global_step=1350
06/08/2022 03:29:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 03:29:57 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=342
06/08/2022 03:29:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=344
06/08/2022 03:30:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/08/2022 03:30:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 03:30:06 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.44747920997921 on epoch=349
06/08/2022 03:30:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 03:30:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 03:30:15 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=357
06/08/2022 03:30:17 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 03:30:20 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=362
06/08/2022 03:30:21 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.49806604634190843 on epoch=362
06/08/2022 03:30:24 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 03:30:27 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 03:30:29 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 03:30:32 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 03:30:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/08/2022 03:30:36 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.5169590643274854 on epoch=374
06/08/2022 03:30:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=377
06/08/2022 03:30:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 03:30:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=382
06/08/2022 03:30:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 03:30:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 03:30:51 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5141551515437339 on epoch=387
06/08/2022 03:30:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/08/2022 03:30:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/08/2022 03:30:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 03:31:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 03:31:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 03:31:06 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.5035130718954248 on epoch=399
06/08/2022 03:31:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 03:31:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 03:31:15 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 03:31:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 03:31:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 03:31:21 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.5677350427350427 on epoch=412
06/08/2022 03:31:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5490890083632018 -> 0.5677350427350427 on epoch=412, global_step=1650
06/08/2022 03:31:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 03:31:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 03:31:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 03:31:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 03:31:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/08/2022 03:31:37 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.5142164037512875 on epoch=424
06/08/2022 03:31:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 03:31:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 03:31:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 03:31:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 03:31:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 03:31:52 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.4972701149425287 on epoch=437
06/08/2022 03:31:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 03:31:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 03:32:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 03:32:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 03:32:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=449
06/08/2022 03:32:08 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.5642870672419236 on epoch=449
06/08/2022 03:32:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 03:32:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=454
06/08/2022 03:32:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 03:32:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 03:32:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 03:32:23 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5236586175998023 on epoch=462
06/08/2022 03:32:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 03:32:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 03:32:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 03:32:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 03:32:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/08/2022 03:32:38 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.5101929222785789 on epoch=474
06/08/2022 03:32:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 03:32:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/08/2022 03:32:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 03:32:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=484
06/08/2022 03:32:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/08/2022 03:32:53 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.5952629940865235 on epoch=487
06/08/2022 03:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5677350427350427 -> 0.5952629940865235 on epoch=487, global_step=1950
06/08/2022 03:32:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 03:32:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 03:33:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 03:33:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 03:33:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 03:33:09 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5949175824175824 on epoch=499
06/08/2022 03:33:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 03:33:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 03:33:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 03:33:20 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=509
06/08/2022 03:33:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 03:33:24 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6212605606758832 on epoch=512
06/08/2022 03:33:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5952629940865235 -> 0.6212605606758832 on epoch=512, global_step=2050
06/08/2022 03:33:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 03:33:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 03:33:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 03:33:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 03:33:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 03:33:39 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.5663029499236396 on epoch=524
06/08/2022 03:33:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 03:33:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 03:33:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 03:33:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 03:33:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 03:33:54 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.5455941907554811 on epoch=537
06/08/2022 03:33:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 03:34:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 03:34:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 03:34:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 03:34:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 03:34:10 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.5494619725837893 on epoch=549
06/08/2022 03:34:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 03:34:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 03:34:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 03:34:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 03:34:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 03:34:25 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.48462566844919786 on epoch=562
06/08/2022 03:34:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 03:34:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 03:34:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 03:34:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 03:34:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 03:34:40 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5468456650953065 on epoch=574
06/08/2022 03:34:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 03:34:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 03:34:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 03:34:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 03:34:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 03:34:55 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5591339914720059 on epoch=587
06/08/2022 03:34:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 03:35:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 03:35:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=594
06/08/2022 03:35:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 03:35:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 03:35:10 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5515151515151515 on epoch=599
06/08/2022 03:35:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/08/2022 03:35:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 03:35:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 03:35:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 03:35:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 03:35:25 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.49937489037637106 on epoch=612
06/08/2022 03:35:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 03:35:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 03:35:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/08/2022 03:35:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 03:35:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/08/2022 03:35:40 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5691705498602051 on epoch=624
06/08/2022 03:35:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 03:35:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 03:35:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 03:35:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 03:35:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 03:35:56 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5647977169716301 on epoch=637
06/08/2022 03:35:58 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 03:36:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 03:36:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 03:36:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 03:36:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 03:36:11 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5020371785077667 on epoch=649
06/08/2022 03:36:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 03:36:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 03:36:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 03:36:22 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 03:36:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 03:36:26 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5474917239623123 on epoch=662
06/08/2022 03:36:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 03:36:31 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 03:36:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 03:36:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 03:36:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 03:36:41 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5839255269836032 on epoch=674
06/08/2022 03:36:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 03:36:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 03:36:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 03:36:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 03:36:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 03:36:56 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5839255269836032 on epoch=687
06/08/2022 03:36:59 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 03:37:02 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 03:37:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 03:37:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 03:37:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/08/2022 03:37:11 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5923168826394632 on epoch=699
06/08/2022 03:37:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 03:37:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 03:37:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 03:37:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 03:37:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 03:37:26 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5621976063152534 on epoch=712
06/08/2022 03:37:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 03:37:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 03:37:35 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 03:37:38 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/08/2022 03:37:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/08/2022 03:37:42 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5040296018344799 on epoch=724
06/08/2022 03:37:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 03:37:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 03:37:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 03:37:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 03:37:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 03:37:57 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5667881241565452 on epoch=737
06/08/2022 03:37:59 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 03:38:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 03:38:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 03:38:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 03:38:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 03:38:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:38:12 - INFO - __main__ - Printing 3 examples
06/08/2022 03:38:12 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:38:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:38:12 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:38:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:38:12 - INFO - __main__ - Printing 3 examples
06/08/2022 03:38:12 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:38:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:38:12 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5712599298806195 on epoch=749
06/08/2022 03:38:12 - INFO - __main__ - save last model!
06/08/2022 03:38:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 03:38:12 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:38:12 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 03:38:12 - INFO - __main__ - Printing 3 examples
06/08/2022 03:38:12 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 03:38:12 - INFO - __main__ - ['others']
06/08/2022 03:38:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:38:15 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:38:20 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 03:38:29 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:38:29 - INFO - __main__ - task name: emo
06/08/2022 03:38:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:38:30 - INFO - __main__ - Starting training!
06/08/2022 03:40:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_100_0.4_8_predictions.txt
06/08/2022 03:40:15 - INFO - __main__ - Classification-F1 on test data: 0.2295
06/08/2022 03:40:16 - INFO - __main__ - prefix=emo_16_100, lr=0.4, bsz=8, dev_performance=0.6212605606758832, test_performance=0.22946281961038928
06/08/2022 03:40:16 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.3, bsz=8 ...
06/08/2022 03:40:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:40:17 - INFO - __main__ - Printing 3 examples
06/08/2022 03:40:17 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:40:17 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:40:17 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:40:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:40:17 - INFO - __main__ - Printing 3 examples
06/08/2022 03:40:17 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:40:17 - INFO - __main__ - ['others']
06/08/2022 03:40:17 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:40:17 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:40:17 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:40:35 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:40:35 - INFO - __main__ - task name: emo
06/08/2022 03:40:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:40:37 - INFO - __main__ - Starting training!
06/08/2022 03:40:40 - INFO - __main__ - Step 10 Global step 10 Train loss 6.32 on epoch=2
06/08/2022 03:40:42 - INFO - __main__ - Step 20 Global step 20 Train loss 2.66 on epoch=4
06/08/2022 03:40:45 - INFO - __main__ - Step 30 Global step 30 Train loss 1.45 on epoch=7
06/08/2022 03:40:48 - INFO - __main__ - Step 40 Global step 40 Train loss 1.13 on epoch=9
06/08/2022 03:40:51 - INFO - __main__ - Step 50 Global step 50 Train loss 0.99 on epoch=12
06/08/2022 03:40:52 - INFO - __main__ - Global step 50 Train loss 2.51 Classification-F1 0.1 on epoch=12
06/08/2022 03:40:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 03:40:55 - INFO - __main__ - Step 60 Global step 60 Train loss 1.12 on epoch=14
06/08/2022 03:40:58 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=17
06/08/2022 03:41:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=19
06/08/2022 03:41:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.95 on epoch=22
06/08/2022 03:41:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/08/2022 03:41:07 - INFO - __main__ - Global step 100 Train loss 1.00 Classification-F1 0.24487179487179486 on epoch=24
06/08/2022 03:41:07 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.24487179487179486 on epoch=24, global_step=100
06/08/2022 03:41:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.85 on epoch=27
06/08/2022 03:41:13 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=29
06/08/2022 03:41:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=32
06/08/2022 03:41:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=34
06/08/2022 03:41:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.90 on epoch=37
06/08/2022 03:41:22 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.09493670886075949 on epoch=37
06/08/2022 03:41:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=39
06/08/2022 03:41:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.81 on epoch=42
06/08/2022 03:41:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=44
06/08/2022 03:41:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=47
06/08/2022 03:41:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.91 on epoch=49
06/08/2022 03:41:37 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.18871001031991746 on epoch=49
06/08/2022 03:41:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=52
06/08/2022 03:41:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=54
06/08/2022 03:41:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.78 on epoch=57
06/08/2022 03:41:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.81 on epoch=59
06/08/2022 03:41:51 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=62
06/08/2022 03:41:52 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.09589041095890412 on epoch=62
06/08/2022 03:41:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=64
06/08/2022 03:41:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.82 on epoch=67
06/08/2022 03:42:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.82 on epoch=69
06/08/2022 03:42:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.73 on epoch=72
06/08/2022 03:42:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.73 on epoch=74
06/08/2022 03:42:07 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.2663419913419913 on epoch=74
06/08/2022 03:42:07 - INFO - __main__ - Saving model with best Classification-F1: 0.24487179487179486 -> 0.2663419913419913 on epoch=74, global_step=300
06/08/2022 03:42:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=77
06/08/2022 03:42:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=79
06/08/2022 03:42:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.66 on epoch=82
06/08/2022 03:42:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.77 on epoch=84
06/08/2022 03:42:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.69 on epoch=87
06/08/2022 03:42:22 - INFO - __main__ - Global step 350 Train loss 0.71 Classification-F1 0.17848557692307693 on epoch=87
06/08/2022 03:42:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=89
06/08/2022 03:42:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=92
06/08/2022 03:42:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=94
06/08/2022 03:42:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=97
06/08/2022 03:42:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.40 on epoch=99
06/08/2022 03:42:37 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.3096975447070324 on epoch=99
06/08/2022 03:42:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2663419913419913 -> 0.3096975447070324 on epoch=99, global_step=400
06/08/2022 03:42:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=102
06/08/2022 03:42:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=104
06/08/2022 03:42:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=107
06/08/2022 03:42:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.36 on epoch=109
06/08/2022 03:42:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=112
06/08/2022 03:42:52 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.3258022774327122 on epoch=112
06/08/2022 03:42:52 - INFO - __main__ - Saving model with best Classification-F1: 0.3096975447070324 -> 0.3258022774327122 on epoch=112, global_step=450
06/08/2022 03:42:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=114
06/08/2022 03:42:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=117
06/08/2022 03:43:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=119
06/08/2022 03:43:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.35 on epoch=122
06/08/2022 03:43:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=124
06/08/2022 03:43:07 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.3154304029304029 on epoch=124
06/08/2022 03:43:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=127
06/08/2022 03:43:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=129
06/08/2022 03:43:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=132
06/08/2022 03:43:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.23 on epoch=134
06/08/2022 03:43:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=137
06/08/2022 03:43:21 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.2948717948717949 on epoch=137
06/08/2022 03:43:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.10 on epoch=139
06/08/2022 03:43:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=142
06/08/2022 03:43:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=144
06/08/2022 03:43:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=147
06/08/2022 03:43:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=149
06/08/2022 03:43:36 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.3951612903225806 on epoch=149
06/08/2022 03:43:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3258022774327122 -> 0.3951612903225806 on epoch=149, global_step=600
06/08/2022 03:43:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/08/2022 03:43:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=154
06/08/2022 03:43:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/08/2022 03:43:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=159
06/08/2022 03:43:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/08/2022 03:43:51 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.3617863617863618 on epoch=162
06/08/2022 03:43:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=164
06/08/2022 03:43:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/08/2022 03:43:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/08/2022 03:44:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=172
06/08/2022 03:44:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/08/2022 03:44:06 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.39969278033794164 on epoch=174
06/08/2022 03:44:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3951612903225806 -> 0.39969278033794164 on epoch=174, global_step=700
06/08/2022 03:44:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=177
06/08/2022 03:44:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.05 on epoch=179
06/08/2022 03:44:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=182
06/08/2022 03:44:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=184
06/08/2022 03:44:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/08/2022 03:44:21 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.35784313725490197 on epoch=187
06/08/2022 03:44:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=189
06/08/2022 03:44:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/08/2022 03:44:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=194
06/08/2022 03:44:32 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/08/2022 03:44:35 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=199
06/08/2022 03:44:36 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.35807673509286414 on epoch=199
06/08/2022 03:44:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=202
06/08/2022 03:44:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=204
06/08/2022 03:44:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/08/2022 03:44:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.05 on epoch=209
06/08/2022 03:44:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/08/2022 03:44:51 - INFO - __main__ - Global step 850 Train loss 0.07 Classification-F1 0.3848634191376127 on epoch=212
06/08/2022 03:44:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=214
06/08/2022 03:44:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=217
06/08/2022 03:45:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/08/2022 03:45:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=222
06/08/2022 03:45:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=224
06/08/2022 03:45:07 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.43104155884065476 on epoch=224
06/08/2022 03:45:07 - INFO - __main__ - Saving model with best Classification-F1: 0.39969278033794164 -> 0.43104155884065476 on epoch=224, global_step=900
06/08/2022 03:45:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/08/2022 03:45:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/08/2022 03:45:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=232
06/08/2022 03:45:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/08/2022 03:45:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/08/2022 03:45:22 - INFO - __main__ - Global step 950 Train loss 0.05 Classification-F1 0.42272139625080807 on epoch=237
06/08/2022 03:45:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=239
06/08/2022 03:45:28 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=242
06/08/2022 03:45:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/08/2022 03:45:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/08/2022 03:45:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=249
06/08/2022 03:45:37 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.5172239637756879 on epoch=249
06/08/2022 03:45:37 - INFO - __main__ - Saving model with best Classification-F1: 0.43104155884065476 -> 0.5172239637756879 on epoch=249, global_step=1000
06/08/2022 03:45:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=252
06/08/2022 03:45:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=254
06/08/2022 03:45:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=257
06/08/2022 03:45:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/08/2022 03:45:51 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.02 on epoch=262
06/08/2022 03:45:52 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.42235449735449737 on epoch=262
06/08/2022 03:45:55 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=264
06/08/2022 03:45:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/08/2022 03:46:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.03 on epoch=269
06/08/2022 03:46:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/08/2022 03:46:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 03:46:08 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.5011450631420533 on epoch=274
06/08/2022 03:46:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/08/2022 03:46:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/08/2022 03:46:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/08/2022 03:46:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/08/2022 03:46:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.02 on epoch=287
06/08/2022 03:46:22 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.5157088122605364 on epoch=287
06/08/2022 03:46:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/08/2022 03:46:28 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/08/2022 03:46:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 03:46:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/08/2022 03:46:36 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/08/2022 03:46:37 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.4542424242424242 on epoch=299
06/08/2022 03:46:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 03:46:42 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/08/2022 03:46:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/08/2022 03:46:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/08/2022 03:46:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 03:46:52 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.4937533227006911 on epoch=312
06/08/2022 03:46:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 03:46:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=317
06/08/2022 03:47:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 03:47:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/08/2022 03:47:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 03:47:07 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5334821428571429 on epoch=324
06/08/2022 03:47:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5172239637756879 -> 0.5334821428571429 on epoch=324, global_step=1300
06/08/2022 03:47:10 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.04 on epoch=327
06/08/2022 03:47:13 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=329
06/08/2022 03:47:15 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=332
06/08/2022 03:47:18 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=334
06/08/2022 03:47:21 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 03:47:22 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.49738095238095237 on epoch=337
06/08/2022 03:47:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 03:47:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/08/2022 03:47:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/08/2022 03:47:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/08/2022 03:47:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 03:47:37 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.4602714322281368 on epoch=349
06/08/2022 03:47:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/08/2022 03:47:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=354
06/08/2022 03:47:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/08/2022 03:47:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/08/2022 03:47:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/08/2022 03:47:53 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.48822851721333693 on epoch=362
06/08/2022 03:47:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/08/2022 03:47:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/08/2022 03:48:01 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 03:48:04 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 03:48:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 03:48:08 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.5331495098039216 on epoch=374
06/08/2022 03:48:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 03:48:14 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 03:48:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 03:48:19 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=384
06/08/2022 03:48:22 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 03:48:23 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.4677083333333333 on epoch=387
06/08/2022 03:48:26 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/08/2022 03:48:29 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 03:48:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 03:48:34 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 03:48:37 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 03:48:38 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.5127688172043011 on epoch=399
06/08/2022 03:48:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 03:48:44 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 03:48:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 03:48:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=409
06/08/2022 03:48:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 03:48:53 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.5394345238095238 on epoch=412
06/08/2022 03:48:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5334821428571429 -> 0.5394345238095238 on epoch=412, global_step=1650
06/08/2022 03:48:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 03:48:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 03:49:01 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 03:49:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 03:49:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 03:49:08 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.5198761811665037 on epoch=424
06/08/2022 03:49:11 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 03:49:13 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 03:49:16 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 03:49:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 03:49:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 03:49:23 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.5102073365231261 on epoch=437
06/08/2022 03:49:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 03:49:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=442
06/08/2022 03:49:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 03:49:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 03:49:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/08/2022 03:49:38 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.4569872156179545 on epoch=449
06/08/2022 03:49:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 03:49:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 03:49:46 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/08/2022 03:49:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 03:49:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=462
06/08/2022 03:49:53 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5146627565982405 on epoch=462
06/08/2022 03:49:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=464
06/08/2022 03:49:59 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/08/2022 03:50:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 03:50:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/08/2022 03:50:07 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/08/2022 03:50:09 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.5025541640832143 on epoch=474
06/08/2022 03:50:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/08/2022 03:50:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 03:50:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 03:50:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 03:50:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 03:50:24 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.4828114404727308 on epoch=487
06/08/2022 03:50:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 03:50:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 03:50:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 03:50:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 03:50:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 03:50:40 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.47906979560205365 on epoch=499
06/08/2022 03:50:43 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 03:50:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 03:50:48 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 03:50:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 03:50:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/08/2022 03:50:55 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.49671178119453985 on epoch=512
06/08/2022 03:50:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 03:51:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 03:51:04 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/08/2022 03:51:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=522
06/08/2022 03:51:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 03:51:11 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5049699752775044 on epoch=524
06/08/2022 03:51:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 03:51:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 03:51:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 03:51:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/08/2022 03:51:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/08/2022 03:51:26 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.4977777777777778 on epoch=537
06/08/2022 03:51:29 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 03:51:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 03:51:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 03:51:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=547
06/08/2022 03:51:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 03:51:42 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.4440433175727293 on epoch=549
06/08/2022 03:51:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 03:51:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/08/2022 03:51:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 03:51:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 03:51:56 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 03:51:57 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.5592700598262333 on epoch=562
06/08/2022 03:51:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5394345238095238 -> 0.5592700598262333 on epoch=562, global_step=2250
06/08/2022 03:52:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 03:52:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 03:52:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 03:52:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 03:52:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 03:52:13 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5179487179487179 on epoch=574
06/08/2022 03:52:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 03:52:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/08/2022 03:52:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/08/2022 03:52:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 03:52:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 03:52:28 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5238901033386327 on epoch=587
06/08/2022 03:52:31 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 03:52:34 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 03:52:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 03:52:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 03:52:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 03:52:43 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.47477733415233414 on epoch=599
06/08/2022 03:52:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/08/2022 03:52:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=604
06/08/2022 03:52:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/08/2022 03:52:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 03:52:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 03:52:58 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.5228011630856898 on epoch=612
06/08/2022 03:53:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 03:53:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 03:53:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=619
06/08/2022 03:53:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 03:53:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 03:53:13 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.550843253968254 on epoch=624
06/08/2022 03:53:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/08/2022 03:53:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 03:53:22 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 03:53:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 03:53:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/08/2022 03:53:28 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.47906979560205365 on epoch=637
06/08/2022 03:53:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 03:53:33 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 03:53:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 03:53:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 03:53:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 03:53:43 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5605534511784511 on epoch=649
06/08/2022 03:53:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5592700598262333 -> 0.5605534511784511 on epoch=649, global_step=2600
06/08/2022 03:53:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 03:53:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=654
06/08/2022 03:53:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 03:53:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=659
06/08/2022 03:53:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 03:53:58 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.4338803088803089 on epoch=662
06/08/2022 03:54:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/08/2022 03:54:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 03:54:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 03:54:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 03:54:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/08/2022 03:54:13 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.42543859649122806 on epoch=674
06/08/2022 03:54:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 03:54:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 03:54:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 03:54:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 03:54:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 03:54:29 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.3843700159489633 on epoch=687
06/08/2022 03:54:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 03:54:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 03:54:37 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 03:54:40 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=697
06/08/2022 03:54:42 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 03:54:44 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.4852941176470588 on epoch=699
06/08/2022 03:54:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 03:54:49 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 03:54:52 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 03:54:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 03:54:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 03:54:59 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.38868411000763947 on epoch=712
06/08/2022 03:55:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 03:55:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 03:55:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 03:55:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 03:55:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 03:55:14 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.391087516087516 on epoch=724
06/08/2022 03:55:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 03:55:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 03:55:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 03:55:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 03:55:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 03:55:29 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.503684946289302 on epoch=737
06/08/2022 03:55:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 03:55:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 03:55:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=744
06/08/2022 03:55:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/08/2022 03:55:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 03:55:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:55:44 - INFO - __main__ - Printing 3 examples
06/08/2022 03:55:44 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:55:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:55:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5204259520897891 on epoch=749
06/08/2022 03:55:44 - INFO - __main__ - save last model!
06/08/2022 03:55:44 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:55:44 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:55:44 - INFO - __main__ - Printing 3 examples
06/08/2022 03:55:44 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:55:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 03:55:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:55:44 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 03:55:44 - INFO - __main__ - Printing 3 examples
06/08/2022 03:55:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 03:55:44 - INFO - __main__ - ['others']
06/08/2022 03:55:44 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:55:44 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:55:46 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:55:52 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 03:56:01 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:56:01 - INFO - __main__ - task name: emo
06/08/2022 03:56:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:56:02 - INFO - __main__ - Starting training!
06/08/2022 03:57:45 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_100_0.3_8_predictions.txt
06/08/2022 03:57:45 - INFO - __main__ - Classification-F1 on test data: 0.3855
06/08/2022 03:57:46 - INFO - __main__ - prefix=emo_16_100, lr=0.3, bsz=8, dev_performance=0.5605534511784511, test_performance=0.38553462316453896
06/08/2022 03:57:46 - INFO - __main__ - Running ... prefix=emo_16_100, lr=0.2, bsz=8 ...
06/08/2022 03:57:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:57:47 - INFO - __main__ - Printing 3 examples
06/08/2022 03:57:47 - INFO - __main__ -  [emo] how cause yes am listening
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ -  [emo] ok that way i like living wwrong
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:57:47 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:57:47 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 03:57:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 03:57:47 - INFO - __main__ - Printing 3 examples
06/08/2022 03:57:47 - INFO - __main__ -  [emo] ok i wiil ask u some questions done what is ur full name
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ -  [emo] give your num i send message to this num no to tjis
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ -  [emo] what is docker vagrant and docker are different beasts what is vagrant
06/08/2022 03:57:47 - INFO - __main__ - ['others']
06/08/2022 03:57:47 - INFO - __main__ - Tokenizing Input ...
06/08/2022 03:57:47 - INFO - __main__ - Tokenizing Output ...
06/08/2022 03:57:47 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 03:58:02 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 03:58:02 - INFO - __main__ - task name: emo
06/08/2022 03:58:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 03:58:03 - INFO - __main__ - Starting training!
06/08/2022 03:58:06 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=2
06/08/2022 03:58:08 - INFO - __main__ - Step 20 Global step 20 Train loss 4.72 on epoch=4
06/08/2022 03:58:11 - INFO - __main__ - Step 30 Global step 30 Train loss 2.53 on epoch=7
06/08/2022 03:58:14 - INFO - __main__ - Step 40 Global step 40 Train loss 1.57 on epoch=9
06/08/2022 03:58:17 - INFO - __main__ - Step 50 Global step 50 Train loss 1.31 on epoch=12
06/08/2022 03:58:18 - INFO - __main__ - Global step 50 Train loss 3.48 Classification-F1 0.16855418592706728 on epoch=12
06/08/2022 03:58:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16855418592706728 on epoch=12, global_step=50
06/08/2022 03:58:20 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=14
06/08/2022 03:58:23 - INFO - __main__ - Step 70 Global step 70 Train loss 1.03 on epoch=17
06/08/2022 03:58:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=19
06/08/2022 03:58:28 - INFO - __main__ - Step 90 Global step 90 Train loss 1.15 on epoch=22
06/08/2022 03:58:31 - INFO - __main__ - Step 100 Global step 100 Train loss 1.05 on epoch=24
06/08/2022 03:58:32 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.20138888888888887 on epoch=24
06/08/2022 03:58:32 - INFO - __main__ - Saving model with best Classification-F1: 0.16855418592706728 -> 0.20138888888888887 on epoch=24, global_step=100
06/08/2022 03:58:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.99 on epoch=27
06/08/2022 03:58:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/08/2022 03:58:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/08/2022 03:58:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=34
06/08/2022 03:58:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=37
06/08/2022 03:58:47 - INFO - __main__ - Global step 150 Train loss 0.93 Classification-F1 0.1360774818401937 on epoch=37
06/08/2022 03:58:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=39
06/08/2022 03:58:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.95 on epoch=42
06/08/2022 03:58:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=44
06/08/2022 03:58:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.88 on epoch=47
06/08/2022 03:59:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=49
06/08/2022 03:59:01 - INFO - __main__ - Global step 200 Train loss 0.90 Classification-F1 0.1392982456140351 on epoch=49
06/08/2022 03:59:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=52
06/08/2022 03:59:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=54
06/08/2022 03:59:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.91 on epoch=57
06/08/2022 03:59:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.88 on epoch=59
06/08/2022 03:59:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=62
06/08/2022 03:59:16 - INFO - __main__ - Global step 250 Train loss 0.88 Classification-F1 0.13166666666666668 on epoch=62
06/08/2022 03:59:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=64
06/08/2022 03:59:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=67
06/08/2022 03:59:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.91 on epoch=69
06/08/2022 03:59:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=72
06/08/2022 03:59:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.84 on epoch=74
06/08/2022 03:59:31 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.15136932707355244 on epoch=74
06/08/2022 03:59:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.81 on epoch=77
06/08/2022 03:59:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.74 on epoch=79
06/08/2022 03:59:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.76 on epoch=82
06/08/2022 03:59:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.72 on epoch=84
06/08/2022 03:59:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.76 on epoch=87
06/08/2022 03:59:45 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.1695313603260102 on epoch=87
06/08/2022 03:59:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.77 on epoch=89
06/08/2022 03:59:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.67 on epoch=92
06/08/2022 03:59:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.69 on epoch=94
06/08/2022 03:59:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.74 on epoch=97
06/08/2022 03:59:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.69 on epoch=99
06/08/2022 04:00:00 - INFO - __main__ - Global step 400 Train loss 0.71 Classification-F1 0.2410493317934334 on epoch=99
06/08/2022 04:00:00 - INFO - __main__ - Saving model with best Classification-F1: 0.20138888888888887 -> 0.2410493317934334 on epoch=99, global_step=400
06/08/2022 04:00:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.72 on epoch=102
06/08/2022 04:00:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=104
06/08/2022 04:00:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.55 on epoch=107
06/08/2022 04:00:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.61 on epoch=109
06/08/2022 04:00:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=112
06/08/2022 04:00:15 - INFO - __main__ - Global step 450 Train loss 0.60 Classification-F1 0.24007587321540808 on epoch=112
06/08/2022 04:00:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.56 on epoch=114
06/08/2022 04:00:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=117
06/08/2022 04:00:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=119
06/08/2022 04:00:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=122
06/08/2022 04:00:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=124
06/08/2022 04:00:30 - INFO - __main__ - Global step 500 Train loss 0.48 Classification-F1 0.2784976927834071 on epoch=124
06/08/2022 04:00:30 - INFO - __main__ - Saving model with best Classification-F1: 0.2410493317934334 -> 0.2784976927834071 on epoch=124, global_step=500
06/08/2022 04:00:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=127
06/08/2022 04:00:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=129
06/08/2022 04:00:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=132
06/08/2022 04:00:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=134
06/08/2022 04:00:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=137
06/08/2022 04:00:45 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.3727777777777778 on epoch=137
06/08/2022 04:00:45 - INFO - __main__ - Saving model with best Classification-F1: 0.2784976927834071 -> 0.3727777777777778 on epoch=137, global_step=550
06/08/2022 04:00:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=139
06/08/2022 04:00:51 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/08/2022 04:00:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=144
06/08/2022 04:00:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=147
06/08/2022 04:00:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=149
06/08/2022 04:01:00 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.4025174912543728 on epoch=149
06/08/2022 04:01:00 - INFO - __main__ - Saving model with best Classification-F1: 0.3727777777777778 -> 0.4025174912543728 on epoch=149, global_step=600
06/08/2022 04:01:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=152
06/08/2022 04:01:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/08/2022 04:01:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=157
06/08/2022 04:01:12 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=159
06/08/2022 04:01:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=162
06/08/2022 04:01:16 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.3496188594014681 on epoch=162
06/08/2022 04:01:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=164
06/08/2022 04:01:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=167
06/08/2022 04:01:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/08/2022 04:01:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/08/2022 04:01:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/08/2022 04:01:31 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.3540100250626566 on epoch=174
06/08/2022 04:01:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.20 on epoch=177
06/08/2022 04:01:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=179
06/08/2022 04:01:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=182
06/08/2022 04:01:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=184
06/08/2022 04:01:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/08/2022 04:01:45 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.46295516074803 on epoch=187
06/08/2022 04:01:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4025174912543728 -> 0.46295516074803 on epoch=187, global_step=750
06/08/2022 04:01:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/08/2022 04:01:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=192
06/08/2022 04:01:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=194
06/08/2022 04:01:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=197
06/08/2022 04:01:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=199
06/08/2022 04:02:00 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.43472644376899694 on epoch=199
06/08/2022 04:02:03 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=202
06/08/2022 04:02:06 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=204
06/08/2022 04:02:09 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=207
06/08/2022 04:02:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=209
06/08/2022 04:02:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=212
06/08/2022 04:02:15 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.43 on epoch=212
06/08/2022 04:02:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=214
06/08/2022 04:02:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=217
06/08/2022 04:02:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/08/2022 04:02:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=222
06/08/2022 04:02:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/08/2022 04:02:31 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5488649682314478 on epoch=224
06/08/2022 04:02:31 - INFO - __main__ - Saving model with best Classification-F1: 0.46295516074803 -> 0.5488649682314478 on epoch=224, global_step=900
06/08/2022 04:02:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=227
06/08/2022 04:02:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/08/2022 04:02:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=232
06/08/2022 04:02:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/08/2022 04:02:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=237
06/08/2022 04:02:46 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.4938034188034188 on epoch=237
06/08/2022 04:02:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=239
06/08/2022 04:02:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=242
06/08/2022 04:02:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
06/08/2022 04:02:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=247
06/08/2022 04:02:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=249
06/08/2022 04:03:00 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.4540209326974033 on epoch=249
06/08/2022 04:03:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=252
06/08/2022 04:03:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=254
06/08/2022 04:03:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=257
06/08/2022 04:03:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.03 on epoch=259
06/08/2022 04:03:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=262
06/08/2022 04:03:15 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.5652777777777778 on epoch=262
06/08/2022 04:03:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5488649682314478 -> 0.5652777777777778 on epoch=262, global_step=1050
06/08/2022 04:03:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/08/2022 04:03:21 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/08/2022 04:03:24 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.05 on epoch=269
06/08/2022 04:03:26 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=272
06/08/2022 04:03:29 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/08/2022 04:03:30 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.5728516694033936 on epoch=274
06/08/2022 04:03:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5652777777777778 -> 0.5728516694033936 on epoch=274, global_step=1100
06/08/2022 04:03:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/08/2022 04:03:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/08/2022 04:03:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=282
06/08/2022 04:03:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=284
06/08/2022 04:03:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/08/2022 04:03:46 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.5531938540190603 on epoch=287
06/08/2022 04:03:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.03 on epoch=289
06/08/2022 04:03:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/08/2022 04:03:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/08/2022 04:03:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/08/2022 04:04:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.04 on epoch=299
06/08/2022 04:04:01 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.4116498316498316 on epoch=299
06/08/2022 04:04:04 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/08/2022 04:04:07 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/08/2022 04:04:09 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/08/2022 04:04:12 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=309
06/08/2022 04:04:15 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/08/2022 04:04:16 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.5231162196679437 on epoch=312
06/08/2022 04:04:19 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/08/2022 04:04:22 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/08/2022 04:04:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 04:04:27 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/08/2022 04:04:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/08/2022 04:04:32 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.5571158741890448 on epoch=324
06/08/2022 04:04:34 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/08/2022 04:04:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/08/2022 04:04:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=332
06/08/2022 04:04:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/08/2022 04:04:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 04:04:47 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.48913686014135793 on epoch=337
06/08/2022 04:04:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 04:04:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.01 on epoch=342
06/08/2022 04:04:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 04:04:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 04:05:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 04:05:03 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.5725335249042145 on epoch=349
06/08/2022 04:05:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/08/2022 04:05:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/08/2022 04:05:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/08/2022 04:05:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/08/2022 04:05:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/08/2022 04:05:18 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.5643765115078394 on epoch=362
06/08/2022 04:05:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/08/2022 04:05:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/08/2022 04:05:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 04:05:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=372
06/08/2022 04:05:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/08/2022 04:05:33 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.5131585249042145 on epoch=374
06/08/2022 04:05:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 04:05:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/08/2022 04:05:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/08/2022 04:05:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/08/2022 04:05:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 04:05:49 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.5424740010946907 on epoch=387
06/08/2022 04:05:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 04:05:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/08/2022 04:05:57 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 04:06:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=397
06/08/2022 04:06:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/08/2022 04:06:04 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.5235042735042734 on epoch=399
06/08/2022 04:06:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 04:06:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=404
06/08/2022 04:06:12 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/08/2022 04:06:15 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/08/2022 04:06:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=412
06/08/2022 04:06:19 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.5444298918136128 on epoch=412
06/08/2022 04:06:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 04:06:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 04:06:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/08/2022 04:06:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 04:06:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/08/2022 04:06:34 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.47546813894639983 on epoch=424
06/08/2022 04:06:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/08/2022 04:06:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/08/2022 04:06:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 04:06:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 04:06:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 04:06:50 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5653954766857993 on epoch=437
06/08/2022 04:06:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 04:06:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/08/2022 04:06:58 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/08/2022 04:07:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 04:07:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/08/2022 04:07:05 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5292207792207793 on epoch=449
06/08/2022 04:07:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 04:07:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 04:07:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/08/2022 04:07:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/08/2022 04:07:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 04:07:20 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.49980243161094223 on epoch=462
06/08/2022 04:07:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 04:07:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/08/2022 04:07:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/08/2022 04:07:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 04:07:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/08/2022 04:07:36 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.49044072948328266 on epoch=474
06/08/2022 04:07:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 04:07:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/08/2022 04:07:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/08/2022 04:07:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=484
06/08/2022 04:07:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/08/2022 04:07:51 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.48214285714285715 on epoch=487
06/08/2022 04:07:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/08/2022 04:07:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 04:07:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/08/2022 04:08:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=497
06/08/2022 04:08:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 04:08:06 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.5768849206349206 on epoch=499
06/08/2022 04:08:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5728516694033936 -> 0.5768849206349206 on epoch=499, global_step=2000
06/08/2022 04:08:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 04:08:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/08/2022 04:08:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 04:08:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/08/2022 04:08:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 04:08:21 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.49624864986861406 on epoch=512
06/08/2022 04:08:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/08/2022 04:08:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=517
06/08/2022 04:08:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 04:08:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/08/2022 04:08:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 04:08:36 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5714285714285714 on epoch=524
06/08/2022 04:08:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 04:08:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/08/2022 04:08:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 04:08:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 04:08:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 04:08:51 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5581890331890332 on epoch=537
06/08/2022 04:08:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 04:08:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 04:09:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 04:09:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 04:09:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 04:09:06 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.5727303742009624 on epoch=549
06/08/2022 04:09:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/08/2022 04:09:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/08/2022 04:09:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=557
06/08/2022 04:09:18 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/08/2022 04:09:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/08/2022 04:09:22 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5433935676392573 on epoch=562
06/08/2022 04:09:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 04:09:27 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 04:09:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/08/2022 04:09:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 04:09:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 04:09:37 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5858405483405483 on epoch=574
06/08/2022 04:09:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5768849206349206 -> 0.5858405483405483 on epoch=574, global_step=2300
06/08/2022 04:09:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 04:09:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/08/2022 04:09:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=582
06/08/2022 04:09:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 04:09:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/08/2022 04:09:51 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5254669094024417 on epoch=587
06/08/2022 04:09:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 04:09:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 04:10:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 04:10:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 04:10:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 04:10:06 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5732328086827667 on epoch=599
06/08/2022 04:10:09 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 04:10:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 04:10:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=607
06/08/2022 04:10:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 04:10:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 04:10:21 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5760416666666666 on epoch=612
06/08/2022 04:10:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/08/2022 04:10:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=617
06/08/2022 04:10:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=619
06/08/2022 04:10:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 04:10:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 04:10:36 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.619699275998673 on epoch=624
06/08/2022 04:10:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5858405483405483 -> 0.619699275998673 on epoch=624, global_step=2500
06/08/2022 04:10:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 04:10:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 04:10:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=632
06/08/2022 04:10:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 04:10:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 04:10:51 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.614068100358423 on epoch=637
06/08/2022 04:10:54 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 04:10:56 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
06/08/2022 04:10:59 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 04:11:02 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/08/2022 04:11:05 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 04:11:06 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.629050293857596 on epoch=649
06/08/2022 04:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.619699275998673 -> 0.629050293857596 on epoch=649, global_step=2600
06/08/2022 04:11:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/08/2022 04:11:11 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 04:11:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 04:11:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 04:11:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 04:11:21 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6017067223963776 on epoch=662
06/08/2022 04:11:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/08/2022 04:11:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 04:11:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/08/2022 04:11:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/08/2022 04:11:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 04:11:37 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5565499843817341 on epoch=674
06/08/2022 04:11:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 04:11:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 04:11:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/08/2022 04:11:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 04:11:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 04:11:52 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6089635854341736 on epoch=687
06/08/2022 04:11:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 04:11:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 04:12:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 04:12:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 04:12:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 04:12:07 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6009605862547038 on epoch=699
06/08/2022 04:12:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=702
06/08/2022 04:12:13 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 04:12:16 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 04:12:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 04:12:21 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 04:12:22 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6188023148704394 on epoch=712
06/08/2022 04:12:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 04:12:28 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=717
06/08/2022 04:12:31 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 04:12:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/08/2022 04:12:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=724
06/08/2022 04:12:38 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6100797177316307 on epoch=724
06/08/2022 04:12:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 04:12:43 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 04:12:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 04:12:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 04:12:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=737
06/08/2022 04:12:53 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.5883620689655172 on epoch=737
06/08/2022 04:12:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 04:12:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 04:13:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 04:13:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 04:13:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 04:13:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:13:08 - INFO - __main__ - Printing 3 examples
06/08/2022 04:13:08 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:13:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:13:08 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:13:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:13:08 - INFO - __main__ - Printing 3 examples
06/08/2022 04:13:08 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:13:08 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5613691360061597 on epoch=749
06/08/2022 04:13:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:13:08 - INFO - __main__ - save last model!
06/08/2022 04:13:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 04:13:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 04:13:08 - INFO - __main__ - Printing 3 examples
06/08/2022 04:13:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 04:13:08 - INFO - __main__ - ['others']
06/08/2022 04:13:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:13:08 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:13:11 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:13:17 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 04:13:24 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:13:24 - INFO - __main__ - task name: emo
06/08/2022 04:13:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:13:25 - INFO - __main__ - Starting training!
06/08/2022 04:15:05 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_100_0.2_8_predictions.txt
06/08/2022 04:15:05 - INFO - __main__ - Classification-F1 on test data: 0.2231
06/08/2022 04:15:05 - INFO - __main__ - prefix=emo_16_100, lr=0.2, bsz=8, dev_performance=0.629050293857596, test_performance=0.22307431354545262
06/08/2022 04:15:05 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.5, bsz=8 ...
06/08/2022 04:15:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:15:06 - INFO - __main__ - Printing 3 examples
06/08/2022 04:15:06 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:15:06 - INFO - __main__ - ['others']
06/08/2022 04:15:06 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:15:06 - INFO - __main__ - ['others']
06/08/2022 04:15:06 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:15:06 - INFO - __main__ - ['others']
06/08/2022 04:15:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:15:06 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:15:07 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:15:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:15:07 - INFO - __main__ - Printing 3 examples
06/08/2022 04:15:07 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:15:07 - INFO - __main__ - ['others']
06/08/2022 04:15:07 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:15:07 - INFO - __main__ - ['others']
06/08/2022 04:15:07 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:15:07 - INFO - __main__ - ['others']
06/08/2022 04:15:07 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:15:07 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:15:07 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:15:21 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:15:21 - INFO - __main__ - task name: emo
06/08/2022 04:15:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:15:22 - INFO - __main__ - Starting training!
06/08/2022 04:15:25 - INFO - __main__ - Step 10 Global step 10 Train loss 5.38 on epoch=2
06/08/2022 04:15:28 - INFO - __main__ - Step 20 Global step 20 Train loss 1.92 on epoch=4
06/08/2022 04:15:31 - INFO - __main__ - Step 30 Global step 30 Train loss 1.34 on epoch=7
06/08/2022 04:15:33 - INFO - __main__ - Step 40 Global step 40 Train loss 1.03 on epoch=9
06/08/2022 04:15:36 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=12
06/08/2022 04:15:37 - INFO - __main__ - Global step 50 Train loss 2.15 Classification-F1 0.09493670886075949 on epoch=12
06/08/2022 04:15:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09493670886075949 on epoch=12, global_step=50
06/08/2022 04:15:40 - INFO - __main__ - Step 60 Global step 60 Train loss 1.01 on epoch=14
06/08/2022 04:15:43 - INFO - __main__ - Step 70 Global step 70 Train loss 0.92 on epoch=17
06/08/2022 04:15:46 - INFO - __main__ - Step 80 Global step 80 Train loss 0.86 on epoch=19
06/08/2022 04:15:49 - INFO - __main__ - Step 90 Global step 90 Train loss 0.86 on epoch=22
06/08/2022 04:15:51 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=24
06/08/2022 04:15:52 - INFO - __main__ - Global step 100 Train loss 0.92 Classification-F1 0.11710526315789474 on epoch=24
06/08/2022 04:15:52 - INFO - __main__ - Saving model with best Classification-F1: 0.09493670886075949 -> 0.11710526315789474 on epoch=24, global_step=100
06/08/2022 04:15:55 - INFO - __main__ - Step 110 Global step 110 Train loss 1.07 on epoch=27
06/08/2022 04:15:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=29
06/08/2022 04:16:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=32
06/08/2022 04:16:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=34
06/08/2022 04:16:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=37
06/08/2022 04:16:08 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.1 on epoch=37
06/08/2022 04:16:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.81 on epoch=39
06/08/2022 04:16:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.79 on epoch=42
06/08/2022 04:16:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=44
06/08/2022 04:16:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=47
06/08/2022 04:16:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
06/08/2022 04:16:23 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.35473594472113784 on epoch=49
06/08/2022 04:16:23 - INFO - __main__ - Saving model with best Classification-F1: 0.11710526315789474 -> 0.35473594472113784 on epoch=49, global_step=200
06/08/2022 04:16:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=52
06/08/2022 04:16:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.63 on epoch=54
06/08/2022 04:16:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.51 on epoch=57
06/08/2022 04:16:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=59
06/08/2022 04:16:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=62
06/08/2022 04:16:39 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.4380034908700322 on epoch=62
06/08/2022 04:16:39 - INFO - __main__ - Saving model with best Classification-F1: 0.35473594472113784 -> 0.4380034908700322 on epoch=62, global_step=250
06/08/2022 04:16:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.36 on epoch=64
06/08/2022 04:16:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.49 on epoch=67
06/08/2022 04:16:47 - INFO - __main__ - Step 280 Global step 280 Train loss 0.43 on epoch=69
06/08/2022 04:16:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.31 on epoch=72
06/08/2022 04:16:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.25 on epoch=74
06/08/2022 04:16:54 - INFO - __main__ - Global step 300 Train loss 0.37 Classification-F1 0.4344516594516595 on epoch=74
06/08/2022 04:16:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.27 on epoch=77
06/08/2022 04:16:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.29 on epoch=79
06/08/2022 04:17:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.25 on epoch=82
06/08/2022 04:17:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/08/2022 04:17:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.12 on epoch=87
06/08/2022 04:17:09 - INFO - __main__ - Global step 350 Train loss 0.22 Classification-F1 0.5197477253928867 on epoch=87
06/08/2022 04:17:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4380034908700322 -> 0.5197477253928867 on epoch=87, global_step=350
06/08/2022 04:17:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.18 on epoch=89
06/08/2022 04:17:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.14 on epoch=92
06/08/2022 04:17:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.17 on epoch=94
06/08/2022 04:17:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.13 on epoch=97
06/08/2022 04:17:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.09 on epoch=99
06/08/2022 04:17:24 - INFO - __main__ - Global step 400 Train loss 0.14 Classification-F1 0.5517195767195767 on epoch=99
06/08/2022 04:17:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5197477253928867 -> 0.5517195767195767 on epoch=99, global_step=400
06/08/2022 04:17:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=102
06/08/2022 04:17:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.09 on epoch=104
06/08/2022 04:17:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.06 on epoch=107
06/08/2022 04:17:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.14 on epoch=109
06/08/2022 04:17:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.08 on epoch=112
06/08/2022 04:17:40 - INFO - __main__ - Global step 450 Train loss 0.10 Classification-F1 0.5061520655270655 on epoch=112
06/08/2022 04:17:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/08/2022 04:17:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=117
06/08/2022 04:17:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/08/2022 04:17:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.03 on epoch=122
06/08/2022 04:17:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.07 on epoch=124
06/08/2022 04:17:55 - INFO - __main__ - Global step 500 Train loss 0.07 Classification-F1 0.4753936057181493 on epoch=124
06/08/2022 04:17:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/08/2022 04:18:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
06/08/2022 04:18:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/08/2022 04:18:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=134
06/08/2022 04:18:10 - INFO - __main__ - Step 550 Global step 550 Train loss 0.06 on epoch=137
06/08/2022 04:18:12 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.4697458791208791 on epoch=137
06/08/2022 04:18:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.05 on epoch=139
06/08/2022 04:18:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/08/2022 04:18:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=144
06/08/2022 04:18:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/08/2022 04:18:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=149
06/08/2022 04:18:27 - INFO - __main__ - Global step 600 Train loss 0.04 Classification-F1 0.5416841223292836 on epoch=149
06/08/2022 04:18:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.07 on epoch=152
06/08/2022 04:18:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/08/2022 04:18:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/08/2022 04:18:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/08/2022 04:18:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/08/2022 04:18:43 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.5587342417500927 on epoch=162
06/08/2022 04:18:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5517195767195767 -> 0.5587342417500927 on epoch=162, global_step=650
06/08/2022 04:18:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/08/2022 04:18:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/08/2022 04:18:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/08/2022 04:18:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=172
06/08/2022 04:18:57 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/08/2022 04:18:58 - INFO - __main__ - Global step 700 Train loss 0.04 Classification-F1 0.5431275958659325 on epoch=174
06/08/2022 04:19:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/08/2022 04:19:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.03 on epoch=179
06/08/2022 04:19:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/08/2022 04:19:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.02 on epoch=184
06/08/2022 04:19:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=187
06/08/2022 04:19:14 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.5596489346489347 on epoch=187
06/08/2022 04:19:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5587342417500927 -> 0.5596489346489347 on epoch=187, global_step=750
06/08/2022 04:19:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/08/2022 04:19:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=192
06/08/2022 04:19:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.00 on epoch=194
06/08/2022 04:19:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/08/2022 04:19:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/08/2022 04:19:29 - INFO - __main__ - Global step 800 Train loss 0.03 Classification-F1 0.533625730994152 on epoch=199
06/08/2022 04:19:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/08/2022 04:19:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/08/2022 04:19:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/08/2022 04:19:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=209
06/08/2022 04:19:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=212
06/08/2022 04:19:45 - INFO - __main__ - Global step 850 Train loss 0.03 Classification-F1 0.5062724014336918 on epoch=212
06/08/2022 04:19:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/08/2022 04:19:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/08/2022 04:19:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 04:19:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/08/2022 04:19:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/08/2022 04:20:01 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.4986880970336852 on epoch=224
06/08/2022 04:20:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/08/2022 04:20:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/08/2022 04:20:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/08/2022 04:20:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/08/2022 04:20:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=237
06/08/2022 04:20:16 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.5298174048174048 on epoch=237
06/08/2022 04:20:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.02 on epoch=239
06/08/2022 04:20:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/08/2022 04:20:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 04:20:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/08/2022 04:20:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/08/2022 04:20:32 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.5326520606225955 on epoch=249
06/08/2022 04:20:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/08/2022 04:20:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/08/2022 04:20:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/08/2022 04:20:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/08/2022 04:20:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 04:20:47 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.5184271161775407 on epoch=262
06/08/2022 04:20:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 04:20:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/08/2022 04:20:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/08/2022 04:20:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=272
06/08/2022 04:21:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 04:21:02 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.5569444444444445 on epoch=274
06/08/2022 04:21:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/08/2022 04:21:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=279
06/08/2022 04:21:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=282
06/08/2022 04:21:14 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/08/2022 04:21:17 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 04:21:18 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.5343362282878411 on epoch=287
06/08/2022 04:21:21 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/08/2022 04:21:24 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.01 on epoch=292
06/08/2022 04:21:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 04:21:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 04:21:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 04:21:34 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.5218390804597701 on epoch=299
06/08/2022 04:21:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 04:21:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 04:21:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/08/2022 04:21:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 04:21:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 04:21:49 - INFO - __main__ - Global step 1250 Train loss 0.00 Classification-F1 0.5629838485101644 on epoch=312
06/08/2022 04:21:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5596489346489347 -> 0.5629838485101644 on epoch=312, global_step=1250
06/08/2022 04:21:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=314
06/08/2022 04:21:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 04:21:58 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 04:22:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=322
06/08/2022 04:22:03 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 04:22:05 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.5939325314325314 on epoch=324
06/08/2022 04:22:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5629838485101644 -> 0.5939325314325314 on epoch=324, global_step=1300
06/08/2022 04:22:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/08/2022 04:22:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=329
06/08/2022 04:22:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 04:22:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/08/2022 04:22:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/08/2022 04:22:20 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.5916789516789517 on epoch=337
06/08/2022 04:22:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 04:22:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 04:22:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 04:22:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/08/2022 04:22:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 04:22:36 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6166666666666667 on epoch=349
06/08/2022 04:22:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5939325314325314 -> 0.6166666666666667 on epoch=349, global_step=1400
06/08/2022 04:22:39 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/08/2022 04:22:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 04:22:44 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 04:22:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/08/2022 04:22:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/08/2022 04:22:51 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.5860449735449735 on epoch=362
06/08/2022 04:22:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 04:22:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 04:23:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 04:23:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 04:23:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 04:23:07 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.5741608362485424 on epoch=374
06/08/2022 04:23:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 04:23:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 04:23:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 04:23:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 04:23:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 04:23:22 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.605844204528415 on epoch=387
06/08/2022 04:23:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 04:23:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 04:23:31 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 04:23:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=397
06/08/2022 04:23:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 04:23:38 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.5312685164298068 on epoch=399
06/08/2022 04:23:40 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 04:23:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 04:23:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 04:23:49 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 04:23:52 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 04:23:53 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.5466520934262871 on epoch=412
06/08/2022 04:23:56 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 04:23:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 04:24:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 04:24:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 04:24:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 04:24:09 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.5571707045391256 on epoch=424
06/08/2022 04:24:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 04:24:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 04:24:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 04:24:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 04:24:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 04:24:24 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.5571707045391256 on epoch=437
06/08/2022 04:24:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 04:24:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 04:24:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 04:24:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 04:24:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 04:24:40 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.5231684981684982 on epoch=449
06/08/2022 04:24:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 04:24:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 04:24:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 04:24:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 04:24:54 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 04:24:55 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.5726097450235381 on epoch=462
06/08/2022 04:24:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 04:25:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 04:25:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 04:25:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 04:25:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 04:25:11 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.5708923208923209 on epoch=474
06/08/2022 04:25:14 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 04:25:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 04:25:19 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 04:25:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 04:25:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 04:25:26 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.5533377507061717 on epoch=487
06/08/2022 04:25:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 04:25:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 04:25:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 04:25:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 04:25:40 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/08/2022 04:25:42 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5548517846339988 on epoch=499
06/08/2022 04:25:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/08/2022 04:25:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 04:25:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/08/2022 04:25:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 04:25:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 04:25:57 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.5569591698623957 on epoch=512
06/08/2022 04:26:00 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 04:26:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 04:26:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 04:26:08 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 04:26:11 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 04:26:12 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.5024305682200418 on epoch=524
06/08/2022 04:26:15 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 04:26:18 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 04:26:21 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 04:26:23 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/08/2022 04:26:26 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 04:26:28 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5065701169149445 on epoch=537
06/08/2022 04:26:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 04:26:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/08/2022 04:26:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 04:26:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 04:26:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 04:26:43 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.48433048433048426 on epoch=549
06/08/2022 04:26:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 04:26:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 04:26:51 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 04:26:54 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 04:26:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 04:26:58 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.5191391941391942 on epoch=562
06/08/2022 04:27:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 04:27:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=567
06/08/2022 04:27:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 04:27:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 04:27:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 04:27:13 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5204678362573099 on epoch=574
06/08/2022 04:27:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 04:27:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 04:27:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 04:27:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 04:27:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 04:27:28 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5349002849002849 on epoch=587
06/08/2022 04:27:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 04:27:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 04:27:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 04:27:38 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 04:27:41 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 04:27:42 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5525623708882886 on epoch=599
06/08/2022 04:27:45 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 04:27:48 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/08/2022 04:27:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 04:27:53 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 04:27:56 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 04:27:57 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5059523809523809 on epoch=612
06/08/2022 04:28:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 04:28:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 04:28:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 04:28:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 04:28:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 04:28:11 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5224548440065682 on epoch=624
06/08/2022 04:28:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 04:28:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 04:28:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 04:28:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 04:28:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 04:28:26 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5059523809523809 on epoch=637
06/08/2022 04:28:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=639
06/08/2022 04:28:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=642
06/08/2022 04:28:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 04:28:37 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 04:28:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 04:28:41 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.5056770571476454 on epoch=649
06/08/2022 04:28:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 04:28:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 04:28:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 04:28:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 04:28:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 04:28:55 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5169172932330828 on epoch=662
06/08/2022 04:28:58 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/08/2022 04:29:00 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=667
06/08/2022 04:29:03 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 04:29:06 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 04:29:09 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 04:29:10 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.4605911330049261 on epoch=674
06/08/2022 04:29:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 04:29:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 04:29:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 04:29:21 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 04:29:24 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 04:29:25 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5059523809523809 on epoch=687
06/08/2022 04:29:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 04:29:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 04:29:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 04:29:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 04:29:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 04:29:40 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5347119097119097 on epoch=699
06/08/2022 04:29:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 04:29:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 04:29:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 04:29:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 04:29:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 04:29:55 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5203417703417704 on epoch=712
06/08/2022 04:29:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 04:30:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 04:30:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 04:30:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/08/2022 04:30:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 04:30:11 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5036630036630036 on epoch=724
06/08/2022 04:30:13 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 04:30:16 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 04:30:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 04:30:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 04:30:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 04:30:26 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5389448514448514 on epoch=737
06/08/2022 04:30:29 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 04:30:32 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 04:30:35 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 04:30:37 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 04:30:40 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 04:30:41 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5382553606237817 on epoch=749
06/08/2022 04:30:41 - INFO - __main__ - save last model!
06/08/2022 04:30:41 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 04:30:41 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 04:30:41 - INFO - __main__ - Printing 3 examples
06/08/2022 04:30:41 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 04:30:41 - INFO - __main__ - ['others']
06/08/2022 04:30:41 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 04:30:41 - INFO - __main__ - ['others']
06/08/2022 04:30:41 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 04:30:41 - INFO - __main__ - ['others']
06/08/2022 04:30:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:30:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:30:42 - INFO - __main__ - Printing 3 examples
06/08/2022 04:30:42 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:30:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:30:42 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:30:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:30:42 - INFO - __main__ - Printing 3 examples
06/08/2022 04:30:42 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:30:42 - INFO - __main__ - ['others']
06/08/2022 04:30:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:30:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:30:42 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:30:44 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:30:49 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 04:31:00 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:31:00 - INFO - __main__ - task name: emo
06/08/2022 04:31:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:31:00 - INFO - __main__ - Starting training!
06/08/2022 04:32:40 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_13_0.5_8_predictions.txt
06/08/2022 04:32:40 - INFO - __main__ - Classification-F1 on test data: 0.2926
06/08/2022 04:32:40 - INFO - __main__ - prefix=emo_16_13, lr=0.5, bsz=8, dev_performance=0.6166666666666667, test_performance=0.29255699360613485
06/08/2022 04:32:40 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.4, bsz=8 ...
06/08/2022 04:32:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:32:41 - INFO - __main__ - Printing 3 examples
06/08/2022 04:32:41 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:32:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:32:41 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:32:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:32:41 - INFO - __main__ - Printing 3 examples
06/08/2022 04:32:41 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:32:41 - INFO - __main__ - ['others']
06/08/2022 04:32:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:32:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:32:42 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:33:01 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:33:01 - INFO - __main__ - task name: emo
06/08/2022 04:33:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:33:02 - INFO - __main__ - Starting training!
06/08/2022 04:33:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.08 on epoch=2
06/08/2022 04:33:08 - INFO - __main__ - Step 20 Global step 20 Train loss 2.00 on epoch=4
06/08/2022 04:33:11 - INFO - __main__ - Step 30 Global step 30 Train loss 1.16 on epoch=7
06/08/2022 04:33:14 - INFO - __main__ - Step 40 Global step 40 Train loss 1.04 on epoch=9
06/08/2022 04:33:16 - INFO - __main__ - Step 50 Global step 50 Train loss 1.06 on epoch=12
06/08/2022 04:33:18 - INFO - __main__ - Global step 50 Train loss 2.27 Classification-F1 0.0974025974025974 on epoch=12
06/08/2022 04:33:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0974025974025974 on epoch=12, global_step=50
06/08/2022 04:33:20 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=14
06/08/2022 04:33:23 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/08/2022 04:33:26 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
06/08/2022 04:33:29 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=22
06/08/2022 04:33:31 - INFO - __main__ - Step 100 Global step 100 Train loss 0.89 on epoch=24
06/08/2022 04:33:32 - INFO - __main__ - Global step 100 Train loss 0.96 Classification-F1 0.1 on epoch=24
06/08/2022 04:33:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0974025974025974 -> 0.1 on epoch=24, global_step=100
06/08/2022 04:33:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=27
06/08/2022 04:33:38 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=29
06/08/2022 04:33:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=32
06/08/2022 04:33:43 - INFO - __main__ - Step 140 Global step 140 Train loss 0.89 on epoch=34
06/08/2022 04:33:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=37
06/08/2022 04:33:47 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.1 on epoch=37
06/08/2022 04:33:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.90 on epoch=39
06/08/2022 04:33:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=42
06/08/2022 04:33:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=44
06/08/2022 04:33:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=47
06/08/2022 04:34:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=49
06/08/2022 04:34:01 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.1 on epoch=49
06/08/2022 04:34:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=52
06/08/2022 04:34:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=54
06/08/2022 04:34:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.71 on epoch=57
06/08/2022 04:34:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.66 on epoch=59
06/08/2022 04:34:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=62
06/08/2022 04:34:16 - INFO - __main__ - Global step 250 Train loss 0.73 Classification-F1 0.3600109900419498 on epoch=62
06/08/2022 04:34:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.3600109900419498 on epoch=62, global_step=250
06/08/2022 04:34:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=64
06/08/2022 04:34:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=67
06/08/2022 04:34:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=69
06/08/2022 04:34:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=72
06/08/2022 04:34:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=74
06/08/2022 04:34:30 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.4673669467787115 on epoch=74
06/08/2022 04:34:30 - INFO - __main__ - Saving model with best Classification-F1: 0.3600109900419498 -> 0.4673669467787115 on epoch=74, global_step=300
06/08/2022 04:34:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=77
06/08/2022 04:34:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.38 on epoch=79
06/08/2022 04:34:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.35 on epoch=82
06/08/2022 04:34:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.17 on epoch=84
06/08/2022 04:34:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=87
06/08/2022 04:34:45 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.5175538070274912 on epoch=87
06/08/2022 04:34:45 - INFO - __main__ - Saving model with best Classification-F1: 0.4673669467787115 -> 0.5175538070274912 on epoch=87, global_step=350
06/08/2022 04:34:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=89
06/08/2022 04:34:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.22 on epoch=92
06/08/2022 04:34:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
06/08/2022 04:34:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.19 on epoch=97
06/08/2022 04:34:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.14 on epoch=99
06/08/2022 04:34:59 - INFO - __main__ - Global step 400 Train loss 0.20 Classification-F1 0.4876828667151248 on epoch=99
06/08/2022 04:35:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.12 on epoch=102
06/08/2022 04:35:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.19 on epoch=104
06/08/2022 04:35:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.09 on epoch=107
06/08/2022 04:35:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.11 on epoch=109
06/08/2022 04:35:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/08/2022 04:35:14 - INFO - __main__ - Global step 450 Train loss 0.13 Classification-F1 0.5460784313725491 on epoch=112
06/08/2022 04:35:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5175538070274912 -> 0.5460784313725491 on epoch=112, global_step=450
06/08/2022 04:35:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.07 on epoch=114
06/08/2022 04:35:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.08 on epoch=117
06/08/2022 04:35:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.05 on epoch=119
06/08/2022 04:35:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.12 on epoch=122
06/08/2022 04:35:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=124
06/08/2022 04:35:29 - INFO - __main__ - Global step 500 Train loss 0.09 Classification-F1 0.5519153225806451 on epoch=124
06/08/2022 04:35:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5460784313725491 -> 0.5519153225806451 on epoch=124, global_step=500
06/08/2022 04:35:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.10 on epoch=127
06/08/2022 04:35:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.08 on epoch=129
06/08/2022 04:35:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.09 on epoch=132
06/08/2022 04:35:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=134
06/08/2022 04:35:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.10 on epoch=137
06/08/2022 04:35:44 - INFO - __main__ - Global step 550 Train loss 0.08 Classification-F1 0.5428931875525651 on epoch=137
06/08/2022 04:35:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.03 on epoch=139
06/08/2022 04:35:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.07 on epoch=142
06/08/2022 04:35:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.05 on epoch=144
06/08/2022 04:35:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.08 on epoch=147
06/08/2022 04:35:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.04 on epoch=149
06/08/2022 04:35:59 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.6166272373168924 on epoch=149
06/08/2022 04:35:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5519153225806451 -> 0.6166272373168924 on epoch=149, global_step=600
06/08/2022 04:36:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/08/2022 04:36:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/08/2022 04:36:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.04 on epoch=157
06/08/2022 04:36:10 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=159
06/08/2022 04:36:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.02 on epoch=162
06/08/2022 04:36:14 - INFO - __main__ - Global step 650 Train loss 0.04 Classification-F1 0.5610948191593353 on epoch=162
06/08/2022 04:36:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.05 on epoch=164
06/08/2022 04:36:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/08/2022 04:36:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=169
06/08/2022 04:36:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.04 on epoch=172
06/08/2022 04:36:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.02 on epoch=174
06/08/2022 04:36:29 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.533169934640523 on epoch=174
06/08/2022 04:36:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/08/2022 04:36:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/08/2022 04:36:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/08/2022 04:36:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/08/2022 04:36:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/08/2022 04:36:44 - INFO - __main__ - Global step 750 Train loss 0.04 Classification-F1 0.49047619047619045 on epoch=187
06/08/2022 04:36:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/08/2022 04:36:50 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
06/08/2022 04:36:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/08/2022 04:36:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/08/2022 04:36:58 - INFO - __main__ - Step 800 Global step 800 Train loss 0.03 on epoch=199
06/08/2022 04:37:00 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.5762867647058824 on epoch=199
06/08/2022 04:37:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=202
06/08/2022 04:37:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/08/2022 04:37:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/08/2022 04:37:11 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/08/2022 04:37:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/08/2022 04:37:15 - INFO - __main__ - Global step 850 Train loss 0.01 Classification-F1 0.5814516129032258 on epoch=212
06/08/2022 04:37:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=214
06/08/2022 04:37:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/08/2022 04:37:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/08/2022 04:37:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.03 on epoch=222
06/08/2022 04:37:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=224
06/08/2022 04:37:30 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.48532899208997654 on epoch=224
06/08/2022 04:37:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/08/2022 04:37:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/08/2022 04:37:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/08/2022 04:37:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/08/2022 04:37:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.01 on epoch=237
06/08/2022 04:37:45 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.5334323049840292 on epoch=237
06/08/2022 04:37:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/08/2022 04:37:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/08/2022 04:37:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 04:37:57 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=247
06/08/2022 04:38:00 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/08/2022 04:38:01 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.5485449735449734 on epoch=249
06/08/2022 04:38:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/08/2022 04:38:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/08/2022 04:38:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/08/2022 04:38:12 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.00 on epoch=259
06/08/2022 04:38:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=262
06/08/2022 04:38:17 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.4980392156862745 on epoch=262
06/08/2022 04:38:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 04:38:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/08/2022 04:38:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/08/2022 04:38:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 04:38:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 04:38:32 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.5010416666666666 on epoch=274
06/08/2022 04:38:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 04:38:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/08/2022 04:38:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/08/2022 04:38:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 04:38:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 04:38:47 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6223358294930876 on epoch=287
06/08/2022 04:38:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6166272373168924 -> 0.6223358294930876 on epoch=287, global_step=1150
06/08/2022 04:38:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/08/2022 04:38:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 04:38:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/08/2022 04:38:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 04:39:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 04:39:02 - INFO - __main__ - Global step 1200 Train loss 0.00 Classification-F1 0.6337230087230088 on epoch=299
06/08/2022 04:39:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6223358294930876 -> 0.6337230087230088 on epoch=299, global_step=1200
06/08/2022 04:39:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 04:39:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 04:39:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 04:39:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 04:39:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 04:39:17 - INFO - __main__ - Global step 1250 Train loss 0.00 Classification-F1 0.6091909882232464 on epoch=312
06/08/2022 04:39:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/08/2022 04:39:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/08/2022 04:39:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 04:39:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/08/2022 04:39:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/08/2022 04:39:33 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5469630921243824 on epoch=324
06/08/2022 04:39:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/08/2022 04:39:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/08/2022 04:39:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 04:39:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/08/2022 04:39:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 04:39:48 - INFO - __main__ - Global step 1350 Train loss 0.00 Classification-F1 0.5977065826330532 on epoch=337
06/08/2022 04:39:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 04:39:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 04:39:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=344
06/08/2022 04:39:59 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=347
06/08/2022 04:40:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 04:40:03 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.5766546166961768 on epoch=349
06/08/2022 04:40:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/08/2022 04:40:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 04:40:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 04:40:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 04:40:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 04:40:18 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.537542242703533 on epoch=362
06/08/2022 04:40:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/08/2022 04:40:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=367
06/08/2022 04:40:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 04:40:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/08/2022 04:40:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 04:40:33 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.5938979039891819 on epoch=374
06/08/2022 04:40:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 04:40:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 04:40:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 04:40:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/08/2022 04:40:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/08/2022 04:40:48 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.5900735294117647 on epoch=387
06/08/2022 04:40:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 04:40:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 04:40:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 04:40:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 04:41:02 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 04:41:03 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.5943304007820137 on epoch=399
06/08/2022 04:41:06 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 04:41:09 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 04:41:11 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/08/2022 04:41:14 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 04:41:17 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 04:41:18 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5925546607531902 on epoch=412
06/08/2022 04:41:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/08/2022 04:41:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=417
06/08/2022 04:41:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/08/2022 04:41:29 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 04:41:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 04:41:33 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5982101718943824 on epoch=424
06/08/2022 04:41:36 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 04:41:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 04:41:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 04:41:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 04:41:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 04:41:49 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.6021202236719478 on epoch=437
06/08/2022 04:41:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 04:41:55 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 04:41:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 04:42:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 04:42:03 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 04:42:04 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6338077889802027 on epoch=449
06/08/2022 04:42:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6337230087230088 -> 0.6338077889802027 on epoch=449, global_step=1800
06/08/2022 04:42:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 04:42:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 04:42:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 04:42:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 04:42:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 04:42:20 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.6832368082368082 on epoch=462
06/08/2022 04:42:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6338077889802027 -> 0.6832368082368082 on epoch=462, global_step=1850
06/08/2022 04:42:23 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 04:42:25 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=467
06/08/2022 04:42:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 04:42:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 04:42:34 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=474
06/08/2022 04:42:35 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6221727845754542 on epoch=474
06/08/2022 04:42:38 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/08/2022 04:42:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 04:42:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 04:42:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 04:42:50 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 04:42:51 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6230798771121352 on epoch=487
06/08/2022 04:42:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 04:42:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/08/2022 04:43:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 04:43:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 04:43:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/08/2022 04:43:07 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5924695198592258 on epoch=499
06/08/2022 04:43:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 04:43:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 04:43:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 04:43:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 04:43:21 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 04:43:22 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6069400905607802 on epoch=512
06/08/2022 04:43:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=514
06/08/2022 04:43:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 04:43:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 04:43:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 04:43:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 04:43:38 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6340277777777777 on epoch=524
06/08/2022 04:43:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 04:43:43 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 04:43:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 04:43:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 04:43:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 04:43:53 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6470853500886872 on epoch=537
06/08/2022 04:43:56 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 04:43:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 04:44:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 04:44:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 04:44:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 04:44:09 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.61531279178338 on epoch=549
06/08/2022 04:44:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 04:44:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 04:44:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 04:44:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 04:44:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 04:44:24 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.605481568209763 on epoch=562
06/08/2022 04:44:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 04:44:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 04:44:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/08/2022 04:44:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 04:44:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 04:44:40 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6211155961155961 on epoch=574
06/08/2022 04:44:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 04:44:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 04:44:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 04:44:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 04:44:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 04:44:55 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6296640141467728 on epoch=587
06/08/2022 04:44:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 04:45:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 04:45:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 04:45:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 04:45:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/08/2022 04:45:11 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.585971685971686 on epoch=599
06/08/2022 04:45:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 04:45:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 04:45:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 04:45:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 04:45:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 04:45:26 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6417999457847655 on epoch=612
06/08/2022 04:45:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 04:45:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 04:45:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 04:45:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 04:45:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 04:45:41 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6595219759847124 on epoch=624
06/08/2022 04:45:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 04:45:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 04:45:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 04:45:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 04:45:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 04:45:57 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6595219759847124 on epoch=637
06/08/2022 04:45:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 04:46:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 04:46:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 04:46:08 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 04:46:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 04:46:12 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6449490662139219 on epoch=649
06/08/2022 04:46:15 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 04:46:18 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 04:46:20 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 04:46:23 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/08/2022 04:46:26 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 04:46:27 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6260683760683761 on epoch=662
06/08/2022 04:46:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 04:46:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 04:46:36 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 04:46:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 04:46:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 04:46:43 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6467829001784858 on epoch=674
06/08/2022 04:46:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 04:46:49 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 04:46:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 04:46:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 04:46:57 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 04:46:58 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6462011219270747 on epoch=687
06/08/2022 04:47:01 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 04:47:04 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 04:47:07 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 04:47:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 04:47:12 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 04:47:14 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6805555555555556 on epoch=699
06/08/2022 04:47:16 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 04:47:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 04:47:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 04:47:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 04:47:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 04:47:29 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.680084551052293 on epoch=712
06/08/2022 04:47:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 04:47:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 04:47:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 04:47:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 04:47:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 04:47:44 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6353862108853034 on epoch=724
06/08/2022 04:47:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 04:47:50 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 04:47:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 04:47:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 04:47:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 04:47:59 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6382734382734383 on epoch=737
06/08/2022 04:48:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 04:48:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 04:48:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 04:48:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 04:48:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=749
06/08/2022 04:48:14 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6191756272401433 on epoch=749
06/08/2022 04:48:14 - INFO - __main__ - save last model!
06/08/2022 04:48:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:48:14 - INFO - __main__ - Printing 3 examples
06/08/2022 04:48:14 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:48:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 04:48:14 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 04:48:14 - INFO - __main__ - Printing 3 examples
06/08/2022 04:48:14 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:48:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:48:14 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:48:14 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:48:14 - INFO - __main__ - Printing 3 examples
06/08/2022 04:48:14 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:48:14 - INFO - __main__ - ['others']
06/08/2022 04:48:14 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:48:14 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:48:15 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:48:17 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:48:22 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 04:48:31 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:48:31 - INFO - __main__ - task name: emo
06/08/2022 04:48:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:48:32 - INFO - __main__ - Starting training!
06/08/2022 04:50:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_13_0.4_8_predictions.txt
06/08/2022 04:50:15 - INFO - __main__ - Classification-F1 on test data: 0.1969
06/08/2022 04:50:15 - INFO - __main__ - prefix=emo_16_13, lr=0.4, bsz=8, dev_performance=0.6832368082368082, test_performance=0.19687600588799506
06/08/2022 04:50:15 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.3, bsz=8 ...
06/08/2022 04:50:16 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:50:16 - INFO - __main__ - Printing 3 examples
06/08/2022 04:50:16 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 04:50:16 - INFO - __main__ - ['others']
06/08/2022 04:50:16 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 04:50:16 - INFO - __main__ - ['others']
06/08/2022 04:50:16 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 04:50:16 - INFO - __main__ - ['others']
06/08/2022 04:50:16 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:50:16 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:50:17 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 04:50:17 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 04:50:17 - INFO - __main__ - Printing 3 examples
06/08/2022 04:50:17 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 04:50:17 - INFO - __main__ - ['others']
06/08/2022 04:50:17 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 04:50:17 - INFO - __main__ - ['others']
06/08/2022 04:50:17 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 04:50:17 - INFO - __main__ - ['others']
06/08/2022 04:50:17 - INFO - __main__ - Tokenizing Input ...
06/08/2022 04:50:17 - INFO - __main__ - Tokenizing Output ...
06/08/2022 04:50:17 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 04:50:36 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 04:50:36 - INFO - __main__ - task name: emo
06/08/2022 04:50:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 04:50:37 - INFO - __main__ - Starting training!
06/08/2022 04:50:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.14 on epoch=2
06/08/2022 04:50:44 - INFO - __main__ - Step 20 Global step 20 Train loss 2.40 on epoch=4
06/08/2022 04:50:46 - INFO - __main__ - Step 30 Global step 30 Train loss 1.39 on epoch=7
06/08/2022 04:50:49 - INFO - __main__ - Step 40 Global step 40 Train loss 1.26 on epoch=9
06/08/2022 04:50:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=12
06/08/2022 04:50:53 - INFO - __main__ - Global step 50 Train loss 2.46 Classification-F1 0.16390740605083876 on epoch=12
06/08/2022 04:50:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.16390740605083876 on epoch=12, global_step=50
06/08/2022 04:50:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=14
06/08/2022 04:50:59 - INFO - __main__ - Step 70 Global step 70 Train loss 1.12 on epoch=17
06/08/2022 04:51:01 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/08/2022 04:51:04 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=22
06/08/2022 04:51:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=24
06/08/2022 04:51:08 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.17450980392156862 on epoch=24
06/08/2022 04:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.16390740605083876 -> 0.17450980392156862 on epoch=24, global_step=100
06/08/2022 04:51:11 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=27
06/08/2022 04:51:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/08/2022 04:51:17 - INFO - __main__ - Step 130 Global step 130 Train loss 0.90 on epoch=32
06/08/2022 04:51:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=34
06/08/2022 04:51:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=37
06/08/2022 04:51:23 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.13936867182846935 on epoch=37
06/08/2022 04:51:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.89 on epoch=39
06/08/2022 04:51:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=42
06/08/2022 04:51:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=44
06/08/2022 04:51:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/08/2022 04:51:37 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=49
06/08/2022 04:51:38 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.1682769726247987 on epoch=49
06/08/2022 04:51:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.93 on epoch=52
06/08/2022 04:51:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.74 on epoch=54
06/08/2022 04:51:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.84 on epoch=57
06/08/2022 04:51:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=59
06/08/2022 04:51:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.84 on epoch=62
06/08/2022 04:51:53 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.15144596651445968 on epoch=62
06/08/2022 04:51:56 - INFO - __main__ - Step 260 Global step 260 Train loss 0.76 on epoch=64
06/08/2022 04:51:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.72 on epoch=67
06/08/2022 04:52:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.71 on epoch=69
06/08/2022 04:52:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=72
06/08/2022 04:52:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.69 on epoch=74
06/08/2022 04:52:08 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.2708333333333333 on epoch=74
06/08/2022 04:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.17450980392156862 -> 0.2708333333333333 on epoch=74, global_step=300
06/08/2022 04:52:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.66 on epoch=77
06/08/2022 04:52:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.69 on epoch=79
06/08/2022 04:52:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=82
06/08/2022 04:52:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.67 on epoch=84
06/08/2022 04:52:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=87
06/08/2022 04:52:23 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.34054341226472373 on epoch=87
06/08/2022 04:52:24 - INFO - __main__ - Saving model with best Classification-F1: 0.2708333333333333 -> 0.34054341226472373 on epoch=87, global_step=350
06/08/2022 04:52:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=89
06/08/2022 04:52:29 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=92
06/08/2022 04:52:32 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=94
06/08/2022 04:52:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.55 on epoch=97
06/08/2022 04:52:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=99
06/08/2022 04:52:39 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.5311454311454311 on epoch=99
06/08/2022 04:52:39 - INFO - __main__ - Saving model with best Classification-F1: 0.34054341226472373 -> 0.5311454311454311 on epoch=99, global_step=400
06/08/2022 04:52:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.48 on epoch=102
06/08/2022 04:52:44 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=104
06/08/2022 04:52:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.47 on epoch=107
06/08/2022 04:52:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=109
06/08/2022 04:52:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=112
06/08/2022 04:52:53 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.4719125072066248 on epoch=112
06/08/2022 04:52:56 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=114
06/08/2022 04:52:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.32 on epoch=117
06/08/2022 04:53:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=119
06/08/2022 04:53:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=122
06/08/2022 04:53:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=124
06/08/2022 04:53:08 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.4489774593222869 on epoch=124
06/08/2022 04:53:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=127
06/08/2022 04:53:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/08/2022 04:53:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=132
06/08/2022 04:53:19 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=134
06/08/2022 04:53:22 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=137
06/08/2022 04:53:23 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.5674603174603174 on epoch=137
06/08/2022 04:53:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5311454311454311 -> 0.5674603174603174 on epoch=137, global_step=550
06/08/2022 04:53:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=139
06/08/2022 04:53:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=142
06/08/2022 04:53:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=144
06/08/2022 04:53:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.21 on epoch=147
06/08/2022 04:53:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/08/2022 04:53:37 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.44543064979521974 on epoch=149
06/08/2022 04:53:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=152
06/08/2022 04:53:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=154
06/08/2022 04:53:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.12 on epoch=157
06/08/2022 04:53:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=159
06/08/2022 04:53:52 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/08/2022 04:53:53 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.513780337309749 on epoch=162
06/08/2022 04:53:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/08/2022 04:53:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/08/2022 04:54:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=169
06/08/2022 04:54:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
06/08/2022 04:54:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=174
06/08/2022 04:54:08 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.5516369047619047 on epoch=174
06/08/2022 04:54:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=177
06/08/2022 04:54:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=179
06/08/2022 04:54:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/08/2022 04:54:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/08/2022 04:54:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.06 on epoch=187
06/08/2022 04:54:23 - INFO - __main__ - Global step 750 Train loss 0.08 Classification-F1 0.5876630679262258 on epoch=187
06/08/2022 04:54:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5674603174603174 -> 0.5876630679262258 on epoch=187, global_step=750
06/08/2022 04:54:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.07 on epoch=189
06/08/2022 04:54:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.06 on epoch=192
06/08/2022 04:54:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/08/2022 04:54:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=197
06/08/2022 04:54:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=199
06/08/2022 04:54:39 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.5590620306093452 on epoch=199
06/08/2022 04:54:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=202
06/08/2022 04:54:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.04 on epoch=204
06/08/2022 04:54:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/08/2022 04:54:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/08/2022 04:54:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/08/2022 04:54:54 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.5095084154351396 on epoch=212
06/08/2022 04:54:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/08/2022 04:55:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/08/2022 04:55:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 04:55:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/08/2022 04:55:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/08/2022 04:55:10 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6628758169934641 on epoch=224
06/08/2022 04:55:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5876630679262258 -> 0.6628758169934641 on epoch=224, global_step=900
06/08/2022 04:55:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/08/2022 04:55:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=229
06/08/2022 04:55:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/08/2022 04:55:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=234
06/08/2022 04:55:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/08/2022 04:55:25 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.5860510563585855 on epoch=237
06/08/2022 04:55:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/08/2022 04:55:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.03 on epoch=242
06/08/2022 04:55:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 04:55:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/08/2022 04:55:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/08/2022 04:55:41 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.6009745564892623 on epoch=249
06/08/2022 04:55:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/08/2022 04:55:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/08/2022 04:55:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/08/2022 04:55:52 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/08/2022 04:55:55 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/08/2022 04:55:56 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6139025725232622 on epoch=262
06/08/2022 04:55:59 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/08/2022 04:56:02 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=267
06/08/2022 04:56:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/08/2022 04:56:07 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=272
06/08/2022 04:56:10 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/08/2022 04:56:12 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.5724014336917562 on epoch=274
06/08/2022 04:56:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/08/2022 04:56:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=279
06/08/2022 04:56:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 04:56:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 04:56:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 04:56:27 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.6434308628047285 on epoch=287
06/08/2022 04:56:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/08/2022 04:56:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/08/2022 04:56:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=294
06/08/2022 04:56:38 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 04:56:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 04:56:42 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.642748320167675 on epoch=299
06/08/2022 04:56:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 04:56:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=304
06/08/2022 04:56:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/08/2022 04:56:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 04:56:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 04:56:57 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.6278899146842696 on epoch=312
06/08/2022 04:57:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=314
06/08/2022 04:57:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 04:57:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 04:57:09 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 04:57:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=324
06/08/2022 04:57:13 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.630033733923677 on epoch=324
06/08/2022 04:57:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/08/2022 04:57:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/08/2022 04:57:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 04:57:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/08/2022 04:57:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 04:57:28 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6699969526794655 on epoch=337
06/08/2022 04:57:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6628758169934641 -> 0.6699969526794655 on epoch=337, global_step=1350
06/08/2022 04:57:31 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/08/2022 04:57:34 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 04:57:37 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 04:57:39 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 04:57:42 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 04:57:44 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6578446115288221 on epoch=349
06/08/2022 04:57:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 04:57:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 04:57:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/08/2022 04:57:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=359
06/08/2022 04:57:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/08/2022 04:57:59 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.5742624079665237 on epoch=362
06/08/2022 04:58:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/08/2022 04:58:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/08/2022 04:58:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 04:58:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 04:58:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/08/2022 04:58:15 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.6419388138138138 on epoch=374
06/08/2022 04:58:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 04:58:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 04:58:23 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/08/2022 04:58:26 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 04:58:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 04:58:30 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6538679204214009 on epoch=387
06/08/2022 04:58:33 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 04:58:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 04:58:38 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 04:58:41 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 04:58:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 04:58:45 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.6734892787524367 on epoch=399
06/08/2022 04:58:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6699969526794655 -> 0.6734892787524367 on epoch=399, global_step=1600
06/08/2022 04:58:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 04:58:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 04:58:53 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=407
06/08/2022 04:58:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/08/2022 04:58:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 04:59:00 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.7293484707277811 on epoch=412
06/08/2022 04:59:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6734892787524367 -> 0.7293484707277811 on epoch=412, global_step=1650
06/08/2022 04:59:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/08/2022 04:59:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 04:59:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/08/2022 04:59:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 04:59:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 04:59:15 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.6697983870967743 on epoch=424
06/08/2022 04:59:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 04:59:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/08/2022 04:59:24 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 04:59:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 04:59:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 04:59:31 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6909372236958444 on epoch=437
06/08/2022 04:59:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 04:59:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 04:59:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 04:59:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 04:59:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 04:59:46 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6696979491097138 on epoch=449
06/08/2022 04:59:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/08/2022 04:59:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/08/2022 04:59:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 04:59:58 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=459
06/08/2022 05:00:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 05:00:02 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6710906279217475 on epoch=462
06/08/2022 05:00:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 05:00:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 05:00:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 05:00:14 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 05:00:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 05:00:18 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6405467967967968 on epoch=474
06/08/2022 05:00:21 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 05:00:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/08/2022 05:00:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 05:00:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 05:00:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 05:00:33 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6873041519780649 on epoch=487
06/08/2022 05:00:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=489
06/08/2022 05:00:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/08/2022 05:00:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 05:00:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 05:00:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 05:00:49 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6714437902999719 on epoch=499
06/08/2022 05:00:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 05:00:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 05:00:57 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 05:01:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 05:01:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 05:01:04 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6665377247273799 on epoch=512
06/08/2022 05:01:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 05:01:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=517
06/08/2022 05:01:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 05:01:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/08/2022 05:01:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 05:01:20 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6776931401931402 on epoch=524
06/08/2022 05:01:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/08/2022 05:01:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 05:01:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 05:01:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=534
06/08/2022 05:01:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 05:01:36 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6502756892230577 on epoch=537
06/08/2022 05:01:38 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 05:01:41 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 05:01:44 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 05:01:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 05:01:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 05:01:51 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6601294123033253 on epoch=549
06/08/2022 05:01:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 05:01:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 05:02:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 05:02:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 05:02:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 05:02:07 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6440642864758904 on epoch=562
06/08/2022 05:02:09 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 05:02:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 05:02:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 05:02:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=572
06/08/2022 05:02:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 05:02:22 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6753862691362691 on epoch=574
06/08/2022 05:02:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 05:02:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=579
06/08/2022 05:02:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 05:02:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 05:02:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 05:02:38 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6230550284629981 on epoch=587
06/08/2022 05:02:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 05:02:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 05:02:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 05:02:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 05:02:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=599
06/08/2022 05:02:53 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6197487810391036 on epoch=599
06/08/2022 05:02:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 05:02:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=604
06/08/2022 05:03:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 05:03:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 05:03:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 05:03:08 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6626717835693993 on epoch=612
06/08/2022 05:03:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/08/2022 05:03:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 05:03:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 05:03:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 05:03:22 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 05:03:23 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6239120528594213 on epoch=624
06/08/2022 05:03:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/08/2022 05:03:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 05:03:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 05:03:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 05:03:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 05:03:39 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6447514478764479 on epoch=637
06/08/2022 05:03:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 05:03:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 05:03:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/08/2022 05:03:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 05:03:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 05:03:54 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6315031586770717 on epoch=649
06/08/2022 05:03:57 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 05:04:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 05:04:02 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 05:04:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/08/2022 05:04:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=662
06/08/2022 05:04:09 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6203439803439804 on epoch=662
06/08/2022 05:04:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 05:04:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=667
06/08/2022 05:04:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 05:04:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 05:04:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 05:04:24 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6475933975933975 on epoch=674
06/08/2022 05:04:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=677
06/08/2022 05:04:30 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 05:04:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 05:04:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.11 on epoch=684
06/08/2022 05:04:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=687
06/08/2022 05:04:39 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6541666666666667 on epoch=687
06/08/2022 05:04:42 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=689
06/08/2022 05:04:45 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 05:04:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 05:04:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 05:04:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 05:04:55 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6495432178005991 on epoch=699
06/08/2022 05:04:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 05:05:00 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=704
06/08/2022 05:05:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=707
06/08/2022 05:05:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/08/2022 05:05:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=712
06/08/2022 05:05:10 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6819298245614035 on epoch=712
06/08/2022 05:05:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 05:05:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 05:05:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 05:05:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 05:05:24 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 05:05:25 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6099778270509978 on epoch=724
06/08/2022 05:05:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 05:05:31 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 05:05:34 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 05:05:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 05:05:39 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 05:05:41 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.656944376318242 on epoch=737
06/08/2022 05:05:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=739
06/08/2022 05:05:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 05:05:49 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 05:05:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 05:05:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 05:05:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:05:56 - INFO - __main__ - Printing 3 examples
06/08/2022 05:05:56 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:05:56 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6080808080808081 on epoch=749
06/08/2022 05:05:56 - INFO - __main__ - save last model!
06/08/2022 05:05:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:05:56 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 05:05:56 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 05:05:56 - INFO - __main__ - Printing 3 examples
06/08/2022 05:05:56 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:05:56 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:05:56 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:05:56 - INFO - __main__ - Printing 3 examples
06/08/2022 05:05:56 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 05:05:56 - INFO - __main__ - ['others']
06/08/2022 05:05:56 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:05:56 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:05:56 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:05:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:06:05 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 05:06:14 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:06:14 - INFO - __main__ - task name: emo
06/08/2022 05:06:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:06:15 - INFO - __main__ - Starting training!
06/08/2022 05:07:58 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_13_0.3_8_predictions.txt
06/08/2022 05:07:58 - INFO - __main__ - Classification-F1 on test data: 0.3827
06/08/2022 05:07:59 - INFO - __main__ - prefix=emo_16_13, lr=0.3, bsz=8, dev_performance=0.7293484707277811, test_performance=0.3827193857811658
06/08/2022 05:07:59 - INFO - __main__ - Running ... prefix=emo_16_13, lr=0.2, bsz=8 ...
06/08/2022 05:08:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:08:00 - INFO - __main__ - Printing 3 examples
06/08/2022 05:08:00 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:08:00 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:08:00 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:08:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:08:00 - INFO - __main__ - Printing 3 examples
06/08/2022 05:08:00 - INFO - __main__ -  [emo] ok thx you and you  ok tell me about your  family
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ -  [emo] i did ask now you did tell ms
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ -  [emo] buddy how you tell me your contact no
06/08/2022 05:08:00 - INFO - __main__ - ['others']
06/08/2022 05:08:00 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:08:00 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:08:00 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:08:15 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:08:15 - INFO - __main__ - task name: emo
06/08/2022 05:08:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:08:16 - INFO - __main__ - Starting training!
06/08/2022 05:08:19 - INFO - __main__ - Step 10 Global step 10 Train loss 6.83 on epoch=2
06/08/2022 05:08:22 - INFO - __main__ - Step 20 Global step 20 Train loss 4.21 on epoch=4
06/08/2022 05:08:25 - INFO - __main__ - Step 30 Global step 30 Train loss 2.33 on epoch=7
06/08/2022 05:08:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.31 on epoch=9
06/08/2022 05:08:30 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/08/2022 05:08:31 - INFO - __main__ - Global step 50 Train loss 3.16 Classification-F1 0.1 on epoch=12
06/08/2022 05:08:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 05:08:34 - INFO - __main__ - Step 60 Global step 60 Train loss 0.93 on epoch=14
06/08/2022 05:08:37 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=17
06/08/2022 05:08:40 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/08/2022 05:08:42 - INFO - __main__ - Step 90 Global step 90 Train loss 0.91 on epoch=22
06/08/2022 05:08:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.86 on epoch=24
06/08/2022 05:08:46 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.09868421052631579 on epoch=24
06/08/2022 05:08:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=27
06/08/2022 05:08:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.97 on epoch=29
06/08/2022 05:08:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=32
06/08/2022 05:08:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.91 on epoch=34
06/08/2022 05:09:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.81 on epoch=37
06/08/2022 05:09:01 - INFO - __main__ - Global step 150 Train loss 0.91 Classification-F1 0.09210526315789473 on epoch=37
06/08/2022 05:09:04 - INFO - __main__ - Step 160 Global step 160 Train loss 0.88 on epoch=39
06/08/2022 05:09:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=42
06/08/2022 05:09:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=44
06/08/2022 05:09:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.85 on epoch=47
06/08/2022 05:09:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.80 on epoch=49
06/08/2022 05:09:16 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.11805555555555555 on epoch=49
06/08/2022 05:09:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.11805555555555555 on epoch=49, global_step=200
06/08/2022 05:09:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=52
06/08/2022 05:09:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=54
06/08/2022 05:09:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.84 on epoch=57
06/08/2022 05:09:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.89 on epoch=59
06/08/2022 05:09:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.86 on epoch=62
06/08/2022 05:09:32 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.12393162393162392 on epoch=62
06/08/2022 05:09:32 - INFO - __main__ - Saving model with best Classification-F1: 0.11805555555555555 -> 0.12393162393162392 on epoch=62, global_step=250
06/08/2022 05:09:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.92 on epoch=64
06/08/2022 05:09:37 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=67
06/08/2022 05:09:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.81 on epoch=69
06/08/2022 05:09:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=72
06/08/2022 05:09:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.81 on epoch=74
06/08/2022 05:09:47 - INFO - __main__ - Global step 300 Train loss 0.83 Classification-F1 0.2965466032369302 on epoch=74
06/08/2022 05:09:47 - INFO - __main__ - Saving model with best Classification-F1: 0.12393162393162392 -> 0.2965466032369302 on epoch=74, global_step=300
06/08/2022 05:09:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=77
06/08/2022 05:09:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.84 on epoch=79
06/08/2022 05:09:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.73 on epoch=82
06/08/2022 05:09:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.75 on epoch=84
06/08/2022 05:10:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.75 on epoch=87
06/08/2022 05:10:02 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.22318840579710147 on epoch=87
06/08/2022 05:10:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.75 on epoch=89
06/08/2022 05:10:08 - INFO - __main__ - Step 370 Global step 370 Train loss 0.71 on epoch=92
06/08/2022 05:10:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.73 on epoch=94
06/08/2022 05:10:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.66 on epoch=97
06/08/2022 05:10:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.70 on epoch=99
06/08/2022 05:10:18 - INFO - __main__ - Global step 400 Train loss 0.71 Classification-F1 0.23607843137254902 on epoch=99
06/08/2022 05:10:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.74 on epoch=102
06/08/2022 05:10:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.66 on epoch=104
06/08/2022 05:10:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.71 on epoch=107
06/08/2022 05:10:29 - INFO - __main__ - Step 440 Global step 440 Train loss 0.64 on epoch=109
06/08/2022 05:10:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.67 on epoch=112
06/08/2022 05:10:33 - INFO - __main__ - Global step 450 Train loss 0.69 Classification-F1 0.26299533799533803 on epoch=112
06/08/2022 05:10:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.65 on epoch=114
06/08/2022 05:10:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.59 on epoch=117
06/08/2022 05:10:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.65 on epoch=119
06/08/2022 05:10:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.64 on epoch=122
06/08/2022 05:10:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=124
06/08/2022 05:10:47 - INFO - __main__ - Global step 500 Train loss 0.63 Classification-F1 0.37275862068965515 on epoch=124
06/08/2022 05:10:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2965466032369302 -> 0.37275862068965515 on epoch=124, global_step=500
06/08/2022 05:10:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.61 on epoch=127
06/08/2022 05:10:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.49 on epoch=129
06/08/2022 05:10:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.58 on epoch=132
06/08/2022 05:10:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.55 on epoch=134
06/08/2022 05:11:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.52 on epoch=137
06/08/2022 05:11:02 - INFO - __main__ - Global step 550 Train loss 0.55 Classification-F1 0.3748168498168498 on epoch=137
06/08/2022 05:11:02 - INFO - __main__ - Saving model with best Classification-F1: 0.37275862068965515 -> 0.3748168498168498 on epoch=137, global_step=550
06/08/2022 05:11:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.55 on epoch=139
06/08/2022 05:11:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.50 on epoch=142
06/08/2022 05:11:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.59 on epoch=144
06/08/2022 05:11:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=147
06/08/2022 05:11:16 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=149
06/08/2022 05:11:17 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.46701597918989235 on epoch=149
06/08/2022 05:11:17 - INFO - __main__ - Saving model with best Classification-F1: 0.3748168498168498 -> 0.46701597918989235 on epoch=149, global_step=600
06/08/2022 05:11:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.41 on epoch=152
06/08/2022 05:11:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.48 on epoch=154
06/08/2022 05:11:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=157
06/08/2022 05:11:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.48 on epoch=159
06/08/2022 05:11:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.48 on epoch=162
06/08/2022 05:11:32 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.2893939393939394 on epoch=162
06/08/2022 05:11:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.51 on epoch=164
06/08/2022 05:11:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.51 on epoch=167
06/08/2022 05:11:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.50 on epoch=169
06/08/2022 05:11:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.47 on epoch=172
06/08/2022 05:11:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.47 on epoch=174
06/08/2022 05:11:47 - INFO - __main__ - Global step 700 Train loss 0.49 Classification-F1 0.42917138009049777 on epoch=174
06/08/2022 05:11:50 - INFO - __main__ - Step 710 Global step 710 Train loss 0.41 on epoch=177
06/08/2022 05:11:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.48 on epoch=179
06/08/2022 05:11:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.48 on epoch=182
06/08/2022 05:11:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=184
06/08/2022 05:12:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=187
06/08/2022 05:12:02 - INFO - __main__ - Global step 750 Train loss 0.44 Classification-F1 0.4342878174457122 on epoch=187
06/08/2022 05:12:05 - INFO - __main__ - Step 760 Global step 760 Train loss 0.42 on epoch=189
06/08/2022 05:12:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.41 on epoch=192
06/08/2022 05:12:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=194
06/08/2022 05:12:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.41 on epoch=197
06/08/2022 05:12:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.40 on epoch=199
06/08/2022 05:12:16 - INFO - __main__ - Global step 800 Train loss 0.41 Classification-F1 0.5286098310291858 on epoch=199
06/08/2022 05:12:16 - INFO - __main__ - Saving model with best Classification-F1: 0.46701597918989235 -> 0.5286098310291858 on epoch=199, global_step=800
06/08/2022 05:12:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.41 on epoch=202
06/08/2022 05:12:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=204
06/08/2022 05:12:25 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=207
06/08/2022 05:12:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=209
06/08/2022 05:12:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=212
06/08/2022 05:12:31 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.5491172248032005 on epoch=212
06/08/2022 05:12:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5286098310291858 -> 0.5491172248032005 on epoch=212, global_step=850
06/08/2022 05:12:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.28 on epoch=214
06/08/2022 05:12:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=217
06/08/2022 05:12:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.28 on epoch=219
06/08/2022 05:12:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=222
06/08/2022 05:12:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.24 on epoch=224
06/08/2022 05:12:46 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.6276069518716577 on epoch=224
06/08/2022 05:12:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5491172248032005 -> 0.6276069518716577 on epoch=224, global_step=900
06/08/2022 05:12:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=227
06/08/2022 05:12:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=229
06/08/2022 05:12:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=232
06/08/2022 05:12:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=234
06/08/2022 05:13:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=237
06/08/2022 05:13:02 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.6494824016563148 on epoch=237
06/08/2022 05:13:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6276069518716577 -> 0.6494824016563148 on epoch=237, global_step=950
06/08/2022 05:13:04 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=239
06/08/2022 05:13:07 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=242
06/08/2022 05:13:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=244
06/08/2022 05:13:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=247
06/08/2022 05:13:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=249
06/08/2022 05:13:17 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5511617458279846 on epoch=249
06/08/2022 05:13:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=252
06/08/2022 05:13:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=254
06/08/2022 05:13:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=257
06/08/2022 05:13:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=259
06/08/2022 05:13:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=262
06/08/2022 05:13:31 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.585887445887446 on epoch=262
06/08/2022 05:13:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=264
06/08/2022 05:13:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/08/2022 05:13:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/08/2022 05:13:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=272
06/08/2022 05:13:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=274
06/08/2022 05:13:45 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.5842638544251447 on epoch=274
06/08/2022 05:13:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=277
06/08/2022 05:13:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=279
06/08/2022 05:13:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/08/2022 05:13:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=284
06/08/2022 05:13:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/08/2022 05:14:00 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.5926428891946133 on epoch=287
06/08/2022 05:14:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=289
06/08/2022 05:14:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=292
06/08/2022 05:14:08 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=294
06/08/2022 05:14:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=297
06/08/2022 05:14:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=299
06/08/2022 05:14:14 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.5578609986504722 on epoch=299
06/08/2022 05:14:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=302
06/08/2022 05:14:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/08/2022 05:14:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/08/2022 05:14:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=309
06/08/2022 05:14:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=312
06/08/2022 05:14:29 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6013392857142857 on epoch=312
06/08/2022 05:14:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=314
06/08/2022 05:14:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/08/2022 05:14:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=319
06/08/2022 05:14:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/08/2022 05:14:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 05:14:44 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6072148617511521 on epoch=324
06/08/2022 05:14:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/08/2022 05:14:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/08/2022 05:14:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/08/2022 05:14:55 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/08/2022 05:14:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 05:14:59 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6181107794011019 on epoch=337
06/08/2022 05:15:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/08/2022 05:15:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=342
06/08/2022 05:15:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/08/2022 05:15:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/08/2022 05:15:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=349
06/08/2022 05:15:13 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.6185074755855156 on epoch=349
06/08/2022 05:15:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/08/2022 05:15:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/08/2022 05:15:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=357
06/08/2022 05:15:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/08/2022 05:15:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/08/2022 05:15:28 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.6242830086580087 on epoch=362
06/08/2022 05:15:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=364
06/08/2022 05:15:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=367
06/08/2022 05:15:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=369
06/08/2022 05:15:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/08/2022 05:15:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=374
06/08/2022 05:15:42 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5931306306306307 on epoch=374
06/08/2022 05:15:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=377
06/08/2022 05:15:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=379
06/08/2022 05:15:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=382
06/08/2022 05:15:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=384
06/08/2022 05:15:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 05:15:58 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6235926628716002 on epoch=387
06/08/2022 05:16:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/08/2022 05:16:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/08/2022 05:16:06 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 05:16:09 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=397
06/08/2022 05:16:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/08/2022 05:16:12 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.6220555953418857 on epoch=399
06/08/2022 05:16:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 05:16:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=404
06/08/2022 05:16:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/08/2022 05:16:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/08/2022 05:16:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 05:16:27 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.609969229880242 on epoch=412
06/08/2022 05:16:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=414
06/08/2022 05:16:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 05:16:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=419
06/08/2022 05:16:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=422
06/08/2022 05:16:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/08/2022 05:16:42 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5570512820512821 on epoch=424
06/08/2022 05:16:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=427
06/08/2022 05:16:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/08/2022 05:16:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=432
06/08/2022 05:16:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/08/2022 05:16:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/08/2022 05:16:57 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6226420559881349 on epoch=437
06/08/2022 05:17:00 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=439
06/08/2022 05:17:03 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/08/2022 05:17:05 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 05:17:08 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 05:17:11 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 05:17:12 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6089324618736384 on epoch=449
06/08/2022 05:17:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 05:17:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/08/2022 05:17:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=457
06/08/2022 05:17:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=459
06/08/2022 05:17:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=462
06/08/2022 05:17:27 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6069346275999502 on epoch=462
06/08/2022 05:17:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 05:17:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/08/2022 05:17:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 05:17:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/08/2022 05:17:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/08/2022 05:17:41 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6063988095238095 on epoch=474
06/08/2022 05:17:44 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=477
06/08/2022 05:17:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=479
06/08/2022 05:17:49 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/08/2022 05:17:52 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/08/2022 05:17:55 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=487
06/08/2022 05:17:56 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5822091994692614 on epoch=487
06/08/2022 05:17:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/08/2022 05:18:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 05:18:04 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/08/2022 05:18:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 05:18:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/08/2022 05:18:11 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6314903846153846 on epoch=499
06/08/2022 05:18:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 05:18:16 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/08/2022 05:18:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/08/2022 05:18:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=509
06/08/2022 05:18:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=512
06/08/2022 05:18:26 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.5777458492975733 on epoch=512
06/08/2022 05:18:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=514
06/08/2022 05:18:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/08/2022 05:18:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 05:18:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=522
06/08/2022 05:18:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 05:18:41 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6037872458925091 on epoch=524
06/08/2022 05:18:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/08/2022 05:18:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=529
06/08/2022 05:18:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=532
06/08/2022 05:18:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 05:18:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/08/2022 05:18:55 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.616457586618877 on epoch=537
06/08/2022 05:18:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/08/2022 05:19:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/08/2022 05:19:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=544
06/08/2022 05:19:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/08/2022 05:19:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 05:19:10 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5629551820728291 on epoch=549
06/08/2022 05:19:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=552
06/08/2022 05:19:16 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/08/2022 05:19:19 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 05:19:21 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 05:19:24 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/08/2022 05:19:25 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6080932580932581 on epoch=562
06/08/2022 05:19:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 05:19:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=567
06/08/2022 05:19:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/08/2022 05:19:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 05:19:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 05:19:40 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6016279190721381 on epoch=574
06/08/2022 05:19:43 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 05:19:46 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=579
06/08/2022 05:19:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/08/2022 05:19:51 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 05:19:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/08/2022 05:19:55 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.624869383490073 on epoch=587
06/08/2022 05:19:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/08/2022 05:20:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 05:20:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 05:20:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/08/2022 05:20:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/08/2022 05:20:10 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.651376424933301 on epoch=599
06/08/2022 05:20:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6494824016563148 -> 0.651376424933301 on epoch=599, global_step=2400
06/08/2022 05:20:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 05:20:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 05:20:18 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 05:20:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 05:20:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 05:20:25 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6378472222222222 on epoch=612
06/08/2022 05:20:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/08/2022 05:20:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 05:20:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=619
06/08/2022 05:20:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 05:20:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/08/2022 05:20:40 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6169070512820513 on epoch=624
06/08/2022 05:20:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=627
06/08/2022 05:20:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 05:20:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 05:20:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 05:20:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=637
06/08/2022 05:20:55 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6088867805186591 on epoch=637
06/08/2022 05:20:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=639
06/08/2022 05:21:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 05:21:03 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/08/2022 05:21:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 05:21:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 05:21:09 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6198840294335116 on epoch=649
06/08/2022 05:21:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=652
06/08/2022 05:21:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/08/2022 05:21:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/08/2022 05:21:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 05:21:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 05:21:24 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.5679021271126534 on epoch=662
06/08/2022 05:21:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 05:21:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 05:21:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/08/2022 05:21:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 05:21:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/08/2022 05:21:39 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6184099684099684 on epoch=674
06/08/2022 05:21:42 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=677
06/08/2022 05:21:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 05:21:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/08/2022 05:21:50 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=684
06/08/2022 05:21:53 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 05:21:54 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6011514347721244 on epoch=687
06/08/2022 05:21:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 05:22:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 05:22:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 05:22:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=697
06/08/2022 05:22:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=699
06/08/2022 05:22:09 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6011514347721244 on epoch=699
06/08/2022 05:22:12 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 05:22:14 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 05:22:17 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 05:22:20 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=709
06/08/2022 05:22:22 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=712
06/08/2022 05:22:24 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6321960297766749 on epoch=712
06/08/2022 05:22:26 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 05:22:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 05:22:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=719
06/08/2022 05:22:34 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=722
06/08/2022 05:22:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 05:22:38 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.5755534471853258 on epoch=724
06/08/2022 05:22:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 05:22:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=729
06/08/2022 05:22:46 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 05:22:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 05:22:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=737
06/08/2022 05:22:53 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6346841836274539 on epoch=737
06/08/2022 05:22:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 05:22:59 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 05:23:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=744
06/08/2022 05:23:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=747
06/08/2022 05:23:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/08/2022 05:23:08 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6011514347721244 on epoch=749
06/08/2022 05:23:08 - INFO - __main__ - save last model!
06/08/2022 05:23:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:23:08 - INFO - __main__ - Printing 3 examples
06/08/2022 05:23:08 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:23:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 05:23:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 05:23:08 - INFO - __main__ - Printing 3 examples
06/08/2022 05:23:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 05:23:08 - INFO - __main__ - ['others']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 05:23:08 - INFO - __main__ - ['others']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 05:23:08 - INFO - __main__ - ['others']
06/08/2022 05:23:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:23:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:23:08 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:23:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:23:08 - INFO - __main__ - Printing 3 examples
06/08/2022 05:23:08 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 05:23:08 - INFO - __main__ - ['sad']
06/08/2022 05:23:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:23:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:23:08 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:23:11 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:23:17 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 05:23:24 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:23:24 - INFO - __main__ - task name: emo
06/08/2022 05:23:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:23:25 - INFO - __main__ - Starting training!
06/08/2022 05:25:05 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_13_0.2_8_predictions.txt
06/08/2022 05:25:05 - INFO - __main__ - Classification-F1 on test data: 0.3546
06/08/2022 05:25:05 - INFO - __main__ - prefix=emo_16_13, lr=0.2, bsz=8, dev_performance=0.651376424933301, test_performance=0.35456168411450456
06/08/2022 05:25:05 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.5, bsz=8 ...
06/08/2022 05:25:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:25:06 - INFO - __main__ - Printing 3 examples
06/08/2022 05:25:06 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:25:06 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:25:06 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:25:06 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:25:06 - INFO - __main__ - Printing 3 examples
06/08/2022 05:25:06 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 05:25:06 - INFO - __main__ - ['sad']
06/08/2022 05:25:06 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:25:06 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:25:06 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:25:25 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:25:25 - INFO - __main__ - task name: emo
06/08/2022 05:25:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:25:26 - INFO - __main__ - Starting training!
06/08/2022 05:25:29 - INFO - __main__ - Step 10 Global step 10 Train loss 5.73 on epoch=2
06/08/2022 05:25:32 - INFO - __main__ - Step 20 Global step 20 Train loss 2.07 on epoch=4
06/08/2022 05:25:35 - INFO - __main__ - Step 30 Global step 30 Train loss 1.25 on epoch=7
06/08/2022 05:25:38 - INFO - __main__ - Step 40 Global step 40 Train loss 1.18 on epoch=9
06/08/2022 05:25:41 - INFO - __main__ - Step 50 Global step 50 Train loss 1.12 on epoch=12
06/08/2022 05:25:42 - INFO - __main__ - Global step 50 Train loss 2.27 Classification-F1 0.1 on epoch=12
06/08/2022 05:25:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 05:25:45 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=14
06/08/2022 05:25:47 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/08/2022 05:25:50 - INFO - __main__ - Step 80 Global step 80 Train loss 0.94 on epoch=19
06/08/2022 05:25:53 - INFO - __main__ - Step 90 Global step 90 Train loss 0.97 on epoch=22
06/08/2022 05:25:56 - INFO - __main__ - Step 100 Global step 100 Train loss 0.79 on epoch=24
06/08/2022 05:25:57 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.17220843672456576 on epoch=24
06/08/2022 05:25:57 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.17220843672456576 on epoch=24, global_step=100
06/08/2022 05:26:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=27
06/08/2022 05:26:03 - INFO - __main__ - Step 120 Global step 120 Train loss 0.87 on epoch=29
06/08/2022 05:26:05 - INFO - __main__ - Step 130 Global step 130 Train loss 0.79 on epoch=32
06/08/2022 05:26:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.88 on epoch=34
06/08/2022 05:26:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=37
06/08/2022 05:26:12 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.28100038963569063 on epoch=37
06/08/2022 05:26:12 - INFO - __main__ - Saving model with best Classification-F1: 0.17220843672456576 -> 0.28100038963569063 on epoch=37, global_step=150
06/08/2022 05:26:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.77 on epoch=39
06/08/2022 05:26:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=42
06/08/2022 05:26:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=44
06/08/2022 05:26:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=47
06/08/2022 05:26:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=49
06/08/2022 05:26:27 - INFO - __main__ - Global step 200 Train loss 0.74 Classification-F1 0.3500089509488006 on epoch=49
06/08/2022 05:26:27 - INFO - __main__ - Saving model with best Classification-F1: 0.28100038963569063 -> 0.3500089509488006 on epoch=49, global_step=200
06/08/2022 05:26:30 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/08/2022 05:26:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=54
06/08/2022 05:26:36 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=57
06/08/2022 05:26:39 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=59
06/08/2022 05:26:41 - INFO - __main__ - Step 250 Global step 250 Train loss 0.37 on epoch=62
06/08/2022 05:26:43 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.4408168642951251 on epoch=62
06/08/2022 05:26:43 - INFO - __main__ - Saving model with best Classification-F1: 0.3500089509488006 -> 0.4408168642951251 on epoch=62, global_step=250
06/08/2022 05:26:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/08/2022 05:26:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=67
06/08/2022 05:26:51 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/08/2022 05:26:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.17 on epoch=72
06/08/2022 05:26:57 - INFO - __main__ - Step 300 Global step 300 Train loss 0.23 on epoch=74
06/08/2022 05:26:58 - INFO - __main__ - Global step 300 Train loss 0.28 Classification-F1 0.6153835386338186 on epoch=74
06/08/2022 05:26:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4408168642951251 -> 0.6153835386338186 on epoch=74, global_step=300
06/08/2022 05:27:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.11 on epoch=77
06/08/2022 05:27:03 - INFO - __main__ - Step 320 Global step 320 Train loss 0.14 on epoch=79
06/08/2022 05:27:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.06 on epoch=82
06/08/2022 05:27:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.07 on epoch=84
06/08/2022 05:27:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.05 on epoch=87
06/08/2022 05:27:13 - INFO - __main__ - Global step 350 Train loss 0.09 Classification-F1 0.637206073496396 on epoch=87
06/08/2022 05:27:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6153835386338186 -> 0.637206073496396 on epoch=87, global_step=350
06/08/2022 05:27:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.06 on epoch=89
06/08/2022 05:27:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.13 on epoch=92
06/08/2022 05:27:21 - INFO - __main__ - Step 380 Global step 380 Train loss 0.06 on epoch=94
06/08/2022 05:27:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.09 on epoch=97
06/08/2022 05:27:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.04 on epoch=99
06/08/2022 05:27:28 - INFO - __main__ - Global step 400 Train loss 0.08 Classification-F1 0.6638548209006614 on epoch=99
06/08/2022 05:27:28 - INFO - __main__ - Saving model with best Classification-F1: 0.637206073496396 -> 0.6638548209006614 on epoch=99, global_step=400
06/08/2022 05:27:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.03 on epoch=102
06/08/2022 05:27:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=104
06/08/2022 05:27:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.05 on epoch=107
06/08/2022 05:27:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.09 on epoch=109
06/08/2022 05:27:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.05 on epoch=112
06/08/2022 05:27:43 - INFO - __main__ - Global step 450 Train loss 0.05 Classification-F1 0.7111984548266408 on epoch=112
06/08/2022 05:27:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6638548209006614 -> 0.7111984548266408 on epoch=112, global_step=450
06/08/2022 05:27:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.02 on epoch=114
06/08/2022 05:27:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.01 on epoch=117
06/08/2022 05:27:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.07 on epoch=119
06/08/2022 05:27:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.05 on epoch=122
06/08/2022 05:27:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.09 on epoch=124
06/08/2022 05:27:58 - INFO - __main__ - Global step 500 Train loss 0.05 Classification-F1 0.7348635434720749 on epoch=124
06/08/2022 05:27:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7111984548266408 -> 0.7348635434720749 on epoch=124, global_step=500
06/08/2022 05:28:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/08/2022 05:28:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.03 on epoch=129
06/08/2022 05:28:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.03 on epoch=132
06/08/2022 05:28:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.03 on epoch=134
06/08/2022 05:28:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.05 on epoch=137
06/08/2022 05:28:14 - INFO - __main__ - Global step 550 Train loss 0.04 Classification-F1 0.7079492336237836 on epoch=137
06/08/2022 05:28:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=139
06/08/2022 05:28:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=142
06/08/2022 05:28:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=144
06/08/2022 05:28:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=147
06/08/2022 05:28:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.10 on epoch=149
06/08/2022 05:28:29 - INFO - __main__ - Global step 600 Train loss 0.03 Classification-F1 0.6601033166889945 on epoch=149
06/08/2022 05:28:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.06 on epoch=152
06/08/2022 05:28:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.04 on epoch=154
06/08/2022 05:28:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=157
06/08/2022 05:28:40 - INFO - __main__ - Step 640 Global step 640 Train loss 0.08 on epoch=159
06/08/2022 05:28:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.05 on epoch=162
06/08/2022 05:28:44 - INFO - __main__ - Global step 650 Train loss 0.05 Classification-F1 0.7400831926693996 on epoch=162
06/08/2022 05:28:44 - INFO - __main__ - Saving model with best Classification-F1: 0.7348635434720749 -> 0.7400831926693996 on epoch=162, global_step=650
06/08/2022 05:28:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
06/08/2022 05:28:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.01 on epoch=167
06/08/2022 05:28:52 - INFO - __main__ - Step 680 Global step 680 Train loss 0.02 on epoch=169
06/08/2022 05:28:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/08/2022 05:28:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.04 on epoch=174
06/08/2022 05:28:59 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.7344186046511628 on epoch=174
06/08/2022 05:29:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.01 on epoch=177
06/08/2022 05:29:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=179
06/08/2022 05:29:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.00 on epoch=182
06/08/2022 05:29:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/08/2022 05:29:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.00 on epoch=187
06/08/2022 05:29:15 - INFO - __main__ - Global step 750 Train loss 0.00 Classification-F1 0.7186638826686033 on epoch=187
06/08/2022 05:29:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/08/2022 05:29:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/08/2022 05:29:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.02 on epoch=194
06/08/2022 05:29:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=197
06/08/2022 05:29:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=199
06/08/2022 05:29:30 - INFO - __main__ - Global step 800 Train loss 0.01 Classification-F1 0.6943053197509904 on epoch=199
06/08/2022 05:29:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.00 on epoch=202
06/08/2022 05:29:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.00 on epoch=204
06/08/2022 05:29:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=207
06/08/2022 05:29:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/08/2022 05:29:44 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/08/2022 05:29:46 - INFO - __main__ - Global step 850 Train loss 0.01 Classification-F1 0.6305825917686319 on epoch=212
06/08/2022 05:29:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=214
06/08/2022 05:29:51 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=217
06/08/2022 05:29:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/08/2022 05:29:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/08/2022 05:30:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/08/2022 05:30:01 - INFO - __main__ - Global step 900 Train loss 0.00 Classification-F1 0.7126574500768049 on epoch=224
06/08/2022 05:30:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.00 on epoch=227
06/08/2022 05:30:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/08/2022 05:30:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/08/2022 05:30:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/08/2022 05:30:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=237
06/08/2022 05:30:16 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.7321774193548387 on epoch=237
06/08/2022 05:30:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/08/2022 05:30:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/08/2022 05:30:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/08/2022 05:30:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/08/2022 05:30:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.00 on epoch=249
06/08/2022 05:30:32 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.6594742063492064 on epoch=249
06/08/2022 05:30:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/08/2022 05:30:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/08/2022 05:30:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.01 on epoch=257
06/08/2022 05:30:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/08/2022 05:30:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 05:30:47 - INFO - __main__ - Global step 1050 Train loss 0.02 Classification-F1 0.6949155145929339 on epoch=262
06/08/2022 05:30:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 05:30:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/08/2022 05:30:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/08/2022 05:30:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 05:31:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.00 on epoch=274
06/08/2022 05:31:02 - INFO - __main__ - Global step 1100 Train loss 0.00 Classification-F1 0.6816911779539632 on epoch=274
06/08/2022 05:31:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 05:31:07 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/08/2022 05:31:10 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 05:31:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 05:31:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 05:31:17 - INFO - __main__ - Global step 1150 Train loss 0.00 Classification-F1 0.6943053197509904 on epoch=287
06/08/2022 05:31:20 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/08/2022 05:31:22 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 05:31:25 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/08/2022 05:31:28 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 05:31:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 05:31:32 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.6785304659498207 on epoch=299
06/08/2022 05:31:35 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/08/2022 05:31:38 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 05:31:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 05:31:43 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 05:31:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 05:31:47 - INFO - __main__ - Global step 1250 Train loss 0.00 Classification-F1 0.7192357980602229 on epoch=312
06/08/2022 05:31:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 05:31:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=317
06/08/2022 05:31:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 05:31:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/08/2022 05:32:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 05:32:03 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7131170691359519 on epoch=324
06/08/2022 05:32:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 05:32:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/08/2022 05:32:11 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 05:32:14 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/08/2022 05:32:16 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 05:32:18 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7093045174403356 on epoch=337
06/08/2022 05:32:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 05:32:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 05:32:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 05:32:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/08/2022 05:32:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/08/2022 05:32:33 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6943053197509904 on epoch=349
06/08/2022 05:32:36 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 05:32:38 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 05:32:41 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 05:32:44 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 05:32:47 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 05:32:48 - INFO - __main__ - Global step 1450 Train loss 0.00 Classification-F1 0.7187723365208153 on epoch=362
06/08/2022 05:32:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 05:32:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=367
06/08/2022 05:32:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 05:32:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 05:33:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 05:33:03 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.7033316430020284 on epoch=374
06/08/2022 05:33:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 05:33:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 05:33:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 05:33:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 05:33:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 05:33:18 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7313516009852217 on epoch=387
06/08/2022 05:33:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 05:33:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 05:33:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 05:33:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 05:33:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 05:33:34 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.7482371794871795 on epoch=399
06/08/2022 05:33:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7400831926693996 -> 0.7482371794871795 on epoch=399, global_step=1600
06/08/2022 05:33:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 05:33:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 05:33:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 05:33:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 05:33:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 05:33:49 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.7033259552656105 on epoch=412
06/08/2022 05:33:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 05:33:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 05:33:57 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 05:34:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 05:34:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 05:34:04 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.7700784528370734 on epoch=424
06/08/2022 05:34:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7482371794871795 -> 0.7700784528370734 on epoch=424, global_step=1700
06/08/2022 05:34:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 05:34:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 05:34:12 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 05:34:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 05:34:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 05:34:19 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.7029197454844007 on epoch=437
06/08/2022 05:34:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 05:34:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 05:34:27 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 05:34:30 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 05:34:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 05:34:34 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6364583333333333 on epoch=449
06/08/2022 05:34:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 05:34:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 05:34:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 05:34:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 05:34:48 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/08/2022 05:34:49 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.6689935064935065 on epoch=462
06/08/2022 05:34:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=464
06/08/2022 05:34:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 05:34:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/08/2022 05:35:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 05:35:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 05:35:04 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.7326121794871795 on epoch=474
06/08/2022 05:35:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 05:35:10 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 05:35:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 05:35:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 05:35:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 05:35:20 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.7441733870967743 on epoch=487
06/08/2022 05:35:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 05:35:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 05:35:28 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 05:35:31 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 05:35:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 05:35:35 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.7100453705055224 on epoch=499
06/08/2022 05:35:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 05:35:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 05:35:43 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 05:35:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 05:35:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 05:35:50 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.7001133400233176 on epoch=512
06/08/2022 05:35:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 05:35:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 05:35:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 05:36:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 05:36:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 05:36:05 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6731265188711998 on epoch=524
06/08/2022 05:36:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 05:36:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/08/2022 05:36:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 05:36:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 05:36:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/08/2022 05:36:20 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6805912679860786 on epoch=537
06/08/2022 05:36:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 05:36:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 05:36:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 05:36:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 05:36:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 05:36:35 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.7001133400233176 on epoch=549
06/08/2022 05:36:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 05:36:40 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 05:36:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 05:36:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 05:36:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 05:36:50 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.7215821812596006 on epoch=562
06/08/2022 05:36:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 05:36:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 05:36:58 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 05:37:01 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 05:37:04 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 05:37:05 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.701020622895623 on epoch=574
06/08/2022 05:37:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 05:37:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 05:37:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 05:37:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 05:37:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 05:37:20 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6660579528872212 on epoch=587
06/08/2022 05:37:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 05:37:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 05:37:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 05:37:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=597
06/08/2022 05:37:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 05:37:35 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6928030303030304 on epoch=599
06/08/2022 05:37:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 05:37:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 05:37:43 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 05:37:46 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 05:37:49 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 05:37:50 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6823644338118022 on epoch=612
06/08/2022 05:37:53 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 05:37:56 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 05:37:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 05:38:01 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 05:38:04 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 05:38:06 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6881791786025658 on epoch=624
06/08/2022 05:38:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 05:38:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 05:38:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 05:38:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 05:38:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 05:38:21 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6816946329813977 on epoch=637
06/08/2022 05:38:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 05:38:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 05:38:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 05:38:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 05:38:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 05:38:37 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7259375819564647 on epoch=649
06/08/2022 05:38:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 05:38:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 05:38:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 05:38:48 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 05:38:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 05:38:52 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7153030303030303 on epoch=662
06/08/2022 05:38:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 05:38:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 05:39:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 05:39:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 05:39:06 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 05:39:07 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.7313516009852217 on epoch=674
06/08/2022 05:39:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 05:39:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 05:39:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 05:39:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 05:39:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 05:39:22 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6615306080356406 on epoch=687
06/08/2022 05:39:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 05:39:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 05:39:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 05:39:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 05:39:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 05:39:37 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7399804496578691 on epoch=699
06/08/2022 05:39:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 05:39:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 05:39:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 05:39:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 05:39:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 05:39:52 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7441733870967743 on epoch=712
06/08/2022 05:39:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 05:39:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=717
06/08/2022 05:40:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 05:40:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=722
06/08/2022 05:40:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 05:40:07 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.777876293651274 on epoch=724
06/08/2022 05:40:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7700784528370734 -> 0.777876293651274 on epoch=724, global_step=2900
06/08/2022 05:40:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 05:40:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 05:40:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 05:40:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 05:40:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 05:40:23 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.777876293651274 on epoch=737
06/08/2022 05:40:25 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 05:40:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 05:40:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 05:40:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 05:40:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 05:40:37 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:40:37 - INFO - __main__ - Printing 3 examples
06/08/2022 05:40:37 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 05:40:37 - INFO - __main__ - ['sad']
06/08/2022 05:40:37 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 05:40:37 - INFO - __main__ - ['sad']
06/08/2022 05:40:37 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 05:40:37 - INFO - __main__ - ['sad']
06/08/2022 05:40:37 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:40:38 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:40:38 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:40:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:40:38 - INFO - __main__ - Printing 3 examples
06/08/2022 05:40:38 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 05:40:38 - INFO - __main__ - ['sad']
06/08/2022 05:40:38 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 05:40:38 - INFO - __main__ - ['sad']
06/08/2022 05:40:38 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 05:40:38 - INFO - __main__ - ['sad']
06/08/2022 05:40:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:40:38 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:40:38 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:40:38 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7246600173750335 on epoch=749
06/08/2022 05:40:38 - INFO - __main__ - save last model!
06/08/2022 05:40:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 05:40:38 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 05:40:38 - INFO - __main__ - Printing 3 examples
06/08/2022 05:40:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 05:40:38 - INFO - __main__ - ['others']
06/08/2022 05:40:38 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 05:40:38 - INFO - __main__ - ['others']
06/08/2022 05:40:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 05:40:38 - INFO - __main__ - ['others']
06/08/2022 05:40:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:40:40 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:40:46 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 05:40:56 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:40:56 - INFO - __main__ - task name: emo
06/08/2022 05:40:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:40:56 - INFO - __main__ - Starting training!
06/08/2022 05:42:40 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_21_0.5_8_predictions.txt
06/08/2022 05:42:40 - INFO - __main__ - Classification-F1 on test data: 0.4148
06/08/2022 05:42:41 - INFO - __main__ - prefix=emo_16_21, lr=0.5, bsz=8, dev_performance=0.777876293651274, test_performance=0.4148258442129409
06/08/2022 05:42:41 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.4, bsz=8 ...
06/08/2022 05:42:41 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:42:41 - INFO - __main__ - Printing 3 examples
06/08/2022 05:42:41 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 05:42:41 - INFO - __main__ - ['sad']
06/08/2022 05:42:41 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 05:42:41 - INFO - __main__ - ['sad']
06/08/2022 05:42:41 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 05:42:41 - INFO - __main__ - ['sad']
06/08/2022 05:42:41 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:42:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:42:42 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:42:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:42:42 - INFO - __main__ - Printing 3 examples
06/08/2022 05:42:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 05:42:42 - INFO - __main__ - ['sad']
06/08/2022 05:42:42 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 05:42:42 - INFO - __main__ - ['sad']
06/08/2022 05:42:42 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 05:42:42 - INFO - __main__ - ['sad']
06/08/2022 05:42:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:42:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:42:42 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:42:57 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:42:57 - INFO - __main__ - task name: emo
06/08/2022 05:42:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:42:58 - INFO - __main__ - Starting training!
06/08/2022 05:43:01 - INFO - __main__ - Step 10 Global step 10 Train loss 6.20 on epoch=2
06/08/2022 05:43:04 - INFO - __main__ - Step 20 Global step 20 Train loss 2.56 on epoch=4
06/08/2022 05:43:06 - INFO - __main__ - Step 30 Global step 30 Train loss 1.43 on epoch=7
06/08/2022 05:43:09 - INFO - __main__ - Step 40 Global step 40 Train loss 1.23 on epoch=9
06/08/2022 05:43:12 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=12
06/08/2022 05:43:13 - INFO - __main__ - Global step 50 Train loss 2.50 Classification-F1 0.1 on epoch=12
06/08/2022 05:43:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 05:43:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.05 on epoch=14
06/08/2022 05:43:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.05 on epoch=17
06/08/2022 05:43:21 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/08/2022 05:43:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.02 on epoch=22
06/08/2022 05:43:26 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/08/2022 05:43:27 - INFO - __main__ - Global step 100 Train loss 1.00 Classification-F1 0.10126582278481013 on epoch=24
06/08/2022 05:43:27 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10126582278481013 on epoch=24, global_step=100
06/08/2022 05:43:30 - INFO - __main__ - Step 110 Global step 110 Train loss 0.97 on epoch=27
06/08/2022 05:43:32 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=29
06/08/2022 05:43:35 - INFO - __main__ - Step 130 Global step 130 Train loss 0.92 on epoch=32
06/08/2022 05:43:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=34
06/08/2022 05:43:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.98 on epoch=37
06/08/2022 05:43:41 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.1 on epoch=37
06/08/2022 05:43:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=39
06/08/2022 05:43:47 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=42
06/08/2022 05:43:49 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=44
06/08/2022 05:43:52 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=47
06/08/2022 05:43:55 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=49
06/08/2022 05:43:56 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.13026315789473686 on epoch=49
06/08/2022 05:43:56 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.13026315789473686 on epoch=49, global_step=200
06/08/2022 05:43:58 - INFO - __main__ - Step 210 Global step 210 Train loss 0.93 on epoch=52
06/08/2022 05:44:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.91 on epoch=54
06/08/2022 05:44:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.81 on epoch=57
06/08/2022 05:44:06 - INFO - __main__ - Step 240 Global step 240 Train loss 0.90 on epoch=59
06/08/2022 05:44:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=62
06/08/2022 05:44:10 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.1 on epoch=62
06/08/2022 05:44:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.90 on epoch=64
06/08/2022 05:44:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=67
06/08/2022 05:44:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.88 on epoch=69
06/08/2022 05:44:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.89 on epoch=72
06/08/2022 05:44:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=74
06/08/2022 05:44:24 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.13197586726998492 on epoch=74
06/08/2022 05:44:24 - INFO - __main__ - Saving model with best Classification-F1: 0.13026315789473686 -> 0.13197586726998492 on epoch=74, global_step=300
06/08/2022 05:44:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.83 on epoch=77
06/08/2022 05:44:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.73 on epoch=79
06/08/2022 05:44:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.80 on epoch=82
06/08/2022 05:44:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.76 on epoch=84
06/08/2022 05:44:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.79 on epoch=87
06/08/2022 05:44:39 - INFO - __main__ - Global step 350 Train loss 0.78 Classification-F1 0.3473462301587301 on epoch=87
06/08/2022 05:44:39 - INFO - __main__ - Saving model with best Classification-F1: 0.13197586726998492 -> 0.3473462301587301 on epoch=87, global_step=350
06/08/2022 05:44:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.64 on epoch=89
06/08/2022 05:44:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=92
06/08/2022 05:44:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=94
06/08/2022 05:44:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=97
06/08/2022 05:44:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=99
06/08/2022 05:44:53 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.48803130186243776 on epoch=99
06/08/2022 05:44:53 - INFO - __main__ - Saving model with best Classification-F1: 0.3473462301587301 -> 0.48803130186243776 on epoch=99, global_step=400
06/08/2022 05:44:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=102
06/08/2022 05:44:58 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=104
06/08/2022 05:45:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.32 on epoch=107
06/08/2022 05:45:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=109
06/08/2022 05:45:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=112
06/08/2022 05:45:07 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.5099290244639081 on epoch=112
06/08/2022 05:45:07 - INFO - __main__ - Saving model with best Classification-F1: 0.48803130186243776 -> 0.5099290244639081 on epoch=112, global_step=450
06/08/2022 05:45:10 - INFO - __main__ - Step 460 Global step 460 Train loss 0.25 on epoch=114
06/08/2022 05:45:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.14 on epoch=117
06/08/2022 05:45:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.19 on epoch=119
06/08/2022 05:45:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.16 on epoch=122
06/08/2022 05:45:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.14 on epoch=124
06/08/2022 05:45:22 - INFO - __main__ - Global step 500 Train loss 0.18 Classification-F1 0.6280701754385964 on epoch=124
06/08/2022 05:45:22 - INFO - __main__ - Saving model with best Classification-F1: 0.5099290244639081 -> 0.6280701754385964 on epoch=124, global_step=500
06/08/2022 05:45:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.07 on epoch=127
06/08/2022 05:45:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/08/2022 05:45:30 - INFO - __main__ - Step 530 Global step 530 Train loss 0.11 on epoch=132
06/08/2022 05:45:33 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=134
06/08/2022 05:45:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.07 on epoch=137
06/08/2022 05:45:37 - INFO - __main__ - Global step 550 Train loss 0.11 Classification-F1 0.6530501089324618 on epoch=137
06/08/2022 05:45:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6280701754385964 -> 0.6530501089324618 on epoch=137, global_step=550
06/08/2022 05:45:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=139
06/08/2022 05:45:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.09 on epoch=142
06/08/2022 05:45:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.04 on epoch=144
06/08/2022 05:45:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.04 on epoch=147
06/08/2022 05:45:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.05 on epoch=149
06/08/2022 05:45:52 - INFO - __main__ - Global step 600 Train loss 0.05 Classification-F1 0.5635988289457422 on epoch=149
06/08/2022 05:45:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.11 on epoch=152
06/08/2022 05:45:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.07 on epoch=154
06/08/2022 05:46:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.03 on epoch=157
06/08/2022 05:46:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.09 on epoch=159
06/08/2022 05:46:07 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/08/2022 05:46:08 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.6379310344827587 on epoch=162
06/08/2022 05:46:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.02 on epoch=164
06/08/2022 05:46:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.02 on epoch=167
06/08/2022 05:46:16 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/08/2022 05:46:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/08/2022 05:46:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/08/2022 05:46:23 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.6713394994644994 on epoch=174
06/08/2022 05:46:23 - INFO - __main__ - Saving model with best Classification-F1: 0.6530501089324618 -> 0.6713394994644994 on epoch=174, global_step=700
06/08/2022 05:46:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/08/2022 05:46:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/08/2022 05:46:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/08/2022 05:46:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/08/2022 05:46:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.02 on epoch=187
06/08/2022 05:46:38 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.6068181818181817 on epoch=187
06/08/2022 05:46:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/08/2022 05:46:44 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=192
06/08/2022 05:46:47 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/08/2022 05:46:50 - INFO - __main__ - Step 790 Global step 790 Train loss 0.03 on epoch=197
06/08/2022 05:46:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/08/2022 05:46:54 - INFO - __main__ - Global step 800 Train loss 0.04 Classification-F1 0.6233206757400306 on epoch=199
06/08/2022 05:46:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/08/2022 05:47:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/08/2022 05:47:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/08/2022 05:47:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/08/2022 05:47:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/08/2022 05:47:09 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.6738584691170899 on epoch=212
06/08/2022 05:47:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6713394994644994 -> 0.6738584691170899 on epoch=212, global_step=850
06/08/2022 05:47:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=214
06/08/2022 05:47:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/08/2022 05:47:18 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 05:47:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/08/2022 05:47:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/08/2022 05:47:25 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.6555059523809523 on epoch=224
06/08/2022 05:47:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/08/2022 05:47:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/08/2022 05:47:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.00 on epoch=232
06/08/2022 05:47:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.00 on epoch=234
06/08/2022 05:47:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=237
06/08/2022 05:47:40 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.6530501089324618 on epoch=237
06/08/2022 05:47:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/08/2022 05:47:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/08/2022 05:47:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 05:47:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/08/2022 05:47:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/08/2022 05:47:56 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.648599831358452 on epoch=249
06/08/2022 05:47:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.00 on epoch=252
06/08/2022 05:48:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/08/2022 05:48:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/08/2022 05:48:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 05:48:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 05:48:11 - INFO - __main__ - Global step 1050 Train loss 0.00 Classification-F1 0.6245296098237275 on epoch=262
06/08/2022 05:48:14 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/08/2022 05:48:16 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.02 on epoch=267
06/08/2022 05:48:19 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 05:48:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.01 on epoch=272
06/08/2022 05:48:24 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 05:48:26 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6568287037037037 on epoch=274
06/08/2022 05:48:29 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/08/2022 05:48:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/08/2022 05:48:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 05:48:37 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 05:48:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 05:48:41 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6123949579831933 on epoch=287
06/08/2022 05:48:44 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/08/2022 05:48:47 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 05:48:49 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/08/2022 05:48:52 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 05:48:55 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 05:48:56 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.6374231950844853 on epoch=299
06/08/2022 05:48:59 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=302
06/08/2022 05:49:02 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 05:49:05 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/08/2022 05:49:07 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 05:49:10 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 05:49:12 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.6712825713839913 on epoch=312
06/08/2022 05:49:14 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 05:49:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 05:49:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 05:49:23 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/08/2022 05:49:26 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 05:49:27 - INFO - __main__ - Global step 1300 Train loss 0.00 Classification-F1 0.6882366625310173 on epoch=324
06/08/2022 05:49:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6738584691170899 -> 0.6882366625310173 on epoch=324, global_step=1300
06/08/2022 05:49:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 05:49:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/08/2022 05:49:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 05:49:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.01 on epoch=334
06/08/2022 05:49:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 05:49:43 - INFO - __main__ - Global step 1350 Train loss 0.00 Classification-F1 0.6994397759103641 on epoch=337
06/08/2022 05:49:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6882366625310173 -> 0.6994397759103641 on epoch=337, global_step=1350
06/08/2022 05:49:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 05:49:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 05:49:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 05:49:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 05:49:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 05:49:58 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.687049062049062 on epoch=349
06/08/2022 05:50:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 05:50:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/08/2022 05:50:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/08/2022 05:50:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 05:50:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 05:50:13 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6905443548387097 on epoch=362
06/08/2022 05:50:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/08/2022 05:50:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/08/2022 05:50:21 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 05:50:24 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/08/2022 05:50:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 05:50:28 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.6706209150326798 on epoch=374
06/08/2022 05:50:30 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 05:50:33 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 05:50:36 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 05:50:38 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 05:50:41 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 05:50:42 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.6693181818181818 on epoch=387
06/08/2022 05:50:45 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/08/2022 05:50:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 05:50:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 05:50:53 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 05:50:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 05:50:57 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6863026819923371 on epoch=399
06/08/2022 05:51:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 05:51:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 05:51:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=407
06/08/2022 05:51:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 05:51:11 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 05:51:12 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.6444742155949051 on epoch=412
06/08/2022 05:51:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 05:51:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 05:51:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 05:51:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 05:51:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=424
06/08/2022 05:51:27 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6289785921979587 on epoch=424
06/08/2022 05:51:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 05:51:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=429
06/08/2022 05:51:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 05:51:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 05:51:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 05:51:42 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6267538980933981 on epoch=437
06/08/2022 05:51:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 05:51:47 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 05:51:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 05:51:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 05:51:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 05:51:57 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6125544899738448 on epoch=449
06/08/2022 05:51:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 05:52:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 05:52:05 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 05:52:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 05:52:10 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 05:52:12 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.6293470368310469 on epoch=462
06/08/2022 05:52:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 05:52:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 05:52:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 05:52:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 05:52:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/08/2022 05:52:27 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6696754022121669 on epoch=474
06/08/2022 05:52:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 05:52:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 05:52:35 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 05:52:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 05:52:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/08/2022 05:52:41 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6576976663183559 on epoch=487
06/08/2022 05:52:44 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 05:52:47 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 05:52:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 05:52:52 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 05:52:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 05:52:56 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6731601731601731 on epoch=499
06/08/2022 05:52:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 05:53:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=504
06/08/2022 05:53:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 05:53:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 05:53:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 05:53:11 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6533927190948063 on epoch=512
06/08/2022 05:53:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 05:53:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 05:53:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 05:53:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 05:53:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 05:53:27 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6510270774976658 on epoch=524
06/08/2022 05:53:29 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 05:53:32 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 05:53:35 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 05:53:38 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 05:53:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 05:53:42 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6510628275334157 on epoch=537
06/08/2022 05:53:45 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=539
06/08/2022 05:53:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 05:53:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 05:53:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 05:53:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 05:53:57 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.6442583732057416 on epoch=549
06/08/2022 05:54:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 05:54:03 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 05:54:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 05:54:08 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 05:54:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/08/2022 05:54:12 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.668061568061568 on epoch=562
06/08/2022 05:54:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 05:54:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 05:54:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 05:54:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 05:54:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/08/2022 05:54:28 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6828665535562087 on epoch=574
06/08/2022 05:54:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 05:54:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 05:54:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 05:54:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 05:54:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 05:54:43 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6526044761338878 on epoch=587
06/08/2022 05:54:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 05:54:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 05:54:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 05:54:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 05:54:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 05:54:58 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6530501089324618 on epoch=599
06/08/2022 05:55:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 05:55:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 05:55:07 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 05:55:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 05:55:12 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=612
06/08/2022 05:55:14 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.6679663473781121 on epoch=612
06/08/2022 05:55:16 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 05:55:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/08/2022 05:55:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 05:55:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 05:55:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 05:55:29 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6665813278716504 on epoch=624
06/08/2022 05:55:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 05:55:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 05:55:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 05:55:40 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 05:55:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 05:55:44 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.6817878540305011 on epoch=637
06/08/2022 05:55:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 05:55:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 05:55:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 05:55:56 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 05:55:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 05:56:00 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6817878540305011 on epoch=649
06/08/2022 05:56:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 05:56:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 05:56:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 05:56:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 05:56:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 05:56:15 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7320346320346319 on epoch=662
06/08/2022 05:56:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6994397759103641 -> 0.7320346320346319 on epoch=662, global_step=2650
06/08/2022 05:56:18 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 05:56:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 05:56:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/08/2022 05:56:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 05:56:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 05:56:31 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6728670634920635 on epoch=674
06/08/2022 05:56:34 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 05:56:37 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 05:56:39 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 05:56:42 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 05:56:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 05:56:46 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6867018398268399 on epoch=687
06/08/2022 05:56:49 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 05:56:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 05:56:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 05:56:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 05:57:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 05:57:02 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6564752539450949 on epoch=699
06/08/2022 05:57:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 05:57:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 05:57:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 05:57:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 05:57:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 05:57:17 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6564752539450949 on epoch=712
06/08/2022 05:57:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 05:57:22 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 05:57:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 05:57:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/08/2022 05:57:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 05:57:32 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.684614313561682 on epoch=724
06/08/2022 05:57:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 05:57:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 05:57:41 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 05:57:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 05:57:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 05:57:48 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6665813278716504 on epoch=737
06/08/2022 05:57:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 05:57:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 05:57:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 05:57:59 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 05:58:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/08/2022 05:58:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:58:03 - INFO - __main__ - Printing 3 examples
06/08/2022 05:58:03 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:58:03 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:58:03 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 05:58:03 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 05:58:03 - INFO - __main__ - Printing 3 examples
06/08/2022 05:58:03 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 05:58:03 - INFO - __main__ - ['sad']
06/08/2022 05:58:03 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:58:03 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:58:03 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.7068996806039489 on epoch=749
06/08/2022 05:58:03 - INFO - __main__ - save last model!
06/08/2022 05:58:03 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 05:58:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 05:58:03 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 05:58:03 - INFO - __main__ - Printing 3 examples
06/08/2022 05:58:03 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 05:58:03 - INFO - __main__ - ['others']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 05:58:03 - INFO - __main__ - ['others']
06/08/2022 05:58:03 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 05:58:03 - INFO - __main__ - ['others']
06/08/2022 05:58:03 - INFO - __main__ - Tokenizing Input ...
06/08/2022 05:58:05 - INFO - __main__ - Tokenizing Output ...
06/08/2022 05:58:10 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 05:58:19 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 05:58:19 - INFO - __main__ - task name: emo
06/08/2022 05:58:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 05:58:19 - INFO - __main__ - Starting training!
06/08/2022 06:00:03 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_21_0.4_8_predictions.txt
06/08/2022 06:00:03 - INFO - __main__ - Classification-F1 on test data: 0.2166
06/08/2022 06:00:03 - INFO - __main__ - prefix=emo_16_21, lr=0.4, bsz=8, dev_performance=0.7320346320346319, test_performance=0.21660830371281367
06/08/2022 06:00:03 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.3, bsz=8 ...
06/08/2022 06:00:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:00:04 - INFO - __main__ - Printing 3 examples
06/08/2022 06:00:04 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:00:04 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:00:04 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:00:04 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:00:04 - INFO - __main__ - Printing 3 examples
06/08/2022 06:00:04 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 06:00:04 - INFO - __main__ - ['sad']
06/08/2022 06:00:04 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:00:04 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:00:04 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:00:22 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:00:22 - INFO - __main__ - task name: emo
06/08/2022 06:00:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:00:23 - INFO - __main__ - Starting training!
06/08/2022 06:00:26 - INFO - __main__ - Step 10 Global step 10 Train loss 6.81 on epoch=2
06/08/2022 06:00:29 - INFO - __main__ - Step 20 Global step 20 Train loss 3.24 on epoch=4
06/08/2022 06:00:32 - INFO - __main__ - Step 30 Global step 30 Train loss 1.63 on epoch=7
06/08/2022 06:00:34 - INFO - __main__ - Step 40 Global step 40 Train loss 1.16 on epoch=9
06/08/2022 06:00:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.10 on epoch=12
06/08/2022 06:00:38 - INFO - __main__ - Global step 50 Train loss 2.79 Classification-F1 0.1 on epoch=12
06/08/2022 06:00:38 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 06:00:41 - INFO - __main__ - Step 60 Global step 60 Train loss 1.02 on epoch=14
06/08/2022 06:00:44 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/08/2022 06:00:47 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/08/2022 06:00:49 - INFO - __main__ - Step 90 Global step 90 Train loss 0.93 on epoch=22
06/08/2022 06:00:52 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=24
06/08/2022 06:00:53 - INFO - __main__ - Global step 100 Train loss 0.98 Classification-F1 0.10256410256410256 on epoch=24
06/08/2022 06:00:53 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.10256410256410256 on epoch=24, global_step=100
06/08/2022 06:00:56 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/08/2022 06:00:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.95 on epoch=29
06/08/2022 06:01:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=32
06/08/2022 06:01:04 - INFO - __main__ - Step 140 Global step 140 Train loss 0.99 on epoch=34
06/08/2022 06:01:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.92 on epoch=37
06/08/2022 06:01:08 - INFO - __main__ - Global step 150 Train loss 0.94 Classification-F1 0.1 on epoch=37
06/08/2022 06:01:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=39
06/08/2022 06:01:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.96 on epoch=42
06/08/2022 06:01:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.92 on epoch=44
06/08/2022 06:01:20 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=47
06/08/2022 06:01:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.91 on epoch=49
06/08/2022 06:01:23 - INFO - __main__ - Global step 200 Train loss 0.91 Classification-F1 0.09493670886075949 on epoch=49
06/08/2022 06:01:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=52
06/08/2022 06:01:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.86 on epoch=54
06/08/2022 06:01:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.87 on epoch=57
06/08/2022 06:01:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=59
06/08/2022 06:01:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.89 on epoch=62
06/08/2022 06:01:38 - INFO - __main__ - Global step 250 Train loss 0.86 Classification-F1 0.1 on epoch=62
06/08/2022 06:01:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.92 on epoch=64
06/08/2022 06:01:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.80 on epoch=67
06/08/2022 06:01:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=69
06/08/2022 06:01:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.81 on epoch=72
06/08/2022 06:01:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=74
06/08/2022 06:01:53 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.24300653594771243 on epoch=74
06/08/2022 06:01:53 - INFO - __main__ - Saving model with best Classification-F1: 0.10256410256410256 -> 0.24300653594771243 on epoch=74, global_step=300
06/08/2022 06:01:56 - INFO - __main__ - Step 310 Global step 310 Train loss 0.82 on epoch=77
06/08/2022 06:01:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.79 on epoch=79
06/08/2022 06:02:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.83 on epoch=82
06/08/2022 06:02:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.77 on epoch=84
06/08/2022 06:02:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.77 on epoch=87
06/08/2022 06:02:08 - INFO - __main__ - Global step 350 Train loss 0.79 Classification-F1 0.12646198830409355 on epoch=87
06/08/2022 06:02:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.74 on epoch=89
06/08/2022 06:02:14 - INFO - __main__ - Step 370 Global step 370 Train loss 0.79 on epoch=92
06/08/2022 06:02:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.68 on epoch=94
06/08/2022 06:02:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=97
06/08/2022 06:02:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.74 on epoch=99
06/08/2022 06:02:23 - INFO - __main__ - Global step 400 Train loss 0.73 Classification-F1 0.37836065573770494 on epoch=99
06/08/2022 06:02:23 - INFO - __main__ - Saving model with best Classification-F1: 0.24300653594771243 -> 0.37836065573770494 on epoch=99, global_step=400
06/08/2022 06:02:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.70 on epoch=102
06/08/2022 06:02:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.62 on epoch=104
06/08/2022 06:02:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=107
06/08/2022 06:02:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.67 on epoch=109
06/08/2022 06:02:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=112
06/08/2022 06:02:38 - INFO - __main__ - Global step 450 Train loss 0.60 Classification-F1 0.48921568627450984 on epoch=112
06/08/2022 06:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.37836065573770494 -> 0.48921568627450984 on epoch=112, global_step=450
06/08/2022 06:02:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=114
06/08/2022 06:02:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=117
06/08/2022 06:02:46 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=119
06/08/2022 06:02:49 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=122
06/08/2022 06:02:52 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=124
06/08/2022 06:02:53 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.48426704014939315 on epoch=124
06/08/2022 06:02:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=127
06/08/2022 06:02:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=129
06/08/2022 06:03:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=132
06/08/2022 06:03:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=134
06/08/2022 06:03:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=137
06/08/2022 06:03:09 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.4700772200772201 on epoch=137
06/08/2022 06:03:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=139
06/08/2022 06:03:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=142
06/08/2022 06:03:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.12 on epoch=144
06/08/2022 06:03:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=147
06/08/2022 06:03:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.15 on epoch=149
06/08/2022 06:03:24 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.5605380164647406 on epoch=149
06/08/2022 06:03:24 - INFO - __main__ - Saving model with best Classification-F1: 0.48921568627450984 -> 0.5605380164647406 on epoch=149, global_step=600
06/08/2022 06:03:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/08/2022 06:03:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=154
06/08/2022 06:03:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.10 on epoch=157
06/08/2022 06:03:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.07 on epoch=159
06/08/2022 06:03:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.04 on epoch=162
06/08/2022 06:03:39 - INFO - __main__ - Global step 650 Train loss 0.08 Classification-F1 0.5811796898753421 on epoch=162
06/08/2022 06:03:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5605380164647406 -> 0.5811796898753421 on epoch=162, global_step=650
06/08/2022 06:03:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=164
06/08/2022 06:03:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=167
06/08/2022 06:03:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.06 on epoch=169
06/08/2022 06:03:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/08/2022 06:03:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/08/2022 06:03:55 - INFO - __main__ - Global step 700 Train loss 0.10 Classification-F1 0.5930871212121213 on epoch=174
06/08/2022 06:03:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5811796898753421 -> 0.5930871212121213 on epoch=174, global_step=700
06/08/2022 06:03:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=177
06/08/2022 06:04:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=179
06/08/2022 06:04:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.05 on epoch=182
06/08/2022 06:04:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.08 on epoch=184
06/08/2022 06:04:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=187
06/08/2022 06:04:12 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.621031746031746 on epoch=187
06/08/2022 06:04:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5930871212121213 -> 0.621031746031746 on epoch=187, global_step=750
06/08/2022 06:04:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=189
06/08/2022 06:04:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=192
06/08/2022 06:04:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.07 on epoch=194
06/08/2022 06:04:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/08/2022 06:04:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/08/2022 06:04:28 - INFO - __main__ - Global step 800 Train loss 0.06 Classification-F1 0.6544308490915833 on epoch=199
06/08/2022 06:04:28 - INFO - __main__ - Saving model with best Classification-F1: 0.621031746031746 -> 0.6544308490915833 on epoch=199, global_step=800
06/08/2022 06:04:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.03 on epoch=202
06/08/2022 06:04:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=204
06/08/2022 06:04:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/08/2022 06:04:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/08/2022 06:04:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/08/2022 06:04:44 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.6423655913978494 on epoch=212
06/08/2022 06:04:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.02 on epoch=214
06/08/2022 06:04:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=217
06/08/2022 06:04:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=219
06/08/2022 06:04:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.05 on epoch=222
06/08/2022 06:04:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.02 on epoch=224
06/08/2022 06:04:59 - INFO - __main__ - Global step 900 Train loss 0.05 Classification-F1 0.6237861888584915 on epoch=224
06/08/2022 06:05:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/08/2022 06:05:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.02 on epoch=229
06/08/2022 06:05:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.02 on epoch=232
06/08/2022 06:05:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=234
06/08/2022 06:05:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/08/2022 06:05:14 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.5916930034873583 on epoch=237
06/08/2022 06:05:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=239
06/08/2022 06:05:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/08/2022 06:05:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/08/2022 06:05:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.02 on epoch=247
06/08/2022 06:05:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 06:05:29 - INFO - __main__ - Global step 1000 Train loss 0.04 Classification-F1 0.6448275862068966 on epoch=249
06/08/2022 06:05:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.02 on epoch=252
06/08/2022 06:05:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/08/2022 06:05:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/08/2022 06:05:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 06:05:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 06:05:45 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.6268398268398269 on epoch=262
06/08/2022 06:05:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 06:05:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/08/2022 06:05:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 06:05:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=272
06/08/2022 06:05:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/08/2022 06:06:00 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6218865018865019 on epoch=274
06/08/2022 06:06:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 06:06:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/08/2022 06:06:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/08/2022 06:06:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 06:06:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 06:06:16 - INFO - __main__ - Global step 1150 Train loss 0.02 Classification-F1 0.5693589743589744 on epoch=287
06/08/2022 06:06:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/08/2022 06:06:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/08/2022 06:06:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 06:06:27 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 06:06:30 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 06:06:31 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.6239151305683563 on epoch=299
06/08/2022 06:06:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 06:06:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/08/2022 06:06:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/08/2022 06:06:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/08/2022 06:06:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/08/2022 06:06:46 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.6087856289469192 on epoch=312
06/08/2022 06:06:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/08/2022 06:06:52 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/08/2022 06:06:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 06:06:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 06:07:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 06:07:02 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6670199253790585 on epoch=324
06/08/2022 06:07:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6544308490915833 -> 0.6670199253790585 on epoch=324, global_step=1300
06/08/2022 06:07:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 06:07:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/08/2022 06:07:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 06:07:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=334
06/08/2022 06:07:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 06:07:17 - INFO - __main__ - Global step 1350 Train loss 0.03 Classification-F1 0.7231702358362699 on epoch=337
06/08/2022 06:07:17 - INFO - __main__ - Saving model with best Classification-F1: 0.6670199253790585 -> 0.7231702358362699 on epoch=337, global_step=1350
06/08/2022 06:07:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 06:07:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 06:07:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 06:07:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.01 on epoch=347
06/08/2022 06:07:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 06:07:32 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6857142857142858 on epoch=349
06/08/2022 06:07:35 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/08/2022 06:07:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=354
06/08/2022 06:07:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 06:07:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=359
06/08/2022 06:07:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 06:07:47 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.7049396179720723 on epoch=362
06/08/2022 06:07:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 06:07:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 06:07:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 06:07:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/08/2022 06:08:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=374
06/08/2022 06:08:02 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.6691595441595442 on epoch=374
06/08/2022 06:08:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 06:08:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/08/2022 06:08:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=382
06/08/2022 06:08:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/08/2022 06:08:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 06:08:17 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6715686274509803 on epoch=387
06/08/2022 06:08:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 06:08:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/08/2022 06:08:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 06:08:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 06:08:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 06:08:33 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.6715053763440859 on epoch=399
06/08/2022 06:08:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 06:08:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 06:08:41 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 06:08:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 06:08:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=412
06/08/2022 06:08:48 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.6615712074303406 on epoch=412
06/08/2022 06:08:50 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 06:08:53 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 06:08:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 06:08:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 06:09:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=424
06/08/2022 06:09:03 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.6916730089963506 on epoch=424
06/08/2022 06:09:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=427
06/08/2022 06:09:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 06:09:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 06:09:14 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 06:09:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/08/2022 06:09:18 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5125648295190681 on epoch=437
06/08/2022 06:09:21 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=439
06/08/2022 06:09:23 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 06:09:26 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=444
06/08/2022 06:09:29 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/08/2022 06:09:32 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 06:09:33 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6673454639308297 on epoch=449
06/08/2022 06:09:36 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=452
06/08/2022 06:09:38 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 06:09:41 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 06:09:44 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 06:09:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/08/2022 06:09:48 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6494360562653245 on epoch=462
06/08/2022 06:09:51 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 06:09:54 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 06:09:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/08/2022 06:09:59 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 06:10:02 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=474
06/08/2022 06:10:04 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6652526395173454 on epoch=474
06/08/2022 06:10:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 06:10:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 06:10:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=482
06/08/2022 06:10:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/08/2022 06:10:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 06:10:19 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6557938965059709 on epoch=487
06/08/2022 06:10:22 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 06:10:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 06:10:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 06:10:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=497
06/08/2022 06:10:33 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=499
06/08/2022 06:10:34 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.673847749346842 on epoch=499
06/08/2022 06:10:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 06:10:40 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 06:10:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 06:10:45 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 06:10:48 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 06:10:49 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6903756697874345 on epoch=512
06/08/2022 06:10:52 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 06:10:55 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 06:10:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 06:11:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 06:11:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/08/2022 06:11:05 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6520839260312945 on epoch=524
06/08/2022 06:11:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 06:11:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 06:11:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=532
06/08/2022 06:11:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/08/2022 06:11:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=537
06/08/2022 06:11:20 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.6816293183940243 on epoch=537
06/08/2022 06:11:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 06:11:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 06:11:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 06:11:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 06:11:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=549
06/08/2022 06:11:35 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7036326649229875 on epoch=549
06/08/2022 06:11:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 06:11:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/08/2022 06:11:44 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=557
06/08/2022 06:11:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 06:11:49 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 06:11:50 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6717436974789917 on epoch=562
06/08/2022 06:11:53 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 06:11:56 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 06:11:59 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=569
06/08/2022 06:12:02 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 06:12:05 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 06:12:06 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.686843487394958 on epoch=574
06/08/2022 06:12:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 06:12:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 06:12:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 06:12:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 06:12:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 06:12:21 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.7029124259674544 on epoch=587
06/08/2022 06:12:24 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 06:12:26 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 06:12:29 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 06:12:32 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 06:12:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/08/2022 06:12:36 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.6917162698412699 on epoch=599
06/08/2022 06:12:39 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=602
06/08/2022 06:12:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 06:12:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 06:12:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 06:12:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 06:12:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6934392184392184 on epoch=612
06/08/2022 06:12:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 06:12:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 06:12:59 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 06:13:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=622
06/08/2022 06:13:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/08/2022 06:13:06 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.7109775809965564 on epoch=624
06/08/2022 06:13:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 06:13:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 06:13:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=632
06/08/2022 06:13:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/08/2022 06:13:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 06:13:21 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.6646945646945647 on epoch=637
06/08/2022 06:13:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 06:13:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=642
06/08/2022 06:13:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 06:13:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 06:13:35 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 06:13:36 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7003968253968255 on epoch=649
06/08/2022 06:13:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=652
06/08/2022 06:13:42 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 06:13:45 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 06:13:47 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 06:13:50 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 06:13:51 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6865058698222999 on epoch=662
06/08/2022 06:13:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 06:13:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 06:14:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 06:14:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 06:14:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 06:14:07 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6863899613899613 on epoch=674
06/08/2022 06:14:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 06:14:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 06:14:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 06:14:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 06:14:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 06:14:22 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6724548440065681 on epoch=687
06/08/2022 06:14:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 06:14:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 06:14:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 06:14:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 06:14:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 06:14:37 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7003968253968255 on epoch=699
06/08/2022 06:14:40 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 06:14:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 06:14:45 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 06:14:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 06:14:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 06:14:52 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.7003968253968255 on epoch=712
06/08/2022 06:14:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 06:14:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 06:15:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 06:15:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 06:15:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 06:15:08 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.676984126984127 on epoch=724
06/08/2022 06:15:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=727
06/08/2022 06:15:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 06:15:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 06:15:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 06:15:22 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 06:15:23 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6411038961038961 on epoch=737
06/08/2022 06:15:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 06:15:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 06:15:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 06:15:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 06:15:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 06:15:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:15:38 - INFO - __main__ - Printing 3 examples
06/08/2022 06:15:38 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:15:38 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:15:38 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:15:38 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:15:38 - INFO - __main__ - Printing 3 examples
06/08/2022 06:15:38 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 06:15:38 - INFO - __main__ - ['sad']
06/08/2022 06:15:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:15:38 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:15:38 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6215614947539307 on epoch=749
06/08/2022 06:15:38 - INFO - __main__ - save last model!
06/08/2022 06:15:38 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 06:15:38 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 06:15:38 - INFO - __main__ - Printing 3 examples
06/08/2022 06:15:38 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 06:15:38 - INFO - __main__ - ['others']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 06:15:38 - INFO - __main__ - ['others']
06/08/2022 06:15:38 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 06:15:38 - INFO - __main__ - ['others']
06/08/2022 06:15:38 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:15:38 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:15:41 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:15:47 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 06:15:56 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:15:56 - INFO - __main__ - task name: emo
06/08/2022 06:15:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:15:57 - INFO - __main__ - Starting training!
06/08/2022 06:17:40 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_21_0.3_8_predictions.txt
06/08/2022 06:17:40 - INFO - __main__ - Classification-F1 on test data: 0.3938
06/08/2022 06:17:41 - INFO - __main__ - prefix=emo_16_21, lr=0.3, bsz=8, dev_performance=0.7231702358362699, test_performance=0.3937574096037839
06/08/2022 06:17:41 - INFO - __main__ - Running ... prefix=emo_16_21, lr=0.2, bsz=8 ...
06/08/2022 06:17:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:17:42 - INFO - __main__ - Printing 3 examples
06/08/2022 06:17:42 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:17:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:17:42 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:17:42 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:17:42 - INFO - __main__ - Printing 3 examples
06/08/2022 06:17:42 - INFO - __main__ -  [emo] i am good i'm doing great what are u doing feeling lonely
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ -  [emo] what about nonveg non veg food is also not allowed in canteens egg is though so sad
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ -  [emo] you wiollbe hre on monday sadly yes i work everyday but thursday sadly  whaynyou say
06/08/2022 06:17:42 - INFO - __main__ - ['sad']
06/08/2022 06:17:42 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:17:42 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:17:42 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:18:01 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:18:01 - INFO - __main__ - task name: emo
06/08/2022 06:18:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:18:02 - INFO - __main__ - Starting training!
06/08/2022 06:18:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.97 on epoch=2
06/08/2022 06:18:08 - INFO - __main__ - Step 20 Global step 20 Train loss 4.61 on epoch=4
06/08/2022 06:18:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.56 on epoch=7
06/08/2022 06:18:13 - INFO - __main__ - Step 40 Global step 40 Train loss 1.50 on epoch=9
06/08/2022 06:18:16 - INFO - __main__ - Step 50 Global step 50 Train loss 1.30 on epoch=12
06/08/2022 06:18:17 - INFO - __main__ - Global step 50 Train loss 3.39 Classification-F1 0.1 on epoch=12
06/08/2022 06:18:17 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 06:18:20 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=14
06/08/2022 06:18:22 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=17
06/08/2022 06:18:25 - INFO - __main__ - Step 80 Global step 80 Train loss 1.05 on epoch=19
06/08/2022 06:18:28 - INFO - __main__ - Step 90 Global step 90 Train loss 1.04 on epoch=22
06/08/2022 06:18:30 - INFO - __main__ - Step 100 Global step 100 Train loss 1.00 on epoch=24
06/08/2022 06:18:31 - INFO - __main__ - Global step 100 Train loss 1.08 Classification-F1 0.09493670886075949 on epoch=24
06/08/2022 06:18:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.00 on epoch=27
06/08/2022 06:18:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=29
06/08/2022 06:18:40 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=32
06/08/2022 06:18:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=34
06/08/2022 06:18:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.00 on epoch=37
06/08/2022 06:18:46 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.1 on epoch=37
06/08/2022 06:18:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=39
06/08/2022 06:18:52 - INFO - __main__ - Step 170 Global step 170 Train loss 1.00 on epoch=42
06/08/2022 06:18:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=44
06/08/2022 06:18:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=47
06/08/2022 06:19:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=49
06/08/2022 06:19:01 - INFO - __main__ - Global step 200 Train loss 0.92 Classification-F1 0.19307400379506642 on epoch=49
06/08/2022 06:19:01 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.19307400379506642 on epoch=49, global_step=200
06/08/2022 06:19:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.96 on epoch=52
06/08/2022 06:19:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=54
06/08/2022 06:19:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.94 on epoch=57
06/08/2022 06:19:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=59
06/08/2022 06:19:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.85 on epoch=62
06/08/2022 06:19:16 - INFO - __main__ - Global step 250 Train loss 0.87 Classification-F1 0.1 on epoch=62
06/08/2022 06:19:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=64
06/08/2022 06:19:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.86 on epoch=67
06/08/2022 06:19:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=69
06/08/2022 06:19:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=72
06/08/2022 06:19:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.80 on epoch=74
06/08/2022 06:19:30 - INFO - __main__ - Global step 300 Train loss 0.82 Classification-F1 0.1 on epoch=74
06/08/2022 06:19:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.86 on epoch=77
06/08/2022 06:19:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.84 on epoch=79
06/08/2022 06:19:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.81 on epoch=82
06/08/2022 06:19:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.82 on epoch=84
06/08/2022 06:19:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.78 on epoch=87
06/08/2022 06:19:45 - INFO - __main__ - Global step 350 Train loss 0.82 Classification-F1 0.15526315789473685 on epoch=87
06/08/2022 06:19:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.82 on epoch=89
06/08/2022 06:19:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.84 on epoch=92
06/08/2022 06:19:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.74 on epoch=94
06/08/2022 06:19:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.76 on epoch=97
06/08/2022 06:19:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.78 on epoch=99
06/08/2022 06:19:59 - INFO - __main__ - Global step 400 Train loss 0.79 Classification-F1 0.368597091840423 on epoch=99
06/08/2022 06:19:59 - INFO - __main__ - Saving model with best Classification-F1: 0.19307400379506642 -> 0.368597091840423 on epoch=99, global_step=400
06/08/2022 06:20:02 - INFO - __main__ - Step 410 Global step 410 Train loss 0.83 on epoch=102
06/08/2022 06:20:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.79 on epoch=104
06/08/2022 06:20:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.75 on epoch=107
06/08/2022 06:20:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.81 on epoch=109
06/08/2022 06:20:13 - INFO - __main__ - Step 450 Global step 450 Train loss 0.83 on epoch=112
06/08/2022 06:20:14 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.15596101454280342 on epoch=112
06/08/2022 06:20:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=114
06/08/2022 06:20:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.77 on epoch=117
06/08/2022 06:20:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.65 on epoch=119
06/08/2022 06:20:25 - INFO - __main__ - Step 490 Global step 490 Train loss 0.70 on epoch=122
06/08/2022 06:20:27 - INFO - __main__ - Step 500 Global step 500 Train loss 0.64 on epoch=124
06/08/2022 06:20:29 - INFO - __main__ - Global step 500 Train loss 0.70 Classification-F1 0.3056798806479114 on epoch=124
06/08/2022 06:20:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.72 on epoch=127
06/08/2022 06:20:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.68 on epoch=129
06/08/2022 06:20:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=132
06/08/2022 06:20:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.57 on epoch=134
06/08/2022 06:20:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.64 on epoch=137
06/08/2022 06:20:43 - INFO - __main__ - Global step 550 Train loss 0.65 Classification-F1 0.2681521093285799 on epoch=137
06/08/2022 06:20:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=139
06/08/2022 06:20:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.57 on epoch=142
06/08/2022 06:20:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.53 on epoch=144
06/08/2022 06:20:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.60 on epoch=147
06/08/2022 06:20:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.43 on epoch=149
06/08/2022 06:20:58 - INFO - __main__ - Global step 600 Train loss 0.53 Classification-F1 0.3729427736006683 on epoch=149
06/08/2022 06:20:58 - INFO - __main__ - Saving model with best Classification-F1: 0.368597091840423 -> 0.3729427736006683 on epoch=149, global_step=600
06/08/2022 06:21:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.55 on epoch=152
06/08/2022 06:21:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=154
06/08/2022 06:21:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=157
06/08/2022 06:21:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=159
06/08/2022 06:21:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.62 on epoch=162
06/08/2022 06:21:13 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.45984848484848484 on epoch=162
06/08/2022 06:21:13 - INFO - __main__ - Saving model with best Classification-F1: 0.3729427736006683 -> 0.45984848484848484 on epoch=162, global_step=650
06/08/2022 06:21:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.37 on epoch=164
06/08/2022 06:21:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.43 on epoch=167
06/08/2022 06:21:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=169
06/08/2022 06:21:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.46 on epoch=172
06/08/2022 06:21:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.43 on epoch=174
06/08/2022 06:21:28 - INFO - __main__ - Global step 700 Train loss 0.42 Classification-F1 0.576241134751773 on epoch=174
06/08/2022 06:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.45984848484848484 -> 0.576241134751773 on epoch=174, global_step=700
06/08/2022 06:21:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.47 on epoch=177
06/08/2022 06:21:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.38 on epoch=179
06/08/2022 06:21:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.44 on epoch=182
06/08/2022 06:21:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=184
06/08/2022 06:21:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=187
06/08/2022 06:21:43 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.39886500069803155 on epoch=187
06/08/2022 06:21:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=189
06/08/2022 06:21:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=192
06/08/2022 06:21:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=194
06/08/2022 06:21:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=197
06/08/2022 06:21:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=199
06/08/2022 06:21:58 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.39770547057298417 on epoch=199
06/08/2022 06:22:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=202
06/08/2022 06:22:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.34 on epoch=204
06/08/2022 06:22:06 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=207
06/08/2022 06:22:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=209
06/08/2022 06:22:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=212
06/08/2022 06:22:13 - INFO - __main__ - Global step 850 Train loss 0.27 Classification-F1 0.533768115942029 on epoch=212
06/08/2022 06:22:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.31 on epoch=214
06/08/2022 06:22:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=217
06/08/2022 06:22:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.27 on epoch=219
06/08/2022 06:22:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=222
06/08/2022 06:22:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=224
06/08/2022 06:22:28 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.5414980297869498 on epoch=224
06/08/2022 06:22:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=227
06/08/2022 06:22:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=229
06/08/2022 06:22:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=232
06/08/2022 06:22:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=234
06/08/2022 06:22:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=237
06/08/2022 06:22:43 - INFO - __main__ - Global step 950 Train loss 0.22 Classification-F1 0.5796008245877061 on epoch=237
06/08/2022 06:22:43 - INFO - __main__ - Saving model with best Classification-F1: 0.576241134751773 -> 0.5796008245877061 on epoch=237, global_step=950
06/08/2022 06:22:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=239
06/08/2022 06:22:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=242
06/08/2022 06:22:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.19 on epoch=244
06/08/2022 06:22:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.21 on epoch=247
06/08/2022 06:22:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=249
06/08/2022 06:22:58 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.5254356526710916 on epoch=249
06/08/2022 06:23:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
06/08/2022 06:23:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=254
06/08/2022 06:23:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=257
06/08/2022 06:23:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=259
06/08/2022 06:23:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=262
06/08/2022 06:23:13 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.6905270119953102 on epoch=262
06/08/2022 06:23:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5796008245877061 -> 0.6905270119953102 on epoch=262, global_step=1050
06/08/2022 06:23:16 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=264
06/08/2022 06:23:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=267
06/08/2022 06:23:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=269
06/08/2022 06:23:24 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=272
06/08/2022 06:23:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=274
06/08/2022 06:23:28 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6159544693865774 on epoch=274
06/08/2022 06:23:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=277
06/08/2022 06:23:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/08/2022 06:23:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=282
06/08/2022 06:23:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=284
06/08/2022 06:23:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=287
06/08/2022 06:23:44 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.6159544693865774 on epoch=287
06/08/2022 06:23:47 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=289
06/08/2022 06:23:49 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=292
06/08/2022 06:23:52 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/08/2022 06:23:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=297
06/08/2022 06:23:57 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=299
06/08/2022 06:23:59 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7136285836542575 on epoch=299
06/08/2022 06:23:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6905270119953102 -> 0.7136285836542575 on epoch=299, global_step=1200
06/08/2022 06:24:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/08/2022 06:24:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/08/2022 06:24:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=307
06/08/2022 06:24:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/08/2022 06:24:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=312
06/08/2022 06:24:14 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.5689718614718615 on epoch=312
06/08/2022 06:24:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=314
06/08/2022 06:24:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=317
06/08/2022 06:24:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=319
06/08/2022 06:24:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=322
06/08/2022 06:24:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=324
06/08/2022 06:24:29 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6950208181744685 on epoch=324
06/08/2022 06:24:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=327
06/08/2022 06:24:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=329
06/08/2022 06:24:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/08/2022 06:24:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/08/2022 06:24:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=337
06/08/2022 06:24:44 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7132675568159439 on epoch=337
06/08/2022 06:24:47 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/08/2022 06:24:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=342
06/08/2022 06:24:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/08/2022 06:24:55 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/08/2022 06:24:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=349
06/08/2022 06:24:59 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.5293566388068666 on epoch=349
06/08/2022 06:25:02 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/08/2022 06:25:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/08/2022 06:25:07 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/08/2022 06:25:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=359
06/08/2022 06:25:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/08/2022 06:25:14 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6219191479529053 on epoch=362
06/08/2022 06:25:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=364
06/08/2022 06:25:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=367
06/08/2022 06:25:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=369
06/08/2022 06:25:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=372
06/08/2022 06:25:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=374
06/08/2022 06:25:29 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.7144007661834487 on epoch=374
06/08/2022 06:25:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7136285836542575 -> 0.7144007661834487 on epoch=374, global_step=1500
06/08/2022 06:25:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/08/2022 06:25:35 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=379
06/08/2022 06:25:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=382
06/08/2022 06:25:40 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=384
06/08/2022 06:25:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=387
06/08/2022 06:25:45 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.6687992187992188 on epoch=387
06/08/2022 06:25:47 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=389
06/08/2022 06:25:50 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=392
06/08/2022 06:25:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=394
06/08/2022 06:25:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=397
06/08/2022 06:25:58 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/08/2022 06:26:00 - INFO - __main__ - Global step 1600 Train loss 0.03 Classification-F1 0.6996675155631012 on epoch=399
06/08/2022 06:26:03 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=402
06/08/2022 06:26:05 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 06:26:08 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=407
06/08/2022 06:26:11 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/08/2022 06:26:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/08/2022 06:26:15 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.695639097744361 on epoch=412
06/08/2022 06:26:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=414
06/08/2022 06:26:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 06:26:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=419
06/08/2022 06:26:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=422
06/08/2022 06:26:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/08/2022 06:26:30 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6746571694847556 on epoch=424
06/08/2022 06:26:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=427
06/08/2022 06:26:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=429
06/08/2022 06:26:39 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 06:26:42 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/08/2022 06:26:44 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/08/2022 06:26:46 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.7000000000000001 on epoch=437
06/08/2022 06:26:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 06:26:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/08/2022 06:26:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/08/2022 06:26:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=447
06/08/2022 06:27:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=449
06/08/2022 06:27:01 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6768074710866472 on epoch=449
06/08/2022 06:27:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/08/2022 06:27:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=454
06/08/2022 06:27:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/08/2022 06:27:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 06:27:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/08/2022 06:27:16 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.641510928096294 on epoch=462
06/08/2022 06:27:19 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=464
06/08/2022 06:27:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=467
06/08/2022 06:27:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/08/2022 06:27:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=472
06/08/2022 06:27:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/08/2022 06:27:32 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.730273489708634 on epoch=474
06/08/2022 06:27:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7144007661834487 -> 0.730273489708634 on epoch=474, global_step=1900
06/08/2022 06:27:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 06:27:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=479
06/08/2022 06:27:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/08/2022 06:27:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/08/2022 06:27:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=487
06/08/2022 06:27:47 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6832368082368082 on epoch=487
06/08/2022 06:27:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/08/2022 06:27:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/08/2022 06:27:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/08/2022 06:27:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 06:28:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/08/2022 06:28:02 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6967105263157894 on epoch=499
06/08/2022 06:28:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=502
06/08/2022 06:28:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/08/2022 06:28:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 06:28:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=509
06/08/2022 06:28:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/08/2022 06:28:18 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6528255528255529 on epoch=512
06/08/2022 06:28:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/08/2022 06:28:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/08/2022 06:28:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=519
06/08/2022 06:28:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/08/2022 06:28:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=524
06/08/2022 06:28:33 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7419871794871794 on epoch=524
06/08/2022 06:28:34 - INFO - __main__ - Saving model with best Classification-F1: 0.730273489708634 -> 0.7419871794871794 on epoch=524, global_step=2100
06/08/2022 06:28:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=527
06/08/2022 06:28:39 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/08/2022 06:28:42 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/08/2022 06:28:45 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 06:28:48 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=537
06/08/2022 06:28:49 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7453530950305144 on epoch=537
06/08/2022 06:28:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7419871794871794 -> 0.7453530950305144 on epoch=537, global_step=2150
06/08/2022 06:28:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/08/2022 06:28:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=542
06/08/2022 06:28:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 06:29:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=547
06/08/2022 06:29:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/08/2022 06:29:05 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.7662004662004662 on epoch=549
06/08/2022 06:29:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7453530950305144 -> 0.7662004662004662 on epoch=549, global_step=2200
06/08/2022 06:29:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 06:29:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=554
06/08/2022 06:29:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 06:29:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=559
06/08/2022 06:29:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=562
06/08/2022 06:29:20 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7450644162588634 on epoch=562
06/08/2022 06:29:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/08/2022 06:29:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
06/08/2022 06:29:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=569
06/08/2022 06:29:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/08/2022 06:29:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 06:29:36 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7086538461538462 on epoch=574
06/08/2022 06:29:39 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=577
06/08/2022 06:29:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=579
06/08/2022 06:29:44 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=582
06/08/2022 06:29:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/08/2022 06:29:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 06:29:52 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6621952181803835 on epoch=587
06/08/2022 06:29:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/08/2022 06:29:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/08/2022 06:30:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=594
06/08/2022 06:30:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 06:30:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=599
06/08/2022 06:30:07 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7328978978978979 on epoch=599
06/08/2022 06:30:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 06:30:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 06:30:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=607
06/08/2022 06:30:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=609
06/08/2022 06:30:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=612
06/08/2022 06:30:23 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7486363636363637 on epoch=612
06/08/2022 06:30:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=614
06/08/2022 06:30:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/08/2022 06:30:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 06:30:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 06:30:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 06:30:38 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.6928868898883891 on epoch=624
06/08/2022 06:30:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/08/2022 06:30:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/08/2022 06:30:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 06:30:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/08/2022 06:30:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 06:30:54 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5817621431219875 on epoch=637
06/08/2022 06:30:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 06:30:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 06:31:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/08/2022 06:31:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=647
06/08/2022 06:31:08 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 06:31:09 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6852262982568974 on epoch=649
06/08/2022 06:31:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=652
06/08/2022 06:31:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=654
06/08/2022 06:31:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=657
06/08/2022 06:31:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 06:31:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 06:31:24 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7252010939510939 on epoch=662
06/08/2022 06:31:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=664
06/08/2022 06:31:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 06:31:33 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 06:31:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=672
06/08/2022 06:31:38 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=674
06/08/2022 06:31:40 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.6796736766751759 on epoch=674
06/08/2022 06:31:43 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 06:31:45 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 06:31:48 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=682
06/08/2022 06:31:51 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 06:31:54 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 06:31:55 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6789980009995003 on epoch=687
06/08/2022 06:31:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/08/2022 06:32:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=692
06/08/2022 06:32:04 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 06:32:07 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 06:32:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 06:32:11 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6804223502499365 on epoch=699
06/08/2022 06:32:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=702
06/08/2022 06:32:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 06:32:19 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=707
06/08/2022 06:32:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 06:32:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 06:32:26 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7078136062503045 on epoch=712
06/08/2022 06:32:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 06:32:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 06:32:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/08/2022 06:32:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=722
06/08/2022 06:32:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=724
06/08/2022 06:32:41 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7252554974329168 on epoch=724
06/08/2022 06:32:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 06:32:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 06:32:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 06:32:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 06:32:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 06:32:57 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.7599777196551389 on epoch=737
06/08/2022 06:33:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=739
06/08/2022 06:33:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=742
06/08/2022 06:33:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=744
06/08/2022 06:33:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 06:33:11 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 06:33:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:33:12 - INFO - __main__ - Printing 3 examples
06/08/2022 06:33:12 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:33:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:33:12 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:33:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:33:12 - INFO - __main__ - Printing 3 examples
06/08/2022 06:33:12 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 06:33:12 - INFO - __main__ - ['happy']
06/08/2022 06:33:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:33:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:33:13 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6789980009995003 on epoch=749
06/08/2022 06:33:13 - INFO - __main__ - save last model!
06/08/2022 06:33:13 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:33:13 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 06:33:13 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 06:33:13 - INFO - __main__ - Printing 3 examples
06/08/2022 06:33:13 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 06:33:13 - INFO - __main__ - ['others']
06/08/2022 06:33:13 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 06:33:13 - INFO - __main__ - ['others']
06/08/2022 06:33:13 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 06:33:13 - INFO - __main__ - ['others']
06/08/2022 06:33:13 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:33:15 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:33:20 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 06:33:28 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:33:28 - INFO - __main__ - task name: emo
06/08/2022 06:33:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:33:29 - INFO - __main__ - Starting training!
06/08/2022 06:35:11 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_21_0.2_8_predictions.txt
06/08/2022 06:35:11 - INFO - __main__ - Classification-F1 on test data: 0.3183
06/08/2022 06:35:11 - INFO - __main__ - prefix=emo_16_21, lr=0.2, bsz=8, dev_performance=0.7662004662004662, test_performance=0.31828057548652233
06/08/2022 06:35:11 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.5, bsz=8 ...
06/08/2022 06:35:12 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:35:12 - INFO - __main__ - Printing 3 examples
06/08/2022 06:35:12 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 06:35:12 - INFO - __main__ - ['happy']
06/08/2022 06:35:12 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 06:35:12 - INFO - __main__ - ['happy']
06/08/2022 06:35:12 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 06:35:12 - INFO - __main__ - ['happy']
06/08/2022 06:35:12 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:35:12 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:35:13 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:35:13 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:35:13 - INFO - __main__ - Printing 3 examples
06/08/2022 06:35:13 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 06:35:13 - INFO - __main__ - ['happy']
06/08/2022 06:35:13 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 06:35:13 - INFO - __main__ - ['happy']
06/08/2022 06:35:13 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 06:35:13 - INFO - __main__ - ['happy']
06/08/2022 06:35:13 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:35:13 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:35:13 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:35:31 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:35:31 - INFO - __main__ - task name: emo
06/08/2022 06:35:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:35:32 - INFO - __main__ - Starting training!
06/08/2022 06:35:35 - INFO - __main__ - Step 10 Global step 10 Train loss 5.87 on epoch=2
06/08/2022 06:35:38 - INFO - __main__ - Step 20 Global step 20 Train loss 2.09 on epoch=4
06/08/2022 06:35:41 - INFO - __main__ - Step 30 Global step 30 Train loss 1.18 on epoch=7
06/08/2022 06:35:44 - INFO - __main__ - Step 40 Global step 40 Train loss 1.10 on epoch=9
06/08/2022 06:35:47 - INFO - __main__ - Step 50 Global step 50 Train loss 0.97 on epoch=12
06/08/2022 06:35:48 - INFO - __main__ - Global step 50 Train loss 2.24 Classification-F1 0.1 on epoch=12
06/08/2022 06:35:48 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 06:35:51 - INFO - __main__ - Step 60 Global step 60 Train loss 1.00 on epoch=14
06/08/2022 06:35:53 - INFO - __main__ - Step 70 Global step 70 Train loss 1.00 on epoch=17
06/08/2022 06:35:56 - INFO - __main__ - Step 80 Global step 80 Train loss 0.97 on epoch=19
06/08/2022 06:35:59 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=22
06/08/2022 06:36:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=24
06/08/2022 06:36:03 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.1565276828434723 on epoch=24
06/08/2022 06:36:03 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.1565276828434723 on epoch=24, global_step=100
06/08/2022 06:36:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.92 on epoch=27
06/08/2022 06:36:08 - INFO - __main__ - Step 120 Global step 120 Train loss 0.90 on epoch=29
06/08/2022 06:36:11 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=32
06/08/2022 06:36:14 - INFO - __main__ - Step 140 Global step 140 Train loss 0.84 on epoch=34
06/08/2022 06:36:17 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=37
06/08/2022 06:36:18 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.12368421052631579 on epoch=37
06/08/2022 06:36:21 - INFO - __main__ - Step 160 Global step 160 Train loss 0.84 on epoch=39
06/08/2022 06:36:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=42
06/08/2022 06:36:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=44
06/08/2022 06:36:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.84 on epoch=47
06/08/2022 06:36:32 - INFO - __main__ - Step 200 Global step 200 Train loss 0.73 on epoch=49
06/08/2022 06:36:33 - INFO - __main__ - Global step 200 Train loss 0.80 Classification-F1 0.260289227680532 on epoch=49
06/08/2022 06:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.1565276828434723 -> 0.260289227680532 on epoch=49, global_step=200
06/08/2022 06:36:36 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=52
06/08/2022 06:36:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=54
06/08/2022 06:36:41 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=57
06/08/2022 06:36:44 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=59
06/08/2022 06:36:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=62
06/08/2022 06:36:48 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.4464153732446416 on epoch=62
06/08/2022 06:36:48 - INFO - __main__ - Saving model with best Classification-F1: 0.260289227680532 -> 0.4464153732446416 on epoch=62, global_step=250
06/08/2022 06:36:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=64
06/08/2022 06:36:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=67
06/08/2022 06:36:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=69
06/08/2022 06:36:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=72
06/08/2022 06:37:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.29 on epoch=74
06/08/2022 06:37:03 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.46994502808456295 on epoch=74
06/08/2022 06:37:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4464153732446416 -> 0.46994502808456295 on epoch=74, global_step=300
06/08/2022 06:37:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=77
06/08/2022 06:37:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=79
06/08/2022 06:37:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.23 on epoch=82
06/08/2022 06:37:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/08/2022 06:37:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.19 on epoch=87
06/08/2022 06:37:19 - INFO - __main__ - Global step 350 Train loss 0.26 Classification-F1 0.5312045950837362 on epoch=87
06/08/2022 06:37:19 - INFO - __main__ - Saving model with best Classification-F1: 0.46994502808456295 -> 0.5312045950837362 on epoch=87, global_step=350
06/08/2022 06:37:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.20 on epoch=89
06/08/2022 06:37:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.17 on epoch=92
06/08/2022 06:37:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.14 on epoch=94
06/08/2022 06:37:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.14 on epoch=97
06/08/2022 06:37:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.10 on epoch=99
06/08/2022 06:37:34 - INFO - __main__ - Global step 400 Train loss 0.15 Classification-F1 0.5328166457198715 on epoch=99
06/08/2022 06:37:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5312045950837362 -> 0.5328166457198715 on epoch=99, global_step=400
06/08/2022 06:37:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.11 on epoch=102
06/08/2022 06:37:40 - INFO - __main__ - Step 420 Global step 420 Train loss 0.10 on epoch=104
06/08/2022 06:37:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.07 on epoch=107
06/08/2022 06:37:45 - INFO - __main__ - Step 440 Global step 440 Train loss 0.16 on epoch=109
06/08/2022 06:37:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/08/2022 06:37:49 - INFO - __main__ - Global step 450 Train loss 0.11 Classification-F1 0.545138888888889 on epoch=112
06/08/2022 06:37:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5328166457198715 -> 0.545138888888889 on epoch=112, global_step=450
06/08/2022 06:37:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.10 on epoch=114
06/08/2022 06:37:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.02 on epoch=117
06/08/2022 06:37:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.11 on epoch=119
06/08/2022 06:38:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.11 on epoch=122
06/08/2022 06:38:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.04 on epoch=124
06/08/2022 06:38:05 - INFO - __main__ - Global step 500 Train loss 0.08 Classification-F1 0.5232893450635386 on epoch=124
06/08/2022 06:38:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.03 on epoch=127
06/08/2022 06:38:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.04 on epoch=129
06/08/2022 06:38:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.02 on epoch=132
06/08/2022 06:38:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.02 on epoch=134
06/08/2022 06:38:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.03 on epoch=137
06/08/2022 06:38:20 - INFO - __main__ - Global step 550 Train loss 0.03 Classification-F1 0.5496794871794872 on epoch=137
06/08/2022 06:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.545138888888889 -> 0.5496794871794872 on epoch=137, global_step=550
06/08/2022 06:38:23 - INFO - __main__ - Step 560 Global step 560 Train loss 0.02 on epoch=139
06/08/2022 06:38:26 - INFO - __main__ - Step 570 Global step 570 Train loss 0.05 on epoch=142
06/08/2022 06:38:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.01 on epoch=144
06/08/2022 06:38:31 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=147
06/08/2022 06:38:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.01 on epoch=149
06/08/2022 06:38:36 - INFO - __main__ - Global step 600 Train loss 0.02 Classification-F1 0.5118322345031282 on epoch=149
06/08/2022 06:38:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.01 on epoch=152
06/08/2022 06:38:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/08/2022 06:38:44 - INFO - __main__ - Step 630 Global step 630 Train loss 0.01 on epoch=157
06/08/2022 06:38:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.02 on epoch=159
06/08/2022 06:38:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=162
06/08/2022 06:38:51 - INFO - __main__ - Global step 650 Train loss 0.06 Classification-F1 0.4034398034398034 on epoch=162
06/08/2022 06:38:54 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=164
06/08/2022 06:38:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.03 on epoch=167
06/08/2022 06:39:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.03 on epoch=169
06/08/2022 06:39:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.05 on epoch=172
06/08/2022 06:39:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.01 on epoch=174
06/08/2022 06:39:06 - INFO - __main__ - Global step 700 Train loss 0.05 Classification-F1 0.5068941475191475 on epoch=174
06/08/2022 06:39:09 - INFO - __main__ - Step 710 Global step 710 Train loss 0.03 on epoch=177
06/08/2022 06:39:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.02 on epoch=179
06/08/2022 06:39:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/08/2022 06:39:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.01 on epoch=184
06/08/2022 06:39:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/08/2022 06:39:22 - INFO - __main__ - Global step 750 Train loss 0.01 Classification-F1 0.5058960647195941 on epoch=187
06/08/2022 06:39:25 - INFO - __main__ - Step 760 Global step 760 Train loss 0.02 on epoch=189
06/08/2022 06:39:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.01 on epoch=192
06/08/2022 06:39:30 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/08/2022 06:39:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.00 on epoch=197
06/08/2022 06:39:36 - INFO - __main__ - Step 800 Global step 800 Train loss 0.00 on epoch=199
06/08/2022 06:39:37 - INFO - __main__ - Global step 800 Train loss 0.01 Classification-F1 0.5305204397946334 on epoch=199
06/08/2022 06:39:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/08/2022 06:39:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.02 on epoch=204
06/08/2022 06:39:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/08/2022 06:39:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.00 on epoch=209
06/08/2022 06:39:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.00 on epoch=212
06/08/2022 06:39:52 - INFO - __main__ - Global step 850 Train loss 0.02 Classification-F1 0.5965274365274366 on epoch=212
06/08/2022 06:39:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5496794871794872 -> 0.5965274365274366 on epoch=212, global_step=850
06/08/2022 06:39:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.00 on epoch=214
06/08/2022 06:39:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=217
06/08/2022 06:40:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.00 on epoch=219
06/08/2022 06:40:04 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/08/2022 06:40:07 - INFO - __main__ - Step 900 Global step 900 Train loss 0.00 on epoch=224
06/08/2022 06:40:08 - INFO - __main__ - Global step 900 Train loss 0.00 Classification-F1 0.5448842970582102 on epoch=224
06/08/2022 06:40:11 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/08/2022 06:40:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.00 on epoch=229
06/08/2022 06:40:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/08/2022 06:40:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.02 on epoch=234
06/08/2022 06:40:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.00 on epoch=237
06/08/2022 06:40:23 - INFO - __main__ - Global step 950 Train loss 0.01 Classification-F1 0.5079308777666915 on epoch=237
06/08/2022 06:40:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/08/2022 06:40:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.00 on epoch=242
06/08/2022 06:40:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.03 on epoch=244
06/08/2022 06:40:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/08/2022 06:40:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/08/2022 06:40:39 - INFO - __main__ - Global step 1000 Train loss 0.01 Classification-F1 0.5032677000418936 on epoch=249
06/08/2022 06:40:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/08/2022 06:40:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/08/2022 06:40:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/08/2022 06:40:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 06:40:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.00 on epoch=262
06/08/2022 06:40:54 - INFO - __main__ - Global step 1050 Train loss 0.00 Classification-F1 0.5822689075630252 on epoch=262
06/08/2022 06:40:57 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 06:41:00 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/08/2022 06:41:02 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 06:41:05 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 06:41:08 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.01 on epoch=274
06/08/2022 06:41:09 - INFO - __main__ - Global step 1100 Train loss 0.00 Classification-F1 0.5857262897111094 on epoch=274
06/08/2022 06:41:12 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 06:41:15 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/08/2022 06:41:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 06:41:20 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/08/2022 06:41:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 06:41:25 - INFO - __main__ - Global step 1150 Train loss 0.00 Classification-F1 0.49699699699699706 on epoch=287
06/08/2022 06:41:27 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/08/2022 06:41:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 06:41:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 06:41:36 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 06:41:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.00 on epoch=299
06/08/2022 06:41:40 - INFO - __main__ - Global step 1200 Train loss 0.00 Classification-F1 0.5282910543039766 on epoch=299
06/08/2022 06:41:43 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 06:41:45 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 06:41:48 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 06:41:51 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/08/2022 06:41:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=312
06/08/2022 06:41:55 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.49233954451345746 on epoch=312
06/08/2022 06:41:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/08/2022 06:42:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=317
06/08/2022 06:42:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 06:42:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.00 on epoch=322
06/08/2022 06:42:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 06:42:10 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.5154216605829509 on epoch=324
06/08/2022 06:42:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 06:42:16 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=329
06/08/2022 06:42:19 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.00 on epoch=332
06/08/2022 06:42:21 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/08/2022 06:42:24 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 06:42:26 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.559901479019126 on epoch=337
06/08/2022 06:42:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 06:42:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 06:42:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 06:42:37 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=347
06/08/2022 06:42:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 06:42:41 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.546794903340633 on epoch=349
06/08/2022 06:42:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/08/2022 06:42:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 06:42:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 06:42:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/08/2022 06:42:55 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 06:42:56 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.513017168589924 on epoch=362
06/08/2022 06:42:59 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 06:43:02 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 06:43:04 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 06:43:07 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 06:43:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 06:43:11 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.5993819905584612 on epoch=374
06/08/2022 06:43:12 - INFO - __main__ - Saving model with best Classification-F1: 0.5965274365274366 -> 0.5993819905584612 on epoch=374, global_step=1500
06/08/2022 06:43:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 06:43:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 06:43:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 06:43:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.01 on epoch=384
06/08/2022 06:43:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 06:43:27 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.5493243243243243 on epoch=387
06/08/2022 06:43:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 06:43:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 06:43:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 06:43:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 06:43:41 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 06:43:42 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.550523088023088 on epoch=399
06/08/2022 06:43:45 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 06:43:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 06:43:50 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=407
06/08/2022 06:43:53 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 06:43:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 06:43:57 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5968321182462798 on epoch=412
06/08/2022 06:44:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 06:44:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 06:44:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 06:44:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 06:44:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 06:44:12 - INFO - __main__ - Global step 1700 Train loss 0.00 Classification-F1 0.5650176962676964 on epoch=424
06/08/2022 06:44:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 06:44:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 06:44:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 06:44:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/08/2022 06:44:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 06:44:27 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.4980257645580226 on epoch=437
06/08/2022 06:44:30 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 06:44:33 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 06:44:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 06:44:38 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 06:44:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 06:44:43 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.5422868944608075 on epoch=449
06/08/2022 06:44:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 06:44:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 06:44:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 06:44:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 06:44:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 06:44:58 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.5464445423684554 on epoch=462
06/08/2022 06:45:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 06:45:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 06:45:06 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 06:45:09 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 06:45:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 06:45:13 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.5128890717126011 on epoch=474
06/08/2022 06:45:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 06:45:18 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 06:45:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 06:45:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 06:45:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 06:45:28 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.5882822477650064 on epoch=487
06/08/2022 06:45:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 06:45:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 06:45:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/08/2022 06:45:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 06:45:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 06:45:43 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.6247129186602871 on epoch=499
06/08/2022 06:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5993819905584612 -> 0.6247129186602871 on epoch=499, global_step=2000
06/08/2022 06:45:46 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=502
06/08/2022 06:45:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 06:45:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 06:45:54 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 06:45:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 06:45:58 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.5581779952783789 on epoch=512
06/08/2022 06:46:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=514
06/08/2022 06:46:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 06:46:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 06:46:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 06:46:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 06:46:13 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5340038314176245 on epoch=524
06/08/2022 06:46:16 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 06:46:19 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 06:46:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 06:46:24 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 06:46:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 06:46:28 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.5093117310859246 on epoch=537
06/08/2022 06:46:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 06:46:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=542
06/08/2022 06:46:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 06:46:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 06:46:42 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/08/2022 06:46:44 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5578567861779686 on epoch=549
06/08/2022 06:46:46 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 06:46:49 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 06:46:52 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 06:46:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 06:46:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 06:46:59 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.515097576349845 on epoch=562
06/08/2022 06:47:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 06:47:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 06:47:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 06:47:10 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=572
06/08/2022 06:47:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=574
06/08/2022 06:47:14 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5121485121485121 on epoch=574
06/08/2022 06:47:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 06:47:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 06:47:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 06:47:25 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 06:47:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 06:47:29 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5266431203931204 on epoch=587
06/08/2022 06:47:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 06:47:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=592
06/08/2022 06:47:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 06:47:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 06:47:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 06:47:44 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5800584795321637 on epoch=599
06/08/2022 06:47:47 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 06:47:50 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 06:47:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 06:47:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 06:47:58 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 06:47:59 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5561548313937599 on epoch=612
06/08/2022 06:48:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 06:48:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 06:48:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 06:48:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 06:48:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 06:48:15 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5725626685309098 on epoch=624
06/08/2022 06:48:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 06:48:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 06:48:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 06:48:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 06:48:28 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 06:48:30 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5540344427244581 on epoch=637
06/08/2022 06:48:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 06:48:35 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 06:48:38 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 06:48:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 06:48:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 06:48:45 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5540344427244581 on epoch=649
06/08/2022 06:48:47 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 06:48:50 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 06:48:53 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 06:48:56 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 06:48:59 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 06:49:00 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5464445423684554 on epoch=662
06/08/2022 06:49:03 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 06:49:06 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 06:49:08 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 06:49:11 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 06:49:14 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 06:49:15 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5464445423684554 on epoch=674
06/08/2022 06:49:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 06:49:21 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 06:49:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 06:49:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/08/2022 06:49:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 06:49:30 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5314216247139588 on epoch=687
06/08/2022 06:49:33 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 06:49:36 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=692
06/08/2022 06:49:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 06:49:41 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 06:49:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 06:49:46 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.5130507558272512 on epoch=699
06/08/2022 06:49:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 06:49:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 06:49:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 06:49:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 06:50:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 06:50:01 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.4984336567995203 on epoch=712
06/08/2022 06:50:04 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 06:50:07 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 06:50:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 06:50:12 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 06:50:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 06:50:16 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5329151850890981 on epoch=724
06/08/2022 06:50:19 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 06:50:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 06:50:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 06:50:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 06:50:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 06:50:32 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5500350140056023 on epoch=737
06/08/2022 06:50:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 06:50:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 06:50:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 06:50:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 06:50:46 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 06:50:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:50:47 - INFO - __main__ - Printing 3 examples
06/08/2022 06:50:47 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 06:50:47 - INFO - __main__ - ['happy']
06/08/2022 06:50:47 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 06:50:47 - INFO - __main__ - ['happy']
06/08/2022 06:50:47 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 06:50:47 - INFO - __main__ - ['happy']
06/08/2022 06:50:47 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:50:47 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5175756113256114 on epoch=749
06/08/2022 06:50:47 - INFO - __main__ - save last model!
06/08/2022 06:50:48 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:50:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 06:50:48 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 06:50:48 - INFO - __main__ - Printing 3 examples
06/08/2022 06:50:48 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 06:50:48 - INFO - __main__ - ['others']
06/08/2022 06:50:48 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 06:50:48 - INFO - __main__ - ['others']
06/08/2022 06:50:48 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 06:50:48 - INFO - __main__ - ['others']
06/08/2022 06:50:48 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:50:48 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:50:48 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:50:48 - INFO - __main__ - Printing 3 examples
06/08/2022 06:50:48 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 06:50:48 - INFO - __main__ - ['happy']
06/08/2022 06:50:48 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 06:50:48 - INFO - __main__ - ['happy']
06/08/2022 06:50:48 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 06:50:48 - INFO - __main__ - ['happy']
06/08/2022 06:50:48 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:50:48 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:50:48 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:50:50 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:50:55 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 06:51:04 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:51:04 - INFO - __main__ - task name: emo
06/08/2022 06:51:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:51:04 - INFO - __main__ - Starting training!
06/08/2022 06:52:45 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_42_0.5_8_predictions.txt
06/08/2022 06:52:46 - INFO - __main__ - Classification-F1 on test data: 0.1726
06/08/2022 06:52:46 - INFO - __main__ - prefix=emo_16_42, lr=0.5, bsz=8, dev_performance=0.6247129186602871, test_performance=0.17258788182827722
06/08/2022 06:52:46 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.4, bsz=8 ...
06/08/2022 06:52:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:52:47 - INFO - __main__ - Printing 3 examples
06/08/2022 06:52:47 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:52:47 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:52:47 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 06:52:47 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 06:52:47 - INFO - __main__ - Printing 3 examples
06/08/2022 06:52:47 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 06:52:47 - INFO - __main__ - ['happy']
06/08/2022 06:52:47 - INFO - __main__ - Tokenizing Input ...
06/08/2022 06:52:47 - INFO - __main__ - Tokenizing Output ...
06/08/2022 06:52:47 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 06:53:06 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 06:53:06 - INFO - __main__ - task name: emo
06/08/2022 06:53:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 06:53:07 - INFO - __main__ - Starting training!
06/08/2022 06:53:10 - INFO - __main__ - Step 10 Global step 10 Train loss 6.92 on epoch=2
06/08/2022 06:53:13 - INFO - __main__ - Step 20 Global step 20 Train loss 3.02 on epoch=4
06/08/2022 06:53:16 - INFO - __main__ - Step 30 Global step 30 Train loss 1.49 on epoch=7
06/08/2022 06:53:18 - INFO - __main__ - Step 40 Global step 40 Train loss 1.26 on epoch=9
06/08/2022 06:53:21 - INFO - __main__ - Step 50 Global step 50 Train loss 1.01 on epoch=12
06/08/2022 06:53:22 - INFO - __main__ - Global step 50 Train loss 2.74 Classification-F1 0.1795366795366795 on epoch=12
06/08/2022 06:53:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1795366795366795 on epoch=12, global_step=50
06/08/2022 06:53:25 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=14
06/08/2022 06:53:28 - INFO - __main__ - Step 70 Global step 70 Train loss 0.94 on epoch=17
06/08/2022 06:53:31 - INFO - __main__ - Step 80 Global step 80 Train loss 0.85 on epoch=19
06/08/2022 06:53:34 - INFO - __main__ - Step 90 Global step 90 Train loss 0.89 on epoch=22
06/08/2022 06:53:36 - INFO - __main__ - Step 100 Global step 100 Train loss 0.97 on epoch=24
06/08/2022 06:53:37 - INFO - __main__ - Global step 100 Train loss 0.94 Classification-F1 0.21485380116959063 on epoch=24
06/08/2022 06:53:38 - INFO - __main__ - Saving model with best Classification-F1: 0.1795366795366795 -> 0.21485380116959063 on epoch=24, global_step=100
06/08/2022 06:53:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.84 on epoch=27
06/08/2022 06:53:43 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=29
06/08/2022 06:53:46 - INFO - __main__ - Step 130 Global step 130 Train loss 0.58 on epoch=32
06/08/2022 06:53:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.67 on epoch=34
06/08/2022 06:53:51 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=37
06/08/2022 06:53:52 - INFO - __main__ - Global step 150 Train loss 0.72 Classification-F1 0.45769850117676203 on epoch=37
06/08/2022 06:53:53 - INFO - __main__ - Saving model with best Classification-F1: 0.21485380116959063 -> 0.45769850117676203 on epoch=37, global_step=150
06/08/2022 06:53:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=39
06/08/2022 06:53:58 - INFO - __main__ - Step 170 Global step 170 Train loss 0.59 on epoch=42
06/08/2022 06:54:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=44
06/08/2022 06:54:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.47 on epoch=47
06/08/2022 06:54:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.49 on epoch=49
06/08/2022 06:54:07 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.37370883291507884 on epoch=49
06/08/2022 06:54:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.41 on epoch=52
06/08/2022 06:54:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.50 on epoch=54
06/08/2022 06:54:16 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=57
06/08/2022 06:54:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=59
06/08/2022 06:54:21 - INFO - __main__ - Step 250 Global step 250 Train loss 0.44 on epoch=62
06/08/2022 06:54:22 - INFO - __main__ - Global step 250 Train loss 0.45 Classification-F1 0.5690517578889671 on epoch=62
06/08/2022 06:54:22 - INFO - __main__ - Saving model with best Classification-F1: 0.45769850117676203 -> 0.5690517578889671 on epoch=62, global_step=250
06/08/2022 06:54:25 - INFO - __main__ - Step 260 Global step 260 Train loss 0.38 on epoch=64
06/08/2022 06:54:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.36 on epoch=67
06/08/2022 06:54:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.27 on epoch=69
06/08/2022 06:54:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=72
06/08/2022 06:54:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=74
06/08/2022 06:54:37 - INFO - __main__ - Global step 300 Train loss 0.34 Classification-F1 0.47026471590425084 on epoch=74
06/08/2022 06:54:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.33 on epoch=77
06/08/2022 06:54:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=79
06/08/2022 06:54:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=82
06/08/2022 06:54:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.19 on epoch=84
06/08/2022 06:54:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.23 on epoch=87
06/08/2022 06:54:52 - INFO - __main__ - Global step 350 Train loss 0.27 Classification-F1 0.4228728377746611 on epoch=87
06/08/2022 06:54:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.23 on epoch=89
06/08/2022 06:54:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.18 on epoch=92
06/08/2022 06:55:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.18 on epoch=94
06/08/2022 06:55:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.10 on epoch=97
06/08/2022 06:55:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.13 on epoch=99
06/08/2022 06:55:07 - INFO - __main__ - Global step 400 Train loss 0.16 Classification-F1 0.5574270405836753 on epoch=99
06/08/2022 06:55:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.13 on epoch=102
06/08/2022 06:55:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=104
06/08/2022 06:55:15 - INFO - __main__ - Step 430 Global step 430 Train loss 0.18 on epoch=107
06/08/2022 06:55:18 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=109
06/08/2022 06:55:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.06 on epoch=112
06/08/2022 06:55:22 - INFO - __main__ - Global step 450 Train loss 0.14 Classification-F1 0.43919423508200545 on epoch=112
06/08/2022 06:55:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.11 on epoch=114
06/08/2022 06:55:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.12 on epoch=117
06/08/2022 06:55:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.10 on epoch=119
06/08/2022 06:55:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.09 on epoch=122
06/08/2022 06:55:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.16 on epoch=124
06/08/2022 06:55:37 - INFO - __main__ - Global step 500 Train loss 0.11 Classification-F1 0.5734427609427608 on epoch=124
06/08/2022 06:55:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5690517578889671 -> 0.5734427609427608 on epoch=124, global_step=500
06/08/2022 06:55:40 - INFO - __main__ - Step 510 Global step 510 Train loss 0.05 on epoch=127
06/08/2022 06:55:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.06 on epoch=129
06/08/2022 06:55:45 - INFO - __main__ - Step 530 Global step 530 Train loss 0.06 on epoch=132
06/08/2022 06:55:48 - INFO - __main__ - Step 540 Global step 540 Train loss 0.06 on epoch=134
06/08/2022 06:55:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=137
06/08/2022 06:55:52 - INFO - __main__ - Global step 550 Train loss 0.05 Classification-F1 0.4593088071348941 on epoch=137
06/08/2022 06:55:55 - INFO - __main__ - Step 560 Global step 560 Train loss 0.06 on epoch=139
06/08/2022 06:55:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=142
06/08/2022 06:56:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.06 on epoch=144
06/08/2022 06:56:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.01 on epoch=147
06/08/2022 06:56:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.06 on epoch=149
06/08/2022 06:56:07 - INFO - __main__ - Global step 600 Train loss 0.06 Classification-F1 0.5355782428953161 on epoch=149
06/08/2022 06:56:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.10 on epoch=152
06/08/2022 06:56:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.05 on epoch=154
06/08/2022 06:56:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.05 on epoch=157
06/08/2022 06:56:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=159
06/08/2022 06:56:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/08/2022 06:56:22 - INFO - __main__ - Global step 650 Train loss 0.07 Classification-F1 0.550379791556262 on epoch=162
06/08/2022 06:56:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=164
06/08/2022 06:56:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.04 on epoch=167
06/08/2022 06:56:30 - INFO - __main__ - Step 680 Global step 680 Train loss 0.01 on epoch=169
06/08/2022 06:56:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/08/2022 06:56:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/08/2022 06:56:37 - INFO - __main__ - Global step 700 Train loss 0.03 Classification-F1 0.44343980343980344 on epoch=174
06/08/2022 06:56:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/08/2022 06:56:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.01 on epoch=179
06/08/2022 06:56:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/08/2022 06:56:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/08/2022 06:56:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.01 on epoch=187
06/08/2022 06:56:52 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.5160839160839161 on epoch=187
06/08/2022 06:56:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/08/2022 06:56:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.00 on epoch=192
06/08/2022 06:57:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/08/2022 06:57:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/08/2022 06:57:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/08/2022 06:57:07 - INFO - __main__ - Global step 800 Train loss 0.02 Classification-F1 0.5121259102654451 on epoch=199
06/08/2022 06:57:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/08/2022 06:57:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=204
06/08/2022 06:57:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.01 on epoch=207
06/08/2022 06:57:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.03 on epoch=209
06/08/2022 06:57:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.04 on epoch=212
06/08/2022 06:57:22 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.5518018018018017 on epoch=212
06/08/2022 06:57:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/08/2022 06:57:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.01 on epoch=217
06/08/2022 06:57:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 06:57:33 - INFO - __main__ - Step 890 Global step 890 Train loss 0.01 on epoch=222
06/08/2022 06:57:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.03 on epoch=224
06/08/2022 06:57:37 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.5523990241257793 on epoch=224
06/08/2022 06:57:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.02 on epoch=227
06/08/2022 06:57:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=229
06/08/2022 06:57:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/08/2022 06:57:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/08/2022 06:57:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/08/2022 06:57:52 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.49845351817334577 on epoch=237
06/08/2022 06:57:55 - INFO - __main__ - Step 960 Global step 960 Train loss 0.05 on epoch=239
06/08/2022 06:57:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=242
06/08/2022 06:58:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.02 on epoch=244
06/08/2022 06:58:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.00 on epoch=247
06/08/2022 06:58:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 06:58:07 - INFO - __main__ - Global step 1000 Train loss 0.03 Classification-F1 0.5546128707893414 on epoch=249
06/08/2022 06:58:10 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/08/2022 06:58:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.01 on epoch=254
06/08/2022 06:58:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.00 on epoch=257
06/08/2022 06:58:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=259
06/08/2022 06:58:21 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/08/2022 06:58:22 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.583855212887471 on epoch=262
06/08/2022 06:58:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5734427609427608 -> 0.583855212887471 on epoch=262, global_step=1050
06/08/2022 06:58:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.02 on epoch=264
06/08/2022 06:58:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/08/2022 06:58:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 06:58:34 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 06:58:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/08/2022 06:58:38 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6026455026455027 on epoch=274
06/08/2022 06:58:38 - INFO - __main__ - Saving model with best Classification-F1: 0.583855212887471 -> 0.6026455026455027 on epoch=274, global_step=1100
06/08/2022 06:58:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.00 on epoch=277
06/08/2022 06:58:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.00 on epoch=279
06/08/2022 06:58:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 06:58:49 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/08/2022 06:58:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 06:58:53 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.523379713651946 on epoch=287
06/08/2022 06:58:55 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/08/2022 06:58:58 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 06:59:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.00 on epoch=294
06/08/2022 06:59:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.00 on epoch=297
06/08/2022 06:59:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 06:59:08 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.5659832246039143 on epoch=299
06/08/2022 06:59:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.00 on epoch=302
06/08/2022 06:59:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 06:59:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.01 on epoch=307
06/08/2022 06:59:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/08/2022 06:59:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 06:59:23 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.5695415695415695 on epoch=312
06/08/2022 06:59:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 06:59:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.01 on epoch=317
06/08/2022 06:59:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.00 on epoch=319
06/08/2022 06:59:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=322
06/08/2022 06:59:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 06:59:38 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.5120465190124633 on epoch=324
06/08/2022 06:59:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 06:59:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/08/2022 06:59:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 06:59:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/08/2022 06:59:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 06:59:53 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.5256595256595257 on epoch=337
06/08/2022 06:59:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 06:59:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 07:00:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 07:00:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 07:00:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 07:00:08 - INFO - __main__ - Global step 1400 Train loss 0.00 Classification-F1 0.505028735632184 on epoch=349
06/08/2022 07:00:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 07:00:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=354
06/08/2022 07:00:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 07:00:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 07:00:22 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.00 on epoch=362
06/08/2022 07:00:23 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.5545365099444796 on epoch=362
06/08/2022 07:00:26 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 07:00:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 07:00:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 07:00:34 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 07:00:37 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/08/2022 07:00:38 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.5512659854765118 on epoch=374
06/08/2022 07:00:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 07:00:43 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/08/2022 07:00:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 07:00:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=384
06/08/2022 07:00:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 07:00:53 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5694991283226578 on epoch=387
06/08/2022 07:00:55 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 07:00:58 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/08/2022 07:01:01 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 07:01:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 07:01:06 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=399
06/08/2022 07:01:08 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.5692982456140351 on epoch=399
06/08/2022 07:01:11 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=402
06/08/2022 07:01:13 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 07:01:16 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 07:01:19 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=409
06/08/2022 07:01:21 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=412
06/08/2022 07:01:23 - INFO - __main__ - Global step 1650 Train loss 0.02 Classification-F1 0.5524539512774808 on epoch=412
06/08/2022 07:01:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=414
06/08/2022 07:01:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 07:01:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/08/2022 07:01:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=422
06/08/2022 07:01:37 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/08/2022 07:01:38 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5318738995786958 on epoch=424
06/08/2022 07:01:41 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 07:01:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/08/2022 07:01:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 07:01:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 07:01:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 07:01:53 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5164628914628915 on epoch=437
06/08/2022 07:01:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 07:01:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 07:02:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 07:02:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 07:02:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 07:02:08 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.5693187531422825 on epoch=449
06/08/2022 07:02:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/08/2022 07:02:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/08/2022 07:02:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 07:02:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 07:02:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 07:02:23 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.5957880512908976 on epoch=462
06/08/2022 07:02:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 07:02:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 07:02:32 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 07:02:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 07:02:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 07:02:38 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6104594330400782 on epoch=474
06/08/2022 07:02:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6026455026455027 -> 0.6104594330400782 on epoch=474, global_step=1900
06/08/2022 07:02:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 07:02:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 07:02:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/08/2022 07:02:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 07:02:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=487
06/08/2022 07:02:53 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5673499972501788 on epoch=487
06/08/2022 07:02:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 07:02:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 07:03:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 07:03:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 07:03:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=499
06/08/2022 07:03:08 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5199234189723321 on epoch=499
06/08/2022 07:03:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 07:03:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=504
06/08/2022 07:03:17 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 07:03:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 07:03:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 07:03:23 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5586080586080586 on epoch=512
06/08/2022 07:03:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 07:03:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 07:03:32 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 07:03:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 07:03:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 07:03:39 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6254556954746708 on epoch=524
06/08/2022 07:03:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6104594330400782 -> 0.6254556954746708 on epoch=524, global_step=2100
06/08/2022 07:03:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/08/2022 07:03:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 07:03:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/08/2022 07:03:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 07:03:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 07:03:54 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.5669264069264068 on epoch=537
06/08/2022 07:03:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 07:03:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 07:04:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/08/2022 07:04:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/08/2022 07:04:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 07:04:09 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5668767507002801 on epoch=549
06/08/2022 07:04:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 07:04:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 07:04:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 07:04:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/08/2022 07:04:22 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 07:04:24 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5525910364145659 on epoch=562
06/08/2022 07:04:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 07:04:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 07:04:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 07:04:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 07:04:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/08/2022 07:04:38 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.5376623376623376 on epoch=574
06/08/2022 07:04:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 07:04:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 07:04:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 07:04:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 07:04:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 07:04:53 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.46679738562091505 on epoch=587
06/08/2022 07:04:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 07:04:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 07:05:01 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 07:05:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 07:05:06 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 07:05:08 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5667368667368667 on epoch=599
06/08/2022 07:05:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 07:05:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 07:05:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 07:05:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/08/2022 07:05:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 07:05:22 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5528138528138529 on epoch=612
06/08/2022 07:05:25 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 07:05:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 07:05:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 07:05:33 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 07:05:36 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 07:05:37 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6284382284382284 on epoch=624
06/08/2022 07:05:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6254556954746708 -> 0.6284382284382284 on epoch=624, global_step=2500
06/08/2022 07:05:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 07:05:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 07:05:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 07:05:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=634
06/08/2022 07:05:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 07:05:52 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5967958626468082 on epoch=637
06/08/2022 07:05:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 07:05:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 07:06:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 07:06:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 07:06:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 07:06:07 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5820075757575757 on epoch=649
06/08/2022 07:06:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 07:06:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 07:06:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=657
06/08/2022 07:06:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 07:06:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 07:06:22 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.5806612118531623 on epoch=662
06/08/2022 07:06:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 07:06:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 07:06:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 07:06:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 07:06:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 07:06:37 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5664799253034547 on epoch=674
06/08/2022 07:06:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 07:06:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 07:06:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 07:06:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 07:06:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 07:06:52 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5679298642533936 on epoch=687
06/08/2022 07:06:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 07:06:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 07:07:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 07:07:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 07:07:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 07:07:07 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5702991452991453 on epoch=699
06/08/2022 07:07:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 07:07:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 07:07:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 07:07:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 07:07:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 07:07:22 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5535714285714286 on epoch=712
06/08/2022 07:07:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 07:07:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 07:07:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 07:07:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 07:07:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 07:07:36 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5938191065900044 on epoch=724
06/08/2022 07:07:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 07:07:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 07:07:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 07:07:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 07:07:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 07:07:51 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5650124069478909 on epoch=737
06/08/2022 07:07:54 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 07:07:57 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 07:08:00 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 07:08:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 07:08:05 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 07:08:07 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5804513027295285 on epoch=749
06/08/2022 07:08:07 - INFO - __main__ - save last model!
06/08/2022 07:08:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:08:07 - INFO - __main__ - Printing 3 examples
06/08/2022 07:08:07 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:08:07 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:08:07 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 07:08:07 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 07:08:07 - INFO - __main__ - Printing 3 examples
06/08/2022 07:08:07 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 07:08:07 - INFO - __main__ - ['others']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 07:08:07 - INFO - __main__ - ['others']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 07:08:07 - INFO - __main__ - ['others']
06/08/2022 07:08:07 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:08:07 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:08:07 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:08:07 - INFO - __main__ - Printing 3 examples
06/08/2022 07:08:07 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 07:08:07 - INFO - __main__ - ['happy']
06/08/2022 07:08:07 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:08:07 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:08:07 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:08:09 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:08:14 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 07:08:22 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:08:22 - INFO - __main__ - task name: emo
06/08/2022 07:08:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:08:23 - INFO - __main__ - Starting training!
06/08/2022 07:10:04 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_42_0.4_8_predictions.txt
06/08/2022 07:10:04 - INFO - __main__ - Classification-F1 on test data: 0.2480
06/08/2022 07:10:04 - INFO - __main__ - prefix=emo_16_42, lr=0.4, bsz=8, dev_performance=0.6284382284382284, test_performance=0.2480248653747798
06/08/2022 07:10:04 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.3, bsz=8 ...
06/08/2022 07:10:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:10:05 - INFO - __main__ - Printing 3 examples
06/08/2022 07:10:05 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:10:05 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:10:05 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:10:05 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:10:05 - INFO - __main__ - Printing 3 examples
06/08/2022 07:10:05 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 07:10:05 - INFO - __main__ - ['happy']
06/08/2022 07:10:05 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:10:05 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:10:05 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:10:25 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:10:25 - INFO - __main__ - task name: emo
06/08/2022 07:10:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:10:26 - INFO - __main__ - Starting training!
06/08/2022 07:10:29 - INFO - __main__ - Step 10 Global step 10 Train loss 6.89 on epoch=2
06/08/2022 07:10:32 - INFO - __main__ - Step 20 Global step 20 Train loss 3.70 on epoch=4
06/08/2022 07:10:34 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/08/2022 07:10:37 - INFO - __main__ - Step 40 Global step 40 Train loss 1.50 on epoch=9
06/08/2022 07:10:40 - INFO - __main__ - Step 50 Global step 50 Train loss 1.18 on epoch=12
06/08/2022 07:10:41 - INFO - __main__ - Global step 50 Train loss 3.06 Classification-F1 0.10126582278481013 on epoch=12
06/08/2022 07:10:41 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10126582278481013 on epoch=12, global_step=50
06/08/2022 07:10:44 - INFO - __main__ - Step 60 Global step 60 Train loss 1.25 on epoch=14
06/08/2022 07:10:46 - INFO - __main__ - Step 70 Global step 70 Train loss 1.14 on epoch=17
06/08/2022 07:10:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.99 on epoch=19
06/08/2022 07:10:52 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=22
06/08/2022 07:10:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=24
06/08/2022 07:10:56 - INFO - __main__ - Global step 100 Train loss 1.08 Classification-F1 0.1 on epoch=24
06/08/2022 07:10:58 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=27
06/08/2022 07:11:01 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=29
06/08/2022 07:11:04 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/08/2022 07:11:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.96 on epoch=34
06/08/2022 07:11:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.95 on epoch=37
06/08/2022 07:11:10 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.32290513104466595 on epoch=37
06/08/2022 07:11:11 - INFO - __main__ - Saving model with best Classification-F1: 0.10126582278481013 -> 0.32290513104466595 on epoch=37, global_step=150
06/08/2022 07:11:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=39
06/08/2022 07:11:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.90 on epoch=42
06/08/2022 07:11:19 - INFO - __main__ - Step 180 Global step 180 Train loss 1.03 on epoch=44
06/08/2022 07:11:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=47
06/08/2022 07:11:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.89 on epoch=49
06/08/2022 07:11:25 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.25480859010270773 on epoch=49
06/08/2022 07:11:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.84 on epoch=52
06/08/2022 07:11:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=54
06/08/2022 07:11:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.94 on epoch=57
06/08/2022 07:11:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.85 on epoch=59
06/08/2022 07:11:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.76 on epoch=62
06/08/2022 07:11:40 - INFO - __main__ - Global step 250 Train loss 0.84 Classification-F1 0.10389610389610389 on epoch=62
06/08/2022 07:11:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.75 on epoch=64
06/08/2022 07:11:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=67
06/08/2022 07:11:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=69
06/08/2022 07:11:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=72
06/08/2022 07:11:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=74
06/08/2022 07:11:54 - INFO - __main__ - Global step 300 Train loss 0.76 Classification-F1 0.22520999468367886 on epoch=74
06/08/2022 07:11:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.64 on epoch=77
06/08/2022 07:12:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=79
06/08/2022 07:12:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.63 on epoch=82
06/08/2022 07:12:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=84
06/08/2022 07:12:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=87
06/08/2022 07:12:09 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.3460810810810811 on epoch=87
06/08/2022 07:12:09 - INFO - __main__ - Saving model with best Classification-F1: 0.32290513104466595 -> 0.3460810810810811 on epoch=87, global_step=350
06/08/2022 07:12:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=89
06/08/2022 07:12:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=92
06/08/2022 07:12:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=94
06/08/2022 07:12:20 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=97
06/08/2022 07:12:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=99
06/08/2022 07:12:24 - INFO - __main__ - Global step 400 Train loss 0.48 Classification-F1 0.5122294372294373 on epoch=99
06/08/2022 07:12:24 - INFO - __main__ - Saving model with best Classification-F1: 0.3460810810810811 -> 0.5122294372294373 on epoch=99, global_step=400
06/08/2022 07:12:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=102
06/08/2022 07:12:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.50 on epoch=104
06/08/2022 07:12:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=107
06/08/2022 07:12:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=109
06/08/2022 07:12:38 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=112
06/08/2022 07:12:39 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.4448779883562492 on epoch=112
06/08/2022 07:12:41 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=114
06/08/2022 07:12:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=117
06/08/2022 07:12:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=119
06/08/2022 07:12:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=122
06/08/2022 07:12:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=124
06/08/2022 07:12:54 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.43978354978354983 on epoch=124
06/08/2022 07:12:57 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=127
06/08/2022 07:12:59 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=129
06/08/2022 07:13:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=132
06/08/2022 07:13:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.15 on epoch=134
06/08/2022 07:13:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=137
06/08/2022 07:13:09 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.46457489878542507 on epoch=137
06/08/2022 07:13:11 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=139
06/08/2022 07:13:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=142
06/08/2022 07:13:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=144
06/08/2022 07:13:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/08/2022 07:13:22 - INFO - __main__ - Step 600 Global step 600 Train loss 0.16 on epoch=149
06/08/2022 07:13:23 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.454935064935065 on epoch=149
06/08/2022 07:13:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=152
06/08/2022 07:13:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/08/2022 07:13:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.06 on epoch=157
06/08/2022 07:13:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=159
06/08/2022 07:13:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.07 on epoch=162
06/08/2022 07:13:38 - INFO - __main__ - Global step 650 Train loss 0.13 Classification-F1 0.46082858868184956 on epoch=162
06/08/2022 07:13:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=164
06/08/2022 07:13:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=167
06/08/2022 07:13:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=169
06/08/2022 07:13:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.09 on epoch=172
06/08/2022 07:13:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=174
06/08/2022 07:13:53 - INFO - __main__ - Global step 700 Train loss 0.12 Classification-F1 0.41093292639394585 on epoch=174
06/08/2022 07:13:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
06/08/2022 07:13:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=179
06/08/2022 07:14:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=182
06/08/2022 07:14:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.06 on epoch=184
06/08/2022 07:14:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=187
06/08/2022 07:14:08 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.41205204662510164 on epoch=187
06/08/2022 07:14:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.06 on epoch=189
06/08/2022 07:14:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.02 on epoch=192
06/08/2022 07:14:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=194
06/08/2022 07:14:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.04 on epoch=197
06/08/2022 07:14:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/08/2022 07:14:24 - INFO - __main__ - Global step 800 Train loss 0.05 Classification-F1 0.38719578993494463 on epoch=199
06/08/2022 07:14:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.01 on epoch=202
06/08/2022 07:14:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.09 on epoch=204
06/08/2022 07:14:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/08/2022 07:14:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=209
06/08/2022 07:14:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/08/2022 07:14:39 - INFO - __main__ - Global step 850 Train loss 0.06 Classification-F1 0.3833921107628004 on epoch=212
06/08/2022 07:14:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/08/2022 07:14:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.04 on epoch=217
06/08/2022 07:14:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.03 on epoch=219
06/08/2022 07:14:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/08/2022 07:14:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=224
06/08/2022 07:14:54 - INFO - __main__ - Global step 900 Train loss 0.04 Classification-F1 0.4620311432373143 on epoch=224
06/08/2022 07:14:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=227
06/08/2022 07:14:59 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/08/2022 07:15:02 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/08/2022 07:15:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/08/2022 07:15:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=237
06/08/2022 07:15:09 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.4457677738927739 on epoch=237
06/08/2022 07:15:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/08/2022 07:15:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=242
06/08/2022 07:15:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=244
06/08/2022 07:15:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/08/2022 07:15:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=249
06/08/2022 07:15:24 - INFO - __main__ - Global step 1000 Train loss 0.06 Classification-F1 0.4602184637068357 on epoch=249
06/08/2022 07:15:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=252
06/08/2022 07:15:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.02 on epoch=254
06/08/2022 07:15:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/08/2022 07:15:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 07:15:38 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/08/2022 07:15:39 - INFO - __main__ - Global step 1050 Train loss 0.03 Classification-F1 0.6105897199647199 on epoch=262
06/08/2022 07:15:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5122294372294373 -> 0.6105897199647199 on epoch=262, global_step=1050
06/08/2022 07:15:42 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.03 on epoch=264
06/08/2022 07:15:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/08/2022 07:15:47 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.01 on epoch=269
06/08/2022 07:15:50 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.02 on epoch=272
06/08/2022 07:15:53 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/08/2022 07:15:54 - INFO - __main__ - Global step 1100 Train loss 0.02 Classification-F1 0.4709030427967834 on epoch=274
06/08/2022 07:15:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.02 on epoch=277
06/08/2022 07:16:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/08/2022 07:16:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=282
06/08/2022 07:16:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/08/2022 07:16:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 07:16:10 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.5151453334957171 on epoch=287
06/08/2022 07:16:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.01 on epoch=289
06/08/2022 07:16:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 07:16:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 07:16:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=297
06/08/2022 07:16:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 07:16:25 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.5177845528455285 on epoch=299
06/08/2022 07:16:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.01 on epoch=302
06/08/2022 07:16:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 07:16:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 07:16:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.01 on epoch=309
06/08/2022 07:16:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=312
06/08/2022 07:16:40 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.47227564102564096 on epoch=312
06/08/2022 07:16:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 07:16:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/08/2022 07:16:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 07:16:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/08/2022 07:16:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 07:16:55 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5302846747186496 on epoch=324
06/08/2022 07:16:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=327
06/08/2022 07:17:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/08/2022 07:17:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 07:17:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=334
06/08/2022 07:17:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.00 on epoch=337
06/08/2022 07:17:10 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.5635461760461761 on epoch=337
06/08/2022 07:17:13 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 07:17:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 07:17:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 07:17:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 07:17:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=349
06/08/2022 07:17:26 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.5091122742200329 on epoch=349
06/08/2022 07:17:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=352
06/08/2022 07:17:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=354
06/08/2022 07:17:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.01 on epoch=357
06/08/2022 07:17:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=359
06/08/2022 07:17:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/08/2022 07:17:41 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.5271217921989311 on epoch=362
06/08/2022 07:17:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/08/2022 07:17:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 07:17:49 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 07:17:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=372
06/08/2022 07:17:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 07:17:56 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.5036772196145012 on epoch=374
06/08/2022 07:17:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 07:18:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 07:18:04 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 07:18:07 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 07:18:10 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=387
06/08/2022 07:18:12 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.48192996524993315 on epoch=387
06/08/2022 07:18:14 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 07:18:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=392
06/08/2022 07:18:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.01 on epoch=394
06/08/2022 07:18:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 07:18:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=399
06/08/2022 07:18:27 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.5687758478081059 on epoch=399
06/08/2022 07:18:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 07:18:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=404
06/08/2022 07:18:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 07:18:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 07:18:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 07:18:42 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.4985842985842986 on epoch=412
06/08/2022 07:18:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 07:18:48 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=417
06/08/2022 07:18:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=419
06/08/2022 07:18:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=422
06/08/2022 07:18:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 07:18:58 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.567358193277311 on epoch=424
06/08/2022 07:19:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 07:19:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 07:19:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/08/2022 07:19:09 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/08/2022 07:19:12 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/08/2022 07:19:13 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.5140356591969495 on epoch=437
06/08/2022 07:19:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 07:19:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=442
06/08/2022 07:19:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=444
06/08/2022 07:19:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 07:19:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 07:19:28 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.5203258145363409 on epoch=449
06/08/2022 07:19:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 07:19:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 07:19:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/08/2022 07:19:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 07:19:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 07:19:44 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.5244885174913638 on epoch=462
06/08/2022 07:19:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 07:19:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 07:19:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=469
06/08/2022 07:19:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 07:19:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=474
06/08/2022 07:19:59 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.5643319237069238 on epoch=474
06/08/2022 07:20:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 07:20:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 07:20:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 07:20:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/08/2022 07:20:13 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 07:20:14 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.5837384160554893 on epoch=487
06/08/2022 07:20:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=489
06/08/2022 07:20:20 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=492
06/08/2022 07:20:23 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=494
06/08/2022 07:20:26 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 07:20:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=499
06/08/2022 07:20:30 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.511469180973825 on epoch=499
06/08/2022 07:20:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 07:20:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/08/2022 07:20:38 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 07:20:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 07:20:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/08/2022 07:20:45 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.5401669316375199 on epoch=512
06/08/2022 07:20:48 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=514
06/08/2022 07:20:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=517
06/08/2022 07:20:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 07:20:56 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=522
06/08/2022 07:20:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 07:21:00 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5479720990391722 on epoch=524
06/08/2022 07:21:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 07:21:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 07:21:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 07:21:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 07:21:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 07:21:16 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6039257690870594 on epoch=537
06/08/2022 07:21:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/08/2022 07:21:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 07:21:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=544
06/08/2022 07:21:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/08/2022 07:21:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 07:21:31 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5855337191544088 on epoch=549
06/08/2022 07:21:34 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/08/2022 07:21:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=554
06/08/2022 07:21:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 07:21:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 07:21:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 07:21:46 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.5675702545068929 on epoch=562
06/08/2022 07:21:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 07:21:52 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=567
06/08/2022 07:21:54 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 07:21:57 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 07:22:00 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 07:22:01 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.549556894718185 on epoch=574
06/08/2022 07:22:04 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 07:22:07 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 07:22:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 07:22:12 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 07:22:15 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=587
06/08/2022 07:22:16 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.5582862903225807 on epoch=587
06/08/2022 07:22:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/08/2022 07:22:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 07:22:25 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 07:22:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=597
06/08/2022 07:22:30 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 07:22:32 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5708740096208262 on epoch=599
06/08/2022 07:22:34 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/08/2022 07:22:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 07:22:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 07:22:42 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 07:22:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 07:22:47 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.5698132149745052 on epoch=612
06/08/2022 07:22:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=614
06/08/2022 07:22:52 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 07:22:55 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 07:22:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 07:23:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 07:23:02 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6151380544169918 on epoch=624
06/08/2022 07:23:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6105897199647199 -> 0.6151380544169918 on epoch=624, global_step=2500
06/08/2022 07:23:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 07:23:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 07:23:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 07:23:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 07:23:16 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=637
06/08/2022 07:23:17 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5508774148480031 on epoch=637
06/08/2022 07:23:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 07:23:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 07:23:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=644
06/08/2022 07:23:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 07:23:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 07:23:32 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5528044871794872 on epoch=649
06/08/2022 07:23:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 07:23:38 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 07:23:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=657
06/08/2022 07:23:43 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/08/2022 07:23:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 07:23:48 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5699978916297702 on epoch=662
06/08/2022 07:23:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=664
06/08/2022 07:23:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 07:23:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 07:23:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 07:24:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/08/2022 07:24:03 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5699978916297702 on epoch=674
06/08/2022 07:24:05 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 07:24:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 07:24:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=682
06/08/2022 07:24:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/08/2022 07:24:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 07:24:18 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5833682446585673 on epoch=687
06/08/2022 07:24:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 07:24:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 07:24:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 07:24:29 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 07:24:32 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 07:24:33 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.5816701680672269 on epoch=699
06/08/2022 07:24:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 07:24:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 07:24:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 07:24:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 07:24:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 07:24:48 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6252801120448179 on epoch=712
06/08/2022 07:24:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6151380544169918 -> 0.6252801120448179 on epoch=712, global_step=2850
06/08/2022 07:24:51 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 07:24:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=717
06/08/2022 07:24:56 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/08/2022 07:24:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 07:25:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 07:25:03 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.5734513964737089 on epoch=724
06/08/2022 07:25:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 07:25:09 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 07:25:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 07:25:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 07:25:17 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 07:25:18 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5583874458874459 on epoch=737
06/08/2022 07:25:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 07:25:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 07:25:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 07:25:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 07:25:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=749
06/08/2022 07:25:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:25:33 - INFO - __main__ - Printing 3 examples
06/08/2022 07:25:33 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:25:33 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:25:33 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.5440263554814638 on epoch=749
06/08/2022 07:25:33 - INFO - __main__ - save last model!
06/08/2022 07:25:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 07:25:33 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 07:25:33 - INFO - __main__ - Printing 3 examples
06/08/2022 07:25:33 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 07:25:33 - INFO - __main__ - ['others']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 07:25:33 - INFO - __main__ - ['others']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 07:25:33 - INFO - __main__ - ['others']
06/08/2022 07:25:33 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:25:33 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:25:33 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:25:33 - INFO - __main__ - Printing 3 examples
06/08/2022 07:25:33 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 07:25:33 - INFO - __main__ - ['happy']
06/08/2022 07:25:33 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:25:33 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:25:34 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:25:36 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:25:41 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 07:25:52 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:25:52 - INFO - __main__ - task name: emo
06/08/2022 07:25:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:25:53 - INFO - __main__ - Starting training!
06/08/2022 07:27:30 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_42_0.3_8_predictions.txt
06/08/2022 07:27:30 - INFO - __main__ - Classification-F1 on test data: 0.2775
06/08/2022 07:27:30 - INFO - __main__ - prefix=emo_16_42, lr=0.3, bsz=8, dev_performance=0.6252801120448179, test_performance=0.27752166368706405
06/08/2022 07:27:30 - INFO - __main__ - Running ... prefix=emo_16_42, lr=0.2, bsz=8 ...
06/08/2022 07:27:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:27:31 - INFO - __main__ - Printing 3 examples
06/08/2022 07:27:31 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ -  [emo] your right i'm always right i am impressed
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:27:31 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:27:31 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:27:31 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:27:31 - INFO - __main__ - Printing 3 examples
06/08/2022 07:27:31 - INFO - __main__ -  [emo] i am happy i love u so much you  love me
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ -  [emo] yes because of shame to shame how and why are you saying shame i laughed because for the sentence you told shame to shame
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ -  [emo] excellent dvd fm 2 on a dvd everybody
06/08/2022 07:27:31 - INFO - __main__ - ['happy']
06/08/2022 07:27:31 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:27:31 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:27:31 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:27:51 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:27:51 - INFO - __main__ - task name: emo
06/08/2022 07:27:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:27:52 - INFO - __main__ - Starting training!
06/08/2022 07:27:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.97 on epoch=2
06/08/2022 07:27:58 - INFO - __main__ - Step 20 Global step 20 Train loss 4.18 on epoch=4
06/08/2022 07:28:01 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=7
06/08/2022 07:28:04 - INFO - __main__ - Step 40 Global step 40 Train loss 1.56 on epoch=9
06/08/2022 07:28:06 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/08/2022 07:28:07 - INFO - __main__ - Global step 50 Train loss 3.17 Classification-F1 0.18322182192485847 on epoch=12
06/08/2022 07:28:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18322182192485847 on epoch=12, global_step=50
06/08/2022 07:28:10 - INFO - __main__ - Step 60 Global step 60 Train loss 1.10 on epoch=14
06/08/2022 07:28:13 - INFO - __main__ - Step 70 Global step 70 Train loss 1.11 on epoch=17
06/08/2022 07:28:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.01 on epoch=19
06/08/2022 07:28:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=22
06/08/2022 07:28:21 - INFO - __main__ - Step 100 Global step 100 Train loss 0.92 on epoch=24
06/08/2022 07:28:22 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.1978552615075881 on epoch=24
06/08/2022 07:28:22 - INFO - __main__ - Saving model with best Classification-F1: 0.18322182192485847 -> 0.1978552615075881 on epoch=24, global_step=100
06/08/2022 07:28:25 - INFO - __main__ - Step 110 Global step 110 Train loss 1.31 on epoch=27
06/08/2022 07:28:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=29
06/08/2022 07:28:31 - INFO - __main__ - Step 130 Global step 130 Train loss 0.93 on epoch=32
06/08/2022 07:28:34 - INFO - __main__ - Step 140 Global step 140 Train loss 1.01 on epoch=34
06/08/2022 07:28:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.93 on epoch=37
06/08/2022 07:28:37 - INFO - __main__ - Global step 150 Train loss 1.02 Classification-F1 0.1762899262899263 on epoch=37
06/08/2022 07:28:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=39
06/08/2022 07:28:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=42
06/08/2022 07:28:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.88 on epoch=44
06/08/2022 07:28:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=47
06/08/2022 07:28:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=49
06/08/2022 07:28:52 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.1986013986013986 on epoch=49
06/08/2022 07:28:52 - INFO - __main__ - Saving model with best Classification-F1: 0.1978552615075881 -> 0.1986013986013986 on epoch=49, global_step=200
06/08/2022 07:28:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.82 on epoch=52
06/08/2022 07:28:57 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=54
06/08/2022 07:29:00 - INFO - __main__ - Step 230 Global step 230 Train loss 0.83 on epoch=57
06/08/2022 07:29:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=59
06/08/2022 07:29:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=62
06/08/2022 07:29:07 - INFO - __main__ - Global step 250 Train loss 0.81 Classification-F1 0.15189520624303232 on epoch=62
06/08/2022 07:29:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=64
06/08/2022 07:29:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=67
06/08/2022 07:29:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=69
06/08/2022 07:29:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.76 on epoch=72
06/08/2022 07:29:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.77 on epoch=74
06/08/2022 07:29:22 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.2635411183798281 on epoch=74
06/08/2022 07:29:22 - INFO - __main__ - Saving model with best Classification-F1: 0.1986013986013986 -> 0.2635411183798281 on epoch=74, global_step=300
06/08/2022 07:29:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=77
06/08/2022 07:29:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=79
06/08/2022 07:29:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.70 on epoch=82
06/08/2022 07:29:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=84
06/08/2022 07:29:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.74 on epoch=87
06/08/2022 07:29:37 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.296875 on epoch=87
06/08/2022 07:29:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2635411183798281 -> 0.296875 on epoch=87, global_step=350
06/08/2022 07:29:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.59 on epoch=89
06/08/2022 07:29:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=92
06/08/2022 07:29:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.68 on epoch=94
06/08/2022 07:29:48 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=97
06/08/2022 07:29:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=99
06/08/2022 07:29:51 - INFO - __main__ - Global step 400 Train loss 0.64 Classification-F1 0.4404980385071735 on epoch=99
06/08/2022 07:29:51 - INFO - __main__ - Saving model with best Classification-F1: 0.296875 -> 0.4404980385071735 on epoch=99, global_step=400
06/08/2022 07:29:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.71 on epoch=102
06/08/2022 07:29:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.65 on epoch=104
06/08/2022 07:30:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.59 on epoch=107
06/08/2022 07:30:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.56 on epoch=109
06/08/2022 07:30:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=112
06/08/2022 07:30:06 - INFO - __main__ - Global step 450 Train loss 0.61 Classification-F1 0.4095737993788968 on epoch=112
06/08/2022 07:30:09 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=114
06/08/2022 07:30:12 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=117
06/08/2022 07:30:14 - INFO - __main__ - Step 480 Global step 480 Train loss 0.49 on epoch=119
06/08/2022 07:30:17 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=122
06/08/2022 07:30:20 - INFO - __main__ - Step 500 Global step 500 Train loss 0.47 on epoch=124
06/08/2022 07:30:21 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.4173022472215429 on epoch=124
06/08/2022 07:30:24 - INFO - __main__ - Step 510 Global step 510 Train loss 0.55 on epoch=127
06/08/2022 07:30:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.47 on epoch=129
06/08/2022 07:30:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=132
06/08/2022 07:30:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=134
06/08/2022 07:30:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.32 on epoch=137
06/08/2022 07:30:36 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.441468253968254 on epoch=137
06/08/2022 07:30:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4404980385071735 -> 0.441468253968254 on epoch=137, global_step=550
06/08/2022 07:30:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.52 on epoch=139
06/08/2022 07:30:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=142
06/08/2022 07:30:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/08/2022 07:30:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=147
06/08/2022 07:30:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=149
06/08/2022 07:30:51 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.4600529100529101 on epoch=149
06/08/2022 07:30:51 - INFO - __main__ - Saving model with best Classification-F1: 0.441468253968254 -> 0.4600529100529101 on epoch=149, global_step=600
06/08/2022 07:30:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=152
06/08/2022 07:30:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.34 on epoch=154
06/08/2022 07:30:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.34 on epoch=157
06/08/2022 07:31:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=159
06/08/2022 07:31:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=162
06/08/2022 07:31:06 - INFO - __main__ - Global step 650 Train loss 0.31 Classification-F1 0.47717113665389527 on epoch=162
06/08/2022 07:31:06 - INFO - __main__ - Saving model with best Classification-F1: 0.4600529100529101 -> 0.47717113665389527 on epoch=162, global_step=650
06/08/2022 07:31:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=164
06/08/2022 07:31:11 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=167
06/08/2022 07:31:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=169
06/08/2022 07:31:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=172
06/08/2022 07:31:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=174
06/08/2022 07:31:21 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.4792977137804724 on epoch=174
06/08/2022 07:31:21 - INFO - __main__ - Saving model with best Classification-F1: 0.47717113665389527 -> 0.4792977137804724 on epoch=174, global_step=700
06/08/2022 07:31:24 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=177
06/08/2022 07:31:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=179
06/08/2022 07:31:29 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=182
06/08/2022 07:31:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=184
06/08/2022 07:31:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/08/2022 07:31:36 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.45618349031702365 on epoch=187
06/08/2022 07:31:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
06/08/2022 07:31:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=192
06/08/2022 07:31:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=194
06/08/2022 07:31:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/08/2022 07:31:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=199
06/08/2022 07:31:51 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.4943847072879331 on epoch=199
06/08/2022 07:31:51 - INFO - __main__ - Saving model with best Classification-F1: 0.4792977137804724 -> 0.4943847072879331 on epoch=199, global_step=800
06/08/2022 07:31:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=202
06/08/2022 07:31:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=204
06/08/2022 07:32:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=207
06/08/2022 07:32:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=209
06/08/2022 07:32:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.06 on epoch=212
06/08/2022 07:32:07 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.4792628667628667 on epoch=212
06/08/2022 07:32:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=214
06/08/2022 07:32:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=217
06/08/2022 07:32:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=219
06/08/2022 07:32:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=222
06/08/2022 07:32:20 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=224
06/08/2022 07:32:22 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.4709976105137395 on epoch=224
06/08/2022 07:32:24 - INFO - __main__ - Step 910 Global step 910 Train loss 0.05 on epoch=227
06/08/2022 07:32:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=229
06/08/2022 07:32:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=232
06/08/2022 07:32:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=234
06/08/2022 07:32:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.03 on epoch=237
06/08/2022 07:32:37 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.47487283908889316 on epoch=237
06/08/2022 07:32:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=239
06/08/2022 07:32:42 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=242
06/08/2022 07:32:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
06/08/2022 07:32:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.03 on epoch=247
06/08/2022 07:32:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=249
06/08/2022 07:32:52 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5429830586080586 on epoch=249
06/08/2022 07:32:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4943847072879331 -> 0.5429830586080586 on epoch=249, global_step=1000
06/08/2022 07:32:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=252
06/08/2022 07:32:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/08/2022 07:33:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/08/2022 07:33:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/08/2022 07:33:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/08/2022 07:33:07 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.47199217851391767 on epoch=262
06/08/2022 07:33:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=264
06/08/2022 07:33:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=267
06/08/2022 07:33:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=269
06/08/2022 07:33:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/08/2022 07:33:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=274
06/08/2022 07:33:23 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.51581725807732 on epoch=274
06/08/2022 07:33:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/08/2022 07:33:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=279
06/08/2022 07:33:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.01 on epoch=282
06/08/2022 07:33:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=284
06/08/2022 07:33:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=287
06/08/2022 07:33:38 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.47437189826302734 on epoch=287
06/08/2022 07:33:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=289
06/08/2022 07:33:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/08/2022 07:33:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/08/2022 07:33:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/08/2022 07:33:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=299
06/08/2022 07:33:54 - INFO - __main__ - Global step 1200 Train loss 0.04 Classification-F1 0.4751322751322752 on epoch=299
06/08/2022 07:33:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=302
06/08/2022 07:33:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=304
06/08/2022 07:34:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=307
06/08/2022 07:34:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=309
06/08/2022 07:34:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/08/2022 07:34:09 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.4684981684981685 on epoch=312
06/08/2022 07:34:11 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 07:34:14 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/08/2022 07:34:17 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 07:34:19 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 07:34:22 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=324
06/08/2022 07:34:23 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.48290515154373387 on epoch=324
06/08/2022 07:34:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 07:34:29 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=329
06/08/2022 07:34:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=332
06/08/2022 07:34:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/08/2022 07:34:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 07:34:38 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.5191142191142192 on epoch=337
06/08/2022 07:34:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.02 on epoch=339
06/08/2022 07:34:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=342
06/08/2022 07:34:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 07:34:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/08/2022 07:34:51 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 07:34:53 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.5837391774891775 on epoch=349
06/08/2022 07:34:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5429830586080586 -> 0.5837391774891775 on epoch=349, global_step=1400
06/08/2022 07:34:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=352
06/08/2022 07:34:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/08/2022 07:35:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/08/2022 07:35:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/08/2022 07:35:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=362
06/08/2022 07:35:07 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.5825711027323931 on epoch=362
06/08/2022 07:35:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=364
06/08/2022 07:35:13 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/08/2022 07:35:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 07:35:18 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=372
06/08/2022 07:35:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 07:35:22 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.5162414569742155 on epoch=374
06/08/2022 07:35:25 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/08/2022 07:35:28 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.01 on epoch=379
06/08/2022 07:35:31 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/08/2022 07:35:33 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=384
06/08/2022 07:35:36 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 07:35:37 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5186864219371959 on epoch=387
06/08/2022 07:35:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=389
06/08/2022 07:35:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=392
06/08/2022 07:35:45 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/08/2022 07:35:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/08/2022 07:35:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 07:35:52 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.5331777023203169 on epoch=399
06/08/2022 07:35:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=402
06/08/2022 07:35:57 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=404
06/08/2022 07:36:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=407
06/08/2022 07:36:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/08/2022 07:36:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/08/2022 07:36:07 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.5656273352845934 on epoch=412
06/08/2022 07:36:09 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/08/2022 07:36:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 07:36:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=419
06/08/2022 07:36:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/08/2022 07:36:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=424
06/08/2022 07:36:22 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.5345345345345346 on epoch=424
06/08/2022 07:36:24 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 07:36:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=429
06/08/2022 07:36:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=432
06/08/2022 07:36:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=434
06/08/2022 07:36:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=437
06/08/2022 07:36:36 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.5318474536216472 on epoch=437
06/08/2022 07:36:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 07:36:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/08/2022 07:36:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 07:36:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 07:36:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=449
06/08/2022 07:36:51 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.48757793439956626 on epoch=449
06/08/2022 07:36:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=452
06/08/2022 07:36:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=454
06/08/2022 07:36:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=457
06/08/2022 07:37:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 07:37:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 07:37:06 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.5231729055258467 on epoch=462
06/08/2022 07:37:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=464
06/08/2022 07:37:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=467
06/08/2022 07:37:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=469
06/08/2022 07:37:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 07:37:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=474
06/08/2022 07:37:21 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.5325938429386705 on epoch=474
06/08/2022 07:37:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=477
06/08/2022 07:37:27 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 07:37:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 07:37:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 07:37:35 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 07:37:36 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5663778011204481 on epoch=487
06/08/2022 07:37:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/08/2022 07:37:41 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=492
06/08/2022 07:37:44 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=494
06/08/2022 07:37:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 07:37:49 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 07:37:51 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.547266160169386 on epoch=499
06/08/2022 07:37:53 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 07:37:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=504
06/08/2022 07:37:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/08/2022 07:38:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=509
06/08/2022 07:38:05 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 07:38:06 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5045819716775599 on epoch=512
06/08/2022 07:38:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 07:38:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 07:38:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=519
06/08/2022 07:38:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 07:38:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=524
06/08/2022 07:38:21 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.513624461900324 on epoch=524
06/08/2022 07:38:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 07:38:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=529
06/08/2022 07:38:30 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 07:38:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/08/2022 07:38:35 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 07:38:36 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5375289900906599 on epoch=537
06/08/2022 07:38:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 07:38:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 07:38:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 07:38:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=547
06/08/2022 07:38:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/08/2022 07:38:52 - INFO - __main__ - Global step 2200 Train loss 0.01 Classification-F1 0.5361276455026455 on epoch=549
06/08/2022 07:38:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 07:38:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=554
06/08/2022 07:39:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 07:39:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=559
06/08/2022 07:39:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 07:39:07 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.5681662087912087 on epoch=562
06/08/2022 07:39:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=564
06/08/2022 07:39:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 07:39:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=569
06/08/2022 07:39:18 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 07:39:21 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/08/2022 07:39:22 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.5445402298850575 on epoch=574
06/08/2022 07:39:25 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 07:39:28 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 07:39:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=582
06/08/2022 07:39:33 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/08/2022 07:39:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 07:39:38 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.5356409624702307 on epoch=587
06/08/2022 07:39:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/08/2022 07:39:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/08/2022 07:39:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 07:39:49 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 07:39:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=599
06/08/2022 07:39:53 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.5558755760368663 on epoch=599
06/08/2022 07:39:56 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=602
06/08/2022 07:39:59 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 07:40:01 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 07:40:04 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=609
06/08/2022 07:40:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=612
06/08/2022 07:40:08 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5648217609958045 on epoch=612
06/08/2022 07:40:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 07:40:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 07:40:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 07:40:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 07:40:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=624
06/08/2022 07:40:24 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.5066146325113327 on epoch=624
06/08/2022 07:40:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 07:40:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/08/2022 07:40:33 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 07:40:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 07:40:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 07:40:40 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.5377142465377759 on epoch=637
06/08/2022 07:40:43 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=639
06/08/2022 07:40:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 07:40:48 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 07:40:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 07:40:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 07:40:55 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5687430786267995 on epoch=649
06/08/2022 07:40:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 07:41:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=654
06/08/2022 07:41:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 07:41:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=659
06/08/2022 07:41:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=662
06/08/2022 07:41:11 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.5244588744588744 on epoch=662
06/08/2022 07:41:14 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 07:41:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 07:41:19 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=669
06/08/2022 07:41:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 07:41:25 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 07:41:26 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.5421514759750053 on epoch=674
06/08/2022 07:41:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 07:41:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 07:41:35 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 07:41:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=684
06/08/2022 07:41:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 07:41:42 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5208087909700813 on epoch=687
06/08/2022 07:41:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 07:41:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 07:41:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 07:41:53 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 07:41:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 07:41:57 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.556704260651629 on epoch=699
06/08/2022 07:42:00 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=702
06/08/2022 07:42:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=704
06/08/2022 07:42:05 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=707
06/08/2022 07:42:08 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 07:42:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 07:42:12 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.57387328556641 on epoch=712
06/08/2022 07:42:15 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 07:42:18 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 07:42:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 07:42:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 07:42:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 07:42:28 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5455128205128205 on epoch=724
06/08/2022 07:42:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 07:42:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 07:42:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 07:42:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 07:42:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 07:42:43 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.5621707482573561 on epoch=737
06/08/2022 07:42:46 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 07:42:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 07:42:51 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 07:42:54 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 07:42:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 07:42:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:42:59 - INFO - __main__ - Printing 3 examples
06/08/2022 07:42:59 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:42:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:42:59 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.516938691938692 on epoch=749
06/08/2022 07:42:59 - INFO - __main__ - save last model!
06/08/2022 07:42:59 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:42:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:42:59 - INFO - __main__ - Printing 3 examples
06/08/2022 07:42:59 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:42:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 07:42:59 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 07:42:59 - INFO - __main__ - Printing 3 examples
06/08/2022 07:42:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 07:42:59 - INFO - __main__ - ['others']
06/08/2022 07:42:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:42:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:42:59 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:43:01 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:43:07 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 07:43:17 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:43:17 - INFO - __main__ - task name: emo
06/08/2022 07:43:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:43:18 - INFO - __main__ - Starting training!
06/08/2022 07:44:58 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_42_0.2_8_predictions.txt
06/08/2022 07:44:58 - INFO - __main__ - Classification-F1 on test data: 0.3831
06/08/2022 07:44:58 - INFO - __main__ - prefix=emo_16_42, lr=0.2, bsz=8, dev_performance=0.5837391774891775, test_performance=0.3830767706424092
06/08/2022 07:44:58 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.5, bsz=8 ...
06/08/2022 07:44:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:44:59 - INFO - __main__ - Printing 3 examples
06/08/2022 07:44:59 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:44:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:44:59 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 07:44:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 07:44:59 - INFO - __main__ - Printing 3 examples
06/08/2022 07:44:59 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 07:44:59 - INFO - __main__ - ['others']
06/08/2022 07:44:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 07:44:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 07:44:59 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 07:45:15 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 07:45:15 - INFO - __main__ - task name: emo
06/08/2022 07:45:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 07:45:16 - INFO - __main__ - Starting training!
06/08/2022 07:45:19 - INFO - __main__ - Step 10 Global step 10 Train loss 5.51 on epoch=2
06/08/2022 07:45:22 - INFO - __main__ - Step 20 Global step 20 Train loss 1.56 on epoch=4
06/08/2022 07:45:25 - INFO - __main__ - Step 30 Global step 30 Train loss 1.24 on epoch=7
06/08/2022 07:45:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.12 on epoch=9
06/08/2022 07:45:30 - INFO - __main__ - Step 50 Global step 50 Train loss 0.95 on epoch=12
06/08/2022 07:45:31 - INFO - __main__ - Global step 50 Train loss 2.08 Classification-F1 0.1 on epoch=12
06/08/2022 07:45:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 07:45:34 - INFO - __main__ - Step 60 Global step 60 Train loss 0.94 on epoch=14
06/08/2022 07:45:37 - INFO - __main__ - Step 70 Global step 70 Train loss 0.98 on epoch=17
06/08/2022 07:45:40 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=19
06/08/2022 07:45:43 - INFO - __main__ - Step 90 Global step 90 Train loss 1.02 on epoch=22
06/08/2022 07:45:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.80 on epoch=24
06/08/2022 07:45:46 - INFO - __main__ - Global step 100 Train loss 0.93 Classification-F1 0.31591660310195774 on epoch=24
06/08/2022 07:45:46 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.31591660310195774 on epoch=24, global_step=100
06/08/2022 07:45:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.99 on epoch=27
06/08/2022 07:45:52 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=29
06/08/2022 07:45:55 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=32
06/08/2022 07:45:58 - INFO - __main__ - Step 140 Global step 140 Train loss 0.79 on epoch=34
06/08/2022 07:46:01 - INFO - __main__ - Step 150 Global step 150 Train loss 0.78 on epoch=37
06/08/2022 07:46:02 - INFO - __main__ - Global step 150 Train loss 0.86 Classification-F1 0.41209150326797384 on epoch=37
06/08/2022 07:46:02 - INFO - __main__ - Saving model with best Classification-F1: 0.31591660310195774 -> 0.41209150326797384 on epoch=37, global_step=150
06/08/2022 07:46:05 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=39
06/08/2022 07:46:07 - INFO - __main__ - Step 170 Global step 170 Train loss 0.51 on epoch=42
06/08/2022 07:46:10 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=44
06/08/2022 07:46:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=47
06/08/2022 07:46:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.48 on epoch=49
06/08/2022 07:46:17 - INFO - __main__ - Global step 200 Train loss 0.57 Classification-F1 0.36765272399180876 on epoch=49
06/08/2022 07:46:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=52
06/08/2022 07:46:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.36 on epoch=54
06/08/2022 07:46:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.27 on epoch=57
06/08/2022 07:46:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.36 on epoch=59
06/08/2022 07:46:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.29 on epoch=62
06/08/2022 07:46:32 - INFO - __main__ - Global step 250 Train loss 0.36 Classification-F1 0.5990953386942892 on epoch=62
06/08/2022 07:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.41209150326797384 -> 0.5990953386942892 on epoch=62, global_step=250
06/08/2022 07:46:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.31 on epoch=64
06/08/2022 07:46:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.23 on epoch=67
06/08/2022 07:46:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.22 on epoch=69
06/08/2022 07:46:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.25 on epoch=72
06/08/2022 07:46:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.19 on epoch=74
06/08/2022 07:46:47 - INFO - __main__ - Global step 300 Train loss 0.24 Classification-F1 0.6104895104895105 on epoch=74
06/08/2022 07:46:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5990953386942892 -> 0.6104895104895105 on epoch=74, global_step=300
06/08/2022 07:46:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.19 on epoch=77
06/08/2022 07:46:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.18 on epoch=79
06/08/2022 07:46:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.13 on epoch=82
06/08/2022 07:46:59 - INFO - __main__ - Step 340 Global step 340 Train loss 0.05 on epoch=84
06/08/2022 07:47:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.14 on epoch=87
06/08/2022 07:47:03 - INFO - __main__ - Global step 350 Train loss 0.14 Classification-F1 0.6470238095238094 on epoch=87
06/08/2022 07:47:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6104895104895105 -> 0.6470238095238094 on epoch=87, global_step=350
06/08/2022 07:47:06 - INFO - __main__ - Step 360 Global step 360 Train loss 0.10 on epoch=89
06/08/2022 07:47:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.11 on epoch=92
06/08/2022 07:47:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.03 on epoch=94
06/08/2022 07:47:14 - INFO - __main__ - Step 390 Global step 390 Train loss 0.02 on epoch=97
06/08/2022 07:47:17 - INFO - __main__ - Step 400 Global step 400 Train loss 0.04 on epoch=99
06/08/2022 07:47:18 - INFO - __main__ - Global step 400 Train loss 0.06 Classification-F1 0.6681372549019609 on epoch=99
06/08/2022 07:47:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6470238095238094 -> 0.6681372549019609 on epoch=99, global_step=400
06/08/2022 07:47:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.04 on epoch=102
06/08/2022 07:47:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.04 on epoch=104
06/08/2022 07:47:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.03 on epoch=107
06/08/2022 07:47:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.05 on epoch=109
06/08/2022 07:47:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.02 on epoch=112
06/08/2022 07:47:34 - INFO - __main__ - Global step 450 Train loss 0.04 Classification-F1 0.6701315096900836 on epoch=112
06/08/2022 07:47:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6681372549019609 -> 0.6701315096900836 on epoch=112, global_step=450
06/08/2022 07:47:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.01 on epoch=114
06/08/2022 07:47:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=117
06/08/2022 07:47:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.02 on epoch=119
06/08/2022 07:47:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.04 on epoch=122
06/08/2022 07:47:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.02 on epoch=124
06/08/2022 07:47:49 - INFO - __main__ - Global step 500 Train loss 0.05 Classification-F1 0.618334711883099 on epoch=124
06/08/2022 07:47:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.02 on epoch=127
06/08/2022 07:47:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.05 on epoch=129
06/08/2022 07:47:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.05 on epoch=132
06/08/2022 07:48:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.04 on epoch=134
06/08/2022 07:48:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.02 on epoch=137
06/08/2022 07:48:05 - INFO - __main__ - Global step 550 Train loss 0.04 Classification-F1 0.6400874801875915 on epoch=137
06/08/2022 07:48:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.04 on epoch=139
06/08/2022 07:48:11 - INFO - __main__ - Step 570 Global step 570 Train loss 0.02 on epoch=142
06/08/2022 07:48:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.03 on epoch=144
06/08/2022 07:48:16 - INFO - __main__ - Step 590 Global step 590 Train loss 0.02 on epoch=147
06/08/2022 07:48:19 - INFO - __main__ - Step 600 Global step 600 Train loss 0.02 on epoch=149
06/08/2022 07:48:20 - INFO - __main__ - Global step 600 Train loss 0.03 Classification-F1 0.6322738060487607 on epoch=149
06/08/2022 07:48:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.02 on epoch=152
06/08/2022 07:48:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.08 on epoch=154
06/08/2022 07:48:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.09 on epoch=157
06/08/2022 07:48:32 - INFO - __main__ - Step 640 Global step 640 Train loss 0.01 on epoch=159
06/08/2022 07:48:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.03 on epoch=162
06/08/2022 07:48:36 - INFO - __main__ - Global step 650 Train loss 0.05 Classification-F1 0.6390196078431373 on epoch=162
06/08/2022 07:48:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.01 on epoch=164
06/08/2022 07:48:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.07 on epoch=167
06/08/2022 07:48:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.00 on epoch=169
06/08/2022 07:48:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.01 on epoch=172
06/08/2022 07:48:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.03 on epoch=174
06/08/2022 07:48:52 - INFO - __main__ - Global step 700 Train loss 0.02 Classification-F1 0.6991029822926375 on epoch=174
06/08/2022 07:48:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6701315096900836 -> 0.6991029822926375 on epoch=174, global_step=700
06/08/2022 07:48:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/08/2022 07:48:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.00 on epoch=179
06/08/2022 07:49:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.01 on epoch=182
06/08/2022 07:49:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.04 on epoch=184
06/08/2022 07:49:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.03 on epoch=187
06/08/2022 07:49:08 - INFO - __main__ - Global step 750 Train loss 0.02 Classification-F1 0.6990603594637317 on epoch=187
06/08/2022 07:49:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.01 on epoch=189
06/08/2022 07:49:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.04 on epoch=192
06/08/2022 07:49:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.01 on epoch=194
06/08/2022 07:49:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.01 on epoch=197
06/08/2022 07:49:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.01 on epoch=199
06/08/2022 07:49:23 - INFO - __main__ - Global step 800 Train loss 0.01 Classification-F1 0.6365860052429925 on epoch=199
06/08/2022 07:49:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.02 on epoch=202
06/08/2022 07:49:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.01 on epoch=204
06/08/2022 07:49:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.00 on epoch=207
06/08/2022 07:49:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/08/2022 07:49:38 - INFO - __main__ - Step 850 Global step 850 Train loss 0.01 on epoch=212
06/08/2022 07:49:39 - INFO - __main__ - Global step 850 Train loss 0.01 Classification-F1 0.6998268398268399 on epoch=212
06/08/2022 07:49:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6991029822926375 -> 0.6998268398268399 on epoch=212, global_step=850
06/08/2022 07:49:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.01 on epoch=214
06/08/2022 07:49:45 - INFO - __main__ - Step 870 Global step 870 Train loss 0.00 on epoch=217
06/08/2022 07:49:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.01 on epoch=219
06/08/2022 07:49:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.00 on epoch=222
06/08/2022 07:49:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=224
06/08/2022 07:49:55 - INFO - __main__ - Global step 900 Train loss 0.02 Classification-F1 0.67956299972429 on epoch=224
06/08/2022 07:49:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.01 on epoch=227
06/08/2022 07:50:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/08/2022 07:50:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.03 on epoch=232
06/08/2022 07:50:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/08/2022 07:50:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.02 on epoch=237
06/08/2022 07:50:11 - INFO - __main__ - Global step 950 Train loss 0.02 Classification-F1 0.5890494309611956 on epoch=237
06/08/2022 07:50:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.00 on epoch=239
06/08/2022 07:50:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.01 on epoch=242
06/08/2022 07:50:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.00 on epoch=244
06/08/2022 07:50:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=247
06/08/2022 07:50:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 07:50:26 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.6152777777777778 on epoch=249
06/08/2022 07:50:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.01 on epoch=252
06/08/2022 07:50:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.00 on epoch=254
06/08/2022 07:50:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/08/2022 07:50:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.01 on epoch=259
06/08/2022 07:50:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=262
06/08/2022 07:50:42 - INFO - __main__ - Global step 1050 Train loss 0.01 Classification-F1 0.5954027111265028 on epoch=262
06/08/2022 07:50:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.00 on epoch=264
06/08/2022 07:50:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.00 on epoch=267
06/08/2022 07:50:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.00 on epoch=269
06/08/2022 07:50:54 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.00 on epoch=272
06/08/2022 07:50:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/08/2022 07:50:58 - INFO - __main__ - Global step 1100 Train loss 0.01 Classification-F1 0.6708227395518831 on epoch=274
06/08/2022 07:51:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=277
06/08/2022 07:51:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.01 on epoch=279
06/08/2022 07:51:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.00 on epoch=282
06/08/2022 07:51:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.00 on epoch=284
06/08/2022 07:51:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.00 on epoch=287
06/08/2022 07:51:13 - INFO - __main__ - Global step 1150 Train loss 0.01 Classification-F1 0.6539413745296099 on epoch=287
06/08/2022 07:51:16 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.00 on epoch=289
06/08/2022 07:51:19 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.00 on epoch=292
06/08/2022 07:51:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 07:51:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/08/2022 07:51:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 07:51:29 - INFO - __main__ - Global step 1200 Train loss 0.01 Classification-F1 0.6907090355366218 on epoch=299
06/08/2022 07:51:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/08/2022 07:51:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.00 on epoch=304
06/08/2022 07:51:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.00 on epoch=307
06/08/2022 07:51:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 07:51:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/08/2022 07:51:45 - INFO - __main__ - Global step 1250 Train loss 0.01 Classification-F1 0.7023897058823529 on epoch=312
06/08/2022 07:51:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6998268398268399 -> 0.7023897058823529 on epoch=312, global_step=1250
06/08/2022 07:51:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 07:51:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.00 on epoch=317
06/08/2022 07:51:53 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 07:51:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 07:51:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 07:52:01 - INFO - __main__ - Global step 1300 Train loss 0.01 Classification-F1 0.6417399804496579 on epoch=324
06/08/2022 07:52:03 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=327
06/08/2022 07:52:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.00 on epoch=329
06/08/2022 07:52:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 07:52:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.00 on epoch=334
06/08/2022 07:52:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/08/2022 07:52:16 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.6188357434186132 on epoch=337
06/08/2022 07:52:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=339
06/08/2022 07:52:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 07:52:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/08/2022 07:52:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=347
06/08/2022 07:52:30 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=349
06/08/2022 07:52:32 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.6815850815850817 on epoch=349
06/08/2022 07:52:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.00 on epoch=352
06/08/2022 07:52:37 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.00 on epoch=354
06/08/2022 07:52:40 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 07:52:43 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 07:52:46 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/08/2022 07:52:47 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6866452921546816 on epoch=362
06/08/2022 07:52:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 07:52:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 07:52:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 07:52:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 07:53:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=374
06/08/2022 07:53:03 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7006628787878788 on epoch=374
06/08/2022 07:53:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 07:53:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.00 on epoch=379
06/08/2022 07:53:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 07:53:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 07:53:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.00 on epoch=387
06/08/2022 07:53:18 - INFO - __main__ - Global step 1550 Train loss 0.00 Classification-F1 0.7021967243741438 on epoch=387
06/08/2022 07:53:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 07:53:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 07:53:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 07:53:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 07:53:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 07:53:34 - INFO - __main__ - Global step 1600 Train loss 0.00 Classification-F1 0.695128367003367 on epoch=399
06/08/2022 07:53:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 07:53:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 07:53:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 07:53:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=409
06/08/2022 07:53:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/08/2022 07:53:49 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6486580086580086 on epoch=412
06/08/2022 07:53:52 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 07:53:55 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 07:53:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 07:54:00 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=422
06/08/2022 07:54:03 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 07:54:05 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6524976565861454 on epoch=424
06/08/2022 07:54:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 07:54:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 07:54:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=432
06/08/2022 07:54:16 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.00 on epoch=434
06/08/2022 07:54:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=437
06/08/2022 07:54:20 - INFO - __main__ - Global step 1750 Train loss 0.00 Classification-F1 0.6763087185047257 on epoch=437
06/08/2022 07:54:22 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 07:54:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.00 on epoch=442
06/08/2022 07:54:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 07:54:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 07:54:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 07:54:35 - INFO - __main__ - Global step 1800 Train loss 0.00 Classification-F1 0.6546926046926047 on epoch=449
06/08/2022 07:54:38 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 07:54:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 07:54:43 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=457
06/08/2022 07:54:46 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 07:54:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 07:54:50 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.6553153153153153 on epoch=462
06/08/2022 07:54:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 07:54:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 07:54:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 07:55:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 07:55:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 07:55:05 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.6682340647857888 on epoch=474
06/08/2022 07:55:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 07:55:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 07:55:14 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 07:55:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 07:55:19 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 07:55:21 - INFO - __main__ - Global step 1950 Train loss 0.00 Classification-F1 0.6617157335907335 on epoch=487
06/08/2022 07:55:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=489
06/08/2022 07:55:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 07:55:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 07:55:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=497
06/08/2022 07:55:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 07:55:36 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6561350835544385 on epoch=499
06/08/2022 07:55:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 07:55:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 07:55:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 07:55:48 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 07:55:51 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 07:55:52 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6684246458440007 on epoch=512
06/08/2022 07:55:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 07:55:57 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 07:56:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 07:56:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 07:56:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 07:56:07 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.6682582123758596 on epoch=524
06/08/2022 07:56:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 07:56:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=529
06/08/2022 07:56:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 07:56:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 07:56:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 07:56:23 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6313072603395185 on epoch=537
06/08/2022 07:56:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 07:56:29 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 07:56:32 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 07:56:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 07:56:37 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 07:56:39 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6182659932659933 on epoch=549
06/08/2022 07:56:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 07:56:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 07:56:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 07:56:51 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 07:56:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 07:56:55 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6700738916256158 on epoch=562
06/08/2022 07:56:58 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 07:57:01 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 07:57:03 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 07:57:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 07:57:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 07:57:10 - INFO - __main__ - Global step 2300 Train loss 0.00 Classification-F1 0.6488523573200993 on epoch=574
06/08/2022 07:57:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=577
06/08/2022 07:57:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 07:57:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 07:57:22 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 07:57:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=587
06/08/2022 07:57:27 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6684766383042245 on epoch=587
06/08/2022 07:57:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.19 on epoch=589
06/08/2022 07:57:33 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 07:57:36 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 07:57:39 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 07:57:42 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 07:57:43 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6411439604445897 on epoch=599
06/08/2022 07:57:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 07:57:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 07:57:51 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 07:57:54 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 07:57:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 07:57:59 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.684077380952381 on epoch=612
06/08/2022 07:58:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 07:58:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 07:58:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 07:58:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 07:58:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 07:58:14 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6511784511784512 on epoch=624
06/08/2022 07:58:17 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 07:58:20 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 07:58:23 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 07:58:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 07:58:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 07:58:30 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.684077380952381 on epoch=637
06/08/2022 07:58:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 07:58:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 07:58:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 07:58:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 07:58:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 07:58:46 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.6631001681404908 on epoch=649
06/08/2022 07:58:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 07:58:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 07:58:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 07:58:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 07:59:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 07:59:01 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.6474930087833313 on epoch=662
06/08/2022 07:59:04 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 07:59:07 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 07:59:10 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 07:59:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 07:59:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 07:59:17 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6300840336134453 on epoch=674
06/08/2022 07:59:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 07:59:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 07:59:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 07:59:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 07:59:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 07:59:32 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6634623015873016 on epoch=687
06/08/2022 07:59:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 07:59:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/08/2022 07:59:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 07:59:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 07:59:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 07:59:48 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6673669467787116 on epoch=699
06/08/2022 07:59:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 07:59:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 07:59:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 07:59:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 08:00:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 08:00:03 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6673669467787116 on epoch=712
06/08/2022 08:00:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 08:00:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 08:00:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 08:00:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 08:00:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 08:00:19 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6643697478991596 on epoch=724
06/08/2022 08:00:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 08:00:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 08:00:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 08:00:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 08:00:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 08:00:35 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6496013790131437 on epoch=737
06/08/2022 08:00:37 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 08:00:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 08:00:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 08:00:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 08:00:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 08:00:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:00:50 - INFO - __main__ - Printing 3 examples
06/08/2022 08:00:50 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:00:50 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:00:50 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:00:50 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:00:50 - INFO - __main__ - Printing 3 examples
06/08/2022 08:00:50 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:00:50 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:00:50 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6651985269632329 on epoch=749
06/08/2022 08:00:50 - INFO - __main__ - save last model!
06/08/2022 08:00:50 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:00:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 08:00:50 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 08:00:50 - INFO - __main__ - Printing 3 examples
06/08/2022 08:00:50 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 08:00:50 - INFO - __main__ - ['others']
06/08/2022 08:00:50 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:00:53 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:00:59 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 08:01:09 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:01:09 - INFO - __main__ - task name: emo
06/08/2022 08:01:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:01:10 - INFO - __main__ - Starting training!
06/08/2022 08:02:58 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_87_0.5_8_predictions.txt
06/08/2022 08:02:58 - INFO - __main__ - Classification-F1 on test data: 0.3551
06/08/2022 08:02:58 - INFO - __main__ - prefix=emo_16_87, lr=0.5, bsz=8, dev_performance=0.7023897058823529, test_performance=0.3550950527433737
06/08/2022 08:02:58 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.4, bsz=8 ...
06/08/2022 08:02:59 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:02:59 - INFO - __main__ - Printing 3 examples
06/08/2022 08:02:59 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:02:59 - INFO - __main__ - ['others']
06/08/2022 08:02:59 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:02:59 - INFO - __main__ - ['others']
06/08/2022 08:02:59 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:02:59 - INFO - __main__ - ['others']
06/08/2022 08:02:59 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:02:59 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:03:00 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:03:00 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:03:00 - INFO - __main__ - Printing 3 examples
06/08/2022 08:03:00 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:03:00 - INFO - __main__ - ['others']
06/08/2022 08:03:00 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:03:00 - INFO - __main__ - ['others']
06/08/2022 08:03:00 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:03:00 - INFO - __main__ - ['others']
06/08/2022 08:03:00 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:03:00 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:03:00 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:03:15 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:03:15 - INFO - __main__ - task name: emo
06/08/2022 08:03:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:03:15 - INFO - __main__ - Starting training!
06/08/2022 08:03:18 - INFO - __main__ - Step 10 Global step 10 Train loss 6.74 on epoch=2
06/08/2022 08:03:21 - INFO - __main__ - Step 20 Global step 20 Train loss 2.41 on epoch=4
06/08/2022 08:03:24 - INFO - __main__ - Step 30 Global step 30 Train loss 1.27 on epoch=7
06/08/2022 08:03:27 - INFO - __main__ - Step 40 Global step 40 Train loss 1.21 on epoch=9
06/08/2022 08:03:29 - INFO - __main__ - Step 50 Global step 50 Train loss 0.96 on epoch=12
06/08/2022 08:03:31 - INFO - __main__ - Global step 50 Train loss 2.52 Classification-F1 0.1 on epoch=12
06/08/2022 08:03:31 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 08:03:33 - INFO - __main__ - Step 60 Global step 60 Train loss 1.13 on epoch=14
06/08/2022 08:03:36 - INFO - __main__ - Step 70 Global step 70 Train loss 1.07 on epoch=17
06/08/2022 08:03:39 - INFO - __main__ - Step 80 Global step 80 Train loss 1.05 on epoch=19
06/08/2022 08:03:42 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=22
06/08/2022 08:03:45 - INFO - __main__ - Step 100 Global step 100 Train loss 0.99 on epoch=24
06/08/2022 08:03:46 - INFO - __main__ - Global step 100 Train loss 1.05 Classification-F1 0.1 on epoch=24
06/08/2022 08:03:49 - INFO - __main__ - Step 110 Global step 110 Train loss 0.96 on epoch=27
06/08/2022 08:03:51 - INFO - __main__ - Step 120 Global step 120 Train loss 0.92 on epoch=29
06/08/2022 08:03:54 - INFO - __main__ - Step 130 Global step 130 Train loss 0.96 on epoch=32
06/08/2022 08:03:57 - INFO - __main__ - Step 140 Global step 140 Train loss 0.98 on epoch=34
06/08/2022 08:03:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.98 on epoch=37
06/08/2022 08:04:01 - INFO - __main__ - Global step 150 Train loss 0.96 Classification-F1 0.13067758749069247 on epoch=37
06/08/2022 08:04:01 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.13067758749069247 on epoch=37, global_step=150
06/08/2022 08:04:03 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=39
06/08/2022 08:04:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=42
06/08/2022 08:04:09 - INFO - __main__ - Step 180 Global step 180 Train loss 0.93 on epoch=44
06/08/2022 08:04:12 - INFO - __main__ - Step 190 Global step 190 Train loss 0.80 on epoch=47
06/08/2022 08:04:15 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=49
06/08/2022 08:04:16 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.4613909932659933 on epoch=49
06/08/2022 08:04:16 - INFO - __main__ - Saving model with best Classification-F1: 0.13067758749069247 -> 0.4613909932659933 on epoch=49, global_step=200
06/08/2022 08:04:19 - INFO - __main__ - Step 210 Global step 210 Train loss 0.77 on epoch=52
06/08/2022 08:04:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=54
06/08/2022 08:04:24 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=57
06/08/2022 08:04:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=59
06/08/2022 08:04:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=62
06/08/2022 08:04:31 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4102365911061564 on epoch=62
06/08/2022 08:04:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=64
06/08/2022 08:04:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=67
06/08/2022 08:04:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=69
06/08/2022 08:04:42 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=72
06/08/2022 08:04:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=74
06/08/2022 08:04:46 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.5259259259259259 on epoch=74
06/08/2022 08:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.4613909932659933 -> 0.5259259259259259 on epoch=74, global_step=300
06/08/2022 08:04:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.35 on epoch=77
06/08/2022 08:04:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.92 on epoch=79
06/08/2022 08:04:54 - INFO - __main__ - Step 330 Global step 330 Train loss 1.08 on epoch=82
06/08/2022 08:04:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.20 on epoch=84
06/08/2022 08:05:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.26 on epoch=87
06/08/2022 08:05:01 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.5326599326599326 on epoch=87
06/08/2022 08:05:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5259259259259259 -> 0.5326599326599326 on epoch=87, global_step=350
06/08/2022 08:05:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.26 on epoch=89
06/08/2022 08:05:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.24 on epoch=92
06/08/2022 08:05:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.19 on epoch=94
06/08/2022 08:05:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=97
06/08/2022 08:05:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.19 on epoch=99
06/08/2022 08:05:16 - INFO - __main__ - Global step 400 Train loss 0.22 Classification-F1 0.5981566820276498 on epoch=99
06/08/2022 08:05:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5326599326599326 -> 0.5981566820276498 on epoch=99, global_step=400
06/08/2022 08:05:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.17 on epoch=102
06/08/2022 08:05:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=104
06/08/2022 08:05:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.13 on epoch=107
06/08/2022 08:05:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.12 on epoch=109
06/08/2022 08:05:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.12 on epoch=112
06/08/2022 08:05:32 - INFO - __main__ - Global step 450 Train loss 0.16 Classification-F1 0.6137623152709359 on epoch=112
06/08/2022 08:05:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5981566820276498 -> 0.6137623152709359 on epoch=112, global_step=450
06/08/2022 08:05:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.15 on epoch=114
06/08/2022 08:05:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.13 on epoch=117
06/08/2022 08:05:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.14 on epoch=119
06/08/2022 08:05:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.15 on epoch=122
06/08/2022 08:05:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.11 on epoch=124
06/08/2022 08:05:46 - INFO - __main__ - Global step 500 Train loss 0.14 Classification-F1 0.6438596897787665 on epoch=124
06/08/2022 08:05:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6137623152709359 -> 0.6438596897787665 on epoch=124, global_step=500
06/08/2022 08:05:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=127
06/08/2022 08:05:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.09 on epoch=129
06/08/2022 08:05:55 - INFO - __main__ - Step 530 Global step 530 Train loss 0.10 on epoch=132
06/08/2022 08:05:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=134
06/08/2022 08:06:00 - INFO - __main__ - Step 550 Global step 550 Train loss 0.12 on epoch=137
06/08/2022 08:06:02 - INFO - __main__ - Global step 550 Train loss 0.13 Classification-F1 0.645791542423421 on epoch=137
06/08/2022 08:06:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6438596897787665 -> 0.645791542423421 on epoch=137, global_step=550
06/08/2022 08:06:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.13 on epoch=139
06/08/2022 08:06:07 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=142
06/08/2022 08:06:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/08/2022 08:06:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.06 on epoch=147
06/08/2022 08:06:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.03 on epoch=149
06/08/2022 08:06:17 - INFO - __main__ - Global step 600 Train loss 0.11 Classification-F1 0.6097689075630253 on epoch=149
06/08/2022 08:06:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.08 on epoch=152
06/08/2022 08:06:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.06 on epoch=154
06/08/2022 08:06:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=157
06/08/2022 08:06:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.04 on epoch=159
06/08/2022 08:06:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=162
06/08/2022 08:06:32 - INFO - __main__ - Global step 650 Train loss 0.09 Classification-F1 0.5871697922968341 on epoch=162
06/08/2022 08:06:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.06 on epoch=164
06/08/2022 08:06:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.08 on epoch=167
06/08/2022 08:06:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.07 on epoch=169
06/08/2022 08:06:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=172
06/08/2022 08:06:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=174
06/08/2022 08:06:46 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.5032278267572384 on epoch=174
06/08/2022 08:06:49 - INFO - __main__ - Step 710 Global step 710 Train loss 0.05 on epoch=177
06/08/2022 08:06:52 - INFO - __main__ - Step 720 Global step 720 Train loss 0.04 on epoch=179
06/08/2022 08:06:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=182
06/08/2022 08:06:57 - INFO - __main__ - Step 740 Global step 740 Train loss 0.05 on epoch=184
06/08/2022 08:07:00 - INFO - __main__ - Step 750 Global step 750 Train loss 0.08 on epoch=187
06/08/2022 08:07:01 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.5506695709280175 on epoch=187
06/08/2022 08:07:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=189
06/08/2022 08:07:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=192
06/08/2022 08:07:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.06 on epoch=194
06/08/2022 08:07:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.07 on epoch=197
06/08/2022 08:07:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=199
06/08/2022 08:07:16 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.57279307631786 on epoch=199
06/08/2022 08:07:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/08/2022 08:07:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/08/2022 08:07:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.02 on epoch=207
06/08/2022 08:07:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.01 on epoch=209
06/08/2022 08:07:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.03 on epoch=212
06/08/2022 08:07:31 - INFO - __main__ - Global step 850 Train loss 0.04 Classification-F1 0.5933528836754642 on epoch=212
06/08/2022 08:07:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=214
06/08/2022 08:07:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.09 on epoch=217
06/08/2022 08:07:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.02 on epoch=219
06/08/2022 08:07:41 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=222
06/08/2022 08:07:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=224
06/08/2022 08:07:45 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6077340836223254 on epoch=224
06/08/2022 08:07:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/08/2022 08:07:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.01 on epoch=229
06/08/2022 08:07:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=232
06/08/2022 08:07:56 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=234
06/08/2022 08:07:59 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/08/2022 08:08:00 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.5494416873449132 on epoch=237
06/08/2022 08:08:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.03 on epoch=239
06/08/2022 08:08:06 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=242
06/08/2022 08:08:08 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=244
06/08/2022 08:08:11 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=247
06/08/2022 08:08:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 08:08:15 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5689745983863631 on epoch=249
06/08/2022 08:08:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=252
06/08/2022 08:08:20 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=254
06/08/2022 08:08:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=257
06/08/2022 08:08:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=259
06/08/2022 08:08:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.01 on epoch=262
06/08/2022 08:08:30 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.5529007029007029 on epoch=262
06/08/2022 08:08:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=264
06/08/2022 08:08:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=267
06/08/2022 08:08:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=269
06/08/2022 08:08:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=272
06/08/2022 08:08:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=274
06/08/2022 08:08:44 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.5908595761536938 on epoch=274
06/08/2022 08:08:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.01 on epoch=277
06/08/2022 08:08:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=279
06/08/2022 08:08:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/08/2022 08:08:55 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=284
06/08/2022 08:08:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.01 on epoch=287
06/08/2022 08:08:59 - INFO - __main__ - Global step 1150 Train loss 0.03 Classification-F1 0.5345643142951806 on epoch=287
06/08/2022 08:09:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/08/2022 08:09:04 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/08/2022 08:09:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=294
06/08/2022 08:09:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.01 on epoch=297
06/08/2022 08:09:13 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 08:09:14 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6530825496342737 on epoch=299
06/08/2022 08:09:14 - INFO - __main__ - Saving model with best Classification-F1: 0.645791542423421 -> 0.6530825496342737 on epoch=299, global_step=1200
06/08/2022 08:09:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=302
06/08/2022 08:09:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/08/2022 08:09:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=307
06/08/2022 08:09:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=309
06/08/2022 08:09:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=312
06/08/2022 08:09:29 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.5590463458110517 on epoch=312
06/08/2022 08:09:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.01 on epoch=314
06/08/2022 08:09:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.02 on epoch=317
06/08/2022 08:09:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=319
06/08/2022 08:09:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/08/2022 08:09:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.00 on epoch=324
06/08/2022 08:09:43 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.5454827705464378 on epoch=324
06/08/2022 08:09:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/08/2022 08:09:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/08/2022 08:09:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 08:09:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=334
06/08/2022 08:09:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.02 on epoch=337
06/08/2022 08:09:58 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.592339713663243 on epoch=337
06/08/2022 08:10:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=339
06/08/2022 08:10:04 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=342
06/08/2022 08:10:07 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=344
06/08/2022 08:10:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.00 on epoch=347
06/08/2022 08:10:12 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 08:10:13 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.5921797034225876 on epoch=349
06/08/2022 08:10:16 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/08/2022 08:10:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=354
06/08/2022 08:10:21 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/08/2022 08:10:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=359
06/08/2022 08:10:26 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=362
06/08/2022 08:10:28 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6088923024406896 on epoch=362
06/08/2022 08:10:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.00 on epoch=364
06/08/2022 08:10:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=367
06/08/2022 08:10:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.01 on epoch=369
06/08/2022 08:10:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=372
06/08/2022 08:10:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=374
06/08/2022 08:10:43 - INFO - __main__ - Global step 1500 Train loss 0.02 Classification-F1 0.5776264245014245 on epoch=374
06/08/2022 08:10:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=377
06/08/2022 08:10:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/08/2022 08:10:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 08:10:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 08:10:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 08:10:57 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.5558333234483549 on epoch=387
06/08/2022 08:11:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 08:11:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 08:11:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.00 on epoch=394
06/08/2022 08:11:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=397
06/08/2022 08:11:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 08:11:12 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.5841328026811898 on epoch=399
06/08/2022 08:11:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 08:11:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 08:11:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=407
06/08/2022 08:11:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=409
06/08/2022 08:11:25 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 08:11:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.5244597289906031 on epoch=412
06/08/2022 08:11:29 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=414
06/08/2022 08:11:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=417
06/08/2022 08:11:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 08:11:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/08/2022 08:11:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=424
06/08/2022 08:11:41 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.6081903017386889 on epoch=424
06/08/2022 08:11:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=427
06/08/2022 08:11:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=429
06/08/2022 08:11:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 08:11:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=434
06/08/2022 08:11:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=437
06/08/2022 08:11:56 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.5413082437275986 on epoch=437
06/08/2022 08:11:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 08:12:01 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=442
06/08/2022 08:12:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 08:12:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=447
06/08/2022 08:12:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=449
06/08/2022 08:12:11 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.5898027898027898 on epoch=449
06/08/2022 08:12:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.00 on epoch=452
06/08/2022 08:12:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=454
06/08/2022 08:12:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/08/2022 08:12:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.00 on epoch=459
06/08/2022 08:12:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=462
06/08/2022 08:12:26 - INFO - __main__ - Global step 1850 Train loss 0.00 Classification-F1 0.5879275922781865 on epoch=462
06/08/2022 08:12:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 08:12:31 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 08:12:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 08:12:36 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 08:12:39 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=474
06/08/2022 08:12:40 - INFO - __main__ - Global step 1900 Train loss 0.00 Classification-F1 0.5421522921522921 on epoch=474
06/08/2022 08:12:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 08:12:46 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 08:12:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 08:12:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=484
06/08/2022 08:12:54 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=487
06/08/2022 08:12:55 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.579586038961039 on epoch=487
06/08/2022 08:12:58 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 08:13:01 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 08:13:03 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=494
06/08/2022 08:13:06 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 08:13:09 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 08:13:10 - INFO - __main__ - Global step 2000 Train loss 0.00 Classification-F1 0.5032278267572384 on epoch=499
06/08/2022 08:13:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=502
06/08/2022 08:13:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=504
06/08/2022 08:13:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 08:13:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 08:13:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=512
06/08/2022 08:13:25 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.5748563218390804 on epoch=512
06/08/2022 08:13:27 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 08:13:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 08:13:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 08:13:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 08:13:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 08:13:40 - INFO - __main__ - Global step 2100 Train loss 0.00 Classification-F1 0.546772224191579 on epoch=524
06/08/2022 08:13:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=527
06/08/2022 08:13:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=529
06/08/2022 08:13:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 08:13:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 08:13:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 08:13:54 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.5975831280788177 on epoch=537
06/08/2022 08:13:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 08:14:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 08:14:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 08:14:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 08:14:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=549
06/08/2022 08:14:09 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.5546639634874929 on epoch=549
06/08/2022 08:14:12 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=552
06/08/2022 08:14:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=554
06/08/2022 08:14:17 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 08:14:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 08:14:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 08:14:24 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5748167954050307 on epoch=562
06/08/2022 08:14:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/08/2022 08:14:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 08:14:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 08:14:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 08:14:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=574
06/08/2022 08:14:39 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6405110138429237 on epoch=574
06/08/2022 08:14:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 08:14:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 08:14:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 08:14:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=584
06/08/2022 08:14:52 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=587
06/08/2022 08:14:53 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.6559027777777777 on epoch=587
06/08/2022 08:14:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6530825496342737 -> 0.6559027777777777 on epoch=587, global_step=2350
06/08/2022 08:14:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=589
06/08/2022 08:14:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 08:15:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 08:15:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 08:15:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=599
06/08/2022 08:15:08 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.5537957074721781 on epoch=599
06/08/2022 08:15:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/08/2022 08:15:14 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 08:15:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 08:15:19 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 08:15:22 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 08:15:23 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6065407772304324 on epoch=612
06/08/2022 08:15:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=614
06/08/2022 08:15:28 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 08:15:31 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 08:15:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=622
06/08/2022 08:15:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=624
06/08/2022 08:15:38 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.5234585234585234 on epoch=624
06/08/2022 08:15:41 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=627
06/08/2022 08:15:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=629
06/08/2022 08:15:46 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 08:15:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 08:15:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 08:15:53 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5210254721124287 on epoch=637
06/08/2022 08:15:55 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 08:15:58 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 08:16:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=644
06/08/2022 08:16:03 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/08/2022 08:16:06 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 08:16:07 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.5485147527910685 on epoch=649
06/08/2022 08:16:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 08:16:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 08:16:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 08:16:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=659
06/08/2022 08:16:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 08:16:22 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.47935644399460187 on epoch=662
06/08/2022 08:16:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 08:16:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 08:16:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 08:16:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 08:16:36 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/08/2022 08:16:37 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.4789915966386554 on epoch=674
06/08/2022 08:16:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 08:16:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 08:16:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=682
06/08/2022 08:16:48 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 08:16:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 08:16:52 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.5127876984126984 on epoch=687
06/08/2022 08:16:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 08:16:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 08:17:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=694
06/08/2022 08:17:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 08:17:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=699
06/08/2022 08:17:07 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6071428571428571 on epoch=699
06/08/2022 08:17:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 08:17:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 08:17:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 08:17:18 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 08:17:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 08:17:22 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5157967032967032 on epoch=712
06/08/2022 08:17:25 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 08:17:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 08:17:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=719
06/08/2022 08:17:33 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 08:17:36 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 08:17:37 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.5610941169200346 on epoch=724
06/08/2022 08:17:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 08:17:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 08:17:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 08:17:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=734
06/08/2022 08:17:51 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 08:17:52 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.4957101806239737 on epoch=737
06/08/2022 08:17:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 08:17:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 08:18:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=744
06/08/2022 08:18:04 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.11 on epoch=747
06/08/2022 08:18:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=749
06/08/2022 08:18:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:18:08 - INFO - __main__ - Printing 3 examples
06/08/2022 08:18:08 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:18:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:18:08 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5894209956709957 on epoch=749
06/08/2022 08:18:08 - INFO - __main__ - save last model!
06/08/2022 08:18:08 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 08:18:08 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:18:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:18:08 - INFO - __main__ - Printing 3 examples
06/08/2022 08:18:08 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:18:08 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 08:18:08 - INFO - __main__ - Printing 3 examples
06/08/2022 08:18:08 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 08:18:08 - INFO - __main__ - ['others']
06/08/2022 08:18:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:18:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:18:08 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:18:10 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:18:16 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 08:18:26 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:18:26 - INFO - __main__ - task name: emo
06/08/2022 08:18:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:18:27 - INFO - __main__ - Starting training!
06/08/2022 08:20:06 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_87_0.4_8_predictions.txt
06/08/2022 08:20:06 - INFO - __main__ - Classification-F1 on test data: 0.0933
06/08/2022 08:20:07 - INFO - __main__ - prefix=emo_16_87, lr=0.4, bsz=8, dev_performance=0.6559027777777777, test_performance=0.09332281750939647
06/08/2022 08:20:07 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.3, bsz=8 ...
06/08/2022 08:20:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:20:08 - INFO - __main__ - Printing 3 examples
06/08/2022 08:20:08 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:20:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:20:08 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:20:08 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:20:08 - INFO - __main__ - Printing 3 examples
06/08/2022 08:20:08 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:20:08 - INFO - __main__ - ['others']
06/08/2022 08:20:08 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:20:08 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:20:08 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:20:24 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:20:24 - INFO - __main__ - task name: emo
06/08/2022 08:20:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:20:25 - INFO - __main__ - Starting training!
06/08/2022 08:20:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.57 on epoch=2
06/08/2022 08:20:30 - INFO - __main__ - Step 20 Global step 20 Train loss 3.14 on epoch=4
06/08/2022 08:20:33 - INFO - __main__ - Step 30 Global step 30 Train loss 1.61 on epoch=7
06/08/2022 08:20:36 - INFO - __main__ - Step 40 Global step 40 Train loss 1.27 on epoch=9
06/08/2022 08:20:39 - INFO - __main__ - Step 50 Global step 50 Train loss 1.14 on epoch=12
06/08/2022 08:20:40 - INFO - __main__ - Global step 50 Train loss 2.75 Classification-F1 0.18353174603174605 on epoch=12
06/08/2022 08:20:40 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.18353174603174605 on epoch=12, global_step=50
06/08/2022 08:20:43 - INFO - __main__ - Step 60 Global step 60 Train loss 1.07 on epoch=14
06/08/2022 08:20:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.09 on epoch=17
06/08/2022 08:20:48 - INFO - __main__ - Step 80 Global step 80 Train loss 1.02 on epoch=19
06/08/2022 08:20:51 - INFO - __main__ - Step 90 Global step 90 Train loss 1.05 on epoch=22
06/08/2022 08:20:54 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=24
06/08/2022 08:20:55 - INFO - __main__ - Global step 100 Train loss 1.04 Classification-F1 0.08904109589041095 on epoch=24
06/08/2022 08:20:58 - INFO - __main__ - Step 110 Global step 110 Train loss 0.95 on epoch=27
06/08/2022 08:21:01 - INFO - __main__ - Step 120 Global step 120 Train loss 1.01 on epoch=29
06/08/2022 08:21:03 - INFO - __main__ - Step 130 Global step 130 Train loss 1.01 on epoch=32
06/08/2022 08:21:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.93 on epoch=34
06/08/2022 08:21:09 - INFO - __main__ - Step 150 Global step 150 Train loss 0.96 on epoch=37
06/08/2022 08:21:10 - INFO - __main__ - Global step 150 Train loss 0.97 Classification-F1 0.19068450849202268 on epoch=37
06/08/2022 08:21:10 - INFO - __main__ - Saving model with best Classification-F1: 0.18353174603174605 -> 0.19068450849202268 on epoch=37, global_step=150
06/08/2022 08:21:13 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=39
06/08/2022 08:21:16 - INFO - __main__ - Step 170 Global step 170 Train loss 0.94 on epoch=42
06/08/2022 08:21:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.96 on epoch=44
06/08/2022 08:21:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=47
06/08/2022 08:21:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.96 on epoch=49
06/08/2022 08:21:25 - INFO - __main__ - Global step 200 Train loss 0.95 Classification-F1 0.38497150997151 on epoch=49
06/08/2022 08:21:25 - INFO - __main__ - Saving model with best Classification-F1: 0.19068450849202268 -> 0.38497150997151 on epoch=49, global_step=200
06/08/2022 08:21:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.96 on epoch=52
06/08/2022 08:21:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=54
06/08/2022 08:21:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.83 on epoch=57
06/08/2022 08:21:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.91 on epoch=59
06/08/2022 08:21:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.82 on epoch=62
06/08/2022 08:21:40 - INFO - __main__ - Global step 250 Train loss 0.88 Classification-F1 0.19943188543022844 on epoch=62
06/08/2022 08:21:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.89 on epoch=64
06/08/2022 08:21:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=67
06/08/2022 08:21:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.78 on epoch=69
06/08/2022 08:21:51 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=72
06/08/2022 08:21:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=74
06/08/2022 08:21:55 - INFO - __main__ - Global step 300 Train loss 0.81 Classification-F1 0.27029095130875314 on epoch=74
06/08/2022 08:21:58 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=77
06/08/2022 08:22:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=79
06/08/2022 08:22:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=82
06/08/2022 08:22:06 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=84
06/08/2022 08:22:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=87
06/08/2022 08:22:09 - INFO - __main__ - Global step 350 Train loss 0.68 Classification-F1 0.41927413671599717 on epoch=87
06/08/2022 08:22:09 - INFO - __main__ - Saving model with best Classification-F1: 0.38497150997151 -> 0.41927413671599717 on epoch=87, global_step=350
06/08/2022 08:22:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=89
06/08/2022 08:22:15 - INFO - __main__ - Step 370 Global step 370 Train loss 0.61 on epoch=92
06/08/2022 08:22:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.59 on epoch=94
06/08/2022 08:22:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=97
06/08/2022 08:22:23 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=99
06/08/2022 08:22:24 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.5033365261813538 on epoch=99
06/08/2022 08:22:24 - INFO - __main__ - Saving model with best Classification-F1: 0.41927413671599717 -> 0.5033365261813538 on epoch=99, global_step=400
06/08/2022 08:22:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=102
06/08/2022 08:22:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=104
06/08/2022 08:22:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=107
06/08/2022 08:22:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=109
06/08/2022 08:22:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=112
06/08/2022 08:22:40 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.5471193792766373 on epoch=112
06/08/2022 08:22:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5033365261813538 -> 0.5471193792766373 on epoch=112, global_step=450
06/08/2022 08:22:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=114
06/08/2022 08:22:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=117
06/08/2022 08:22:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=119
06/08/2022 08:22:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.25 on epoch=122
06/08/2022 08:22:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=124
06/08/2022 08:22:55 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.5190302911093627 on epoch=124
06/08/2022 08:22:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=127
06/08/2022 08:23:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=129
06/08/2022 08:23:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=132
06/08/2022 08:23:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=134
06/08/2022 08:23:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=137
06/08/2022 08:23:10 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.5474941724941724 on epoch=137
06/08/2022 08:23:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5471193792766373 -> 0.5474941724941724 on epoch=137, global_step=550
06/08/2022 08:23:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=139
06/08/2022 08:23:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=142
06/08/2022 08:23:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=144
06/08/2022 08:23:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=147
06/08/2022 08:23:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=149
06/08/2022 08:23:25 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.5646106581590453 on epoch=149
06/08/2022 08:23:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5474941724941724 -> 0.5646106581590453 on epoch=149, global_step=600
06/08/2022 08:23:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=152
06/08/2022 08:23:30 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=154
06/08/2022 08:23:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=157
06/08/2022 08:23:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.13 on epoch=159
06/08/2022 08:23:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.10 on epoch=162
06/08/2022 08:23:40 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.5668588880432449 on epoch=162
06/08/2022 08:23:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5646106581590453 -> 0.5668588880432449 on epoch=162, global_step=650
06/08/2022 08:23:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.08 on epoch=164
06/08/2022 08:23:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=167
06/08/2022 08:23:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.05 on epoch=169
06/08/2022 08:23:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=172
06/08/2022 08:23:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.06 on epoch=174
06/08/2022 08:23:55 - INFO - __main__ - Global step 700 Train loss 0.08 Classification-F1 0.5458646616541353 on epoch=174
06/08/2022 08:23:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.02 on epoch=177
06/08/2022 08:24:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.07 on epoch=179
06/08/2022 08:24:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.04 on epoch=182
06/08/2022 08:24:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.03 on epoch=184
06/08/2022 08:24:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=187
06/08/2022 08:24:10 - INFO - __main__ - Global step 750 Train loss 0.07 Classification-F1 0.533238072556958 on epoch=187
06/08/2022 08:24:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=189
06/08/2022 08:24:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.10 on epoch=192
06/08/2022 08:24:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/08/2022 08:24:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=197
06/08/2022 08:24:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.04 on epoch=199
06/08/2022 08:24:25 - INFO - __main__ - Global step 800 Train loss 0.07 Classification-F1 0.6242647058823529 on epoch=199
06/08/2022 08:24:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5668588880432449 -> 0.6242647058823529 on epoch=199, global_step=800
06/08/2022 08:24:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=202
06/08/2022 08:24:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.06 on epoch=204
06/08/2022 08:24:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.05 on epoch=207
06/08/2022 08:24:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=209
06/08/2022 08:24:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=212
06/08/2022 08:24:40 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.6211627906976744 on epoch=212
06/08/2022 08:24:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.03 on epoch=214
06/08/2022 08:24:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.03 on epoch=217
06/08/2022 08:24:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.04 on epoch=219
06/08/2022 08:24:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=222
06/08/2022 08:24:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.01 on epoch=224
06/08/2022 08:24:55 - INFO - __main__ - Global step 900 Train loss 0.03 Classification-F1 0.588456943295653 on epoch=224
06/08/2022 08:24:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=227
06/08/2022 08:25:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.03 on epoch=229
06/08/2022 08:25:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.01 on epoch=232
06/08/2022 08:25:07 - INFO - __main__ - Step 940 Global step 940 Train loss 0.01 on epoch=234
06/08/2022 08:25:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=237
06/08/2022 08:25:11 - INFO - __main__ - Global step 950 Train loss 0.03 Classification-F1 0.5797510206428612 on epoch=237
06/08/2022 08:25:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.01 on epoch=239
06/08/2022 08:25:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.02 on epoch=242
06/08/2022 08:25:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.01 on epoch=244
06/08/2022 08:25:22 - INFO - __main__ - Step 990 Global step 990 Train loss 0.01 on epoch=247
06/08/2022 08:25:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.01 on epoch=249
06/08/2022 08:25:26 - INFO - __main__ - Global step 1000 Train loss 0.02 Classification-F1 0.671253167099246 on epoch=249
06/08/2022 08:25:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6242647058823529 -> 0.671253167099246 on epoch=249, global_step=1000
06/08/2022 08:25:29 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=252
06/08/2022 08:25:32 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=254
06/08/2022 08:25:34 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=257
06/08/2022 08:25:37 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.02 on epoch=259
06/08/2022 08:25:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=262
06/08/2022 08:25:41 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.5976220786003394 on epoch=262
06/08/2022 08:25:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=264
06/08/2022 08:25:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.01 on epoch=267
06/08/2022 08:25:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=269
06/08/2022 08:25:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/08/2022 08:25:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=274
06/08/2022 08:25:56 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.5884643779992618 on epoch=274
06/08/2022 08:25:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=277
06/08/2022 08:26:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.02 on epoch=279
06/08/2022 08:26:05 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=282
06/08/2022 08:26:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=284
06/08/2022 08:26:10 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=287
06/08/2022 08:26:12 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.6006147402838171 on epoch=287
06/08/2022 08:26:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=289
06/08/2022 08:26:17 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.02 on epoch=292
06/08/2022 08:26:20 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 08:26:23 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.02 on epoch=297
06/08/2022 08:26:26 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=299
06/08/2022 08:26:27 - INFO - __main__ - Global step 1200 Train loss 0.02 Classification-F1 0.5964285714285714 on epoch=299
06/08/2022 08:26:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=302
06/08/2022 08:26:32 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.01 on epoch=304
06/08/2022 08:26:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=307
06/08/2022 08:26:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.00 on epoch=309
06/08/2022 08:26:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.00 on epoch=312
06/08/2022 08:26:42 - INFO - __main__ - Global step 1250 Train loss 0.02 Classification-F1 0.5896768744551003 on epoch=312
06/08/2022 08:26:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 08:26:47 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=317
06/08/2022 08:26:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=319
06/08/2022 08:26:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.01 on epoch=322
06/08/2022 08:26:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 08:26:57 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.6411390949341613 on epoch=324
06/08/2022 08:27:00 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.00 on epoch=327
06/08/2022 08:27:02 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/08/2022 08:27:05 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=332
06/08/2022 08:27:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/08/2022 08:27:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=337
06/08/2022 08:27:12 - INFO - __main__ - Global step 1350 Train loss 0.02 Classification-F1 0.6064794215795328 on epoch=337
06/08/2022 08:27:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 08:27:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.00 on epoch=342
06/08/2022 08:27:20 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.00 on epoch=344
06/08/2022 08:27:23 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=347
06/08/2022 08:27:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.01 on epoch=349
06/08/2022 08:27:27 - INFO - __main__ - Global step 1400 Train loss 0.01 Classification-F1 0.6250100626760968 on epoch=349
06/08/2022 08:27:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=352
06/08/2022 08:27:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/08/2022 08:27:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.00 on epoch=357
06/08/2022 08:27:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.00 on epoch=359
06/08/2022 08:27:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=362
06/08/2022 08:27:41 - INFO - __main__ - Global step 1450 Train loss 0.01 Classification-F1 0.6410331384015595 on epoch=362
06/08/2022 08:27:44 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.01 on epoch=364
06/08/2022 08:27:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 08:27:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 08:27:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.00 on epoch=372
06/08/2022 08:27:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.01 on epoch=374
06/08/2022 08:27:57 - INFO - __main__ - Global step 1500 Train loss 0.00 Classification-F1 0.6266319640948249 on epoch=374
06/08/2022 08:27:59 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.00 on epoch=377
06/08/2022 08:28:02 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/08/2022 08:28:05 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.00 on epoch=382
06/08/2022 08:28:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 08:28:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.01 on epoch=387
06/08/2022 08:28:12 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.6285714285714286 on epoch=387
06/08/2022 08:28:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=389
06/08/2022 08:28:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.00 on epoch=392
06/08/2022 08:28:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=394
06/08/2022 08:28:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.00 on epoch=397
06/08/2022 08:28:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=399
06/08/2022 08:28:27 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.606935634188137 on epoch=399
06/08/2022 08:28:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.00 on epoch=402
06/08/2022 08:28:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.00 on epoch=404
06/08/2022 08:28:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.00 on epoch=407
06/08/2022 08:28:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/08/2022 08:28:42 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=412
06/08/2022 08:28:43 - INFO - __main__ - Global step 1650 Train loss 0.00 Classification-F1 0.6249471966205837 on epoch=412
06/08/2022 08:28:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=414
06/08/2022 08:28:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=417
06/08/2022 08:28:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=419
06/08/2022 08:28:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=422
06/08/2022 08:28:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 08:28:58 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.5890964240102171 on epoch=424
06/08/2022 08:29:01 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.00 on epoch=427
06/08/2022 08:29:04 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=429
06/08/2022 08:29:07 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 08:29:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/08/2022 08:29:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/08/2022 08:29:14 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6316436251920123 on epoch=437
06/08/2022 08:29:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=439
06/08/2022 08:29:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=442
06/08/2022 08:29:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 08:29:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.00 on epoch=447
06/08/2022 08:29:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 08:29:29 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.621969696969697 on epoch=449
06/08/2022 08:29:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=452
06/08/2022 08:29:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 08:29:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=457
06/08/2022 08:29:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/08/2022 08:29:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=462
06/08/2022 08:29:45 - INFO - __main__ - Global step 1850 Train loss 0.01 Classification-F1 0.6062467997951869 on epoch=462
06/08/2022 08:29:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 08:29:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=467
06/08/2022 08:29:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 08:29:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=472
06/08/2022 08:29:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=474
06/08/2022 08:30:00 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6068282444942786 on epoch=474
06/08/2022 08:30:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=477
06/08/2022 08:30:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 08:30:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=482
06/08/2022 08:30:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=484
06/08/2022 08:30:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 08:30:16 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.5651447245564893 on epoch=487
06/08/2022 08:30:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=489
06/08/2022 08:30:21 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 08:30:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.00 on epoch=494
06/08/2022 08:30:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.36 on epoch=497
06/08/2022 08:30:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.50 on epoch=499
06/08/2022 08:30:31 - INFO - __main__ - Global step 2000 Train loss 0.18 Classification-F1 0.6141155386885937 on epoch=499
06/08/2022 08:30:34 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 08:30:37 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 08:30:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=507
06/08/2022 08:30:42 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=509
06/08/2022 08:30:45 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.00 on epoch=512
06/08/2022 08:30:47 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.6078518173345759 on epoch=512
06/08/2022 08:30:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 08:30:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 08:30:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 08:30:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=522
06/08/2022 08:31:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=524
06/08/2022 08:31:02 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6192019818680161 on epoch=524
06/08/2022 08:31:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=527
06/08/2022 08:31:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 08:31:11 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=532
06/08/2022 08:31:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=534
06/08/2022 08:31:16 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 08:31:17 - INFO - __main__ - Global step 2150 Train loss 0.00 Classification-F1 0.6045679231163102 on epoch=537
06/08/2022 08:31:20 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=539
06/08/2022 08:31:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 08:31:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 08:31:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 08:31:32 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 08:31:33 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6486398421882292 on epoch=549
06/08/2022 08:31:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 08:31:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 08:31:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=557
06/08/2022 08:31:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=559
06/08/2022 08:31:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 08:31:48 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6571428571428571 on epoch=562
06/08/2022 08:31:51 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=564
06/08/2022 08:31:54 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=567
06/08/2022 08:31:57 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=569
06/08/2022 08:32:00 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=572
06/08/2022 08:32:03 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=574
06/08/2022 08:32:04 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6256109481915934 on epoch=574
06/08/2022 08:32:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 08:32:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 08:32:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 08:32:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=584
06/08/2022 08:32:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 08:32:20 - INFO - __main__ - Global step 2350 Train loss 0.00 Classification-F1 0.6202922077922078 on epoch=587
06/08/2022 08:32:23 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=589
06/08/2022 08:32:25 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=592
06/08/2022 08:32:28 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 08:32:31 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 08:32:34 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=599
06/08/2022 08:32:35 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.6321924603174602 on epoch=599
06/08/2022 08:32:38 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=602
06/08/2022 08:32:41 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=604
06/08/2022 08:32:44 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=607
06/08/2022 08:32:47 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 08:32:50 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=612
06/08/2022 08:32:51 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.6202922077922078 on epoch=612
06/08/2022 08:32:54 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 08:32:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=617
06/08/2022 08:33:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 08:33:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 08:33:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 08:33:07 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6479779411764706 on epoch=624
06/08/2022 08:33:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 08:33:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=629
06/08/2022 08:33:15 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 08:33:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 08:33:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 08:33:22 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6538624787775891 on epoch=637
06/08/2022 08:33:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 08:33:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=642
06/08/2022 08:33:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 08:33:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=647
06/08/2022 08:33:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=649
06/08/2022 08:33:37 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.636029411764706 on epoch=649
06/08/2022 08:33:40 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.25 on epoch=652
06/08/2022 08:33:43 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=654
06/08/2022 08:33:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 08:33:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=659
06/08/2022 08:33:52 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 08:33:53 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6192504627988499 on epoch=662
06/08/2022 08:33:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 08:33:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 08:34:02 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=669
06/08/2022 08:34:05 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 08:34:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=674
06/08/2022 08:34:09 - INFO - __main__ - Global step 2700 Train loss 0.00 Classification-F1 0.6410528434247599 on epoch=674
06/08/2022 08:34:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 08:34:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 08:34:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 08:34:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=684
06/08/2022 08:34:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=687
06/08/2022 08:34:25 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6561547462548574 on epoch=687
06/08/2022 08:34:28 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=689
06/08/2022 08:34:30 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=692
06/08/2022 08:34:33 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=694
06/08/2022 08:34:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 08:34:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 08:34:40 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.6537743506493506 on epoch=699
06/08/2022 08:34:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=702
06/08/2022 08:34:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 08:34:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 08:34:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=709
06/08/2022 08:34:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 08:34:56 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6374566511810508 on epoch=712
06/08/2022 08:34:59 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 08:35:02 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 08:35:04 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 08:35:07 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 08:35:10 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 08:35:11 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.6124144672531769 on epoch=724
06/08/2022 08:35:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=727
06/08/2022 08:35:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=729
06/08/2022 08:35:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 08:35:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 08:35:26 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 08:35:27 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6209681756715226 on epoch=737
06/08/2022 08:35:30 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 08:35:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 08:35:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 08:35:39 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=747
06/08/2022 08:35:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 08:35:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:35:43 - INFO - __main__ - Printing 3 examples
06/08/2022 08:35:43 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:35:43 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:35:43 - INFO - __main__ - Global step 3000 Train loss 0.00 Classification-F1 0.6074754901960785 on epoch=749
06/08/2022 08:35:43 - INFO - __main__ - save last model!
06/08/2022 08:35:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 08:35:43 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:35:43 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:35:43 - INFO - __main__ - Printing 3 examples
06/08/2022 08:35:43 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:35:43 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 08:35:43 - INFO - __main__ - Printing 3 examples
06/08/2022 08:35:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 08:35:43 - INFO - __main__ - ['others']
06/08/2022 08:35:43 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:35:43 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:35:43 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:35:45 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:35:51 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 08:36:00 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:36:00 - INFO - __main__ - task name: emo
06/08/2022 08:36:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:36:00 - INFO - __main__ - Starting training!
06/08/2022 08:37:44 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_87_0.3_8_predictions.txt
06/08/2022 08:37:44 - INFO - __main__ - Classification-F1 on test data: 0.3662
06/08/2022 08:37:44 - INFO - __main__ - prefix=emo_16_87, lr=0.3, bsz=8, dev_performance=0.671253167099246, test_performance=0.3662035833259274
06/08/2022 08:37:44 - INFO - __main__ - Running ... prefix=emo_16_87, lr=0.2, bsz=8 ...
06/08/2022 08:37:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:37:45 - INFO - __main__ - Printing 3 examples
06/08/2022 08:37:45 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:37:45 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:37:45 - INFO - __main__ - Loaded 64 examples from train data
06/08/2022 08:37:45 - INFO - __main__ - Start tokenizing ... 64 instances
06/08/2022 08:37:45 - INFO - __main__ - Printing 3 examples
06/08/2022 08:37:45 - INFO - __main__ -  [emo] you 5050 hahaha not even close haha slightlysmilingface yas
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ -  [emo] punjabi movie as a punjabi this is my answer too you are giving diplomatic ans
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ -  [emo] for exaple what kind of music do you listen to rap music for example eminem
06/08/2022 08:37:45 - INFO - __main__ - ['others']
06/08/2022 08:37:45 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:37:45 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:37:45 - INFO - __main__ - Loaded 64 examples from dev data
06/08/2022 08:38:00 - INFO - __main__ - try to initialize prompt embeddings
06/08/2022 08:38:00 - INFO - __main__ - task name: emo
06/08/2022 08:38:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/08/2022 08:38:01 - INFO - __main__ - Starting training!
06/08/2022 08:38:04 - INFO - __main__ - Step 10 Global step 10 Train loss 7.06 on epoch=2
06/08/2022 08:38:07 - INFO - __main__ - Step 20 Global step 20 Train loss 4.30 on epoch=4
06/08/2022 08:38:10 - INFO - __main__ - Step 30 Global step 30 Train loss 2.54 on epoch=7
06/08/2022 08:38:12 - INFO - __main__ - Step 40 Global step 40 Train loss 1.54 on epoch=9
06/08/2022 08:38:15 - INFO - __main__ - Step 50 Global step 50 Train loss 1.13 on epoch=12
06/08/2022 08:38:16 - INFO - __main__ - Global step 50 Train loss 3.31 Classification-F1 0.1 on epoch=12
06/08/2022 08:38:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1 on epoch=12, global_step=50
06/08/2022 08:38:19 - INFO - __main__ - Step 60 Global step 60 Train loss 1.10 on epoch=14
06/08/2022 08:38:22 - INFO - __main__ - Step 70 Global step 70 Train loss 1.01 on epoch=17
06/08/2022 08:38:24 - INFO - __main__ - Step 80 Global step 80 Train loss 0.98 on epoch=19
06/08/2022 08:38:27 - INFO - __main__ - Step 90 Global step 90 Train loss 1.00 on epoch=22
06/08/2022 08:38:30 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=24
06/08/2022 08:38:31 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.1 on epoch=24
06/08/2022 08:38:34 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=27
06/08/2022 08:38:37 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=29
06/08/2022 08:38:39 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=32
06/08/2022 08:38:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=34
06/08/2022 08:38:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.84 on epoch=37
06/08/2022 08:38:46 - INFO - __main__ - Global step 150 Train loss 0.90 Classification-F1 0.19722222222222222 on epoch=37
06/08/2022 08:38:46 - INFO - __main__ - Saving model with best Classification-F1: 0.1 -> 0.19722222222222222 on epoch=37, global_step=150
06/08/2022 08:38:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.93 on epoch=39
06/08/2022 08:38:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=42
06/08/2022 08:38:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.95 on epoch=44
06/08/2022 08:38:57 - INFO - __main__ - Step 190 Global step 190 Train loss 0.87 on epoch=47
06/08/2022 08:39:00 - INFO - __main__ - Step 200 Global step 200 Train loss 0.87 on epoch=49
06/08/2022 08:39:01 - INFO - __main__ - Global step 200 Train loss 0.90 Classification-F1 0.10526315789473685 on epoch=49
06/08/2022 08:39:04 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=52
06/08/2022 08:39:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=54
06/08/2022 08:39:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.84 on epoch=57
06/08/2022 08:39:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=59
06/08/2022 08:39:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.87 on epoch=62
06/08/2022 08:39:16 - INFO - __main__ - Global step 250 Train loss 0.83 Classification-F1 0.31558782012502523 on epoch=62
06/08/2022 08:39:16 - INFO - __main__ - Saving model with best Classification-F1: 0.19722222222222222 -> 0.31558782012502523 on epoch=62, global_step=250
06/08/2022 08:39:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.79 on epoch=64
06/08/2022 08:39:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=67
06/08/2022 08:39:24 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=69
06/08/2022 08:39:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=72
06/08/2022 08:39:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.73 on epoch=74
06/08/2022 08:39:31 - INFO - __main__ - Global step 300 Train loss 0.74 Classification-F1 0.21485380116959063 on epoch=74
06/08/2022 08:39:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=77
06/08/2022 08:39:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=79
06/08/2022 08:39:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.75 on epoch=82
06/08/2022 08:39:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.72 on epoch=84
06/08/2022 08:39:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.77 on epoch=87
06/08/2022 08:39:46 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.28197274031563846 on epoch=87
06/08/2022 08:39:49 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=89
06/08/2022 08:39:52 - INFO - __main__ - Step 370 Global step 370 Train loss 0.78 on epoch=92
06/08/2022 08:39:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.66 on epoch=94
06/08/2022 08:39:57 - INFO - __main__ - Step 390 Global step 390 Train loss 0.77 on epoch=97
06/08/2022 08:40:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.66 on epoch=99
06/08/2022 08:40:01 - INFO - __main__ - Global step 400 Train loss 0.71 Classification-F1 0.45531746031746034 on epoch=99
06/08/2022 08:40:01 - INFO - __main__ - Saving model with best Classification-F1: 0.31558782012502523 -> 0.45531746031746034 on epoch=99, global_step=400
06/08/2022 08:40:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.66 on epoch=102
06/08/2022 08:40:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.67 on epoch=104
06/08/2022 08:40:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.64 on epoch=107
06/08/2022 08:40:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=109
06/08/2022 08:40:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.73 on epoch=112
06/08/2022 08:40:17 - INFO - __main__ - Global step 450 Train loss 0.68 Classification-F1 0.514423076923077 on epoch=112
06/08/2022 08:40:17 - INFO - __main__ - Saving model with best Classification-F1: 0.45531746031746034 -> 0.514423076923077 on epoch=112, global_step=450
06/08/2022 08:40:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.66 on epoch=114
06/08/2022 08:40:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.63 on epoch=117
06/08/2022 08:40:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.51 on epoch=119
06/08/2022 08:40:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=122
06/08/2022 08:40:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=124
06/08/2022 08:40:32 - INFO - __main__ - Global step 500 Train loss 0.59 Classification-F1 0.5433087027914615 on epoch=124
06/08/2022 08:40:32 - INFO - __main__ - Saving model with best Classification-F1: 0.514423076923077 -> 0.5433087027914615 on epoch=124, global_step=500
06/08/2022 08:40:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=127
06/08/2022 08:40:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.58 on epoch=129
06/08/2022 08:40:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.59 on epoch=132
06/08/2022 08:40:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=134
06/08/2022 08:40:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.46 on epoch=137
06/08/2022 08:40:47 - INFO - __main__ - Global step 550 Train loss 0.54 Classification-F1 0.38026054590570724 on epoch=137
06/08/2022 08:40:50 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=139
06/08/2022 08:40:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.51 on epoch=142
06/08/2022 08:40:56 - INFO - __main__ - Step 580 Global step 580 Train loss 0.39 on epoch=144
06/08/2022 08:40:58 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=147
06/08/2022 08:41:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.35 on epoch=149
06/08/2022 08:41:02 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.6419298245614035 on epoch=149
06/08/2022 08:41:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5433087027914615 -> 0.6419298245614035 on epoch=149, global_step=600
06/08/2022 08:41:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=152
06/08/2022 08:41:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=154
06/08/2022 08:41:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=157
06/08/2022 08:41:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.29 on epoch=159
06/08/2022 08:41:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=162
06/08/2022 08:41:17 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.5890993295085366 on epoch=162
06/08/2022 08:41:20 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=164
06/08/2022 08:41:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=167
06/08/2022 08:41:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=169
06/08/2022 08:41:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=172
06/08/2022 08:41:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.18 on epoch=174
06/08/2022 08:41:33 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.6284722222222222 on epoch=174
06/08/2022 08:41:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=177
06/08/2022 08:41:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=179
06/08/2022 08:41:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=182
06/08/2022 08:41:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=184
06/08/2022 08:41:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=187
06/08/2022 08:41:48 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.6807692307692308 on epoch=187
06/08/2022 08:41:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6419298245614035 -> 0.6807692307692308 on epoch=187, global_step=750
06/08/2022 08:41:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.09 on epoch=189
06/08/2022 08:41:54 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=192
06/08/2022 08:41:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=194
06/08/2022 08:41:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=197
06/08/2022 08:42:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=199
06/08/2022 08:42:04 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.666368075007781 on epoch=199
06/08/2022 08:42:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.04 on epoch=202
06/08/2022 08:42:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=204
06/08/2022 08:42:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=207
06/08/2022 08:42:15 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=209
06/08/2022 08:42:17 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=212
06/08/2022 08:42:19 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7491401802656547 on epoch=212
06/08/2022 08:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6807692307692308 -> 0.7491401802656547 on epoch=212, global_step=850
06/08/2022 08:42:22 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=214
06/08/2022 08:42:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=217
06/08/2022 08:42:27 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=219
06/08/2022 08:42:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.04 on epoch=222
06/08/2022 08:42:33 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=224
06/08/2022 08:42:34 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.7346376050420169 on epoch=224
06/08/2022 08:42:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.03 on epoch=227
06/08/2022 08:42:40 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=229
06/08/2022 08:42:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=232
06/08/2022 08:42:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.03 on epoch=234
06/08/2022 08:42:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=237
06/08/2022 08:42:50 - INFO - __main__ - Global step 950 Train loss 0.04 Classification-F1 0.7498121035384661 on epoch=237
06/08/2022 08:42:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7491401802656547 -> 0.7498121035384661 on epoch=237, global_step=950
06/08/2022 08:42:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=239
06/08/2022 08:42:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=242
06/08/2022 08:42:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=244
06/08/2022 08:43:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=247
06/08/2022 08:43:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.02 on epoch=249
06/08/2022 08:43:05 - INFO - __main__ - Global step 1000 Train loss 0.05 Classification-F1 0.729016029016029 on epoch=249
06/08/2022 08:43:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.03 on epoch=252
06/08/2022 08:43:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.04 on epoch=254
06/08/2022 08:43:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=257
06/08/2022 08:43:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=259
06/08/2022 08:43:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.04 on epoch=262
06/08/2022 08:43:21 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7424862661704767 on epoch=262
06/08/2022 08:43:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=264
06/08/2022 08:43:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.03 on epoch=267
06/08/2022 08:43:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.02 on epoch=269
06/08/2022 08:43:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=272
06/08/2022 08:43:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=274
06/08/2022 08:43:36 - INFO - __main__ - Global step 1100 Train loss 0.03 Classification-F1 0.6875791490219803 on epoch=274
06/08/2022 08:43:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=277
06/08/2022 08:43:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=279
06/08/2022 08:43:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.02 on epoch=282
06/08/2022 08:43:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.01 on epoch=284
06/08/2022 08:43:50 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=287
06/08/2022 08:43:52 - INFO - __main__ - Global step 1150 Train loss 0.04 Classification-F1 0.7002590661100117 on epoch=287
06/08/2022 08:43:54 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.02 on epoch=289
06/08/2022 08:43:57 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=292
06/08/2022 08:44:00 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=294
06/08/2022 08:44:03 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=297
06/08/2022 08:44:06 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.01 on epoch=299
06/08/2022 08:44:07 - INFO - __main__ - Global step 1200 Train loss 0.03 Classification-F1 0.6540229885057471 on epoch=299
06/08/2022 08:44:10 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=302
06/08/2022 08:44:13 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=304
06/08/2022 08:44:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.03 on epoch=307
06/08/2022 08:44:18 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=309
06/08/2022 08:44:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.01 on epoch=312
06/08/2022 08:44:23 - INFO - __main__ - Global step 1250 Train loss 0.04 Classification-F1 0.6396551724137931 on epoch=312
06/08/2022 08:44:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.00 on epoch=314
06/08/2022 08:44:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=317
06/08/2022 08:44:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.01 on epoch=319
06/08/2022 08:44:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=322
06/08/2022 08:44:37 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.01 on epoch=324
06/08/2022 08:44:38 - INFO - __main__ - Global step 1300 Train loss 0.02 Classification-F1 0.7325071157495255 on epoch=324
06/08/2022 08:44:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=327
06/08/2022 08:44:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.01 on epoch=329
06/08/2022 08:44:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=332
06/08/2022 08:44:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=334
06/08/2022 08:44:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.01 on epoch=337
06/08/2022 08:44:54 - INFO - __main__ - Global step 1350 Train loss 0.01 Classification-F1 0.7426939885556185 on epoch=337
06/08/2022 08:44:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.00 on epoch=339
06/08/2022 08:45:00 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=342
06/08/2022 08:45:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=344
06/08/2022 08:45:05 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=347
06/08/2022 08:45:08 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.00 on epoch=349
06/08/2022 08:45:10 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7105626452400646 on epoch=349
06/08/2022 08:45:12 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=352
06/08/2022 08:45:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.01 on epoch=354
06/08/2022 08:45:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=357
06/08/2022 08:45:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=359
06/08/2022 08:45:24 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=362
06/08/2022 08:45:25 - INFO - __main__ - Global step 1450 Train loss 0.02 Classification-F1 0.7329313272056671 on epoch=362
06/08/2022 08:45:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=364
06/08/2022 08:45:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.00 on epoch=367
06/08/2022 08:45:34 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.00 on epoch=369
06/08/2022 08:45:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=372
06/08/2022 08:45:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.00 on epoch=374
06/08/2022 08:45:41 - INFO - __main__ - Global step 1500 Train loss 0.01 Classification-F1 0.7320631700956244 on epoch=374
06/08/2022 08:45:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=377
06/08/2022 08:45:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=379
06/08/2022 08:45:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=382
06/08/2022 08:45:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.00 on epoch=384
06/08/2022 08:45:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=387
06/08/2022 08:45:56 - INFO - __main__ - Global step 1550 Train loss 0.01 Classification-F1 0.7006000384024578 on epoch=387
06/08/2022 08:45:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=389
06/08/2022 08:46:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=392
06/08/2022 08:46:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=394
06/08/2022 08:46:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=397
06/08/2022 08:46:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=399
06/08/2022 08:46:12 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7110390751282593 on epoch=399
06/08/2022 08:46:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=402
06/08/2022 08:46:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=404
06/08/2022 08:46:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=407
06/08/2022 08:46:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=409
06/08/2022 08:46:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.00 on epoch=412
06/08/2022 08:46:27 - INFO - __main__ - Global step 1650 Train loss 0.01 Classification-F1 0.7231602762562515 on epoch=412
06/08/2022 08:46:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.00 on epoch=414
06/08/2022 08:46:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=417
06/08/2022 08:46:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.00 on epoch=419
06/08/2022 08:46:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=422
06/08/2022 08:46:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.00 on epoch=424
06/08/2022 08:46:43 - INFO - __main__ - Global step 1700 Train loss 0.01 Classification-F1 0.655423959428536 on epoch=424
06/08/2022 08:46:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=427
06/08/2022 08:46:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=429
06/08/2022 08:46:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=432
06/08/2022 08:46:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=434
06/08/2022 08:46:57 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=437
06/08/2022 08:46:58 - INFO - __main__ - Global step 1750 Train loss 0.01 Classification-F1 0.6423423423423422 on epoch=437
06/08/2022 08:47:01 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=439
06/08/2022 08:47:04 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=442
06/08/2022 08:47:07 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.00 on epoch=444
06/08/2022 08:47:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=447
06/08/2022 08:47:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=449
06/08/2022 08:47:14 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.7141634042635155 on epoch=449
06/08/2022 08:47:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=452
06/08/2022 08:47:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.00 on epoch=454
06/08/2022 08:47:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=457
06/08/2022 08:47:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=459
06/08/2022 08:47:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=462
06/08/2022 08:47:29 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.700304771856496 on epoch=462
06/08/2022 08:47:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.00 on epoch=464
06/08/2022 08:47:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.00 on epoch=467
06/08/2022 08:47:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.00 on epoch=469
06/08/2022 08:47:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=472
06/08/2022 08:47:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=474
06/08/2022 08:47:45 - INFO - __main__ - Global step 1900 Train loss 0.01 Classification-F1 0.6773809523809524 on epoch=474
06/08/2022 08:47:48 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.00 on epoch=477
06/08/2022 08:47:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.00 on epoch=479
06/08/2022 08:47:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=482
06/08/2022 08:47:56 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=484
06/08/2022 08:47:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=487
06/08/2022 08:48:01 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.6629078351988569 on epoch=487
06/08/2022 08:48:04 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.00 on epoch=489
06/08/2022 08:48:06 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=492
06/08/2022 08:48:09 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=494
06/08/2022 08:48:12 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.00 on epoch=497
06/08/2022 08:48:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=499
06/08/2022 08:48:16 - INFO - __main__ - Global step 2000 Train loss 0.01 Classification-F1 0.6576717637201509 on epoch=499
06/08/2022 08:48:19 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=502
06/08/2022 08:48:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=504
06/08/2022 08:48:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=507
06/08/2022 08:48:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.00 on epoch=509
06/08/2022 08:48:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=512
06/08/2022 08:48:32 - INFO - __main__ - Global step 2050 Train loss 0.00 Classification-F1 0.6311342592592593 on epoch=512
06/08/2022 08:48:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=514
06/08/2022 08:48:38 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=517
06/08/2022 08:48:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.00 on epoch=519
06/08/2022 08:48:43 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=522
06/08/2022 08:48:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=524
06/08/2022 08:48:47 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.6140979689366786 on epoch=524
06/08/2022 08:48:50 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=527
06/08/2022 08:48:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=529
06/08/2022 08:48:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=532
06/08/2022 08:48:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.00 on epoch=534
06/08/2022 08:49:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=537
06/08/2022 08:49:03 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.686217008797654 on epoch=537
06/08/2022 08:49:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=539
06/08/2022 08:49:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=542
06/08/2022 08:49:11 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=544
06/08/2022 08:49:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.00 on epoch=547
06/08/2022 08:49:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.00 on epoch=549
06/08/2022 08:49:18 - INFO - __main__ - Global step 2200 Train loss 0.00 Classification-F1 0.6856161232821575 on epoch=549
06/08/2022 08:49:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=552
06/08/2022 08:49:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=554
06/08/2022 08:49:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=557
06/08/2022 08:49:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=559
06/08/2022 08:49:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=562
06/08/2022 08:49:33 - INFO - __main__ - Global step 2250 Train loss 0.00 Classification-F1 0.6688460061443933 on epoch=562
06/08/2022 08:49:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=564
06/08/2022 08:49:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=567
06/08/2022 08:49:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=569
06/08/2022 08:49:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=572
06/08/2022 08:49:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=574
06/08/2022 08:49:49 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.6202898550724637 on epoch=574
06/08/2022 08:49:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=577
06/08/2022 08:49:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.00 on epoch=579
06/08/2022 08:49:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=582
06/08/2022 08:50:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=584
06/08/2022 08:50:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=587
06/08/2022 08:50:04 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7161764705882353 on epoch=587
06/08/2022 08:50:07 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=589
06/08/2022 08:50:10 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=592
06/08/2022 08:50:13 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=594
06/08/2022 08:50:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=597
06/08/2022 08:50:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=599
06/08/2022 08:50:20 - INFO - __main__ - Global step 2400 Train loss 0.00 Classification-F1 0.7477150537634408 on epoch=599
06/08/2022 08:50:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=602
06/08/2022 08:50:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=604
06/08/2022 08:50:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=607
06/08/2022 08:50:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=609
06/08/2022 08:50:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=612
06/08/2022 08:50:36 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.7141923379531561 on epoch=612
06/08/2022 08:50:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=614
06/08/2022 08:50:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=617
06/08/2022 08:50:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=619
06/08/2022 08:50:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=622
06/08/2022 08:50:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=624
06/08/2022 08:50:51 - INFO - __main__ - Global step 2500 Train loss 0.00 Classification-F1 0.6874999999999999 on epoch=624
06/08/2022 08:50:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=627
06/08/2022 08:50:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=629
06/08/2022 08:51:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=632
06/08/2022 08:51:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=634
06/08/2022 08:51:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=637
06/08/2022 08:51:07 - INFO - __main__ - Global step 2550 Train loss 0.00 Classification-F1 0.7181019585253456 on epoch=637
06/08/2022 08:51:10 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=639
06/08/2022 08:51:13 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=642
06/08/2022 08:51:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=644
06/08/2022 08:51:19 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=647
06/08/2022 08:51:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=649
06/08/2022 08:51:23 - INFO - __main__ - Global step 2600 Train loss 0.00 Classification-F1 0.7192240627724499 on epoch=649
06/08/2022 08:51:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=652
06/08/2022 08:51:28 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=654
06/08/2022 08:51:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=657
06/08/2022 08:51:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=659
06/08/2022 08:51:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=662
06/08/2022 08:51:38 - INFO - __main__ - Global step 2650 Train loss 0.00 Classification-F1 0.7178631527908502 on epoch=662
06/08/2022 08:51:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=664
06/08/2022 08:51:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=667
06/08/2022 08:51:47 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=669
06/08/2022 08:51:50 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=672
06/08/2022 08:51:53 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=674
06/08/2022 08:51:54 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.667911877394636 on epoch=674
06/08/2022 08:51:57 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=677
06/08/2022 08:52:00 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=679
06/08/2022 08:52:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=682
06/08/2022 08:52:05 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=684
06/08/2022 08:52:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=687
06/08/2022 08:52:09 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.6671726300828081 on epoch=687
06/08/2022 08:52:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=689
06/08/2022 08:52:15 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=692
06/08/2022 08:52:18 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=694
06/08/2022 08:52:21 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=697
06/08/2022 08:52:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=699
06/08/2022 08:52:25 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.6849750384024578 on epoch=699
06/08/2022 08:52:28 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=702
06/08/2022 08:52:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=704
06/08/2022 08:52:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=707
06/08/2022 08:52:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=709
06/08/2022 08:52:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=712
06/08/2022 08:52:41 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.6674327220766849 on epoch=712
06/08/2022 08:52:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=714
06/08/2022 08:52:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=717
06/08/2022 08:52:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=719
06/08/2022 08:52:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=722
06/08/2022 08:52:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=724
06/08/2022 08:52:57 - INFO - __main__ - Global step 2900 Train loss 0.00 Classification-F1 0.709168956043956 on epoch=724
06/08/2022 08:52:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=727
06/08/2022 08:53:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=729
06/08/2022 08:53:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=732
06/08/2022 08:53:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=734
06/08/2022 08:53:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=737
06/08/2022 08:53:12 - INFO - __main__ - Global step 2950 Train loss 0.00 Classification-F1 0.6419104459150226 on epoch=737
06/08/2022 08:53:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=739
06/08/2022 08:53:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=742
06/08/2022 08:53:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=744
06/08/2022 08:53:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=747
06/08/2022 08:53:27 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=749
06/08/2022 08:53:28 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.6557765151515151 on epoch=749
06/08/2022 08:53:28 - INFO - __main__ - save last model!
06/08/2022 08:53:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
06/08/2022 08:53:28 - INFO - __main__ - Start tokenizing ... 5509 instances
06/08/2022 08:53:28 - INFO - __main__ - Printing 3 examples
06/08/2022 08:53:28 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
06/08/2022 08:53:28 - INFO - __main__ - ['others']
06/08/2022 08:53:28 - INFO - __main__ -  [emo] what you like very little things ok
06/08/2022 08:53:28 - INFO - __main__ - ['others']
06/08/2022 08:53:28 - INFO - __main__ -  [emo] yes how so i want to fuck babu
06/08/2022 08:53:28 - INFO - __main__ - ['others']
06/08/2022 08:53:28 - INFO - __main__ - Tokenizing Input ...
06/08/2022 08:53:30 - INFO - __main__ - Tokenizing Output ...
06/08/2022 08:53:36 - INFO - __main__ - Loaded 5509 examples from test data
06/08/2022 08:55:27 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-200prompt/singletask-emo/emo_16_87_0.2_8_predictions.txt
06/08/2022 08:55:27 - INFO - __main__ - Classification-F1 on test data: 0.2018
06/08/2022 08:55:28 - INFO - __main__ - prefix=emo_16_87, lr=0.2, bsz=8, dev_performance=0.7498121035384661, test_performance=0.20180385170676235
