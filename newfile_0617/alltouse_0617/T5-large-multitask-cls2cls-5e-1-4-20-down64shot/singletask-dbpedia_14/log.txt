05/24/2022 23:21:05 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/24/2022 23:21:05 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14
05/24/2022 23:21:05 - INFO - __main__ - Namespace(task_dir='data_64/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down64shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/24/2022 23:21:05 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14
05/24/2022 23:21:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/24/2022 23:21:06 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/24/2022 23:21:06 - INFO - __main__ - args.device: cuda:0
05/24/2022 23:21:06 - INFO - __main__ - Using 2 gpus
05/24/2022 23:21:06 - INFO - __main__ - args.device: cuda:1
05/24/2022 23:21:06 - INFO - __main__ - Using 2 gpus
05/24/2022 23:21:06 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/24/2022 23:21:06 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_64_100', 'dbpedia_14_64_13', 'dbpedia_14_64_21', 'dbpedia_14_64_42', 'dbpedia_14_64_87']
05/24/2022 23:21:10 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.5, bsz=8 ...
05/24/2022 23:21:11 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:21:11 - INFO - __main__ - Printing 3 examples
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:21:11 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:21:11 - INFO - __main__ - Printing 3 examples
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/24/2022 23:21:11 - INFO - __main__ - ['Animal']
05/24/2022 23:21:11 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:21:12 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:21:12 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:21:13 - INFO - __main__ - Loaded 896 examples from train data
05/24/2022 23:21:13 - INFO - __main__ - Loaded 896 examples from train data
05/24/2022 23:21:13 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:21:13 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:21:13 - INFO - __main__ - Printing 3 examples
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ - Printing 3 examples
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/24/2022 23:21:13 - INFO - __main__ - ['Animal']
05/24/2022 23:21:13 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:21:13 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:21:13 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:21:13 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:21:14 - INFO - __main__ - Loaded 896 examples from dev data
05/24/2022 23:21:14 - INFO - __main__ - Loaded 896 examples from dev data
05/24/2022 23:21:32 - INFO - __main__ - load prompt embedding from ckpt
05/24/2022 23:21:32 - INFO - __main__ - load prompt embedding from ckpt
05/24/2022 23:21:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/24/2022 23:21:33 - INFO - __main__ - Starting training!
05/24/2022 23:21:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/24/2022 23:21:38 - INFO - __main__ - Starting training!
05/24/2022 23:21:42 - INFO - __main__ - Step 10 Global step 10 Train loss 6.69 on epoch=0
05/24/2022 23:21:45 - INFO - __main__ - Step 20 Global step 20 Train loss 4.55 on epoch=0
05/24/2022 23:21:47 - INFO - __main__ - Step 30 Global step 30 Train loss 3.88 on epoch=0
05/24/2022 23:21:50 - INFO - __main__ - Step 40 Global step 40 Train loss 3.68 on epoch=0
05/24/2022 23:21:52 - INFO - __main__ - Step 50 Global step 50 Train loss 3.20 on epoch=0
05/24/2022 23:22:18 - INFO - __main__ - Global step 50 Train loss 4.40 Classification-F1 0.021390796707433508 on epoch=0
05/24/2022 23:22:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.021390796707433508 on epoch=0, global_step=50
05/24/2022 23:22:21 - INFO - __main__ - Step 60 Global step 60 Train loss 2.57 on epoch=1
05/24/2022 23:22:23 - INFO - __main__ - Step 70 Global step 70 Train loss 2.14 on epoch=1
05/24/2022 23:22:26 - INFO - __main__ - Step 80 Global step 80 Train loss 1.96 on epoch=1
05/24/2022 23:22:28 - INFO - __main__ - Step 90 Global step 90 Train loss 2.14 on epoch=1
05/24/2022 23:22:31 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=1
05/24/2022 23:22:52 - INFO - __main__ - Global step 100 Train loss 2.17 Classification-F1 0.06284610708384283 on epoch=1
05/24/2022 23:22:52 - INFO - __main__ - Saving model with best Classification-F1: 0.021390796707433508 -> 0.06284610708384283 on epoch=1, global_step=100
05/24/2022 23:22:55 - INFO - __main__ - Step 110 Global step 110 Train loss 1.59 on epoch=1
05/24/2022 23:22:57 - INFO - __main__ - Step 120 Global step 120 Train loss 1.43 on epoch=2
05/24/2022 23:23:00 - INFO - __main__ - Step 130 Global step 130 Train loss 1.29 on epoch=2
05/24/2022 23:23:02 - INFO - __main__ - Step 140 Global step 140 Train loss 1.20 on epoch=2
05/24/2022 23:23:05 - INFO - __main__ - Step 150 Global step 150 Train loss 1.32 on epoch=2
05/24/2022 23:23:26 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.13466019243983277 on epoch=2
05/24/2022 23:23:26 - INFO - __main__ - Saving model with best Classification-F1: 0.06284610708384283 -> 0.13466019243983277 on epoch=2, global_step=150
05/24/2022 23:23:28 - INFO - __main__ - Step 160 Global step 160 Train loss 1.40 on epoch=2
05/24/2022 23:23:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=3
05/24/2022 23:23:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=3
05/24/2022 23:23:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=3
05/24/2022 23:23:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=3
05/24/2022 23:24:02 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.22249661915157343 on epoch=3
05/24/2022 23:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.13466019243983277 -> 0.22249661915157343 on epoch=3, global_step=200
05/24/2022 23:24:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.74 on epoch=3
05/24/2022 23:24:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=3
05/24/2022 23:24:10 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=4
05/24/2022 23:24:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.41 on epoch=4
05/24/2022 23:24:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=4
05/24/2022 23:24:40 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.2850887983119928 on epoch=4
05/24/2022 23:24:40 - INFO - __main__ - Saving model with best Classification-F1: 0.22249661915157343 -> 0.2850887983119928 on epoch=4, global_step=250
05/24/2022 23:24:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=4
05/24/2022 23:24:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.82 on epoch=4
05/24/2022 23:24:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=4
05/24/2022 23:24:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.32 on epoch=5
05/24/2022 23:24:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.32 on epoch=5
05/24/2022 23:25:18 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.3609547065484712 on epoch=5
05/24/2022 23:25:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2850887983119928 -> 0.3609547065484712 on epoch=5, global_step=300
05/24/2022 23:25:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.42 on epoch=5
05/24/2022 23:25:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=5
05/24/2022 23:25:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=5
05/24/2022 23:25:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=6
05/24/2022 23:25:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.30 on epoch=6
05/24/2022 23:25:56 - INFO - __main__ - Global step 350 Train loss 0.39 Classification-F1 0.3533673883141904 on epoch=6
05/24/2022 23:25:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.28 on epoch=6
05/24/2022 23:26:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.31 on epoch=6
05/24/2022 23:26:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=6
05/24/2022 23:26:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=6
05/24/2022 23:26:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=7
05/24/2022 23:26:33 - INFO - __main__ - Global step 400 Train loss 0.33 Classification-F1 0.42490479457971486 on epoch=7
05/24/2022 23:26:33 - INFO - __main__ - Saving model with best Classification-F1: 0.3609547065484712 -> 0.42490479457971486 on epoch=7, global_step=400
05/24/2022 23:26:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.26 on epoch=7
05/24/2022 23:26:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=7
05/24/2022 23:26:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=7
05/24/2022 23:26:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=7
05/24/2022 23:26:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=8
05/24/2022 23:27:10 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.45506357716580026 on epoch=8
05/24/2022 23:27:10 - INFO - __main__ - Saving model with best Classification-F1: 0.42490479457971486 -> 0.45506357716580026 on epoch=8, global_step=450
05/24/2022 23:27:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=8
05/24/2022 23:27:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.17 on epoch=8
05/24/2022 23:27:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=8
05/24/2022 23:27:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=8
05/24/2022 23:27:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.55 on epoch=8
05/24/2022 23:27:48 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.4378645274371223 on epoch=8
05/24/2022 23:27:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=9
05/24/2022 23:27:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=9
05/24/2022 23:27:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=9
05/24/2022 23:27:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=9
05/24/2022 23:28:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=9
05/24/2022 23:28:25 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.5211588374458348 on epoch=9
05/24/2022 23:28:25 - INFO - __main__ - Saving model with best Classification-F1: 0.45506357716580026 -> 0.5211588374458348 on epoch=9, global_step=550
05/24/2022 23:28:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=9
05/24/2022 23:28:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=10
05/24/2022 23:28:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=10
05/24/2022 23:28:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=10
05/24/2022 23:28:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=10
05/24/2022 23:29:03 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.5213412039451579 on epoch=10
05/24/2022 23:29:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5211588374458348 -> 0.5213412039451579 on epoch=10, global_step=600
05/24/2022 23:29:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.55 on epoch=10
05/24/2022 23:29:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.11 on epoch=11
05/24/2022 23:29:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
05/24/2022 23:29:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=11
05/24/2022 23:29:15 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=11
05/24/2022 23:29:40 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.6045580147629316 on epoch=11
05/24/2022 23:29:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5213412039451579 -> 0.6045580147629316 on epoch=11, global_step=650
05/24/2022 23:29:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=11
05/24/2022 23:29:45 - INFO - __main__ - Step 670 Global step 670 Train loss 0.48 on epoch=11
05/24/2022 23:29:48 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
05/24/2022 23:29:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=12
05/24/2022 23:29:53 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=12
05/24/2022 23:30:18 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.5385712748119207 on epoch=12
05/24/2022 23:30:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=12
05/24/2022 23:30:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.52 on epoch=12
05/24/2022 23:30:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=13
05/24/2022 23:30:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=13
05/24/2022 23:30:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
05/24/2022 23:30:56 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.5719551926421643 on epoch=13
05/24/2022 23:30:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
05/24/2022 23:31:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=13
05/24/2022 23:31:03 - INFO - __main__ - Step 780 Global step 780 Train loss 0.43 on epoch=13
05/24/2022 23:31:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=14
05/24/2022 23:31:08 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=14
05/24/2022 23:31:33 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.5229243439139898 on epoch=14
05/24/2022 23:31:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=14
05/24/2022 23:31:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=14
05/24/2022 23:31:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=14
05/24/2022 23:31:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
05/24/2022 23:31:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
05/24/2022 23:32:11 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.5863567550128976 on epoch=15
05/24/2022 23:32:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=15
05/24/2022 23:32:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=15
05/24/2022 23:32:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
05/24/2022 23:32:21 - INFO - __main__ - Step 890 Global step 890 Train loss 0.41 on epoch=15
05/24/2022 23:32:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=16
05/24/2022 23:32:49 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6218034150920212 on epoch=16
05/24/2022 23:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6045580147629316 -> 0.6218034150920212 on epoch=16, global_step=900
05/24/2022 23:32:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=16
05/24/2022 23:32:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
05/24/2022 23:32:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=16
05/24/2022 23:32:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/24/2022 23:33:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=16
05/24/2022 23:33:27 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6576868857744819 on epoch=16
05/24/2022 23:33:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6218034150920212 -> 0.6576868857744819 on epoch=16, global_step=950
05/24/2022 23:33:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=17
05/24/2022 23:33:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=17
05/24/2022 23:33:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=17
05/24/2022 23:33:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=17
05/24/2022 23:33:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/24/2022 23:34:05 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.5518202584584985 on epoch=17
05/24/2022 23:34:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=18
05/24/2022 23:34:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
05/24/2022 23:34:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
05/24/2022 23:34:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=18
05/24/2022 23:34:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=18
05/24/2022 23:34:43 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5406663712006552 on epoch=18
05/24/2022 23:34:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/24/2022 23:34:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
05/24/2022 23:34:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
05/24/2022 23:34:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=19
05/24/2022 23:34:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=19
05/24/2022 23:35:20 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6038424974803276 on epoch=19
05/24/2022 23:35:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.40 on epoch=19
05/24/2022 23:35:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=19
05/24/2022 23:35:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=20
05/24/2022 23:35:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
05/24/2022 23:35:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=20
05/24/2022 23:35:57 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.5421778213151487 on epoch=20
05/24/2022 23:36:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=20
05/24/2022 23:36:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/24/2022 23:36:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=21
05/24/2022 23:36:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=21
05/24/2022 23:36:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
05/24/2022 23:36:35 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5486589834936219 on epoch=21
05/24/2022 23:36:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
05/24/2022 23:36:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=21
05/24/2022 23:36:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.56 on epoch=21
05/24/2022 23:36:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
05/24/2022 23:36:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=22
05/24/2022 23:37:12 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.641371099520409 on epoch=22
05/24/2022 23:37:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
05/24/2022 23:37:17 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=22
05/24/2022 23:37:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=22
05/24/2022 23:37:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
05/24/2022 23:37:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=23
05/24/2022 23:37:50 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6005253155996273 on epoch=23
05/24/2022 23:37:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=23
05/24/2022 23:37:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=23
05/24/2022 23:37:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/24/2022 23:38:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=23
05/24/2022 23:38:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/24/2022 23:38:27 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.561677004028614 on epoch=24
05/24/2022 23:38:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
05/24/2022 23:38:32 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
05/24/2022 23:38:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=24
05/24/2022 23:38:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=24
05/24/2022 23:38:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/24/2022 23:39:05 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.4894686798554519 on epoch=24
05/24/2022 23:39:08 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=25
05/24/2022 23:39:10 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=25
05/24/2022 23:39:13 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
05/24/2022 23:39:15 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/24/2022 23:39:18 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=25
05/24/2022 23:39:42 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6764063391949753 on epoch=25
05/24/2022 23:39:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6576868857744819 -> 0.6764063391949753 on epoch=25, global_step=1450
05/24/2022 23:39:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=26
05/24/2022 23:39:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
05/24/2022 23:39:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=26
05/24/2022 23:39:53 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
05/24/2022 23:39:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=26
05/24/2022 23:40:20 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.563642838140658 on epoch=26
05/24/2022 23:40:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/24/2022 23:40:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=27
05/24/2022 23:40:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/24/2022 23:40:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
05/24/2022 23:40:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/24/2022 23:40:57 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5908298486886824 on epoch=27
05/24/2022 23:41:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/24/2022 23:41:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/24/2022 23:41:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/24/2022 23:41:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
05/24/2022 23:41:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
05/24/2022 23:41:35 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.5928668178104645 on epoch=28
05/24/2022 23:41:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=28
05/24/2022 23:41:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/24/2022 23:41:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=29
05/24/2022 23:41:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
05/24/2022 23:41:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/24/2022 23:42:12 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6473884030282552 on epoch=29
05/24/2022 23:42:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=29
05/24/2022 23:42:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=29
05/24/2022 23:42:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
05/24/2022 23:42:23 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/24/2022 23:42:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=30
05/24/2022 23:42:49 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6210471588094685 on epoch=30
05/24/2022 23:42:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=30
05/24/2022 23:42:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=30
05/24/2022 23:42:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.45 on epoch=30
05/24/2022 23:43:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
05/24/2022 23:43:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
05/24/2022 23:43:27 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.6219533650884723 on epoch=31
05/24/2022 23:43:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/24/2022 23:43:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=31
05/24/2022 23:43:35 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=31
05/24/2022 23:43:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.35 on epoch=31
05/24/2022 23:43:40 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
05/24/2022 23:44:04 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5921511999387742 on epoch=32
05/24/2022 23:44:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/24/2022 23:44:09 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/24/2022 23:44:12 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/24/2022 23:44:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
05/24/2022 23:44:17 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/24/2022 23:44:41 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5957293170664905 on epoch=33
05/24/2022 23:44:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
05/24/2022 23:44:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/24/2022 23:44:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
05/24/2022 23:44:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
05/24/2022 23:44:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
05/24/2022 23:45:19 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.6260039760091229 on epoch=33
05/24/2022 23:45:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/24/2022 23:45:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
05/24/2022 23:45:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/24/2022 23:45:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/24/2022 23:45:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.09 on epoch=34
05/24/2022 23:45:57 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7348482771184519 on epoch=34
05/24/2022 23:45:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6764063391949753 -> 0.7348482771184519 on epoch=34, global_step=1950
05/24/2022 23:45:59 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/24/2022 23:46:02 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=35
05/24/2022 23:46:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
05/24/2022 23:46:07 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
05/24/2022 23:46:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=35
05/24/2022 23:46:34 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6325279980635657 on epoch=35
05/24/2022 23:46:36 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.34 on epoch=35
05/24/2022 23:46:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=36
05/24/2022 23:46:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=36
05/24/2022 23:46:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
05/24/2022 23:46:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/24/2022 23:47:12 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.6803181394623179 on epoch=36
05/24/2022 23:47:14 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=36
05/24/2022 23:47:17 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
05/24/2022 23:47:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=37
05/24/2022 23:47:22 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=37
05/24/2022 23:47:25 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
05/24/2022 23:47:49 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7185242265174389 on epoch=37
05/24/2022 23:47:52 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=37
05/24/2022 23:47:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.39 on epoch=37
05/24/2022 23:47:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/24/2022 23:48:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
05/24/2022 23:48:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/24/2022 23:48:27 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.7643078069295778 on epoch=38
05/24/2022 23:48:27 - INFO - __main__ - Saving model with best Classification-F1: 0.7348482771184519 -> 0.7643078069295778 on epoch=38, global_step=2150
05/24/2022 23:48:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/24/2022 23:48:32 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
05/24/2022 23:48:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.28 on epoch=38
05/24/2022 23:48:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/24/2022 23:48:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
05/24/2022 23:49:05 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.6847516640425845 on epoch=39
05/24/2022 23:49:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/24/2022 23:49:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
05/24/2022 23:49:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.39 on epoch=39
05/24/2022 23:49:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/24/2022 23:49:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
05/24/2022 23:49:43 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.7395219996911429 on epoch=40
05/24/2022 23:49:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=40
05/24/2022 23:49:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=40
05/24/2022 23:49:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=40
05/24/2022 23:49:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.37 on epoch=40
05/24/2022 23:49:56 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/24/2022 23:50:21 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.8223957404492177 on epoch=41
05/24/2022 23:50:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7643078069295778 -> 0.8223957404492177 on epoch=41, global_step=2300
05/24/2022 23:50:24 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/24/2022 23:50:26 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
05/24/2022 23:50:29 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=41
05/24/2022 23:50:32 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/24/2022 23:50:34 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.36 on epoch=41
05/24/2022 23:50:59 - INFO - __main__ - Global step 2350 Train loss 0.12 Classification-F1 0.7174380625870801 on epoch=41
05/24/2022 23:51:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/24/2022 23:51:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
05/24/2022 23:51:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/24/2022 23:51:10 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=42
05/24/2022 23:51:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
05/24/2022 23:51:37 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6892179915954647 on epoch=42
05/24/2022 23:51:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/24/2022 23:51:42 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/24/2022 23:51:45 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=43
05/24/2022 23:51:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/24/2022 23:51:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
05/24/2022 23:52:15 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7620946380370244 on epoch=43
05/24/2022 23:52:18 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/24/2022 23:52:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/24/2022 23:52:23 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=44
05/24/2022 23:52:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/24/2022 23:52:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/24/2022 23:52:53 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8352808437632655 on epoch=44
05/24/2022 23:52:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8223957404492177 -> 0.8352808437632655 on epoch=44, global_step=2500
05/24/2022 23:52:56 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
05/24/2022 23:52:58 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/24/2022 23:53:01 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/24/2022 23:53:04 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/24/2022 23:53:06 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
05/24/2022 23:53:31 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8953898991238262 on epoch=45
05/24/2022 23:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.8352808437632655 -> 0.8953898991238262 on epoch=45, global_step=2550
05/24/2022 23:53:34 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/24/2022 23:53:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/24/2022 23:53:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/24/2022 23:53:42 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=46
05/24/2022 23:53:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
05/24/2022 23:54:09 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9140714933833182 on epoch=46
05/24/2022 23:54:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8953898991238262 -> 0.9140714933833182 on epoch=46, global_step=2600
05/24/2022 23:54:12 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/24/2022 23:54:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
05/24/2022 23:54:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/24/2022 23:54:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
05/24/2022 23:54:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/24/2022 23:54:47 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8557663617665514 on epoch=47
05/24/2022 23:54:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/24/2022 23:54:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/24/2022 23:54:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.40 on epoch=47
05/24/2022 23:54:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.10 on epoch=48
05/24/2022 23:55:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/24/2022 23:55:25 - INFO - __main__ - Global step 2700 Train loss 0.11 Classification-F1 0.7583673977765651 on epoch=48
05/24/2022 23:55:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/24/2022 23:55:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/24/2022 23:55:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
05/24/2022 23:55:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=48
05/24/2022 23:55:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/24/2022 23:56:03 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8058330089779634 on epoch=49
05/24/2022 23:56:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/24/2022 23:56:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/24/2022 23:56:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=49
05/24/2022 23:56:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/24/2022 23:56:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/24/2022 23:56:40 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.747095104650517 on epoch=49
05/24/2022 23:56:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
05/24/2022 23:56:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=50
05/24/2022 23:56:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=50
05/24/2022 23:56:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/24/2022 23:56:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.30 on epoch=50
05/24/2022 23:57:18 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.9083799644077359 on epoch=50
05/24/2022 23:57:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
05/24/2022 23:57:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
05/24/2022 23:57:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/24/2022 23:57:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/24/2022 23:57:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/24/2022 23:57:56 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.750721748633918 on epoch=51
05/24/2022 23:57:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/24/2022 23:58:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/24/2022 23:58:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/24/2022 23:58:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/24/2022 23:58:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=52
05/24/2022 23:58:33 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8497188422811204 on epoch=52
05/24/2022 23:58:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.28 on epoch=52
05/24/2022 23:58:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/24/2022 23:58:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/24/2022 23:58:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/24/2022 23:58:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
05/24/2022 23:58:48 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:58:48 - INFO - __main__ - Printing 3 examples
05/24/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/24/2022 23:58:48 - INFO - __main__ - ['Animal']
05/24/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/24/2022 23:58:48 - INFO - __main__ - ['Animal']
05/24/2022 23:58:48 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/24/2022 23:58:48 - INFO - __main__ - ['Animal']
05/24/2022 23:58:48 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:58:49 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:58:50 - INFO - __main__ - Loaded 896 examples from train data
05/24/2022 23:58:50 - INFO - __main__ - Start tokenizing ... 896 instances
05/24/2022 23:58:50 - INFO - __main__ - Printing 3 examples
05/24/2022 23:58:50 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/24/2022 23:58:50 - INFO - __main__ - ['Animal']
05/24/2022 23:58:50 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/24/2022 23:58:50 - INFO - __main__ - ['Animal']
05/24/2022 23:58:50 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/24/2022 23:58:50 - INFO - __main__ - ['Animal']
05/24/2022 23:58:50 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:58:50 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:58:51 - INFO - __main__ - Loaded 896 examples from dev data
05/24/2022 23:59:07 - INFO - __main__ - load prompt embedding from ckpt
05/24/2022 23:59:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/24/2022 23:59:08 - INFO - __main__ - Starting training!
05/24/2022 23:59:11 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.7581025649974832 on epoch=53
05/24/2022 23:59:11 - INFO - __main__ - save last model!
05/24/2022 23:59:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/24/2022 23:59:11 - INFO - __main__ - Start tokenizing ... 3500 instances
05/24/2022 23:59:11 - INFO - __main__ - Printing 3 examples
05/24/2022 23:59:11 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/24/2022 23:59:11 - INFO - __main__ - ['Animal']
05/24/2022 23:59:11 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/24/2022 23:59:11 - INFO - __main__ - ['Animal']
05/24/2022 23:59:11 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/24/2022 23:59:11 - INFO - __main__ - ['Village']
05/24/2022 23:59:11 - INFO - __main__ - Tokenizing Input ...
05/24/2022 23:59:13 - INFO - __main__ - Tokenizing Output ...
05/24/2022 23:59:17 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 00:01:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.5_8_predictions.txt
05/25/2022 00:01:23 - INFO - __main__ - Classification-F1 on test data: 0.5921
05/25/2022 00:01:24 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.5, bsz=8, dev_performance=0.9140714933833182, test_performance=0.592102361268882
05/25/2022 00:01:24 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.4, bsz=8 ...
05/25/2022 00:01:25 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:01:25 - INFO - __main__ - Printing 3 examples
05/25/2022 00:01:25 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 00:01:25 - INFO - __main__ - ['Animal']
05/25/2022 00:01:25 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 00:01:25 - INFO - __main__ - ['Animal']
05/25/2022 00:01:25 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 00:01:25 - INFO - __main__ - ['Animal']
05/25/2022 00:01:25 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:01:25 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:01:26 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 00:01:26 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:01:26 - INFO - __main__ - Printing 3 examples
05/25/2022 00:01:26 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/25/2022 00:01:26 - INFO - __main__ - ['Animal']
05/25/2022 00:01:26 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/25/2022 00:01:26 - INFO - __main__ - ['Animal']
05/25/2022 00:01:26 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/25/2022 00:01:26 - INFO - __main__ - ['Animal']
05/25/2022 00:01:26 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:01:26 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:01:27 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 00:01:43 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 00:01:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 00:01:44 - INFO - __main__ - Starting training!
05/25/2022 00:01:48 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=0
05/25/2022 00:01:50 - INFO - __main__ - Step 20 Global step 20 Train loss 4.52 on epoch=0
05/25/2022 00:01:53 - INFO - __main__ - Step 30 Global step 30 Train loss 4.33 on epoch=0
05/25/2022 00:01:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.93 on epoch=0
05/25/2022 00:01:58 - INFO - __main__ - Step 50 Global step 50 Train loss 3.53 on epoch=0
05/25/2022 00:02:24 - INFO - __main__ - Global step 50 Train loss 4.65 Classification-F1 0.019331980790009168 on epoch=0
05/25/2022 00:02:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.019331980790009168 on epoch=0, global_step=50
05/25/2022 00:02:27 - INFO - __main__ - Step 60 Global step 60 Train loss 3.16 on epoch=1
05/25/2022 00:02:29 - INFO - __main__ - Step 70 Global step 70 Train loss 2.53 on epoch=1
05/25/2022 00:02:32 - INFO - __main__ - Step 80 Global step 80 Train loss 2.14 on epoch=1
05/25/2022 00:02:35 - INFO - __main__ - Step 90 Global step 90 Train loss 2.37 on epoch=1
05/25/2022 00:02:37 - INFO - __main__ - Step 100 Global step 100 Train loss 2.28 on epoch=1
05/25/2022 00:03:00 - INFO - __main__ - Global step 100 Train loss 2.50 Classification-F1 0.048661603991617605 on epoch=1
05/25/2022 00:03:00 - INFO - __main__ - Saving model with best Classification-F1: 0.019331980790009168 -> 0.048661603991617605 on epoch=1, global_step=100
05/25/2022 00:03:03 - INFO - __main__ - Step 110 Global step 110 Train loss 1.98 on epoch=1
05/25/2022 00:03:06 - INFO - __main__ - Step 120 Global step 120 Train loss 1.80 on epoch=2
05/25/2022 00:03:08 - INFO - __main__ - Step 130 Global step 130 Train loss 1.60 on epoch=2
05/25/2022 00:03:11 - INFO - __main__ - Step 140 Global step 140 Train loss 1.48 on epoch=2
05/25/2022 00:03:14 - INFO - __main__ - Step 150 Global step 150 Train loss 1.61 on epoch=2
05/25/2022 00:03:36 - INFO - __main__ - Global step 150 Train loss 1.69 Classification-F1 0.1079025994991236 on epoch=2
05/25/2022 00:03:36 - INFO - __main__ - Saving model with best Classification-F1: 0.048661603991617605 -> 0.1079025994991236 on epoch=2, global_step=150
05/25/2022 00:03:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.46 on epoch=2
05/25/2022 00:03:41 - INFO - __main__ - Step 170 Global step 170 Train loss 1.39 on epoch=3
05/25/2022 00:03:43 - INFO - __main__ - Step 180 Global step 180 Train loss 1.03 on epoch=3
05/25/2022 00:03:46 - INFO - __main__ - Step 190 Global step 190 Train loss 1.09 on epoch=3
05/25/2022 00:03:49 - INFO - __main__ - Step 200 Global step 200 Train loss 1.01 on epoch=3
05/25/2022 00:04:10 - INFO - __main__ - Global step 200 Train loss 1.20 Classification-F1 0.16224785970561642 on epoch=3
05/25/2022 00:04:11 - INFO - __main__ - Saving model with best Classification-F1: 0.1079025994991236 -> 0.16224785970561642 on epoch=3, global_step=200
05/25/2022 00:04:13 - INFO - __main__ - Step 210 Global step 210 Train loss 1.02 on epoch=3
05/25/2022 00:04:16 - INFO - __main__ - Step 220 Global step 220 Train loss 0.87 on epoch=3
05/25/2022 00:04:19 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=4
05/25/2022 00:04:21 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=4
05/25/2022 00:04:24 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=4
05/25/2022 00:04:48 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.24156092698931603 on epoch=4
05/25/2022 00:04:48 - INFO - __main__ - Saving model with best Classification-F1: 0.16224785970561642 -> 0.24156092698931603 on epoch=4, global_step=250
05/25/2022 00:04:51 - INFO - __main__ - Step 260 Global step 260 Train loss 0.65 on epoch=4
05/25/2022 00:04:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.92 on epoch=4
05/25/2022 00:04:56 - INFO - __main__ - Step 280 Global step 280 Train loss 0.63 on epoch=4
05/25/2022 00:04:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=5
05/25/2022 00:05:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=5
05/25/2022 00:05:27 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.29015728796935286 on epoch=5
05/25/2022 00:05:27 - INFO - __main__ - Saving model with best Classification-F1: 0.24156092698931603 -> 0.29015728796935286 on epoch=5, global_step=300
05/25/2022 00:05:30 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=5
05/25/2022 00:05:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=5
05/25/2022 00:05:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.71 on epoch=5
05/25/2022 00:05:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.42 on epoch=6
05/25/2022 00:05:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=6
05/25/2022 00:06:06 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.3940399720778118 on epoch=6
05/25/2022 00:06:06 - INFO - __main__ - Saving model with best Classification-F1: 0.29015728796935286 -> 0.3940399720778118 on epoch=6, global_step=350
05/25/2022 00:06:08 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=6
05/25/2022 00:06:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.41 on epoch=6
05/25/2022 00:06:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=6
05/25/2022 00:06:16 - INFO - __main__ - Step 390 Global step 390 Train loss 0.63 on epoch=6
05/25/2022 00:06:19 - INFO - __main__ - Step 400 Global step 400 Train loss 0.29 on epoch=7
05/25/2022 00:06:44 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.44708322576940823 on epoch=7
05/25/2022 00:06:44 - INFO - __main__ - Saving model with best Classification-F1: 0.3940399720778118 -> 0.44708322576940823 on epoch=7, global_step=400
05/25/2022 00:06:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=7
05/25/2022 00:06:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.25 on epoch=7
05/25/2022 00:06:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=7
05/25/2022 00:06:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.67 on epoch=7
05/25/2022 00:06:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=8
05/25/2022 00:07:22 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.39773627917420384 on epoch=8
05/25/2022 00:07:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=8
05/25/2022 00:07:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=8
05/25/2022 00:07:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=8
05/25/2022 00:07:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=8
05/25/2022 00:07:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.53 on epoch=8
05/25/2022 00:08:01 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.47148273811528435 on epoch=8
05/25/2022 00:08:01 - INFO - __main__ - Saving model with best Classification-F1: 0.44708322576940823 -> 0.47148273811528435 on epoch=8, global_step=500
05/25/2022 00:08:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=9
05/25/2022 00:08:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.15 on epoch=9
05/25/2022 00:08:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=9
05/25/2022 00:08:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=9
05/25/2022 00:08:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.60 on epoch=9
05/25/2022 00:08:40 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.49965899505273653 on epoch=9
05/25/2022 00:08:40 - INFO - __main__ - Saving model with best Classification-F1: 0.47148273811528435 -> 0.49965899505273653 on epoch=9, global_step=550
05/25/2022 00:08:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=9
05/25/2022 00:08:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=10
05/25/2022 00:08:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=10
05/25/2022 00:08:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.25 on epoch=10
05/25/2022 00:08:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=10
05/25/2022 00:09:19 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.4280584691029224 on epoch=10
05/25/2022 00:09:22 - INFO - __main__ - Step 610 Global step 610 Train loss 0.54 on epoch=10
05/25/2022 00:09:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=11
05/25/2022 00:09:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=11
05/25/2022 00:09:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=11
05/25/2022 00:09:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=11
05/25/2022 00:09:59 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.5106824997562073 on epoch=11
05/25/2022 00:09:59 - INFO - __main__ - Saving model with best Classification-F1: 0.49965899505273653 -> 0.5106824997562073 on epoch=11, global_step=650
05/25/2022 00:10:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=11
05/25/2022 00:10:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=11
05/25/2022 00:10:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=12
05/25/2022 00:10:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=12
05/25/2022 00:10:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=12
05/25/2022 00:10:37 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.534253419183375 on epoch=12
05/25/2022 00:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5106824997562073 -> 0.534253419183375 on epoch=12, global_step=700
05/25/2022 00:10:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=12
05/25/2022 00:10:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=12
05/25/2022 00:10:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=13
05/25/2022 00:10:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=13
05/25/2022 00:10:50 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
05/25/2022 00:11:15 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.47873248201008806 on epoch=13
05/25/2022 00:11:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=13
05/25/2022 00:11:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=13
05/25/2022 00:11:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=13
05/25/2022 00:11:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=14
05/25/2022 00:11:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=14
05/25/2022 00:11:53 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.5570252511252375 on epoch=14
05/25/2022 00:11:53 - INFO - __main__ - Saving model with best Classification-F1: 0.534253419183375 -> 0.5570252511252375 on epoch=14, global_step=800
05/25/2022 00:11:56 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=14
05/25/2022 00:11:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=14
05/25/2022 00:12:01 - INFO - __main__ - Step 830 Global step 830 Train loss 0.40 on epoch=14
05/25/2022 00:12:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=14
05/25/2022 00:12:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=15
05/25/2022 00:12:32 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.5555220528186201 on epoch=15
05/25/2022 00:12:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=15
05/25/2022 00:12:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
05/25/2022 00:12:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=15
05/25/2022 00:12:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=15
05/25/2022 00:12:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=16
05/25/2022 00:13:10 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5470253261476195 on epoch=16
05/25/2022 00:13:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=16
05/25/2022 00:13:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=16
05/25/2022 00:13:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=16
05/25/2022 00:13:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=16
05/25/2022 00:13:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=16
05/25/2022 00:13:49 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.5191750353811997 on epoch=16
05/25/2022 00:13:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=17
05/25/2022 00:13:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=17
05/25/2022 00:13:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=17
05/25/2022 00:13:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=17
05/25/2022 00:14:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=17
05/25/2022 00:14:28 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.48505089490714376 on epoch=17
05/25/2022 00:14:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=18
05/25/2022 00:14:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=18
05/25/2022 00:14:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=18
05/25/2022 00:14:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
05/25/2022 00:14:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=18
05/25/2022 00:15:06 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.558062135639513 on epoch=18
05/25/2022 00:15:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5570252511252375 -> 0.558062135639513 on epoch=18, global_step=1050
05/25/2022 00:15:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=18
05/25/2022 00:15:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=19
05/25/2022 00:15:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=19
05/25/2022 00:15:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/25/2022 00:15:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=19
05/25/2022 00:15:43 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5093116040587911 on epoch=19
05/25/2022 00:15:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.50 on epoch=19
05/25/2022 00:15:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=19
05/25/2022 00:15:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=20
05/25/2022 00:15:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=20
05/25/2022 00:15:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=20
05/25/2022 00:16:21 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.5265232476197277 on epoch=20
05/25/2022 00:16:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=20
05/25/2022 00:16:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/25/2022 00:16:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
05/25/2022 00:16:31 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=21
05/25/2022 00:16:34 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=21
05/25/2022 00:16:59 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5816035380776412 on epoch=21
05/25/2022 00:16:59 - INFO - __main__ - Saving model with best Classification-F1: 0.558062135639513 -> 0.5816035380776412 on epoch=21, global_step=1200
05/25/2022 00:17:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
05/25/2022 00:17:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/25/2022 00:17:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.44 on epoch=21
05/25/2022 00:17:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=22
05/25/2022 00:17:12 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=22
05/25/2022 00:17:37 - INFO - __main__ - Global step 1250 Train loss 0.15 Classification-F1 0.6330983843060728 on epoch=22
05/25/2022 00:17:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5816035380776412 -> 0.6330983843060728 on epoch=22, global_step=1250
05/25/2022 00:17:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=22
05/25/2022 00:17:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=22
05/25/2022 00:17:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=22
05/25/2022 00:17:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=23
05/25/2022 00:17:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=23
05/25/2022 00:18:13 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.5275459873389948 on epoch=23
05/25/2022 00:18:16 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=23
05/25/2022 00:18:18 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=23
05/25/2022 00:18:21 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=23
05/25/2022 00:18:24 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=23
05/25/2022 00:18:26 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=24
05/25/2022 00:18:50 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.581424531280434 on epoch=24
05/25/2022 00:18:53 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=24
05/25/2022 00:18:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/25/2022 00:18:58 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=24
05/25/2022 00:19:01 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=24
05/25/2022 00:19:03 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/25/2022 00:19:27 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.5869924076177018 on epoch=24
05/25/2022 00:19:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
05/25/2022 00:19:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=25
05/25/2022 00:19:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=25
05/25/2022 00:19:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=25
05/25/2022 00:19:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.38 on epoch=25
05/25/2022 00:20:04 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5120763574074093 on epoch=25
05/25/2022 00:20:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=26
05/25/2022 00:20:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
05/25/2022 00:20:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
05/25/2022 00:20:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
05/25/2022 00:20:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=26
05/25/2022 00:20:41 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5090043893841428 on epoch=26
05/25/2022 00:20:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=26
05/25/2022 00:20:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/25/2022 00:20:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/25/2022 00:20:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/25/2022 00:20:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=27
05/25/2022 00:21:18 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.5347068498531626 on epoch=27
05/25/2022 00:21:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.42 on epoch=27
05/25/2022 00:21:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/25/2022 00:21:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=28
05/25/2022 00:21:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=28
05/25/2022 00:21:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
05/25/2022 00:21:54 - INFO - __main__ - Global step 1600 Train loss 0.12 Classification-F1 0.45340901972941877 on epoch=28
05/25/2022 00:21:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
05/25/2022 00:22:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/25/2022 00:22:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=29
05/25/2022 00:22:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=29
05/25/2022 00:22:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=29
05/25/2022 00:22:32 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6118136278416477 on epoch=29
05/25/2022 00:22:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
05/25/2022 00:22:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.44 on epoch=29
05/25/2022 00:22:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=29
05/25/2022 00:22:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=30
05/25/2022 00:22:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=30
05/25/2022 00:23:09 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.5618588997853124 on epoch=30
05/25/2022 00:23:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=30
05/25/2022 00:23:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=30
05/25/2022 00:23:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=30
05/25/2022 00:23:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/25/2022 00:23:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
05/25/2022 00:23:46 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.5031044411277172 on epoch=31
05/25/2022 00:23:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=31
05/25/2022 00:23:51 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=31
05/25/2022 00:23:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/25/2022 00:23:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.38 on epoch=31
05/25/2022 00:23:59 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
05/25/2022 00:24:23 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.4307964094358499 on epoch=32
05/25/2022 00:24:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=32
05/25/2022 00:24:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
05/25/2022 00:24:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=32
05/25/2022 00:24:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.37 on epoch=32
05/25/2022 00:24:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=33
05/25/2022 00:25:00 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.49463572461200367 on epoch=33
05/25/2022 00:25:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/25/2022 00:25:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=33
05/25/2022 00:25:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 00:25:11 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
05/25/2022 00:25:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/25/2022 00:25:37 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.4790114754369602 on epoch=33
05/25/2022 00:25:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/25/2022 00:25:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
05/25/2022 00:25:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/25/2022 00:25:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=34
05/25/2022 00:25:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.39 on epoch=34
05/25/2022 00:26:14 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.48155536097257706 on epoch=34
05/25/2022 00:26:17 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/25/2022 00:26:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
05/25/2022 00:26:22 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
05/25/2022 00:26:25 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=35
05/25/2022 00:26:28 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=35
05/25/2022 00:26:51 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.46791736144511054 on epoch=35
05/25/2022 00:26:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=35
05/25/2022 00:26:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
05/25/2022 00:26:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=36
05/25/2022 00:27:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
05/25/2022 00:27:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/25/2022 00:27:28 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.520674107617877 on epoch=36
05/25/2022 00:27:31 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/25/2022 00:27:33 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
05/25/2022 00:27:36 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
05/25/2022 00:27:39 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/25/2022 00:27:41 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/25/2022 00:28:06 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5235322457582621 on epoch=37
05/25/2022 00:28:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/25/2022 00:28:11 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=37
05/25/2022 00:28:14 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/25/2022 00:28:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
05/25/2022 00:28:19 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
05/25/2022 00:28:43 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6401422211108286 on epoch=38
05/25/2022 00:28:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6330983843060728 -> 0.6401422211108286 on epoch=38, global_step=2150
05/25/2022 00:28:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
05/25/2022 00:28:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=38
05/25/2022 00:28:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
05/25/2022 00:28:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/25/2022 00:28:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=39
05/25/2022 00:29:20 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.5063907453771715 on epoch=39
05/25/2022 00:29:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/25/2022 00:29:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
05/25/2022 00:29:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/25/2022 00:29:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/25/2022 00:29:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=40
05/25/2022 00:29:57 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.5407929362427469 on epoch=40
05/25/2022 00:30:00 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=40
05/25/2022 00:30:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/25/2022 00:30:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/25/2022 00:30:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/25/2022 00:30:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/25/2022 00:30:34 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.48783433905897583 on epoch=41
05/25/2022 00:30:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/25/2022 00:30:40 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=41
05/25/2022 00:30:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
05/25/2022 00:30:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/25/2022 00:30:48 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=41
05/25/2022 00:31:11 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5242057408404022 on epoch=41
05/25/2022 00:31:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
05/25/2022 00:31:16 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=42
05/25/2022 00:31:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
05/25/2022 00:31:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/25/2022 00:31:24 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=42
05/25/2022 00:31:48 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.44348825636864536 on epoch=42
05/25/2022 00:31:50 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/25/2022 00:31:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/25/2022 00:31:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/25/2022 00:31:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/25/2022 00:32:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=43
05/25/2022 00:32:25 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.4482713236839815 on epoch=43
05/25/2022 00:32:27 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=43
05/25/2022 00:32:30 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/25/2022 00:32:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
05/25/2022 00:32:35 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=44
05/25/2022 00:32:38 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/25/2022 00:33:02 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.5129541919318257 on epoch=44
05/25/2022 00:33:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=44
05/25/2022 00:33:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/25/2022 00:33:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/25/2022 00:33:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/25/2022 00:33:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=45
05/25/2022 00:33:39 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.48642856675146845 on epoch=45
05/25/2022 00:33:41 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=45
05/25/2022 00:33:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=45
05/25/2022 00:33:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/25/2022 00:33:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/25/2022 00:33:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/25/2022 00:34:16 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6071348411727544 on epoch=46
05/25/2022 00:34:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
05/25/2022 00:34:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=46
05/25/2022 00:34:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.41 on epoch=46
05/25/2022 00:34:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
05/25/2022 00:34:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
05/25/2022 00:34:53 - INFO - __main__ - Global step 2650 Train loss 0.11 Classification-F1 0.5526868843786333 on epoch=47
05/25/2022 00:34:56 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=47
05/25/2022 00:34:59 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=47
05/25/2022 00:35:01 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.32 on epoch=47
05/25/2022 00:35:04 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 00:35:07 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/25/2022 00:35:30 - INFO - __main__ - Global step 2700 Train loss 0.10 Classification-F1 0.5290654837460151 on epoch=48
05/25/2022 00:35:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/25/2022 00:35:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
05/25/2022 00:35:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/25/2022 00:35:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=48
05/25/2022 00:35:44 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
05/25/2022 00:36:08 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5353311697423679 on epoch=49
05/25/2022 00:36:10 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/25/2022 00:36:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/25/2022 00:36:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/25/2022 00:36:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=49
05/25/2022 00:36:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/25/2022 00:36:45 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6099069945175543 on epoch=49
05/25/2022 00:36:47 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/25/2022 00:36:50 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=50
05/25/2022 00:36:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/25/2022 00:36:55 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=50
05/25/2022 00:36:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=50
05/25/2022 00:37:22 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5158753538707906 on epoch=50
05/25/2022 00:37:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/25/2022 00:37:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
05/25/2022 00:37:30 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/25/2022 00:37:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/25/2022 00:37:35 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/25/2022 00:37:59 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.4986203811760297 on epoch=51
05/25/2022 00:38:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 00:38:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 00:38:07 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/25/2022 00:38:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
05/25/2022 00:38:12 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/25/2022 00:38:37 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5283079718079676 on epoch=52
05/25/2022 00:38:39 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=52
05/25/2022 00:38:42 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 00:38:44 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/25/2022 00:38:47 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/25/2022 00:38:49 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
05/25/2022 00:38:51 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:38:51 - INFO - __main__ - Printing 3 examples
05/25/2022 00:38:51 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 00:38:51 - INFO - __main__ - ['Animal']
05/25/2022 00:38:51 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 00:38:51 - INFO - __main__ - ['Animal']
05/25/2022 00:38:51 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 00:38:51 - INFO - __main__ - ['Animal']
05/25/2022 00:38:51 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:38:51 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:38:52 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 00:38:52 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:38:52 - INFO - __main__ - Printing 3 examples
05/25/2022 00:38:52 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/25/2022 00:38:52 - INFO - __main__ - ['Animal']
05/25/2022 00:38:52 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/25/2022 00:38:52 - INFO - __main__ - ['Animal']
05/25/2022 00:38:52 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/25/2022 00:38:52 - INFO - __main__ - ['Animal']
05/25/2022 00:38:52 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:38:53 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:38:54 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 00:39:09 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 00:39:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 00:39:10 - INFO - __main__ - Starting training!
05/25/2022 00:39:14 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.5554319176231183 on epoch=53
05/25/2022 00:39:14 - INFO - __main__ - save last model!
05/25/2022 00:39:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 00:39:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 00:39:14 - INFO - __main__ - Printing 3 examples
05/25/2022 00:39:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 00:39:14 - INFO - __main__ - ['Animal']
05/25/2022 00:39:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 00:39:14 - INFO - __main__ - ['Animal']
05/25/2022 00:39:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 00:39:14 - INFO - __main__ - ['Village']
05/25/2022 00:39:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:39:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:39:19 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 00:41:22 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.4_8_predictions.txt
05/25/2022 00:41:22 - INFO - __main__ - Classification-F1 on test data: 0.3896
05/25/2022 00:41:22 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.4, bsz=8, dev_performance=0.6401422211108286, test_performance=0.3895710727064782
05/25/2022 00:41:22 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.3, bsz=8 ...
05/25/2022 00:41:23 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:41:23 - INFO - __main__ - Printing 3 examples
05/25/2022 00:41:23 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 00:41:23 - INFO - __main__ - ['Animal']
05/25/2022 00:41:23 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 00:41:23 - INFO - __main__ - ['Animal']
05/25/2022 00:41:23 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 00:41:23 - INFO - __main__ - ['Animal']
05/25/2022 00:41:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:41:24 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:41:24 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 00:41:24 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 00:41:24 - INFO - __main__ - Printing 3 examples
05/25/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/25/2022 00:41:24 - INFO - __main__ - ['Animal']
05/25/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/25/2022 00:41:24 - INFO - __main__ - ['Animal']
05/25/2022 00:41:24 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/25/2022 00:41:24 - INFO - __main__ - ['Animal']
05/25/2022 00:41:24 - INFO - __main__ - Tokenizing Input ...
05/25/2022 00:41:25 - INFO - __main__ - Tokenizing Output ...
05/25/2022 00:41:26 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 00:41:44 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 00:41:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 00:41:45 - INFO - __main__ - Starting training!
05/25/2022 00:41:49 - INFO - __main__ - Step 10 Global step 10 Train loss 7.43 on epoch=0
05/25/2022 00:41:52 - INFO - __main__ - Step 20 Global step 20 Train loss 5.07 on epoch=0
05/25/2022 00:41:54 - INFO - __main__ - Step 30 Global step 30 Train loss 4.47 on epoch=0
05/25/2022 00:41:57 - INFO - __main__ - Step 40 Global step 40 Train loss 4.24 on epoch=0
05/25/2022 00:42:00 - INFO - __main__ - Step 50 Global step 50 Train loss 3.93 on epoch=0
05/25/2022 00:42:29 - INFO - __main__ - Global step 50 Train loss 5.03 Classification-F1 0.011093723086088397 on epoch=0
05/25/2022 00:42:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.011093723086088397 on epoch=0, global_step=50
05/25/2022 00:42:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.56 on epoch=1
05/25/2022 00:42:34 - INFO - __main__ - Step 70 Global step 70 Train loss 2.95 on epoch=1
05/25/2022 00:42:37 - INFO - __main__ - Step 80 Global step 80 Train loss 2.61 on epoch=1
05/25/2022 00:42:39 - INFO - __main__ - Step 90 Global step 90 Train loss 2.72 on epoch=1
05/25/2022 00:42:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.63 on epoch=1
05/25/2022 00:43:07 - INFO - __main__ - Global step 100 Train loss 2.89 Classification-F1 0.03119628383320924 on epoch=1
05/25/2022 00:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.011093723086088397 -> 0.03119628383320924 on epoch=1, global_step=100
05/25/2022 00:43:10 - INFO - __main__ - Step 110 Global step 110 Train loss 2.26 on epoch=1
05/25/2022 00:43:12 - INFO - __main__ - Step 120 Global step 120 Train loss 2.25 on epoch=2
05/25/2022 00:43:15 - INFO - __main__ - Step 130 Global step 130 Train loss 1.93 on epoch=2
05/25/2022 00:43:17 - INFO - __main__ - Step 140 Global step 140 Train loss 1.83 on epoch=2
05/25/2022 00:43:20 - INFO - __main__ - Step 150 Global step 150 Train loss 1.93 on epoch=2
05/25/2022 00:43:42 - INFO - __main__ - Global step 150 Train loss 2.04 Classification-F1 0.057591417046844215 on epoch=2
05/25/2022 00:43:42 - INFO - __main__ - Saving model with best Classification-F1: 0.03119628383320924 -> 0.057591417046844215 on epoch=2, global_step=150
05/25/2022 00:43:45 - INFO - __main__ - Step 160 Global step 160 Train loss 1.81 on epoch=2
05/25/2022 00:43:48 - INFO - __main__ - Step 170 Global step 170 Train loss 1.63 on epoch=3
05/25/2022 00:43:50 - INFO - __main__ - Step 180 Global step 180 Train loss 1.41 on epoch=3
05/25/2022 00:43:53 - INFO - __main__ - Step 190 Global step 190 Train loss 1.34 on epoch=3
05/25/2022 00:43:56 - INFO - __main__ - Step 200 Global step 200 Train loss 1.47 on epoch=3
05/25/2022 00:44:18 - INFO - __main__ - Global step 200 Train loss 1.53 Classification-F1 0.11091374421611429 on epoch=3
05/25/2022 00:44:18 - INFO - __main__ - Saving model with best Classification-F1: 0.057591417046844215 -> 0.11091374421611429 on epoch=3, global_step=200
05/25/2022 00:44:21 - INFO - __main__ - Step 210 Global step 210 Train loss 1.46 on epoch=3
05/25/2022 00:44:24 - INFO - __main__ - Step 220 Global step 220 Train loss 1.50 on epoch=3
05/25/2022 00:44:27 - INFO - __main__ - Step 230 Global step 230 Train loss 1.18 on epoch=4
05/25/2022 00:44:29 - INFO - __main__ - Step 240 Global step 240 Train loss 1.06 on epoch=4
05/25/2022 00:44:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.95 on epoch=4
05/25/2022 00:44:55 - INFO - __main__ - Global step 250 Train loss 1.23 Classification-F1 0.1528615700173388 on epoch=4
05/25/2022 00:44:55 - INFO - __main__ - Saving model with best Classification-F1: 0.11091374421611429 -> 0.1528615700173388 on epoch=4, global_step=250
05/25/2022 00:44:58 - INFO - __main__ - Step 260 Global step 260 Train loss 1.07 on epoch=4
05/25/2022 00:45:01 - INFO - __main__ - Step 270 Global step 270 Train loss 1.02 on epoch=4
05/25/2022 00:45:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.89 on epoch=4
05/25/2022 00:45:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=5
05/25/2022 00:45:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=5
05/25/2022 00:45:32 - INFO - __main__ - Global step 300 Train loss 0.90 Classification-F1 0.24207737395441964 on epoch=5
05/25/2022 00:45:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1528615700173388 -> 0.24207737395441964 on epoch=5, global_step=300
05/25/2022 00:45:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.81 on epoch=5
05/25/2022 00:45:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.80 on epoch=5
05/25/2022 00:45:41 - INFO - __main__ - Step 330 Global step 330 Train loss 1.11 on epoch=5
05/25/2022 00:45:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=6
05/25/2022 00:45:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=6
05/25/2022 00:46:12 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.2910392214159583 on epoch=6
05/25/2022 00:46:12 - INFO - __main__ - Saving model with best Classification-F1: 0.24207737395441964 -> 0.2910392214159583 on epoch=6, global_step=350
05/25/2022 00:46:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=6
05/25/2022 00:46:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.65 on epoch=6
05/25/2022 00:46:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=6
05/25/2022 00:46:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=6
05/25/2022 00:46:26 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=7
05/25/2022 00:46:52 - INFO - __main__ - Global step 400 Train loss 0.55 Classification-F1 0.35239326376171415 on epoch=7
05/25/2022 00:46:52 - INFO - __main__ - Saving model with best Classification-F1: 0.2910392214159583 -> 0.35239326376171415 on epoch=7, global_step=400
05/25/2022 00:46:54 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=7
05/25/2022 00:46:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=7
05/25/2022 00:47:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=7
05/25/2022 00:47:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.46 on epoch=7
05/25/2022 00:47:05 - INFO - __main__ - Step 450 Global step 450 Train loss 0.46 on epoch=8
05/25/2022 00:47:31 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.35395063240879976 on epoch=8
05/25/2022 00:47:31 - INFO - __main__ - Saving model with best Classification-F1: 0.35239326376171415 -> 0.35395063240879976 on epoch=8, global_step=450
05/25/2022 00:47:34 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=8
05/25/2022 00:47:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=8
05/25/2022 00:47:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=8
05/25/2022 00:47:42 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=8
05/25/2022 00:47:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.75 on epoch=8
05/25/2022 00:48:11 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.40553635530010823 on epoch=8
05/25/2022 00:48:11 - INFO - __main__ - Saving model with best Classification-F1: 0.35395063240879976 -> 0.40553635530010823 on epoch=8, global_step=500
05/25/2022 00:48:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=9
05/25/2022 00:48:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=9
05/25/2022 00:48:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=9
05/25/2022 00:48:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=9
05/25/2022 00:48:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=9
05/25/2022 00:48:53 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.47778291805742773 on epoch=9
05/25/2022 00:48:53 - INFO - __main__ - Saving model with best Classification-F1: 0.40553635530010823 -> 0.47778291805742773 on epoch=9, global_step=550
05/25/2022 00:48:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.36 on epoch=9
05/25/2022 00:48:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.34 on epoch=10
05/25/2022 00:49:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.28 on epoch=10
05/25/2022 00:49:04 - INFO - __main__ - Step 590 Global step 590 Train loss 0.36 on epoch=10
05/25/2022 00:49:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=10
05/25/2022 00:49:34 - INFO - __main__ - Global step 600 Train loss 0.35 Classification-F1 0.5443921706770556 on epoch=10
05/25/2022 00:49:34 - INFO - __main__ - Saving model with best Classification-F1: 0.47778291805742773 -> 0.5443921706770556 on epoch=10, global_step=600
05/25/2022 00:49:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.72 on epoch=10
05/25/2022 00:49:40 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=11
05/25/2022 00:49:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
05/25/2022 00:49:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=11
05/25/2022 00:49:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=11
05/25/2022 00:50:15 - INFO - __main__ - Global step 650 Train loss 0.38 Classification-F1 0.5231397381615119 on epoch=11
05/25/2022 00:50:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.33 on epoch=11
05/25/2022 00:50:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=11
05/25/2022 00:50:23 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=12
05/25/2022 00:50:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=12
05/25/2022 00:50:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=12
05/25/2022 00:50:56 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.5349865602465103 on epoch=12
05/25/2022 00:50:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=12
05/25/2022 00:51:01 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=12
05/25/2022 00:51:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=13
05/25/2022 00:51:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=13
05/25/2022 00:51:10 - INFO - __main__ - Step 750 Global step 750 Train loss 0.28 on epoch=13
05/25/2022 00:51:36 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.5919055830570165 on epoch=13
05/25/2022 00:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5443921706770556 -> 0.5919055830570165 on epoch=13, global_step=750
05/25/2022 00:51:39 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=13
05/25/2022 00:51:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=13
05/25/2022 00:51:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.54 on epoch=13
05/25/2022 00:51:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=14
05/25/2022 00:51:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=14
05/25/2022 00:52:16 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.5291482275311894 on epoch=14
05/25/2022 00:52:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.18 on epoch=14
05/25/2022 00:52:21 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=14
05/25/2022 00:52:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=14
05/25/2022 00:52:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=14
05/25/2022 00:52:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=15
05/25/2022 00:52:56 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.510263511770971 on epoch=15
05/25/2022 00:52:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=15
05/25/2022 00:53:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=15
05/25/2022 00:53:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=15
05/25/2022 00:53:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.49 on epoch=15
05/25/2022 00:53:09 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=16
05/25/2022 00:53:35 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.5330767691411359 on epoch=16
05/25/2022 00:53:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=16
05/25/2022 00:53:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=16
05/25/2022 00:53:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=16
05/25/2022 00:53:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=16
05/25/2022 00:53:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=16
05/25/2022 00:54:15 - INFO - __main__ - Global step 950 Train loss 0.20 Classification-F1 0.5045417568699248 on epoch=16
05/25/2022 00:54:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=17
05/25/2022 00:54:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=17
05/25/2022 00:54:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=17
05/25/2022 00:54:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=17
05/25/2022 00:54:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.55 on epoch=17
05/25/2022 00:54:56 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.5759194148318458 on epoch=17
05/25/2022 00:54:58 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=18
05/25/2022 00:55:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
05/25/2022 00:55:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=18
05/25/2022 00:55:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=18
05/25/2022 00:55:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=18
05/25/2022 00:55:36 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.6052253605565572 on epoch=18
05/25/2022 00:55:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5919055830570165 -> 0.6052253605565572 on epoch=18, global_step=1050
05/25/2022 00:55:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.39 on epoch=18
05/25/2022 00:55:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=19
05/25/2022 00:55:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=19
05/25/2022 00:55:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=19
05/25/2022 00:55:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=19
05/25/2022 00:56:17 - INFO - __main__ - Global step 1100 Train loss 0.19 Classification-F1 0.5611293605171722 on epoch=19
05/25/2022 00:56:20 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=19
05/25/2022 00:56:22 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=19
05/25/2022 00:56:25 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=20
05/25/2022 00:56:28 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=20
05/25/2022 00:56:31 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=20
05/25/2022 00:56:57 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.555654289005288 on epoch=20
05/25/2022 00:57:00 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=20
05/25/2022 00:57:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=20
05/25/2022 00:57:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=21
05/25/2022 00:57:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=21
05/25/2022 00:57:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=21
05/25/2022 00:57:37 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.5881916424342111 on epoch=21
05/25/2022 00:57:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=21
05/25/2022 00:57:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=21
05/25/2022 00:57:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.47 on epoch=21
05/25/2022 00:57:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=22
05/25/2022 00:57:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.10 on epoch=22
05/25/2022 00:58:18 - INFO - __main__ - Global step 1250 Train loss 0.21 Classification-F1 0.6153211662318776 on epoch=22
05/25/2022 00:58:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6052253605565572 -> 0.6153211662318776 on epoch=22, global_step=1250
05/25/2022 00:58:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=22
05/25/2022 00:58:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=22
05/25/2022 00:58:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.27 on epoch=22
05/25/2022 00:58:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=23
05/25/2022 00:58:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
05/25/2022 00:58:58 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.6115993647881088 on epoch=23
05/25/2022 00:59:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=23
05/25/2022 00:59:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=23
05/25/2022 00:59:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=23
05/25/2022 00:59:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=23
05/25/2022 00:59:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/25/2022 00:59:38 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.6461206333052596 on epoch=24
05/25/2022 00:59:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6153211662318776 -> 0.6461206333052596 on epoch=24, global_step=1350
05/25/2022 00:59:41 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
05/25/2022 00:59:44 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
05/25/2022 00:59:46 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=24
05/25/2022 00:59:49 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=24
05/25/2022 00:59:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/25/2022 01:00:18 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.5825621045967488 on epoch=24
05/25/2022 01:00:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=25
05/25/2022 01:00:23 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=25
05/25/2022 01:00:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=25
05/25/2022 01:00:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=25
05/25/2022 01:00:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.52 on epoch=25
05/25/2022 01:00:58 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.5081283385121825 on epoch=25
05/25/2022 01:01:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/25/2022 01:01:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
05/25/2022 01:01:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/25/2022 01:01:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=26
05/25/2022 01:01:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=26
05/25/2022 01:01:38 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.588097402009416 on epoch=26
05/25/2022 01:01:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.42 on epoch=26
05/25/2022 01:01:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=27
05/25/2022 01:01:47 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=27
05/25/2022 01:01:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=27
05/25/2022 01:01:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=27
05/25/2022 01:02:19 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5680143467262595 on epoch=27
05/25/2022 01:02:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.44 on epoch=27
05/25/2022 01:02:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
05/25/2022 01:02:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/25/2022 01:02:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=28
05/25/2022 01:02:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
05/25/2022 01:02:58 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.5305958222447572 on epoch=28
05/25/2022 01:03:01 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=28
05/25/2022 01:03:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.54 on epoch=28
05/25/2022 01:03:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
05/25/2022 01:03:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=29
05/25/2022 01:03:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
05/25/2022 01:03:38 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.571410062762461 on epoch=29
05/25/2022 01:03:41 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=29
05/25/2022 01:03:44 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.35 on epoch=29
05/25/2022 01:03:46 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=29
05/25/2022 01:03:49 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=30
05/25/2022 01:03:52 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
05/25/2022 01:04:19 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.6519496849745574 on epoch=30
05/25/2022 01:04:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6461206333052596 -> 0.6519496849745574 on epoch=30, global_step=1700
05/25/2022 01:04:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=30
05/25/2022 01:04:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=30
05/25/2022 01:04:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.39 on epoch=30
05/25/2022 01:04:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=31
05/25/2022 01:04:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=31
05/25/2022 01:04:59 - INFO - __main__ - Global step 1750 Train loss 0.17 Classification-F1 0.6198573177354707 on epoch=31
05/25/2022 01:05:02 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/25/2022 01:05:05 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/25/2022 01:05:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=31
05/25/2022 01:05:10 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.34 on epoch=31
05/25/2022 01:05:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
05/25/2022 01:05:39 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.6531109713260467 on epoch=32
05/25/2022 01:05:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6519496849745574 -> 0.6531109713260467 on epoch=32, global_step=1800
05/25/2022 01:05:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=32
05/25/2022 01:05:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=32
05/25/2022 01:05:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=32
05/25/2022 01:05:50 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.52 on epoch=32
05/25/2022 01:05:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/25/2022 01:06:18 - INFO - __main__ - Global step 1850 Train loss 0.16 Classification-F1 0.5321728195333808 on epoch=33
05/25/2022 01:06:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/25/2022 01:06:24 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/25/2022 01:06:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=33
05/25/2022 01:06:29 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
05/25/2022 01:06:32 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.42 on epoch=33
05/25/2022 01:06:57 - INFO - __main__ - Global step 1900 Train loss 0.15 Classification-F1 0.6516543810528933 on epoch=33
05/25/2022 01:07:00 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
05/25/2022 01:07:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=34
05/25/2022 01:07:05 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=34
05/25/2022 01:07:08 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=34
05/25/2022 01:07:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=34
05/25/2022 01:07:35 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.5911881738473352 on epoch=34
05/25/2022 01:07:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=34
05/25/2022 01:07:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=35
05/25/2022 01:07:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=35
05/25/2022 01:07:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
05/25/2022 01:07:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=35
05/25/2022 01:08:13 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.6537443213071508 on epoch=35
05/25/2022 01:08:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6531109713260467 -> 0.6537443213071508 on epoch=35, global_step=2000
05/25/2022 01:08:16 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.38 on epoch=35
05/25/2022 01:08:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
05/25/2022 01:08:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=36
05/25/2022 01:08:24 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
05/25/2022 01:08:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=36
05/25/2022 01:08:53 - INFO - __main__ - Global step 2050 Train loss 0.13 Classification-F1 0.6605030609711563 on epoch=36
05/25/2022 01:08:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6537443213071508 -> 0.6605030609711563 on epoch=36, global_step=2050
05/25/2022 01:08:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=36
05/25/2022 01:08:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/25/2022 01:09:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=37
05/25/2022 01:09:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/25/2022 01:09:07 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/25/2022 01:09:33 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.6934419587799963 on epoch=37
05/25/2022 01:09:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6605030609711563 -> 0.6934419587799963 on epoch=37, global_step=2100
05/25/2022 01:09:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/25/2022 01:09:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=37
05/25/2022 01:09:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/25/2022 01:09:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=38
05/25/2022 01:09:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=38
05/25/2022 01:10:12 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6929674559963712 on epoch=38
05/25/2022 01:10:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/25/2022 01:10:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=38
05/25/2022 01:10:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.15 on epoch=38
05/25/2022 01:10:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=39
05/25/2022 01:10:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=39
05/25/2022 01:10:51 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.7431284764043488 on epoch=39
05/25/2022 01:10:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6934419587799963 -> 0.7431284764043488 on epoch=39, global_step=2200
05/25/2022 01:10:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=39
05/25/2022 01:10:57 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=39
05/25/2022 01:11:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.38 on epoch=39
05/25/2022 01:11:02 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=39
05/25/2022 01:11:05 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=40
05/25/2022 01:11:31 - INFO - __main__ - Global step 2250 Train loss 0.14 Classification-F1 0.702838767112812 on epoch=40
05/25/2022 01:11:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/25/2022 01:11:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=40
05/25/2022 01:11:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=40
05/25/2022 01:11:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.37 on epoch=40
05/25/2022 01:11:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/25/2022 01:12:10 - INFO - __main__ - Global step 2300 Train loss 0.13 Classification-F1 0.6587669924567742 on epoch=41
05/25/2022 01:12:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=41
05/25/2022 01:12:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=41
05/25/2022 01:12:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/25/2022 01:12:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/25/2022 01:12:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.38 on epoch=41
05/25/2022 01:12:50 - INFO - __main__ - Global step 2350 Train loss 0.13 Classification-F1 0.6705221856001822 on epoch=41
05/25/2022 01:12:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
05/25/2022 01:12:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/25/2022 01:12:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=42
05/25/2022 01:13:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=42
05/25/2022 01:13:03 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.39 on epoch=42
05/25/2022 01:13:30 - INFO - __main__ - Global step 2400 Train loss 0.12 Classification-F1 0.7175232083761158 on epoch=42
05/25/2022 01:13:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/25/2022 01:13:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
05/25/2022 01:13:38 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/25/2022 01:13:41 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=43
05/25/2022 01:13:43 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.14 on epoch=43
05/25/2022 01:14:09 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7147380724539484 on epoch=43
05/25/2022 01:14:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 01:14:15 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/25/2022 01:14:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=44
05/25/2022 01:14:20 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/25/2022 01:14:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=44
05/25/2022 01:14:49 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7320188317455019 on epoch=44
05/25/2022 01:14:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.32 on epoch=44
05/25/2022 01:14:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=44
05/25/2022 01:14:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/25/2022 01:15:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/25/2022 01:15:03 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=45
05/25/2022 01:15:29 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.6839464204560659 on epoch=45
05/25/2022 01:15:32 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=45
05/25/2022 01:15:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.45 on epoch=45
05/25/2022 01:15:37 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
05/25/2022 01:15:40 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/25/2022 01:15:43 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=46
05/25/2022 01:16:08 - INFO - __main__ - Global step 2600 Train loss 0.14 Classification-F1 0.7248029384932475 on epoch=46
05/25/2022 01:16:10 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=46
05/25/2022 01:16:13 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=46
05/25/2022 01:16:15 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.34 on epoch=46
05/25/2022 01:16:18 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=47
05/25/2022 01:16:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/25/2022 01:16:46 - INFO - __main__ - Global step 2650 Train loss 0.11 Classification-F1 0.6493536540027123 on epoch=47
05/25/2022 01:16:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
05/25/2022 01:16:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=47
05/25/2022 01:16:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.40 on epoch=47
05/25/2022 01:16:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/25/2022 01:16:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=48
05/25/2022 01:17:24 - INFO - __main__ - Global step 2700 Train loss 0.12 Classification-F1 0.7746377863397325 on epoch=48
05/25/2022 01:17:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7431284764043488 -> 0.7746377863397325 on epoch=48, global_step=2700
05/25/2022 01:17:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.07 on epoch=48
05/25/2022 01:17:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=48
05/25/2022 01:17:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.08 on epoch=48
05/25/2022 01:17:35 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.36 on epoch=48
05/25/2022 01:17:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=49
05/25/2022 01:18:02 - INFO - __main__ - Global step 2750 Train loss 0.12 Classification-F1 0.6579228591581754 on epoch=49
05/25/2022 01:18:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=49
05/25/2022 01:18:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/25/2022 01:18:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=49
05/25/2022 01:18:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=49
05/25/2022 01:18:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/25/2022 01:18:40 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7851812685978741 on epoch=49
05/25/2022 01:18:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7746377863397325 -> 0.7851812685978741 on epoch=49, global_step=2800
05/25/2022 01:18:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/25/2022 01:18:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/25/2022 01:18:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=50
05/25/2022 01:18:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=50
05/25/2022 01:18:53 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.35 on epoch=50
05/25/2022 01:19:18 - INFO - __main__ - Global step 2850 Train loss 0.12 Classification-F1 0.7382588688402069 on epoch=50
05/25/2022 01:19:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
05/25/2022 01:19:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=51
05/25/2022 01:19:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
05/25/2022 01:19:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=51
05/25/2022 01:19:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=51
05/25/2022 01:19:55 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7009313781988362 on epoch=51
05/25/2022 01:19:58 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/25/2022 01:20:01 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=52
05/25/2022 01:20:03 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=52
05/25/2022 01:20:06 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
05/25/2022 01:20:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=52
05/25/2022 01:20:33 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6282425451135341 on epoch=52
05/25/2022 01:20:36 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.36 on epoch=52
05/25/2022 01:20:39 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=53
05/25/2022 01:20:41 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=53
05/25/2022 01:20:44 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
05/25/2022 01:20:47 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=53
05/25/2022 01:20:48 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 01:20:48 - INFO - __main__ - Printing 3 examples
05/25/2022 01:20:48 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 01:20:48 - INFO - __main__ - ['Animal']
05/25/2022 01:20:48 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 01:20:48 - INFO - __main__ - ['Animal']
05/25/2022 01:20:48 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 01:20:48 - INFO - __main__ - ['Animal']
05/25/2022 01:20:48 - INFO - __main__ - Tokenizing Input ...
05/25/2022 01:20:49 - INFO - __main__ - Tokenizing Output ...
05/25/2022 01:20:50 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 01:20:50 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 01:20:50 - INFO - __main__ - Printing 3 examples
05/25/2022 01:20:50 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/25/2022 01:20:50 - INFO - __main__ - ['Animal']
05/25/2022 01:20:50 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/25/2022 01:20:50 - INFO - __main__ - ['Animal']
05/25/2022 01:20:50 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/25/2022 01:20:50 - INFO - __main__ - ['Animal']
05/25/2022 01:20:50 - INFO - __main__ - Tokenizing Input ...
05/25/2022 01:20:50 - INFO - __main__ - Tokenizing Output ...
05/25/2022 01:20:51 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 01:21:08 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 01:21:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 01:21:09 - INFO - __main__ - Starting training!
05/25/2022 01:21:11 - INFO - __main__ - Global step 3000 Train loss 0.11 Classification-F1 0.5984280016534855 on epoch=53
05/25/2022 01:21:11 - INFO - __main__ - save last model!
05/25/2022 01:21:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 01:21:11 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 01:21:11 - INFO - __main__ - Printing 3 examples
05/25/2022 01:21:11 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 01:21:11 - INFO - __main__ - ['Animal']
05/25/2022 01:21:11 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 01:21:11 - INFO - __main__ - ['Animal']
05/25/2022 01:21:11 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 01:21:11 - INFO - __main__ - ['Village']
05/25/2022 01:21:11 - INFO - __main__ - Tokenizing Input ...
05/25/2022 01:21:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 01:21:17 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 01:23:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.3_8_predictions.txt
05/25/2022 01:23:16 - INFO - __main__ - Classification-F1 on test data: 0.5306
05/25/2022 01:23:17 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.3, bsz=8, dev_performance=0.7851812685978741, test_performance=0.5305734904158382
05/25/2022 01:23:17 - INFO - __main__ - Running ... prefix=dbpedia_14_64_100, lr=0.2, bsz=8 ...
05/25/2022 01:23:18 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 01:23:18 - INFO - __main__ - Printing 3 examples
05/25/2022 01:23:18 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 01:23:18 - INFO - __main__ - ['Animal']
05/25/2022 01:23:18 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 01:23:18 - INFO - __main__ - ['Animal']
05/25/2022 01:23:18 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 01:23:18 - INFO - __main__ - ['Animal']
05/25/2022 01:23:18 - INFO - __main__ - Tokenizing Input ...
05/25/2022 01:23:18 - INFO - __main__ - Tokenizing Output ...
05/25/2022 01:23:19 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 01:23:19 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 01:23:19 - INFO - __main__ - Printing 3 examples
05/25/2022 01:23:19 - INFO - __main__ -  [dbpedia_14] Metareva aenescens is a moth of the Arctiidae family. It was described by Hampson in 1900. It is found in Bolivia.
05/25/2022 01:23:19 - INFO - __main__ - ['Animal']
05/25/2022 01:23:19 - INFO - __main__ -  [dbpedia_14] Xenopipo is a genus of bird in the Pipridae family. It contains the following species: Black Manakin (Xenopipo atronitens) Yellow-headed Manakin (Xenopipo flavicapilla) Green Manakin (Xenopipo holochlora) Jet Manakin (Xenopipo unicolor) Olive Manakin (Xenopipo uniformis)
05/25/2022 01:23:19 - INFO - __main__ - ['Animal']
05/25/2022 01:23:19 - INFO - __main__ -  [dbpedia_14] The Tardy Renia (Renia nemoralis) is a moth of the Noctuidae family. It is found from Illinois to south-eastern Massachusetts south to Florida and Texas.The wingspan is 28-30 mm. There is one generation per year.The larvae feed on organic matter including dead leaves.
05/25/2022 01:23:19 - INFO - __main__ - ['Animal']
05/25/2022 01:23:19 - INFO - __main__ - Tokenizing Input ...
05/25/2022 01:23:20 - INFO - __main__ - Tokenizing Output ...
05/25/2022 01:23:21 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 01:23:36 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 01:23:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 01:23:37 - INFO - __main__ - Starting training!
05/25/2022 01:23:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.45 on epoch=0
05/25/2022 01:23:43 - INFO - __main__ - Step 20 Global step 20 Train loss 5.90 on epoch=0
05/25/2022 01:23:46 - INFO - __main__ - Step 30 Global step 30 Train loss 5.25 on epoch=0
05/25/2022 01:23:49 - INFO - __main__ - Step 40 Global step 40 Train loss 5.05 on epoch=0
05/25/2022 01:23:51 - INFO - __main__ - Step 50 Global step 50 Train loss 4.52 on epoch=0
05/25/2022 01:24:14 - INFO - __main__ - Global step 50 Train loss 5.63 Classification-F1 0.01204020832699077 on epoch=0
05/25/2022 01:24:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01204020832699077 on epoch=0, global_step=50
05/25/2022 01:24:17 - INFO - __main__ - Step 60 Global step 60 Train loss 4.35 on epoch=1
05/25/2022 01:24:20 - INFO - __main__ - Step 70 Global step 70 Train loss 3.30 on epoch=1
05/25/2022 01:24:22 - INFO - __main__ - Step 80 Global step 80 Train loss 3.19 on epoch=1
05/25/2022 01:24:25 - INFO - __main__ - Step 90 Global step 90 Train loss 3.36 on epoch=1
05/25/2022 01:24:28 - INFO - __main__ - Step 100 Global step 100 Train loss 3.26 on epoch=1
05/25/2022 01:24:52 - INFO - __main__ - Global step 100 Train loss 3.49 Classification-F1 0.02086434023760294 on epoch=1
05/25/2022 01:24:52 - INFO - __main__ - Saving model with best Classification-F1: 0.01204020832699077 -> 0.02086434023760294 on epoch=1, global_step=100
05/25/2022 01:24:54 - INFO - __main__ - Step 110 Global step 110 Train loss 2.83 on epoch=1
05/25/2022 01:24:57 - INFO - __main__ - Step 120 Global step 120 Train loss 2.84 on epoch=2
05/25/2022 01:25:00 - INFO - __main__ - Step 130 Global step 130 Train loss 2.36 on epoch=2
05/25/2022 01:25:02 - INFO - __main__ - Step 140 Global step 140 Train loss 2.33 on epoch=2
05/25/2022 01:25:05 - INFO - __main__ - Step 150 Global step 150 Train loss 2.48 on epoch=2
05/25/2022 01:25:30 - INFO - __main__ - Global step 150 Train loss 2.57 Classification-F1 0.03226917502390023 on epoch=2
05/25/2022 01:25:30 - INFO - __main__ - Saving model with best Classification-F1: 0.02086434023760294 -> 0.03226917502390023 on epoch=2, global_step=150
05/25/2022 01:25:32 - INFO - __main__ - Step 160 Global step 160 Train loss 2.55 on epoch=2
05/25/2022 01:25:35 - INFO - __main__ - Step 170 Global step 170 Train loss 2.24 on epoch=3
05/25/2022 01:25:38 - INFO - __main__ - Step 180 Global step 180 Train loss 1.87 on epoch=3
05/25/2022 01:25:40 - INFO - __main__ - Step 190 Global step 190 Train loss 1.93 on epoch=3
05/25/2022 01:25:43 - INFO - __main__ - Step 200 Global step 200 Train loss 1.78 on epoch=3
05/25/2022 01:26:05 - INFO - __main__ - Global step 200 Train loss 2.07 Classification-F1 0.05102244424446056 on epoch=3
05/25/2022 01:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.03226917502390023 -> 0.05102244424446056 on epoch=3, global_step=200
05/25/2022 01:26:07 - INFO - __main__ - Step 210 Global step 210 Train loss 2.17 on epoch=3
05/25/2022 01:26:10 - INFO - __main__ - Step 220 Global step 220 Train loss 1.92 on epoch=3
05/25/2022 01:26:13 - INFO - __main__ - Step 230 Global step 230 Train loss 1.85 on epoch=4
05/25/2022 01:26:15 - INFO - __main__ - Step 240 Global step 240 Train loss 1.62 on epoch=4
05/25/2022 01:26:18 - INFO - __main__ - Step 250 Global step 250 Train loss 1.51 on epoch=4
05/25/2022 01:26:41 - INFO - __main__ - Global step 250 Train loss 1.81 Classification-F1 0.08421841600973098 on epoch=4
05/25/2022 01:26:41 - INFO - __main__ - Saving model with best Classification-F1: 0.05102244424446056 -> 0.08421841600973098 on epoch=4, global_step=250
05/25/2022 01:26:44 - INFO - __main__ - Step 260 Global step 260 Train loss 1.75 on epoch=4
05/25/2022 01:26:46 - INFO - __main__ - Step 270 Global step 270 Train loss 1.60 on epoch=4
05/25/2022 01:26:49 - INFO - __main__ - Step 280 Global step 280 Train loss 1.49 on epoch=4
05/25/2022 01:26:52 - INFO - __main__ - Step 290 Global step 290 Train loss 1.36 on epoch=5
05/25/2022 01:26:55 - INFO - __main__ - Step 300 Global step 300 Train loss 1.25 on epoch=5
05/25/2022 01:27:18 - INFO - __main__ - Global step 300 Train loss 1.49 Classification-F1 0.10792656444500114 on epoch=5
05/25/2022 01:27:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08421841600973098 -> 0.10792656444500114 on epoch=5, global_step=300
05/25/2022 01:27:21 - INFO - __main__ - Step 310 Global step 310 Train loss 1.33 on epoch=5
05/25/2022 01:27:23 - INFO - __main__ - Step 320 Global step 320 Train loss 1.39 on epoch=5
05/25/2022 01:27:26 - INFO - __main__ - Step 330 Global step 330 Train loss 1.35 on epoch=5
05/25/2022 01:27:29 - INFO - __main__ - Step 340 Global step 340 Train loss 1.20 on epoch=6
05/25/2022 01:27:31 - INFO - __main__ - Step 350 Global step 350 Train loss 0.91 on epoch=6
05/25/2022 01:27:54 - INFO - __main__ - Global step 350 Train loss 1.23 Classification-F1 0.14095367908566606 on epoch=6
05/25/2022 01:27:54 - INFO - __main__ - Saving model with best Classification-F1: 0.10792656444500114 -> 0.14095367908566606 on epoch=6, global_step=350
05/25/2022 01:27:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.89 on epoch=6
05/25/2022 01:27:59 - INFO - __main__ - Step 370 Global step 370 Train loss 1.23 on epoch=6
05/25/2022 01:28:02 - INFO - __main__ - Step 380 Global step 380 Train loss 1.00 on epoch=6
05/25/2022 01:28:05 - INFO - __main__ - Step 390 Global step 390 Train loss 1.24 on epoch=6
05/25/2022 01:28:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.89 on epoch=7
05/25/2022 01:28:31 - INFO - __main__ - Global step 400 Train loss 1.05 Classification-F1 0.1941474348343143 on epoch=7
05/25/2022 01:28:31 - INFO - __main__ - Saving model with best Classification-F1: 0.14095367908566606 -> 0.1941474348343143 on epoch=7, global_step=400
05/25/2022 01:28:33 - INFO - __main__ - Step 410 Global step 410 Train loss 0.81 on epoch=7
05/25/2022 01:28:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.74 on epoch=7
05/25/2022 01:28:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.84 on epoch=7
05/25/2022 01:28:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.84 on epoch=7
05/25/2022 01:28:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.68 on epoch=8
05/25/2022 01:29:08 - INFO - __main__ - Global step 450 Train loss 0.78 Classification-F1 0.21549613277158247 on epoch=8
05/25/2022 01:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.1941474348343143 -> 0.21549613277158247 on epoch=8, global_step=450
05/25/2022 01:29:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.52 on epoch=8
05/25/2022 01:29:14 - INFO - __main__ - Step 470 Global step 470 Train loss 0.82 on epoch=8
05/25/2022 01:29:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.75 on epoch=8
05/25/2022 01:29:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.81 on epoch=8
05/25/2022 01:29:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.98 on epoch=8
05/25/2022 01:29:47 - INFO - __main__ - Global step 500 Train loss 0.78 Classification-F1 0.2623733036597892 on epoch=8
05/25/2022 01:29:47 - INFO - __main__ - Saving model with best Classification-F1: 0.21549613277158247 -> 0.2623733036597892 on epoch=8, global_step=500
05/25/2022 01:29:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=9
05/25/2022 01:29:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.45 on epoch=9
05/25/2022 01:29:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.63 on epoch=9
05/25/2022 01:29:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=9
05/25/2022 01:30:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.94 on epoch=9
05/25/2022 01:30:28 - INFO - __main__ - Global step 550 Train loss 0.62 Classification-F1 0.28421930720381694 on epoch=9
05/25/2022 01:30:28 - INFO - __main__ - Saving model with best Classification-F1: 0.2623733036597892 -> 0.28421930720381694 on epoch=9, global_step=550
05/25/2022 01:30:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=9
05/25/2022 01:30:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.50 on epoch=10
05/25/2022 01:30:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=10
05/25/2022 01:30:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=10
05/25/2022 01:30:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.58 on epoch=10
05/25/2022 01:31:08 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.33953167540031476 on epoch=10
05/25/2022 01:31:08 - INFO - __main__ - Saving model with best Classification-F1: 0.28421930720381694 -> 0.33953167540031476 on epoch=10, global_step=600
05/25/2022 01:31:11 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=10
05/25/2022 01:31:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.39 on epoch=11
05/25/2022 01:31:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=11
05/25/2022 01:31:19 - INFO - __main__ - Step 640 Global step 640 Train loss 0.42 on epoch=11
05/25/2022 01:31:22 - INFO - __main__ - Step 650 Global step 650 Train loss 0.53 on epoch=11
05/25/2022 01:31:50 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.33518892167210174 on epoch=11
05/25/2022 01:31:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=11
05/25/2022 01:31:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.41 on epoch=11
05/25/2022 01:31:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.37 on epoch=12
05/25/2022 01:32:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.37 on epoch=12
05/25/2022 01:32:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.46 on epoch=12
05/25/2022 01:32:30 - INFO - __main__ - Global step 700 Train loss 0.41 Classification-F1 0.3381860883252691 on epoch=12
05/25/2022 01:32:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.39 on epoch=12
05/25/2022 01:32:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.81 on epoch=12
05/25/2022 01:32:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=13
05/25/2022 01:32:41 - INFO - __main__ - Step 740 Global step 740 Train loss 0.31 on epoch=13
05/25/2022 01:32:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.35 on epoch=13
05/25/2022 01:33:11 - INFO - __main__ - Global step 750 Train loss 0.44 Classification-F1 0.37877570473563277 on epoch=13
05/25/2022 01:33:11 - INFO - __main__ - Saving model with best Classification-F1: 0.33953167540031476 -> 0.37877570473563277 on epoch=13, global_step=750
05/25/2022 01:33:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=13
05/25/2022 01:33:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.46 on epoch=13
05/25/2022 01:33:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.68 on epoch=13
05/25/2022 01:33:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=14
05/25/2022 01:33:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.29 on epoch=14
05/25/2022 01:33:51 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.39775445398447157 on epoch=14
05/25/2022 01:33:51 - INFO - __main__ - Saving model with best Classification-F1: 0.37877570473563277 -> 0.39775445398447157 on epoch=14, global_step=800
05/25/2022 01:33:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.36 on epoch=14
05/25/2022 01:33:57 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=14
05/25/2022 01:34:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=14
05/25/2022 01:34:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.30 on epoch=14
05/25/2022 01:34:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.32 on epoch=15
05/25/2022 01:34:31 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.42214645351279734 on epoch=15
05/25/2022 01:34:31 - INFO - __main__ - Saving model with best Classification-F1: 0.39775445398447157 -> 0.42214645351279734 on epoch=15, global_step=850
05/25/2022 01:34:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=15
05/25/2022 01:34:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=15
05/25/2022 01:34:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.36 on epoch=15
05/25/2022 01:34:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.33 on epoch=15
05/25/2022 01:34:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=16
05/25/2022 01:35:12 - INFO - __main__ - Global step 900 Train loss 0.29 Classification-F1 0.39893312985200907 on epoch=16
05/25/2022 01:35:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=16
05/25/2022 01:35:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.25 on epoch=16
05/25/2022 01:35:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=16
05/25/2022 01:35:23 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=16
05/25/2022 01:35:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=16
05/25/2022 01:35:53 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.487602564958868 on epoch=16
05/25/2022 01:35:53 - INFO - __main__ - Saving model with best Classification-F1: 0.42214645351279734 -> 0.487602564958868 on epoch=16, global_step=950
05/25/2022 01:35:56 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=17
05/25/2022 01:35:58 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=17
05/25/2022 01:36:01 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=17
05/25/2022 01:36:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.31 on epoch=17
05/25/2022 01:36:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.68 on epoch=17
05/25/2022 01:36:33 - INFO - __main__ - Global step 1000 Train loss 0.35 Classification-F1 0.5064981216331806 on epoch=17
05/25/2022 01:36:34 - INFO - __main__ - Saving model with best Classification-F1: 0.487602564958868 -> 0.5064981216331806 on epoch=17, global_step=1000
05/25/2022 01:36:36 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=18
05/25/2022 01:36:39 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=18
05/25/2022 01:36:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=18
05/25/2022 01:36:44 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.30 on epoch=18
05/25/2022 01:36:47 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=18
05/25/2022 01:37:14 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.5087110678752239 on epoch=18
05/25/2022 01:37:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5064981216331806 -> 0.5087110678752239 on epoch=18, global_step=1050
05/25/2022 01:37:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.57 on epoch=18
05/25/2022 01:37:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=19
05/25/2022 01:37:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=19
05/25/2022 01:37:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.24 on epoch=19
05/25/2022 01:37:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.32 on epoch=19
05/25/2022 01:37:54 - INFO - __main__ - Global step 1100 Train loss 0.31 Classification-F1 0.5030079697607966 on epoch=19
05/25/2022 01:37:57 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.53 on epoch=19
05/25/2022 01:38:00 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.26 on epoch=19
05/25/2022 01:38:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=20
05/25/2022 01:38:05 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
05/25/2022 01:38:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=20
05/25/2022 01:38:35 - INFO - __main__ - Global step 1150 Train loss 0.30 Classification-F1 0.5595539895390992 on epoch=20
05/25/2022 01:38:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5087110678752239 -> 0.5595539895390992 on epoch=20, global_step=1150
05/25/2022 01:38:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=20
05/25/2022 01:38:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.63 on epoch=20
05/25/2022 01:38:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=21
05/25/2022 01:38:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.27 on epoch=21
05/25/2022 01:38:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=21
05/25/2022 01:39:16 - INFO - __main__ - Global step 1200 Train loss 0.30 Classification-F1 0.5555389613776011 on epoch=21
05/25/2022 01:39:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.23 on epoch=21
05/25/2022 01:39:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.24 on epoch=21
05/25/2022 01:39:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.53 on epoch=21
05/25/2022 01:39:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=22
05/25/2022 01:39:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=22
05/25/2022 01:39:57 - INFO - __main__ - Global step 1250 Train loss 0.27 Classification-F1 0.5599653145906894 on epoch=22
05/25/2022 01:39:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5595539895390992 -> 0.5599653145906894 on epoch=22, global_step=1250
05/25/2022 01:39:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=22
05/25/2022 01:40:02 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.20 on epoch=22
05/25/2022 01:40:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.53 on epoch=22
05/25/2022 01:40:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.21 on epoch=23
05/25/2022 01:40:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=23
05/25/2022 01:40:37 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.5612739016476906 on epoch=23
05/25/2022 01:40:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5599653145906894 -> 0.5612739016476906 on epoch=23, global_step=1300
05/25/2022 01:40:40 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=23
05/25/2022 01:40:42 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=23
05/25/2022 01:40:45 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.21 on epoch=23
05/25/2022 01:40:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.21 on epoch=23
05/25/2022 01:40:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=24
05/25/2022 01:41:18 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.5375782591346236 on epoch=24
05/25/2022 01:41:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=24
05/25/2022 01:41:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=24
05/25/2022 01:41:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=24
05/25/2022 01:41:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.54 on epoch=24
05/25/2022 01:41:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=24
05/25/2022 01:41:58 - INFO - __main__ - Global step 1400 Train loss 0.23 Classification-F1 0.5329266541415538 on epoch=24
05/25/2022 01:42:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=25
05/25/2022 01:42:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=25
05/25/2022 01:42:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=25
05/25/2022 01:42:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=25
05/25/2022 01:42:12 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.45 on epoch=25
05/25/2022 01:42:38 - INFO - __main__ - Global step 1450 Train loss 0.24 Classification-F1 0.5364723024515023 on epoch=25
05/25/2022 01:42:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=26
05/25/2022 01:42:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=26
05/25/2022 01:42:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=26
05/25/2022 01:42:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.22 on epoch=26
05/25/2022 01:42:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=26
05/25/2022 01:43:19 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.5832671822534686 on epoch=26
05/25/2022 01:43:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5612739016476906 -> 0.5832671822534686 on epoch=26, global_step=1500
05/25/2022 01:43:22 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.41 on epoch=26
05/25/2022 01:43:25 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.21 on epoch=27
05/25/2022 01:43:27 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=27
05/25/2022 01:43:30 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=27
05/25/2022 01:43:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=27
05/25/2022 01:43:59 - INFO - __main__ - Global step 1550 Train loss 0.20 Classification-F1 0.5851619882112412 on epoch=27
05/25/2022 01:43:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5832671822534686 -> 0.5851619882112412 on epoch=27, global_step=1550
05/25/2022 01:44:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.19 on epoch=27
05/25/2022 01:44:04 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=28
05/25/2022 01:44:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=28
05/25/2022 01:44:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=28
05/25/2022 01:44:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=28
05/25/2022 01:44:40 - INFO - __main__ - Global step 1600 Train loss 0.15 Classification-F1 0.5270224693918799 on epoch=28
05/25/2022 01:44:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=28
05/25/2022 01:44:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.44 on epoch=28
05/25/2022 01:44:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=29
05/25/2022 01:44:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=29
05/25/2022 01:44:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=29
05/25/2022 01:45:20 - INFO - __main__ - Global step 1650 Train loss 0.22 Classification-F1 0.5364033520601876 on epoch=29
05/25/2022 01:45:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=29
05/25/2022 01:45:26 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.52 on epoch=29
05/25/2022 01:45:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=29
05/25/2022 01:45:31 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=30
05/25/2022 01:45:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=30
05/25/2022 01:46:01 - INFO - __main__ - Global step 1700 Train loss 0.19 Classification-F1 0.5376140609261046 on epoch=30
05/25/2022 01:46:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=30
05/25/2022 01:46:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.18 on epoch=30
05/25/2022 01:46:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.24 on epoch=30
05/25/2022 01:46:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=31
05/25/2022 01:46:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=31
05/25/2022 01:46:42 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.5619402452336217 on epoch=31
05/25/2022 01:46:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.18 on epoch=31
05/25/2022 01:46:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=31
05/25/2022 01:46:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.18 on epoch=31
05/25/2022 01:46:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.38 on epoch=31
05/25/2022 01:46:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=32
05/25/2022 01:47:23 - INFO - __main__ - Global step 1800 Train loss 0.20 Classification-F1 0.5300053463992932 on epoch=32
05/25/2022 01:47:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=32
05/25/2022 01:47:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=32
05/25/2022 01:47:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.15 on epoch=32
05/25/2022 01:47:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.53 on epoch=32
05/25/2022 01:47:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=33
05/25/2022 01:48:04 - INFO - __main__ - Global step 1850 Train loss 0.20 Classification-F1 0.5233174154042883 on epoch=33
05/25/2022 01:48:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=33
05/25/2022 01:48:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=33
05/25/2022 01:48:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=33
05/25/2022 01:48:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=33
05/25/2022 01:48:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.48 on epoch=33
05/25/2022 01:48:44 - INFO - __main__ - Global step 1900 Train loss 0.18 Classification-F1 0.547639432598027 on epoch=33
05/25/2022 01:48:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=34
05/25/2022 01:48:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=34
05/25/2022 01:48:53 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.14 on epoch=34
05/25/2022 01:48:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.13 on epoch=34
05/25/2022 01:48:58 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.39 on epoch=34
05/25/2022 01:49:25 - INFO - __main__ - Global step 1950 Train loss 0.18 Classification-F1 0.5248286298345688 on epoch=34
05/25/2022 01:49:28 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=34
05/25/2022 01:49:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=35
05/25/2022 01:49:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=35
05/25/2022 01:49:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=35
05/25/2022 01:49:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.16 on epoch=35
05/25/2022 01:50:06 - INFO - __main__ - Global step 2000 Train loss 0.12 Classification-F1 0.5514982701042803 on epoch=35
05/25/2022 01:50:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.45 on epoch=35
05/25/2022 01:50:12 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.19 on epoch=36
05/25/2022 01:50:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.17 on epoch=36
05/25/2022 01:50:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
05/25/2022 01:50:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.16 on epoch=36
05/25/2022 01:50:47 - INFO - __main__ - Global step 2050 Train loss 0.21 Classification-F1 0.5325832908228081 on epoch=36
05/25/2022 01:50:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.11 on epoch=36
05/25/2022 01:50:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=36
05/25/2022 01:50:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=37
05/25/2022 01:50:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=37
05/25/2022 01:51:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/25/2022 01:51:28 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.5588633037135289 on epoch=37
05/25/2022 01:51:31 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.19 on epoch=37
05/25/2022 01:51:33 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.17 on epoch=37
05/25/2022 01:51:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=38
05/25/2022 01:51:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=38
05/25/2022 01:51:42 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.16 on epoch=38
05/25/2022 01:52:09 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.5540251320839726 on epoch=38
05/25/2022 01:52:11 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=38
05/25/2022 01:52:14 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.12 on epoch=38
05/25/2022 01:52:17 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.14 on epoch=38
05/25/2022 01:52:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=39
05/25/2022 01:52:22 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.13 on epoch=39
05/25/2022 01:52:49 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.5305154167605883 on epoch=39
05/25/2022 01:52:51 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=39
05/25/2022 01:52:54 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.15 on epoch=39
05/25/2022 01:52:57 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.41 on epoch=39
05/25/2022 01:52:59 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=39
05/25/2022 01:53:02 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=40
05/25/2022 01:53:27 - INFO - __main__ - Global step 2250 Train loss 0.17 Classification-F1 0.5561184314466555 on epoch=40
05/25/2022 01:53:30 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=40
05/25/2022 01:53:33 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=40
05/25/2022 01:53:35 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=40
05/25/2022 01:53:38 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.44 on epoch=40
05/25/2022 01:53:41 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=41
05/25/2022 01:54:06 - INFO - __main__ - Global step 2300 Train loss 0.17 Classification-F1 0.5843021199063707 on epoch=41
05/25/2022 01:54:09 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.12 on epoch=41
05/25/2022 01:54:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=41
05/25/2022 01:54:14 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.14 on epoch=41
05/25/2022 01:54:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.13 on epoch=41
05/25/2022 01:54:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.36 on epoch=41
05/25/2022 01:54:45 - INFO - __main__ - Global step 2350 Train loss 0.17 Classification-F1 0.5583888700688838 on epoch=41
05/25/2022 01:54:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.14 on epoch=42
05/25/2022 01:54:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=42
05/25/2022 01:54:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=42
05/25/2022 01:54:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.16 on epoch=42
05/25/2022 01:54:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.13 on epoch=42
05/25/2022 01:55:25 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.5608903667770675 on epoch=42
05/25/2022 01:55:27 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=43
05/25/2022 01:55:30 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=43
05/25/2022 01:55:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=43
05/25/2022 01:55:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=43
05/25/2022 01:55:38 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=43
05/25/2022 01:56:04 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.5208034245951695 on epoch=43
05/25/2022 01:56:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.43 on epoch=43
05/25/2022 01:56:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=44
05/25/2022 01:56:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.13 on epoch=44
05/25/2022 01:56:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=44
05/25/2022 01:56:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.15 on epoch=44
05/25/2022 01:56:42 - INFO - __main__ - Global step 2500 Train loss 0.18 Classification-F1 0.5272756964125517 on epoch=44
05/25/2022 01:56:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.47 on epoch=44
05/25/2022 01:56:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=44
05/25/2022 01:56:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=45
05/25/2022 01:56:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/25/2022 01:56:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=45
05/25/2022 01:57:20 - INFO - __main__ - Global step 2550 Train loss 0.16 Classification-F1 0.534278037221861 on epoch=45
05/25/2022 01:57:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=45
05/25/2022 01:57:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.11 on epoch=45
05/25/2022 01:57:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=46
05/25/2022 01:57:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=46
05/25/2022 01:57:33 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/25/2022 01:57:58 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.5045892421492052 on epoch=46
05/25/2022 01:58:01 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=46
05/25/2022 01:58:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.12 on epoch=46
05/25/2022 01:58:06 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.33 on epoch=46
05/25/2022 01:58:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=47
05/25/2022 01:58:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
05/25/2022 01:58:37 - INFO - __main__ - Global step 2650 Train loss 0.14 Classification-F1 0.5016074820155224 on epoch=47
05/25/2022 01:58:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.13 on epoch=47
05/25/2022 01:58:42 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=47
05/25/2022 01:58:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.12 on epoch=47
05/25/2022 01:58:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=48
05/25/2022 01:58:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/25/2022 01:59:15 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.4628670219227588 on epoch=48
05/25/2022 01:59:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
05/25/2022 01:59:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=48
05/25/2022 01:59:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.13 on epoch=48
05/25/2022 01:59:26 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=48
05/25/2022 01:59:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=49
05/25/2022 01:59:53 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.4453948862691541 on epoch=49
05/25/2022 01:59:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=49
05/25/2022 01:59:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=49
05/25/2022 02:00:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=49
05/25/2022 02:00:04 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=49
05/25/2022 02:00:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=49
05/25/2022 02:00:32 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.5056475134245041 on epoch=49
05/25/2022 02:00:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=50
05/25/2022 02:00:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/25/2022 02:00:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=50
05/25/2022 02:00:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=50
05/25/2022 02:00:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.45 on epoch=50
05/25/2022 02:01:10 - INFO - __main__ - Global step 2850 Train loss 0.15 Classification-F1 0.46180044118934427 on epoch=50
05/25/2022 02:01:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=51
05/25/2022 02:01:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/25/2022 02:01:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=51
05/25/2022 02:01:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=51
05/25/2022 02:01:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=51
05/25/2022 02:01:48 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.45874739108166784 on epoch=51
05/25/2022 02:01:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.33 on epoch=51
05/25/2022 02:01:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=52
05/25/2022 02:01:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=52
05/25/2022 02:01:59 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=52
05/25/2022 02:02:02 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=52
05/25/2022 02:02:26 - INFO - __main__ - Global step 2950 Train loss 0.12 Classification-F1 0.47962606749388115 on epoch=52
05/25/2022 02:02:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.42 on epoch=52
05/25/2022 02:02:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=53
05/25/2022 02:02:34 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=53
05/25/2022 02:02:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=53
05/25/2022 02:02:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.15 on epoch=53
05/25/2022 02:02:41 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:02:41 - INFO - __main__ - Printing 3 examples
05/25/2022 02:02:41 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 02:02:41 - INFO - __main__ - ['Animal']
05/25/2022 02:02:41 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 02:02:41 - INFO - __main__ - ['Animal']
05/25/2022 02:02:41 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 02:02:41 - INFO - __main__ - ['Animal']
05/25/2022 02:02:41 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:02:41 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:02:42 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 02:02:42 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:02:42 - INFO - __main__ - Printing 3 examples
05/25/2022 02:02:42 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 02:02:42 - INFO - __main__ - ['Animal']
05/25/2022 02:02:42 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 02:02:42 - INFO - __main__ - ['Animal']
05/25/2022 02:02:42 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 02:02:42 - INFO - __main__ - ['Animal']
05/25/2022 02:02:42 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:02:42 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:02:43 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 02:03:02 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 02:03:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 02:03:03 - INFO - __main__ - Starting training!
05/25/2022 02:03:04 - INFO - __main__ - Global step 3000 Train loss 0.16 Classification-F1 0.4744024844594189 on epoch=53
05/25/2022 02:03:04 - INFO - __main__ - save last model!
05/25/2022 02:03:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 02:03:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 02:03:04 - INFO - __main__ - Printing 3 examples
05/25/2022 02:03:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 02:03:04 - INFO - __main__ - ['Animal']
05/25/2022 02:03:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 02:03:04 - INFO - __main__ - ['Animal']
05/25/2022 02:03:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 02:03:04 - INFO - __main__ - ['Village']
05/25/2022 02:03:04 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:03:06 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:03:09 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 02:04:58 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_100_0.2_8_predictions.txt
05/25/2022 02:04:58 - INFO - __main__ - Classification-F1 on test data: 0.3876
05/25/2022 02:04:59 - INFO - __main__ - prefix=dbpedia_14_64_100, lr=0.2, bsz=8, dev_performance=0.5851619882112412, test_performance=0.3875788211503911
05/25/2022 02:04:59 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.5, bsz=8 ...
05/25/2022 02:05:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:05:00 - INFO - __main__ - Printing 3 examples
05/25/2022 02:05:00 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 02:05:00 - INFO - __main__ - ['Animal']
05/25/2022 02:05:00 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 02:05:00 - INFO - __main__ - ['Animal']
05/25/2022 02:05:00 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 02:05:00 - INFO - __main__ - ['Animal']
05/25/2022 02:05:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:05:00 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:05:01 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 02:05:01 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:05:01 - INFO - __main__ - Printing 3 examples
05/25/2022 02:05:01 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 02:05:01 - INFO - __main__ - ['Animal']
05/25/2022 02:05:01 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 02:05:01 - INFO - __main__ - ['Animal']
05/25/2022 02:05:01 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 02:05:01 - INFO - __main__ - ['Animal']
05/25/2022 02:05:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:05:02 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:05:03 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 02:05:18 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 02:05:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 02:05:19 - INFO - __main__ - Starting training!
05/25/2022 02:05:22 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=0
05/25/2022 02:05:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.40 on epoch=0
05/25/2022 02:05:27 - INFO - __main__ - Step 30 Global step 30 Train loss 4.20 on epoch=0
05/25/2022 02:05:30 - INFO - __main__ - Step 40 Global step 40 Train loss 3.08 on epoch=0
05/25/2022 02:05:33 - INFO - __main__ - Step 50 Global step 50 Train loss 3.01 on epoch=0
05/25/2022 02:05:58 - INFO - __main__ - Global step 50 Train loss 4.49 Classification-F1 0.023169569537077227 on epoch=0
05/25/2022 02:05:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.023169569537077227 on epoch=0, global_step=50
05/25/2022 02:06:00 - INFO - __main__ - Step 60 Global step 60 Train loss 2.32 on epoch=1
05/25/2022 02:06:03 - INFO - __main__ - Step 70 Global step 70 Train loss 2.20 on epoch=1
05/25/2022 02:06:05 - INFO - __main__ - Step 80 Global step 80 Train loss 2.41 on epoch=1
05/25/2022 02:06:08 - INFO - __main__ - Step 90 Global step 90 Train loss 2.19 on epoch=1
05/25/2022 02:06:11 - INFO - __main__ - Step 100 Global step 100 Train loss 1.58 on epoch=1
05/25/2022 02:06:33 - INFO - __main__ - Global step 100 Train loss 2.14 Classification-F1 0.06490732894769985 on epoch=1
05/25/2022 02:06:33 - INFO - __main__ - Saving model with best Classification-F1: 0.023169569537077227 -> 0.06490732894769985 on epoch=1, global_step=100
05/25/2022 02:06:35 - INFO - __main__ - Step 110 Global step 110 Train loss 1.66 on epoch=1
05/25/2022 02:06:38 - INFO - __main__ - Step 120 Global step 120 Train loss 1.35 on epoch=2
05/25/2022 02:06:41 - INFO - __main__ - Step 130 Global step 130 Train loss 1.59 on epoch=2
05/25/2022 02:06:43 - INFO - __main__ - Step 140 Global step 140 Train loss 1.34 on epoch=2
05/25/2022 02:06:46 - INFO - __main__ - Step 150 Global step 150 Train loss 1.11 on epoch=2
05/25/2022 02:07:08 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.14250236637653796 on epoch=2
05/25/2022 02:07:08 - INFO - __main__ - Saving model with best Classification-F1: 0.06490732894769985 -> 0.14250236637653796 on epoch=2, global_step=150
05/25/2022 02:07:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.00 on epoch=2
05/25/2022 02:07:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=3
05/25/2022 02:07:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=3
05/25/2022 02:07:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.89 on epoch=3
05/25/2022 02:07:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=3
05/25/2022 02:07:45 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.22566508111731498 on epoch=3
05/25/2022 02:07:45 - INFO - __main__ - Saving model with best Classification-F1: 0.14250236637653796 -> 0.22566508111731498 on epoch=3, global_step=200
05/25/2022 02:07:48 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=3
05/25/2022 02:07:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=3
05/25/2022 02:07:53 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=4
05/25/2022 02:07:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=4
05/25/2022 02:07:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=4
05/25/2022 02:08:26 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.3280597558159083 on epoch=4
05/25/2022 02:08:26 - INFO - __main__ - Saving model with best Classification-F1: 0.22566508111731498 -> 0.3280597558159083 on epoch=4, global_step=250
05/25/2022 02:08:28 - INFO - __main__ - Step 260 Global step 260 Train loss 0.50 on epoch=4
05/25/2022 02:08:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=4
05/25/2022 02:08:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.38 on epoch=4
05/25/2022 02:08:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=5
05/25/2022 02:08:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=5
05/25/2022 02:09:04 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.3132400265448938 on epoch=5
05/25/2022 02:09:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=5
05/25/2022 02:09:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.30 on epoch=5
05/25/2022 02:09:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=5
05/25/2022 02:09:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=6
05/25/2022 02:09:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=6
05/25/2022 02:09:43 - INFO - __main__ - Global step 350 Train loss 0.37 Classification-F1 0.3947159136772503 on epoch=6
05/25/2022 02:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.3280597558159083 -> 0.3947159136772503 on epoch=6, global_step=350
05/25/2022 02:09:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=6
05/25/2022 02:09:49 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=6
05/25/2022 02:09:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=6
05/25/2022 02:09:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=6
05/25/2022 02:09:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.28 on epoch=7
05/25/2022 02:10:22 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.41563233225189616 on epoch=7
05/25/2022 02:10:22 - INFO - __main__ - Saving model with best Classification-F1: 0.3947159136772503 -> 0.41563233225189616 on epoch=7, global_step=400
05/25/2022 02:10:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=7
05/25/2022 02:10:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=7
05/25/2022 02:10:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.23 on epoch=7
05/25/2022 02:10:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=7
05/25/2022 02:10:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=8
05/25/2022 02:11:00 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.4542734370197383 on epoch=8
05/25/2022 02:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.41563233225189616 -> 0.4542734370197383 on epoch=8, global_step=450
05/25/2022 02:11:03 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=8
05/25/2022 02:11:05 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=8
05/25/2022 02:11:08 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=8
05/25/2022 02:11:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=8
05/25/2022 02:11:13 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=8
05/25/2022 02:11:39 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.49336049065008986 on epoch=8
05/25/2022 02:11:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4542734370197383 -> 0.49336049065008986 on epoch=8, global_step=500
05/25/2022 02:11:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.15 on epoch=9
05/25/2022 02:11:45 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=9
05/25/2022 02:11:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=9
05/25/2022 02:11:50 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=9
05/25/2022 02:11:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.16 on epoch=9
05/25/2022 02:12:18 - INFO - __main__ - Global step 550 Train loss 0.21 Classification-F1 0.4519658700095246 on epoch=9
05/25/2022 02:12:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=9
05/25/2022 02:12:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=10
05/25/2022 02:12:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=10
05/25/2022 02:12:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=10
05/25/2022 02:12:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
05/25/2022 02:12:57 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.45496411573779005 on epoch=10
05/25/2022 02:12:59 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=10
05/25/2022 02:13:02 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=11
05/25/2022 02:13:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=11
05/25/2022 02:13:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=11
05/25/2022 02:13:09 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=11
05/25/2022 02:13:35 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.5142749332493808 on epoch=11
05/25/2022 02:13:35 - INFO - __main__ - Saving model with best Classification-F1: 0.49336049065008986 -> 0.5142749332493808 on epoch=11, global_step=650
05/25/2022 02:13:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=11
05/25/2022 02:13:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=11
05/25/2022 02:13:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=12
05/25/2022 02:13:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=12
05/25/2022 02:13:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=12
05/25/2022 02:14:13 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.47573048641567 on epoch=12
05/25/2022 02:14:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=12
05/25/2022 02:14:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=12
05/25/2022 02:14:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=13
05/25/2022 02:14:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=13
05/25/2022 02:14:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=13
05/25/2022 02:14:51 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.49305661659126726 on epoch=13
05/25/2022 02:14:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=13
05/25/2022 02:14:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=13
05/25/2022 02:14:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=13
05/25/2022 02:15:01 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=14
05/25/2022 02:15:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=14
05/25/2022 02:15:30 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.4768364848597307 on epoch=14
05/25/2022 02:15:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=14
05/25/2022 02:15:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
05/25/2022 02:15:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=14
05/25/2022 02:15:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=14
05/25/2022 02:15:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=15
05/25/2022 02:16:09 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.5200656684645432 on epoch=15
05/25/2022 02:16:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5142749332493808 -> 0.5200656684645432 on epoch=15, global_step=850
05/25/2022 02:16:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=15
05/25/2022 02:16:14 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=15
05/25/2022 02:16:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.05 on epoch=15
05/25/2022 02:16:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=15
05/25/2022 02:16:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=16
05/25/2022 02:16:48 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.5220469933257125 on epoch=16
05/25/2022 02:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5200656684645432 -> 0.5220469933257125 on epoch=16, global_step=900
05/25/2022 02:16:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=16
05/25/2022 02:16:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=16
05/25/2022 02:16:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
05/25/2022 02:16:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/25/2022 02:17:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
05/25/2022 02:17:27 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.5381521609943967 on epoch=16
05/25/2022 02:17:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5220469933257125 -> 0.5381521609943967 on epoch=16, global_step=950
05/25/2022 02:17:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
05/25/2022 02:17:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
05/25/2022 02:17:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=17
05/25/2022 02:17:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=17
05/25/2022 02:17:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=17
05/25/2022 02:18:06 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.5657303984079862 on epoch=17
05/25/2022 02:18:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5381521609943967 -> 0.5657303984079862 on epoch=17, global_step=1000
05/25/2022 02:18:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=18
05/25/2022 02:18:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=18
05/25/2022 02:18:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=18
05/25/2022 02:18:17 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=18
05/25/2022 02:18:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
05/25/2022 02:18:45 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.56876926443752 on epoch=18
05/25/2022 02:18:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5657303984079862 -> 0.56876926443752 on epoch=18, global_step=1050
05/25/2022 02:18:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/25/2022 02:18:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
05/25/2022 02:18:53 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
05/25/2022 02:18:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=19
05/25/2022 02:18:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=19
05/25/2022 02:19:24 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.5248548743955066 on epoch=19
05/25/2022 02:19:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=19
05/25/2022 02:19:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
05/25/2022 02:19:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=20
05/25/2022 02:19:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=20
05/25/2022 02:19:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=20
05/25/2022 02:20:03 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.5479540884923623 on epoch=20
05/25/2022 02:20:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=20
05/25/2022 02:20:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=20
05/25/2022 02:20:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=21
05/25/2022 02:20:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=21
05/25/2022 02:20:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/25/2022 02:20:43 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.4725672011447199 on epoch=21
05/25/2022 02:20:45 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=21
05/25/2022 02:20:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=21
05/25/2022 02:20:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=21
05/25/2022 02:20:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=22
05/25/2022 02:20:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=22
05/25/2022 02:21:22 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.5421635809114492 on epoch=22
05/25/2022 02:21:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
05/25/2022 02:21:28 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/25/2022 02:21:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
05/25/2022 02:21:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
05/25/2022 02:21:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=23
05/25/2022 02:22:02 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5266303898286835 on epoch=23
05/25/2022 02:22:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=23
05/25/2022 02:22:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=23
05/25/2022 02:22:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=23
05/25/2022 02:22:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=23
05/25/2022 02:22:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=24
05/25/2022 02:22:41 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6181752028456698 on epoch=24
05/25/2022 02:22:41 - INFO - __main__ - Saving model with best Classification-F1: 0.56876926443752 -> 0.6181752028456698 on epoch=24, global_step=1350
05/25/2022 02:22:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/25/2022 02:22:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/25/2022 02:22:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/25/2022 02:22:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=24
05/25/2022 02:22:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=24
05/25/2022 02:23:20 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6478899278399892 on epoch=24
05/25/2022 02:23:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6181752028456698 -> 0.6478899278399892 on epoch=24, global_step=1400
05/25/2022 02:23:23 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=25
05/25/2022 02:23:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=25
05/25/2022 02:23:28 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
05/25/2022 02:23:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=25
05/25/2022 02:23:33 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=25
05/25/2022 02:24:00 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6058199433980619 on epoch=25
05/25/2022 02:24:02 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/25/2022 02:24:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=26
05/25/2022 02:24:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=26
05/25/2022 02:24:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
05/25/2022 02:24:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=26
05/25/2022 02:24:38 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5446912796205686 on epoch=26
05/25/2022 02:24:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=26
05/25/2022 02:24:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
05/25/2022 02:24:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=27
05/25/2022 02:24:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
05/25/2022 02:24:52 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/25/2022 02:25:17 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.47576137061268753 on epoch=27
05/25/2022 02:25:20 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
05/25/2022 02:25:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
05/25/2022 02:25:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=28
05/25/2022 02:25:28 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
05/25/2022 02:25:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=28
05/25/2022 02:25:55 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6006943595573486 on epoch=28
05/25/2022 02:25:58 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=28
05/25/2022 02:26:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/25/2022 02:26:03 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
05/25/2022 02:26:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=29
05/25/2022 02:26:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
05/25/2022 02:26:34 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.606128443590572 on epoch=29
05/25/2022 02:26:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/25/2022 02:26:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
05/25/2022 02:26:42 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/25/2022 02:26:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
05/25/2022 02:26:47 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/25/2022 02:27:14 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.56369264196335 on epoch=30
05/25/2022 02:27:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
05/25/2022 02:27:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=30
05/25/2022 02:27:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/25/2022 02:27:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/25/2022 02:27:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=31
05/25/2022 02:27:52 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.5652348448980319 on epoch=31
05/25/2022 02:27:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
05/25/2022 02:27:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
05/25/2022 02:28:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/25/2022 02:28:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=31
05/25/2022 02:28:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
05/25/2022 02:28:31 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6657927405147234 on epoch=32
05/25/2022 02:28:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6478899278399892 -> 0.6657927405147234 on epoch=32, global_step=1800
05/25/2022 02:28:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=32
05/25/2022 02:28:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/25/2022 02:28:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
05/25/2022 02:28:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=32
05/25/2022 02:28:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/25/2022 02:29:10 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.596283170985383 on epoch=33
05/25/2022 02:29:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/25/2022 02:29:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=33
05/25/2022 02:29:18 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
05/25/2022 02:29:21 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/25/2022 02:29:23 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/25/2022 02:29:51 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6082611565518002 on epoch=33
05/25/2022 02:29:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/25/2022 02:29:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.11 on epoch=34
05/25/2022 02:29:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
05/25/2022 02:30:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/25/2022 02:30:04 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=34
05/25/2022 02:30:31 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5181659106739068 on epoch=34
05/25/2022 02:30:34 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=34
05/25/2022 02:30:37 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=35
05/25/2022 02:30:39 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
05/25/2022 02:30:42 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
05/25/2022 02:30:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
05/25/2022 02:31:12 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6191090935054226 on epoch=35
05/25/2022 02:31:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=35
05/25/2022 02:31:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=36
05/25/2022 02:31:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=36
05/25/2022 02:31:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=36
05/25/2022 02:31:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=36
05/25/2022 02:31:53 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5792836380641075 on epoch=36
05/25/2022 02:31:56 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
05/25/2022 02:31:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/25/2022 02:32:01 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
05/25/2022 02:32:04 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=37
05/25/2022 02:32:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
05/25/2022 02:32:33 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.5966300178661452 on epoch=37
05/25/2022 02:32:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/25/2022 02:32:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=37
05/25/2022 02:32:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/25/2022 02:32:44 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=38
05/25/2022 02:32:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
05/25/2022 02:33:13 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6010769492943898 on epoch=38
05/25/2022 02:33:16 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 02:33:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=38
05/25/2022 02:33:21 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=38
05/25/2022 02:33:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=39
05/25/2022 02:33:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=39
05/25/2022 02:33:53 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.5858108518189288 on epoch=39
05/25/2022 02:33:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/25/2022 02:33:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
05/25/2022 02:34:00 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/25/2022 02:34:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
05/25/2022 02:34:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=40
05/25/2022 02:34:32 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6798065304486862 on epoch=40
05/25/2022 02:34:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6657927405147234 -> 0.6798065304486862 on epoch=40, global_step=2250
05/25/2022 02:34:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/25/2022 02:34:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/25/2022 02:34:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/25/2022 02:34:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
05/25/2022 02:34:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/25/2022 02:35:12 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7512603170034167 on epoch=41
05/25/2022 02:35:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6798065304486862 -> 0.7512603170034167 on epoch=41, global_step=2300
05/25/2022 02:35:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=41
05/25/2022 02:35:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=41
05/25/2022 02:35:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/25/2022 02:35:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
05/25/2022 02:35:25 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/25/2022 02:35:52 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6682630962636987 on epoch=41
05/25/2022 02:35:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=42
05/25/2022 02:35:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.12 on epoch=42
05/25/2022 02:36:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/25/2022 02:36:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 02:36:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/25/2022 02:36:32 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5852011391759784 on epoch=42
05/25/2022 02:36:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/25/2022 02:36:37 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/25/2022 02:36:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=43
05/25/2022 02:36:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/25/2022 02:36:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/25/2022 02:37:12 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6200109886866378 on epoch=43
05/25/2022 02:37:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=43
05/25/2022 02:37:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=44
05/25/2022 02:37:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=44
05/25/2022 02:37:22 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 02:37:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/25/2022 02:37:51 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.46344826659132404 on epoch=44
05/25/2022 02:37:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
05/25/2022 02:37:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/25/2022 02:37:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/25/2022 02:38:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=45
05/25/2022 02:38:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=45
05/25/2022 02:38:31 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.5145418195778247 on epoch=45
05/25/2022 02:38:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/25/2022 02:38:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/25/2022 02:38:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 02:38:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=46
05/25/2022 02:38:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/25/2022 02:39:10 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.4672559920347188 on epoch=46
05/25/2022 02:39:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/25/2022 02:39:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
05/25/2022 02:39:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/25/2022 02:39:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
05/25/2022 02:39:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/25/2022 02:39:50 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.4854348986259307 on epoch=47
05/25/2022 02:39:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/25/2022 02:39:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
05/25/2022 02:39:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=47
05/25/2022 02:40:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/25/2022 02:40:03 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=48
05/25/2022 02:40:30 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.581081182606219 on epoch=48
05/25/2022 02:40:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
05/25/2022 02:40:35 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/25/2022 02:40:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/25/2022 02:40:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/25/2022 02:40:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/25/2022 02:41:09 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6344866440269431 on epoch=49
05/25/2022 02:41:12 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=49
05/25/2022 02:41:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/25/2022 02:41:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/25/2022 02:41:20 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=49
05/25/2022 02:41:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/25/2022 02:41:49 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.5978899541800723 on epoch=49
05/25/2022 02:41:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.07 on epoch=50
05/25/2022 02:41:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/25/2022 02:41:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 02:42:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=50
05/25/2022 02:42:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/25/2022 02:42:28 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.547959919026744 on epoch=50
05/25/2022 02:42:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/25/2022 02:42:33 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
05/25/2022 02:42:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/25/2022 02:42:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 02:42:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
05/25/2022 02:43:08 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.509562230585236 on epoch=51
05/25/2022 02:43:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/25/2022 02:43:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
05/25/2022 02:43:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=52
05/25/2022 02:43:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/25/2022 02:43:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/25/2022 02:43:48 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.5788488303314017 on epoch=52
05/25/2022 02:43:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/25/2022 02:43:53 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 02:43:56 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/25/2022 02:43:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/25/2022 02:44:01 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/25/2022 02:44:02 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:44:02 - INFO - __main__ - Printing 3 examples
05/25/2022 02:44:02 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 02:44:02 - INFO - __main__ - ['Animal']
05/25/2022 02:44:02 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 02:44:02 - INFO - __main__ - ['Animal']
05/25/2022 02:44:02 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 02:44:02 - INFO - __main__ - ['Animal']
05/25/2022 02:44:02 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:44:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:44:04 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 02:44:04 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:44:04 - INFO - __main__ - Printing 3 examples
05/25/2022 02:44:04 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 02:44:04 - INFO - __main__ - ['Animal']
05/25/2022 02:44:04 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 02:44:04 - INFO - __main__ - ['Animal']
05/25/2022 02:44:04 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 02:44:04 - INFO - __main__ - ['Animal']
05/25/2022 02:44:04 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:44:04 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:44:05 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 02:44:23 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 02:44:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 02:44:24 - INFO - __main__ - Starting training!
05/25/2022 02:44:27 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.5419420641273152 on epoch=53
05/25/2022 02:44:27 - INFO - __main__ - save last model!
05/25/2022 02:44:27 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 02:44:27 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 02:44:27 - INFO - __main__ - Printing 3 examples
05/25/2022 02:44:27 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 02:44:27 - INFO - __main__ - ['Animal']
05/25/2022 02:44:27 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 02:44:27 - INFO - __main__ - ['Animal']
05/25/2022 02:44:27 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 02:44:27 - INFO - __main__ - ['Village']
05/25/2022 02:44:27 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:44:29 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:44:32 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 02:46:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.5_8_predictions.txt
05/25/2022 02:46:35 - INFO - __main__ - Classification-F1 on test data: 0.4376
05/25/2022 02:46:36 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.5, bsz=8, dev_performance=0.7512603170034167, test_performance=0.43758866621337117
05/25/2022 02:46:36 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.4, bsz=8 ...
05/25/2022 02:46:37 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:46:37 - INFO - __main__ - Printing 3 examples
05/25/2022 02:46:37 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 02:46:37 - INFO - __main__ - ['Animal']
05/25/2022 02:46:37 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 02:46:37 - INFO - __main__ - ['Animal']
05/25/2022 02:46:37 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 02:46:37 - INFO - __main__ - ['Animal']
05/25/2022 02:46:37 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:46:37 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:46:38 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 02:46:38 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 02:46:38 - INFO - __main__ - Printing 3 examples
05/25/2022 02:46:38 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 02:46:38 - INFO - __main__ - ['Animal']
05/25/2022 02:46:38 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 02:46:38 - INFO - __main__ - ['Animal']
05/25/2022 02:46:38 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 02:46:38 - INFO - __main__ - ['Animal']
05/25/2022 02:46:38 - INFO - __main__ - Tokenizing Input ...
05/25/2022 02:46:39 - INFO - __main__ - Tokenizing Output ...
05/25/2022 02:46:40 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 02:46:55 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 02:46:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 02:46:56 - INFO - __main__ - Starting training!
05/25/2022 02:46:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.03 on epoch=0
05/25/2022 02:47:02 - INFO - __main__ - Step 20 Global step 20 Train loss 5.59 on epoch=0
05/25/2022 02:47:05 - INFO - __main__ - Step 30 Global step 30 Train loss 4.71 on epoch=0
05/25/2022 02:47:07 - INFO - __main__ - Step 40 Global step 40 Train loss 3.45 on epoch=0
05/25/2022 02:47:10 - INFO - __main__ - Step 50 Global step 50 Train loss 3.36 on epoch=0
05/25/2022 02:47:36 - INFO - __main__ - Global step 50 Train loss 4.83 Classification-F1 0.01617021459038523 on epoch=0
05/25/2022 02:47:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01617021459038523 on epoch=0, global_step=50
05/25/2022 02:47:39 - INFO - __main__ - Step 60 Global step 60 Train loss 2.81 on epoch=1
05/25/2022 02:47:42 - INFO - __main__ - Step 70 Global step 70 Train loss 2.45 on epoch=1
05/25/2022 02:47:44 - INFO - __main__ - Step 80 Global step 80 Train loss 2.82 on epoch=1
05/25/2022 02:47:47 - INFO - __main__ - Step 90 Global step 90 Train loss 2.47 on epoch=1
05/25/2022 02:47:49 - INFO - __main__ - Step 100 Global step 100 Train loss 1.82 on epoch=1
05/25/2022 02:48:13 - INFO - __main__ - Global step 100 Train loss 2.47 Classification-F1 0.04332634464501045 on epoch=1
05/25/2022 02:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.01617021459038523 -> 0.04332634464501045 on epoch=1, global_step=100
05/25/2022 02:48:16 - INFO - __main__ - Step 110 Global step 110 Train loss 2.02 on epoch=1
05/25/2022 02:48:19 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=2
05/25/2022 02:48:21 - INFO - __main__ - Step 130 Global step 130 Train loss 1.89 on epoch=2
05/25/2022 02:48:24 - INFO - __main__ - Step 140 Global step 140 Train loss 1.65 on epoch=2
05/25/2022 02:48:26 - INFO - __main__ - Step 150 Global step 150 Train loss 1.47 on epoch=2
05/25/2022 02:48:49 - INFO - __main__ - Global step 150 Train loss 1.73 Classification-F1 0.11441093529195114 on epoch=2
05/25/2022 02:48:49 - INFO - __main__ - Saving model with best Classification-F1: 0.04332634464501045 -> 0.11441093529195114 on epoch=2, global_step=150
05/25/2022 02:48:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.24 on epoch=2
05/25/2022 02:48:54 - INFO - __main__ - Step 170 Global step 170 Train loss 1.29 on epoch=3
05/25/2022 02:48:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.20 on epoch=3
05/25/2022 02:48:59 - INFO - __main__ - Step 190 Global step 190 Train loss 1.16 on epoch=3
05/25/2022 02:49:02 - INFO - __main__ - Step 200 Global step 200 Train loss 1.16 on epoch=3
05/25/2022 02:49:24 - INFO - __main__ - Global step 200 Train loss 1.21 Classification-F1 0.16132992922500522 on epoch=3
05/25/2022 02:49:24 - INFO - __main__ - Saving model with best Classification-F1: 0.11441093529195114 -> 0.16132992922500522 on epoch=3, global_step=200
05/25/2022 02:49:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=3
05/25/2022 02:49:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.90 on epoch=3
05/25/2022 02:49:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=4
05/25/2022 02:49:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=4
05/25/2022 02:49:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=4
05/25/2022 02:50:02 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.2655314685851679 on epoch=4
05/25/2022 02:50:02 - INFO - __main__ - Saving model with best Classification-F1: 0.16132992922500522 -> 0.2655314685851679 on epoch=4, global_step=250
05/25/2022 02:50:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=4
05/25/2022 02:50:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=4
05/25/2022 02:50:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=4
05/25/2022 02:50:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=5
05/25/2022 02:50:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=5
05/25/2022 02:50:41 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.27992734417691023 on epoch=5
05/25/2022 02:50:41 - INFO - __main__ - Saving model with best Classification-F1: 0.2655314685851679 -> 0.27992734417691023 on epoch=5, global_step=300
05/25/2022 02:50:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=5
05/25/2022 02:50:46 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=5
05/25/2022 02:50:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=5
05/25/2022 02:50:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=6
05/25/2022 02:50:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=6
05/25/2022 02:51:20 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.3680041948543762 on epoch=6
05/25/2022 02:51:20 - INFO - __main__ - Saving model with best Classification-F1: 0.27992734417691023 -> 0.3680041948543762 on epoch=6, global_step=350
05/25/2022 02:51:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=6
05/25/2022 02:51:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=6
05/25/2022 02:51:28 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=6
05/25/2022 02:51:30 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=6
05/25/2022 02:51:33 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=7
05/25/2022 02:52:01 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.4569809984695581 on epoch=7
05/25/2022 02:52:01 - INFO - __main__ - Saving model with best Classification-F1: 0.3680041948543762 -> 0.4569809984695581 on epoch=7, global_step=400
05/25/2022 02:52:03 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
05/25/2022 02:52:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=7
05/25/2022 02:52:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=7
05/25/2022 02:52:11 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=7
05/25/2022 02:52:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=8
05/25/2022 02:52:40 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.40500767365327145 on epoch=8
05/25/2022 02:52:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.33 on epoch=8
05/25/2022 02:52:45 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=8
05/25/2022 02:52:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=8
05/25/2022 02:52:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=8
05/25/2022 02:52:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=8
05/25/2022 02:53:17 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.4253555722208531 on epoch=8
05/25/2022 02:53:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=9
05/25/2022 02:53:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.29 on epoch=9
05/25/2022 02:53:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
05/25/2022 02:53:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=9
05/25/2022 02:53:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=9
05/25/2022 02:53:56 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.4758424415249031 on epoch=9
05/25/2022 02:53:56 - INFO - __main__ - Saving model with best Classification-F1: 0.4569809984695581 -> 0.4758424415249031 on epoch=9, global_step=550
05/25/2022 02:53:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=9
05/25/2022 02:54:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=10
05/25/2022 02:54:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=10
05/25/2022 02:54:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.23 on epoch=10
05/25/2022 02:54:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=10
05/25/2022 02:54:34 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.4653666685945011 on epoch=10
05/25/2022 02:54:37 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=10
05/25/2022 02:54:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=11
05/25/2022 02:54:42 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=11
05/25/2022 02:54:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=11
05/25/2022 02:54:47 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=11
05/25/2022 02:55:13 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.49261969640537034 on epoch=11
05/25/2022 02:55:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4758424415249031 -> 0.49261969640537034 on epoch=11, global_step=650
05/25/2022 02:55:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=11
05/25/2022 02:55:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=11
05/25/2022 02:55:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=12
05/25/2022 02:55:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=12
05/25/2022 02:55:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=12
05/25/2022 02:55:52 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.4442047423759466 on epoch=12
05/25/2022 02:55:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.13 on epoch=12
05/25/2022 02:55:57 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=12
05/25/2022 02:56:00 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=13
05/25/2022 02:56:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=13
05/25/2022 02:56:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=13
05/25/2022 02:56:31 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.4800248683281087 on epoch=13
05/25/2022 02:56:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=13
05/25/2022 02:56:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=13
05/25/2022 02:56:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=13
05/25/2022 02:56:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=14
05/25/2022 02:56:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=14
05/25/2022 02:57:09 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.5090332594033108 on epoch=14
05/25/2022 02:57:09 - INFO - __main__ - Saving model with best Classification-F1: 0.49261969640537034 -> 0.5090332594033108 on epoch=14, global_step=800
05/25/2022 02:57:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=14
05/25/2022 02:57:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=14
05/25/2022 02:57:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=14
05/25/2022 02:57:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=14
05/25/2022 02:57:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=15
05/25/2022 02:57:47 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.5391907756688635 on epoch=15
05/25/2022 02:57:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5090332594033108 -> 0.5391907756688635 on epoch=15, global_step=850
05/25/2022 02:57:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=15
05/25/2022 02:57:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
05/25/2022 02:57:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=15
05/25/2022 02:57:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=15
05/25/2022 02:58:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=16
05/25/2022 02:58:26 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.5576729291461533 on epoch=16
05/25/2022 02:58:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5391907756688635 -> 0.5576729291461533 on epoch=16, global_step=900
05/25/2022 02:58:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.23 on epoch=16
05/25/2022 02:58:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=16
05/25/2022 02:58:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=16
05/25/2022 02:58:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/25/2022 02:58:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=16
05/25/2022 02:59:05 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.5651671581970887 on epoch=16
05/25/2022 02:59:05 - INFO - __main__ - Saving model with best Classification-F1: 0.5576729291461533 -> 0.5651671581970887 on epoch=16, global_step=950
05/25/2022 02:59:07 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=17
05/25/2022 02:59:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=17
05/25/2022 02:59:12 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=17
05/25/2022 02:59:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=17
05/25/2022 02:59:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/25/2022 02:59:43 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5835912695291439 on epoch=17
05/25/2022 02:59:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5651671581970887 -> 0.5835912695291439 on epoch=17, global_step=1000
05/25/2022 02:59:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=18
05/25/2022 02:59:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=18
05/25/2022 02:59:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
05/25/2022 02:59:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=18
05/25/2022 02:59:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=18
05/25/2022 03:00:22 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5051020359329328 on epoch=18
05/25/2022 03:00:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=18
05/25/2022 03:00:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=19
05/25/2022 03:00:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=19
05/25/2022 03:00:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=19
05/25/2022 03:00:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=19
05/25/2022 03:01:01 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.5665602353069514 on epoch=19
05/25/2022 03:01:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=19
05/25/2022 03:01:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=19
05/25/2022 03:01:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=20
05/25/2022 03:01:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=20
05/25/2022 03:01:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=20
05/25/2022 03:01:38 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.5356509348620228 on epoch=20
05/25/2022 03:01:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=20
05/25/2022 03:01:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=20
05/25/2022 03:01:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=21
05/25/2022 03:01:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=21
05/25/2022 03:01:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/25/2022 03:02:17 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.608372379070906 on epoch=21
05/25/2022 03:02:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5835912695291439 -> 0.608372379070906 on epoch=21, global_step=1200
05/25/2022 03:02:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=21
05/25/2022 03:02:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/25/2022 03:02:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=21
05/25/2022 03:02:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
05/25/2022 03:02:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=22
05/25/2022 03:02:55 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.5062635352985912 on epoch=22
05/25/2022 03:02:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
05/25/2022 03:03:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=22
05/25/2022 03:03:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
05/25/2022 03:03:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=23
05/25/2022 03:03:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=23
05/25/2022 03:03:33 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.5562776053692643 on epoch=23
05/25/2022 03:03:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=23
05/25/2022 03:03:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=23
05/25/2022 03:03:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=23
05/25/2022 03:03:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=23
05/25/2022 03:03:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
05/25/2022 03:04:11 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.5667572476240742 on epoch=24
05/25/2022 03:04:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.24 on epoch=24
05/25/2022 03:04:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
05/25/2022 03:04:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/25/2022 03:04:21 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=24
05/25/2022 03:04:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=24
05/25/2022 03:04:49 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6279303772478715 on epoch=24
05/25/2022 03:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.608372379070906 -> 0.6279303772478715 on epoch=24, global_step=1400
05/25/2022 03:04:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=25
05/25/2022 03:04:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=25
05/25/2022 03:04:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
05/25/2022 03:04:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=25
05/25/2022 03:05:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=25
05/25/2022 03:05:27 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.5596870935048331 on epoch=25
05/25/2022 03:05:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=26
05/25/2022 03:05:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=26
05/25/2022 03:05:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 03:05:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=26
05/25/2022 03:05:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/25/2022 03:06:05 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6087058335453697 on epoch=26
05/25/2022 03:06:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
05/25/2022 03:06:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=27
05/25/2022 03:06:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=27
05/25/2022 03:06:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/25/2022 03:06:18 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
05/25/2022 03:06:43 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.6480803846966632 on epoch=27
05/25/2022 03:06:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6279303772478715 -> 0.6480803846966632 on epoch=27, global_step=1550
05/25/2022 03:06:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=27
05/25/2022 03:06:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
05/25/2022 03:06:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=28
05/25/2022 03:06:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=28
05/25/2022 03:06:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
05/25/2022 03:07:21 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.648654642673711 on epoch=28
05/25/2022 03:07:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6480803846966632 -> 0.648654642673711 on epoch=28, global_step=1600
05/25/2022 03:07:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
05/25/2022 03:07:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
05/25/2022 03:07:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=29
05/25/2022 03:07:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=29
05/25/2022 03:07:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
05/25/2022 03:07:59 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.5990952803569666 on epoch=29
05/25/2022 03:08:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
05/25/2022 03:08:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=29
05/25/2022 03:08:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
05/25/2022 03:08:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=30
05/25/2022 03:08:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=30
05/25/2022 03:08:36 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.5432491881825876 on epoch=30
05/25/2022 03:08:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=30
05/25/2022 03:08:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/25/2022 03:08:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/25/2022 03:08:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=31
05/25/2022 03:08:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=31
05/25/2022 03:09:13 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5535394519678195 on epoch=31
05/25/2022 03:09:16 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
05/25/2022 03:09:19 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
05/25/2022 03:09:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=31
05/25/2022 03:09:24 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=31
05/25/2022 03:09:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/25/2022 03:09:51 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6642060886353834 on epoch=32
05/25/2022 03:09:52 - INFO - __main__ - Saving model with best Classification-F1: 0.648654642673711 -> 0.6642060886353834 on epoch=32, global_step=1800
05/25/2022 03:09:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
05/25/2022 03:09:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/25/2022 03:09:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=32
05/25/2022 03:10:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=32
05/25/2022 03:10:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/25/2022 03:10:30 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6387973451541429 on epoch=33
05/25/2022 03:10:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=33
05/25/2022 03:10:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=33
05/25/2022 03:10:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 03:10:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
05/25/2022 03:10:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/25/2022 03:11:08 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.5805264059045893 on epoch=33
05/25/2022 03:11:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/25/2022 03:11:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=34
05/25/2022 03:11:16 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=34
05/25/2022 03:11:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/25/2022 03:11:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=34
05/25/2022 03:11:46 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.5964557063494237 on epoch=34
05/25/2022 03:11:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/25/2022 03:11:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=35
05/25/2022 03:11:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=35
05/25/2022 03:11:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=35
05/25/2022 03:11:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=35
05/25/2022 03:12:24 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.6402607242018785 on epoch=35
05/25/2022 03:12:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=35
05/25/2022 03:12:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=36
05/25/2022 03:12:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=36
05/25/2022 03:12:34 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/25/2022 03:12:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/25/2022 03:13:01 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5533959026067891 on epoch=36
05/25/2022 03:13:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=36
05/25/2022 03:13:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=36
05/25/2022 03:13:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/25/2022 03:13:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=37
05/25/2022 03:13:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/25/2022 03:13:40 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.62100733582493 on epoch=37
05/25/2022 03:13:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/25/2022 03:13:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
05/25/2022 03:13:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=38
05/25/2022 03:13:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
05/25/2022 03:13:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=38
05/25/2022 03:14:18 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.5830236955620812 on epoch=38
05/25/2022 03:14:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 03:14:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/25/2022 03:14:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=38
05/25/2022 03:14:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=39
05/25/2022 03:14:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/25/2022 03:14:55 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.549866275491552 on epoch=39
05/25/2022 03:14:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=39
05/25/2022 03:15:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
05/25/2022 03:15:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=39
05/25/2022 03:15:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/25/2022 03:15:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=40
05/25/2022 03:15:33 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.4914021992935598 on epoch=40
05/25/2022 03:15:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
05/25/2022 03:15:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/25/2022 03:15:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/25/2022 03:15:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/25/2022 03:15:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=41
05/25/2022 03:16:10 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.5480776587248309 on epoch=41
05/25/2022 03:16:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.16 on epoch=41
05/25/2022 03:16:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/25/2022 03:16:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/25/2022 03:16:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/25/2022 03:16:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=41
05/25/2022 03:16:48 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.615528239714106 on epoch=41
05/25/2022 03:16:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/25/2022 03:16:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=42
05/25/2022 03:16:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/25/2022 03:16:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=42
05/25/2022 03:17:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
05/25/2022 03:17:25 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6493146934700066 on epoch=42
05/25/2022 03:17:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
05/25/2022 03:17:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/25/2022 03:17:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=43
05/25/2022 03:17:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/25/2022 03:17:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
05/25/2022 03:18:03 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.63320967068398 on epoch=43
05/25/2022 03:18:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 03:18:08 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/25/2022 03:18:11 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.12 on epoch=44
05/25/2022 03:18:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 03:18:16 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/25/2022 03:18:41 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7493279801848776 on epoch=44
05/25/2022 03:18:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6642060886353834 -> 0.7493279801848776 on epoch=44, global_step=2500
05/25/2022 03:18:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/25/2022 03:18:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/25/2022 03:18:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=45
05/25/2022 03:18:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/25/2022 03:18:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/25/2022 03:19:18 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7116144415292261 on epoch=45
05/25/2022 03:19:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/25/2022 03:19:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/25/2022 03:19:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/25/2022 03:19:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=46
05/25/2022 03:19:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
05/25/2022 03:19:56 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6994169034560536 on epoch=46
05/25/2022 03:19:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/25/2022 03:20:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
05/25/2022 03:20:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/25/2022 03:20:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
05/25/2022 03:20:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
05/25/2022 03:20:34 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6326095223881774 on epoch=47
05/25/2022 03:20:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
05/25/2022 03:20:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/25/2022 03:20:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/25/2022 03:20:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=48
05/25/2022 03:20:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.10 on epoch=48
05/25/2022 03:21:11 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6163621518389489 on epoch=48
05/25/2022 03:21:14 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=48
05/25/2022 03:21:17 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=48
05/25/2022 03:21:19 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=48
05/25/2022 03:21:22 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/25/2022 03:21:25 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=49
05/25/2022 03:21:49 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6410249937741701 on epoch=49
05/25/2022 03:21:51 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=49
05/25/2022 03:21:54 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/25/2022 03:21:57 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/25/2022 03:22:00 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=49
05/25/2022 03:22:02 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/25/2022 03:22:26 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6369042582573666 on epoch=49
05/25/2022 03:22:29 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=50
05/25/2022 03:22:31 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/25/2022 03:22:34 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=50
05/25/2022 03:22:37 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/25/2022 03:22:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 03:23:04 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5753280058453671 on epoch=50
05/25/2022 03:23:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/25/2022 03:23:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=51
05/25/2022 03:23:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/25/2022 03:23:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 03:23:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/25/2022 03:23:41 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6083251835705263 on epoch=51
05/25/2022 03:23:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/25/2022 03:23:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=52
05/25/2022 03:23:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.08 on epoch=52
05/25/2022 03:23:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/25/2022 03:23:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/25/2022 03:24:19 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.5722051345876631 on epoch=52
05/25/2022 03:24:21 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=52
05/25/2022 03:24:24 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 03:24:26 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.11 on epoch=53
05/25/2022 03:24:29 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=53
05/25/2022 03:24:32 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/25/2022 03:24:33 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 03:24:33 - INFO - __main__ - Printing 3 examples
05/25/2022 03:24:33 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 03:24:33 - INFO - __main__ - ['Animal']
05/25/2022 03:24:33 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 03:24:33 - INFO - __main__ - ['Animal']
05/25/2022 03:24:33 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 03:24:33 - INFO - __main__ - ['Animal']
05/25/2022 03:24:33 - INFO - __main__ - Tokenizing Input ...
05/25/2022 03:24:34 - INFO - __main__ - Tokenizing Output ...
05/25/2022 03:24:35 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 03:24:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 03:24:35 - INFO - __main__ - Printing 3 examples
05/25/2022 03:24:35 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 03:24:35 - INFO - __main__ - ['Animal']
05/25/2022 03:24:35 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 03:24:35 - INFO - __main__ - ['Animal']
05/25/2022 03:24:35 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 03:24:35 - INFO - __main__ - ['Animal']
05/25/2022 03:24:35 - INFO - __main__ - Tokenizing Input ...
05/25/2022 03:24:35 - INFO - __main__ - Tokenizing Output ...
05/25/2022 03:24:36 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 03:24:54 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 03:24:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 03:24:55 - INFO - __main__ - Starting training!
05/25/2022 03:24:57 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.5758319613767532 on epoch=53
05/25/2022 03:24:57 - INFO - __main__ - save last model!
05/25/2022 03:24:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 03:24:57 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 03:24:57 - INFO - __main__ - Printing 3 examples
05/25/2022 03:24:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 03:24:57 - INFO - __main__ - ['Animal']
05/25/2022 03:24:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 03:24:57 - INFO - __main__ - ['Animal']
05/25/2022 03:24:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 03:24:57 - INFO - __main__ - ['Village']
05/25/2022 03:24:57 - INFO - __main__ - Tokenizing Input ...
05/25/2022 03:24:58 - INFO - __main__ - Tokenizing Output ...
05/25/2022 03:25:02 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 03:26:59 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.4_8_predictions.txt
05/25/2022 03:26:59 - INFO - __main__ - Classification-F1 on test data: 0.4951
05/25/2022 03:26:59 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.4, bsz=8, dev_performance=0.7493279801848776, test_performance=0.49509675858349794
05/25/2022 03:26:59 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.3, bsz=8 ...
05/25/2022 03:27:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 03:27:00 - INFO - __main__ - Printing 3 examples
05/25/2022 03:27:00 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 03:27:00 - INFO - __main__ - ['Animal']
05/25/2022 03:27:00 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 03:27:00 - INFO - __main__ - ['Animal']
05/25/2022 03:27:00 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 03:27:00 - INFO - __main__ - ['Animal']
05/25/2022 03:27:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 03:27:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 03:27:02 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 03:27:02 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 03:27:02 - INFO - __main__ - Printing 3 examples
05/25/2022 03:27:02 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 03:27:02 - INFO - __main__ - ['Animal']
05/25/2022 03:27:02 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 03:27:02 - INFO - __main__ - ['Animal']
05/25/2022 03:27:02 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 03:27:02 - INFO - __main__ - ['Animal']
05/25/2022 03:27:02 - INFO - __main__ - Tokenizing Input ...
05/25/2022 03:27:02 - INFO - __main__ - Tokenizing Output ...
05/25/2022 03:27:03 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 03:27:18 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 03:27:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 03:27:19 - INFO - __main__ - Starting training!
05/25/2022 03:27:22 - INFO - __main__ - Step 10 Global step 10 Train loss 6.52 on epoch=0
05/25/2022 03:27:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.66 on epoch=0
05/25/2022 03:27:28 - INFO - __main__ - Step 30 Global step 30 Train loss 4.76 on epoch=0
05/25/2022 03:27:30 - INFO - __main__ - Step 40 Global step 40 Train loss 3.78 on epoch=0
05/25/2022 03:27:33 - INFO - __main__ - Step 50 Global step 50 Train loss 3.75 on epoch=0
05/25/2022 03:28:01 - INFO - __main__ - Global step 50 Train loss 4.89 Classification-F1 0.013825569804259351 on epoch=0
05/25/2022 03:28:01 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013825569804259351 on epoch=0, global_step=50
05/25/2022 03:28:03 - INFO - __main__ - Step 60 Global step 60 Train loss 3.00 on epoch=1
05/25/2022 03:28:06 - INFO - __main__ - Step 70 Global step 70 Train loss 2.81 on epoch=1
05/25/2022 03:28:08 - INFO - __main__ - Step 80 Global step 80 Train loss 3.24 on epoch=1
05/25/2022 03:28:11 - INFO - __main__ - Step 90 Global step 90 Train loss 2.85 on epoch=1
05/25/2022 03:28:14 - INFO - __main__ - Step 100 Global step 100 Train loss 2.03 on epoch=1
05/25/2022 03:28:38 - INFO - __main__ - Global step 100 Train loss 2.79 Classification-F1 0.03319697120754127 on epoch=1
05/25/2022 03:28:38 - INFO - __main__ - Saving model with best Classification-F1: 0.013825569804259351 -> 0.03319697120754127 on epoch=1, global_step=100
05/25/2022 03:28:41 - INFO - __main__ - Step 110 Global step 110 Train loss 2.25 on epoch=1
05/25/2022 03:28:43 - INFO - __main__ - Step 120 Global step 120 Train loss 1.81 on epoch=2
05/25/2022 03:28:46 - INFO - __main__ - Step 130 Global step 130 Train loss 2.23 on epoch=2
05/25/2022 03:28:48 - INFO - __main__ - Step 140 Global step 140 Train loss 2.16 on epoch=2
05/25/2022 03:28:51 - INFO - __main__ - Step 150 Global step 150 Train loss 1.92 on epoch=2
05/25/2022 03:29:13 - INFO - __main__ - Global step 150 Train loss 2.08 Classification-F1 0.06276466666726888 on epoch=2
05/25/2022 03:29:13 - INFO - __main__ - Saving model with best Classification-F1: 0.03319697120754127 -> 0.06276466666726888 on epoch=2, global_step=150
05/25/2022 03:29:16 - INFO - __main__ - Step 160 Global step 160 Train loss 1.56 on epoch=2
05/25/2022 03:29:18 - INFO - __main__ - Step 170 Global step 170 Train loss 1.55 on epoch=3
05/25/2022 03:29:21 - INFO - __main__ - Step 180 Global step 180 Train loss 1.57 on epoch=3
05/25/2022 03:29:23 - INFO - __main__ - Step 190 Global step 190 Train loss 1.67 on epoch=3
05/25/2022 03:29:26 - INFO - __main__ - Step 200 Global step 200 Train loss 1.65 on epoch=3
05/25/2022 03:29:48 - INFO - __main__ - Global step 200 Train loss 1.60 Classification-F1 0.1034095914116977 on epoch=3
05/25/2022 03:29:48 - INFO - __main__ - Saving model with best Classification-F1: 0.06276466666726888 -> 0.1034095914116977 on epoch=3, global_step=200
05/25/2022 03:29:51 - INFO - __main__ - Step 210 Global step 210 Train loss 1.24 on epoch=3
05/25/2022 03:29:53 - INFO - __main__ - Step 220 Global step 220 Train loss 1.31 on epoch=3
05/25/2022 03:29:56 - INFO - __main__ - Step 230 Global step 230 Train loss 1.01 on epoch=4
05/25/2022 03:29:59 - INFO - __main__ - Step 240 Global step 240 Train loss 1.18 on epoch=4
05/25/2022 03:30:01 - INFO - __main__ - Step 250 Global step 250 Train loss 1.15 on epoch=4
05/25/2022 03:30:24 - INFO - __main__ - Global step 250 Train loss 1.18 Classification-F1 0.16540106885746994 on epoch=4
05/25/2022 03:30:24 - INFO - __main__ - Saving model with best Classification-F1: 0.1034095914116977 -> 0.16540106885746994 on epoch=4, global_step=250
05/25/2022 03:30:26 - INFO - __main__ - Step 260 Global step 260 Train loss 1.07 on epoch=4
05/25/2022 03:30:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=4
05/25/2022 03:30:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.78 on epoch=4
05/25/2022 03:30:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.81 on epoch=5
05/25/2022 03:30:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.87 on epoch=5
05/25/2022 03:31:00 - INFO - __main__ - Global step 300 Train loss 0.85 Classification-F1 0.2188811886718089 on epoch=5
05/25/2022 03:31:00 - INFO - __main__ - Saving model with best Classification-F1: 0.16540106885746994 -> 0.2188811886718089 on epoch=5, global_step=300
05/25/2022 03:31:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.73 on epoch=5
05/25/2022 03:31:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=5
05/25/2022 03:31:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=5
05/25/2022 03:31:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=6
05/25/2022 03:31:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.68 on epoch=6
05/25/2022 03:31:37 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.2430639443341365 on epoch=6
05/25/2022 03:31:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2188811886718089 -> 0.2430639443341365 on epoch=6, global_step=350
05/25/2022 03:31:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.69 on epoch=6
05/25/2022 03:31:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.59 on epoch=6
05/25/2022 03:31:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.47 on epoch=6
05/25/2022 03:31:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=6
05/25/2022 03:31:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=7
05/25/2022 03:32:15 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.2793554668026505 on epoch=7
05/25/2022 03:32:15 - INFO - __main__ - Saving model with best Classification-F1: 0.2430639443341365 -> 0.2793554668026505 on epoch=7, global_step=400
05/25/2022 03:32:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=7
05/25/2022 03:32:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=7
05/25/2022 03:32:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.44 on epoch=7
05/25/2022 03:32:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=7
05/25/2022 03:32:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=8
05/25/2022 03:32:53 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.294547292560305 on epoch=8
05/25/2022 03:32:53 - INFO - __main__ - Saving model with best Classification-F1: 0.2793554668026505 -> 0.294547292560305 on epoch=8, global_step=450
05/25/2022 03:32:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=8
05/25/2022 03:32:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=8
05/25/2022 03:33:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=8
05/25/2022 03:33:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.34 on epoch=8
05/25/2022 03:33:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.38 on epoch=8
05/25/2022 03:33:31 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.3424231097866887 on epoch=8
05/25/2022 03:33:31 - INFO - __main__ - Saving model with best Classification-F1: 0.294547292560305 -> 0.3424231097866887 on epoch=8, global_step=500
05/25/2022 03:33:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=9
05/25/2022 03:33:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=9
05/25/2022 03:33:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.42 on epoch=9
05/25/2022 03:33:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=9
05/25/2022 03:33:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=9
05/25/2022 03:34:10 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.3099473588791973 on epoch=9
05/25/2022 03:34:12 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=9
05/25/2022 03:34:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=10
05/25/2022 03:34:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=10
05/25/2022 03:34:20 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=10
05/25/2022 03:34:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=10
05/25/2022 03:34:48 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.3801283912623761 on epoch=10
05/25/2022 03:34:48 - INFO - __main__ - Saving model with best Classification-F1: 0.3424231097866887 -> 0.3801283912623761 on epoch=10, global_step=600
05/25/2022 03:34:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=10
05/25/2022 03:34:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=11
05/25/2022 03:34:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=11
05/25/2022 03:34:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=11
05/25/2022 03:35:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=11
05/25/2022 03:35:27 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.44446984367855263 on epoch=11
05/25/2022 03:35:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3801283912623761 -> 0.44446984367855263 on epoch=11, global_step=650
05/25/2022 03:35:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=11
05/25/2022 03:35:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=11
05/25/2022 03:35:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=12
05/25/2022 03:35:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.37 on epoch=12
05/25/2022 03:35:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=12
05/25/2022 03:36:05 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.48467514210751117 on epoch=12
05/25/2022 03:36:05 - INFO - __main__ - Saving model with best Classification-F1: 0.44446984367855263 -> 0.48467514210751117 on epoch=12, global_step=700
05/25/2022 03:36:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=12
05/25/2022 03:36:11 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=12
05/25/2022 03:36:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=13
05/25/2022 03:36:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=13
05/25/2022 03:36:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=13
05/25/2022 03:36:44 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.4823436701881072 on epoch=13
05/25/2022 03:36:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=13
05/25/2022 03:36:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=13
05/25/2022 03:36:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=13
05/25/2022 03:36:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=14
05/25/2022 03:36:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.31 on epoch=14
05/25/2022 03:37:22 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.5710371918943491 on epoch=14
05/25/2022 03:37:22 - INFO - __main__ - Saving model with best Classification-F1: 0.48467514210751117 -> 0.5710371918943491 on epoch=14, global_step=800
05/25/2022 03:37:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=14
05/25/2022 03:37:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=14
05/25/2022 03:37:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=14
05/25/2022 03:37:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=14
05/25/2022 03:37:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=15
05/25/2022 03:38:00 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.5880346345202567 on epoch=15
05/25/2022 03:38:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5710371918943491 -> 0.5880346345202567 on epoch=15, global_step=850
05/25/2022 03:38:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=15
05/25/2022 03:38:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
05/25/2022 03:38:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=15
05/25/2022 03:38:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=15
05/25/2022 03:38:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=16
05/25/2022 03:38:38 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.5796327531712835 on epoch=16
05/25/2022 03:38:40 - INFO - __main__ - Step 910 Global step 910 Train loss 0.26 on epoch=16
05/25/2022 03:38:43 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=16
05/25/2022 03:38:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=16
05/25/2022 03:38:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=16
05/25/2022 03:38:51 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=16
05/25/2022 03:39:15 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.5103794763138777 on epoch=16
05/25/2022 03:39:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
05/25/2022 03:39:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=17
05/25/2022 03:39:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=17
05/25/2022 03:39:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=17
05/25/2022 03:39:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=17
05/25/2022 03:39:53 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.48921459212343765 on epoch=17
05/25/2022 03:39:55 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=18
05/25/2022 03:39:58 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=18
05/25/2022 03:40:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=18
05/25/2022 03:40:03 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
05/25/2022 03:40:06 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=18
05/25/2022 03:40:30 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.4920377015909636 on epoch=18
05/25/2022 03:40:32 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=18
05/25/2022 03:40:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=19
05/25/2022 03:40:37 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.21 on epoch=19
05/25/2022 03:40:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=19
05/25/2022 03:40:42 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=19
05/25/2022 03:41:07 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.49497996860742105 on epoch=19
05/25/2022 03:41:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=19
05/25/2022 03:41:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=19
05/25/2022 03:41:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=20
05/25/2022 03:41:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.18 on epoch=20
05/25/2022 03:41:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.09 on epoch=20
05/25/2022 03:41:46 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.5367793246353166 on epoch=20
05/25/2022 03:41:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=20
05/25/2022 03:41:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/25/2022 03:41:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=21
05/25/2022 03:41:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=21
05/25/2022 03:42:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=21
05/25/2022 03:42:25 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.5386607458029591 on epoch=21
05/25/2022 03:42:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=21
05/25/2022 03:42:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=21
05/25/2022 03:42:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=21
05/25/2022 03:42:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=22
05/25/2022 03:42:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.21 on epoch=22
05/25/2022 03:43:04 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.47929428348237696 on epoch=22
05/25/2022 03:43:07 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=22
05/25/2022 03:43:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=22
05/25/2022 03:43:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=22
05/25/2022 03:43:15 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=23
05/25/2022 03:43:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=23
05/25/2022 03:43:42 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.49440000839926695 on epoch=23
05/25/2022 03:43:45 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=23
05/25/2022 03:43:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=23
05/25/2022 03:43:50 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=23
05/25/2022 03:43:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=23
05/25/2022 03:43:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=24
05/25/2022 03:44:21 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.542197532180407 on epoch=24
05/25/2022 03:44:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/25/2022 03:44:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=24
05/25/2022 03:44:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=24
05/25/2022 03:44:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=24
05/25/2022 03:44:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=24
05/25/2022 03:45:01 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.5632769464692888 on epoch=24
05/25/2022 03:45:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=25
05/25/2022 03:45:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=25
05/25/2022 03:45:09 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=25
05/25/2022 03:45:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=25
05/25/2022 03:45:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=25
05/25/2022 03:45:40 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.4919284162608625 on epoch=25
05/25/2022 03:45:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=26
05/25/2022 03:45:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=26
05/25/2022 03:45:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 03:45:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=26
05/25/2022 03:45:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=26
05/25/2022 03:46:18 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.4943188377672142 on epoch=26
05/25/2022 03:46:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=26
05/25/2022 03:46:24 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=27
05/25/2022 03:46:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=27
05/25/2022 03:46:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=27
05/25/2022 03:46:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
05/25/2022 03:46:57 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.48833741004670367 on epoch=27
05/25/2022 03:47:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=27
05/25/2022 03:47:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
05/25/2022 03:47:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=28
05/25/2022 03:47:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=28
05/25/2022 03:47:11 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=28
05/25/2022 03:47:36 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.5929414350577388 on epoch=28
05/25/2022 03:47:36 - INFO - __main__ - Saving model with best Classification-F1: 0.5880346345202567 -> 0.5929414350577388 on epoch=28, global_step=1600
05/25/2022 03:47:39 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=28
05/25/2022 03:47:41 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=28
05/25/2022 03:47:44 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
05/25/2022 03:47:47 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=29
05/25/2022 03:47:49 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.12 on epoch=29
05/25/2022 03:48:15 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.6301571558771624 on epoch=29
05/25/2022 03:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5929414350577388 -> 0.6301571558771624 on epoch=29, global_step=1650
05/25/2022 03:48:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=29
05/25/2022 03:48:21 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=29
05/25/2022 03:48:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=29
05/25/2022 03:48:26 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=30
05/25/2022 03:48:29 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
05/25/2022 03:48:53 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.5914721234549892 on epoch=30
05/25/2022 03:48:56 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=30
05/25/2022 03:48:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=30
05/25/2022 03:49:01 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
05/25/2022 03:49:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=31
05/25/2022 03:49:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.20 on epoch=31
05/25/2022 03:49:32 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.5686012100658231 on epoch=31
05/25/2022 03:49:35 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=31
05/25/2022 03:49:38 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/25/2022 03:49:40 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=31
05/25/2022 03:49:43 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=31
05/25/2022 03:49:46 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
05/25/2022 03:50:11 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.577654724379363 on epoch=32
05/25/2022 03:50:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=32
05/25/2022 03:50:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
05/25/2022 03:50:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
05/25/2022 03:50:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=32
05/25/2022 03:50:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/25/2022 03:50:49 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.6325341975927896 on epoch=33
05/25/2022 03:50:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6301571558771624 -> 0.6325341975927896 on epoch=33, global_step=1850
05/25/2022 03:50:52 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=33
05/25/2022 03:50:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=33
05/25/2022 03:50:57 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
05/25/2022 03:51:00 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=33
05/25/2022 03:51:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
05/25/2022 03:51:29 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6385464063208307 on epoch=33
05/25/2022 03:51:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6325341975927896 -> 0.6385464063208307 on epoch=33, global_step=1900
05/25/2022 03:51:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
05/25/2022 03:51:34 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=34
05/25/2022 03:51:37 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
05/25/2022 03:51:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=34
05/25/2022 03:51:42 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=34
05/25/2022 03:52:07 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5536545835427892 on epoch=34
05/25/2022 03:52:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
05/25/2022 03:52:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=35
05/25/2022 03:52:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=35
05/25/2022 03:52:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=35
05/25/2022 03:52:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/25/2022 03:52:45 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.5987259816207184 on epoch=35
05/25/2022 03:52:48 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=35
05/25/2022 03:52:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
05/25/2022 03:52:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.19 on epoch=36
05/25/2022 03:52:56 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
05/25/2022 03:52:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=36
05/25/2022 03:53:22 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.5416318779956072 on epoch=36
05/25/2022 03:53:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=36
05/25/2022 03:53:28 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/25/2022 03:53:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=37
05/25/2022 03:53:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=37
05/25/2022 03:53:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/25/2022 03:54:01 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.5051697319090774 on epoch=37
05/25/2022 03:54:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=37
05/25/2022 03:54:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
05/25/2022 03:54:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=38
05/25/2022 03:54:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=38
05/25/2022 03:54:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/25/2022 03:54:39 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.5672920610096778 on epoch=38
05/25/2022 03:54:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=38
05/25/2022 03:54:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=38
05/25/2022 03:54:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=38
05/25/2022 03:54:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/25/2022 03:54:53 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.13 on epoch=39
05/25/2022 03:55:18 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.5996629852025791 on epoch=39
05/25/2022 03:55:21 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=39
05/25/2022 03:55:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=39
05/25/2022 03:55:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=39
05/25/2022 03:55:29 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=39
05/25/2022 03:55:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=40
05/25/2022 03:55:57 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6271135263003236 on epoch=40
05/25/2022 03:55:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=40
05/25/2022 03:56:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/25/2022 03:56:05 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/25/2022 03:56:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 03:56:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/25/2022 03:56:35 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.5490068192617139 on epoch=41
05/25/2022 03:56:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=41
05/25/2022 03:56:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.13 on epoch=41
05/25/2022 03:56:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=41
05/25/2022 03:56:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
05/25/2022 03:56:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=41
05/25/2022 03:57:13 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.5695271291696682 on epoch=41
05/25/2022 03:57:15 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/25/2022 03:57:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=42
05/25/2022 03:57:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=42
05/25/2022 03:57:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 03:57:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=42
05/25/2022 03:57:50 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.546197291578065 on epoch=42
05/25/2022 03:57:53 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/25/2022 03:57:56 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.13 on epoch=43
05/25/2022 03:57:58 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.15 on epoch=43
05/25/2022 03:58:01 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
05/25/2022 03:58:04 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/25/2022 03:58:28 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6603800901571336 on epoch=43
05/25/2022 03:58:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6385464063208307 -> 0.6603800901571336 on epoch=43, global_step=2450
05/25/2022 03:58:31 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=43
05/25/2022 03:58:34 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/25/2022 03:58:36 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.13 on epoch=44
05/25/2022 03:58:39 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 03:58:42 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=44
05/25/2022 03:59:06 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.6006033033809378 on epoch=44
05/25/2022 03:59:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=44
05/25/2022 03:59:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/25/2022 03:59:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/25/2022 03:59:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.11 on epoch=45
05/25/2022 03:59:20 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/25/2022 03:59:44 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5879666011130232 on epoch=45
05/25/2022 03:59:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/25/2022 03:59:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
05/25/2022 03:59:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=46
05/25/2022 03:59:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.11 on epoch=46
05/25/2022 03:59:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/25/2022 04:00:21 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.43545557537053486 on epoch=46
05/25/2022 04:00:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/25/2022 04:00:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/25/2022 04:00:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=46
05/25/2022 04:00:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/25/2022 04:00:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.10 on epoch=47
05/25/2022 04:00:59 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.5430054812001304 on epoch=47
05/25/2022 04:01:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/25/2022 04:01:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
05/25/2022 04:01:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
05/25/2022 04:01:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=48
05/25/2022 04:01:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.09 on epoch=48
05/25/2022 04:01:36 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.453256846085016 on epoch=48
05/25/2022 04:01:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.11 on epoch=48
05/25/2022 04:01:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
05/25/2022 04:01:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/25/2022 04:01:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/25/2022 04:01:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/25/2022 04:02:14 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6067243933348544 on epoch=49
05/25/2022 04:02:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.11 on epoch=49
05/25/2022 04:02:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/25/2022 04:02:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=49
05/25/2022 04:02:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/25/2022 04:02:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/25/2022 04:02:52 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6327381635816859 on epoch=49
05/25/2022 04:02:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=50
05/25/2022 04:02:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/25/2022 04:03:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/25/2022 04:03:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=50
05/25/2022 04:03:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 04:03:30 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5100610572403333 on epoch=50
05/25/2022 04:03:32 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=51
05/25/2022 04:03:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
05/25/2022 04:03:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/25/2022 04:03:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=51
05/25/2022 04:03:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/25/2022 04:04:07 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.508760870684773 on epoch=51
05/25/2022 04:04:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 04:04:12 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/25/2022 04:04:15 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
05/25/2022 04:04:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/25/2022 04:04:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=52
05/25/2022 04:04:44 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.4863268423198682 on epoch=52
05/25/2022 04:04:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
05/25/2022 04:04:49 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/25/2022 04:04:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=53
05/25/2022 04:04:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=53
05/25/2022 04:04:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=53
05/25/2022 04:04:59 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:04:59 - INFO - __main__ - Printing 3 examples
05/25/2022 04:04:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 04:04:59 - INFO - __main__ - ['Animal']
05/25/2022 04:04:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 04:04:59 - INFO - __main__ - ['Animal']
05/25/2022 04:04:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 04:04:59 - INFO - __main__ - ['Animal']
05/25/2022 04:04:59 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:04:59 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:05:00 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 04:05:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:05:00 - INFO - __main__ - Printing 3 examples
05/25/2022 04:05:00 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 04:05:00 - INFO - __main__ - ['Animal']
05/25/2022 04:05:00 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 04:05:00 - INFO - __main__ - ['Animal']
05/25/2022 04:05:00 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 04:05:00 - INFO - __main__ - ['Animal']
05/25/2022 04:05:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:05:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:05:02 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 04:05:17 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 04:05:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 04:05:18 - INFO - __main__ - Starting training!
05/25/2022 04:05:21 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.513600127341878 on epoch=53
05/25/2022 04:05:21 - INFO - __main__ - save last model!
05/25/2022 04:05:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 04:05:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 04:05:21 - INFO - __main__ - Printing 3 examples
05/25/2022 04:05:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 04:05:21 - INFO - __main__ - ['Animal']
05/25/2022 04:05:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 04:05:21 - INFO - __main__ - ['Animal']
05/25/2022 04:05:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 04:05:21 - INFO - __main__ - ['Village']
05/25/2022 04:05:21 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:05:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:05:27 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 04:07:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.3_8_predictions.txt
05/25/2022 04:07:29 - INFO - __main__ - Classification-F1 on test data: 0.3917
05/25/2022 04:07:29 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.3, bsz=8, dev_performance=0.6603800901571336, test_performance=0.3916995653124375
05/25/2022 04:07:29 - INFO - __main__ - Running ... prefix=dbpedia_14_64_13, lr=0.2, bsz=8 ...
05/25/2022 04:07:30 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:07:30 - INFO - __main__ - Printing 3 examples
05/25/2022 04:07:30 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/25/2022 04:07:30 - INFO - __main__ - ['Animal']
05/25/2022 04:07:30 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/25/2022 04:07:30 - INFO - __main__ - ['Animal']
05/25/2022 04:07:30 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/25/2022 04:07:30 - INFO - __main__ - ['Animal']
05/25/2022 04:07:30 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:07:31 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:07:32 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 04:07:32 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:07:32 - INFO - __main__ - Printing 3 examples
05/25/2022 04:07:32 - INFO - __main__ -  [dbpedia_14] Clarkesvillia is an Upper Ordovician westonocerid genus the differs from Faberoceras in having a more flattened venter and from the later Glyptodendron in having a more ventrally located siphuncle.
05/25/2022 04:07:32 - INFO - __main__ - ['Animal']
05/25/2022 04:07:32 - INFO - __main__ -  [dbpedia_14] Alaena ochracea is a butterfly in the Lycaenidae family. It is found in Malawi (from the southern part of the country to the Shire Highlands). The habitat consists of the fringes of submontane evergreen forests.
05/25/2022 04:07:32 - INFO - __main__ - ['Animal']
05/25/2022 04:07:32 - INFO - __main__ -  [dbpedia_14] Latoia is a genus of moths in the family Limacodidae.
05/25/2022 04:07:32 - INFO - __main__ - ['Animal']
05/25/2022 04:07:32 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:07:32 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:07:33 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 04:07:48 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 04:07:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 04:07:49 - INFO - __main__ - Starting training!
05/25/2022 04:07:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.97 on epoch=0
05/25/2022 04:07:55 - INFO - __main__ - Step 20 Global step 20 Train loss 6.02 on epoch=0
05/25/2022 04:07:58 - INFO - __main__ - Step 30 Global step 30 Train loss 5.82 on epoch=0
05/25/2022 04:08:00 - INFO - __main__ - Step 40 Global step 40 Train loss 4.41 on epoch=0
05/25/2022 04:08:03 - INFO - __main__ - Step 50 Global step 50 Train loss 4.28 on epoch=0
05/25/2022 04:08:30 - INFO - __main__ - Global step 50 Train loss 5.70 Classification-F1 0.009072205243018982 on epoch=0
05/25/2022 04:08:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009072205243018982 on epoch=0, global_step=50
05/25/2022 04:08:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.77 on epoch=1
05/25/2022 04:08:35 - INFO - __main__ - Step 70 Global step 70 Train loss 3.38 on epoch=1
05/25/2022 04:08:37 - INFO - __main__ - Step 80 Global step 80 Train loss 3.86 on epoch=1
05/25/2022 04:08:40 - INFO - __main__ - Step 90 Global step 90 Train loss 3.56 on epoch=1
05/25/2022 04:08:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.69 on epoch=1
05/25/2022 04:09:09 - INFO - __main__ - Global step 100 Train loss 3.45 Classification-F1 0.017869659713348973 on epoch=1
05/25/2022 04:09:09 - INFO - __main__ - Saving model with best Classification-F1: 0.009072205243018982 -> 0.017869659713348973 on epoch=1, global_step=100
05/25/2022 04:09:12 - INFO - __main__ - Step 110 Global step 110 Train loss 2.90 on epoch=1
05/25/2022 04:09:14 - INFO - __main__ - Step 120 Global step 120 Train loss 2.35 on epoch=2
05/25/2022 04:09:17 - INFO - __main__ - Step 130 Global step 130 Train loss 2.93 on epoch=2
05/25/2022 04:09:19 - INFO - __main__ - Step 140 Global step 140 Train loss 2.66 on epoch=2
05/25/2022 04:09:22 - INFO - __main__ - Step 150 Global step 150 Train loss 2.50 on epoch=2
05/25/2022 04:09:46 - INFO - __main__ - Global step 150 Train loss 2.67 Classification-F1 0.03331712641535194 on epoch=2
05/25/2022 04:09:46 - INFO - __main__ - Saving model with best Classification-F1: 0.017869659713348973 -> 0.03331712641535194 on epoch=2, global_step=150
05/25/2022 04:09:49 - INFO - __main__ - Step 160 Global step 160 Train loss 2.03 on epoch=2
05/25/2022 04:09:51 - INFO - __main__ - Step 170 Global step 170 Train loss 2.03 on epoch=3
05/25/2022 04:09:54 - INFO - __main__ - Step 180 Global step 180 Train loss 2.03 on epoch=3
05/25/2022 04:09:56 - INFO - __main__ - Step 190 Global step 190 Train loss 2.34 on epoch=3
05/25/2022 04:09:59 - INFO - __main__ - Step 200 Global step 200 Train loss 2.30 on epoch=3
05/25/2022 04:10:22 - INFO - __main__ - Global step 200 Train loss 2.15 Classification-F1 0.051309479247119455 on epoch=3
05/25/2022 04:10:22 - INFO - __main__ - Saving model with best Classification-F1: 0.03331712641535194 -> 0.051309479247119455 on epoch=3, global_step=200
05/25/2022 04:10:25 - INFO - __main__ - Step 210 Global step 210 Train loss 1.80 on epoch=3
05/25/2022 04:10:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.88 on epoch=3
05/25/2022 04:10:30 - INFO - __main__ - Step 230 Global step 230 Train loss 1.51 on epoch=4
05/25/2022 04:10:33 - INFO - __main__ - Step 240 Global step 240 Train loss 1.75 on epoch=4
05/25/2022 04:10:35 - INFO - __main__ - Step 250 Global step 250 Train loss 1.85 on epoch=4
05/25/2022 04:10:58 - INFO - __main__ - Global step 250 Train loss 1.76 Classification-F1 0.08057542096731538 on epoch=4
05/25/2022 04:10:58 - INFO - __main__ - Saving model with best Classification-F1: 0.051309479247119455 -> 0.08057542096731538 on epoch=4, global_step=250
05/25/2022 04:11:01 - INFO - __main__ - Step 260 Global step 260 Train loss 1.74 on epoch=4
05/25/2022 04:11:03 - INFO - __main__ - Step 270 Global step 270 Train loss 1.29 on epoch=4
05/25/2022 04:11:06 - INFO - __main__ - Step 280 Global step 280 Train loss 1.39 on epoch=4
05/25/2022 04:11:08 - INFO - __main__ - Step 290 Global step 290 Train loss 1.22 on epoch=5
05/25/2022 04:11:11 - INFO - __main__ - Step 300 Global step 300 Train loss 1.58 on epoch=5
05/25/2022 04:11:33 - INFO - __main__ - Global step 300 Train loss 1.45 Classification-F1 0.11083738921199748 on epoch=5
05/25/2022 04:11:33 - INFO - __main__ - Saving model with best Classification-F1: 0.08057542096731538 -> 0.11083738921199748 on epoch=5, global_step=300
05/25/2022 04:11:36 - INFO - __main__ - Step 310 Global step 310 Train loss 1.59 on epoch=5
05/25/2022 04:11:38 - INFO - __main__ - Step 320 Global step 320 Train loss 1.16 on epoch=5
05/25/2022 04:11:41 - INFO - __main__ - Step 330 Global step 330 Train loss 1.31 on epoch=5
05/25/2022 04:11:43 - INFO - __main__ - Step 340 Global step 340 Train loss 1.05 on epoch=6
05/25/2022 04:11:46 - INFO - __main__ - Step 350 Global step 350 Train loss 1.11 on epoch=6
05/25/2022 04:12:08 - INFO - __main__ - Global step 350 Train loss 1.25 Classification-F1 0.1289225575040552 on epoch=6
05/25/2022 04:12:08 - INFO - __main__ - Saving model with best Classification-F1: 0.11083738921199748 -> 0.1289225575040552 on epoch=6, global_step=350
05/25/2022 04:12:11 - INFO - __main__ - Step 360 Global step 360 Train loss 1.24 on epoch=6
05/25/2022 04:12:13 - INFO - __main__ - Step 370 Global step 370 Train loss 1.14 on epoch=6
05/25/2022 04:12:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.80 on epoch=6
05/25/2022 04:12:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.95 on epoch=6
05/25/2022 04:12:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.84 on epoch=7
05/25/2022 04:12:44 - INFO - __main__ - Global step 400 Train loss 0.99 Classification-F1 0.17682489579698366 on epoch=7
05/25/2022 04:12:44 - INFO - __main__ - Saving model with best Classification-F1: 0.1289225575040552 -> 0.17682489579698366 on epoch=7, global_step=400
05/25/2022 04:12:46 - INFO - __main__ - Step 410 Global step 410 Train loss 1.00 on epoch=7
05/25/2022 04:12:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.86 on epoch=7
05/25/2022 04:12:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.82 on epoch=7
05/25/2022 04:12:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.71 on epoch=7
05/25/2022 04:12:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.66 on epoch=8
05/25/2022 04:13:21 - INFO - __main__ - Global step 450 Train loss 0.81 Classification-F1 0.21469893247539829 on epoch=8
05/25/2022 04:13:21 - INFO - __main__ - Saving model with best Classification-F1: 0.17682489579698366 -> 0.21469893247539829 on epoch=8, global_step=450
05/25/2022 04:13:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.71 on epoch=8
05/25/2022 04:13:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.75 on epoch=8
05/25/2022 04:13:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.77 on epoch=8
05/25/2022 04:13:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=8
05/25/2022 04:13:33 - INFO - __main__ - Step 500 Global step 500 Train loss 0.67 on epoch=8
05/25/2022 04:13:59 - INFO - __main__ - Global step 500 Train loss 0.71 Classification-F1 0.2370709230116267 on epoch=8
05/25/2022 04:13:59 - INFO - __main__ - Saving model with best Classification-F1: 0.21469893247539829 -> 0.2370709230116267 on epoch=8, global_step=500
05/25/2022 04:14:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.61 on epoch=9
05/25/2022 04:14:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.68 on epoch=9
05/25/2022 04:14:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=9
05/25/2022 04:14:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=9
05/25/2022 04:14:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.54 on epoch=9
05/25/2022 04:14:37 - INFO - __main__ - Global step 550 Train loss 0.61 Classification-F1 0.27515251459004564 on epoch=9
05/25/2022 04:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2370709230116267 -> 0.27515251459004564 on epoch=9, global_step=550
05/25/2022 04:14:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=9
05/25/2022 04:14:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.49 on epoch=10
05/25/2022 04:14:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.51 on epoch=10
05/25/2022 04:14:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.56 on epoch=10
05/25/2022 04:14:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.50 on epoch=10
05/25/2022 04:15:16 - INFO - __main__ - Global step 600 Train loss 0.51 Classification-F1 0.304017002390791 on epoch=10
05/25/2022 04:15:16 - INFO - __main__ - Saving model with best Classification-F1: 0.27515251459004564 -> 0.304017002390791 on epoch=10, global_step=600
05/25/2022 04:15:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=10
05/25/2022 04:15:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.41 on epoch=11
05/25/2022 04:15:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.57 on epoch=11
05/25/2022 04:15:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.52 on epoch=11
05/25/2022 04:15:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=11
05/25/2022 04:15:55 - INFO - __main__ - Global step 650 Train loss 0.49 Classification-F1 0.34626136528544577 on epoch=11
05/25/2022 04:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.304017002390791 -> 0.34626136528544577 on epoch=11, global_step=650
05/25/2022 04:15:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=11
05/25/2022 04:16:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=11
05/25/2022 04:16:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=12
05/25/2022 04:16:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.48 on epoch=12
05/25/2022 04:16:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=12
05/25/2022 04:16:34 - INFO - __main__ - Global step 700 Train loss 0.41 Classification-F1 0.3375721727361244 on epoch=12
05/25/2022 04:16:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=12
05/25/2022 04:16:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.45 on epoch=12
05/25/2022 04:16:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=13
05/25/2022 04:16:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=13
05/25/2022 04:16:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.39 on epoch=13
05/25/2022 04:17:13 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.3478097430699045 on epoch=13
05/25/2022 04:17:13 - INFO - __main__ - Saving model with best Classification-F1: 0.34626136528544577 -> 0.3478097430699045 on epoch=13, global_step=750
05/25/2022 04:17:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.37 on epoch=13
05/25/2022 04:17:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=13
05/25/2022 04:17:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=13
05/25/2022 04:17:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=14
05/25/2022 04:17:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.38 on epoch=14
05/25/2022 04:17:53 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.32067078406521204 on epoch=14
05/25/2022 04:17:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.28 on epoch=14
05/25/2022 04:17:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=14
05/25/2022 04:18:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=14
05/25/2022 04:18:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=14
05/25/2022 04:18:06 - INFO - __main__ - Step 850 Global step 850 Train loss 0.36 on epoch=15
05/25/2022 04:18:32 - INFO - __main__ - Global step 850 Train loss 0.32 Classification-F1 0.3614690081281805 on epoch=15
05/25/2022 04:18:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3478097430699045 -> 0.3614690081281805 on epoch=15, global_step=850
05/25/2022 04:18:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.43 on epoch=15
05/25/2022 04:18:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=15
05/25/2022 04:18:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=15
05/25/2022 04:18:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=15
05/25/2022 04:18:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=16
05/25/2022 04:19:11 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.3798541883204592 on epoch=16
05/25/2022 04:19:11 - INFO - __main__ - Saving model with best Classification-F1: 0.3614690081281805 -> 0.3798541883204592 on epoch=16, global_step=900
05/25/2022 04:19:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.31 on epoch=16
05/25/2022 04:19:16 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=16
05/25/2022 04:19:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=16
05/25/2022 04:19:21 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=16
05/25/2022 04:19:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.25 on epoch=16
05/25/2022 04:19:50 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.3719522676140104 on epoch=16
05/25/2022 04:19:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.29 on epoch=17
05/25/2022 04:19:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.37 on epoch=17
05/25/2022 04:19:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=17
05/25/2022 04:20:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=17
05/25/2022 04:20:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=17
05/25/2022 04:20:29 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.40300534765530466 on epoch=17
05/25/2022 04:20:29 - INFO - __main__ - Saving model with best Classification-F1: 0.3798541883204592 -> 0.40300534765530466 on epoch=17, global_step=1000
05/25/2022 04:20:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=18
05/25/2022 04:20:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=18
05/25/2022 04:20:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.26 on epoch=18
05/25/2022 04:20:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=18
05/25/2022 04:20:42 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=18
05/25/2022 04:21:08 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.36328438907181226 on epoch=18
05/25/2022 04:21:11 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=18
05/25/2022 04:21:13 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.23 on epoch=19
05/25/2022 04:21:16 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.38 on epoch=19
05/25/2022 04:21:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=19
05/25/2022 04:21:21 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=19
05/25/2022 04:21:48 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.38719438730605266 on epoch=19
05/25/2022 04:21:51 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=19
05/25/2022 04:21:53 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=19
05/25/2022 04:21:56 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.22 on epoch=20
05/25/2022 04:21:58 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.30 on epoch=20
05/25/2022 04:22:01 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=20
05/25/2022 04:22:28 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.47372626077492774 on epoch=20
05/25/2022 04:22:28 - INFO - __main__ - Saving model with best Classification-F1: 0.40300534765530466 -> 0.47372626077492774 on epoch=20, global_step=1150
05/25/2022 04:22:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=20
05/25/2022 04:22:33 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=20
05/25/2022 04:22:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.17 on epoch=21
05/25/2022 04:22:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.28 on epoch=21
05/25/2022 04:22:41 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=21
05/25/2022 04:23:08 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.4699670093222593 on epoch=21
05/25/2022 04:23:11 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=21
05/25/2022 04:23:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=21
05/25/2022 04:23:16 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=21
05/25/2022 04:23:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.24 on epoch=22
05/25/2022 04:23:21 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=22
05/25/2022 04:23:49 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.4953517369937989 on epoch=22
05/25/2022 04:23:49 - INFO - __main__ - Saving model with best Classification-F1: 0.47372626077492774 -> 0.4953517369937989 on epoch=22, global_step=1250
05/25/2022 04:23:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=22
05/25/2022 04:23:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=22
05/25/2022 04:23:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=22
05/25/2022 04:23:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=23
05/25/2022 04:24:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.24 on epoch=23
05/25/2022 04:24:28 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.5199182296871767 on epoch=23
05/25/2022 04:24:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4953517369937989 -> 0.5199182296871767 on epoch=23, global_step=1300
05/25/2022 04:24:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=23
05/25/2022 04:24:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=23
05/25/2022 04:24:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=23
05/25/2022 04:24:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=23
05/25/2022 04:24:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=24
05/25/2022 04:25:08 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.47917924769188613 on epoch=24
05/25/2022 04:25:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=24
05/25/2022 04:25:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.21 on epoch=24
05/25/2022 04:25:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=24
05/25/2022 04:25:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=24
05/25/2022 04:25:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=24
05/25/2022 04:25:48 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.45980359262252624 on epoch=24
05/25/2022 04:25:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=25
05/25/2022 04:25:53 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.21 on epoch=25
05/25/2022 04:25:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=25
05/25/2022 04:25:58 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=25
05/25/2022 04:26:01 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=25
05/25/2022 04:26:28 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.458363959959588 on epoch=25
05/25/2022 04:26:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=26
05/25/2022 04:26:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.23 on epoch=26
05/25/2022 04:26:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=26
05/25/2022 04:26:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=26
05/25/2022 04:26:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=26
05/25/2022 04:27:08 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.4641786174192048 on epoch=26
05/25/2022 04:27:11 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.18 on epoch=26
05/25/2022 04:27:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/25/2022 04:27:16 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.24 on epoch=27
05/25/2022 04:27:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=27
05/25/2022 04:27:21 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.21 on epoch=27
05/25/2022 04:27:48 - INFO - __main__ - Global step 1550 Train loss 0.19 Classification-F1 0.4363783617855728 on epoch=27
05/25/2022 04:27:50 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=27
05/25/2022 04:27:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=28
05/25/2022 04:27:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.19 on epoch=28
05/25/2022 04:27:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.25 on epoch=28
05/25/2022 04:28:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=28
05/25/2022 04:28:27 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.4775322905258801 on epoch=28
05/25/2022 04:28:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=28
05/25/2022 04:28:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.22 on epoch=28
05/25/2022 04:28:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=29
05/25/2022 04:28:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.21 on epoch=29
05/25/2022 04:28:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.23 on epoch=29
05/25/2022 04:29:07 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.49958775463815736 on epoch=29
05/25/2022 04:29:10 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=29
05/25/2022 04:29:12 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=29
05/25/2022 04:29:15 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=29
05/25/2022 04:29:17 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.19 on epoch=30
05/25/2022 04:29:20 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=30
05/25/2022 04:29:47 - INFO - __main__ - Global step 1700 Train loss 0.14 Classification-F1 0.4984033423146148 on epoch=30
05/25/2022 04:29:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=30
05/25/2022 04:29:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=30
05/25/2022 04:29:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=30
05/25/2022 04:29:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=31
05/25/2022 04:30:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.23 on epoch=31
05/25/2022 04:30:26 - INFO - __main__ - Global step 1750 Train loss 0.15 Classification-F1 0.5242872185708151 on epoch=31
05/25/2022 04:30:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5199182296871767 -> 0.5242872185708151 on epoch=31, global_step=1750
05/25/2022 04:30:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=31
05/25/2022 04:30:31 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.17 on epoch=31
05/25/2022 04:30:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
05/25/2022 04:30:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=31
05/25/2022 04:30:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.17 on epoch=32
05/25/2022 04:31:06 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5191190483327714 on epoch=32
05/25/2022 04:31:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.22 on epoch=32
05/25/2022 04:31:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=32
05/25/2022 04:31:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=32
05/25/2022 04:31:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=32
05/25/2022 04:31:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/25/2022 04:31:45 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.52840184952627 on epoch=33
05/25/2022 04:31:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5242872185708151 -> 0.52840184952627 on epoch=33, global_step=1850
05/25/2022 04:31:47 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.26 on epoch=33
05/25/2022 04:31:50 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.24 on epoch=33
05/25/2022 04:31:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=33
05/25/2022 04:31:55 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=33
05/25/2022 04:31:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.16 on epoch=33
05/25/2022 04:32:24 - INFO - __main__ - Global step 1900 Train loss 0.18 Classification-F1 0.5005979131613015 on epoch=33
05/25/2022 04:32:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=34
05/25/2022 04:32:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=34
05/25/2022 04:32:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=34
05/25/2022 04:32:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.16 on epoch=34
05/25/2022 04:32:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=34
05/25/2022 04:33:03 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.5283498544904155 on epoch=34
05/25/2022 04:33:05 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=34
05/25/2022 04:33:08 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=35
05/25/2022 04:33:10 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.16 on epoch=35
05/25/2022 04:33:13 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=35
05/25/2022 04:33:15 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=35
05/25/2022 04:33:41 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.5578168970267208 on epoch=35
05/25/2022 04:33:41 - INFO - __main__ - Saving model with best Classification-F1: 0.52840184952627 -> 0.5578168970267208 on epoch=35, global_step=2000
05/25/2022 04:33:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=35
05/25/2022 04:33:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=36
05/25/2022 04:33:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.21 on epoch=36
05/25/2022 04:33:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=36
05/25/2022 04:33:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=36
05/25/2022 04:34:20 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.5080930845685637 on epoch=36
05/25/2022 04:34:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=36
05/25/2022 04:34:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/25/2022 04:34:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.18 on epoch=37
05/25/2022 04:34:30 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.14 on epoch=37
05/25/2022 04:34:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/25/2022 04:34:58 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.5372002181495207 on epoch=37
05/25/2022 04:35:01 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.15 on epoch=37
05/25/2022 04:35:03 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=37
05/25/2022 04:35:06 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=38
05/25/2022 04:35:09 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.19 on epoch=38
05/25/2022 04:35:11 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.15 on epoch=38
05/25/2022 04:35:37 - INFO - __main__ - Global step 2150 Train loss 0.13 Classification-F1 0.5153587466123383 on epoch=38
05/25/2022 04:35:39 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=38
05/25/2022 04:35:42 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=38
05/25/2022 04:35:45 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
05/25/2022 04:35:47 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=39
05/25/2022 04:35:50 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.18 on epoch=39
05/25/2022 04:36:15 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.5377887547971977 on epoch=39
05/25/2022 04:36:18 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=39
05/25/2022 04:36:20 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=39
05/25/2022 04:36:23 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=39
05/25/2022 04:36:25 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/25/2022 04:36:28 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=40
05/25/2022 04:36:53 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.6195976518346704 on epoch=40
05/25/2022 04:36:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5578168970267208 -> 0.6195976518346704 on epoch=40, global_step=2250
05/25/2022 04:36:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.18 on epoch=40
05/25/2022 04:36:59 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.15 on epoch=40
05/25/2022 04:37:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=40
05/25/2022 04:37:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=40
05/25/2022 04:37:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=41
05/25/2022 04:37:32 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.49447552884027 on epoch=41
05/25/2022 04:37:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.19 on epoch=41
05/25/2022 04:37:37 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=41
05/25/2022 04:37:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=41
05/25/2022 04:37:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/25/2022 04:37:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=41
05/25/2022 04:38:10 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.5181103474098148 on epoch=41
05/25/2022 04:38:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.17 on epoch=42
05/25/2022 04:38:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.21 on epoch=42
05/25/2022 04:38:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=42
05/25/2022 04:38:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.13 on epoch=42
05/25/2022 04:38:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=42
05/25/2022 04:38:48 - INFO - __main__ - Global step 2400 Train loss 0.15 Classification-F1 0.5151802960148711 on epoch=42
05/25/2022 04:38:51 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=43
05/25/2022 04:38:53 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.10 on epoch=43
05/25/2022 04:38:56 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=43
05/25/2022 04:38:58 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=43
05/25/2022 04:39:01 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
05/25/2022 04:39:27 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.5284782472006898 on epoch=43
05/25/2022 04:39:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=43
05/25/2022 04:39:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/25/2022 04:39:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.16 on epoch=44
05/25/2022 04:39:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=44
05/25/2022 04:39:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=44
05/25/2022 04:40:05 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.5354389674408633 on epoch=44
05/25/2022 04:40:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.10 on epoch=44
05/25/2022 04:40:10 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
05/25/2022 04:40:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.15 on epoch=45
05/25/2022 04:40:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=45
05/25/2022 04:40:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=45
05/25/2022 04:40:44 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.5925689757003624 on epoch=45
05/25/2022 04:40:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/25/2022 04:40:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=45
05/25/2022 04:40:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
05/25/2022 04:40:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.13 on epoch=46
05/25/2022 04:40:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/25/2022 04:41:21 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.564315640179777 on epoch=46
05/25/2022 04:41:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=46
05/25/2022 04:41:26 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=46
05/25/2022 04:41:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=46
05/25/2022 04:41:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=47
05/25/2022 04:41:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.16 on epoch=47
05/25/2022 04:41:59 - INFO - __main__ - Global step 2650 Train loss 0.10 Classification-F1 0.5633878902197597 on epoch=47
05/25/2022 04:42:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=47
05/25/2022 04:42:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=47
05/25/2022 04:42:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=47
05/25/2022 04:42:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.09 on epoch=48
05/25/2022 04:42:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.14 on epoch=48
05/25/2022 04:42:37 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.5362916996361186 on epoch=48
05/25/2022 04:42:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.12 on epoch=48
05/25/2022 04:42:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
05/25/2022 04:42:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/25/2022 04:42:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=48
05/25/2022 04:42:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.12 on epoch=49
05/25/2022 04:43:15 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.6012275273374339 on epoch=49
05/25/2022 04:43:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.13 on epoch=49
05/25/2022 04:43:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/25/2022 04:43:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=49
05/25/2022 04:43:26 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=49
05/25/2022 04:43:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=49
05/25/2022 04:43:53 - INFO - __main__ - Global step 2800 Train loss 0.09 Classification-F1 0.6319388378247218 on epoch=49
05/25/2022 04:43:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6195976518346704 -> 0.6319388378247218 on epoch=49, global_step=2800
05/25/2022 04:43:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.13 on epoch=50
05/25/2022 04:43:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=50
05/25/2022 04:44:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=50
05/25/2022 04:44:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=50
05/25/2022 04:44:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=50
05/25/2022 04:44:31 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.6131484515407306 on epoch=50
05/25/2022 04:44:34 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.10 on epoch=51
05/25/2022 04:44:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.13 on epoch=51
05/25/2022 04:44:39 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.14 on epoch=51
05/25/2022 04:44:41 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=51
05/25/2022 04:44:44 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/25/2022 04:45:09 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.6104102979803987 on epoch=51
05/25/2022 04:45:11 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=51
05/25/2022 04:45:14 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.14 on epoch=52
05/25/2022 04:45:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.12 on epoch=52
05/25/2022 04:45:19 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=52
05/25/2022 04:45:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=52
05/25/2022 04:45:46 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.5590104009116941 on epoch=52
05/25/2022 04:45:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
05/25/2022 04:45:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=53
05/25/2022 04:45:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=53
05/25/2022 04:45:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=53
05/25/2022 04:45:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.13 on epoch=53
05/25/2022 04:46:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:46:00 - INFO - __main__ - Printing 3 examples
05/25/2022 04:46:00 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 04:46:00 - INFO - __main__ - ['Plant']
05/25/2022 04:46:00 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 04:46:00 - INFO - __main__ - ['Plant']
05/25/2022 04:46:00 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 04:46:00 - INFO - __main__ - ['Plant']
05/25/2022 04:46:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:46:00 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:46:01 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 04:46:01 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:46:01 - INFO - __main__ - Printing 3 examples
05/25/2022 04:46:01 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 04:46:01 - INFO - __main__ - ['Plant']
05/25/2022 04:46:01 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 04:46:01 - INFO - __main__ - ['Plant']
05/25/2022 04:46:01 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 04:46:01 - INFO - __main__ - ['Plant']
05/25/2022 04:46:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:46:02 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:46:03 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 04:46:18 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 04:46:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 04:46:19 - INFO - __main__ - Starting training!
05/25/2022 04:46:23 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.5878911133431631 on epoch=53
05/25/2022 04:46:23 - INFO - __main__ - save last model!
05/25/2022 04:46:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 04:46:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 04:46:23 - INFO - __main__ - Printing 3 examples
05/25/2022 04:46:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 04:46:23 - INFO - __main__ - ['Animal']
05/25/2022 04:46:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 04:46:23 - INFO - __main__ - ['Animal']
05/25/2022 04:46:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 04:46:23 - INFO - __main__ - ['Village']
05/25/2022 04:46:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:46:25 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:46:28 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 04:48:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_13_0.2_8_predictions.txt
05/25/2022 04:48:25 - INFO - __main__ - Classification-F1 on test data: 0.5122
05/25/2022 04:48:26 - INFO - __main__ - prefix=dbpedia_14_64_13, lr=0.2, bsz=8, dev_performance=0.6319388378247218, test_performance=0.5121934592808909
05/25/2022 04:48:26 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.5, bsz=8 ...
05/25/2022 04:48:26 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:48:26 - INFO - __main__ - Printing 3 examples
05/25/2022 04:48:26 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 04:48:26 - INFO - __main__ - ['Plant']
05/25/2022 04:48:26 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 04:48:26 - INFO - __main__ - ['Plant']
05/25/2022 04:48:26 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 04:48:26 - INFO - __main__ - ['Plant']
05/25/2022 04:48:26 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:48:27 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:48:28 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 04:48:28 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 04:48:28 - INFO - __main__ - Printing 3 examples
05/25/2022 04:48:28 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 04:48:28 - INFO - __main__ - ['Plant']
05/25/2022 04:48:28 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 04:48:28 - INFO - __main__ - ['Plant']
05/25/2022 04:48:28 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 04:48:28 - INFO - __main__ - ['Plant']
05/25/2022 04:48:28 - INFO - __main__ - Tokenizing Input ...
05/25/2022 04:48:28 - INFO - __main__ - Tokenizing Output ...
05/25/2022 04:48:29 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 04:48:44 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 04:48:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 04:48:45 - INFO - __main__ - Starting training!
05/25/2022 04:48:48 - INFO - __main__ - Step 10 Global step 10 Train loss 6.59 on epoch=0
05/25/2022 04:48:51 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=0
05/25/2022 04:48:54 - INFO - __main__ - Step 30 Global step 30 Train loss 3.72 on epoch=0
05/25/2022 04:48:56 - INFO - __main__ - Step 40 Global step 40 Train loss 3.05 on epoch=0
05/25/2022 04:48:59 - INFO - __main__ - Step 50 Global step 50 Train loss 2.95 on epoch=0
05/25/2022 04:49:25 - INFO - __main__ - Global step 50 Train loss 4.17 Classification-F1 0.024552707457267252 on epoch=0
05/25/2022 04:49:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.024552707457267252 on epoch=0, global_step=50
05/25/2022 04:49:28 - INFO - __main__ - Step 60 Global step 60 Train loss 2.59 on epoch=1
05/25/2022 04:49:30 - INFO - __main__ - Step 70 Global step 70 Train loss 2.39 on epoch=1
05/25/2022 04:49:33 - INFO - __main__ - Step 80 Global step 80 Train loss 2.11 on epoch=1
05/25/2022 04:49:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.91 on epoch=1
05/25/2022 04:49:38 - INFO - __main__ - Step 100 Global step 100 Train loss 1.76 on epoch=1
05/25/2022 04:50:01 - INFO - __main__ - Global step 100 Train loss 2.15 Classification-F1 0.06542565121697287 on epoch=1
05/25/2022 04:50:01 - INFO - __main__ - Saving model with best Classification-F1: 0.024552707457267252 -> 0.06542565121697287 on epoch=1, global_step=100
05/25/2022 04:50:03 - INFO - __main__ - Step 110 Global step 110 Train loss 1.70 on epoch=1
05/25/2022 04:50:06 - INFO - __main__ - Step 120 Global step 120 Train loss 1.43 on epoch=2
05/25/2022 04:50:08 - INFO - __main__ - Step 130 Global step 130 Train loss 1.38 on epoch=2
05/25/2022 04:50:11 - INFO - __main__ - Step 140 Global step 140 Train loss 1.29 on epoch=2
05/25/2022 04:50:13 - INFO - __main__ - Step 150 Global step 150 Train loss 1.03 on epoch=2
05/25/2022 04:50:36 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.13744218461837462 on epoch=2
05/25/2022 04:50:36 - INFO - __main__ - Saving model with best Classification-F1: 0.06542565121697287 -> 0.13744218461837462 on epoch=2, global_step=150
05/25/2022 04:50:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.03 on epoch=2
05/25/2022 04:50:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.99 on epoch=3
05/25/2022 04:50:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=3
05/25/2022 04:50:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.79 on epoch=3
05/25/2022 04:50:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=3
05/25/2022 04:51:14 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.2369081568595632 on epoch=3
05/25/2022 04:51:14 - INFO - __main__ - Saving model with best Classification-F1: 0.13744218461837462 -> 0.2369081568595632 on epoch=3, global_step=200
05/25/2022 04:51:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.59 on epoch=3
05/25/2022 04:51:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=3
05/25/2022 04:51:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.52 on epoch=4
05/25/2022 04:51:24 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=4
05/25/2022 04:51:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=4
05/25/2022 04:51:54 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.2998325168491828 on epoch=4
05/25/2022 04:51:54 - INFO - __main__ - Saving model with best Classification-F1: 0.2369081568595632 -> 0.2998325168491828 on epoch=4, global_step=250
05/25/2022 04:51:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=4
05/25/2022 04:51:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.38 on epoch=4
05/25/2022 04:52:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=4
05/25/2022 04:52:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=5
05/25/2022 04:52:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.35 on epoch=5
05/25/2022 04:52:34 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.3402082477976166 on epoch=5
05/25/2022 04:52:34 - INFO - __main__ - Saving model with best Classification-F1: 0.2998325168491828 -> 0.3402082477976166 on epoch=5, global_step=300
05/25/2022 04:52:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=5
05/25/2022 04:52:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.26 on epoch=5
05/25/2022 04:52:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=5
05/25/2022 04:52:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.33 on epoch=6
05/25/2022 04:52:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.25 on epoch=6
05/25/2022 04:53:14 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.42549933006405427 on epoch=6
05/25/2022 04:53:14 - INFO - __main__ - Saving model with best Classification-F1: 0.3402082477976166 -> 0.42549933006405427 on epoch=6, global_step=350
05/25/2022 04:53:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=6
05/25/2022 04:53:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=6
05/25/2022 04:53:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.25 on epoch=6
05/25/2022 04:53:24 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=6
05/25/2022 04:53:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.23 on epoch=7
05/25/2022 04:53:54 - INFO - __main__ - Global step 400 Train loss 0.28 Classification-F1 0.45110306324470134 on epoch=7
05/25/2022 04:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.42549933006405427 -> 0.45110306324470134 on epoch=7, global_step=400
05/25/2022 04:53:56 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=7
05/25/2022 04:53:59 - INFO - __main__ - Step 420 Global step 420 Train loss 0.26 on epoch=7
05/25/2022 04:54:01 - INFO - __main__ - Step 430 Global step 430 Train loss 0.17 on epoch=7
05/25/2022 04:54:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=7
05/25/2022 04:54:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.19 on epoch=8
05/25/2022 04:54:34 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.5384672760285902 on epoch=8
05/25/2022 04:54:34 - INFO - __main__ - Saving model with best Classification-F1: 0.45110306324470134 -> 0.5384672760285902 on epoch=8, global_step=450
05/25/2022 04:54:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.20 on epoch=8
05/25/2022 04:54:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=8
05/25/2022 04:54:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=8
05/25/2022 04:54:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=8
05/25/2022 04:54:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=8
05/25/2022 04:55:13 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.5936135738377674 on epoch=8
05/25/2022 04:55:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5384672760285902 -> 0.5936135738377674 on epoch=8, global_step=500
05/25/2022 04:55:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=9
05/25/2022 04:55:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=9
05/25/2022 04:55:21 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=9
05/25/2022 04:55:23 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=9
05/25/2022 04:55:26 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=9
05/25/2022 04:55:53 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.6308830096456765 on epoch=9
05/25/2022 04:55:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5936135738377674 -> 0.6308830096456765 on epoch=9, global_step=550
05/25/2022 04:55:56 - INFO - __main__ - Step 560 Global step 560 Train loss 0.22 on epoch=9
05/25/2022 04:55:58 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=10
05/25/2022 04:56:01 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=10
05/25/2022 04:56:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.16 on epoch=10
05/25/2022 04:56:06 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=10
05/25/2022 04:56:32 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.5673349650794527 on epoch=10
05/25/2022 04:56:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=10
05/25/2022 04:56:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=11
05/25/2022 04:56:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.14 on epoch=11
05/25/2022 04:56:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=11
05/25/2022 04:56:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=11
05/25/2022 04:57:12 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.5701886759724077 on epoch=11
05/25/2022 04:57:14 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=11
05/25/2022 04:57:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=11
05/25/2022 04:57:20 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=12
05/25/2022 04:57:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=12
05/25/2022 04:57:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=12
05/25/2022 04:57:51 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.5495378782596302 on epoch=12
05/25/2022 04:57:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=12
05/25/2022 04:57:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=12
05/25/2022 04:57:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
05/25/2022 04:58:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=13
05/25/2022 04:58:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=13
05/25/2022 04:58:29 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.5622014563948202 on epoch=13
05/25/2022 04:58:32 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=13
05/25/2022 04:58:34 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=13
05/25/2022 04:58:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=13
05/25/2022 04:58:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=14
05/25/2022 04:58:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=14
05/25/2022 04:59:09 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.5962476522993795 on epoch=14
05/25/2022 04:59:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=14
05/25/2022 04:59:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=14
05/25/2022 04:59:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=14
05/25/2022 04:59:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=14
05/25/2022 04:59:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=15
05/25/2022 04:59:47 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.7080883011190262 on epoch=15
05/25/2022 04:59:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6308830096456765 -> 0.7080883011190262 on epoch=15, global_step=850
05/25/2022 04:59:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=15
05/25/2022 04:59:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=15
05/25/2022 04:59:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=15
05/25/2022 04:59:57 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=15
05/25/2022 05:00:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=16
05/25/2022 05:00:26 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6312625728194151 on epoch=16
05/25/2022 05:00:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=16
05/25/2022 05:00:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.08 on epoch=16
05/25/2022 05:00:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=16
05/25/2022 05:00:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=16
05/25/2022 05:00:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.04 on epoch=16
05/25/2022 05:01:05 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.6438369494201026 on epoch=16
05/25/2022 05:01:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=17
05/25/2022 05:01:10 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=17
05/25/2022 05:01:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
05/25/2022 05:01:15 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=17
05/25/2022 05:01:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=17
05/25/2022 05:01:44 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.651170142459839 on epoch=17
05/25/2022 05:01:47 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=18
05/25/2022 05:01:49 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=18
05/25/2022 05:01:52 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
05/25/2022 05:01:54 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=18
05/25/2022 05:01:57 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=18
05/25/2022 05:02:22 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.668612202159669 on epoch=18
05/25/2022 05:02:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=18
05/25/2022 05:02:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=19
05/25/2022 05:02:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=19
05/25/2022 05:02:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=19
05/25/2022 05:02:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=19
05/25/2022 05:03:00 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6152930152907494 on epoch=19
05/25/2022 05:03:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=19
05/25/2022 05:03:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=19
05/25/2022 05:03:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=20
05/25/2022 05:03:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=20
05/25/2022 05:03:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=20
05/25/2022 05:03:38 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6340894541847247 on epoch=20
05/25/2022 05:03:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
05/25/2022 05:03:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=20
05/25/2022 05:03:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
05/25/2022 05:03:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=21
05/25/2022 05:03:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/25/2022 05:04:17 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7091149796032525 on epoch=21
05/25/2022 05:04:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7080883011190262 -> 0.7091149796032525 on epoch=21, global_step=1200
05/25/2022 05:04:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=21
05/25/2022 05:04:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/25/2022 05:04:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=21
05/25/2022 05:04:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=22
05/25/2022 05:04:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=22
05/25/2022 05:04:55 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.5501620010338942 on epoch=22
05/25/2022 05:04:57 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=22
05/25/2022 05:05:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=22
05/25/2022 05:05:02 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=22
05/25/2022 05:05:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=23
05/25/2022 05:05:07 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=23
05/25/2022 05:05:33 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6612440931966006 on epoch=23
05/25/2022 05:05:36 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
05/25/2022 05:05:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=23
05/25/2022 05:05:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=23
05/25/2022 05:05:44 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=23
05/25/2022 05:05:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=24
05/25/2022 05:06:12 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.5888158768187987 on epoch=24
05/25/2022 05:06:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=24
05/25/2022 05:06:17 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/25/2022 05:06:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=24
05/25/2022 05:06:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/25/2022 05:06:25 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=24
05/25/2022 05:06:50 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5933244986309285 on epoch=24
05/25/2022 05:06:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=25
05/25/2022 05:06:55 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
05/25/2022 05:06:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=25
05/25/2022 05:07:00 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
05/25/2022 05:07:03 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=25
05/25/2022 05:07:28 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.5381861346417552 on epoch=25
05/25/2022 05:07:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=26
05/25/2022 05:07:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=26
05/25/2022 05:07:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/25/2022 05:07:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=26
05/25/2022 05:07:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=26
05/25/2022 05:08:06 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.5065363222703283 on epoch=26
05/25/2022 05:08:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
05/25/2022 05:08:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
05/25/2022 05:08:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=27
05/25/2022 05:08:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
05/25/2022 05:08:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/25/2022 05:08:43 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.5960056050749035 on epoch=27
05/25/2022 05:08:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=27
05/25/2022 05:08:48 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=28
05/25/2022 05:08:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=28
05/25/2022 05:08:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=28
05/25/2022 05:08:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=28
05/25/2022 05:09:21 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6914374274436794 on epoch=28
05/25/2022 05:09:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
05/25/2022 05:09:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=28
05/25/2022 05:09:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/25/2022 05:09:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=29
05/25/2022 05:09:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=29
05/25/2022 05:10:00 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.6836417815239478 on epoch=29
05/25/2022 05:10:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
05/25/2022 05:10:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=29
05/25/2022 05:10:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=29
05/25/2022 05:10:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/25/2022 05:10:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=30
05/25/2022 05:10:37 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7463846722853628 on epoch=30
05/25/2022 05:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7091149796032525 -> 0.7463846722853628 on epoch=30, global_step=1700
05/25/2022 05:10:40 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=30
05/25/2022 05:10:43 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=30
05/25/2022 05:10:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=30
05/25/2022 05:10:48 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
05/25/2022 05:10:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
05/25/2022 05:11:15 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7884589149653355 on epoch=31
05/25/2022 05:11:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7463846722853628 -> 0.7884589149653355 on epoch=31, global_step=1750
05/25/2022 05:11:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/25/2022 05:11:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=31
05/25/2022 05:11:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
05/25/2022 05:11:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=31
05/25/2022 05:11:27 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/25/2022 05:11:52 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7014670072780397 on epoch=32
05/25/2022 05:11:55 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/25/2022 05:11:57 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=32
05/25/2022 05:12:00 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=32
05/25/2022 05:12:02 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=32
05/25/2022 05:12:05 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
05/25/2022 05:12:30 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.725589929665487 on epoch=33
05/25/2022 05:12:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
05/25/2022 05:12:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
05/25/2022 05:12:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=33
05/25/2022 05:12:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=33
05/25/2022 05:12:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/25/2022 05:13:07 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.730573046719562 on epoch=33
05/25/2022 05:13:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/25/2022 05:13:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=34
05/25/2022 05:13:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=34
05/25/2022 05:13:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=34
05/25/2022 05:13:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
05/25/2022 05:13:44 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.5943336635476816 on epoch=34
05/25/2022 05:13:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/25/2022 05:13:49 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
05/25/2022 05:13:52 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
05/25/2022 05:13:54 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/25/2022 05:13:57 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/25/2022 05:14:21 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.5829234263719086 on epoch=35
05/25/2022 05:14:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/25/2022 05:14:26 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/25/2022 05:14:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=36
05/25/2022 05:14:31 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=36
05/25/2022 05:14:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/25/2022 05:14:59 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7816236793016997 on epoch=36
05/25/2022 05:15:02 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=36
05/25/2022 05:15:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/25/2022 05:15:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/25/2022 05:15:09 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=37
05/25/2022 05:15:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
05/25/2022 05:15:37 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7274824224039913 on epoch=37
05/25/2022 05:15:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/25/2022 05:15:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=37
05/25/2022 05:15:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=38
05/25/2022 05:15:48 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=38
05/25/2022 05:15:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
05/25/2022 05:16:16 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7075697875277254 on epoch=38
05/25/2022 05:16:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 05:16:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/25/2022 05:16:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/25/2022 05:16:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/25/2022 05:16:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
05/25/2022 05:16:53 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.6712249138189122 on epoch=39
05/25/2022 05:16:56 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/25/2022 05:16:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/25/2022 05:17:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
05/25/2022 05:17:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/25/2022 05:17:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
05/25/2022 05:17:31 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8012740260369169 on epoch=40
05/25/2022 05:17:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7884589149653355 -> 0.8012740260369169 on epoch=40, global_step=2250
05/25/2022 05:17:34 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/25/2022 05:17:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/25/2022 05:17:39 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
05/25/2022 05:17:42 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 05:17:44 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/25/2022 05:18:09 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.6079154454515635 on epoch=41
05/25/2022 05:18:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/25/2022 05:18:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/25/2022 05:18:16 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/25/2022 05:18:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/25/2022 05:18:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/25/2022 05:18:46 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8886433857459082 on epoch=41
05/25/2022 05:18:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8012740260369169 -> 0.8886433857459082 on epoch=41, global_step=2350
05/25/2022 05:18:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
05/25/2022 05:18:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=42
05/25/2022 05:18:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=42
05/25/2022 05:18:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=42
05/25/2022 05:18:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/25/2022 05:19:23 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8397691263823345 on epoch=42
05/25/2022 05:19:26 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/25/2022 05:19:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=43
05/25/2022 05:19:31 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/25/2022 05:19:34 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/25/2022 05:19:36 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/25/2022 05:20:01 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7825831618328003 on epoch=43
05/25/2022 05:20:03 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 05:20:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/25/2022 05:20:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
05/25/2022 05:20:11 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=44
05/25/2022 05:20:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
05/25/2022 05:20:38 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8508407508052516 on epoch=44
05/25/2022 05:20:40 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
05/25/2022 05:20:43 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
05/25/2022 05:20:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/25/2022 05:20:48 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/25/2022 05:20:51 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/25/2022 05:21:15 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7845566096570005 on epoch=45
05/25/2022 05:21:18 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/25/2022 05:21:20 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
05/25/2022 05:21:23 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 05:21:25 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
05/25/2022 05:21:28 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/25/2022 05:21:52 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7826343845592458 on epoch=46
05/25/2022 05:21:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/25/2022 05:21:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/25/2022 05:22:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/25/2022 05:22:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
05/25/2022 05:22:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
05/25/2022 05:22:29 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.6758708559890807 on epoch=47
05/25/2022 05:22:32 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=47
05/25/2022 05:22:34 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/25/2022 05:22:37 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/25/2022 05:22:39 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=48
05/25/2022 05:22:42 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=48
05/25/2022 05:23:06 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.732273376893954 on epoch=48
05/25/2022 05:23:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/25/2022 05:23:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=48
05/25/2022 05:23:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
05/25/2022 05:23:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/25/2022 05:23:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/25/2022 05:23:44 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9132721792702548 on epoch=49
05/25/2022 05:23:44 - INFO - __main__ - Saving model with best Classification-F1: 0.8886433857459082 -> 0.9132721792702548 on epoch=49, global_step=2750
05/25/2022 05:23:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
05/25/2022 05:23:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/25/2022 05:23:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/25/2022 05:23:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/25/2022 05:23:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/25/2022 05:24:21 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8442578879734148 on epoch=49
05/25/2022 05:24:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/25/2022 05:24:27 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/25/2022 05:24:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 05:24:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/25/2022 05:24:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=50
05/25/2022 05:24:59 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8397938026235146 on epoch=50
05/25/2022 05:25:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/25/2022 05:25:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=51
05/25/2022 05:25:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
05/25/2022 05:25:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 05:25:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/25/2022 05:25:36 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6733786459559604 on epoch=51
05/25/2022 05:25:38 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 05:25:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 05:25:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
05/25/2022 05:25:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/25/2022 05:25:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/25/2022 05:26:13 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.6749132115956866 on epoch=52
05/25/2022 05:26:16 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/25/2022 05:26:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/25/2022 05:26:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/25/2022 05:26:24 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/25/2022 05:26:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
05/25/2022 05:26:28 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 05:26:28 - INFO - __main__ - Printing 3 examples
05/25/2022 05:26:28 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 05:26:28 - INFO - __main__ - ['Plant']
05/25/2022 05:26:28 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 05:26:28 - INFO - __main__ - ['Plant']
05/25/2022 05:26:28 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 05:26:28 - INFO - __main__ - ['Plant']
05/25/2022 05:26:28 - INFO - __main__ - Tokenizing Input ...
05/25/2022 05:26:28 - INFO - __main__ - Tokenizing Output ...
05/25/2022 05:26:29 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 05:26:29 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 05:26:29 - INFO - __main__ - Printing 3 examples
05/25/2022 05:26:29 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 05:26:29 - INFO - __main__ - ['Plant']
05/25/2022 05:26:29 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 05:26:29 - INFO - __main__ - ['Plant']
05/25/2022 05:26:29 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 05:26:29 - INFO - __main__ - ['Plant']
05/25/2022 05:26:29 - INFO - __main__ - Tokenizing Input ...
05/25/2022 05:26:29 - INFO - __main__ - Tokenizing Output ...
05/25/2022 05:26:30 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 05:26:49 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 05:26:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 05:26:50 - INFO - __main__ - Starting training!
05/25/2022 05:26:51 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6828940927737992 on epoch=53
05/25/2022 05:26:51 - INFO - __main__ - save last model!
05/25/2022 05:26:51 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 05:26:51 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 05:26:51 - INFO - __main__ - Printing 3 examples
05/25/2022 05:26:51 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 05:26:51 - INFO - __main__ - ['Animal']
05/25/2022 05:26:51 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 05:26:51 - INFO - __main__ - ['Animal']
05/25/2022 05:26:51 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 05:26:51 - INFO - __main__ - ['Village']
05/25/2022 05:26:51 - INFO - __main__ - Tokenizing Input ...
05/25/2022 05:26:53 - INFO - __main__ - Tokenizing Output ...
05/25/2022 05:26:57 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 05:29:01 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.5_8_predictions.txt
05/25/2022 05:29:01 - INFO - __main__ - Classification-F1 on test data: 0.5052
05/25/2022 05:29:02 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.5, bsz=8, dev_performance=0.9132721792702548, test_performance=0.5052320041347209
05/25/2022 05:29:02 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.4, bsz=8 ...
05/25/2022 05:29:03 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 05:29:03 - INFO - __main__ - Printing 3 examples
05/25/2022 05:29:03 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 05:29:03 - INFO - __main__ - ['Plant']
05/25/2022 05:29:03 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 05:29:03 - INFO - __main__ - ['Plant']
05/25/2022 05:29:03 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 05:29:03 - INFO - __main__ - ['Plant']
05/25/2022 05:29:03 - INFO - __main__ - Tokenizing Input ...
05/25/2022 05:29:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 05:29:04 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 05:29:04 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 05:29:04 - INFO - __main__ - Printing 3 examples
05/25/2022 05:29:04 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 05:29:04 - INFO - __main__ - ['Plant']
05/25/2022 05:29:04 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 05:29:04 - INFO - __main__ - ['Plant']
05/25/2022 05:29:04 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 05:29:04 - INFO - __main__ - ['Plant']
05/25/2022 05:29:04 - INFO - __main__ - Tokenizing Input ...
05/25/2022 05:29:05 - INFO - __main__ - Tokenizing Output ...
05/25/2022 05:29:06 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 05:29:24 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 05:29:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 05:29:25 - INFO - __main__ - Starting training!
05/25/2022 05:29:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.62 on epoch=0
05/25/2022 05:29:32 - INFO - __main__ - Step 20 Global step 20 Train loss 4.81 on epoch=0
05/25/2022 05:29:34 - INFO - __main__ - Step 30 Global step 30 Train loss 4.20 on epoch=0
05/25/2022 05:29:37 - INFO - __main__ - Step 40 Global step 40 Train loss 3.34 on epoch=0
05/25/2022 05:29:39 - INFO - __main__ - Step 50 Global step 50 Train loss 3.32 on epoch=0
05/25/2022 05:30:06 - INFO - __main__ - Global step 50 Train loss 4.66 Classification-F1 0.018492753812377662 on epoch=0
05/25/2022 05:30:06 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.018492753812377662 on epoch=0, global_step=50
05/25/2022 05:30:09 - INFO - __main__ - Step 60 Global step 60 Train loss 3.00 on epoch=1
05/25/2022 05:30:12 - INFO - __main__ - Step 70 Global step 70 Train loss 2.64 on epoch=1
05/25/2022 05:30:14 - INFO - __main__ - Step 80 Global step 80 Train loss 2.23 on epoch=1
05/25/2022 05:30:17 - INFO - __main__ - Step 90 Global step 90 Train loss 2.00 on epoch=1
05/25/2022 05:30:20 - INFO - __main__ - Step 100 Global step 100 Train loss 1.97 on epoch=1
05/25/2022 05:30:43 - INFO - __main__ - Global step 100 Train loss 2.37 Classification-F1 0.04661940255390731 on epoch=1
05/25/2022 05:30:43 - INFO - __main__ - Saving model with best Classification-F1: 0.018492753812377662 -> 0.04661940255390731 on epoch=1, global_step=100
05/25/2022 05:30:46 - INFO - __main__ - Step 110 Global step 110 Train loss 2.02 on epoch=1
05/25/2022 05:30:49 - INFO - __main__ - Step 120 Global step 120 Train loss 1.64 on epoch=2
05/25/2022 05:30:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.89 on epoch=2
05/25/2022 05:30:54 - INFO - __main__ - Step 140 Global step 140 Train loss 1.62 on epoch=2
05/25/2022 05:30:56 - INFO - __main__ - Step 150 Global step 150 Train loss 1.30 on epoch=2
05/25/2022 05:31:19 - INFO - __main__ - Global step 150 Train loss 1.69 Classification-F1 0.08513663304199798 on epoch=2
05/25/2022 05:31:19 - INFO - __main__ - Saving model with best Classification-F1: 0.04661940255390731 -> 0.08513663304199798 on epoch=2, global_step=150
05/25/2022 05:31:22 - INFO - __main__ - Step 160 Global step 160 Train loss 1.31 on epoch=2
05/25/2022 05:31:24 - INFO - __main__ - Step 170 Global step 170 Train loss 1.36 on epoch=3
05/25/2022 05:31:27 - INFO - __main__ - Step 180 Global step 180 Train loss 1.20 on epoch=3
05/25/2022 05:31:29 - INFO - __main__ - Step 190 Global step 190 Train loss 0.99 on epoch=3
05/25/2022 05:31:32 - INFO - __main__ - Step 200 Global step 200 Train loss 1.05 on epoch=3
05/25/2022 05:31:54 - INFO - __main__ - Global step 200 Train loss 1.18 Classification-F1 0.1617629669533423 on epoch=3
05/25/2022 05:31:54 - INFO - __main__ - Saving model with best Classification-F1: 0.08513663304199798 -> 0.1617629669533423 on epoch=3, global_step=200
05/25/2022 05:31:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.89 on epoch=3
05/25/2022 05:31:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.85 on epoch=3
05/25/2022 05:32:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=4
05/25/2022 05:32:05 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=4
05/25/2022 05:32:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=4
05/25/2022 05:32:31 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.23291840205733022 on epoch=4
05/25/2022 05:32:31 - INFO - __main__ - Saving model with best Classification-F1: 0.1617629669533423 -> 0.23291840205733022 on epoch=4, global_step=250
05/25/2022 05:32:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.62 on epoch=4
05/25/2022 05:32:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=4
05/25/2022 05:32:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.52 on epoch=4
05/25/2022 05:32:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=5
05/25/2022 05:32:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=5
05/25/2022 05:33:09 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.2711381410501623 on epoch=5
05/25/2022 05:33:09 - INFO - __main__ - Saving model with best Classification-F1: 0.23291840205733022 -> 0.2711381410501623 on epoch=5, global_step=300
05/25/2022 05:33:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=5
05/25/2022 05:33:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.41 on epoch=5
05/25/2022 05:33:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=5
05/25/2022 05:33:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=6
05/25/2022 05:33:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.37 on epoch=6
05/25/2022 05:33:48 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.32847820558594876 on epoch=6
05/25/2022 05:33:48 - INFO - __main__ - Saving model with best Classification-F1: 0.2711381410501623 -> 0.32847820558594876 on epoch=6, global_step=350
05/25/2022 05:33:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=6
05/25/2022 05:33:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.37 on epoch=6
05/25/2022 05:33:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=6
05/25/2022 05:33:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=6
05/25/2022 05:34:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=7
05/25/2022 05:34:28 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.42687010025599365 on epoch=7
05/25/2022 05:34:28 - INFO - __main__ - Saving model with best Classification-F1: 0.32847820558594876 -> 0.42687010025599365 on epoch=7, global_step=400
05/25/2022 05:34:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=7
05/25/2022 05:34:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.34 on epoch=7
05/25/2022 05:34:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.25 on epoch=7
05/25/2022 05:34:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=7
05/25/2022 05:34:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=8
05/25/2022 05:35:08 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.43949554319615036 on epoch=8
05/25/2022 05:35:08 - INFO - __main__ - Saving model with best Classification-F1: 0.42687010025599365 -> 0.43949554319615036 on epoch=8, global_step=450
05/25/2022 05:35:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=8
05/25/2022 05:35:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=8
05/25/2022 05:35:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=8
05/25/2022 05:35:19 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=8
05/25/2022 05:35:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=8
05/25/2022 05:35:48 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.5299360859625181 on epoch=8
05/25/2022 05:35:48 - INFO - __main__ - Saving model with best Classification-F1: 0.43949554319615036 -> 0.5299360859625181 on epoch=8, global_step=500
05/25/2022 05:35:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.21 on epoch=9
05/25/2022 05:35:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=9
05/25/2022 05:35:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=9
05/25/2022 05:35:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.18 on epoch=9
05/25/2022 05:36:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=9
05/25/2022 05:36:27 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.5625970514728891 on epoch=9
05/25/2022 05:36:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5299360859625181 -> 0.5625970514728891 on epoch=9, global_step=550
05/25/2022 05:36:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=9
05/25/2022 05:36:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=10
05/25/2022 05:36:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=10
05/25/2022 05:36:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=10
05/25/2022 05:36:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=10
05/25/2022 05:37:06 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.650667541551558 on epoch=10
05/25/2022 05:37:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5625970514728891 -> 0.650667541551558 on epoch=10, global_step=600
05/25/2022 05:37:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=10
05/25/2022 05:37:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
05/25/2022 05:37:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=11
05/25/2022 05:37:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=11
05/25/2022 05:37:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=11
05/25/2022 05:37:45 - INFO - __main__ - Global step 650 Train loss 0.19 Classification-F1 0.4986485758788155 on epoch=11
05/25/2022 05:37:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=11
05/25/2022 05:37:50 - INFO - __main__ - Step 670 Global step 670 Train loss 0.21 on epoch=11
05/25/2022 05:37:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.13 on epoch=12
05/25/2022 05:37:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=12
05/25/2022 05:37:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=12
05/25/2022 05:38:24 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.5437342003305974 on epoch=12
05/25/2022 05:38:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=12
05/25/2022 05:38:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=12
05/25/2022 05:38:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=13
05/25/2022 05:38:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=13
05/25/2022 05:38:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=13
05/25/2022 05:39:03 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.6096051789489556 on epoch=13
05/25/2022 05:39:06 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=13
05/25/2022 05:39:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=13
05/25/2022 05:39:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=13
05/25/2022 05:39:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=14
05/25/2022 05:39:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=14
05/25/2022 05:39:42 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.5813256904213211 on epoch=14
05/25/2022 05:39:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=14
05/25/2022 05:39:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=14
05/25/2022 05:39:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=14
05/25/2022 05:39:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=14
05/25/2022 05:39:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=15
05/25/2022 05:40:21 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.5589368490974235 on epoch=15
05/25/2022 05:40:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=15
05/25/2022 05:40:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=15
05/25/2022 05:40:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
05/25/2022 05:40:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=15
05/25/2022 05:40:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=16
05/25/2022 05:41:00 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.6134682727597109 on epoch=16
05/25/2022 05:41:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=16
05/25/2022 05:41:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.13 on epoch=16
05/25/2022 05:41:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=16
05/25/2022 05:41:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/25/2022 05:41:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=16
05/25/2022 05:41:38 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.6668783419811796 on epoch=16
05/25/2022 05:41:38 - INFO - __main__ - Saving model with best Classification-F1: 0.650667541551558 -> 0.6668783419811796 on epoch=16, global_step=950
05/25/2022 05:41:41 - INFO - __main__ - Step 960 Global step 960 Train loss 0.09 on epoch=17
05/25/2022 05:41:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=17
05/25/2022 05:41:46 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=17
05/25/2022 05:41:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=17
05/25/2022 05:41:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=17
05/25/2022 05:42:16 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6405621942413408 on epoch=17
05/25/2022 05:42:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=18
05/25/2022 05:42:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=18
05/25/2022 05:42:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=18
05/25/2022 05:42:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
05/25/2022 05:42:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=18
05/25/2022 05:42:54 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.5864957000981583 on epoch=18
05/25/2022 05:42:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=18
05/25/2022 05:42:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=19
05/25/2022 05:43:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=19
05/25/2022 05:43:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=19
05/25/2022 05:43:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/25/2022 05:43:32 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6047411862537044 on epoch=19
05/25/2022 05:43:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=19
05/25/2022 05:43:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=19
05/25/2022 05:43:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/25/2022 05:43:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=20
05/25/2022 05:43:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=20
05/25/2022 05:44:10 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.5842802585136343 on epoch=20
05/25/2022 05:44:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=20
05/25/2022 05:44:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=20
05/25/2022 05:44:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=21
05/25/2022 05:44:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=21
05/25/2022 05:44:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/25/2022 05:44:49 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.7457141275768285 on epoch=21
05/25/2022 05:44:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6668783419811796 -> 0.7457141275768285 on epoch=21, global_step=1200
05/25/2022 05:44:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=21
05/25/2022 05:44:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/25/2022 05:44:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=21
05/25/2022 05:44:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
05/25/2022 05:45:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=22
05/25/2022 05:45:28 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7448882337311878 on epoch=22
05/25/2022 05:45:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=22
05/25/2022 05:45:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
05/25/2022 05:45:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=22
05/25/2022 05:45:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=23
05/25/2022 05:45:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=23
05/25/2022 05:46:07 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7319654706395362 on epoch=23
05/25/2022 05:46:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=23
05/25/2022 05:46:12 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=23
05/25/2022 05:46:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
05/25/2022 05:46:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
05/25/2022 05:46:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=24
05/25/2022 05:46:45 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6750575325747387 on epoch=24
05/25/2022 05:46:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=24
05/25/2022 05:46:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=24
05/25/2022 05:46:53 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=24
05/25/2022 05:46:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
05/25/2022 05:46:58 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=24
05/25/2022 05:47:23 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7501100841048943 on epoch=24
05/25/2022 05:47:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7457141275768285 -> 0.7501100841048943 on epoch=24, global_step=1400
05/25/2022 05:47:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=25
05/25/2022 05:47:29 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=25
05/25/2022 05:47:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=25
05/25/2022 05:47:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=25
05/25/2022 05:47:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=25
05/25/2022 05:48:02 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.786929103335671 on epoch=25
05/25/2022 05:48:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7501100841048943 -> 0.786929103335671 on epoch=25, global_step=1450
05/25/2022 05:48:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=26
05/25/2022 05:48:07 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=26
05/25/2022 05:48:10 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=26
05/25/2022 05:48:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=26
05/25/2022 05:48:15 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 05:48:40 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7335193547046016 on epoch=26
05/25/2022 05:48:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
05/25/2022 05:48:45 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
05/25/2022 05:48:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=27
05/25/2022 05:48:50 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=27
05/25/2022 05:48:53 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=27
05/25/2022 05:49:18 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8008096037394036 on epoch=27
05/25/2022 05:49:18 - INFO - __main__ - Saving model with best Classification-F1: 0.786929103335671 -> 0.8008096037394036 on epoch=27, global_step=1550
05/25/2022 05:49:21 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=27
05/25/2022 05:49:23 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=28
05/25/2022 05:49:26 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=28
05/25/2022 05:49:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=28
05/25/2022 05:49:31 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
05/25/2022 05:49:57 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7452099704208955 on epoch=28
05/25/2022 05:49:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=28
05/25/2022 05:50:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=28
05/25/2022 05:50:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=29
05/25/2022 05:50:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/25/2022 05:50:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=29
05/25/2022 05:50:35 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7539226652781862 on epoch=29
05/25/2022 05:50:37 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
05/25/2022 05:50:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
05/25/2022 05:50:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
05/25/2022 05:50:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
05/25/2022 05:50:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=30
05/25/2022 05:51:13 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6818883920396578 on epoch=30
05/25/2022 05:51:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=30
05/25/2022 05:51:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=30
05/25/2022 05:51:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/25/2022 05:51:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
05/25/2022 05:51:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=31
05/25/2022 05:51:52 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7599101084182952 on epoch=31
05/25/2022 05:51:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/25/2022 05:51:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
05/25/2022 05:52:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=31
05/25/2022 05:52:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=31
05/25/2022 05:52:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=32
05/25/2022 05:52:31 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7078997897919329 on epoch=32
05/25/2022 05:52:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
05/25/2022 05:52:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/25/2022 05:52:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
05/25/2022 05:52:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
05/25/2022 05:52:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/25/2022 05:53:08 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7087849811843788 on epoch=33
05/25/2022 05:53:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/25/2022 05:53:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=33
05/25/2022 05:53:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 05:53:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=33
05/25/2022 05:53:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/25/2022 05:53:46 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6721218742009742 on epoch=33
05/25/2022 05:53:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=34
05/25/2022 05:53:51 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=34
05/25/2022 05:53:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=34
05/25/2022 05:53:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/25/2022 05:53:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
05/25/2022 05:54:24 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7469252085132977 on epoch=34
05/25/2022 05:54:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=34
05/25/2022 05:54:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=35
05/25/2022 05:54:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=35
05/25/2022 05:54:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/25/2022 05:54:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/25/2022 05:55:03 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7934498627920086 on epoch=35
05/25/2022 05:55:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/25/2022 05:55:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/25/2022 05:55:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=36
05/25/2022 05:55:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/25/2022 05:55:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=36
05/25/2022 05:55:41 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7981326686506868 on epoch=36
05/25/2022 05:55:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
05/25/2022 05:55:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/25/2022 05:55:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=37
05/25/2022 05:55:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
05/25/2022 05:55:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
05/25/2022 05:56:19 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8459260134566069 on epoch=37
05/25/2022 05:56:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8008096037394036 -> 0.8459260134566069 on epoch=37, global_step=2100
05/25/2022 05:56:22 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/25/2022 05:56:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=37
05/25/2022 05:56:27 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=38
05/25/2022 05:56:30 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/25/2022 05:56:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=38
05/25/2022 05:56:57 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7071278010055797 on epoch=38
05/25/2022 05:57:00 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 05:57:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
05/25/2022 05:57:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/25/2022 05:57:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/25/2022 05:57:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
05/25/2022 05:57:35 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.781699428688035 on epoch=39
05/25/2022 05:57:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/25/2022 05:57:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
05/25/2022 05:57:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=39
05/25/2022 05:57:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
05/25/2022 05:57:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=40
05/25/2022 05:58:14 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7879369060609434 on epoch=40
05/25/2022 05:58:17 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
05/25/2022 05:58:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=40
05/25/2022 05:58:22 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
05/25/2022 05:58:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 05:58:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=41
05/25/2022 05:58:52 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.7359088313697907 on epoch=41
05/25/2022 05:58:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=41
05/25/2022 05:58:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/25/2022 05:59:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=41
05/25/2022 05:59:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/25/2022 05:59:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/25/2022 05:59:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7572773477583117 on epoch=41
05/25/2022 05:59:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
05/25/2022 05:59:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=42
05/25/2022 05:59:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/25/2022 05:59:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=42
05/25/2022 05:59:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
05/25/2022 06:00:08 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7019828410114294 on epoch=42
05/25/2022 06:00:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/25/2022 06:00:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=43
05/25/2022 06:00:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=43
05/25/2022 06:00:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=43
05/25/2022 06:00:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
05/25/2022 06:00:46 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6689719827275905 on epoch=43
05/25/2022 06:00:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=43
05/25/2022 06:00:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=44
05/25/2022 06:00:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=44
05/25/2022 06:00:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/25/2022 06:00:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/25/2022 06:01:24 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6964893798805455 on epoch=44
05/25/2022 06:01:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/25/2022 06:01:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
05/25/2022 06:01:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/25/2022 06:01:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=45
05/25/2022 06:01:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
05/25/2022 06:02:02 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7026492688347874 on epoch=45
05/25/2022 06:02:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/25/2022 06:02:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/25/2022 06:02:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 06:02:13 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/25/2022 06:02:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=46
05/25/2022 06:02:41 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7430633336322772 on epoch=46
05/25/2022 06:02:44 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=46
05/25/2022 06:02:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=46
05/25/2022 06:02:49 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/25/2022 06:02:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
05/25/2022 06:02:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=47
05/25/2022 06:03:19 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7350364367231899 on epoch=47
05/25/2022 06:03:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/25/2022 06:03:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/25/2022 06:03:27 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=47
05/25/2022 06:03:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 06:03:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/25/2022 06:03:57 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6864961308347243 on epoch=48
05/25/2022 06:04:00 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/25/2022 06:04:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=48
05/25/2022 06:04:05 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
05/25/2022 06:04:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/25/2022 06:04:10 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
05/25/2022 06:04:35 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6246551164768528 on epoch=49
05/25/2022 06:04:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
05/25/2022 06:04:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/25/2022 06:04:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/25/2022 06:04:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/25/2022 06:04:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/25/2022 06:05:13 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7772427447976923 on epoch=49
05/25/2022 06:05:15 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/25/2022 06:05:18 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/25/2022 06:05:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 06:05:23 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/25/2022 06:05:26 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=50
05/25/2022 06:05:50 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7683960992879679 on epoch=50
05/25/2022 06:05:53 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/25/2022 06:05:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/25/2022 06:05:58 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/25/2022 06:06:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/25/2022 06:06:03 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/25/2022 06:06:28 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.657395461219735 on epoch=51
05/25/2022 06:06:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/25/2022 06:06:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=52
05/25/2022 06:06:36 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/25/2022 06:06:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/25/2022 06:06:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/25/2022 06:07:06 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.668169137699734 on epoch=52
05/25/2022 06:07:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
05/25/2022 06:07:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/25/2022 06:07:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=53
05/25/2022 06:07:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/25/2022 06:07:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/25/2022 06:07:21 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:07:21 - INFO - __main__ - Printing 3 examples
05/25/2022 06:07:21 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 06:07:21 - INFO - __main__ - ['Plant']
05/25/2022 06:07:21 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 06:07:21 - INFO - __main__ - ['Plant']
05/25/2022 06:07:21 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 06:07:21 - INFO - __main__ - ['Plant']
05/25/2022 06:07:21 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:07:21 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:07:22 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 06:07:22 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:07:22 - INFO - __main__ - Printing 3 examples
05/25/2022 06:07:22 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 06:07:22 - INFO - __main__ - ['Plant']
05/25/2022 06:07:22 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 06:07:22 - INFO - __main__ - ['Plant']
05/25/2022 06:07:22 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 06:07:22 - INFO - __main__ - ['Plant']
05/25/2022 06:07:22 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:07:22 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:07:23 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 06:07:42 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 06:07:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 06:07:43 - INFO - __main__ - Starting training!
05/25/2022 06:07:45 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.737869581136325 on epoch=53
05/25/2022 06:07:45 - INFO - __main__ - save last model!
05/25/2022 06:07:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 06:07:45 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 06:07:45 - INFO - __main__ - Printing 3 examples
05/25/2022 06:07:45 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 06:07:45 - INFO - __main__ - ['Animal']
05/25/2022 06:07:45 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 06:07:45 - INFO - __main__ - ['Animal']
05/25/2022 06:07:45 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 06:07:45 - INFO - __main__ - ['Village']
05/25/2022 06:07:45 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:07:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:07:50 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 06:09:52 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.4_8_predictions.txt
05/25/2022 06:09:52 - INFO - __main__ - Classification-F1 on test data: 0.5108
05/25/2022 06:09:53 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.4, bsz=8, dev_performance=0.8459260134566069, test_performance=0.5108328928876176
05/25/2022 06:09:53 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.3, bsz=8 ...
05/25/2022 06:09:54 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:09:54 - INFO - __main__ - Printing 3 examples
05/25/2022 06:09:54 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 06:09:54 - INFO - __main__ - ['Plant']
05/25/2022 06:09:54 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 06:09:54 - INFO - __main__ - ['Plant']
05/25/2022 06:09:54 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 06:09:54 - INFO - __main__ - ['Plant']
05/25/2022 06:09:54 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:09:54 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:09:55 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 06:09:55 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:09:55 - INFO - __main__ - Printing 3 examples
05/25/2022 06:09:55 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 06:09:55 - INFO - __main__ - ['Plant']
05/25/2022 06:09:55 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 06:09:55 - INFO - __main__ - ['Plant']
05/25/2022 06:09:55 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 06:09:55 - INFO - __main__ - ['Plant']
05/25/2022 06:09:55 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:09:56 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:09:57 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 06:10:15 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 06:10:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 06:10:16 - INFO - __main__ - Starting training!
05/25/2022 06:10:20 - INFO - __main__ - Step 10 Global step 10 Train loss 7.42 on epoch=0
05/25/2022 06:10:23 - INFO - __main__ - Step 20 Global step 20 Train loss 5.61 on epoch=0
05/25/2022 06:10:25 - INFO - __main__ - Step 30 Global step 30 Train loss 4.73 on epoch=0
05/25/2022 06:10:28 - INFO - __main__ - Step 40 Global step 40 Train loss 3.94 on epoch=0
05/25/2022 06:10:31 - INFO - __main__ - Step 50 Global step 50 Train loss 3.91 on epoch=0
05/25/2022 06:10:57 - INFO - __main__ - Global step 50 Train loss 5.12 Classification-F1 0.014235730925570612 on epoch=0
05/25/2022 06:10:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.014235730925570612 on epoch=0, global_step=50
05/25/2022 06:11:00 - INFO - __main__ - Step 60 Global step 60 Train loss 3.37 on epoch=1
05/25/2022 06:11:03 - INFO - __main__ - Step 70 Global step 70 Train loss 3.22 on epoch=1
05/25/2022 06:11:05 - INFO - __main__ - Step 80 Global step 80 Train loss 2.79 on epoch=1
05/25/2022 06:11:08 - INFO - __main__ - Step 90 Global step 90 Train loss 2.54 on epoch=1
05/25/2022 06:11:11 - INFO - __main__ - Step 100 Global step 100 Train loss 2.37 on epoch=1
05/25/2022 06:11:36 - INFO - __main__ - Global step 100 Train loss 2.86 Classification-F1 0.03056541635846367 on epoch=1
05/25/2022 06:11:36 - INFO - __main__ - Saving model with best Classification-F1: 0.014235730925570612 -> 0.03056541635846367 on epoch=1, global_step=100
05/25/2022 06:11:39 - INFO - __main__ - Step 110 Global step 110 Train loss 2.40 on epoch=1
05/25/2022 06:11:42 - INFO - __main__ - Step 120 Global step 120 Train loss 2.06 on epoch=2
05/25/2022 06:11:45 - INFO - __main__ - Step 130 Global step 130 Train loss 2.04 on epoch=2
05/25/2022 06:11:47 - INFO - __main__ - Step 140 Global step 140 Train loss 1.94 on epoch=2
05/25/2022 06:11:50 - INFO - __main__ - Step 150 Global step 150 Train loss 1.72 on epoch=2
05/25/2022 06:12:13 - INFO - __main__ - Global step 150 Train loss 2.03 Classification-F1 0.06009150737835014 on epoch=2
05/25/2022 06:12:13 - INFO - __main__ - Saving model with best Classification-F1: 0.03056541635846367 -> 0.06009150737835014 on epoch=2, global_step=150
05/25/2022 06:12:15 - INFO - __main__ - Step 160 Global step 160 Train loss 1.68 on epoch=2
05/25/2022 06:12:18 - INFO - __main__ - Step 170 Global step 170 Train loss 1.73 on epoch=3
05/25/2022 06:12:21 - INFO - __main__ - Step 180 Global step 180 Train loss 1.56 on epoch=3
05/25/2022 06:12:23 - INFO - __main__ - Step 190 Global step 190 Train loss 1.45 on epoch=3
05/25/2022 06:12:26 - INFO - __main__ - Step 200 Global step 200 Train loss 1.46 on epoch=3
05/25/2022 06:12:49 - INFO - __main__ - Global step 200 Train loss 1.58 Classification-F1 0.10080006018018643 on epoch=3
05/25/2022 06:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.06009150737835014 -> 0.10080006018018643 on epoch=3, global_step=200
05/25/2022 06:12:51 - INFO - __main__ - Step 210 Global step 210 Train loss 1.31 on epoch=3
05/25/2022 06:12:54 - INFO - __main__ - Step 220 Global step 220 Train loss 1.46 on epoch=3
05/25/2022 06:12:56 - INFO - __main__ - Step 230 Global step 230 Train loss 1.18 on epoch=4
05/25/2022 06:12:59 - INFO - __main__ - Step 240 Global step 240 Train loss 1.09 on epoch=4
05/25/2022 06:13:01 - INFO - __main__ - Step 250 Global step 250 Train loss 1.10 on epoch=4
05/25/2022 06:13:24 - INFO - __main__ - Global step 250 Train loss 1.23 Classification-F1 0.15556123377955117 on epoch=4
05/25/2022 06:13:24 - INFO - __main__ - Saving model with best Classification-F1: 0.10080006018018643 -> 0.15556123377955117 on epoch=4, global_step=250
05/25/2022 06:13:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.98 on epoch=4
05/25/2022 06:13:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.82 on epoch=4
05/25/2022 06:13:31 - INFO - __main__ - Step 280 Global step 280 Train loss 1.03 on epoch=4
05/25/2022 06:13:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.84 on epoch=5
05/25/2022 06:13:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.74 on epoch=5
05/25/2022 06:13:59 - INFO - __main__ - Global step 300 Train loss 0.88 Classification-F1 0.22630066186819664 on epoch=5
05/25/2022 06:13:59 - INFO - __main__ - Saving model with best Classification-F1: 0.15556123377955117 -> 0.22630066186819664 on epoch=5, global_step=300
05/25/2022 06:14:02 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=5
05/25/2022 06:14:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.60 on epoch=5
05/25/2022 06:14:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.77 on epoch=5
05/25/2022 06:14:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=6
05/25/2022 06:14:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.57 on epoch=6
05/25/2022 06:14:37 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.25224181042171767 on epoch=6
05/25/2022 06:14:37 - INFO - __main__ - Saving model with best Classification-F1: 0.22630066186819664 -> 0.25224181042171767 on epoch=6, global_step=350
05/25/2022 06:14:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.65 on epoch=6
05/25/2022 06:14:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=6
05/25/2022 06:14:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=6
05/25/2022 06:14:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=6
05/25/2022 06:14:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=7
05/25/2022 06:15:16 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.315479789377091 on epoch=7
05/25/2022 06:15:16 - INFO - __main__ - Saving model with best Classification-F1: 0.25224181042171767 -> 0.315479789377091 on epoch=7, global_step=400
05/25/2022 06:15:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.57 on epoch=7
05/25/2022 06:15:21 - INFO - __main__ - Step 420 Global step 420 Train loss 0.55 on epoch=7
05/25/2022 06:15:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=7
05/25/2022 06:15:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.43 on epoch=7
05/25/2022 06:15:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.45 on epoch=8
05/25/2022 06:15:56 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.3816717655676859 on epoch=8
05/25/2022 06:15:56 - INFO - __main__ - Saving model with best Classification-F1: 0.315479789377091 -> 0.3816717655676859 on epoch=8, global_step=450
05/25/2022 06:15:58 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=8
05/25/2022 06:16:01 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=8
05/25/2022 06:16:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=8
05/25/2022 06:16:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=8
05/25/2022 06:16:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=8
05/25/2022 06:16:35 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.39101212003872743 on epoch=8
05/25/2022 06:16:35 - INFO - __main__ - Saving model with best Classification-F1: 0.3816717655676859 -> 0.39101212003872743 on epoch=8, global_step=500
05/25/2022 06:16:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.40 on epoch=9
05/25/2022 06:16:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=9
05/25/2022 06:16:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=9
05/25/2022 06:16:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=9
05/25/2022 06:16:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=9
05/25/2022 06:17:15 - INFO - __main__ - Global step 550 Train loss 0.35 Classification-F1 0.4365528656863009 on epoch=9
05/25/2022 06:17:15 - INFO - __main__ - Saving model with best Classification-F1: 0.39101212003872743 -> 0.4365528656863009 on epoch=9, global_step=550
05/25/2022 06:17:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=9
05/25/2022 06:17:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.22 on epoch=10
05/25/2022 06:17:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=10
05/25/2022 06:17:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=10
05/25/2022 06:17:28 - INFO - __main__ - Step 600 Global step 600 Train loss 0.22 on epoch=10
05/25/2022 06:17:53 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.452582908417422 on epoch=10
05/25/2022 06:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4365528656863009 -> 0.452582908417422 on epoch=10, global_step=600
05/25/2022 06:17:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=10
05/25/2022 06:17:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=11
05/25/2022 06:18:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=11
05/25/2022 06:18:04 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=11
05/25/2022 06:18:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.24 on epoch=11
05/25/2022 06:18:33 - INFO - __main__ - Global step 650 Train loss 0.29 Classification-F1 0.5267300131507916 on epoch=11
05/25/2022 06:18:33 - INFO - __main__ - Saving model with best Classification-F1: 0.452582908417422 -> 0.5267300131507916 on epoch=11, global_step=650
05/25/2022 06:18:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=11
05/25/2022 06:18:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=11
05/25/2022 06:18:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=12
05/25/2022 06:18:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=12
05/25/2022 06:18:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=12
05/25/2022 06:19:13 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.6055821935589922 on epoch=12
05/25/2022 06:19:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5267300131507916 -> 0.6055821935589922 on epoch=12, global_step=700
05/25/2022 06:19:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=12
05/25/2022 06:19:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=12
05/25/2022 06:19:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=13
05/25/2022 06:19:24 - INFO - __main__ - Step 740 Global step 740 Train loss 0.21 on epoch=13
05/25/2022 06:19:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.26 on epoch=13
05/25/2022 06:19:52 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.6428783801702167 on epoch=13
05/25/2022 06:19:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6055821935589922 -> 0.6428783801702167 on epoch=13, global_step=750
05/25/2022 06:19:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=13
05/25/2022 06:19:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=13
05/25/2022 06:20:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=13
05/25/2022 06:20:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=14
05/25/2022 06:20:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=14
05/25/2022 06:20:33 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6150828682939214 on epoch=14
05/25/2022 06:20:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=14
05/25/2022 06:20:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=14
05/25/2022 06:20:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=14
05/25/2022 06:20:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=14
05/25/2022 06:20:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=15
05/25/2022 06:21:12 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6194411870774801 on epoch=15
05/25/2022 06:21:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.21 on epoch=15
05/25/2022 06:21:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.19 on epoch=15
05/25/2022 06:21:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=15
05/25/2022 06:21:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=15
05/25/2022 06:21:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=16
05/25/2022 06:21:52 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.5651530254973655 on epoch=16
05/25/2022 06:21:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=16
05/25/2022 06:21:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=16
05/25/2022 06:21:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=16
05/25/2022 06:22:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/25/2022 06:22:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=16
05/25/2022 06:22:31 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6660499287903193 on epoch=16
05/25/2022 06:22:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6428783801702167 -> 0.6660499287903193 on epoch=16, global_step=950
05/25/2022 06:22:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=17
05/25/2022 06:22:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=17
05/25/2022 06:22:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=17
05/25/2022 06:22:42 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=17
05/25/2022 06:22:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/25/2022 06:23:11 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6255649118956044 on epoch=17
05/25/2022 06:23:13 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=18
05/25/2022 06:23:16 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=18
05/25/2022 06:23:19 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=18
05/25/2022 06:23:21 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=18
05/25/2022 06:23:24 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=18
05/25/2022 06:23:49 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.585625746384733 on epoch=18
05/25/2022 06:23:52 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=18
05/25/2022 06:23:54 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=19
05/25/2022 06:23:57 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.13 on epoch=19
05/25/2022 06:23:59 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
05/25/2022 06:24:02 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=19
05/25/2022 06:24:28 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6214832935654571 on epoch=19
05/25/2022 06:24:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=19
05/25/2022 06:24:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=19
05/25/2022 06:24:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=20
05/25/2022 06:24:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
05/25/2022 06:24:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.19 on epoch=20
05/25/2022 06:25:06 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.5649729724481464 on epoch=20
05/25/2022 06:25:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=20
05/25/2022 06:25:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=20
05/25/2022 06:25:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=21
05/25/2022 06:25:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=21
05/25/2022 06:25:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=21
05/25/2022 06:25:44 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.6228247934209448 on epoch=21
05/25/2022 06:25:47 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=21
05/25/2022 06:25:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/25/2022 06:25:52 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.13 on epoch=21
05/25/2022 06:25:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=22
05/25/2022 06:25:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
05/25/2022 06:26:24 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.6634418963853644 on epoch=22
05/25/2022 06:26:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=22
05/25/2022 06:26:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/25/2022 06:26:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=22
05/25/2022 06:26:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=23
05/25/2022 06:26:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
05/25/2022 06:27:03 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6021173991010753 on epoch=23
05/25/2022 06:27:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=23
05/25/2022 06:27:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=23
05/25/2022 06:27:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=23
05/25/2022 06:27:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=23
05/25/2022 06:27:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/25/2022 06:27:41 - INFO - __main__ - Global step 1350 Train loss 0.12 Classification-F1 0.6115728315933223 on epoch=24
05/25/2022 06:27:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=24
05/25/2022 06:27:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=24
05/25/2022 06:27:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=24
05/25/2022 06:27:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/25/2022 06:27:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=24
05/25/2022 06:28:20 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.6240514998935149 on epoch=24
05/25/2022 06:28:22 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=25
05/25/2022 06:28:25 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=25
05/25/2022 06:28:27 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=25
05/25/2022 06:28:30 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=25
05/25/2022 06:28:32 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=25
05/25/2022 06:28:58 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.6245135526967335 on epoch=25
05/25/2022 06:29:00 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=26
05/25/2022 06:29:03 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=26
05/25/2022 06:29:05 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 06:29:08 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=26
05/25/2022 06:29:10 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 06:29:36 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.5851211942574996 on epoch=26
05/25/2022 06:29:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=26
05/25/2022 06:29:41 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=27
05/25/2022 06:29:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=27
05/25/2022 06:29:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=27
05/25/2022 06:29:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
05/25/2022 06:30:13 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6530463267527014 on epoch=27
05/25/2022 06:30:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=27
05/25/2022 06:30:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/25/2022 06:30:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=28
05/25/2022 06:30:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
05/25/2022 06:30:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=28
05/25/2022 06:30:51 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6843611231538255 on epoch=28
05/25/2022 06:30:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6660499287903193 -> 0.6843611231538255 on epoch=28, global_step=1600
05/25/2022 06:30:54 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=28
05/25/2022 06:30:56 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=28
05/25/2022 06:30:59 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=29
05/25/2022 06:31:02 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/25/2022 06:31:04 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=29
05/25/2022 06:31:29 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.7193155521585636 on epoch=29
05/25/2022 06:31:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6843611231538255 -> 0.7193155521585636 on epoch=29, global_step=1650
05/25/2022 06:31:32 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/25/2022 06:31:34 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=29
05/25/2022 06:31:37 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
05/25/2022 06:31:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=30
05/25/2022 06:31:42 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=30
05/25/2022 06:32:07 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6977771448745231 on epoch=30
05/25/2022 06:32:10 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=30
05/25/2022 06:32:12 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=30
05/25/2022 06:32:15 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=30
05/25/2022 06:32:17 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
05/25/2022 06:32:20 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
05/25/2022 06:32:45 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.6968871156674203 on epoch=31
05/25/2022 06:32:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=31
05/25/2022 06:32:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=31
05/25/2022 06:32:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=31
05/25/2022 06:32:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=31
05/25/2022 06:32:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=32
05/25/2022 06:33:23 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6713041403301115 on epoch=32
05/25/2022 06:33:26 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=32
05/25/2022 06:33:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=32
05/25/2022 06:33:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=32
05/25/2022 06:33:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=32
05/25/2022 06:33:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/25/2022 06:34:01 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6562371619405083 on epoch=33
05/25/2022 06:34:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=33
05/25/2022 06:34:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/25/2022 06:34:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=33
05/25/2022 06:34:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=33
05/25/2022 06:34:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=33
05/25/2022 06:34:40 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.6625312663759433 on epoch=33
05/25/2022 06:34:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=34
05/25/2022 06:34:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
05/25/2022 06:34:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=34
05/25/2022 06:34:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=34
05/25/2022 06:34:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=34
05/25/2022 06:35:18 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6633711880731197 on epoch=34
05/25/2022 06:35:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/25/2022 06:35:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=35
05/25/2022 06:35:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=35
05/25/2022 06:35:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=35
05/25/2022 06:35:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/25/2022 06:35:56 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.629745655671154 on epoch=35
05/25/2022 06:35:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
05/25/2022 06:36:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=36
05/25/2022 06:36:04 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=36
05/25/2022 06:36:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
05/25/2022 06:36:09 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/25/2022 06:36:34 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5367736802836807 on epoch=36
05/25/2022 06:36:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=36
05/25/2022 06:36:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
05/25/2022 06:36:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=37
05/25/2022 06:36:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=37
05/25/2022 06:36:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=37
05/25/2022 06:37:12 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5599945006066779 on epoch=37
05/25/2022 06:37:14 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/25/2022 06:37:17 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=37
05/25/2022 06:37:19 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/25/2022 06:37:22 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=38
05/25/2022 06:37:25 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/25/2022 06:37:50 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.6183261587273228 on epoch=38
05/25/2022 06:37:52 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 06:37:55 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=38
05/25/2022 06:37:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=38
05/25/2022 06:38:00 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=39
05/25/2022 06:38:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=39
05/25/2022 06:38:27 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6143496078808022 on epoch=39
05/25/2022 06:38:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/25/2022 06:38:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/25/2022 06:38:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=39
05/25/2022 06:38:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=39
05/25/2022 06:38:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
05/25/2022 06:39:06 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.65749096488901 on epoch=40
05/25/2022 06:39:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=40
05/25/2022 06:39:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/25/2022 06:39:13 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/25/2022 06:39:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=40
05/25/2022 06:39:18 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/25/2022 06:39:44 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6007797171209328 on epoch=41
05/25/2022 06:39:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
05/25/2022 06:39:49 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
05/25/2022 06:39:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=41
05/25/2022 06:39:54 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/25/2022 06:39:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/25/2022 06:40:22 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7697519944006859 on epoch=41
05/25/2022 06:40:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7193155521585636 -> 0.7697519944006859 on epoch=41, global_step=2350
05/25/2022 06:40:25 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
05/25/2022 06:40:28 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/25/2022 06:40:30 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=42
05/25/2022 06:40:33 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 06:40:35 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/25/2022 06:41:00 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6561442799993966 on epoch=42
05/25/2022 06:41:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=43
05/25/2022 06:41:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/25/2022 06:41:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=43
05/25/2022 06:41:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
05/25/2022 06:41:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
05/25/2022 06:41:38 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.6339335670480802 on epoch=43
05/25/2022 06:41:41 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=43
05/25/2022 06:41:43 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=44
05/25/2022 06:41:46 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
05/25/2022 06:41:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=44
05/25/2022 06:41:51 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/25/2022 06:42:16 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6579868218560847 on epoch=44
05/25/2022 06:42:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=44
05/25/2022 06:42:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
05/25/2022 06:42:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/25/2022 06:42:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=45
05/25/2022 06:42:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=45
05/25/2022 06:42:54 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6120477967652624 on epoch=45
05/25/2022 06:42:56 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=45
05/25/2022 06:42:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/25/2022 06:43:01 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 06:43:04 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/25/2022 06:43:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
05/25/2022 06:43:32 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5860311984625665 on epoch=46
05/25/2022 06:43:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=46
05/25/2022 06:43:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=46
05/25/2022 06:43:39 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=46
05/25/2022 06:43:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/25/2022 06:43:44 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=47
05/25/2022 06:44:09 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.5619559108311594 on epoch=47
05/25/2022 06:44:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/25/2022 06:44:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/25/2022 06:44:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/25/2022 06:44:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/25/2022 06:44:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/25/2022 06:44:47 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6150296131678062 on epoch=48
05/25/2022 06:44:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=48
05/25/2022 06:44:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/25/2022 06:44:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
05/25/2022 06:44:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=48
05/25/2022 06:45:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/25/2022 06:45:24 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6039076209682248 on epoch=49
05/25/2022 06:45:27 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/25/2022 06:45:29 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=49
05/25/2022 06:45:32 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/25/2022 06:45:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=49
05/25/2022 06:45:37 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=49
05/25/2022 06:46:02 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6433465936258453 on epoch=49
05/25/2022 06:46:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/25/2022 06:46:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=50
05/25/2022 06:46:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/25/2022 06:46:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=50
05/25/2022 06:46:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=50
05/25/2022 06:46:39 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6112362684176829 on epoch=50
05/25/2022 06:46:41 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=51
05/25/2022 06:46:44 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/25/2022 06:46:46 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=51
05/25/2022 06:46:49 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/25/2022 06:46:51 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/25/2022 06:47:16 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.580381639457779 on epoch=51
05/25/2022 06:47:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 06:47:21 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 06:47:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/25/2022 06:47:26 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=52
05/25/2022 06:47:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/25/2022 06:47:53 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6574430391387794 on epoch=52
05/25/2022 06:47:56 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=52
05/25/2022 06:47:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 06:48:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/25/2022 06:48:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/25/2022 06:48:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=53
05/25/2022 06:48:07 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:48:07 - INFO - __main__ - Printing 3 examples
05/25/2022 06:48:07 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 06:48:07 - INFO - __main__ - ['Plant']
05/25/2022 06:48:07 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 06:48:07 - INFO - __main__ - ['Plant']
05/25/2022 06:48:07 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 06:48:07 - INFO - __main__ - ['Plant']
05/25/2022 06:48:07 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:48:08 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:48:09 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 06:48:09 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:48:09 - INFO - __main__ - Printing 3 examples
05/25/2022 06:48:09 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 06:48:09 - INFO - __main__ - ['Plant']
05/25/2022 06:48:09 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 06:48:09 - INFO - __main__ - ['Plant']
05/25/2022 06:48:09 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 06:48:09 - INFO - __main__ - ['Plant']
05/25/2022 06:48:09 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:48:09 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:48:10 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 06:48:29 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 06:48:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 06:48:29 - INFO - __main__ - Starting training!
05/25/2022 06:48:31 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7215250924784185 on epoch=53
05/25/2022 06:48:31 - INFO - __main__ - save last model!
05/25/2022 06:48:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 06:48:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 06:48:31 - INFO - __main__ - Printing 3 examples
05/25/2022 06:48:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 06:48:31 - INFO - __main__ - ['Animal']
05/25/2022 06:48:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 06:48:31 - INFO - __main__ - ['Animal']
05/25/2022 06:48:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 06:48:31 - INFO - __main__ - ['Village']
05/25/2022 06:48:31 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:48:33 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:48:37 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 06:50:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.3_8_predictions.txt
05/25/2022 06:50:32 - INFO - __main__ - Classification-F1 on test data: 0.5387
05/25/2022 06:50:33 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.3, bsz=8, dev_performance=0.7697519944006859, test_performance=0.5386893271505366
05/25/2022 06:50:33 - INFO - __main__ - Running ... prefix=dbpedia_14_64_21, lr=0.2, bsz=8 ...
05/25/2022 06:50:34 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:50:34 - INFO - __main__ - Printing 3 examples
05/25/2022 06:50:34 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/25/2022 06:50:34 - INFO - __main__ - ['Plant']
05/25/2022 06:50:34 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/25/2022 06:50:34 - INFO - __main__ - ['Plant']
05/25/2022 06:50:34 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/25/2022 06:50:34 - INFO - __main__ - ['Plant']
05/25/2022 06:50:34 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:50:34 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:50:35 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 06:50:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 06:50:35 - INFO - __main__ - Printing 3 examples
05/25/2022 06:50:35 - INFO - __main__ -  [dbpedia_14] Hardwickia is a genus of flowering plants in the legume family Fabaceae. It belongs to the sub family Caesalpinioideae.
05/25/2022 06:50:35 - INFO - __main__ - ['Plant']
05/25/2022 06:50:35 - INFO - __main__ -  [dbpedia_14] Eurybia eryngiifolia commonly known as the Thistleleaf Aster or Coyote-thistle Aster is an herbaceous perennial in the composite family. It is native to the eastern United States where it is only present along the Florida panhandle and the nearby areas of southern Alabama and Georgia.
05/25/2022 06:50:35 - INFO - __main__ - ['Plant']
05/25/2022 06:50:35 - INFO - __main__ -  [dbpedia_14] Petraeovitex is a genus of eight climbing shrubs species known to science of the Mint family Lamiaceae (formerly placed within Verbenaceae).Collectively they grow naturally in Borneo Peninsular Malaysia Sumatra the Philippines the Moluccas New Guinea Bismarck Archipelago the Solomon Islands and Cape York Peninsula Australia.
05/25/2022 06:50:35 - INFO - __main__ - ['Plant']
05/25/2022 06:50:35 - INFO - __main__ - Tokenizing Input ...
05/25/2022 06:50:36 - INFO - __main__ - Tokenizing Output ...
05/25/2022 06:50:36 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 06:50:52 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 06:50:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 06:50:53 - INFO - __main__ - Starting training!
05/25/2022 06:50:56 - INFO - __main__ - Step 10 Global step 10 Train loss 7.41 on epoch=0
05/25/2022 06:50:59 - INFO - __main__ - Step 20 Global step 20 Train loss 5.81 on epoch=0
05/25/2022 06:51:01 - INFO - __main__ - Step 30 Global step 30 Train loss 5.29 on epoch=0
05/25/2022 06:51:04 - INFO - __main__ - Step 40 Global step 40 Train loss 4.48 on epoch=0
05/25/2022 06:51:06 - INFO - __main__ - Step 50 Global step 50 Train loss 4.39 on epoch=0
05/25/2022 06:51:32 - INFO - __main__ - Global step 50 Train loss 5.48 Classification-F1 0.010287354828897364 on epoch=0
05/25/2022 06:51:32 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.010287354828897364 on epoch=0, global_step=50
05/25/2022 06:51:35 - INFO - __main__ - Step 60 Global step 60 Train loss 3.94 on epoch=1
05/25/2022 06:51:38 - INFO - __main__ - Step 70 Global step 70 Train loss 3.55 on epoch=1
05/25/2022 06:51:40 - INFO - __main__ - Step 80 Global step 80 Train loss 3.37 on epoch=1
05/25/2022 06:51:43 - INFO - __main__ - Step 90 Global step 90 Train loss 3.03 on epoch=1
05/25/2022 06:51:45 - INFO - __main__ - Step 100 Global step 100 Train loss 3.07 on epoch=1
05/25/2022 06:52:12 - INFO - __main__ - Global step 100 Train loss 3.39 Classification-F1 0.020749256898549475 on epoch=1
05/25/2022 06:52:12 - INFO - __main__ - Saving model with best Classification-F1: 0.010287354828897364 -> 0.020749256898549475 on epoch=1, global_step=100
05/25/2022 06:52:14 - INFO - __main__ - Step 110 Global step 110 Train loss 2.76 on epoch=1
05/25/2022 06:52:17 - INFO - __main__ - Step 120 Global step 120 Train loss 2.61 on epoch=2
05/25/2022 06:52:19 - INFO - __main__ - Step 130 Global step 130 Train loss 2.59 on epoch=2
05/25/2022 06:52:22 - INFO - __main__ - Step 140 Global step 140 Train loss 2.40 on epoch=2
05/25/2022 06:52:24 - INFO - __main__ - Step 150 Global step 150 Train loss 2.10 on epoch=2
05/25/2022 06:52:49 - INFO - __main__ - Global step 150 Train loss 2.49 Classification-F1 0.03323146766161606 on epoch=2
05/25/2022 06:52:49 - INFO - __main__ - Saving model with best Classification-F1: 0.020749256898549475 -> 0.03323146766161606 on epoch=2, global_step=150
05/25/2022 06:52:52 - INFO - __main__ - Step 160 Global step 160 Train loss 2.07 on epoch=2
05/25/2022 06:52:55 - INFO - __main__ - Step 170 Global step 170 Train loss 2.23 on epoch=3
05/25/2022 06:52:57 - INFO - __main__ - Step 180 Global step 180 Train loss 2.15 on epoch=3
05/25/2022 06:53:00 - INFO - __main__ - Step 190 Global step 190 Train loss 1.76 on epoch=3
05/25/2022 06:53:02 - INFO - __main__ - Step 200 Global step 200 Train loss 1.99 on epoch=3
05/25/2022 06:53:26 - INFO - __main__ - Global step 200 Train loss 2.04 Classification-F1 0.048014539579217766 on epoch=3
05/25/2022 06:53:26 - INFO - __main__ - Saving model with best Classification-F1: 0.03323146766161606 -> 0.048014539579217766 on epoch=3, global_step=200
05/25/2022 06:53:28 - INFO - __main__ - Step 210 Global step 210 Train loss 1.74 on epoch=3
05/25/2022 06:53:31 - INFO - __main__ - Step 220 Global step 220 Train loss 1.90 on epoch=3
05/25/2022 06:53:34 - INFO - __main__ - Step 230 Global step 230 Train loss 1.84 on epoch=4
05/25/2022 06:53:36 - INFO - __main__ - Step 240 Global step 240 Train loss 1.78 on epoch=4
05/25/2022 06:53:39 - INFO - __main__ - Step 250 Global step 250 Train loss 1.64 on epoch=4
05/25/2022 06:54:02 - INFO - __main__ - Global step 250 Train loss 1.78 Classification-F1 0.08337855432100467 on epoch=4
05/25/2022 06:54:02 - INFO - __main__ - Saving model with best Classification-F1: 0.048014539579217766 -> 0.08337855432100467 on epoch=4, global_step=250
05/25/2022 06:54:04 - INFO - __main__ - Step 260 Global step 260 Train loss 1.60 on epoch=4
05/25/2022 06:54:07 - INFO - __main__ - Step 270 Global step 270 Train loss 1.40 on epoch=4
05/25/2022 06:54:09 - INFO - __main__ - Step 280 Global step 280 Train loss 1.57 on epoch=4
05/25/2022 06:54:12 - INFO - __main__ - Step 290 Global step 290 Train loss 1.33 on epoch=5
05/25/2022 06:54:14 - INFO - __main__ - Step 300 Global step 300 Train loss 1.33 on epoch=5
05/25/2022 06:54:37 - INFO - __main__ - Global step 300 Train loss 1.45 Classification-F1 0.10619460032226992 on epoch=5
05/25/2022 06:54:37 - INFO - __main__ - Saving model with best Classification-F1: 0.08337855432100467 -> 0.10619460032226992 on epoch=5, global_step=300
05/25/2022 06:54:39 - INFO - __main__ - Step 310 Global step 310 Train loss 1.33 on epoch=5
05/25/2022 06:54:42 - INFO - __main__ - Step 320 Global step 320 Train loss 1.03 on epoch=5
05/25/2022 06:54:45 - INFO - __main__ - Step 330 Global step 330 Train loss 1.26 on epoch=5
05/25/2022 06:54:47 - INFO - __main__ - Step 340 Global step 340 Train loss 1.19 on epoch=6
05/25/2022 06:54:50 - INFO - __main__ - Step 350 Global step 350 Train loss 1.05 on epoch=6
05/25/2022 06:55:12 - INFO - __main__ - Global step 350 Train loss 1.17 Classification-F1 0.12147328307969306 on epoch=6
05/25/2022 06:55:12 - INFO - __main__ - Saving model with best Classification-F1: 0.10619460032226992 -> 0.12147328307969306 on epoch=6, global_step=350
05/25/2022 06:55:14 - INFO - __main__ - Step 360 Global step 360 Train loss 1.05 on epoch=6
05/25/2022 06:55:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.98 on epoch=6
05/25/2022 06:55:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.86 on epoch=6
05/25/2022 06:55:22 - INFO - __main__ - Step 390 Global step 390 Train loss 1.02 on epoch=6
05/25/2022 06:55:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.81 on epoch=7
05/25/2022 06:55:47 - INFO - __main__ - Global step 400 Train loss 0.95 Classification-F1 0.17224628549477516 on epoch=7
05/25/2022 06:55:47 - INFO - __main__ - Saving model with best Classification-F1: 0.12147328307969306 -> 0.17224628549477516 on epoch=7, global_step=400
05/25/2022 06:55:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.93 on epoch=7
05/25/2022 06:55:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.92 on epoch=7
05/25/2022 06:55:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.64 on epoch=7
05/25/2022 06:55:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.78 on epoch=7
05/25/2022 06:56:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.73 on epoch=8
05/25/2022 06:56:23 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.2078509566912519 on epoch=8
05/25/2022 06:56:23 - INFO - __main__ - Saving model with best Classification-F1: 0.17224628549477516 -> 0.2078509566912519 on epoch=8, global_step=450
05/25/2022 06:56:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.70 on epoch=8
05/25/2022 06:56:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.74 on epoch=8
05/25/2022 06:56:31 - INFO - __main__ - Step 480 Global step 480 Train loss 0.72 on epoch=8
05/25/2022 06:56:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.58 on epoch=8
05/25/2022 06:56:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=8
05/25/2022 06:57:00 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.2329537797446986 on epoch=8
05/25/2022 06:57:00 - INFO - __main__ - Saving model with best Classification-F1: 0.2078509566912519 -> 0.2329537797446986 on epoch=8, global_step=500
05/25/2022 06:57:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=9
05/25/2022 06:57:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=9
05/25/2022 06:57:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.61 on epoch=9
05/25/2022 06:57:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.61 on epoch=9
05/25/2022 06:57:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=9
05/25/2022 06:57:37 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.2547575446433312 on epoch=9
05/25/2022 06:57:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2329537797446986 -> 0.2547575446433312 on epoch=9, global_step=550
05/25/2022 06:57:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.57 on epoch=9
05/25/2022 06:57:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=10
05/25/2022 06:57:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=10
05/25/2022 06:57:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=10
05/25/2022 06:57:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.41 on epoch=10
05/25/2022 06:58:16 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.28155786227897084 on epoch=10
05/25/2022 06:58:16 - INFO - __main__ - Saving model with best Classification-F1: 0.2547575446433312 -> 0.28155786227897084 on epoch=10, global_step=600
05/25/2022 06:58:18 - INFO - __main__ - Step 610 Global step 610 Train loss 0.59 on epoch=10
05/25/2022 06:58:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.40 on epoch=11
05/25/2022 06:58:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.43 on epoch=11
05/25/2022 06:58:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=11
05/25/2022 06:58:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=11
05/25/2022 06:58:55 - INFO - __main__ - Global step 650 Train loss 0.47 Classification-F1 0.33199240505505817 on epoch=11
05/25/2022 06:58:55 - INFO - __main__ - Saving model with best Classification-F1: 0.28155786227897084 -> 0.33199240505505817 on epoch=11, global_step=650
05/25/2022 06:58:57 - INFO - __main__ - Step 660 Global step 660 Train loss 0.34 on epoch=11
05/25/2022 06:59:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.44 on epoch=11
05/25/2022 06:59:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.34 on epoch=12
05/25/2022 06:59:05 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=12
05/25/2022 06:59:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=12
05/25/2022 06:59:33 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.3290385740978547 on epoch=12
05/25/2022 06:59:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=12
05/25/2022 06:59:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=12
05/25/2022 06:59:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=13
05/25/2022 06:59:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=13
05/25/2022 06:59:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.38 on epoch=13
05/25/2022 07:00:13 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.4019992431940019 on epoch=13
05/25/2022 07:00:13 - INFO - __main__ - Saving model with best Classification-F1: 0.33199240505505817 -> 0.4019992431940019 on epoch=13, global_step=750
05/25/2022 07:00:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=13
05/25/2022 07:00:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=13
05/25/2022 07:00:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=13
05/25/2022 07:00:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=14
05/25/2022 07:00:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=14
05/25/2022 07:00:53 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.4354102888900034 on epoch=14
05/25/2022 07:00:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4019992431940019 -> 0.4354102888900034 on epoch=14, global_step=800
05/25/2022 07:00:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.31 on epoch=14
05/25/2022 07:00:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=14
05/25/2022 07:01:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=14
05/25/2022 07:01:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.41 on epoch=14
05/25/2022 07:01:05 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=15
05/25/2022 07:01:31 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.43918679809224187 on epoch=15
05/25/2022 07:01:32 - INFO - __main__ - Saving model with best Classification-F1: 0.4354102888900034 -> 0.43918679809224187 on epoch=15, global_step=850
05/25/2022 07:01:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=15
05/25/2022 07:01:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.32 on epoch=15
05/25/2022 07:01:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.25 on epoch=15
05/25/2022 07:01:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=15
05/25/2022 07:01:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=16
05/25/2022 07:02:10 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.4395576709988021 on epoch=16
05/25/2022 07:02:10 - INFO - __main__ - Saving model with best Classification-F1: 0.43918679809224187 -> 0.4395576709988021 on epoch=16, global_step=900
05/25/2022 07:02:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=16
05/25/2022 07:02:15 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=16
05/25/2022 07:02:18 - INFO - __main__ - Step 930 Global step 930 Train loss 0.24 on epoch=16
05/25/2022 07:02:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.25 on epoch=16
05/25/2022 07:02:23 - INFO - __main__ - Step 950 Global step 950 Train loss 0.27 on epoch=16
05/25/2022 07:02:49 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.4647087509510603 on epoch=16
05/25/2022 07:02:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4395576709988021 -> 0.4647087509510603 on epoch=16, global_step=950
05/25/2022 07:02:51 - INFO - __main__ - Step 960 Global step 960 Train loss 0.21 on epoch=17
05/25/2022 07:02:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.33 on epoch=17
05/25/2022 07:02:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=17
05/25/2022 07:02:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=17
05/25/2022 07:03:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=17
05/25/2022 07:03:27 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.479804606662735 on epoch=17
05/25/2022 07:03:27 - INFO - __main__ - Saving model with best Classification-F1: 0.4647087509510603 -> 0.479804606662735 on epoch=17, global_step=1000
05/25/2022 07:03:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=18
05/25/2022 07:03:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=18
05/25/2022 07:03:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.29 on epoch=18
05/25/2022 07:03:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.33 on epoch=18
05/25/2022 07:03:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=18
05/25/2022 07:04:07 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.5388152305703051 on epoch=18
05/25/2022 07:04:07 - INFO - __main__ - Saving model with best Classification-F1: 0.479804606662735 -> 0.5388152305703051 on epoch=18, global_step=1050
05/25/2022 07:04:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.26 on epoch=18
05/25/2022 07:04:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=19
05/25/2022 07:04:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=19
05/25/2022 07:04:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=19
05/25/2022 07:04:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=19
05/25/2022 07:04:46 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.5744781434099379 on epoch=19
05/25/2022 07:04:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5388152305703051 -> 0.5744781434099379 on epoch=19, global_step=1100
05/25/2022 07:04:49 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=19
05/25/2022 07:04:51 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.25 on epoch=19
05/25/2022 07:04:54 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.16 on epoch=20
05/25/2022 07:04:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=20
05/25/2022 07:04:59 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=20
05/25/2022 07:05:25 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.6338172835123068 on epoch=20
05/25/2022 07:05:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5744781434099379 -> 0.6338172835123068 on epoch=20, global_step=1150
05/25/2022 07:05:28 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=20
05/25/2022 07:05:30 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=20
05/25/2022 07:05:33 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=21
05/25/2022 07:05:35 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=21
05/25/2022 07:05:38 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=21
05/25/2022 07:06:04 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.6457441834698416 on epoch=21
05/25/2022 07:06:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6338172835123068 -> 0.6457441834698416 on epoch=21, global_step=1200
05/25/2022 07:06:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=21
05/25/2022 07:06:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=21
05/25/2022 07:06:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=21
05/25/2022 07:06:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=22
05/25/2022 07:06:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=22
05/25/2022 07:06:43 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6111712945371199 on epoch=22
05/25/2022 07:06:46 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=22
05/25/2022 07:06:49 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=22
05/25/2022 07:06:51 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=22
05/25/2022 07:06:54 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=23
05/25/2022 07:06:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=23
05/25/2022 07:07:22 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.6223747084430802 on epoch=23
05/25/2022 07:07:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=23
05/25/2022 07:07:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.19 on epoch=23
05/25/2022 07:07:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=23
05/25/2022 07:07:33 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=23
05/25/2022 07:07:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=24
05/25/2022 07:08:02 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6898228178444268 on epoch=24
05/25/2022 07:08:02 - INFO - __main__ - Saving model with best Classification-F1: 0.6457441834698416 -> 0.6898228178444268 on epoch=24, global_step=1350
05/25/2022 07:08:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/25/2022 07:08:07 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.18 on epoch=24
05/25/2022 07:08:09 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=24
05/25/2022 07:08:12 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=24
05/25/2022 07:08:15 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=24
05/25/2022 07:08:40 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.6226192514227383 on epoch=24
05/25/2022 07:08:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.15 on epoch=25
05/25/2022 07:08:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=25
05/25/2022 07:08:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=25
05/25/2022 07:08:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=25
05/25/2022 07:08:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=25
05/25/2022 07:09:19 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.5912499458500635 on epoch=25
05/25/2022 07:09:22 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=26
05/25/2022 07:09:24 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=26
05/25/2022 07:09:27 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=26
05/25/2022 07:09:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=26
05/25/2022 07:09:32 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=26
05/25/2022 07:09:58 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.647436375184386 on epoch=26
05/25/2022 07:10:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=26
05/25/2022 07:10:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=27
05/25/2022 07:10:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=27
05/25/2022 07:10:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=27
05/25/2022 07:10:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=27
05/25/2022 07:10:37 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.5561641848848352 on epoch=27
05/25/2022 07:10:39 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=27
05/25/2022 07:10:42 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
05/25/2022 07:10:44 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=28
05/25/2022 07:10:47 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=28
05/25/2022 07:10:50 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=28
05/25/2022 07:11:16 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.6153223916069763 on epoch=28
05/25/2022 07:11:18 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=28
05/25/2022 07:11:21 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=28
05/25/2022 07:11:23 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=29
05/25/2022 07:11:26 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=29
05/25/2022 07:11:29 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=29
05/25/2022 07:11:54 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5823613979469473 on epoch=29
05/25/2022 07:11:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.15 on epoch=29
05/25/2022 07:12:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=29
05/25/2022 07:12:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=29
05/25/2022 07:12:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=30
05/25/2022 07:12:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=30
05/25/2022 07:12:33 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.6151983897991811 on epoch=30
05/25/2022 07:12:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=30
05/25/2022 07:12:38 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=30
05/25/2022 07:12:41 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.17 on epoch=30
05/25/2022 07:12:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.14 on epoch=31
05/25/2022 07:12:46 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=31
05/25/2022 07:13:11 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.6137386679586403 on epoch=31
05/25/2022 07:13:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=31
05/25/2022 07:13:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=31
05/25/2022 07:13:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.14 on epoch=31
05/25/2022 07:13:21 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=31
05/25/2022 07:13:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=32
05/25/2022 07:13:50 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.5352231906008074 on epoch=32
05/25/2022 07:13:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.11 on epoch=32
05/25/2022 07:13:55 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=32
05/25/2022 07:13:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/25/2022 07:14:00 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=32
05/25/2022 07:14:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/25/2022 07:14:29 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.5630909364812384 on epoch=33
05/25/2022 07:14:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=33
05/25/2022 07:14:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=33
05/25/2022 07:14:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.17 on epoch=33
05/25/2022 07:14:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=33
05/25/2022 07:14:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=33
05/25/2022 07:15:07 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.5509193536978608 on epoch=33
05/25/2022 07:15:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=34
05/25/2022 07:15:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=34
05/25/2022 07:15:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=34
05/25/2022 07:15:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=34
05/25/2022 07:15:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=34
05/25/2022 07:15:46 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.611316810946249 on epoch=34
05/25/2022 07:15:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
05/25/2022 07:15:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=35
05/25/2022 07:15:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.12 on epoch=35
05/25/2022 07:15:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=35
05/25/2022 07:15:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/25/2022 07:16:24 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.5961559435606979 on epoch=35
05/25/2022 07:16:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=35
05/25/2022 07:16:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=36
05/25/2022 07:16:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=36
05/25/2022 07:16:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=36
05/25/2022 07:16:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=36
05/25/2022 07:17:03 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.5841235761235636 on epoch=36
05/25/2022 07:17:06 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=36
05/25/2022 07:17:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.17 on epoch=36
05/25/2022 07:17:11 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=37
05/25/2022 07:17:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
05/25/2022 07:17:16 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.13 on epoch=37
05/25/2022 07:17:42 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.5706354347615709 on epoch=37
05/25/2022 07:17:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=37
05/25/2022 07:17:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.16 on epoch=37
05/25/2022 07:17:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=38
05/25/2022 07:17:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=38
05/25/2022 07:17:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=38
05/25/2022 07:18:20 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.5392856675985854 on epoch=38
05/25/2022 07:18:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=38
05/25/2022 07:18:25 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=38
05/25/2022 07:18:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
05/25/2022 07:18:30 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.13 on epoch=39
05/25/2022 07:18:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/25/2022 07:18:59 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.5959494331587321 on epoch=39
05/25/2022 07:19:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=39
05/25/2022 07:19:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.19 on epoch=39
05/25/2022 07:19:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=39
05/25/2022 07:19:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=39
05/25/2022 07:19:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=40
05/25/2022 07:19:37 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.5451019704198299 on epoch=40
05/25/2022 07:19:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=40
05/25/2022 07:19:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=40
05/25/2022 07:19:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=40
05/25/2022 07:19:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=40
05/25/2022 07:19:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=41
05/25/2022 07:20:16 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.5975557853319639 on epoch=41
05/25/2022 07:20:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=41
05/25/2022 07:20:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=41
05/25/2022 07:20:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=41
05/25/2022 07:20:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/25/2022 07:20:28 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=41
05/25/2022 07:20:54 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6074503344233476 on epoch=41
05/25/2022 07:20:57 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=42
05/25/2022 07:20:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
05/25/2022 07:21:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=42
05/25/2022 07:21:05 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 07:21:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=42
05/25/2022 07:21:33 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.5499335335559785 on epoch=42
05/25/2022 07:21:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/25/2022 07:21:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=43
05/25/2022 07:21:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=43
05/25/2022 07:21:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=43
05/25/2022 07:21:45 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
05/25/2022 07:22:11 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.5252322343750798 on epoch=43
05/25/2022 07:22:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=43
05/25/2022 07:22:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=44
05/25/2022 07:22:19 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=44
05/25/2022 07:22:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=44
05/25/2022 07:22:24 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=44
05/25/2022 07:22:50 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.6021618875886638 on epoch=44
05/25/2022 07:22:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
05/25/2022 07:22:55 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
05/25/2022 07:22:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/25/2022 07:23:00 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=45
05/25/2022 07:23:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=45
05/25/2022 07:23:29 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.5766179182256712 on epoch=45
05/25/2022 07:23:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/25/2022 07:23:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=45
05/25/2022 07:23:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=46
05/25/2022 07:23:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=46
05/25/2022 07:23:41 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=46
05/25/2022 07:24:07 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.6387056270990454 on epoch=46
05/25/2022 07:24:09 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=46
05/25/2022 07:24:12 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=46
05/25/2022 07:24:14 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=46
05/25/2022 07:24:17 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=47
05/25/2022 07:24:20 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=47
05/25/2022 07:24:45 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.5517253507112444 on epoch=47
05/25/2022 07:24:48 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=47
05/25/2022 07:24:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=47
05/25/2022 07:24:53 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=47
05/25/2022 07:24:56 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=48
05/25/2022 07:24:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=48
05/25/2022 07:25:23 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.5381530593328901 on epoch=48
05/25/2022 07:25:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=48
05/25/2022 07:25:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=48
05/25/2022 07:25:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
05/25/2022 07:25:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=48
05/25/2022 07:25:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=49
05/25/2022 07:26:01 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.5782099859738893 on epoch=49
05/25/2022 07:26:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=49
05/25/2022 07:26:06 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/25/2022 07:26:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=49
05/25/2022 07:26:11 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=49
05/25/2022 07:26:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=49
05/25/2022 07:26:38 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.551869621763763 on epoch=49
05/25/2022 07:26:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/25/2022 07:26:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/25/2022 07:26:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=50
05/25/2022 07:26:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/25/2022 07:26:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.12 on epoch=50
05/25/2022 07:27:16 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.5716957657169528 on epoch=50
05/25/2022 07:27:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.07 on epoch=51
05/25/2022 07:27:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=51
05/25/2022 07:27:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=51
05/25/2022 07:27:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=51
05/25/2022 07:27:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/25/2022 07:27:54 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.5086209289180138 on epoch=51
05/25/2022 07:27:56 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=51
05/25/2022 07:27:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=52
05/25/2022 07:28:01 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=52
05/25/2022 07:28:04 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=52
05/25/2022 07:28:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=52
05/25/2022 07:28:32 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.5928336843986395 on epoch=52
05/25/2022 07:28:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.11 on epoch=52
05/25/2022 07:28:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=53
05/25/2022 07:28:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=53
05/25/2022 07:28:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.12 on epoch=53
05/25/2022 07:28:44 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=53
05/25/2022 07:28:46 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 07:28:46 - INFO - __main__ - Printing 3 examples
05/25/2022 07:28:46 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 07:28:46 - INFO - __main__ - ['Company']
05/25/2022 07:28:46 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 07:28:46 - INFO - __main__ - ['Company']
05/25/2022 07:28:46 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 07:28:46 - INFO - __main__ - ['Company']
05/25/2022 07:28:46 - INFO - __main__ - Tokenizing Input ...
05/25/2022 07:28:46 - INFO - __main__ - Tokenizing Output ...
05/25/2022 07:28:47 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 07:28:47 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 07:28:47 - INFO - __main__ - Printing 3 examples
05/25/2022 07:28:47 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 07:28:47 - INFO - __main__ - ['Company']
05/25/2022 07:28:47 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 07:28:47 - INFO - __main__ - ['Company']
05/25/2022 07:28:47 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 07:28:47 - INFO - __main__ - ['Company']
05/25/2022 07:28:47 - INFO - __main__ - Tokenizing Input ...
05/25/2022 07:28:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 07:28:49 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 07:29:06 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 07:29:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 07:29:07 - INFO - __main__ - Starting training!
05/25/2022 07:29:09 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.5346525141660762 on epoch=53
05/25/2022 07:29:09 - INFO - __main__ - save last model!
05/25/2022 07:29:09 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 07:29:09 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 07:29:09 - INFO - __main__ - Printing 3 examples
05/25/2022 07:29:09 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 07:29:09 - INFO - __main__ - ['Animal']
05/25/2022 07:29:09 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 07:29:09 - INFO - __main__ - ['Animal']
05/25/2022 07:29:09 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 07:29:09 - INFO - __main__ - ['Village']
05/25/2022 07:29:09 - INFO - __main__ - Tokenizing Input ...
05/25/2022 07:29:11 - INFO - __main__ - Tokenizing Output ...
05/25/2022 07:29:14 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 07:31:11 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_21_0.2_8_predictions.txt
05/25/2022 07:31:11 - INFO - __main__ - Classification-F1 on test data: 0.4277
05/25/2022 07:31:12 - INFO - __main__ - prefix=dbpedia_14_64_21, lr=0.2, bsz=8, dev_performance=0.6898228178444268, test_performance=0.4276781421050384
05/25/2022 07:31:12 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.5, bsz=8 ...
05/25/2022 07:31:13 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 07:31:13 - INFO - __main__ - Printing 3 examples
05/25/2022 07:31:13 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 07:31:13 - INFO - __main__ - ['Company']
05/25/2022 07:31:13 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 07:31:13 - INFO - __main__ - ['Company']
05/25/2022 07:31:13 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 07:31:13 - INFO - __main__ - ['Company']
05/25/2022 07:31:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 07:31:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 07:31:14 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 07:31:14 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 07:31:14 - INFO - __main__ - Printing 3 examples
05/25/2022 07:31:14 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 07:31:14 - INFO - __main__ - ['Company']
05/25/2022 07:31:14 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 07:31:14 - INFO - __main__ - ['Company']
05/25/2022 07:31:14 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 07:31:14 - INFO - __main__ - ['Company']
05/25/2022 07:31:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 07:31:15 - INFO - __main__ - Tokenizing Output ...
05/25/2022 07:31:16 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 07:31:34 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 07:31:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 07:31:35 - INFO - __main__ - Starting training!
05/25/2022 07:31:39 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=0
05/25/2022 07:31:42 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=0
05/25/2022 07:31:44 - INFO - __main__ - Step 30 Global step 30 Train loss 3.70 on epoch=0
05/25/2022 07:31:47 - INFO - __main__ - Step 40 Global step 40 Train loss 3.10 on epoch=0
05/25/2022 07:31:49 - INFO - __main__ - Step 50 Global step 50 Train loss 2.93 on epoch=0
05/25/2022 07:32:14 - INFO - __main__ - Global step 50 Train loss 4.28 Classification-F1 0.026928246391229295 on epoch=0
05/25/2022 07:32:14 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026928246391229295 on epoch=0, global_step=50
05/25/2022 07:32:17 - INFO - __main__ - Step 60 Global step 60 Train loss 2.60 on epoch=1
05/25/2022 07:32:19 - INFO - __main__ - Step 70 Global step 70 Train loss 2.38 on epoch=1
05/25/2022 07:32:22 - INFO - __main__ - Step 80 Global step 80 Train loss 2.14 on epoch=1
05/25/2022 07:32:25 - INFO - __main__ - Step 90 Global step 90 Train loss 1.88 on epoch=1
05/25/2022 07:32:27 - INFO - __main__ - Step 100 Global step 100 Train loss 1.96 on epoch=1
05/25/2022 07:32:49 - INFO - __main__ - Global step 100 Train loss 2.20 Classification-F1 0.06139719682501249 on epoch=1
05/25/2022 07:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.026928246391229295 -> 0.06139719682501249 on epoch=1, global_step=100
05/25/2022 07:32:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.52 on epoch=1
05/25/2022 07:32:54 - INFO - __main__ - Step 120 Global step 120 Train loss 1.56 on epoch=2
05/25/2022 07:32:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.22 on epoch=2
05/25/2022 07:32:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.16 on epoch=2
05/25/2022 07:33:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.22 on epoch=2
05/25/2022 07:33:23 - INFO - __main__ - Global step 150 Train loss 1.33 Classification-F1 0.15547155357416909 on epoch=2
05/25/2022 07:33:23 - INFO - __main__ - Saving model with best Classification-F1: 0.06139719682501249 -> 0.15547155357416909 on epoch=2, global_step=150
05/25/2022 07:33:26 - INFO - __main__ - Step 160 Global step 160 Train loss 0.94 on epoch=2
05/25/2022 07:33:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.98 on epoch=3
05/25/2022 07:33:31 - INFO - __main__ - Step 180 Global step 180 Train loss 0.87 on epoch=3
05/25/2022 07:33:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=3
05/25/2022 07:33:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=3
05/25/2022 07:34:00 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.24559199236659032 on epoch=3
05/25/2022 07:34:00 - INFO - __main__ - Saving model with best Classification-F1: 0.15547155357416909 -> 0.24559199236659032 on epoch=3, global_step=200
05/25/2022 07:34:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=3
05/25/2022 07:34:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=3
05/25/2022 07:34:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=4
05/25/2022 07:34:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=4
05/25/2022 07:34:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=4
05/25/2022 07:34:38 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.2567791607248453 on epoch=4
05/25/2022 07:34:38 - INFO - __main__ - Saving model with best Classification-F1: 0.24559199236659032 -> 0.2567791607248453 on epoch=4, global_step=250
05/25/2022 07:34:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=4
05/25/2022 07:34:43 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=4
05/25/2022 07:34:45 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=4
05/25/2022 07:34:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=5
05/25/2022 07:34:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.36 on epoch=5
05/25/2022 07:35:17 - INFO - __main__ - Global step 300 Train loss 0.39 Classification-F1 0.3039836415092118 on epoch=5
05/25/2022 07:35:17 - INFO - __main__ - Saving model with best Classification-F1: 0.2567791607248453 -> 0.3039836415092118 on epoch=5, global_step=300
05/25/2022 07:35:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=5
05/25/2022 07:35:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=5
05/25/2022 07:35:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=5
05/25/2022 07:35:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=6
05/25/2022 07:35:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=6
05/25/2022 07:35:56 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.3189478342349032 on epoch=6
05/25/2022 07:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.3039836415092118 -> 0.3189478342349032 on epoch=6, global_step=350
05/25/2022 07:35:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=6
05/25/2022 07:36:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=6
05/25/2022 07:36:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=6
05/25/2022 07:36:06 - INFO - __main__ - Step 390 Global step 390 Train loss 0.22 on epoch=6
05/25/2022 07:36:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=7
05/25/2022 07:36:34 - INFO - __main__ - Global step 400 Train loss 0.26 Classification-F1 0.39121928091889424 on epoch=7
05/25/2022 07:36:34 - INFO - __main__ - Saving model with best Classification-F1: 0.3189478342349032 -> 0.39121928091889424 on epoch=7, global_step=400
05/25/2022 07:36:37 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=7
05/25/2022 07:36:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=7
05/25/2022 07:36:42 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=7
05/25/2022 07:36:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=7
05/25/2022 07:36:47 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=8
05/25/2022 07:37:13 - INFO - __main__ - Global step 450 Train loss 0.24 Classification-F1 0.40401341274194713 on epoch=8
05/25/2022 07:37:13 - INFO - __main__ - Saving model with best Classification-F1: 0.39121928091889424 -> 0.40401341274194713 on epoch=8, global_step=450
05/25/2022 07:37:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=8
05/25/2022 07:37:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.27 on epoch=8
05/25/2022 07:37:21 - INFO - __main__ - Step 480 Global step 480 Train loss 0.20 on epoch=8
05/25/2022 07:37:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=8
05/25/2022 07:37:26 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=8
05/25/2022 07:37:51 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.5652920773458231 on epoch=8
05/25/2022 07:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.40401341274194713 -> 0.5652920773458231 on epoch=8, global_step=500
05/25/2022 07:37:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.20 on epoch=9
05/25/2022 07:37:56 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=9
05/25/2022 07:37:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=9
05/25/2022 07:38:01 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=9
05/25/2022 07:38:04 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=9
05/25/2022 07:38:29 - INFO - __main__ - Global step 550 Train loss 0.18 Classification-F1 0.4589434633170935 on epoch=9
05/25/2022 07:38:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=9
05/25/2022 07:38:34 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=10
05/25/2022 07:38:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=10
05/25/2022 07:38:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=10
05/25/2022 07:38:42 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=10
05/25/2022 07:39:06 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.47847794068095545 on epoch=10
05/25/2022 07:39:08 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=10
05/25/2022 07:39:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/25/2022 07:39:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=11
05/25/2022 07:39:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/25/2022 07:39:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=11
05/25/2022 07:39:42 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.5464688959175712 on epoch=11
05/25/2022 07:39:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=11
05/25/2022 07:39:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=11
05/25/2022 07:39:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.09 on epoch=12
05/25/2022 07:39:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=12
05/25/2022 07:39:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=12
05/25/2022 07:40:20 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.6320760992608263 on epoch=12
05/25/2022 07:40:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5652920773458231 -> 0.6320760992608263 on epoch=12, global_step=700
05/25/2022 07:40:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=12
05/25/2022 07:40:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
05/25/2022 07:40:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=13
05/25/2022 07:40:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=13
05/25/2022 07:40:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
05/25/2022 07:40:58 - INFO - __main__ - Global step 750 Train loss 0.12 Classification-F1 0.6185970964582733 on epoch=13
05/25/2022 07:41:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=13
05/25/2022 07:41:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=13
05/25/2022 07:41:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=13
05/25/2022 07:41:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=14
05/25/2022 07:41:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=14
05/25/2022 07:41:36 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6406322061771541 on epoch=14
05/25/2022 07:41:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6320760992608263 -> 0.6406322061771541 on epoch=14, global_step=800
05/25/2022 07:41:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=14
05/25/2022 07:41:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=14
05/25/2022 07:41:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.07 on epoch=14
05/25/2022 07:41:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.08 on epoch=14
05/25/2022 07:41:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=15
05/25/2022 07:42:13 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7000827436539895 on epoch=15
05/25/2022 07:42:13 - INFO - __main__ - Saving model with best Classification-F1: 0.6406322061771541 -> 0.7000827436539895 on epoch=15, global_step=850
05/25/2022 07:42:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=15
05/25/2022 07:42:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=15
05/25/2022 07:42:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=15
05/25/2022 07:42:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=15
05/25/2022 07:42:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.05 on epoch=16
05/25/2022 07:42:51 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.7521866694987757 on epoch=16
05/25/2022 07:42:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7000827436539895 -> 0.7521866694987757 on epoch=16, global_step=900
05/25/2022 07:42:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
05/25/2022 07:42:56 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=16
05/25/2022 07:42:59 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=16
05/25/2022 07:43:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=16
05/25/2022 07:43:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=16
05/25/2022 07:43:28 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.751947032791198 on epoch=16
05/25/2022 07:43:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=17
05/25/2022 07:43:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=17
05/25/2022 07:43:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=17
05/25/2022 07:43:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
05/25/2022 07:43:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
05/25/2022 07:44:05 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6389466099938994 on epoch=17
05/25/2022 07:44:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=18
05/25/2022 07:44:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=18
05/25/2022 07:44:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=18
05/25/2022 07:44:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=18
05/25/2022 07:44:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=18
05/25/2022 07:44:42 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.5630819000284379 on epoch=18
05/25/2022 07:44:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=18
05/25/2022 07:44:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=19
05/25/2022 07:44:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=19
05/25/2022 07:44:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/25/2022 07:44:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=19
05/25/2022 07:45:19 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7075127560201638 on epoch=19
05/25/2022 07:45:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=19
05/25/2022 07:45:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=19
05/25/2022 07:45:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=20
05/25/2022 07:45:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=20
05/25/2022 07:45:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=20
05/25/2022 07:45:56 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7142688493273126 on epoch=20
05/25/2022 07:45:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=20
05/25/2022 07:46:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=20
05/25/2022 07:46:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=21
05/25/2022 07:46:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=21
05/25/2022 07:46:09 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=21
05/25/2022 07:46:33 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7172757969015093 on epoch=21
05/25/2022 07:46:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=21
05/25/2022 07:46:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=21
05/25/2022 07:46:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=21
05/25/2022 07:46:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
05/25/2022 07:46:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=22
05/25/2022 07:47:10 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.8013057470590282 on epoch=22
05/25/2022 07:47:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7521866694987757 -> 0.8013057470590282 on epoch=22, global_step=1250
05/25/2022 07:47:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=22
05/25/2022 07:47:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=22
05/25/2022 07:47:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=22
05/25/2022 07:47:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=23
05/25/2022 07:47:23 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=23
05/25/2022 07:47:48 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6474251379734784 on epoch=23
05/25/2022 07:47:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
05/25/2022 07:47:53 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=23
05/25/2022 07:47:55 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
05/25/2022 07:47:58 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=23
05/25/2022 07:48:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/25/2022 07:48:25 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7589536930658826 on epoch=24
05/25/2022 07:48:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=24
05/25/2022 07:48:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/25/2022 07:48:33 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=24
05/25/2022 07:48:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=24
05/25/2022 07:48:38 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=24
05/25/2022 07:49:03 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6804576266108916 on epoch=24
05/25/2022 07:49:05 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
05/25/2022 07:49:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=25
05/25/2022 07:49:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=25
05/25/2022 07:49:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=25
05/25/2022 07:49:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=25
05/25/2022 07:49:40 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6471104539858757 on epoch=25
05/25/2022 07:49:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=26
05/25/2022 07:49:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=26
05/25/2022 07:49:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/25/2022 07:49:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=26
05/25/2022 07:49:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 07:50:17 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6770583581171348 on epoch=26
05/25/2022 07:50:20 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/25/2022 07:50:22 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
05/25/2022 07:50:25 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=27
05/25/2022 07:50:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=27
05/25/2022 07:50:30 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=27
05/25/2022 07:50:55 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7165275090567841 on epoch=27
05/25/2022 07:50:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=27
05/25/2022 07:51:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=28
05/25/2022 07:51:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=28
05/25/2022 07:51:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=28
05/25/2022 07:51:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
05/25/2022 07:51:33 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7077135239246826 on epoch=28
05/25/2022 07:51:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
05/25/2022 07:51:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/25/2022 07:51:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=29
05/25/2022 07:51:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/25/2022 07:51:46 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
05/25/2022 07:52:10 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6390195377113846 on epoch=29
05/25/2022 07:52:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=29
05/25/2022 07:52:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=29
05/25/2022 07:52:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=29
05/25/2022 07:52:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/25/2022 07:52:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=30
05/25/2022 07:52:47 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7897487846432466 on epoch=30
05/25/2022 07:52:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=30
05/25/2022 07:52:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=30
05/25/2022 07:52:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=30
05/25/2022 07:52:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=31
05/25/2022 07:53:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=31
05/25/2022 07:53:24 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8539072225809561 on epoch=31
05/25/2022 07:53:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8013057470590282 -> 0.8539072225809561 on epoch=31, global_step=1750
05/25/2022 07:53:27 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
05/25/2022 07:53:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=31
05/25/2022 07:53:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=31
05/25/2022 07:53:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
05/25/2022 07:53:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=32
05/25/2022 07:54:00 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.6642219419824177 on epoch=32
05/25/2022 07:54:03 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=32
05/25/2022 07:54:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/25/2022 07:54:08 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=32
05/25/2022 07:54:11 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=32
05/25/2022 07:54:13 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=33
05/25/2022 07:54:37 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.6848055464232515 on epoch=33
05/25/2022 07:54:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=33
05/25/2022 07:54:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=33
05/25/2022 07:54:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/25/2022 07:54:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=33
05/25/2022 07:54:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=33
05/25/2022 07:55:15 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.6732131956722757 on epoch=33
05/25/2022 07:55:17 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/25/2022 07:55:20 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/25/2022 07:55:22 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.01 on epoch=34
05/25/2022 07:55:25 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/25/2022 07:55:27 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=34
05/25/2022 07:55:52 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7140362690422035 on epoch=34
05/25/2022 07:55:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/25/2022 07:55:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/25/2022 07:55:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=35
05/25/2022 07:56:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/25/2022 07:56:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=35
05/25/2022 07:56:29 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7147089821655035 on epoch=35
05/25/2022 07:56:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/25/2022 07:56:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=36
05/25/2022 07:56:36 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=36
05/25/2022 07:56:39 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=36
05/25/2022 07:56:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/25/2022 07:57:06 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.702276887417112 on epoch=36
05/25/2022 07:57:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=36
05/25/2022 07:57:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/25/2022 07:57:13 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
05/25/2022 07:57:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=37
05/25/2022 07:57:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=37
05/25/2022 07:57:43 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6787603222563175 on epoch=37
05/25/2022 07:57:46 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=37
05/25/2022 07:57:48 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=37
05/25/2022 07:57:51 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/25/2022 07:57:53 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=38
05/25/2022 07:57:56 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=38
05/25/2022 07:58:21 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7975069067338536 on epoch=38
05/25/2022 07:58:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=38
05/25/2022 07:58:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/25/2022 07:58:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/25/2022 07:58:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/25/2022 07:58:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=39
05/25/2022 07:58:59 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7538214678408397 on epoch=39
05/25/2022 07:59:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=39
05/25/2022 07:59:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=39
05/25/2022 07:59:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=39
05/25/2022 07:59:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=39
05/25/2022 07:59:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
05/25/2022 07:59:36 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.752784350983391 on epoch=40
05/25/2022 07:59:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=40
05/25/2022 07:59:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=40
05/25/2022 07:59:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/25/2022 07:59:47 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
05/25/2022 07:59:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/25/2022 08:00:14 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7543510373988317 on epoch=41
05/25/2022 08:00:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/25/2022 08:00:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=41
05/25/2022 08:00:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/25/2022 08:00:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=41
05/25/2022 08:00:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/25/2022 08:00:51 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7534382485566519 on epoch=41
05/25/2022 08:00:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=42
05/25/2022 08:00:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=42
05/25/2022 08:00:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/25/2022 08:01:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
05/25/2022 08:01:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=42
05/25/2022 08:01:29 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7951187041550054 on epoch=42
05/25/2022 08:01:31 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=43
05/25/2022 08:01:34 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
05/25/2022 08:01:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=43
05/25/2022 08:01:39 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=43
05/25/2022 08:01:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=43
05/25/2022 08:02:06 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.6368260743919263 on epoch=43
05/25/2022 08:02:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=43
05/25/2022 08:02:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/25/2022 08:02:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=44
05/25/2022 08:02:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/25/2022 08:02:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=44
05/25/2022 08:02:44 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7156151775785107 on epoch=44
05/25/2022 08:02:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=44
05/25/2022 08:02:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/25/2022 08:02:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
05/25/2022 08:02:54 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=45
05/25/2022 08:02:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=45
05/25/2022 08:03:21 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7147967077718966 on epoch=45
05/25/2022 08:03:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/25/2022 08:03:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/25/2022 08:03:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 08:03:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/25/2022 08:03:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=46
05/25/2022 08:03:59 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7508837075193319 on epoch=46
05/25/2022 08:04:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/25/2022 08:04:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=46
05/25/2022 08:04:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/25/2022 08:04:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/25/2022 08:04:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=47
05/25/2022 08:04:36 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7093262134010532 on epoch=47
05/25/2022 08:04:39 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/25/2022 08:04:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/25/2022 08:04:44 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=47
05/25/2022 08:04:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 08:04:49 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/25/2022 08:05:14 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6685774009789066 on epoch=48
05/25/2022 08:05:17 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=48
05/25/2022 08:05:19 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/25/2022 08:05:22 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=48
05/25/2022 08:05:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/25/2022 08:05:27 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/25/2022 08:05:52 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7063510296365881 on epoch=49
05/25/2022 08:05:54 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=49
05/25/2022 08:05:57 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/25/2022 08:05:59 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=49
05/25/2022 08:06:02 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=49
05/25/2022 08:06:05 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=49
05/25/2022 08:06:29 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7065444499850255 on epoch=49
05/25/2022 08:06:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=50
05/25/2022 08:06:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/25/2022 08:06:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 08:06:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/25/2022 08:06:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 08:07:06 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.794416851830388 on epoch=50
05/25/2022 08:07:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=51
05/25/2022 08:07:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/25/2022 08:07:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/25/2022 08:07:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 08:07:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=51
05/25/2022 08:07:43 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7514970031461092 on epoch=51
05/25/2022 08:07:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/25/2022 08:07:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=52
05/25/2022 08:07:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=52
05/25/2022 08:07:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=52
05/25/2022 08:07:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=52
05/25/2022 08:08:21 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8529272563609246 on epoch=52
05/25/2022 08:08:24 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/25/2022 08:08:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/25/2022 08:08:29 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/25/2022 08:08:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=53
05/25/2022 08:08:34 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=53
05/25/2022 08:08:36 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:08:36 - INFO - __main__ - Printing 3 examples
05/25/2022 08:08:36 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 08:08:36 - INFO - __main__ - ['Company']
05/25/2022 08:08:36 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 08:08:36 - INFO - __main__ - ['Company']
05/25/2022 08:08:36 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 08:08:36 - INFO - __main__ - ['Company']
05/25/2022 08:08:36 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:08:36 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:08:37 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 08:08:37 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:08:37 - INFO - __main__ - Printing 3 examples
05/25/2022 08:08:37 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 08:08:37 - INFO - __main__ - ['Company']
05/25/2022 08:08:37 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 08:08:37 - INFO - __main__ - ['Company']
05/25/2022 08:08:37 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 08:08:37 - INFO - __main__ - ['Company']
05/25/2022 08:08:37 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:08:37 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:08:38 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 08:08:54 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 08:08:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 08:08:55 - INFO - __main__ - Starting training!
05/25/2022 08:08:59 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7909874004642509 on epoch=53
05/25/2022 08:08:59 - INFO - __main__ - save last model!
05/25/2022 08:08:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 08:08:59 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 08:08:59 - INFO - __main__ - Printing 3 examples
05/25/2022 08:08:59 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 08:08:59 - INFO - __main__ - ['Animal']
05/25/2022 08:08:59 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 08:08:59 - INFO - __main__ - ['Animal']
05/25/2022 08:08:59 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 08:08:59 - INFO - __main__ - ['Village']
05/25/2022 08:08:59 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:09:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:09:04 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 08:11:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.5_8_predictions.txt
05/25/2022 08:11:10 - INFO - __main__ - Classification-F1 on test data: 0.6464
05/25/2022 08:11:11 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.5, bsz=8, dev_performance=0.8539072225809561, test_performance=0.6463902688962675
05/25/2022 08:11:11 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.4, bsz=8 ...
05/25/2022 08:11:12 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:11:12 - INFO - __main__ - Printing 3 examples
05/25/2022 08:11:12 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 08:11:12 - INFO - __main__ - ['Company']
05/25/2022 08:11:12 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 08:11:12 - INFO - __main__ - ['Company']
05/25/2022 08:11:12 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 08:11:12 - INFO - __main__ - ['Company']
05/25/2022 08:11:12 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:11:12 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:11:13 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 08:11:13 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:11:13 - INFO - __main__ - Printing 3 examples
05/25/2022 08:11:13 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 08:11:13 - INFO - __main__ - ['Company']
05/25/2022 08:11:13 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 08:11:13 - INFO - __main__ - ['Company']
05/25/2022 08:11:13 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 08:11:13 - INFO - __main__ - ['Company']
05/25/2022 08:11:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:11:13 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:11:14 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 08:11:30 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 08:11:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 08:11:30 - INFO - __main__ - Starting training!
05/25/2022 08:11:34 - INFO - __main__ - Step 10 Global step 10 Train loss 7.02 on epoch=0
05/25/2022 08:11:37 - INFO - __main__ - Step 20 Global step 20 Train loss 4.78 on epoch=0
05/25/2022 08:11:39 - INFO - __main__ - Step 30 Global step 30 Train loss 4.07 on epoch=0
05/25/2022 08:11:42 - INFO - __main__ - Step 40 Global step 40 Train loss 3.44 on epoch=0
05/25/2022 08:11:45 - INFO - __main__ - Step 50 Global step 50 Train loss 3.21 on epoch=0
05/25/2022 08:12:12 - INFO - __main__ - Global step 50 Train loss 4.51 Classification-F1 0.01577421228497689 on epoch=0
05/25/2022 08:12:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01577421228497689 on epoch=0, global_step=50
05/25/2022 08:12:14 - INFO - __main__ - Step 60 Global step 60 Train loss 2.78 on epoch=1
05/25/2022 08:12:17 - INFO - __main__ - Step 70 Global step 70 Train loss 2.54 on epoch=1
05/25/2022 08:12:20 - INFO - __main__ - Step 80 Global step 80 Train loss 2.35 on epoch=1
05/25/2022 08:12:22 - INFO - __main__ - Step 90 Global step 90 Train loss 2.16 on epoch=1
05/25/2022 08:12:25 - INFO - __main__ - Step 100 Global step 100 Train loss 2.04 on epoch=1
05/25/2022 08:12:49 - INFO - __main__ - Global step 100 Train loss 2.37 Classification-F1 0.05009276886221808 on epoch=1
05/25/2022 08:12:49 - INFO - __main__ - Saving model with best Classification-F1: 0.01577421228497689 -> 0.05009276886221808 on epoch=1, global_step=100
05/25/2022 08:12:52 - INFO - __main__ - Step 110 Global step 110 Train loss 1.79 on epoch=1
05/25/2022 08:12:54 - INFO - __main__ - Step 120 Global step 120 Train loss 1.87 on epoch=2
05/25/2022 08:12:57 - INFO - __main__ - Step 130 Global step 130 Train loss 1.57 on epoch=2
05/25/2022 08:12:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.50 on epoch=2
05/25/2022 08:13:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=2
05/25/2022 08:13:25 - INFO - __main__ - Global step 150 Train loss 1.63 Classification-F1 0.08639893065514782 on epoch=2
05/25/2022 08:13:25 - INFO - __main__ - Saving model with best Classification-F1: 0.05009276886221808 -> 0.08639893065514782 on epoch=2, global_step=150
05/25/2022 08:13:28 - INFO - __main__ - Step 160 Global step 160 Train loss 1.33 on epoch=2
05/25/2022 08:13:30 - INFO - __main__ - Step 170 Global step 170 Train loss 1.13 on epoch=3
05/25/2022 08:13:33 - INFO - __main__ - Step 180 Global step 180 Train loss 1.27 on epoch=3
05/25/2022 08:13:35 - INFO - __main__ - Step 190 Global step 190 Train loss 0.99 on epoch=3
05/25/2022 08:13:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=3
05/25/2022 08:14:00 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.1533908703198782 on epoch=3
05/25/2022 08:14:00 - INFO - __main__ - Saving model with best Classification-F1: 0.08639893065514782 -> 0.1533908703198782 on epoch=3, global_step=200
05/25/2022 08:14:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.95 on epoch=3
05/25/2022 08:14:06 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=3
05/25/2022 08:14:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=4
05/25/2022 08:14:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.83 on epoch=4
05/25/2022 08:14:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.67 on epoch=4
05/25/2022 08:14:39 - INFO - __main__ - Global step 250 Train loss 0.80 Classification-F1 0.228768190340444 on epoch=4
05/25/2022 08:14:39 - INFO - __main__ - Saving model with best Classification-F1: 0.1533908703198782 -> 0.228768190340444 on epoch=4, global_step=250
05/25/2022 08:14:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=4
05/25/2022 08:14:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=4
05/25/2022 08:14:46 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=4
05/25/2022 08:14:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=5
05/25/2022 08:14:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=5
05/25/2022 08:15:19 - INFO - __main__ - Global step 300 Train loss 0.57 Classification-F1 0.3419928186090523 on epoch=5
05/25/2022 08:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.228768190340444 -> 0.3419928186090523 on epoch=5, global_step=300
05/25/2022 08:15:21 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=5
05/25/2022 08:15:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=5
05/25/2022 08:15:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=5
05/25/2022 08:15:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=6
05/25/2022 08:15:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=6
05/25/2022 08:15:58 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.3534798164695738 on epoch=6
05/25/2022 08:15:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3419928186090523 -> 0.3534798164695738 on epoch=6, global_step=350
05/25/2022 08:16:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=6
05/25/2022 08:16:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=6
05/25/2022 08:16:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.34 on epoch=6
05/25/2022 08:16:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=6
05/25/2022 08:16:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=7
05/25/2022 08:16:37 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.396729117695053 on epoch=7
05/25/2022 08:16:37 - INFO - __main__ - Saving model with best Classification-F1: 0.3534798164695738 -> 0.396729117695053 on epoch=7, global_step=400
05/25/2022 08:16:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=7
05/25/2022 08:16:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=7
05/25/2022 08:16:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=7
05/25/2022 08:16:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=7
05/25/2022 08:16:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.29 on epoch=8
05/25/2022 08:17:16 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.382121830260472 on epoch=8
05/25/2022 08:17:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=8
05/25/2022 08:17:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=8
05/25/2022 08:17:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=8
05/25/2022 08:17:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=8
05/25/2022 08:17:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=8
05/25/2022 08:17:55 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.48185364581807083 on epoch=8
05/25/2022 08:17:55 - INFO - __main__ - Saving model with best Classification-F1: 0.396729117695053 -> 0.48185364581807083 on epoch=8, global_step=500
05/25/2022 08:17:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=9
05/25/2022 08:18:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=9
05/25/2022 08:18:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=9
05/25/2022 08:18:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=9
05/25/2022 08:18:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=9
05/25/2022 08:18:36 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.4943083804758578 on epoch=9
05/25/2022 08:18:36 - INFO - __main__ - Saving model with best Classification-F1: 0.48185364581807083 -> 0.4943083804758578 on epoch=9, global_step=550
05/25/2022 08:18:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.26 on epoch=9
05/25/2022 08:18:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=10
05/25/2022 08:18:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=10
05/25/2022 08:18:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=10
05/25/2022 08:18:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=10
05/25/2022 08:19:15 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.4077923369784793 on epoch=10
05/25/2022 08:19:17 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=10
05/25/2022 08:19:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/25/2022 08:19:23 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=11
05/25/2022 08:19:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
05/25/2022 08:19:28 - INFO - __main__ - Step 650 Global step 650 Train loss 0.20 on epoch=11
05/25/2022 08:19:54 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.47609608267304054 on epoch=11
05/25/2022 08:19:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=11
05/25/2022 08:19:59 - INFO - __main__ - Step 670 Global step 670 Train loss 0.14 on epoch=11
05/25/2022 08:20:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=12
05/25/2022 08:20:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=12
05/25/2022 08:20:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=12
05/25/2022 08:20:33 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.5805837349931673 on epoch=12
05/25/2022 08:20:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4943083804758578 -> 0.5805837349931673 on epoch=12, global_step=700
05/25/2022 08:20:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=12
05/25/2022 08:20:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=12
05/25/2022 08:20:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=13
05/25/2022 08:20:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=13
05/25/2022 08:20:46 - INFO - __main__ - Step 750 Global step 750 Train loss 0.21 on epoch=13
05/25/2022 08:21:11 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.5157164114907086 on epoch=13
05/25/2022 08:21:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=13
05/25/2022 08:21:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=13
05/25/2022 08:21:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.16 on epoch=13
05/25/2022 08:21:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=14
05/25/2022 08:21:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=14
05/25/2022 08:21:49 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.474951450395158 on epoch=14
05/25/2022 08:21:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=14
05/25/2022 08:21:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=14
05/25/2022 08:21:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=14
05/25/2022 08:21:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=14
05/25/2022 08:22:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=15
05/25/2022 08:22:27 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.4906899682990769 on epoch=15
05/25/2022 08:22:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=15
05/25/2022 08:22:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=15
05/25/2022 08:22:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=15
05/25/2022 08:22:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=15
05/25/2022 08:22:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=16
05/25/2022 08:23:05 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5371933539480299 on epoch=16
05/25/2022 08:23:08 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=16
05/25/2022 08:23:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=16
05/25/2022 08:23:13 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=16
05/25/2022 08:23:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=16
05/25/2022 08:23:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=16
05/25/2022 08:23:43 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.5589110522264767 on epoch=16
05/25/2022 08:23:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=17
05/25/2022 08:23:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=17
05/25/2022 08:23:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=17
05/25/2022 08:23:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=17
05/25/2022 08:23:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=17
05/25/2022 08:24:21 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5885217644791252 on epoch=17
05/25/2022 08:24:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5805837349931673 -> 0.5885217644791252 on epoch=17, global_step=1000
05/25/2022 08:24:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=18
05/25/2022 08:24:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=18
05/25/2022 08:24:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=18
05/25/2022 08:24:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=18
05/25/2022 08:24:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=18
05/25/2022 08:24:59 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5586215069927465 on epoch=18
05/25/2022 08:25:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=18
05/25/2022 08:25:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=19
05/25/2022 08:25:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=19
05/25/2022 08:25:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/25/2022 08:25:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=19
05/25/2022 08:25:38 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6124448451741611 on epoch=19
05/25/2022 08:25:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5885217644791252 -> 0.6124448451741611 on epoch=19, global_step=1100
05/25/2022 08:25:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
05/25/2022 08:25:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=19
05/25/2022 08:25:45 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=20
05/25/2022 08:25:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=20
05/25/2022 08:25:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.05 on epoch=20
05/25/2022 08:26:16 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.5700217618112615 on epoch=20
05/25/2022 08:26:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=20
05/25/2022 08:26:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=20
05/25/2022 08:26:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=21
05/25/2022 08:26:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=21
05/25/2022 08:26:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=21
05/25/2022 08:26:54 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6743883089211682 on epoch=21
05/25/2022 08:26:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6124448451741611 -> 0.6743883089211682 on epoch=21, global_step=1200
05/25/2022 08:26:57 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=21
05/25/2022 08:26:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=21
05/25/2022 08:27:02 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=21
05/25/2022 08:27:05 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=22
05/25/2022 08:27:07 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
05/25/2022 08:27:32 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6314230286632215 on epoch=22
05/25/2022 08:27:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
05/25/2022 08:27:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=22
05/25/2022 08:27:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=22
05/25/2022 08:27:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=23
05/25/2022 08:27:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=23
05/25/2022 08:28:10 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7036201567526241 on epoch=23
05/25/2022 08:28:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6743883089211682 -> 0.7036201567526241 on epoch=23, global_step=1300
05/25/2022 08:28:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=23
05/25/2022 08:28:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=23
05/25/2022 08:28:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=23
05/25/2022 08:28:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=23
05/25/2022 08:28:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=24
05/25/2022 08:28:48 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6395775577697517 on epoch=24
05/25/2022 08:28:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
05/25/2022 08:28:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=24
05/25/2022 08:28:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=24
05/25/2022 08:28:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=24
05/25/2022 08:29:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/25/2022 08:29:26 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.5975980620444225 on epoch=24
05/25/2022 08:29:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=25
05/25/2022 08:29:31 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=25
05/25/2022 08:29:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
05/25/2022 08:29:36 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=25
05/25/2022 08:29:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=25
05/25/2022 08:30:03 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7040806880243105 on epoch=25
05/25/2022 08:30:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7036201567526241 -> 0.7040806880243105 on epoch=25, global_step=1450
05/25/2022 08:30:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=26
05/25/2022 08:30:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=26
05/25/2022 08:30:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 08:30:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=26
05/25/2022 08:30:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 08:30:42 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6480917230625036 on epoch=26
05/25/2022 08:30:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=26
05/25/2022 08:30:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=27
05/25/2022 08:30:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=27
05/25/2022 08:30:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/25/2022 08:30:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
05/25/2022 08:31:19 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6047872234795211 on epoch=27
05/25/2022 08:31:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=27
05/25/2022 08:31:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=28
05/25/2022 08:31:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=28
05/25/2022 08:31:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/25/2022 08:31:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=28
05/25/2022 08:31:57 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6463881869505007 on epoch=28
05/25/2022 08:32:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=28
05/25/2022 08:32:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=28
05/25/2022 08:32:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=29
05/25/2022 08:32:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=29
05/25/2022 08:32:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
05/25/2022 08:32:35 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7585437819072219 on epoch=29
05/25/2022 08:32:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7040806880243105 -> 0.7585437819072219 on epoch=29, global_step=1650
05/25/2022 08:32:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=29
05/25/2022 08:32:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
05/25/2022 08:32:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=29
05/25/2022 08:32:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=30
05/25/2022 08:32:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=30
05/25/2022 08:33:13 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7158403654675995 on epoch=30
05/25/2022 08:33:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=30
05/25/2022 08:33:18 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=30
05/25/2022 08:33:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/25/2022 08:33:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=31
05/25/2022 08:33:26 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=31
05/25/2022 08:33:51 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7615387438617085 on epoch=31
05/25/2022 08:33:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7585437819072219 -> 0.7615387438617085 on epoch=31, global_step=1750
05/25/2022 08:33:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
05/25/2022 08:33:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=31
05/25/2022 08:33:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=31
05/25/2022 08:34:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=31
05/25/2022 08:34:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=32
05/25/2022 08:34:29 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6821251875681356 on epoch=32
05/25/2022 08:34:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.15 on epoch=32
05/25/2022 08:34:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=32
05/25/2022 08:34:37 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/25/2022 08:34:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
05/25/2022 08:34:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=33
05/25/2022 08:35:07 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7606754286299016 on epoch=33
05/25/2022 08:35:09 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/25/2022 08:35:12 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
05/25/2022 08:35:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/25/2022 08:35:17 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=33
05/25/2022 08:35:20 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/25/2022 08:35:44 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7193786027375575 on epoch=33
05/25/2022 08:35:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=34
05/25/2022 08:35:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=34
05/25/2022 08:35:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
05/25/2022 08:35:55 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=34
05/25/2022 08:35:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=34
05/25/2022 08:36:22 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7177398706739635 on epoch=34
05/25/2022 08:36:25 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/25/2022 08:36:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/25/2022 08:36:30 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=35
05/25/2022 08:36:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/25/2022 08:36:35 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
05/25/2022 08:37:00 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8027076329812286 on epoch=35
05/25/2022 08:37:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7615387438617085 -> 0.8027076329812286 on epoch=35, global_step=2000
05/25/2022 08:37:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
05/25/2022 08:37:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/25/2022 08:37:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
05/25/2022 08:37:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
05/25/2022 08:37:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/25/2022 08:37:39 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8568288066998603 on epoch=36
05/25/2022 08:37:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8027076329812286 -> 0.8568288066998603 on epoch=36, global_step=2050
05/25/2022 08:37:41 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=36
05/25/2022 08:37:44 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
05/25/2022 08:37:46 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
05/25/2022 08:37:49 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
05/25/2022 08:37:52 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=37
05/25/2022 08:38:18 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8049196527539525 on epoch=37
05/25/2022 08:38:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/25/2022 08:38:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=37
05/25/2022 08:38:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/25/2022 08:38:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=38
05/25/2022 08:38:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=38
05/25/2022 08:38:57 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7589277848997137 on epoch=38
05/25/2022 08:38:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/25/2022 08:39:02 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=38
05/25/2022 08:39:05 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/25/2022 08:39:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
05/25/2022 08:39:10 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
05/25/2022 08:39:35 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8045910930997938 on epoch=39
05/25/2022 08:39:38 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=39
05/25/2022 08:39:41 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=39
05/25/2022 08:39:43 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
05/25/2022 08:39:46 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
05/25/2022 08:39:48 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=40
05/25/2022 08:40:13 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.8558209471115666 on epoch=40
05/25/2022 08:40:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=40
05/25/2022 08:40:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/25/2022 08:40:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=40
05/25/2022 08:40:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=40
05/25/2022 08:40:26 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=41
05/25/2022 08:40:51 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8036091312618446 on epoch=41
05/25/2022 08:40:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=41
05/25/2022 08:40:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/25/2022 08:40:59 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=41
05/25/2022 08:41:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=41
05/25/2022 08:41:04 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=41
05/25/2022 08:41:30 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7593078276372007 on epoch=41
05/25/2022 08:41:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/25/2022 08:41:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=42
05/25/2022 08:41:37 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/25/2022 08:41:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 08:41:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/25/2022 08:42:08 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8543858401461405 on epoch=42
05/25/2022 08:42:11 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=43
05/25/2022 08:42:13 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
05/25/2022 08:42:16 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
05/25/2022 08:42:18 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/25/2022 08:42:21 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=43
05/25/2022 08:42:46 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.803616768657474 on epoch=43
05/25/2022 08:42:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/25/2022 08:42:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/25/2022 08:42:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=44
05/25/2022 08:42:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/25/2022 08:42:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=44
05/25/2022 08:43:24 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8032092798373072 on epoch=44
05/25/2022 08:43:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=44
05/25/2022 08:43:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
05/25/2022 08:43:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=45
05/25/2022 08:43:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=45
05/25/2022 08:43:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=45
05/25/2022 08:44:02 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9129500616379922 on epoch=45
05/25/2022 08:44:02 - INFO - __main__ - Saving model with best Classification-F1: 0.8568288066998603 -> 0.9129500616379922 on epoch=45, global_step=2550
05/25/2022 08:44:05 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/25/2022 08:44:07 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=45
05/25/2022 08:44:10 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=46
05/25/2022 08:44:12 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=46
05/25/2022 08:44:15 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=46
05/25/2022 08:44:40 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8544201670858539 on epoch=46
05/25/2022 08:44:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/25/2022 08:44:45 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/25/2022 08:44:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=46
05/25/2022 08:44:50 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=47
05/25/2022 08:44:53 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/25/2022 08:45:19 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8533961015456594 on epoch=47
05/25/2022 08:45:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/25/2022 08:45:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/25/2022 08:45:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=47
05/25/2022 08:45:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=48
05/25/2022 08:45:32 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=48
05/25/2022 08:45:56 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8044782686963707 on epoch=48
05/25/2022 08:45:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=48
05/25/2022 08:46:02 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/25/2022 08:46:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=48
05/25/2022 08:46:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=48
05/25/2022 08:46:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=49
05/25/2022 08:46:34 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8054341396977088 on epoch=49
05/25/2022 08:46:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
05/25/2022 08:46:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/25/2022 08:46:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/25/2022 08:46:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/25/2022 08:46:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/25/2022 08:47:12 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8029832417909849 on epoch=49
05/25/2022 08:47:14 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/25/2022 08:47:17 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/25/2022 08:47:20 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/25/2022 08:47:22 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=50
05/25/2022 08:47:25 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 08:47:49 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8538421583633655 on epoch=50
05/25/2022 08:47:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/25/2022 08:47:55 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=51
05/25/2022 08:47:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=51
05/25/2022 08:48:00 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 08:48:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/25/2022 08:48:28 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8045449662415306 on epoch=51
05/25/2022 08:48:30 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 08:48:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/25/2022 08:48:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=52
05/25/2022 08:48:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/25/2022 08:48:41 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=52
05/25/2022 08:49:06 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7129301314010122 on epoch=52
05/25/2022 08:49:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=52
05/25/2022 08:49:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/25/2022 08:49:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/25/2022 08:49:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.09 on epoch=53
05/25/2022 08:49:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/25/2022 08:49:20 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:49:20 - INFO - __main__ - Printing 3 examples
05/25/2022 08:49:20 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 08:49:20 - INFO - __main__ - ['Company']
05/25/2022 08:49:20 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 08:49:20 - INFO - __main__ - ['Company']
05/25/2022 08:49:20 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 08:49:20 - INFO - __main__ - ['Company']
05/25/2022 08:49:20 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:49:21 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:49:22 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 08:49:22 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:49:22 - INFO - __main__ - Printing 3 examples
05/25/2022 08:49:22 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 08:49:22 - INFO - __main__ - ['Company']
05/25/2022 08:49:22 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 08:49:22 - INFO - __main__ - ['Company']
05/25/2022 08:49:22 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 08:49:22 - INFO - __main__ - ['Company']
05/25/2022 08:49:22 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:49:22 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:49:23 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 08:49:41 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 08:49:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 08:49:42 - INFO - __main__ - Starting training!
05/25/2022 08:49:44 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8059429321446565 on epoch=53
05/25/2022 08:49:44 - INFO - __main__ - save last model!
05/25/2022 08:49:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 08:49:44 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 08:49:44 - INFO - __main__ - Printing 3 examples
05/25/2022 08:49:44 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 08:49:44 - INFO - __main__ - ['Animal']
05/25/2022 08:49:44 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 08:49:44 - INFO - __main__ - ['Animal']
05/25/2022 08:49:44 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 08:49:44 - INFO - __main__ - ['Village']
05/25/2022 08:49:44 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:49:46 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:49:49 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 08:51:55 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.4_8_predictions.txt
05/25/2022 08:51:55 - INFO - __main__ - Classification-F1 on test data: 0.6548
05/25/2022 08:51:56 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.4, bsz=8, dev_performance=0.9129500616379922, test_performance=0.6548482749703142
05/25/2022 08:51:56 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.3, bsz=8 ...
05/25/2022 08:51:57 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:51:57 - INFO - __main__ - Printing 3 examples
05/25/2022 08:51:57 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 08:51:57 - INFO - __main__ - ['Company']
05/25/2022 08:51:57 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 08:51:57 - INFO - __main__ - ['Company']
05/25/2022 08:51:57 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 08:51:57 - INFO - __main__ - ['Company']
05/25/2022 08:51:57 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:51:57 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:51:58 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 08:51:58 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 08:51:58 - INFO - __main__ - Printing 3 examples
05/25/2022 08:51:58 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 08:51:58 - INFO - __main__ - ['Company']
05/25/2022 08:51:58 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 08:51:58 - INFO - __main__ - ['Company']
05/25/2022 08:51:58 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 08:51:58 - INFO - __main__ - ['Company']
05/25/2022 08:51:58 - INFO - __main__ - Tokenizing Input ...
05/25/2022 08:51:59 - INFO - __main__ - Tokenizing Output ...
05/25/2022 08:52:00 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 08:52:15 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 08:52:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 08:52:15 - INFO - __main__ - Starting training!
05/25/2022 08:52:19 - INFO - __main__ - Step 10 Global step 10 Train loss 7.92 on epoch=0
05/25/2022 08:52:22 - INFO - __main__ - Step 20 Global step 20 Train loss 5.02 on epoch=0
05/25/2022 08:52:24 - INFO - __main__ - Step 30 Global step 30 Train loss 4.37 on epoch=0
05/25/2022 08:52:27 - INFO - __main__ - Step 40 Global step 40 Train loss 3.86 on epoch=0
05/25/2022 08:52:30 - INFO - __main__ - Step 50 Global step 50 Train loss 3.66 on epoch=0
05/25/2022 08:52:56 - INFO - __main__ - Global step 50 Train loss 4.97 Classification-F1 0.013269561043578439 on epoch=0
05/25/2022 08:52:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.013269561043578439 on epoch=0, global_step=50
05/25/2022 08:52:58 - INFO - __main__ - Step 60 Global step 60 Train loss 3.35 on epoch=1
05/25/2022 08:53:01 - INFO - __main__ - Step 70 Global step 70 Train loss 3.08 on epoch=1
05/25/2022 08:53:04 - INFO - __main__ - Step 80 Global step 80 Train loss 2.85 on epoch=1
05/25/2022 08:53:06 - INFO - __main__ - Step 90 Global step 90 Train loss 2.49 on epoch=1
05/25/2022 08:53:09 - INFO - __main__ - Step 100 Global step 100 Train loss 2.41 on epoch=1
05/25/2022 08:53:34 - INFO - __main__ - Global step 100 Train loss 2.84 Classification-F1 0.03016718043147847 on epoch=1
05/25/2022 08:53:34 - INFO - __main__ - Saving model with best Classification-F1: 0.013269561043578439 -> 0.03016718043147847 on epoch=1, global_step=100
05/25/2022 08:53:36 - INFO - __main__ - Step 110 Global step 110 Train loss 2.29 on epoch=1
05/25/2022 08:53:39 - INFO - __main__ - Step 120 Global step 120 Train loss 2.16 on epoch=2
05/25/2022 08:53:42 - INFO - __main__ - Step 130 Global step 130 Train loss 1.89 on epoch=2
05/25/2022 08:53:44 - INFO - __main__ - Step 140 Global step 140 Train loss 1.78 on epoch=2
05/25/2022 08:53:47 - INFO - __main__ - Step 150 Global step 150 Train loss 1.85 on epoch=2
05/25/2022 08:54:10 - INFO - __main__ - Global step 150 Train loss 1.99 Classification-F1 0.0655099032015476 on epoch=2
05/25/2022 08:54:10 - INFO - __main__ - Saving model with best Classification-F1: 0.03016718043147847 -> 0.0655099032015476 on epoch=2, global_step=150
05/25/2022 08:54:12 - INFO - __main__ - Step 160 Global step 160 Train loss 1.72 on epoch=2
05/25/2022 08:54:15 - INFO - __main__ - Step 170 Global step 170 Train loss 1.62 on epoch=3
05/25/2022 08:54:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.70 on epoch=3
05/25/2022 08:54:20 - INFO - __main__ - Step 190 Global step 190 Train loss 1.35 on epoch=3
05/25/2022 08:54:23 - INFO - __main__ - Step 200 Global step 200 Train loss 1.34 on epoch=3
05/25/2022 08:54:45 - INFO - __main__ - Global step 200 Train loss 1.55 Classification-F1 0.09289249715266079 on epoch=3
05/25/2022 08:54:45 - INFO - __main__ - Saving model with best Classification-F1: 0.0655099032015476 -> 0.09289249715266079 on epoch=3, global_step=200
05/25/2022 08:54:48 - INFO - __main__ - Step 210 Global step 210 Train loss 1.35 on epoch=3
05/25/2022 08:54:51 - INFO - __main__ - Step 220 Global step 220 Train loss 1.26 on epoch=3
05/25/2022 08:54:53 - INFO - __main__ - Step 230 Global step 230 Train loss 1.14 on epoch=4
05/25/2022 08:54:56 - INFO - __main__ - Step 240 Global step 240 Train loss 1.17 on epoch=4
05/25/2022 08:54:58 - INFO - __main__ - Step 250 Global step 250 Train loss 1.03 on epoch=4
05/25/2022 08:55:21 - INFO - __main__ - Global step 250 Train loss 1.19 Classification-F1 0.1484497418445042 on epoch=4
05/25/2022 08:55:21 - INFO - __main__ - Saving model with best Classification-F1: 0.09289249715266079 -> 0.1484497418445042 on epoch=4, global_step=250
05/25/2022 08:55:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.96 on epoch=4
05/25/2022 08:55:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.90 on epoch=4
05/25/2022 08:55:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=4
05/25/2022 08:55:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.85 on epoch=5
05/25/2022 08:55:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.84 on epoch=5
05/25/2022 08:55:57 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.23283388290403426 on epoch=5
05/25/2022 08:55:57 - INFO - __main__ - Saving model with best Classification-F1: 0.1484497418445042 -> 0.23283388290403426 on epoch=5, global_step=300
05/25/2022 08:56:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=5
05/25/2022 08:56:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.64 on epoch=5
05/25/2022 08:56:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=5
05/25/2022 08:56:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=6
05/25/2022 08:56:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=6
05/25/2022 08:56:36 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.2633354095841179 on epoch=6
05/25/2022 08:56:36 - INFO - __main__ - Saving model with best Classification-F1: 0.23283388290403426 -> 0.2633354095841179 on epoch=6, global_step=350
05/25/2022 08:56:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=6
05/25/2022 08:56:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=6
05/25/2022 08:56:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=6
05/25/2022 08:56:46 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=6
05/25/2022 08:56:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=7
05/25/2022 08:57:14 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.29619669982863583 on epoch=7
05/25/2022 08:57:14 - INFO - __main__ - Saving model with best Classification-F1: 0.2633354095841179 -> 0.29619669982863583 on epoch=7, global_step=400
05/25/2022 08:57:17 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=7
05/25/2022 08:57:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=7
05/25/2022 08:57:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.36 on epoch=7
05/25/2022 08:57:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=7
05/25/2022 08:57:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=8
05/25/2022 08:57:53 - INFO - __main__ - Global step 450 Train loss 0.42 Classification-F1 0.3196307047474571 on epoch=8
05/25/2022 08:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.29619669982863583 -> 0.3196307047474571 on epoch=8, global_step=450
05/25/2022 08:57:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.39 on epoch=8
05/25/2022 08:57:58 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=8
05/25/2022 08:58:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=8
05/25/2022 08:58:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.41 on epoch=8
05/25/2022 08:58:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=8
05/25/2022 08:58:31 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.34761057017797675 on epoch=8
05/25/2022 08:58:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3196307047474571 -> 0.34761057017797675 on epoch=8, global_step=500
05/25/2022 08:58:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=9
05/25/2022 08:58:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=9
05/25/2022 08:58:39 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=9
05/25/2022 08:58:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=9
05/25/2022 08:58:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.35 on epoch=9
05/25/2022 08:59:10 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.3888906686727936 on epoch=9
05/25/2022 08:59:10 - INFO - __main__ - Saving model with best Classification-F1: 0.34761057017797675 -> 0.3888906686727936 on epoch=9, global_step=550
05/25/2022 08:59:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=9
05/25/2022 08:59:16 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=10
05/25/2022 08:59:18 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=10
05/25/2022 08:59:21 - INFO - __main__ - Step 590 Global step 590 Train loss 0.31 on epoch=10
05/25/2022 08:59:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=10
05/25/2022 08:59:49 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.3700994624125255 on epoch=10
05/25/2022 08:59:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=10
05/25/2022 08:59:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=11
05/25/2022 08:59:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=11
05/25/2022 08:59:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=11
05/25/2022 09:00:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.21 on epoch=11
05/25/2022 09:00:27 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.40064266808254617 on epoch=11
05/25/2022 09:00:27 - INFO - __main__ - Saving model with best Classification-F1: 0.3888906686727936 -> 0.40064266808254617 on epoch=11, global_step=650
05/25/2022 09:00:30 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=11
05/25/2022 09:00:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.13 on epoch=11
05/25/2022 09:00:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=12
05/25/2022 09:00:38 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=12
05/25/2022 09:00:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=12
05/25/2022 09:01:05 - INFO - __main__ - Global step 700 Train loss 0.20 Classification-F1 0.4145741950314073 on epoch=12
05/25/2022 09:01:05 - INFO - __main__ - Saving model with best Classification-F1: 0.40064266808254617 -> 0.4145741950314073 on epoch=12, global_step=700
05/25/2022 09:01:08 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=12
05/25/2022 09:01:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=12
05/25/2022 09:01:13 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=13
05/25/2022 09:01:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=13
05/25/2022 09:01:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=13
05/25/2022 09:01:44 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.49179693381145173 on epoch=13
05/25/2022 09:01:44 - INFO - __main__ - Saving model with best Classification-F1: 0.4145741950314073 -> 0.49179693381145173 on epoch=13, global_step=750
05/25/2022 09:01:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=13
05/25/2022 09:01:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=13
05/25/2022 09:01:52 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=13
05/25/2022 09:01:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=14
05/25/2022 09:01:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=14
05/25/2022 09:02:22 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.4615506380714636 on epoch=14
05/25/2022 09:02:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=14
05/25/2022 09:02:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=14
05/25/2022 09:02:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=14
05/25/2022 09:02:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=14
05/25/2022 09:02:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
05/25/2022 09:03:01 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.4540155270211655 on epoch=15
05/25/2022 09:03:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=15
05/25/2022 09:03:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=15
05/25/2022 09:03:09 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
05/25/2022 09:03:12 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=15
05/25/2022 09:03:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=16
05/25/2022 09:03:40 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.4528591533179806 on epoch=16
05/25/2022 09:03:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=16
05/25/2022 09:03:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.23 on epoch=16
05/25/2022 09:03:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=16
05/25/2022 09:03:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=16
05/25/2022 09:03:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=16
05/25/2022 09:04:19 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.46120240241314997 on epoch=16
05/25/2022 09:04:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=17
05/25/2022 09:04:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=17
05/25/2022 09:04:27 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=17
05/25/2022 09:04:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=17
05/25/2022 09:04:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=17
05/25/2022 09:04:58 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.49293103484186046 on epoch=17
05/25/2022 09:04:58 - INFO - __main__ - Saving model with best Classification-F1: 0.49179693381145173 -> 0.49293103484186046 on epoch=17, global_step=1000
05/25/2022 09:05:00 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=18
05/25/2022 09:05:03 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=18
05/25/2022 09:05:05 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=18
05/25/2022 09:05:08 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=18
05/25/2022 09:05:10 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=18
05/25/2022 09:05:36 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.46415605622348577 on epoch=18
05/25/2022 09:05:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=18
05/25/2022 09:05:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=19
05/25/2022 09:05:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=19
05/25/2022 09:05:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=19
05/25/2022 09:05:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=19
05/25/2022 09:06:13 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5310740310284686 on epoch=19
05/25/2022 09:06:13 - INFO - __main__ - Saving model with best Classification-F1: 0.49293103484186046 -> 0.5310740310284686 on epoch=19, global_step=1100
05/25/2022 09:06:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=19
05/25/2022 09:06:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=19
05/25/2022 09:06:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=20
05/25/2022 09:06:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=20
05/25/2022 09:06:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=20
05/25/2022 09:06:50 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.5035940078036105 on epoch=20
05/25/2022 09:06:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=20
05/25/2022 09:06:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=20
05/25/2022 09:06:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=21
05/25/2022 09:07:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=21
05/25/2022 09:07:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=21
05/25/2022 09:07:28 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5074389623082952 on epoch=21
05/25/2022 09:07:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/25/2022 09:07:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=21
05/25/2022 09:07:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=21
05/25/2022 09:07:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=22
05/25/2022 09:07:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=22
05/25/2022 09:08:05 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.5267794687026304 on epoch=22
05/25/2022 09:08:08 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=22
05/25/2022 09:08:10 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=22
05/25/2022 09:08:13 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=22
05/25/2022 09:08:16 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=23
05/25/2022 09:08:18 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=23
05/25/2022 09:08:44 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.5950695585099849 on epoch=23
05/25/2022 09:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5310740310284686 -> 0.5950695585099849 on epoch=23, global_step=1300
05/25/2022 09:08:47 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=23
05/25/2022 09:08:49 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=23
05/25/2022 09:08:52 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/25/2022 09:08:54 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=23
05/25/2022 09:08:57 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=24
05/25/2022 09:09:22 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.5290220071886175 on epoch=24
05/25/2022 09:09:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
05/25/2022 09:09:27 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/25/2022 09:09:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=24
05/25/2022 09:09:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=24
05/25/2022 09:09:35 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=24
05/25/2022 09:10:00 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6656725862233744 on epoch=24
05/25/2022 09:10:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5950695585099849 -> 0.6656725862233744 on epoch=24, global_step=1400
05/25/2022 09:10:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=25
05/25/2022 09:10:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.16 on epoch=25
05/25/2022 09:10:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=25
05/25/2022 09:10:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=25
05/25/2022 09:10:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=25
05/25/2022 09:10:38 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.6621444239309043 on epoch=25
05/25/2022 09:10:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
05/25/2022 09:10:44 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=26
05/25/2022 09:10:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=26
05/25/2022 09:10:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=26
05/25/2022 09:10:52 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=26
05/25/2022 09:11:16 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6238334655708717 on epoch=26
05/25/2022 09:11:19 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=26
05/25/2022 09:11:21 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=27
05/25/2022 09:11:24 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=27
05/25/2022 09:11:27 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/25/2022 09:11:29 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=27
05/25/2022 09:11:54 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6310442056910853 on epoch=27
05/25/2022 09:11:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=27
05/25/2022 09:12:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=28
05/25/2022 09:12:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=28
05/25/2022 09:12:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=28
05/25/2022 09:12:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=28
05/25/2022 09:12:32 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6323803908735904 on epoch=28
05/25/2022 09:12:35 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=28
05/25/2022 09:12:38 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/25/2022 09:12:40 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=29
05/25/2022 09:12:43 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/25/2022 09:12:45 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=29
05/25/2022 09:13:09 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5933330056453341 on epoch=29
05/25/2022 09:13:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/25/2022 09:13:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=29
05/25/2022 09:13:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=29
05/25/2022 09:13:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=30
05/25/2022 09:13:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=30
05/25/2022 09:13:48 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6160626144381349 on epoch=30
05/25/2022 09:13:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=30
05/25/2022 09:13:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=30
05/25/2022 09:13:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=30
05/25/2022 09:13:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
05/25/2022 09:14:01 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.06 on epoch=31
05/25/2022 09:14:26 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.6800853833592766 on epoch=31
05/25/2022 09:14:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6656725862233744 -> 0.6800853833592766 on epoch=31, global_step=1750
05/25/2022 09:14:29 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=31
05/25/2022 09:14:32 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
05/25/2022 09:14:34 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=31
05/25/2022 09:14:37 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=31
05/25/2022 09:14:39 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=32
05/25/2022 09:15:05 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.6884931930198763 on epoch=32
05/25/2022 09:15:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6800853833592766 -> 0.6884931930198763 on epoch=32, global_step=1800
05/25/2022 09:15:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
05/25/2022 09:15:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
05/25/2022 09:15:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=32
05/25/2022 09:15:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=32
05/25/2022 09:15:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=33
05/25/2022 09:15:43 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6474380006738873 on epoch=33
05/25/2022 09:15:45 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/25/2022 09:15:48 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/25/2022 09:15:51 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=33
05/25/2022 09:15:53 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=33
05/25/2022 09:15:56 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/25/2022 09:16:21 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5743790025407329 on epoch=33
05/25/2022 09:16:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=34
05/25/2022 09:16:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=34
05/25/2022 09:16:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=34
05/25/2022 09:16:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=34
05/25/2022 09:16:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=34
05/25/2022 09:16:58 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.4399179363577569 on epoch=34
05/25/2022 09:17:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/25/2022 09:17:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/25/2022 09:17:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=35
05/25/2022 09:17:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=35
05/25/2022 09:17:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=35
05/25/2022 09:17:36 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6264775615909132 on epoch=35
05/25/2022 09:17:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=35
05/25/2022 09:17:41 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=36
05/25/2022 09:17:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=36
05/25/2022 09:17:46 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=36
05/25/2022 09:17:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/25/2022 09:18:13 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5956416107474231 on epoch=36
05/25/2022 09:18:16 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/25/2022 09:18:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=36
05/25/2022 09:18:21 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=37
05/25/2022 09:18:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=37
05/25/2022 09:18:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=37
05/25/2022 09:18:52 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7114944203408108 on epoch=37
05/25/2022 09:18:52 - INFO - __main__ - Saving model with best Classification-F1: 0.6884931930198763 -> 0.7114944203408108 on epoch=37, global_step=2100
05/25/2022 09:18:54 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=37
05/25/2022 09:18:57 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/25/2022 09:19:00 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/25/2022 09:19:02 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=38
05/25/2022 09:19:05 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/25/2022 09:19:30 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6646775043020468 on epoch=38
05/25/2022 09:19:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/25/2022 09:19:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=38
05/25/2022 09:19:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/25/2022 09:19:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=39
05/25/2022 09:19:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=39
05/25/2022 09:20:07 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.6416047127876036 on epoch=39
05/25/2022 09:20:10 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=39
05/25/2022 09:20:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=39
05/25/2022 09:20:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=39
05/25/2022 09:20:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=39
05/25/2022 09:20:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.07 on epoch=40
05/25/2022 09:20:45 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7122398008861115 on epoch=40
05/25/2022 09:20:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7114944203408108 -> 0.7122398008861115 on epoch=40, global_step=2250
05/25/2022 09:20:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=40
05/25/2022 09:20:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=40
05/25/2022 09:20:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=40
05/25/2022 09:20:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 09:20:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/25/2022 09:21:23 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.755029302209945 on epoch=41
05/25/2022 09:21:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7122398008861115 -> 0.755029302209945 on epoch=41, global_step=2300
05/25/2022 09:21:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=41
05/25/2022 09:21:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
05/25/2022 09:21:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/25/2022 09:21:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=41
05/25/2022 09:21:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/25/2022 09:22:02 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6816297881859783 on epoch=41
05/25/2022 09:22:04 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=42
05/25/2022 09:22:07 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=42
05/25/2022 09:22:09 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/25/2022 09:22:12 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=42
05/25/2022 09:22:15 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=42
05/25/2022 09:22:39 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6425905430088297 on epoch=42
05/25/2022 09:22:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=43
05/25/2022 09:22:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=43
05/25/2022 09:22:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=43
05/25/2022 09:22:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/25/2022 09:22:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/25/2022 09:23:17 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6127948145741368 on epoch=43
05/25/2022 09:23:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 09:23:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/25/2022 09:23:25 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=44
05/25/2022 09:23:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 09:23:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=44
05/25/2022 09:23:55 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.5882246417688634 on epoch=44
05/25/2022 09:23:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/25/2022 09:24:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/25/2022 09:24:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/25/2022 09:24:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=45
05/25/2022 09:24:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/25/2022 09:24:32 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5780336508036316 on epoch=45
05/25/2022 09:24:35 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/25/2022 09:24:37 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/25/2022 09:24:40 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=46
05/25/2022 09:24:43 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=46
05/25/2022 09:24:45 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=46
05/25/2022 09:25:10 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.6443568663512108 on epoch=46
05/25/2022 09:25:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/25/2022 09:25:15 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=46
05/25/2022 09:25:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
05/25/2022 09:25:20 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=47
05/25/2022 09:25:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=47
05/25/2022 09:25:48 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.672403391080372 on epoch=47
05/25/2022 09:25:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=47
05/25/2022 09:25:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=47
05/25/2022 09:25:56 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/25/2022 09:25:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 09:26:01 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=48
05/25/2022 09:26:25 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6776564651751775 on epoch=48
05/25/2022 09:26:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=48
05/25/2022 09:26:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/25/2022 09:26:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=48
05/25/2022 09:26:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/25/2022 09:26:38 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/25/2022 09:27:03 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6818122489242668 on epoch=49
05/25/2022 09:27:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=49
05/25/2022 09:27:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=49
05/25/2022 09:27:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=49
05/25/2022 09:27:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/25/2022 09:27:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/25/2022 09:27:41 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5905861251492857 on epoch=49
05/25/2022 09:27:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/25/2022 09:27:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=50
05/25/2022 09:27:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 09:27:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/25/2022 09:27:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 09:28:19 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.5859383443815267 on epoch=50
05/25/2022 09:28:22 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=51
05/25/2022 09:28:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
05/25/2022 09:28:27 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=51
05/25/2022 09:28:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 09:28:32 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/25/2022 09:28:57 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7189729611288934 on epoch=51
05/25/2022 09:29:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=51
05/25/2022 09:29:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=52
05/25/2022 09:29:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
05/25/2022 09:29:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/25/2022 09:29:10 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/25/2022 09:29:35 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.6152720305127228 on epoch=52
05/25/2022 09:29:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/25/2022 09:29:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 09:29:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/25/2022 09:29:46 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/25/2022 09:29:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/25/2022 09:29:50 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 09:29:50 - INFO - __main__ - Printing 3 examples
05/25/2022 09:29:50 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 09:29:50 - INFO - __main__ - ['Company']
05/25/2022 09:29:50 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 09:29:50 - INFO - __main__ - ['Company']
05/25/2022 09:29:50 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 09:29:50 - INFO - __main__ - ['Company']
05/25/2022 09:29:50 - INFO - __main__ - Tokenizing Input ...
05/25/2022 09:29:50 - INFO - __main__ - Tokenizing Output ...
05/25/2022 09:29:51 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 09:29:51 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 09:29:51 - INFO - __main__ - Printing 3 examples
05/25/2022 09:29:51 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 09:29:51 - INFO - __main__ - ['Company']
05/25/2022 09:29:51 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 09:29:51 - INFO - __main__ - ['Company']
05/25/2022 09:29:51 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 09:29:51 - INFO - __main__ - ['Company']
05/25/2022 09:29:51 - INFO - __main__ - Tokenizing Input ...
05/25/2022 09:29:52 - INFO - __main__ - Tokenizing Output ...
05/25/2022 09:29:52 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 09:30:11 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 09:30:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 09:30:12 - INFO - __main__ - Starting training!
05/25/2022 09:30:14 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6822105806426609 on epoch=53
05/25/2022 09:30:14 - INFO - __main__ - save last model!
05/25/2022 09:30:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 09:30:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 09:30:14 - INFO - __main__ - Printing 3 examples
05/25/2022 09:30:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 09:30:14 - INFO - __main__ - ['Animal']
05/25/2022 09:30:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 09:30:14 - INFO - __main__ - ['Animal']
05/25/2022 09:30:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 09:30:14 - INFO - __main__ - ['Village']
05/25/2022 09:30:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 09:30:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 09:30:20 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 09:32:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.3_8_predictions.txt
05/25/2022 09:32:29 - INFO - __main__ - Classification-F1 on test data: 0.5465
05/25/2022 09:32:30 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.3, bsz=8, dev_performance=0.755029302209945, test_performance=0.546530126781662
05/25/2022 09:32:30 - INFO - __main__ - Running ... prefix=dbpedia_14_64_42, lr=0.2, bsz=8 ...
05/25/2022 09:32:31 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 09:32:31 - INFO - __main__ - Printing 3 examples
05/25/2022 09:32:31 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/25/2022 09:32:31 - INFO - __main__ - ['Company']
05/25/2022 09:32:31 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/25/2022 09:32:31 - INFO - __main__ - ['Company']
05/25/2022 09:32:31 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/25/2022 09:32:31 - INFO - __main__ - ['Company']
05/25/2022 09:32:31 - INFO - __main__ - Tokenizing Input ...
05/25/2022 09:32:31 - INFO - __main__ - Tokenizing Output ...
05/25/2022 09:32:32 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 09:32:32 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 09:32:32 - INFO - __main__ - Printing 3 examples
05/25/2022 09:32:32 - INFO - __main__ -  [dbpedia_14] Shock Records (now part of Shock Entertainment) is Australia's largest independent record label operating for 24 years releasing independent music to the Australian marketplace.Current major music partners include Cooking Vinyl (including Marilyn Manson The Prodigy Groove Armada and Underworld); Sunday Best (Kitty Daisy & Lewis); Rise Records (Of Mice & Men Miss May I Hot Water Music); Vagrant (including Edward Sharpe and the Magnetic Zeros); Sumerian (Asking Alexandria I See Stars Veil of Maya); and Rough Trade (including Belle and Sebastian).
05/25/2022 09:32:32 - INFO - __main__ - ['Company']
05/25/2022 09:32:32 - INFO - __main__ -  [dbpedia_14] Actio Corporation is an American software company founded in 1996. The company began as an MSDS authoring and data management service using a hosted model which is now known as SaaS or software-as-a-service but in the mid-90's was called ASP.
05/25/2022 09:32:32 - INFO - __main__ - ['Company']
05/25/2022 09:32:32 - INFO - __main__ -  [dbpedia_14] Pacific Corporate Group is a global alternative investment management and advisory company headquartered in La Jolla California. PCG together with affiliates and subsidiaries (together the affiliates) currently manage over $17 billion in assets and has invested and advised upon over $44 billion since 1990. PCG and its affiliates operate through offices based out of La Jolla New York Danvers Washington D.C Singapore and Hong Kong
05/25/2022 09:32:32 - INFO - __main__ - ['Company']
05/25/2022 09:32:32 - INFO - __main__ - Tokenizing Input ...
05/25/2022 09:32:32 - INFO - __main__ - Tokenizing Output ...
05/25/2022 09:32:33 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 09:32:49 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 09:32:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 09:32:49 - INFO - __main__ - Starting training!
05/25/2022 09:32:53 - INFO - __main__ - Step 10 Global step 10 Train loss 7.97 on epoch=0
05/25/2022 09:32:56 - INFO - __main__ - Step 20 Global step 20 Train loss 5.79 on epoch=0
05/25/2022 09:32:58 - INFO - __main__ - Step 30 Global step 30 Train loss 5.03 on epoch=0
05/25/2022 09:33:01 - INFO - __main__ - Step 40 Global step 40 Train loss 4.58 on epoch=0
05/25/2022 09:33:03 - INFO - __main__ - Step 50 Global step 50 Train loss 4.39 on epoch=0
05/25/2022 09:33:27 - INFO - __main__ - Global step 50 Train loss 5.55 Classification-F1 0.011784142166947627 on epoch=0
05/25/2022 09:33:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.011784142166947627 on epoch=0, global_step=50
05/25/2022 09:33:30 - INFO - __main__ - Step 60 Global step 60 Train loss 4.03 on epoch=1
05/25/2022 09:33:32 - INFO - __main__ - Step 70 Global step 70 Train loss 3.82 on epoch=1
05/25/2022 09:33:35 - INFO - __main__ - Step 80 Global step 80 Train loss 3.42 on epoch=1
05/25/2022 09:33:37 - INFO - __main__ - Step 90 Global step 90 Train loss 3.32 on epoch=1
05/25/2022 09:33:40 - INFO - __main__ - Step 100 Global step 100 Train loss 3.15 on epoch=1
05/25/2022 09:34:07 - INFO - __main__ - Global step 100 Train loss 3.54 Classification-F1 0.01576436868530511 on epoch=1
05/25/2022 09:34:07 - INFO - __main__ - Saving model with best Classification-F1: 0.011784142166947627 -> 0.01576436868530511 on epoch=1, global_step=100
05/25/2022 09:34:10 - INFO - __main__ - Step 110 Global step 110 Train loss 2.85 on epoch=1
05/25/2022 09:34:12 - INFO - __main__ - Step 120 Global step 120 Train loss 2.79 on epoch=2
05/25/2022 09:34:15 - INFO - __main__ - Step 130 Global step 130 Train loss 2.40 on epoch=2
05/25/2022 09:34:17 - INFO - __main__ - Step 140 Global step 140 Train loss 2.29 on epoch=2
05/25/2022 09:34:20 - INFO - __main__ - Step 150 Global step 150 Train loss 2.34 on epoch=2
05/25/2022 09:34:45 - INFO - __main__ - Global step 150 Train loss 2.53 Classification-F1 0.032439693960487764 on epoch=2
05/25/2022 09:34:45 - INFO - __main__ - Saving model with best Classification-F1: 0.01576436868530511 -> 0.032439693960487764 on epoch=2, global_step=150
05/25/2022 09:34:48 - INFO - __main__ - Step 160 Global step 160 Train loss 2.22 on epoch=2
05/25/2022 09:34:50 - INFO - __main__ - Step 170 Global step 170 Train loss 2.08 on epoch=3
05/25/2022 09:34:53 - INFO - __main__ - Step 180 Global step 180 Train loss 2.24 on epoch=3
05/25/2022 09:34:56 - INFO - __main__ - Step 190 Global step 190 Train loss 1.70 on epoch=3
05/25/2022 09:34:58 - INFO - __main__ - Step 200 Global step 200 Train loss 1.94 on epoch=3
05/25/2022 09:35:22 - INFO - __main__ - Global step 200 Train loss 2.03 Classification-F1 0.050676460317804685 on epoch=3
05/25/2022 09:35:22 - INFO - __main__ - Saving model with best Classification-F1: 0.032439693960487764 -> 0.050676460317804685 on epoch=3, global_step=200
05/25/2022 09:35:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.91 on epoch=3
05/25/2022 09:35:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.81 on epoch=3
05/25/2022 09:35:30 - INFO - __main__ - Step 230 Global step 230 Train loss 1.73 on epoch=4
05/25/2022 09:35:32 - INFO - __main__ - Step 240 Global step 240 Train loss 1.77 on epoch=4
05/25/2022 09:35:35 - INFO - __main__ - Step 250 Global step 250 Train loss 1.52 on epoch=4
05/25/2022 09:35:57 - INFO - __main__ - Global step 250 Train loss 1.75 Classification-F1 0.0763563387673828 on epoch=4
05/25/2022 09:35:58 - INFO - __main__ - Saving model with best Classification-F1: 0.050676460317804685 -> 0.0763563387673828 on epoch=4, global_step=250
05/25/2022 09:36:00 - INFO - __main__ - Step 260 Global step 260 Train loss 1.51 on epoch=4
05/25/2022 09:36:03 - INFO - __main__ - Step 270 Global step 270 Train loss 1.53 on epoch=4
05/25/2022 09:36:05 - INFO - __main__ - Step 280 Global step 280 Train loss 1.37 on epoch=4
05/25/2022 09:36:08 - INFO - __main__ - Step 290 Global step 290 Train loss 1.58 on epoch=5
05/25/2022 09:36:11 - INFO - __main__ - Step 300 Global step 300 Train loss 1.22 on epoch=5
05/25/2022 09:36:33 - INFO - __main__ - Global step 300 Train loss 1.44 Classification-F1 0.1047545880264178 on epoch=5
05/25/2022 09:36:33 - INFO - __main__ - Saving model with best Classification-F1: 0.0763563387673828 -> 0.1047545880264178 on epoch=5, global_step=300
05/25/2022 09:36:36 - INFO - __main__ - Step 310 Global step 310 Train loss 1.29 on epoch=5
05/25/2022 09:36:39 - INFO - __main__ - Step 320 Global step 320 Train loss 1.30 on epoch=5
05/25/2022 09:36:41 - INFO - __main__ - Step 330 Global step 330 Train loss 1.19 on epoch=5
05/25/2022 09:36:44 - INFO - __main__ - Step 340 Global step 340 Train loss 1.25 on epoch=6
05/25/2022 09:36:46 - INFO - __main__ - Step 350 Global step 350 Train loss 1.06 on epoch=6
05/25/2022 09:37:08 - INFO - __main__ - Global step 350 Train loss 1.22 Classification-F1 0.16548644676362856 on epoch=6
05/25/2022 09:37:09 - INFO - __main__ - Saving model with best Classification-F1: 0.1047545880264178 -> 0.16548644676362856 on epoch=6, global_step=350
05/25/2022 09:37:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.96 on epoch=6
05/25/2022 09:37:14 - INFO - __main__ - Step 370 Global step 370 Train loss 1.05 on epoch=6
05/25/2022 09:37:16 - INFO - __main__ - Step 380 Global step 380 Train loss 1.07 on epoch=6
05/25/2022 09:37:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.92 on epoch=6
05/25/2022 09:37:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.97 on epoch=7
05/25/2022 09:37:44 - INFO - __main__ - Global step 400 Train loss 0.99 Classification-F1 0.18675753844417636 on epoch=7
05/25/2022 09:37:44 - INFO - __main__ - Saving model with best Classification-F1: 0.16548644676362856 -> 0.18675753844417636 on epoch=7, global_step=400
05/25/2022 09:37:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.78 on epoch=7
05/25/2022 09:37:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.72 on epoch=7
05/25/2022 09:37:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.77 on epoch=7
05/25/2022 09:37:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.83 on epoch=7
05/25/2022 09:37:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.68 on epoch=8
05/25/2022 09:38:21 - INFO - __main__ - Global step 450 Train loss 0.76 Classification-F1 0.2051838502457731 on epoch=8
05/25/2022 09:38:21 - INFO - __main__ - Saving model with best Classification-F1: 0.18675753844417636 -> 0.2051838502457731 on epoch=8, global_step=450
05/25/2022 09:38:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=8
05/25/2022 09:38:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=8
05/25/2022 09:38:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.69 on epoch=8
05/25/2022 09:38:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=8
05/25/2022 09:38:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=8
05/25/2022 09:39:00 - INFO - __main__ - Global step 500 Train loss 0.66 Classification-F1 0.23810382316599268 on epoch=8
05/25/2022 09:39:00 - INFO - __main__ - Saving model with best Classification-F1: 0.2051838502457731 -> 0.23810382316599268 on epoch=8, global_step=500
05/25/2022 09:39:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.64 on epoch=9
05/25/2022 09:39:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=9
05/25/2022 09:39:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.52 on epoch=9
05/25/2022 09:39:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=9
05/25/2022 09:39:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.53 on epoch=9
05/25/2022 09:39:39 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.25609606660233025 on epoch=9
05/25/2022 09:39:39 - INFO - __main__ - Saving model with best Classification-F1: 0.23810382316599268 -> 0.25609606660233025 on epoch=9, global_step=550
05/25/2022 09:39:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.46 on epoch=9
05/25/2022 09:39:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.56 on epoch=10
05/25/2022 09:39:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.55 on epoch=10
05/25/2022 09:39:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=10
05/25/2022 09:39:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.49 on epoch=10
05/25/2022 09:40:18 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.27405526360784027 on epoch=10
05/25/2022 09:40:19 - INFO - __main__ - Saving model with best Classification-F1: 0.25609606660233025 -> 0.27405526360784027 on epoch=10, global_step=600
05/25/2022 09:40:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=10
05/25/2022 09:40:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=11
05/25/2022 09:40:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=11
05/25/2022 09:40:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=11
05/25/2022 09:40:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=11
05/25/2022 09:40:58 - INFO - __main__ - Global step 650 Train loss 0.41 Classification-F1 0.31011952962596484 on epoch=11
05/25/2022 09:40:58 - INFO - __main__ - Saving model with best Classification-F1: 0.27405526360784027 -> 0.31011952962596484 on epoch=11, global_step=650
05/25/2022 09:41:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=11
05/25/2022 09:41:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=11
05/25/2022 09:41:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=12
05/25/2022 09:41:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.39 on epoch=12
05/25/2022 09:41:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.34 on epoch=12
05/25/2022 09:41:38 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.3544176639315952 on epoch=12
05/25/2022 09:41:38 - INFO - __main__ - Saving model with best Classification-F1: 0.31011952962596484 -> 0.3544176639315952 on epoch=12, global_step=700
05/25/2022 09:41:40 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=12
05/25/2022 09:41:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=12
05/25/2022 09:41:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.33 on epoch=13
05/25/2022 09:41:48 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=13
05/25/2022 09:41:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.31 on epoch=13
05/25/2022 09:42:17 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.33332250848929257 on epoch=13
05/25/2022 09:42:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=13
05/25/2022 09:42:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=13
05/25/2022 09:42:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=13
05/25/2022 09:42:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=14
05/25/2022 09:42:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.34 on epoch=14
05/25/2022 09:42:58 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.3855308337885607 on epoch=14
05/25/2022 09:42:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3544176639315952 -> 0.3855308337885607 on epoch=14, global_step=800
05/25/2022 09:43:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=14
05/25/2022 09:43:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=14
05/25/2022 09:43:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=14
05/25/2022 09:43:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=14
05/25/2022 09:43:11 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=15
05/25/2022 09:43:37 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.36418554457398944 on epoch=15
05/25/2022 09:43:40 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=15
05/25/2022 09:43:42 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=15
05/25/2022 09:43:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.39 on epoch=15
05/25/2022 09:43:47 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=15
05/25/2022 09:43:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=16
05/25/2022 09:44:16 - INFO - __main__ - Global step 900 Train loss 0.28 Classification-F1 0.36812458159985295 on epoch=16
05/25/2022 09:44:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=16
05/25/2022 09:44:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=16
05/25/2022 09:44:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=16
05/25/2022 09:44:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=16
05/25/2022 09:44:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=16
05/25/2022 09:44:56 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.4313839395874207 on epoch=16
05/25/2022 09:44:56 - INFO - __main__ - Saving model with best Classification-F1: 0.3855308337885607 -> 0.4313839395874207 on epoch=16, global_step=950
05/25/2022 09:44:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=17
05/25/2022 09:45:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.37 on epoch=17
05/25/2022 09:45:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=17
05/25/2022 09:45:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.30 on epoch=17
05/25/2022 09:45:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=17
05/25/2022 09:45:35 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.4606690187278846 on epoch=17
05/25/2022 09:45:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4313839395874207 -> 0.4606690187278846 on epoch=17, global_step=1000
05/25/2022 09:45:38 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=18
05/25/2022 09:45:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.25 on epoch=18
05/25/2022 09:45:43 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=18
05/25/2022 09:45:46 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=18
05/25/2022 09:45:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=18
05/25/2022 09:46:14 - INFO - __main__ - Global step 1050 Train loss 0.22 Classification-F1 0.44651233396868734 on epoch=18
05/25/2022 09:46:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=18
05/25/2022 09:46:19 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=19
05/25/2022 09:46:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.31 on epoch=19
05/25/2022 09:46:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=19
05/25/2022 09:46:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.27 on epoch=19
05/25/2022 09:46:54 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.5187812033520861 on epoch=19
05/25/2022 09:46:54 - INFO - __main__ - Saving model with best Classification-F1: 0.4606690187278846 -> 0.5187812033520861 on epoch=19, global_step=1100
05/25/2022 09:46:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=19
05/25/2022 09:46:59 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.19 on epoch=19
05/25/2022 09:47:02 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=20
05/25/2022 09:47:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=20
05/25/2022 09:47:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=20
05/25/2022 09:47:33 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.49467564040455975 on epoch=20
05/25/2022 09:47:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=20
05/25/2022 09:47:38 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=20
05/25/2022 09:47:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=21
05/25/2022 09:47:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=21
05/25/2022 09:47:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.27 on epoch=21
05/25/2022 09:48:12 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.4769598228943764 on epoch=21
05/25/2022 09:48:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=21
05/25/2022 09:48:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=21
05/25/2022 09:48:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=21
05/25/2022 09:48:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.21 on epoch=22
05/25/2022 09:48:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=22
05/25/2022 09:48:51 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.49874437234626184 on epoch=22
05/25/2022 09:48:53 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=22
05/25/2022 09:48:56 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=22
05/25/2022 09:48:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=22
05/25/2022 09:49:01 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.22 on epoch=23
05/25/2022 09:49:04 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=23
05/25/2022 09:49:29 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.5042105198155763 on epoch=23
05/25/2022 09:49:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=23
05/25/2022 09:49:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=23
05/25/2022 09:49:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=23
05/25/2022 09:49:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=23
05/25/2022 09:49:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=24
05/25/2022 09:50:08 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.5091739465723473 on epoch=24
05/25/2022 09:50:11 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=24
05/25/2022 09:50:13 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=24
05/25/2022 09:50:16 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=24
05/25/2022 09:50:18 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=24
05/25/2022 09:50:21 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=24
05/25/2022 09:50:47 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.5267746086761893 on epoch=24
05/25/2022 09:50:47 - INFO - __main__ - Saving model with best Classification-F1: 0.5187812033520861 -> 0.5267746086761893 on epoch=24, global_step=1400
05/25/2022 09:50:49 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=25
05/25/2022 09:50:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=25
05/25/2022 09:50:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.16 on epoch=25
05/25/2022 09:50:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=25
05/25/2022 09:51:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=25
05/25/2022 09:51:25 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.49240882219400456 on epoch=25
05/25/2022 09:51:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=26
05/25/2022 09:51:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.16 on epoch=26
05/25/2022 09:51:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.15 on epoch=26
05/25/2022 09:51:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.19 on epoch=26
05/25/2022 09:51:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.18 on epoch=26
05/25/2022 09:52:04 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.540171952801841 on epoch=26
05/25/2022 09:52:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5267746086761893 -> 0.540171952801841 on epoch=26, global_step=1500
05/25/2022 09:52:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=26
05/25/2022 09:52:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=27
05/25/2022 09:52:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=27
05/25/2022 09:52:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=27
05/25/2022 09:52:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=27
05/25/2022 09:52:42 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.4904191056534797 on epoch=27
05/25/2022 09:52:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.21 on epoch=27
05/25/2022 09:52:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/25/2022 09:52:50 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=28
05/25/2022 09:52:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.15 on epoch=28
05/25/2022 09:52:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=28
05/25/2022 09:53:20 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.5385546005757229 on epoch=28
05/25/2022 09:53:23 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.15 on epoch=28
05/25/2022 09:53:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=28
05/25/2022 09:53:28 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=29
05/25/2022 09:53:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=29
05/25/2022 09:53:33 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=29
05/25/2022 09:53:58 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.506360122312881 on epoch=29
05/25/2022 09:54:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=29
05/25/2022 09:54:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=29
05/25/2022 09:54:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=29
05/25/2022 09:54:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=30
05/25/2022 09:54:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=30
05/25/2022 09:54:37 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.48206507541441157 on epoch=30
05/25/2022 09:54:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=30
05/25/2022 09:54:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=30
05/25/2022 09:54:45 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=30
05/25/2022 09:54:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=31
05/25/2022 09:54:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=31
05/25/2022 09:55:15 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.5138155053639993 on epoch=31
05/25/2022 09:55:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=31
05/25/2022 09:55:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=31
05/25/2022 09:55:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=31
05/25/2022 09:55:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=31
05/25/2022 09:55:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=32
05/25/2022 09:55:53 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.5175974366289102 on epoch=32
05/25/2022 09:55:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=32
05/25/2022 09:55:58 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=32
05/25/2022 09:56:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/25/2022 09:56:03 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=32
05/25/2022 09:56:06 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/25/2022 09:56:31 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.5927769034500167 on epoch=33
05/25/2022 09:56:31 - INFO - __main__ - Saving model with best Classification-F1: 0.540171952801841 -> 0.5927769034500167 on epoch=33, global_step=1850
05/25/2022 09:56:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=33
05/25/2022 09:56:37 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=33
05/25/2022 09:56:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 09:56:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=33
05/25/2022 09:56:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=33
05/25/2022 09:57:09 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.5964491568385184 on epoch=33
05/25/2022 09:57:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5927769034500167 -> 0.5964491568385184 on epoch=33, global_step=1900
05/25/2022 09:57:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=34
05/25/2022 09:57:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.17 on epoch=34
05/25/2022 09:57:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=34
05/25/2022 09:57:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.10 on epoch=34
05/25/2022 09:57:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=34
05/25/2022 09:57:47 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.5578439936352321 on epoch=34
05/25/2022 09:57:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=34
05/25/2022 09:57:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=35
05/25/2022 09:57:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=35
05/25/2022 09:57:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=35
05/25/2022 09:58:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/25/2022 09:58:24 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.5900453421550023 on epoch=35
05/25/2022 09:58:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=35
05/25/2022 09:58:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=36
05/25/2022 09:58:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=36
05/25/2022 09:58:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=36
05/25/2022 09:58:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/25/2022 09:59:02 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.5166184187095418 on epoch=36
05/25/2022 09:59:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=36
05/25/2022 09:59:07 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=36
05/25/2022 09:59:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.16 on epoch=37
05/25/2022 09:59:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=37
05/25/2022 09:59:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/25/2022 09:59:39 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.5622197743237479 on epoch=37
05/25/2022 09:59:42 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=37
05/25/2022 09:59:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=37
05/25/2022 09:59:47 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=38
05/25/2022 09:59:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=38
05/25/2022 09:59:52 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.11 on epoch=38
05/25/2022 10:00:17 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.5230230355558642 on epoch=38
05/25/2022 10:00:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
05/25/2022 10:00:22 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=38
05/25/2022 10:00:25 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=38
05/25/2022 10:00:27 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=39
05/25/2022 10:00:30 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=39
05/25/2022 10:00:54 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.5234466200100049 on epoch=39
05/25/2022 10:00:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=39
05/25/2022 10:01:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=39
05/25/2022 10:01:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=39
05/25/2022 10:01:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.09 on epoch=39
05/25/2022 10:01:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=40
05/25/2022 10:01:32 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.6046026420091549 on epoch=40
05/25/2022 10:01:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5964491568385184 -> 0.6046026420091549 on epoch=40, global_step=2250
05/25/2022 10:01:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.10 on epoch=40
05/25/2022 10:01:37 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=40
05/25/2022 10:01:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=40
05/25/2022 10:01:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=40
05/25/2022 10:01:45 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=41
05/25/2022 10:02:10 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5748400156937361 on epoch=41
05/25/2022 10:02:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=41
05/25/2022 10:02:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.12 on epoch=41
05/25/2022 10:02:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
05/25/2022 10:02:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=41
05/25/2022 10:02:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=41
05/25/2022 10:02:48 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.6352711638722895 on epoch=41
05/25/2022 10:02:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6046026420091549 -> 0.6352711638722895 on epoch=41, global_step=2350
05/25/2022 10:02:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
05/25/2022 10:02:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=42
05/25/2022 10:02:56 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/25/2022 10:02:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=42
05/25/2022 10:03:01 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=42
05/25/2022 10:03:25 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5836059622529096 on epoch=42
05/25/2022 10:03:28 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=43
05/25/2022 10:03:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=43
05/25/2022 10:03:33 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=43
05/25/2022 10:03:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=43
05/25/2022 10:03:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
05/25/2022 10:04:04 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6068994062244629 on epoch=43
05/25/2022 10:04:06 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=43
05/25/2022 10:04:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=44
05/25/2022 10:04:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=44
05/25/2022 10:04:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=44
05/25/2022 10:04:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=44
05/25/2022 10:04:41 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.5487949720176751 on epoch=44
05/25/2022 10:04:44 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=44
05/25/2022 10:04:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=44
05/25/2022 10:04:49 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.07 on epoch=45
05/25/2022 10:04:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=45
05/25/2022 10:04:54 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=45
05/25/2022 10:05:19 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.575392759035971 on epoch=45
05/25/2022 10:05:22 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=45
05/25/2022 10:05:24 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=45
05/25/2022 10:05:27 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=46
05/25/2022 10:05:29 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
05/25/2022 10:05:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=46
05/25/2022 10:05:57 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.5331375529046601 on epoch=46
05/25/2022 10:06:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=46
05/25/2022 10:06:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=46
05/25/2022 10:06:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=46
05/25/2022 10:06:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/25/2022 10:06:11 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.12 on epoch=47
05/25/2022 10:06:35 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.5056521431490585 on epoch=47
05/25/2022 10:06:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=47
05/25/2022 10:06:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=47
05/25/2022 10:06:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/25/2022 10:06:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=48
05/25/2022 10:06:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=48
05/25/2022 10:07:13 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6320119189697505 on epoch=48
05/25/2022 10:07:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.12 on epoch=48
05/25/2022 10:07:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=48
05/25/2022 10:07:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/25/2022 10:07:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=48
05/25/2022 10:07:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=49
05/25/2022 10:07:51 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6346391290877655 on epoch=49
05/25/2022 10:07:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.11 on epoch=49
05/25/2022 10:07:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/25/2022 10:07:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
05/25/2022 10:08:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/25/2022 10:08:04 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=49
05/25/2022 10:08:28 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.5727704899673299 on epoch=49
05/25/2022 10:08:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/25/2022 10:08:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=50
05/25/2022 10:08:36 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=50
05/25/2022 10:08:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=50
05/25/2022 10:08:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=50
05/25/2022 10:09:06 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.5017439867675643 on epoch=50
05/25/2022 10:09:08 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=51
05/25/2022 10:09:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=51
05/25/2022 10:09:13 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.10 on epoch=51
05/25/2022 10:09:16 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=51
05/25/2022 10:09:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=51
05/25/2022 10:09:43 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.44764911119618495 on epoch=51
05/25/2022 10:09:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=51
05/25/2022 10:09:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=52
05/25/2022 10:09:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=52
05/25/2022 10:09:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/25/2022 10:09:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/25/2022 10:10:20 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.48233921200370755 on epoch=52
05/25/2022 10:10:23 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=52
05/25/2022 10:10:26 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=53
05/25/2022 10:10:28 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=53
05/25/2022 10:10:31 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/25/2022 10:10:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=53
05/25/2022 10:10:35 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:10:35 - INFO - __main__ - Printing 3 examples
05/25/2022 10:10:35 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 10:10:35 - INFO - __main__ - ['Film']
05/25/2022 10:10:35 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 10:10:35 - INFO - __main__ - ['Film']
05/25/2022 10:10:35 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 10:10:35 - INFO - __main__ - ['Film']
05/25/2022 10:10:35 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:10:36 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:10:36 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 10:10:36 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:10:36 - INFO - __main__ - Printing 3 examples
05/25/2022 10:10:36 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 10:10:36 - INFO - __main__ - ['Film']
05/25/2022 10:10:36 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 10:10:36 - INFO - __main__ - ['Film']
05/25/2022 10:10:36 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 10:10:36 - INFO - __main__ - ['Film']
05/25/2022 10:10:36 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:10:37 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:10:38 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 10:10:53 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:10:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 10:10:54 - INFO - __main__ - Starting training!
05/25/2022 10:10:58 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.4841446698856766 on epoch=53
05/25/2022 10:10:58 - INFO - __main__ - save last model!
05/25/2022 10:10:58 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 10:10:58 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 10:10:58 - INFO - __main__ - Printing 3 examples
05/25/2022 10:10:58 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 10:10:58 - INFO - __main__ - ['Animal']
05/25/2022 10:10:58 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 10:10:58 - INFO - __main__ - ['Animal']
05/25/2022 10:10:58 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 10:10:58 - INFO - __main__ - ['Village']
05/25/2022 10:10:58 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:11:00 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:11:03 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 10:12:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_42_0.2_8_predictions.txt
05/25/2022 10:12:57 - INFO - __main__ - Classification-F1 on test data: 0.4355
05/25/2022 10:12:58 - INFO - __main__ - prefix=dbpedia_14_64_42, lr=0.2, bsz=8, dev_performance=0.6352711638722895, test_performance=0.43546900729879334
05/25/2022 10:12:58 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.5, bsz=8 ...
05/25/2022 10:12:59 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:12:59 - INFO - __main__ - Printing 3 examples
05/25/2022 10:12:59 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 10:12:59 - INFO - __main__ - ['Film']
05/25/2022 10:12:59 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 10:12:59 - INFO - __main__ - ['Film']
05/25/2022 10:12:59 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 10:12:59 - INFO - __main__ - ['Film']
05/25/2022 10:12:59 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:12:59 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:13:00 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 10:13:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:13:00 - INFO - __main__ - Printing 3 examples
05/25/2022 10:13:00 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 10:13:00 - INFO - __main__ - ['Film']
05/25/2022 10:13:00 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 10:13:00 - INFO - __main__ - ['Film']
05/25/2022 10:13:00 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 10:13:00 - INFO - __main__ - ['Film']
05/25/2022 10:13:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:13:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:13:02 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 10:13:17 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:13:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 10:13:17 - INFO - __main__ - Starting training!
05/25/2022 10:13:21 - INFO - __main__ - Step 10 Global step 10 Train loss 7.21 on epoch=0
05/25/2022 10:13:23 - INFO - __main__ - Step 20 Global step 20 Train loss 4.92 on epoch=0
05/25/2022 10:13:26 - INFO - __main__ - Step 30 Global step 30 Train loss 4.47 on epoch=0
05/25/2022 10:13:29 - INFO - __main__ - Step 40 Global step 40 Train loss 3.25 on epoch=0
05/25/2022 10:13:31 - INFO - __main__ - Step 50 Global step 50 Train loss 3.29 on epoch=0
05/25/2022 10:13:57 - INFO - __main__ - Global step 50 Train loss 4.63 Classification-F1 0.021651924338291658 on epoch=0
05/25/2022 10:13:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.021651924338291658 on epoch=0, global_step=50
05/25/2022 10:14:00 - INFO - __main__ - Step 60 Global step 60 Train loss 2.36 on epoch=1
05/25/2022 10:14:03 - INFO - __main__ - Step 70 Global step 70 Train loss 2.26 on epoch=1
05/25/2022 10:14:05 - INFO - __main__ - Step 80 Global step 80 Train loss 2.29 on epoch=1
05/25/2022 10:14:08 - INFO - __main__ - Step 90 Global step 90 Train loss 2.23 on epoch=1
05/25/2022 10:14:10 - INFO - __main__ - Step 100 Global step 100 Train loss 1.67 on epoch=1
05/25/2022 10:14:33 - INFO - __main__ - Global step 100 Train loss 2.16 Classification-F1 0.07035798234981554 on epoch=1
05/25/2022 10:14:33 - INFO - __main__ - Saving model with best Classification-F1: 0.021651924338291658 -> 0.07035798234981554 on epoch=1, global_step=100
05/25/2022 10:14:35 - INFO - __main__ - Step 110 Global step 110 Train loss 1.70 on epoch=1
05/25/2022 10:14:38 - INFO - __main__ - Step 120 Global step 120 Train loss 1.45 on epoch=2
05/25/2022 10:14:40 - INFO - __main__ - Step 130 Global step 130 Train loss 1.54 on epoch=2
05/25/2022 10:14:43 - INFO - __main__ - Step 140 Global step 140 Train loss 1.32 on epoch=2
05/25/2022 10:14:46 - INFO - __main__ - Step 150 Global step 150 Train loss 1.15 on epoch=2
05/25/2022 10:15:08 - INFO - __main__ - Global step 150 Train loss 1.43 Classification-F1 0.13804500291137864 on epoch=2
05/25/2022 10:15:08 - INFO - __main__ - Saving model with best Classification-F1: 0.07035798234981554 -> 0.13804500291137864 on epoch=2, global_step=150
05/25/2022 10:15:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.06 on epoch=2
05/25/2022 10:15:13 - INFO - __main__ - Step 170 Global step 170 Train loss 1.03 on epoch=3
05/25/2022 10:15:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.91 on epoch=3
05/25/2022 10:15:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.81 on epoch=3
05/25/2022 10:15:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=3
05/25/2022 10:15:45 - INFO - __main__ - Global step 200 Train loss 0.90 Classification-F1 0.23875647094115127 on epoch=3
05/25/2022 10:15:45 - INFO - __main__ - Saving model with best Classification-F1: 0.13804500291137864 -> 0.23875647094115127 on epoch=3, global_step=200
05/25/2022 10:15:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=3
05/25/2022 10:15:50 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=3
05/25/2022 10:15:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=4
05/25/2022 10:15:55 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=4
05/25/2022 10:15:58 - INFO - __main__ - Step 250 Global step 250 Train loss 0.47 on epoch=4
05/25/2022 10:16:23 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.3464199325366727 on epoch=4
05/25/2022 10:16:23 - INFO - __main__ - Saving model with best Classification-F1: 0.23875647094115127 -> 0.3464199325366727 on epoch=4, global_step=250
05/25/2022 10:16:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=4
05/25/2022 10:16:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=4
05/25/2022 10:16:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.34 on epoch=4
05/25/2022 10:16:33 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=5
05/25/2022 10:16:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=5
05/25/2022 10:17:01 - INFO - __main__ - Global step 300 Train loss 0.45 Classification-F1 0.33044504585014683 on epoch=5
05/25/2022 10:17:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=5
05/25/2022 10:17:06 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=5
05/25/2022 10:17:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=5
05/25/2022 10:17:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=6
05/25/2022 10:17:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=6
05/25/2022 10:17:39 - INFO - __main__ - Global step 350 Train loss 0.36 Classification-F1 0.36290175360667487 on epoch=6
05/25/2022 10:17:39 - INFO - __main__ - Saving model with best Classification-F1: 0.3464199325366727 -> 0.36290175360667487 on epoch=6, global_step=350
05/25/2022 10:17:42 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=6
05/25/2022 10:17:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=6
05/25/2022 10:17:47 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=6
05/25/2022 10:17:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.30 on epoch=6
05/25/2022 10:17:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=7
05/25/2022 10:18:17 - INFO - __main__ - Global step 400 Train loss 0.31 Classification-F1 0.39300544460069214 on epoch=7
05/25/2022 10:18:17 - INFO - __main__ - Saving model with best Classification-F1: 0.36290175360667487 -> 0.39300544460069214 on epoch=7, global_step=400
05/25/2022 10:18:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=7
05/25/2022 10:18:23 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=7
05/25/2022 10:18:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=7
05/25/2022 10:18:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=7
05/25/2022 10:18:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.20 on epoch=8
05/25/2022 10:18:56 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.4926719296312314 on epoch=8
05/25/2022 10:18:56 - INFO - __main__ - Saving model with best Classification-F1: 0.39300544460069214 -> 0.4926719296312314 on epoch=8, global_step=450
05/25/2022 10:18:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=8
05/25/2022 10:19:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.21 on epoch=8
05/25/2022 10:19:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=8
05/25/2022 10:19:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=8
05/25/2022 10:19:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=8
05/25/2022 10:19:35 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.4423056438159065 on epoch=8
05/25/2022 10:19:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=9
05/25/2022 10:19:40 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=9
05/25/2022 10:19:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=9
05/25/2022 10:19:45 - INFO - __main__ - Step 540 Global step 540 Train loss 0.16 on epoch=9
05/25/2022 10:19:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=9
05/25/2022 10:20:13 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.4580070844654568 on epoch=9
05/25/2022 10:20:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=9
05/25/2022 10:20:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=10
05/25/2022 10:20:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.22 on epoch=10
05/25/2022 10:20:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=10
05/25/2022 10:20:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=10
05/25/2022 10:20:51 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.4452019458495177 on epoch=10
05/25/2022 10:20:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=10
05/25/2022 10:20:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.17 on epoch=11
05/25/2022 10:20:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=11
05/25/2022 10:21:02 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
05/25/2022 10:21:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=11
05/25/2022 10:21:30 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.4931851290960056 on epoch=11
05/25/2022 10:21:30 - INFO - __main__ - Saving model with best Classification-F1: 0.4926719296312314 -> 0.4931851290960056 on epoch=11, global_step=650
05/25/2022 10:21:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=11
05/25/2022 10:21:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=11
05/25/2022 10:21:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=12
05/25/2022 10:21:41 - INFO - __main__ - Step 690 Global step 690 Train loss 0.10 on epoch=12
05/25/2022 10:21:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=12
05/25/2022 10:22:08 - INFO - __main__ - Global step 700 Train loss 0.14 Classification-F1 0.5674514484517386 on epoch=12
05/25/2022 10:22:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4931851290960056 -> 0.5674514484517386 on epoch=12, global_step=700
05/25/2022 10:22:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=12
05/25/2022 10:22:14 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=12
05/25/2022 10:22:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=13
05/25/2022 10:22:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=13
05/25/2022 10:22:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=13
05/25/2022 10:22:46 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.5190933274895123 on epoch=13
05/25/2022 10:22:49 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=13
05/25/2022 10:22:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.11 on epoch=13
05/25/2022 10:22:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=13
05/25/2022 10:22:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=14
05/25/2022 10:22:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=14
05/25/2022 10:23:24 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.4934651942301469 on epoch=14
05/25/2022 10:23:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=14
05/25/2022 10:23:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=14
05/25/2022 10:23:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=14
05/25/2022 10:23:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=14
05/25/2022 10:23:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=15
05/25/2022 10:24:03 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6259192871327545 on epoch=15
05/25/2022 10:24:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5674514484517386 -> 0.6259192871327545 on epoch=15, global_step=850
05/25/2022 10:24:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=15
05/25/2022 10:24:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=15
05/25/2022 10:24:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=15
05/25/2022 10:24:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.06 on epoch=15
05/25/2022 10:24:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=16
05/25/2022 10:24:41 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.5584761272272002 on epoch=16
05/25/2022 10:24:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=16
05/25/2022 10:24:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=16
05/25/2022 10:24:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.05 on epoch=16
05/25/2022 10:24:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=16
05/25/2022 10:24:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.08 on epoch=16
05/25/2022 10:25:19 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.5832339880730727 on epoch=16
05/25/2022 10:25:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=17
05/25/2022 10:25:24 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=17
05/25/2022 10:25:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=17
05/25/2022 10:25:29 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=17
05/25/2022 10:25:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=17
05/25/2022 10:25:56 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.594538528391226 on epoch=17
05/25/2022 10:25:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=18
05/25/2022 10:26:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=18
05/25/2022 10:26:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=18
05/25/2022 10:26:06 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=18
05/25/2022 10:26:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=18
05/25/2022 10:26:34 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7366446394388123 on epoch=18
05/25/2022 10:26:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6259192871327545 -> 0.7366446394388123 on epoch=18, global_step=1050
05/25/2022 10:26:36 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=18
05/25/2022 10:26:39 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
05/25/2022 10:26:41 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=19
05/25/2022 10:26:44 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=19
05/25/2022 10:26:47 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/25/2022 10:27:12 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.6483190771621301 on epoch=19
05/25/2022 10:27:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=19
05/25/2022 10:27:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=19
05/25/2022 10:27:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=20
05/25/2022 10:27:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=20
05/25/2022 10:27:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=20
05/25/2022 10:27:49 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7445718504944379 on epoch=20
05/25/2022 10:27:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7366446394388123 -> 0.7445718504944379 on epoch=20, global_step=1150
05/25/2022 10:27:52 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=20
05/25/2022 10:27:54 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=20
05/25/2022 10:27:57 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=21
05/25/2022 10:27:59 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=21
05/25/2022 10:28:02 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=21
05/25/2022 10:28:26 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5412070118093304 on epoch=21
05/25/2022 10:28:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=21
05/25/2022 10:28:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=21
05/25/2022 10:28:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=21
05/25/2022 10:28:37 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
05/25/2022 10:28:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=22
05/25/2022 10:29:04 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.7210116851322823 on epoch=22
05/25/2022 10:29:06 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=22
05/25/2022 10:29:09 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=22
05/25/2022 10:29:12 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=22
05/25/2022 10:29:14 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=23
05/25/2022 10:29:17 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=23
05/25/2022 10:29:41 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6782201128204577 on epoch=23
05/25/2022 10:29:44 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=23
05/25/2022 10:29:46 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=23
05/25/2022 10:29:49 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=23
05/25/2022 10:29:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/25/2022 10:29:54 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=24
05/25/2022 10:30:19 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7432947213577058 on epoch=24
05/25/2022 10:30:21 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=24
05/25/2022 10:30:24 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=24
05/25/2022 10:30:26 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=24
05/25/2022 10:30:29 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=24
05/25/2022 10:30:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=24
05/25/2022 10:30:56 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7134341846158305 on epoch=24
05/25/2022 10:30:58 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=25
05/25/2022 10:31:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=25
05/25/2022 10:31:03 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=25
05/25/2022 10:31:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=25
05/25/2022 10:31:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=25
05/25/2022 10:31:34 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6765929215486653 on epoch=25
05/25/2022 10:31:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=26
05/25/2022 10:31:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=26
05/25/2022 10:31:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 10:31:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/25/2022 10:31:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=26
05/25/2022 10:32:12 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8092627909896509 on epoch=26
05/25/2022 10:32:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7445718504944379 -> 0.8092627909896509 on epoch=26, global_step=1500
05/25/2022 10:32:14 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=26
05/25/2022 10:32:17 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=27
05/25/2022 10:32:19 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=27
05/25/2022 10:32:22 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=27
05/25/2022 10:32:24 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=27
05/25/2022 10:32:50 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.8065161755084752 on epoch=27
05/25/2022 10:32:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/25/2022 10:32:55 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=28
05/25/2022 10:32:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=28
05/25/2022 10:33:00 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=28
05/25/2022 10:33:03 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=28
05/25/2022 10:33:28 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7133004795983864 on epoch=28
05/25/2022 10:33:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
05/25/2022 10:33:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=28
05/25/2022 10:33:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=29
05/25/2022 10:33:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
05/25/2022 10:33:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=29
05/25/2022 10:34:06 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7597791957330748 on epoch=29
05/25/2022 10:34:08 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=29
05/25/2022 10:34:11 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=29
05/25/2022 10:34:13 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
05/25/2022 10:34:16 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/25/2022 10:34:18 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=30
05/25/2022 10:34:43 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6732688073877904 on epoch=30
05/25/2022 10:34:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=30
05/25/2022 10:34:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=30
05/25/2022 10:34:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=30
05/25/2022 10:34:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
05/25/2022 10:34:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=31
05/25/2022 10:35:20 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.680180817266253 on epoch=31
05/25/2022 10:35:23 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=31
05/25/2022 10:35:25 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=31
05/25/2022 10:35:28 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=31
05/25/2022 10:35:31 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=31
05/25/2022 10:35:33 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=32
05/25/2022 10:35:58 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6801826129629935 on epoch=32
05/25/2022 10:36:00 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/25/2022 10:36:03 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=32
05/25/2022 10:36:06 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=32
05/25/2022 10:36:08 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=32
05/25/2022 10:36:11 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=33
05/25/2022 10:36:36 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.9121960683979666 on epoch=33
05/25/2022 10:36:36 - INFO - __main__ - Saving model with best Classification-F1: 0.8092627909896509 -> 0.9121960683979666 on epoch=33, global_step=1850
05/25/2022 10:36:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=33
05/25/2022 10:36:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=33
05/25/2022 10:36:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=33
05/25/2022 10:36:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=33
05/25/2022 10:36:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=33
05/25/2022 10:37:13 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7593332935749134 on epoch=33
05/25/2022 10:37:16 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=34
05/25/2022 10:37:19 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=34
05/25/2022 10:37:21 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/25/2022 10:37:24 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=34
05/25/2022 10:37:26 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=34
05/25/2022 10:37:51 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.805592544749648 on epoch=34
05/25/2022 10:37:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=34
05/25/2022 10:37:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=35
05/25/2022 10:37:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=35
05/25/2022 10:38:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=35
05/25/2022 10:38:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=35
05/25/2022 10:38:29 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.9855228905106646 on epoch=35
05/25/2022 10:38:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9121960683979666 -> 0.9855228905106646 on epoch=35, global_step=2000
05/25/2022 10:38:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=35
05/25/2022 10:38:35 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=36
05/25/2022 10:38:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
05/25/2022 10:38:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=36
05/25/2022 10:38:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=36
05/25/2022 10:39:07 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9193101609513586 on epoch=36
05/25/2022 10:39:10 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
05/25/2022 10:39:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=36
05/25/2022 10:39:15 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=37
05/25/2022 10:39:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=37
05/25/2022 10:39:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=37
05/25/2022 10:39:44 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8092634776984431 on epoch=37
05/25/2022 10:39:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=37
05/25/2022 10:39:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=37
05/25/2022 10:39:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=38
05/25/2022 10:39:54 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/25/2022 10:39:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
05/25/2022 10:40:22 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8068907633894261 on epoch=38
05/25/2022 10:40:24 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=38
05/25/2022 10:40:27 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=38
05/25/2022 10:40:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=38
05/25/2022 10:40:32 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=39
05/25/2022 10:40:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=39
05/25/2022 10:40:58 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.6796466286402876 on epoch=39
05/25/2022 10:41:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=39
05/25/2022 10:41:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=39
05/25/2022 10:41:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=39
05/25/2022 10:41:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=39
05/25/2022 10:41:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
05/25/2022 10:41:36 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8059362216741114 on epoch=40
05/25/2022 10:41:39 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=40
05/25/2022 10:41:41 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/25/2022 10:41:44 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
05/25/2022 10:41:46 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=40
05/25/2022 10:41:49 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=41
05/25/2022 10:42:14 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8060592927506983 on epoch=41
05/25/2022 10:42:17 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
05/25/2022 10:42:19 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=41
05/25/2022 10:42:22 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/25/2022 10:42:24 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/25/2022 10:42:27 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/25/2022 10:42:52 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.685912763433161 on epoch=41
05/25/2022 10:42:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
05/25/2022 10:42:57 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=42
05/25/2022 10:42:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=42
05/25/2022 10:43:02 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=42
05/25/2022 10:43:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=42
05/25/2022 10:43:29 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8078920857881188 on epoch=42
05/25/2022 10:43:32 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=43
05/25/2022 10:43:35 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=43
05/25/2022 10:43:37 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=43
05/25/2022 10:43:40 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=43
05/25/2022 10:43:42 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/25/2022 10:44:07 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7611526929740942 on epoch=43
05/25/2022 10:44:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/25/2022 10:44:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=44
05/25/2022 10:44:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=44
05/25/2022 10:44:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=44
05/25/2022 10:44:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=44
05/25/2022 10:44:45 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7620125627443651 on epoch=44
05/25/2022 10:44:48 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/25/2022 10:44:51 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=44
05/25/2022 10:44:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=45
05/25/2022 10:44:56 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=45
05/25/2022 10:44:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=45
05/25/2022 10:45:23 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6806586462748337 on epoch=45
05/25/2022 10:45:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=45
05/25/2022 10:45:28 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=45
05/25/2022 10:45:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/25/2022 10:45:33 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=46
05/25/2022 10:45:36 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/25/2022 10:46:01 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7178415709625954 on epoch=46
05/25/2022 10:46:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=46
05/25/2022 10:46:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=46
05/25/2022 10:46:08 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/25/2022 10:46:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=47
05/25/2022 10:46:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=47
05/25/2022 10:46:39 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6814037387375603 on epoch=47
05/25/2022 10:46:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=47
05/25/2022 10:46:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=47
05/25/2022 10:46:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/25/2022 10:46:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 10:46:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=48
05/25/2022 10:47:16 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6771405296224318 on epoch=48
05/25/2022 10:47:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/25/2022 10:47:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=48
05/25/2022 10:47:24 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/25/2022 10:47:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=48
05/25/2022 10:47:29 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=49
05/25/2022 10:47:54 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7137164397774977 on epoch=49
05/25/2022 10:47:57 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/25/2022 10:47:59 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=49
05/25/2022 10:48:02 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
05/25/2022 10:48:05 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=49
05/25/2022 10:48:07 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=49
05/25/2022 10:48:32 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7196200482582878 on epoch=49
05/25/2022 10:48:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=50
05/25/2022 10:48:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/25/2022 10:48:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/25/2022 10:48:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/25/2022 10:48:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/25/2022 10:49:09 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.6809043820016226 on epoch=50
05/25/2022 10:49:12 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=51
05/25/2022 10:49:14 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=51
05/25/2022 10:49:17 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=51
05/25/2022 10:49:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=51
05/25/2022 10:49:22 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=51
05/25/2022 10:49:46 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7190342456929093 on epoch=51
05/25/2022 10:49:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=51
05/25/2022 10:49:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 10:49:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=52
05/25/2022 10:49:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=52
05/25/2022 10:49:59 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/25/2022 10:50:24 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.72099367790671 on epoch=52
05/25/2022 10:50:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=52
05/25/2022 10:50:29 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=53
05/25/2022 10:50:32 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=53
05/25/2022 10:50:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/25/2022 10:50:37 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=53
05/25/2022 10:50:38 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:50:38 - INFO - __main__ - Printing 3 examples
05/25/2022 10:50:38 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 10:50:38 - INFO - __main__ - ['Film']
05/25/2022 10:50:38 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 10:50:38 - INFO - __main__ - ['Film']
05/25/2022 10:50:38 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 10:50:38 - INFO - __main__ - ['Film']
05/25/2022 10:50:38 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:50:39 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:50:40 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 10:50:40 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:50:40 - INFO - __main__ - Printing 3 examples
05/25/2022 10:50:40 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 10:50:40 - INFO - __main__ - ['Film']
05/25/2022 10:50:40 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 10:50:40 - INFO - __main__ - ['Film']
05/25/2022 10:50:40 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 10:50:40 - INFO - __main__ - ['Film']
05/25/2022 10:50:40 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:50:40 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:50:41 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 10:50:56 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:50:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 10:50:57 - INFO - __main__ - Starting training!
05/25/2022 10:51:01 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7244460703783955 on epoch=53
05/25/2022 10:51:01 - INFO - __main__ - save last model!
05/25/2022 10:51:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 10:51:01 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 10:51:01 - INFO - __main__ - Printing 3 examples
05/25/2022 10:51:01 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 10:51:01 - INFO - __main__ - ['Animal']
05/25/2022 10:51:01 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 10:51:01 - INFO - __main__ - ['Animal']
05/25/2022 10:51:01 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 10:51:01 - INFO - __main__ - ['Village']
05/25/2022 10:51:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:51:03 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:51:07 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 10:53:13 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.5_8_predictions.txt
05/25/2022 10:53:13 - INFO - __main__ - Classification-F1 on test data: 0.5075
05/25/2022 10:53:13 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.5, bsz=8, dev_performance=0.9855228905106646, test_performance=0.5074725933475347
05/25/2022 10:53:13 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.4, bsz=8 ...
05/25/2022 10:53:14 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:53:14 - INFO - __main__ - Printing 3 examples
05/25/2022 10:53:14 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 10:53:14 - INFO - __main__ - ['Film']
05/25/2022 10:53:14 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 10:53:14 - INFO - __main__ - ['Film']
05/25/2022 10:53:14 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 10:53:14 - INFO - __main__ - ['Film']
05/25/2022 10:53:14 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:53:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:53:15 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 10:53:15 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 10:53:15 - INFO - __main__ - Printing 3 examples
05/25/2022 10:53:15 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 10:53:15 - INFO - __main__ - ['Film']
05/25/2022 10:53:15 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 10:53:15 - INFO - __main__ - ['Film']
05/25/2022 10:53:15 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 10:53:15 - INFO - __main__ - ['Film']
05/25/2022 10:53:15 - INFO - __main__ - Tokenizing Input ...
05/25/2022 10:53:16 - INFO - __main__ - Tokenizing Output ...
05/25/2022 10:53:17 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 10:53:32 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 10:53:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 10:53:33 - INFO - __main__ - Starting training!
05/25/2022 10:53:36 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
05/25/2022 10:53:39 - INFO - __main__ - Step 20 Global step 20 Train loss 5.32 on epoch=0
05/25/2022 10:53:41 - INFO - __main__ - Step 30 Global step 30 Train loss 4.50 on epoch=0
05/25/2022 10:53:44 - INFO - __main__ - Step 40 Global step 40 Train loss 3.62 on epoch=0
05/25/2022 10:53:46 - INFO - __main__ - Step 50 Global step 50 Train loss 3.46 on epoch=0
05/25/2022 10:54:13 - INFO - __main__ - Global step 50 Train loss 4.77 Classification-F1 0.01496457042237061 on epoch=0
05/25/2022 10:54:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01496457042237061 on epoch=0, global_step=50
05/25/2022 10:54:15 - INFO - __main__ - Step 60 Global step 60 Train loss 2.54 on epoch=1
05/25/2022 10:54:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.45 on epoch=1
05/25/2022 10:54:21 - INFO - __main__ - Step 80 Global step 80 Train loss 2.53 on epoch=1
05/25/2022 10:54:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.43 on epoch=1
05/25/2022 10:54:26 - INFO - __main__ - Step 100 Global step 100 Train loss 2.00 on epoch=1
05/25/2022 10:54:48 - INFO - __main__ - Global step 100 Train loss 2.39 Classification-F1 0.04562620148309019 on epoch=1
05/25/2022 10:54:49 - INFO - __main__ - Saving model with best Classification-F1: 0.01496457042237061 -> 0.04562620148309019 on epoch=1, global_step=100
05/25/2022 10:54:51 - INFO - __main__ - Step 110 Global step 110 Train loss 1.92 on epoch=1
05/25/2022 10:54:54 - INFO - __main__ - Step 120 Global step 120 Train loss 1.74 on epoch=2
05/25/2022 10:54:56 - INFO - __main__ - Step 130 Global step 130 Train loss 1.82 on epoch=2
05/25/2022 10:54:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.56 on epoch=2
05/25/2022 10:55:01 - INFO - __main__ - Step 150 Global step 150 Train loss 1.53 on epoch=2
05/25/2022 10:55:23 - INFO - __main__ - Global step 150 Train loss 1.71 Classification-F1 0.1046658959544116 on epoch=2
05/25/2022 10:55:23 - INFO - __main__ - Saving model with best Classification-F1: 0.04562620148309019 -> 0.1046658959544116 on epoch=2, global_step=150
05/25/2022 10:55:26 - INFO - __main__ - Step 160 Global step 160 Train loss 1.35 on epoch=2
05/25/2022 10:55:28 - INFO - __main__ - Step 170 Global step 170 Train loss 1.19 on epoch=3
05/25/2022 10:55:31 - INFO - __main__ - Step 180 Global step 180 Train loss 1.19 on epoch=3
05/25/2022 10:55:33 - INFO - __main__ - Step 190 Global step 190 Train loss 1.18 on epoch=3
05/25/2022 10:55:36 - INFO - __main__ - Step 200 Global step 200 Train loss 1.13 on epoch=3
05/25/2022 10:55:58 - INFO - __main__ - Global step 200 Train loss 1.21 Classification-F1 0.15662148142840882 on epoch=3
05/25/2022 10:55:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1046658959544116 -> 0.15662148142840882 on epoch=3, global_step=200
05/25/2022 10:56:01 - INFO - __main__ - Step 210 Global step 210 Train loss 0.85 on epoch=3
05/25/2022 10:56:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.81 on epoch=3
05/25/2022 10:56:06 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=4
05/25/2022 10:56:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.75 on epoch=4
05/25/2022 10:56:11 - INFO - __main__ - Step 250 Global step 250 Train loss 0.71 on epoch=4
05/25/2022 10:56:36 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.2343550403265051 on epoch=4
05/25/2022 10:56:36 - INFO - __main__ - Saving model with best Classification-F1: 0.15662148142840882 -> 0.2343550403265051 on epoch=4, global_step=250
05/25/2022 10:56:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=4
05/25/2022 10:56:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.54 on epoch=4
05/25/2022 10:56:44 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=4
05/25/2022 10:56:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=5
05/25/2022 10:56:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=5
05/25/2022 10:57:15 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.27301179422701793 on epoch=5
05/25/2022 10:57:15 - INFO - __main__ - Saving model with best Classification-F1: 0.2343550403265051 -> 0.27301179422701793 on epoch=5, global_step=300
05/25/2022 10:57:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.49 on epoch=5
05/25/2022 10:57:20 - INFO - __main__ - Step 320 Global step 320 Train loss 0.59 on epoch=5
05/25/2022 10:57:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=5
05/25/2022 10:57:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=6
05/25/2022 10:57:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=6
05/25/2022 10:57:53 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.3787877946163955 on epoch=6
05/25/2022 10:57:53 - INFO - __main__ - Saving model with best Classification-F1: 0.27301179422701793 -> 0.3787877946163955 on epoch=6, global_step=350
05/25/2022 10:57:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=6
05/25/2022 10:57:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=6
05/25/2022 10:58:01 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=6
05/25/2022 10:58:04 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=6
05/25/2022 10:58:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=7
05/25/2022 10:58:32 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.42338941188401674 on epoch=7
05/25/2022 10:58:32 - INFO - __main__ - Saving model with best Classification-F1: 0.3787877946163955 -> 0.42338941188401674 on epoch=7, global_step=400
05/25/2022 10:58:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=7
05/25/2022 10:58:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=7
05/25/2022 10:58:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=7
05/25/2022 10:58:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=7
05/25/2022 10:58:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=8
05/25/2022 10:59:11 - INFO - __main__ - Global step 450 Train loss 0.31 Classification-F1 0.4092044703891894 on epoch=8
05/25/2022 10:59:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=8
05/25/2022 10:59:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.30 on epoch=8
05/25/2022 10:59:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=8
05/25/2022 10:59:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=8
05/25/2022 10:59:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.17 on epoch=8
05/25/2022 10:59:49 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.37648147597816867 on epoch=8
05/25/2022 10:59:51 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=9
05/25/2022 10:59:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.27 on epoch=9
05/25/2022 10:59:56 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=9
05/25/2022 10:59:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=9
05/25/2022 11:00:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=9
05/25/2022 11:00:26 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.4545799660022792 on epoch=9
05/25/2022 11:00:26 - INFO - __main__ - Saving model with best Classification-F1: 0.42338941188401674 -> 0.4545799660022792 on epoch=9, global_step=550
05/25/2022 11:00:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=9
05/25/2022 11:00:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.25 on epoch=10
05/25/2022 11:00:34 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=10
05/25/2022 11:00:36 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=10
05/25/2022 11:00:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=10
05/25/2022 11:01:03 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.4572126343561137 on epoch=10
05/25/2022 11:01:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4545799660022792 -> 0.4572126343561137 on epoch=10, global_step=600
05/25/2022 11:01:06 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=10
05/25/2022 11:01:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=11
05/25/2022 11:01:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=11
05/25/2022 11:01:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=11
05/25/2022 11:01:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=11
05/25/2022 11:01:41 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.4385026177805985 on epoch=11
05/25/2022 11:01:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=11
05/25/2022 11:01:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=11
05/25/2022 11:01:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=12
05/25/2022 11:01:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=12
05/25/2022 11:01:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=12
05/25/2022 11:02:20 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.5002353778426093 on epoch=12
05/25/2022 11:02:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4572126343561137 -> 0.5002353778426093 on epoch=12, global_step=700
05/25/2022 11:02:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=12
05/25/2022 11:02:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.25 on epoch=12
05/25/2022 11:02:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=13
05/25/2022 11:02:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=13
05/25/2022 11:02:32 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=13
05/25/2022 11:02:58 - INFO - __main__ - Global step 750 Train loss 0.18 Classification-F1 0.5435386661290181 on epoch=13
05/25/2022 11:02:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5002353778426093 -> 0.5435386661290181 on epoch=13, global_step=750
05/25/2022 11:03:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=13
05/25/2022 11:03:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=13
05/25/2022 11:03:06 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=13
05/25/2022 11:03:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=14
05/25/2022 11:03:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=14
05/25/2022 11:03:36 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.4971890227897599 on epoch=14
05/25/2022 11:03:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=14
05/25/2022 11:03:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=14
05/25/2022 11:03:43 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=14
05/25/2022 11:03:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=14
05/25/2022 11:03:49 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=15
05/25/2022 11:04:14 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6037935718753114 on epoch=15
05/25/2022 11:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5435386661290181 -> 0.6037935718753114 on epoch=15, global_step=850
05/25/2022 11:04:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=15
05/25/2022 11:04:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=15
05/25/2022 11:04:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=15
05/25/2022 11:04:24 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=15
05/25/2022 11:04:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=16
05/25/2022 11:04:52 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.5664742928469585 on epoch=16
05/25/2022 11:04:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=16
05/25/2022 11:04:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=16
05/25/2022 11:05:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=16
05/25/2022 11:05:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=16
05/25/2022 11:05:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=16
05/25/2022 11:05:31 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.6086166995675223 on epoch=16
05/25/2022 11:05:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6037935718753114 -> 0.6086166995675223 on epoch=16, global_step=950
05/25/2022 11:05:34 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=17
05/25/2022 11:05:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=17
05/25/2022 11:05:39 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=17
05/25/2022 11:05:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=17
05/25/2022 11:05:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=17
05/25/2022 11:06:09 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.580168405247676 on epoch=17
05/25/2022 11:06:12 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=18
05/25/2022 11:06:15 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=18
05/25/2022 11:06:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=18
05/25/2022 11:06:20 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=18
05/25/2022 11:06:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=18
05/25/2022 11:06:48 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.5436495591966493 on epoch=18
05/25/2022 11:06:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=18
05/25/2022 11:06:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=19
05/25/2022 11:06:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=19
05/25/2022 11:06:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=19
05/25/2022 11:07:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=19
05/25/2022 11:07:26 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.5727909605015971 on epoch=19
05/25/2022 11:07:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=19
05/25/2022 11:07:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=19
05/25/2022 11:07:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=20
05/25/2022 11:07:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=20
05/25/2022 11:07:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=20
05/25/2022 11:08:05 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.575119832472264 on epoch=20
05/25/2022 11:08:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=20
05/25/2022 11:08:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=20
05/25/2022 11:08:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=21
05/25/2022 11:08:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.17 on epoch=21
05/25/2022 11:08:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=21
05/25/2022 11:08:43 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.5758237763296884 on epoch=21
05/25/2022 11:08:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=21
05/25/2022 11:08:48 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=21
05/25/2022 11:08:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=21
05/25/2022 11:08:53 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=22
05/25/2022 11:08:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.15 on epoch=22
05/25/2022 11:09:21 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5605027170047686 on epoch=22
05/25/2022 11:09:24 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=22
05/25/2022 11:09:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=22
05/25/2022 11:09:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=22
05/25/2022 11:09:32 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=23
05/25/2022 11:09:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=23
05/25/2022 11:09:59 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5559389075142679 on epoch=23
05/25/2022 11:10:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=23
05/25/2022 11:10:04 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=23
05/25/2022 11:10:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/25/2022 11:10:09 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=23
05/25/2022 11:10:12 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=24
05/25/2022 11:10:37 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7449917007680846 on epoch=24
05/25/2022 11:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6086166995675223 -> 0.7449917007680846 on epoch=24, global_step=1350
05/25/2022 11:10:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=24
05/25/2022 11:10:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=24
05/25/2022 11:10:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=24
05/25/2022 11:10:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=24
05/25/2022 11:10:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=24
05/25/2022 11:11:14 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7580148624224766 on epoch=24
05/25/2022 11:11:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7449917007680846 -> 0.7580148624224766 on epoch=24, global_step=1400
05/25/2022 11:11:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=25
05/25/2022 11:11:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=25
05/25/2022 11:11:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=25
05/25/2022 11:11:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=25
05/25/2022 11:11:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=25
05/25/2022 11:11:52 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.7521202554353063 on epoch=25
05/25/2022 11:11:54 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=26
05/25/2022 11:11:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=26
05/25/2022 11:12:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=26
05/25/2022 11:12:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=26
05/25/2022 11:12:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 11:12:30 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.8040298584067607 on epoch=26
05/25/2022 11:12:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7580148624224766 -> 0.8040298584067607 on epoch=26, global_step=1500
05/25/2022 11:12:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=26
05/25/2022 11:12:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=27
05/25/2022 11:12:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=27
05/25/2022 11:12:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=27
05/25/2022 11:12:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=27
05/25/2022 11:13:09 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.8058844605171541 on epoch=27
05/25/2022 11:13:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8040298584067607 -> 0.8058844605171541 on epoch=27, global_step=1550
05/25/2022 11:13:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=27
05/25/2022 11:13:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/25/2022 11:13:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=28
05/25/2022 11:13:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=28
05/25/2022 11:13:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=28
05/25/2022 11:13:47 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.754996340182077 on epoch=28
05/25/2022 11:13:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=28
05/25/2022 11:13:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=28
05/25/2022 11:13:55 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=29
05/25/2022 11:13:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=29
05/25/2022 11:14:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=29
05/25/2022 11:14:24 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6425335442762857 on epoch=29
05/25/2022 11:14:27 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=29
05/25/2022 11:14:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=29
05/25/2022 11:14:32 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=29
05/25/2022 11:14:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=30
05/25/2022 11:14:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=30
05/25/2022 11:15:02 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6691127919930737 on epoch=30
05/25/2022 11:15:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=30
05/25/2022 11:15:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=30
05/25/2022 11:15:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=30
05/25/2022 11:15:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=31
05/25/2022 11:15:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=31
05/25/2022 11:15:40 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.6082529123729977 on epoch=31
05/25/2022 11:15:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=31
05/25/2022 11:15:45 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=31
05/25/2022 11:15:48 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/25/2022 11:15:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=31
05/25/2022 11:15:53 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=32
05/25/2022 11:16:18 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8045726605546504 on epoch=32
05/25/2022 11:16:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=32
05/25/2022 11:16:23 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=32
05/25/2022 11:16:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=32
05/25/2022 11:16:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=32
05/25/2022 11:16:31 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=33
05/25/2022 11:16:56 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7600840101396583 on epoch=33
05/25/2022 11:16:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=33
05/25/2022 11:17:02 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=33
05/25/2022 11:17:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=33
05/25/2022 11:17:07 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=33
05/25/2022 11:17:10 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/25/2022 11:17:34 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7522117792318076 on epoch=33
05/25/2022 11:17:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=34
05/25/2022 11:17:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=34
05/25/2022 11:17:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=34
05/25/2022 11:17:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=34
05/25/2022 11:17:48 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=34
05/25/2022 11:18:12 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7496216839604174 on epoch=34
05/25/2022 11:18:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=34
05/25/2022 11:18:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=35
05/25/2022 11:18:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=35
05/25/2022 11:18:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
05/25/2022 11:18:25 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=35
05/25/2022 11:18:50 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7592288462641221 on epoch=35
05/25/2022 11:18:52 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=35
05/25/2022 11:18:55 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=36
05/25/2022 11:18:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=36
05/25/2022 11:19:00 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=36
05/25/2022 11:19:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=36
05/25/2022 11:19:27 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.7620448584780061 on epoch=36
05/25/2022 11:19:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=36
05/25/2022 11:19:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/25/2022 11:19:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=37
05/25/2022 11:19:38 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=37
05/25/2022 11:19:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=37
05/25/2022 11:20:04 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7550165022386328 on epoch=37
05/25/2022 11:20:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/25/2022 11:20:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=37
05/25/2022 11:20:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=38
05/25/2022 11:20:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=38
05/25/2022 11:20:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=38
05/25/2022 11:20:42 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7176951493173243 on epoch=38
05/25/2022 11:20:44 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 11:20:47 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=38
05/25/2022 11:20:50 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=38
05/25/2022 11:20:52 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/25/2022 11:20:55 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=39
05/25/2022 11:21:19 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7103062651161812 on epoch=39
05/25/2022 11:21:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=39
05/25/2022 11:21:24 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=39
05/25/2022 11:21:27 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=39
05/25/2022 11:21:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=39
05/25/2022 11:21:32 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=40
05/25/2022 11:21:56 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8044291369729814 on epoch=40
05/25/2022 11:21:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=40
05/25/2022 11:22:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=40
05/25/2022 11:22:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=40
05/25/2022 11:22:07 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 11:22:10 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=41
05/25/2022 11:22:34 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7514867799684546 on epoch=41
05/25/2022 11:22:37 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=41
05/25/2022 11:22:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=41
05/25/2022 11:22:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=41
05/25/2022 11:22:44 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=41
05/25/2022 11:22:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=41
05/25/2022 11:23:12 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8058076963149314 on epoch=41
05/25/2022 11:23:14 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=42
05/25/2022 11:23:17 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=42
05/25/2022 11:23:19 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=42
05/25/2022 11:23:22 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/25/2022 11:23:25 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=42
05/25/2022 11:23:50 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.7634079145400255 on epoch=42
05/25/2022 11:23:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=43
05/25/2022 11:23:55 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=43
05/25/2022 11:23:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=43
05/25/2022 11:24:00 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=43
05/25/2022 11:24:03 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=43
05/25/2022 11:24:27 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.808784503431336 on epoch=43
05/25/2022 11:24:28 - INFO - __main__ - Saving model with best Classification-F1: 0.8058844605171541 -> 0.808784503431336 on epoch=43, global_step=2450
05/25/2022 11:24:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=43
05/25/2022 11:24:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=44
05/25/2022 11:24:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=44
05/25/2022 11:24:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 11:24:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
05/25/2022 11:25:05 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7174745275749806 on epoch=44
05/25/2022 11:25:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=44
05/25/2022 11:25:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=44
05/25/2022 11:25:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=45
05/25/2022 11:25:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=45
05/25/2022 11:25:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=45
05/25/2022 11:25:43 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8582813298225516 on epoch=45
05/25/2022 11:25:43 - INFO - __main__ - Saving model with best Classification-F1: 0.808784503431336 -> 0.8582813298225516 on epoch=45, global_step=2550
05/25/2022 11:25:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=45
05/25/2022 11:25:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/25/2022 11:25:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=46
05/25/2022 11:25:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=46
05/25/2022 11:25:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/25/2022 11:26:21 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8603559407728038 on epoch=46
05/25/2022 11:26:21 - INFO - __main__ - Saving model with best Classification-F1: 0.8582813298225516 -> 0.8603559407728038 on epoch=46, global_step=2600
05/25/2022 11:26:24 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/25/2022 11:26:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
05/25/2022 11:26:29 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=46
05/25/2022 11:26:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/25/2022 11:26:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=47
05/25/2022 11:26:59 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8598576282615835 on epoch=47
05/25/2022 11:27:02 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=47
05/25/2022 11:27:05 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=47
05/25/2022 11:27:07 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=47
05/25/2022 11:27:10 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/25/2022 11:27:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=48
05/25/2022 11:27:37 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8587824947252962 on epoch=48
05/25/2022 11:27:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=48
05/25/2022 11:27:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=48
05/25/2022 11:27:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=48
05/25/2022 11:27:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=48
05/25/2022 11:27:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/25/2022 11:28:15 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8608391928940622 on epoch=49
05/25/2022 11:28:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8603559407728038 -> 0.8608391928940622 on epoch=49, global_step=2750
05/25/2022 11:28:17 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=49
05/25/2022 11:28:20 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=49
05/25/2022 11:28:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=49
05/25/2022 11:28:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=49
05/25/2022 11:28:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/25/2022 11:28:52 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7629051124369642 on epoch=49
05/25/2022 11:28:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=50
05/25/2022 11:28:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=50
05/25/2022 11:29:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=50
05/25/2022 11:29:03 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=50
05/25/2022 11:29:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/25/2022 11:29:30 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7218318781614496 on epoch=50
05/25/2022 11:29:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=51
05/25/2022 11:29:35 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=51
05/25/2022 11:29:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=51
05/25/2022 11:29:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=51
05/25/2022 11:29:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/25/2022 11:30:08 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7633697895953749 on epoch=51
05/25/2022 11:30:10 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/25/2022 11:30:13 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 11:30:16 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.11 on epoch=52
05/25/2022 11:30:18 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/25/2022 11:30:21 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/25/2022 11:30:46 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8092781043870884 on epoch=52
05/25/2022 11:30:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=52
05/25/2022 11:30:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=53
05/25/2022 11:30:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=53
05/25/2022 11:30:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=53
05/25/2022 11:30:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/25/2022 11:31:00 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 11:31:00 - INFO - __main__ - Printing 3 examples
05/25/2022 11:31:00 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 11:31:00 - INFO - __main__ - ['Film']
05/25/2022 11:31:00 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 11:31:00 - INFO - __main__ - ['Film']
05/25/2022 11:31:00 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 11:31:00 - INFO - __main__ - ['Film']
05/25/2022 11:31:00 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:31:01 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:31:01 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 11:31:01 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 11:31:01 - INFO - __main__ - Printing 3 examples
05/25/2022 11:31:01 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 11:31:01 - INFO - __main__ - ['Film']
05/25/2022 11:31:01 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 11:31:01 - INFO - __main__ - ['Film']
05/25/2022 11:31:01 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 11:31:01 - INFO - __main__ - ['Film']
05/25/2022 11:31:01 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:31:02 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:31:03 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 11:31:18 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:31:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 11:31:19 - INFO - __main__ - Starting training!
05/25/2022 11:31:24 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8082124855602191 on epoch=53
05/25/2022 11:31:24 - INFO - __main__ - save last model!
05/25/2022 11:31:24 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 11:31:24 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 11:31:24 - INFO - __main__ - Printing 3 examples
05/25/2022 11:31:24 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 11:31:24 - INFO - __main__ - ['Animal']
05/25/2022 11:31:24 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 11:31:24 - INFO - __main__ - ['Animal']
05/25/2022 11:31:24 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 11:31:24 - INFO - __main__ - ['Village']
05/25/2022 11:31:24 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:31:26 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:31:29 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 11:33:35 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.4_8_predictions.txt
05/25/2022 11:33:35 - INFO - __main__ - Classification-F1 on test data: 0.6526
05/25/2022 11:33:35 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.4, bsz=8, dev_performance=0.8608391928940622, test_performance=0.6526311481343567
05/25/2022 11:33:35 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.3, bsz=8 ...
05/25/2022 11:33:36 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 11:33:36 - INFO - __main__ - Printing 3 examples
05/25/2022 11:33:36 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 11:33:36 - INFO - __main__ - ['Film']
05/25/2022 11:33:36 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 11:33:36 - INFO - __main__ - ['Film']
05/25/2022 11:33:36 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 11:33:36 - INFO - __main__ - ['Film']
05/25/2022 11:33:36 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:33:37 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:33:38 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 11:33:38 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 11:33:38 - INFO - __main__ - Printing 3 examples
05/25/2022 11:33:38 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 11:33:38 - INFO - __main__ - ['Film']
05/25/2022 11:33:38 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 11:33:38 - INFO - __main__ - ['Film']
05/25/2022 11:33:38 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 11:33:38 - INFO - __main__ - ['Film']
05/25/2022 11:33:38 - INFO - __main__ - Tokenizing Input ...
05/25/2022 11:33:38 - INFO - __main__ - Tokenizing Output ...
05/25/2022 11:33:39 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 11:33:54 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 11:33:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 11:33:55 - INFO - __main__ - Starting training!
05/25/2022 11:33:58 - INFO - __main__ - Step 10 Global step 10 Train loss 7.23 on epoch=0
05/25/2022 11:34:01 - INFO - __main__ - Step 20 Global step 20 Train loss 5.39 on epoch=0
05/25/2022 11:34:04 - INFO - __main__ - Step 30 Global step 30 Train loss 4.80 on epoch=0
05/25/2022 11:34:06 - INFO - __main__ - Step 40 Global step 40 Train loss 3.68 on epoch=0
05/25/2022 11:34:09 - INFO - __main__ - Step 50 Global step 50 Train loss 3.95 on epoch=0
05/25/2022 11:34:35 - INFO - __main__ - Global step 50 Train loss 5.01 Classification-F1 0.016345954028479034 on epoch=0
05/25/2022 11:34:35 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016345954028479034 on epoch=0, global_step=50
05/25/2022 11:34:38 - INFO - __main__ - Step 60 Global step 60 Train loss 2.89 on epoch=1
05/25/2022 11:34:41 - INFO - __main__ - Step 70 Global step 70 Train loss 2.91 on epoch=1
05/25/2022 11:34:43 - INFO - __main__ - Step 80 Global step 80 Train loss 2.93 on epoch=1
05/25/2022 11:34:46 - INFO - __main__ - Step 90 Global step 90 Train loss 2.88 on epoch=1
05/25/2022 11:34:48 - INFO - __main__ - Step 100 Global step 100 Train loss 2.29 on epoch=1
05/25/2022 11:35:12 - INFO - __main__ - Global step 100 Train loss 2.78 Classification-F1 0.0310214568220494 on epoch=1
05/25/2022 11:35:12 - INFO - __main__ - Saving model with best Classification-F1: 0.016345954028479034 -> 0.0310214568220494 on epoch=1, global_step=100
05/25/2022 11:35:15 - INFO - __main__ - Step 110 Global step 110 Train loss 2.30 on epoch=1
05/25/2022 11:35:17 - INFO - __main__ - Step 120 Global step 120 Train loss 2.03 on epoch=2
05/25/2022 11:35:20 - INFO - __main__ - Step 130 Global step 130 Train loss 2.19 on epoch=2
05/25/2022 11:35:23 - INFO - __main__ - Step 140 Global step 140 Train loss 2.04 on epoch=2
05/25/2022 11:35:25 - INFO - __main__ - Step 150 Global step 150 Train loss 1.96 on epoch=2
05/25/2022 11:35:48 - INFO - __main__ - Global step 150 Train loss 2.11 Classification-F1 0.061834619241864744 on epoch=2
05/25/2022 11:35:48 - INFO - __main__ - Saving model with best Classification-F1: 0.0310214568220494 -> 0.061834619241864744 on epoch=2, global_step=150
05/25/2022 11:35:51 - INFO - __main__ - Step 160 Global step 160 Train loss 1.67 on epoch=2
05/25/2022 11:35:53 - INFO - __main__ - Step 170 Global step 170 Train loss 1.52 on epoch=3
05/25/2022 11:35:56 - INFO - __main__ - Step 180 Global step 180 Train loss 1.49 on epoch=3
05/25/2022 11:35:59 - INFO - __main__ - Step 190 Global step 190 Train loss 1.47 on epoch=3
05/25/2022 11:36:01 - INFO - __main__ - Step 200 Global step 200 Train loss 1.61 on epoch=3
05/25/2022 11:36:23 - INFO - __main__ - Global step 200 Train loss 1.55 Classification-F1 0.11065589112526499 on epoch=3
05/25/2022 11:36:23 - INFO - __main__ - Saving model with best Classification-F1: 0.061834619241864744 -> 0.11065589112526499 on epoch=3, global_step=200
05/25/2022 11:36:26 - INFO - __main__ - Step 210 Global step 210 Train loss 1.17 on epoch=3
05/25/2022 11:36:29 - INFO - __main__ - Step 220 Global step 220 Train loss 1.22 on epoch=3
05/25/2022 11:36:31 - INFO - __main__ - Step 230 Global step 230 Train loss 1.10 on epoch=4
05/25/2022 11:36:34 - INFO - __main__ - Step 240 Global step 240 Train loss 1.13 on epoch=4
05/25/2022 11:36:36 - INFO - __main__ - Step 250 Global step 250 Train loss 1.07 on epoch=4
05/25/2022 11:36:58 - INFO - __main__ - Global step 250 Train loss 1.14 Classification-F1 0.15012796951236484 on epoch=4
05/25/2022 11:36:58 - INFO - __main__ - Saving model with best Classification-F1: 0.11065589112526499 -> 0.15012796951236484 on epoch=4, global_step=250
05/25/2022 11:37:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.97 on epoch=4
05/25/2022 11:37:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.84 on epoch=4
05/25/2022 11:37:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.85 on epoch=4
05/25/2022 11:37:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=5
05/25/2022 11:37:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.86 on epoch=5
05/25/2022 11:37:34 - INFO - __main__ - Global step 300 Train loss 0.87 Classification-F1 0.19429194700983532 on epoch=5
05/25/2022 11:37:34 - INFO - __main__ - Saving model with best Classification-F1: 0.15012796951236484 -> 0.19429194700983532 on epoch=5, global_step=300
05/25/2022 11:37:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.79 on epoch=5
05/25/2022 11:37:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.68 on epoch=5
05/25/2022 11:37:41 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=5
05/25/2022 11:37:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=6
05/25/2022 11:37:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=6
05/25/2022 11:38:11 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.28778083305706703 on epoch=6
05/25/2022 11:38:11 - INFO - __main__ - Saving model with best Classification-F1: 0.19429194700983532 -> 0.28778083305706703 on epoch=6, global_step=350
05/25/2022 11:38:13 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=6
05/25/2022 11:38:16 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=6
05/25/2022 11:38:18 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=6
05/25/2022 11:38:21 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=6
05/25/2022 11:38:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=7
05/25/2022 11:38:48 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.31979709556446706 on epoch=7
05/25/2022 11:38:48 - INFO - __main__ - Saving model with best Classification-F1: 0.28778083305706703 -> 0.31979709556446706 on epoch=7, global_step=400
05/25/2022 11:38:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.47 on epoch=7
05/25/2022 11:38:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.42 on epoch=7
05/25/2022 11:38:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=7
05/25/2022 11:38:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=7
05/25/2022 11:39:01 - INFO - __main__ - Step 450 Global step 450 Train loss 0.43 on epoch=8
05/25/2022 11:39:25 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.34435641924315663 on epoch=8
05/25/2022 11:39:25 - INFO - __main__ - Saving model with best Classification-F1: 0.31979709556446706 -> 0.34435641924315663 on epoch=8, global_step=450
05/25/2022 11:39:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=8
05/25/2022 11:39:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=8
05/25/2022 11:39:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=8
05/25/2022 11:39:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=8
05/25/2022 11:39:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=8
05/25/2022 11:40:03 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.39399175825559746 on epoch=8
05/25/2022 11:40:03 - INFO - __main__ - Saving model with best Classification-F1: 0.34435641924315663 -> 0.39399175825559746 on epoch=8, global_step=500
05/25/2022 11:40:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=9
05/25/2022 11:40:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=9
05/25/2022 11:40:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=9
05/25/2022 11:40:13 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=9
05/25/2022 11:40:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.36 on epoch=9
05/25/2022 11:40:41 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.3593188166509408 on epoch=9
05/25/2022 11:40:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=9
05/25/2022 11:40:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=10
05/25/2022 11:40:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.36 on epoch=10
05/25/2022 11:40:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=10
05/25/2022 11:40:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=10
05/25/2022 11:41:18 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.399705192062966 on epoch=10
05/25/2022 11:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.39399175825559746 -> 0.399705192062966 on epoch=10, global_step=600
05/25/2022 11:41:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=10
05/25/2022 11:41:23 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=11
05/25/2022 11:41:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.36 on epoch=11
05/25/2022 11:41:28 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=11
05/25/2022 11:41:31 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=11
05/25/2022 11:41:56 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.49626543491275504 on epoch=11
05/25/2022 11:41:56 - INFO - __main__ - Saving model with best Classification-F1: 0.399705192062966 -> 0.49626543491275504 on epoch=11, global_step=650
05/25/2022 11:41:59 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=11
05/25/2022 11:42:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=11
05/25/2022 11:42:04 - INFO - __main__ - Step 680 Global step 680 Train loss 0.25 on epoch=12
05/25/2022 11:42:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.36 on epoch=12
05/25/2022 11:42:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=12
05/25/2022 11:42:34 - INFO - __main__ - Global step 700 Train loss 0.28 Classification-F1 0.5252316204802514 on epoch=12
05/25/2022 11:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.49626543491275504 -> 0.5252316204802514 on epoch=12, global_step=700
05/25/2022 11:42:36 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=12
05/25/2022 11:42:39 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=12
05/25/2022 11:42:41 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=13
05/25/2022 11:42:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.20 on epoch=13
05/25/2022 11:42:47 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=13
05/25/2022 11:43:12 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.4942519408914924 on epoch=13
05/25/2022 11:43:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=13
05/25/2022 11:43:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=13
05/25/2022 11:43:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=13
05/25/2022 11:43:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.27 on epoch=14
05/25/2022 11:43:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=14
05/25/2022 11:43:49 - INFO - __main__ - Global step 800 Train loss 0.22 Classification-F1 0.5851919175434459 on epoch=14
05/25/2022 11:43:49 - INFO - __main__ - Saving model with best Classification-F1: 0.5252316204802514 -> 0.5851919175434459 on epoch=14, global_step=800
05/25/2022 11:43:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.17 on epoch=14
05/25/2022 11:43:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=14
05/25/2022 11:43:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.23 on epoch=14
05/25/2022 11:44:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=14
05/25/2022 11:44:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.19 on epoch=15
05/25/2022 11:44:26 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.5906885641116283 on epoch=15
05/25/2022 11:44:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5851919175434459 -> 0.5906885641116283 on epoch=15, global_step=850
05/25/2022 11:44:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.25 on epoch=15
05/25/2022 11:44:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=15
05/25/2022 11:44:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=15
05/25/2022 11:44:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=15
05/25/2022 11:44:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=16
05/25/2022 11:45:03 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.6137024231309731 on epoch=16
05/25/2022 11:45:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5906885641116283 -> 0.6137024231309731 on epoch=16, global_step=900
05/25/2022 11:45:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=16
05/25/2022 11:45:08 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=16
05/25/2022 11:45:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=16
05/25/2022 11:45:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.20 on epoch=16
05/25/2022 11:45:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.24 on epoch=16
05/25/2022 11:45:41 - INFO - __main__ - Global step 950 Train loss 0.21 Classification-F1 0.6458553493505292 on epoch=16
05/25/2022 11:45:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6137024231309731 -> 0.6458553493505292 on epoch=16, global_step=950
05/25/2022 11:45:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=17
05/25/2022 11:45:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.20 on epoch=17
05/25/2022 11:45:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=17
05/25/2022 11:45:51 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=17
05/25/2022 11:45:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=17
05/25/2022 11:46:19 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5911002966552441 on epoch=17
05/25/2022 11:46:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.22 on epoch=18
05/25/2022 11:46:24 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=18
05/25/2022 11:46:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=18
05/25/2022 11:46:29 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=18
05/25/2022 11:46:32 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=18
05/25/2022 11:46:58 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.6294974315005184 on epoch=18
05/25/2022 11:47:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=18
05/25/2022 11:47:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=19
05/25/2022 11:47:05 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=19
05/25/2022 11:47:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=19
05/25/2022 11:47:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=19
05/25/2022 11:47:36 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.7118041736566629 on epoch=19
05/25/2022 11:47:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6458553493505292 -> 0.7118041736566629 on epoch=19, global_step=1100
05/25/2022 11:47:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=19
05/25/2022 11:47:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=19
05/25/2022 11:47:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=20
05/25/2022 11:47:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=20
05/25/2022 11:47:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=20
05/25/2022 11:48:15 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.7512442581442482 on epoch=20
05/25/2022 11:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7118041736566629 -> 0.7512442581442482 on epoch=20, global_step=1150
05/25/2022 11:48:17 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=20
05/25/2022 11:48:20 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=20
05/25/2022 11:48:22 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=21
05/25/2022 11:48:25 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=21
05/25/2022 11:48:27 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=21
05/25/2022 11:48:54 - INFO - __main__ - Global step 1200 Train loss 0.13 Classification-F1 0.633564078265889 on epoch=21
05/25/2022 11:48:56 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=21
05/25/2022 11:48:59 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=21
05/25/2022 11:49:01 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=21
05/25/2022 11:49:04 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=22
05/25/2022 11:49:06 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=22
05/25/2022 11:49:32 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.6741585437039391 on epoch=22
05/25/2022 11:49:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.16 on epoch=22
05/25/2022 11:49:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=22
05/25/2022 11:49:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=22
05/25/2022 11:49:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=23
05/25/2022 11:49:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=23
05/25/2022 11:50:10 - INFO - __main__ - Global step 1300 Train loss 0.14 Classification-F1 0.6995945108457533 on epoch=23
05/25/2022 11:50:13 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.10 on epoch=23
05/25/2022 11:50:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=23
05/25/2022 11:50:18 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=23
05/25/2022 11:50:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=23
05/25/2022 11:50:23 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=24
05/25/2022 11:50:48 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.6248358333749979 on epoch=24
05/25/2022 11:50:51 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=24
05/25/2022 11:50:53 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=24
05/25/2022 11:50:56 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=24
05/25/2022 11:50:58 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.13 on epoch=24
05/25/2022 11:51:01 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=24
05/25/2022 11:51:27 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7372072357504328 on epoch=24
05/25/2022 11:51:29 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=25
05/25/2022 11:51:32 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=25
05/25/2022 11:51:34 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=25
05/25/2022 11:51:37 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.11 on epoch=25
05/25/2022 11:51:39 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=25
05/25/2022 11:52:04 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7509887859446764 on epoch=25
05/25/2022 11:52:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=26
05/25/2022 11:52:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=26
05/25/2022 11:52:12 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=26
05/25/2022 11:52:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=26
05/25/2022 11:52:17 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=26
05/25/2022 11:52:42 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.6688630509173928 on epoch=26
05/25/2022 11:52:44 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=26
05/25/2022 11:52:47 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=27
05/25/2022 11:52:49 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.08 on epoch=27
05/25/2022 11:52:52 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=27
05/25/2022 11:52:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=27
05/25/2022 11:53:20 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.6502370927632868 on epoch=27
05/25/2022 11:53:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=27
05/25/2022 11:53:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=28
05/25/2022 11:53:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=28
05/25/2022 11:53:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=28
05/25/2022 11:53:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=28
05/25/2022 11:53:58 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.6199092746253142 on epoch=28
05/25/2022 11:54:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=28
05/25/2022 11:54:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=28
05/25/2022 11:54:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=29
05/25/2022 11:54:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=29
05/25/2022 11:54:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=29
05/25/2022 11:54:35 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6733816316127254 on epoch=29
05/25/2022 11:54:38 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=29
05/25/2022 11:54:40 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=29
05/25/2022 11:54:43 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=29
05/25/2022 11:54:45 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=30
05/25/2022 11:54:48 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=30
05/25/2022 11:55:14 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7107689259931946 on epoch=30
05/25/2022 11:55:16 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=30
05/25/2022 11:55:19 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=30
05/25/2022 11:55:21 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
05/25/2022 11:55:24 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=31
05/25/2022 11:55:27 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=31
05/25/2022 11:55:52 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6121823654669956 on epoch=31
05/25/2022 11:55:55 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=31
05/25/2022 11:55:57 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=31
05/25/2022 11:56:00 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=31
05/25/2022 11:56:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=31
05/25/2022 11:56:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=32
05/25/2022 11:56:31 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6355190577510345 on epoch=32
05/25/2022 11:56:33 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=32
05/25/2022 11:56:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=32
05/25/2022 11:56:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=32
05/25/2022 11:56:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=32
05/25/2022 11:56:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=33
05/25/2022 11:57:08 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.5961057873062627 on epoch=33
05/25/2022 11:57:11 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.16 on epoch=33
05/25/2022 11:57:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.13 on epoch=33
05/25/2022 11:57:16 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 11:57:19 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=33
05/25/2022 11:57:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=33
05/25/2022 11:57:47 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6663408653439518 on epoch=33
05/25/2022 11:57:49 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.13 on epoch=34
05/25/2022 11:57:52 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=34
05/25/2022 11:57:54 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=34
05/25/2022 11:57:57 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=34
05/25/2022 11:57:59 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=34
05/25/2022 11:58:25 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.6710281139310018 on epoch=34
05/25/2022 11:58:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=34
05/25/2022 11:58:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=35
05/25/2022 11:58:32 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=35
05/25/2022 11:58:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=35
05/25/2022 11:58:37 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/25/2022 11:59:03 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6573690543275796 on epoch=35
05/25/2022 11:59:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=35
05/25/2022 11:59:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=36
05/25/2022 11:59:11 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=36
05/25/2022 11:59:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=36
05/25/2022 11:59:16 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=36
05/25/2022 11:59:41 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7032207987247387 on epoch=36
05/25/2022 11:59:44 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=36
05/25/2022 11:59:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=36
05/25/2022 11:59:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=37
05/25/2022 11:59:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=37
05/25/2022 11:59:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=37
05/25/2022 12:00:20 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7616196734073577 on epoch=37
05/25/2022 12:00:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7512442581442482 -> 0.7616196734073577 on epoch=37, global_step=2100
05/25/2022 12:00:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=37
05/25/2022 12:00:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=37
05/25/2022 12:00:28 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=38
05/25/2022 12:00:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=38
05/25/2022 12:00:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=38
05/25/2022 12:01:00 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7125671961943493 on epoch=38
05/25/2022 12:01:02 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=38
05/25/2022 12:01:05 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=38
05/25/2022 12:01:07 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=38
05/25/2022 12:01:10 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=39
05/25/2022 12:01:13 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=39
05/25/2022 12:01:38 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7471056289574713 on epoch=39
05/25/2022 12:01:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=39
05/25/2022 12:01:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=39
05/25/2022 12:01:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=39
05/25/2022 12:01:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=39
05/25/2022 12:01:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=40
05/25/2022 12:02:16 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.7493888604596408 on epoch=40
05/25/2022 12:02:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=40
05/25/2022 12:02:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=40
05/25/2022 12:02:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.10 on epoch=40
05/25/2022 12:02:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=40
05/25/2022 12:02:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/25/2022 12:02:54 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.6412907784305206 on epoch=41
05/25/2022 12:02:57 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
05/25/2022 12:02:59 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=41
05/25/2022 12:03:02 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=41
05/25/2022 12:03:04 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=41
05/25/2022 12:03:07 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=41
05/25/2022 12:03:32 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7126874153195901 on epoch=41
05/25/2022 12:03:35 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=42
05/25/2022 12:03:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=42
05/25/2022 12:03:40 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=42
05/25/2022 12:03:43 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=42
05/25/2022 12:03:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=42
05/25/2022 12:04:11 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7558358806630796 on epoch=42
05/25/2022 12:04:13 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=43
05/25/2022 12:04:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=43
05/25/2022 12:04:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=43
05/25/2022 12:04:21 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
05/25/2022 12:04:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=43
05/25/2022 12:04:49 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8012234577445747 on epoch=43
05/25/2022 12:04:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7616196734073577 -> 0.8012234577445747 on epoch=43, global_step=2450
05/25/2022 12:04:52 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 12:04:54 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=44
05/25/2022 12:04:57 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=44
05/25/2022 12:04:59 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=44
05/25/2022 12:05:02 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
05/25/2022 12:05:27 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.6743383775558864 on epoch=44
05/25/2022 12:05:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=44
05/25/2022 12:05:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=44
05/25/2022 12:05:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=45
05/25/2022 12:05:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=45
05/25/2022 12:05:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=45
05/25/2022 12:06:05 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7121549338426006 on epoch=45
05/25/2022 12:06:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=45
05/25/2022 12:06:10 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=45
05/25/2022 12:06:13 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=46
05/25/2022 12:06:15 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=46
05/25/2022 12:06:18 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=46
05/25/2022 12:06:43 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.6583760403673258 on epoch=46
05/25/2022 12:06:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=46
05/25/2022 12:06:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
05/25/2022 12:06:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=46
05/25/2022 12:06:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=47
05/25/2022 12:06:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=47
05/25/2022 12:07:21 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7098122843106602 on epoch=47
05/25/2022 12:07:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=47
05/25/2022 12:07:26 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=47
05/25/2022 12:07:29 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=47
05/25/2022 12:07:31 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=48
05/25/2022 12:07:34 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=48
05/25/2022 12:07:59 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7129282896112104 on epoch=48
05/25/2022 12:08:01 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=48
05/25/2022 12:08:04 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=48
05/25/2022 12:08:07 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=48
05/25/2022 12:08:09 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=48
05/25/2022 12:08:12 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=49
05/25/2022 12:08:37 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7496192500016668 on epoch=49
05/25/2022 12:08:39 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=49
05/25/2022 12:08:42 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=49
05/25/2022 12:08:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/25/2022 12:08:47 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=49
05/25/2022 12:08:50 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=49
05/25/2022 12:09:15 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7534569496691589 on epoch=49
05/25/2022 12:09:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=50
05/25/2022 12:09:20 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=50
05/25/2022 12:09:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/25/2022 12:09:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=50
05/25/2022 12:09:28 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=50
05/25/2022 12:09:53 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8067545405068599 on epoch=50
05/25/2022 12:09:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8012234577445747 -> 0.8067545405068599 on epoch=50, global_step=2850
05/25/2022 12:09:55 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=51
05/25/2022 12:09:58 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=51
05/25/2022 12:10:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=51
05/25/2022 12:10:03 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=51
05/25/2022 12:10:06 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=51
05/25/2022 12:10:30 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7524658304293388 on epoch=51
05/25/2022 12:10:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=51
05/25/2022 12:10:36 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=52
05/25/2022 12:10:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=52
05/25/2022 12:10:41 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/25/2022 12:10:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=52
05/25/2022 12:11:08 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8039667173172874 on epoch=52
05/25/2022 12:11:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=52
05/25/2022 12:11:14 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=53
05/25/2022 12:11:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=53
05/25/2022 12:11:19 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=53
05/25/2022 12:11:22 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=53
05/25/2022 12:11:23 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 12:11:23 - INFO - __main__ - Printing 3 examples
05/25/2022 12:11:23 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 12:11:23 - INFO - __main__ - ['Film']
05/25/2022 12:11:23 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 12:11:23 - INFO - __main__ - ['Film']
05/25/2022 12:11:23 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 12:11:23 - INFO - __main__ - ['Film']
05/25/2022 12:11:23 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:11:23 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:11:24 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 12:11:24 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 12:11:24 - INFO - __main__ - Printing 3 examples
05/25/2022 12:11:24 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 12:11:24 - INFO - __main__ - ['Film']
05/25/2022 12:11:24 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 12:11:24 - INFO - __main__ - ['Film']
05/25/2022 12:11:24 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 12:11:24 - INFO - __main__ - ['Film']
05/25/2022 12:11:24 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:11:25 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:11:26 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 12:11:44 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:11:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 12:11:45 - INFO - __main__ - Starting training!
05/25/2022 12:11:46 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.9138677059312864 on epoch=53
05/25/2022 12:11:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8067545405068599 -> 0.9138677059312864 on epoch=53, global_step=3000
05/25/2022 12:11:46 - INFO - __main__ - save last model!
05/25/2022 12:11:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 12:11:46 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 12:11:46 - INFO - __main__ - Printing 3 examples
05/25/2022 12:11:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 12:11:46 - INFO - __main__ - ['Animal']
05/25/2022 12:11:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 12:11:46 - INFO - __main__ - ['Animal']
05/25/2022 12:11:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 12:11:46 - INFO - __main__ - ['Village']
05/25/2022 12:11:46 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:11:48 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:11:51 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 12:13:56 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.3_8_predictions.txt
05/25/2022 12:13:56 - INFO - __main__ - Classification-F1 on test data: 0.6513
05/25/2022 12:13:57 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.3, bsz=8, dev_performance=0.9138677059312864, test_performance=0.6512650208221078
05/25/2022 12:13:57 - INFO - __main__ - Running ... prefix=dbpedia_14_64_87, lr=0.2, bsz=8 ...
05/25/2022 12:13:58 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 12:13:58 - INFO - __main__ - Printing 3 examples
05/25/2022 12:13:58 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/25/2022 12:13:58 - INFO - __main__ - ['Film']
05/25/2022 12:13:58 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/25/2022 12:13:58 - INFO - __main__ - ['Film']
05/25/2022 12:13:58 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/25/2022 12:13:58 - INFO - __main__ - ['Film']
05/25/2022 12:13:58 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:13:58 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:13:59 - INFO - __main__ - Loaded 896 examples from train data
05/25/2022 12:13:59 - INFO - __main__ - Start tokenizing ... 896 instances
05/25/2022 12:13:59 - INFO - __main__ - Printing 3 examples
05/25/2022 12:13:59 - INFO - __main__ -  [dbpedia_14] The Minority is a 2007 American film written and directed by Dwayne Buckle and starring Billoah Greene as Jake Jackson. The Minority was Dwayne Buckle's first feature length film which was shot in New York City. The movie had its theatrical motion picture release in 2007 and debuted at the 15th Annual Pan African Film Festival in Los Angeles where it won an Honorable Mention Award. The film had its DVD release in 2009.
05/25/2022 12:13:59 - INFO - __main__ - ['Film']
05/25/2022 12:13:59 - INFO - __main__ -  [dbpedia_14] A Sign Days (Aサインデイズ) is a 1989 Japanese film directed by Yōichi Sai.
05/25/2022 12:13:59 - INFO - __main__ - ['Film']
05/25/2022 12:13:59 - INFO - __main__ -  [dbpedia_14] That Championship Season is a 1999 television film about a four members of a championship high school basketball team along with their coach that reunite 20 years later. The film is based on Jason Miller's Pulitzer Prize winning play of the same name. Sorvino assumes the role played by Robert Mitchum in the original film with D'Onofrio in his role from that presentation.
05/25/2022 12:13:59 - INFO - __main__ - ['Film']
05/25/2022 12:13:59 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:13:59 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:14:00 - INFO - __main__ - Loaded 896 examples from dev data
05/25/2022 12:14:19 - INFO - __main__ - load prompt embedding from ckpt
05/25/2022 12:14:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 12:14:20 - INFO - __main__ - Starting training!
05/25/2022 12:14:23 - INFO - __main__ - Step 10 Global step 10 Train loss 7.57 on epoch=0
05/25/2022 12:14:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.24 on epoch=0
05/25/2022 12:14:29 - INFO - __main__ - Step 30 Global step 30 Train loss 5.62 on epoch=0
05/25/2022 12:14:31 - INFO - __main__ - Step 40 Global step 40 Train loss 4.35 on epoch=0
05/25/2022 12:14:34 - INFO - __main__ - Step 50 Global step 50 Train loss 4.61 on epoch=0
05/25/2022 12:14:56 - INFO - __main__ - Global step 50 Train loss 5.68 Classification-F1 0.016482304999022524 on epoch=0
05/25/2022 12:14:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016482304999022524 on epoch=0, global_step=50
05/25/2022 12:14:59 - INFO - __main__ - Step 60 Global step 60 Train loss 3.81 on epoch=1
05/25/2022 12:15:01 - INFO - __main__ - Step 70 Global step 70 Train loss 3.73 on epoch=1
05/25/2022 12:15:04 - INFO - __main__ - Step 80 Global step 80 Train loss 3.66 on epoch=1
05/25/2022 12:15:07 - INFO - __main__ - Step 90 Global step 90 Train loss 3.64 on epoch=1
05/25/2022 12:15:09 - INFO - __main__ - Step 100 Global step 100 Train loss 2.84 on epoch=1
05/25/2022 12:15:36 - INFO - __main__ - Global step 100 Train loss 3.54 Classification-F1 0.017764357496278145 on epoch=1
05/25/2022 12:15:36 - INFO - __main__ - Saving model with best Classification-F1: 0.016482304999022524 -> 0.017764357496278145 on epoch=1, global_step=100
05/25/2022 12:15:39 - INFO - __main__ - Step 110 Global step 110 Train loss 2.72 on epoch=1
05/25/2022 12:15:41 - INFO - __main__ - Step 120 Global step 120 Train loss 2.55 on epoch=2
05/25/2022 12:15:44 - INFO - __main__ - Step 130 Global step 130 Train loss 2.87 on epoch=2
05/25/2022 12:15:46 - INFO - __main__ - Step 140 Global step 140 Train loss 2.50 on epoch=2
05/25/2022 12:15:49 - INFO - __main__ - Step 150 Global step 150 Train loss 2.48 on epoch=2
05/25/2022 12:16:13 - INFO - __main__ - Global step 150 Train loss 2.63 Classification-F1 0.03200041203430869 on epoch=2
05/25/2022 12:16:13 - INFO - __main__ - Saving model with best Classification-F1: 0.017764357496278145 -> 0.03200041203430869 on epoch=2, global_step=150
05/25/2022 12:16:16 - INFO - __main__ - Step 160 Global step 160 Train loss 2.29 on epoch=2
05/25/2022 12:16:18 - INFO - __main__ - Step 170 Global step 170 Train loss 2.01 on epoch=3
05/25/2022 12:16:21 - INFO - __main__ - Step 180 Global step 180 Train loss 2.00 on epoch=3
05/25/2022 12:16:23 - INFO - __main__ - Step 190 Global step 190 Train loss 2.01 on epoch=3
05/25/2022 12:16:26 - INFO - __main__ - Step 200 Global step 200 Train loss 2.25 on epoch=3
05/25/2022 12:16:49 - INFO - __main__ - Global step 200 Train loss 2.11 Classification-F1 0.053951527394293465 on epoch=3
05/25/2022 12:16:49 - INFO - __main__ - Saving model with best Classification-F1: 0.03200041203430869 -> 0.053951527394293465 on epoch=3, global_step=200
05/25/2022 12:16:51 - INFO - __main__ - Step 210 Global step 210 Train loss 1.74 on epoch=3
05/25/2022 12:16:54 - INFO - __main__ - Step 220 Global step 220 Train loss 1.89 on epoch=3
05/25/2022 12:16:56 - INFO - __main__ - Step 230 Global step 230 Train loss 1.64 on epoch=4
05/25/2022 12:16:59 - INFO - __main__ - Step 240 Global step 240 Train loss 1.68 on epoch=4
05/25/2022 12:17:01 - INFO - __main__ - Step 250 Global step 250 Train loss 1.82 on epoch=4
05/25/2022 12:17:24 - INFO - __main__ - Global step 250 Train loss 1.75 Classification-F1 0.07466953467888046 on epoch=4
05/25/2022 12:17:24 - INFO - __main__ - Saving model with best Classification-F1: 0.053951527394293465 -> 0.07466953467888046 on epoch=4, global_step=250
05/25/2022 12:17:26 - INFO - __main__ - Step 260 Global step 260 Train loss 1.66 on epoch=4
05/25/2022 12:17:29 - INFO - __main__ - Step 270 Global step 270 Train loss 1.41 on epoch=4
05/25/2022 12:17:31 - INFO - __main__ - Step 280 Global step 280 Train loss 1.38 on epoch=4
05/25/2022 12:17:34 - INFO - __main__ - Step 290 Global step 290 Train loss 1.32 on epoch=5
05/25/2022 12:17:36 - INFO - __main__ - Step 300 Global step 300 Train loss 1.53 on epoch=5
05/25/2022 12:17:59 - INFO - __main__ - Global step 300 Train loss 1.46 Classification-F1 0.10890525050633985 on epoch=5
05/25/2022 12:17:59 - INFO - __main__ - Saving model with best Classification-F1: 0.07466953467888046 -> 0.10890525050633985 on epoch=5, global_step=300
05/25/2022 12:18:01 - INFO - __main__ - Step 310 Global step 310 Train loss 1.44 on epoch=5
05/25/2022 12:18:04 - INFO - __main__ - Step 320 Global step 320 Train loss 1.29 on epoch=5
05/25/2022 12:18:06 - INFO - __main__ - Step 330 Global step 330 Train loss 1.21 on epoch=5
05/25/2022 12:18:09 - INFO - __main__ - Step 340 Global step 340 Train loss 1.03 on epoch=6
05/25/2022 12:18:12 - INFO - __main__ - Step 350 Global step 350 Train loss 1.13 on epoch=6
05/25/2022 12:18:33 - INFO - __main__ - Global step 350 Train loss 1.22 Classification-F1 0.13296677926214193 on epoch=6
05/25/2022 12:18:33 - INFO - __main__ - Saving model with best Classification-F1: 0.10890525050633985 -> 0.13296677926214193 on epoch=6, global_step=350
05/25/2022 12:18:36 - INFO - __main__ - Step 360 Global step 360 Train loss 1.10 on epoch=6
05/25/2022 12:18:39 - INFO - __main__ - Step 370 Global step 370 Train loss 1.14 on epoch=6
05/25/2022 12:18:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.91 on epoch=6
05/25/2022 12:18:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.90 on epoch=6
05/25/2022 12:18:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.88 on epoch=7
05/25/2022 12:19:08 - INFO - __main__ - Global step 400 Train loss 0.99 Classification-F1 0.18646125800622132 on epoch=7
05/25/2022 12:19:08 - INFO - __main__ - Saving model with best Classification-F1: 0.13296677926214193 -> 0.18646125800622132 on epoch=7, global_step=400
05/25/2022 12:19:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.91 on epoch=7
05/25/2022 12:19:13 - INFO - __main__ - Step 420 Global step 420 Train loss 0.91 on epoch=7
05/25/2022 12:19:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.83 on epoch=7
05/25/2022 12:19:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.78 on epoch=7
05/25/2022 12:19:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.66 on epoch=8
05/25/2022 12:19:44 - INFO - __main__ - Global step 450 Train loss 0.82 Classification-F1 0.23777574471446586 on epoch=8
05/25/2022 12:19:44 - INFO - __main__ - Saving model with best Classification-F1: 0.18646125800622132 -> 0.23777574471446586 on epoch=8, global_step=450
05/25/2022 12:19:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.69 on epoch=8
05/25/2022 12:19:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=8
05/25/2022 12:19:51 - INFO - __main__ - Step 480 Global step 480 Train loss 0.86 on epoch=8
05/25/2022 12:19:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.55 on epoch=8
05/25/2022 12:19:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.56 on epoch=8
05/25/2022 12:20:21 - INFO - __main__ - Global step 500 Train loss 0.66 Classification-F1 0.26908002604632203 on epoch=8
05/25/2022 12:20:21 - INFO - __main__ - Saving model with best Classification-F1: 0.23777574471446586 -> 0.26908002604632203 on epoch=8, global_step=500
05/25/2022 12:20:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=9
05/25/2022 12:20:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.66 on epoch=9
05/25/2022 12:20:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.49 on epoch=9
05/25/2022 12:20:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.54 on epoch=9
05/25/2022 12:20:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.55 on epoch=9
05/25/2022 12:20:58 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.28715843806880986 on epoch=9
05/25/2022 12:20:58 - INFO - __main__ - Saving model with best Classification-F1: 0.26908002604632203 -> 0.28715843806880986 on epoch=9, global_step=550
05/25/2022 12:21:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.47 on epoch=9
05/25/2022 12:21:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=10
05/25/2022 12:21:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.51 on epoch=10
05/25/2022 12:21:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=10
05/25/2022 12:21:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.51 on epoch=10
05/25/2022 12:21:37 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.3531650647254136 on epoch=10
05/25/2022 12:21:37 - INFO - __main__ - Saving model with best Classification-F1: 0.28715843806880986 -> 0.3531650647254136 on epoch=10, global_step=600
05/25/2022 12:21:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.45 on epoch=10
05/25/2022 12:21:42 - INFO - __main__ - Step 620 Global step 620 Train loss 0.41 on epoch=11
05/25/2022 12:21:45 - INFO - __main__ - Step 630 Global step 630 Train loss 0.49 on epoch=11
05/25/2022 12:21:47 - INFO - __main__ - Step 640 Global step 640 Train loss 0.48 on epoch=11
05/25/2022 12:21:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.41 on epoch=11
05/25/2022 12:22:16 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.34542832322348743 on epoch=11
05/25/2022 12:22:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.39 on epoch=11
05/25/2022 12:22:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=11
05/25/2022 12:22:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.35 on epoch=12
05/25/2022 12:22:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.35 on epoch=12
05/25/2022 12:22:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=12
05/25/2022 12:22:55 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.3939418909270374 on epoch=12
05/25/2022 12:22:55 - INFO - __main__ - Saving model with best Classification-F1: 0.3531650647254136 -> 0.3939418909270374 on epoch=12, global_step=700
05/25/2022 12:22:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=12
05/25/2022 12:23:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=12
05/25/2022 12:23:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=13
05/25/2022 12:23:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.34 on epoch=13
05/25/2022 12:23:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=13
05/25/2022 12:23:34 - INFO - __main__ - Global step 750 Train loss 0.36 Classification-F1 0.37069680387517634 on epoch=13
05/25/2022 12:23:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=13
05/25/2022 12:23:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=13
05/25/2022 12:23:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=13
05/25/2022 12:23:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.38 on epoch=14
05/25/2022 12:23:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.34 on epoch=14
05/25/2022 12:24:12 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.412772143354386 on epoch=14
05/25/2022 12:24:12 - INFO - __main__ - Saving model with best Classification-F1: 0.3939418909270374 -> 0.412772143354386 on epoch=14, global_step=800
05/25/2022 12:24:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.35 on epoch=14
05/25/2022 12:24:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=14
05/25/2022 12:24:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=14
05/25/2022 12:24:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.28 on epoch=14
05/25/2022 12:24:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=15
05/25/2022 12:24:49 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.4117304095001977 on epoch=15
05/25/2022 12:24:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=15
05/25/2022 12:24:54 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=15
05/25/2022 12:24:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=15
05/25/2022 12:24:59 - INFO - __main__ - Step 890 Global step 890 Train loss 0.31 on epoch=15
05/25/2022 12:25:02 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=16
05/25/2022 12:25:28 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.4575059505791075 on epoch=16
05/25/2022 12:25:28 - INFO - __main__ - Saving model with best Classification-F1: 0.412772143354386 -> 0.4575059505791075 on epoch=16, global_step=900
05/25/2022 12:25:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=16
05/25/2022 12:25:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=16
05/25/2022 12:25:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=16
05/25/2022 12:25:38 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=16
05/25/2022 12:25:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.21 on epoch=16
05/25/2022 12:26:05 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.4177276344196289 on epoch=16
05/25/2022 12:26:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.26 on epoch=17
05/25/2022 12:26:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=17
05/25/2022 12:26:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=17
05/25/2022 12:26:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=17
05/25/2022 12:26:18 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=17
05/25/2022 12:26:43 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.3994564824212498 on epoch=17
05/25/2022 12:26:46 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=18
05/25/2022 12:26:48 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.26 on epoch=18
05/25/2022 12:26:51 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=18
05/25/2022 12:26:53 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=18
05/25/2022 12:26:56 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.24 on epoch=18
05/25/2022 12:27:21 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.41933055609079567 on epoch=18
05/25/2022 12:27:24 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.22 on epoch=18
05/25/2022 12:27:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=19
05/25/2022 12:27:29 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=19
05/25/2022 12:27:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=19
05/25/2022 12:27:34 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=19
05/25/2022 12:27:58 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.49141620384334633 on epoch=19
05/25/2022 12:27:58 - INFO - __main__ - Saving model with best Classification-F1: 0.4575059505791075 -> 0.49141620384334633 on epoch=19, global_step=1100
05/25/2022 12:28:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=19
05/25/2022 12:28:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=19
05/25/2022 12:28:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.32 on epoch=20
05/25/2022 12:28:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=20
05/25/2022 12:28:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=20
05/25/2022 12:28:36 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.5500887793190741 on epoch=20
05/25/2022 12:28:36 - INFO - __main__ - Saving model with best Classification-F1: 0.49141620384334633 -> 0.5500887793190741 on epoch=20, global_step=1150
05/25/2022 12:28:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.26 on epoch=20
05/25/2022 12:28:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=20
05/25/2022 12:28:44 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.25 on epoch=21
05/25/2022 12:28:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.28 on epoch=21
05/25/2022 12:28:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.25 on epoch=21
05/25/2022 12:29:14 - INFO - __main__ - Global step 1200 Train loss 0.24 Classification-F1 0.49098571009306213 on epoch=21
05/25/2022 12:29:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=21
05/25/2022 12:29:20 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.20 on epoch=21
05/25/2022 12:29:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=21
05/25/2022 12:29:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.23 on epoch=22
05/25/2022 12:29:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=22
05/25/2022 12:29:53 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.534021498422221 on epoch=22
05/25/2022 12:29:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=22
05/25/2022 12:29:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=22
05/25/2022 12:30:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.24 on epoch=22
05/25/2022 12:30:03 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=23
05/25/2022 12:30:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=23
05/25/2022 12:30:31 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.5120934932764107 on epoch=23
05/25/2022 12:30:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=23
05/25/2022 12:30:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=23
05/25/2022 12:30:39 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=23
05/25/2022 12:30:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=23
05/25/2022 12:30:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.25 on epoch=24
05/25/2022 12:31:09 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.577892383508102 on epoch=24
05/25/2022 12:31:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5500887793190741 -> 0.577892383508102 on epoch=24, global_step=1350
05/25/2022 12:31:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=24
05/25/2022 12:31:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=24
05/25/2022 12:31:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=24
05/25/2022 12:31:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=24
05/25/2022 12:31:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=24
05/25/2022 12:31:47 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.5862902791033358 on epoch=24
05/25/2022 12:31:47 - INFO - __main__ - Saving model with best Classification-F1: 0.577892383508102 -> 0.5862902791033358 on epoch=24, global_step=1400
05/25/2022 12:31:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=25
05/25/2022 12:31:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.20 on epoch=25
05/25/2022 12:31:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=25
05/25/2022 12:31:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=25
05/25/2022 12:32:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=25
05/25/2022 12:32:26 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.619651430432553 on epoch=25
05/25/2022 12:32:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5862902791033358 -> 0.619651430432553 on epoch=25, global_step=1450
05/25/2022 12:32:28 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=26
05/25/2022 12:32:31 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.15 on epoch=26
05/25/2022 12:32:33 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=26
05/25/2022 12:32:36 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=26
05/25/2022 12:32:39 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=26
05/25/2022 12:33:04 - INFO - __main__ - Global step 1500 Train loss 0.15 Classification-F1 0.5953971647325584 on epoch=26
05/25/2022 12:33:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.17 on epoch=26
05/25/2022 12:33:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=27
05/25/2022 12:33:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=27
05/25/2022 12:33:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.14 on epoch=27
05/25/2022 12:33:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=27
05/25/2022 12:33:42 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.5937176027744817 on epoch=27
05/25/2022 12:33:44 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=27
05/25/2022 12:33:47 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=28
05/25/2022 12:33:49 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.15 on epoch=28
05/25/2022 12:33:52 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=28
05/25/2022 12:33:55 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=28
05/25/2022 12:34:20 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.5439665757894023 on epoch=28
05/25/2022 12:34:22 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.22 on epoch=28
05/25/2022 12:34:25 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=28
05/25/2022 12:34:27 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=29
05/25/2022 12:34:30 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=29
05/25/2022 12:34:32 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.19 on epoch=29
05/25/2022 12:34:57 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5686662599631677 on epoch=29
05/25/2022 12:35:00 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=29
05/25/2022 12:35:02 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=29
05/25/2022 12:35:05 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=29
05/25/2022 12:35:07 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=30
05/25/2022 12:35:10 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.19 on epoch=30
05/25/2022 12:35:35 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.5686057323652981 on epoch=30
05/25/2022 12:35:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=30
05/25/2022 12:35:40 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=30
05/25/2022 12:35:43 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=30
05/25/2022 12:35:45 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=31
05/25/2022 12:35:48 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.15 on epoch=31
05/25/2022 12:36:13 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.5966203730955361 on epoch=31
05/25/2022 12:36:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=31
05/25/2022 12:36:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=31
05/25/2022 12:36:21 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=31
05/25/2022 12:36:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=31
05/25/2022 12:36:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.16 on epoch=32
05/25/2022 12:36:51 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5469309227874173 on epoch=32
05/25/2022 12:36:53 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=32
05/25/2022 12:36:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.12 on epoch=32
05/25/2022 12:36:58 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=32
05/25/2022 12:37:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=32
05/25/2022 12:37:03 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=33
05/25/2022 12:37:29 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.6034892770607063 on epoch=33
05/25/2022 12:37:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.17 on epoch=33
05/25/2022 12:37:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=33
05/25/2022 12:37:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=33
05/25/2022 12:37:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.15 on epoch=33
05/25/2022 12:37:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=33
05/25/2022 12:38:07 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.635151262167921 on epoch=33
05/25/2022 12:38:08 - INFO - __main__ - Saving model with best Classification-F1: 0.619651430432553 -> 0.635151262167921 on epoch=33, global_step=1900
05/25/2022 12:38:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=34
05/25/2022 12:38:13 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.13 on epoch=34
05/25/2022 12:38:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=34
05/25/2022 12:38:18 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=34
05/25/2022 12:38:21 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=34
05/25/2022 12:38:46 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.6052830826967168 on epoch=34
05/25/2022 12:38:48 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=34
05/25/2022 12:38:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=35
05/25/2022 12:38:53 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.15 on epoch=35
05/25/2022 12:38:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=35
05/25/2022 12:38:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=35
05/25/2022 12:39:23 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.6592608728498116 on epoch=35
05/25/2022 12:39:23 - INFO - __main__ - Saving model with best Classification-F1: 0.635151262167921 -> 0.6592608728498116 on epoch=35, global_step=2000
05/25/2022 12:39:26 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=35
05/25/2022 12:39:28 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=36
05/25/2022 12:39:31 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=36
05/25/2022 12:39:33 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=36
05/25/2022 12:39:36 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=36
05/25/2022 12:40:00 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.6647928725440175 on epoch=36
05/25/2022 12:40:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6592608728498116 -> 0.6647928725440175 on epoch=36, global_step=2050
05/25/2022 12:40:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=36
05/25/2022 12:40:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=36
05/25/2022 12:40:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.14 on epoch=37
05/25/2022 12:40:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=37
05/25/2022 12:40:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=37
05/25/2022 12:40:37 - INFO - __main__ - Global step 2100 Train loss 0.11 Classification-F1 0.6329657662032685 on epoch=37
05/25/2022 12:40:40 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.14 on epoch=37
05/25/2022 12:40:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=37
05/25/2022 12:40:45 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=38
05/25/2022 12:40:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.10 on epoch=38
05/25/2022 12:40:50 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=38
05/25/2022 12:41:14 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6743086385466244 on epoch=38
05/25/2022 12:41:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6647928725440175 -> 0.6743086385466244 on epoch=38, global_step=2150
05/25/2022 12:41:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=38
05/25/2022 12:41:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=38
05/25/2022 12:41:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=38
05/25/2022 12:41:25 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.18 on epoch=39
05/25/2022 12:41:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=39
05/25/2022 12:41:51 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.6750523359874644 on epoch=39
05/25/2022 12:41:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6743086385466244 -> 0.6750523359874644 on epoch=39, global_step=2200
05/25/2022 12:41:54 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=39
05/25/2022 12:41:56 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=39
05/25/2022 12:41:59 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=39
05/25/2022 12:42:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=39
05/25/2022 12:42:04 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.20 on epoch=40
05/25/2022 12:42:29 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7580092578550487 on epoch=40
05/25/2022 12:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6750523359874644 -> 0.7580092578550487 on epoch=40, global_step=2250
05/25/2022 12:42:32 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=40
05/25/2022 12:42:34 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=40
05/25/2022 12:42:37 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=40
05/25/2022 12:42:39 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=40
05/25/2022 12:42:42 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=41
05/25/2022 12:43:07 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.7711137272219495 on epoch=41
05/25/2022 12:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7580092578550487 -> 0.7711137272219495 on epoch=41, global_step=2300
05/25/2022 12:43:10 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=41
05/25/2022 12:43:12 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.13 on epoch=41
05/25/2022 12:43:15 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=41
05/25/2022 12:43:17 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=41
05/25/2022 12:43:20 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=41
05/25/2022 12:43:45 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.7733662677218425 on epoch=41
05/25/2022 12:43:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7711137272219495 -> 0.7733662677218425 on epoch=41, global_step=2350
05/25/2022 12:43:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.09 on epoch=42
05/25/2022 12:43:50 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=42
05/25/2022 12:43:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=42
05/25/2022 12:43:55 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=42
05/25/2022 12:43:58 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=42
05/25/2022 12:44:23 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.7719014395014177 on epoch=42
05/25/2022 12:44:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=43
05/25/2022 12:44:28 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=43
05/25/2022 12:44:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.11 on epoch=43
05/25/2022 12:44:33 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=43
05/25/2022 12:44:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=43
05/25/2022 12:45:00 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7778592540769156 on epoch=43
05/25/2022 12:45:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7733662677218425 -> 0.7778592540769156 on epoch=43, global_step=2450
05/25/2022 12:45:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=43
05/25/2022 12:45:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=44
05/25/2022 12:45:08 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=44
05/25/2022 12:45:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=44
05/25/2022 12:45:13 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=44
05/25/2022 12:45:37 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.6872452698510884 on epoch=44
05/25/2022 12:45:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=44
05/25/2022 12:45:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=44
05/25/2022 12:45:45 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=45
05/25/2022 12:45:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=45
05/25/2022 12:45:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=45
05/25/2022 12:46:14 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.6546333320986245 on epoch=45
05/25/2022 12:46:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.12 on epoch=45
05/25/2022 12:46:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=45
05/25/2022 12:46:22 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.11 on epoch=46
05/25/2022 12:46:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=46
05/25/2022 12:46:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=46
05/25/2022 12:46:51 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.6440645337679339 on epoch=46
05/25/2022 12:46:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.09 on epoch=46
05/25/2022 12:46:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=46
05/25/2022 12:46:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=46
05/25/2022 12:47:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=47
05/25/2022 12:47:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=47
05/25/2022 12:47:27 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.678288726379388 on epoch=47
05/25/2022 12:47:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.10 on epoch=47
05/25/2022 12:47:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=47
05/25/2022 12:47:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=47
05/25/2022 12:47:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=48
05/25/2022 12:47:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.10 on epoch=48
05/25/2022 12:48:04 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.6454909570437761 on epoch=48
05/25/2022 12:48:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=48
05/25/2022 12:48:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=48
05/25/2022 12:48:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=48
05/25/2022 12:48:15 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=48
05/25/2022 12:48:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=49
05/25/2022 12:48:41 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.6389703011337406 on epoch=49
05/25/2022 12:48:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=49
05/25/2022 12:48:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=49
05/25/2022 12:48:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=49
05/25/2022 12:48:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=49
05/25/2022 12:48:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=49
05/25/2022 12:49:18 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6547465033268123 on epoch=49
05/25/2022 12:49:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=50
05/25/2022 12:49:23 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.10 on epoch=50
05/25/2022 12:49:25 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=50
05/25/2022 12:49:28 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.08 on epoch=50
05/25/2022 12:49:30 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=50
05/25/2022 12:49:54 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.68847586247248 on epoch=50
05/25/2022 12:49:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=51
05/25/2022 12:50:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=51
05/25/2022 12:50:02 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=51
05/25/2022 12:50:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=51
05/25/2022 12:50:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=51
05/25/2022 12:50:31 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.6864683081224298 on epoch=51
05/25/2022 12:50:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=51
05/25/2022 12:50:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=52
05/25/2022 12:50:39 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=52
05/25/2022 12:50:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=52
05/25/2022 12:50:44 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=52
05/25/2022 12:51:08 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6839859380186247 on epoch=52
05/25/2022 12:51:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.06 on epoch=52
05/25/2022 12:51:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.10 on epoch=53
05/25/2022 12:51:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=53
05/25/2022 12:51:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=53
05/25/2022 12:51:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=53
05/25/2022 12:51:45 - INFO - __main__ - Global step 3000 Train loss 0.07 Classification-F1 0.7467549167040398 on epoch=53
05/25/2022 12:51:45 - INFO - __main__ - save last model!
05/25/2022 12:51:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/25/2022 12:51:45 - INFO - __main__ - Start tokenizing ... 3500 instances
05/25/2022 12:51:45 - INFO - __main__ - Printing 3 examples
05/25/2022 12:51:45 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/25/2022 12:51:45 - INFO - __main__ - ['Animal']
05/25/2022 12:51:45 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/25/2022 12:51:45 - INFO - __main__ - ['Animal']
05/25/2022 12:51:45 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/25/2022 12:51:45 - INFO - __main__ - ['Village']
05/25/2022 12:51:45 - INFO - __main__ - Tokenizing Input ...
05/25/2022 12:51:47 - INFO - __main__ - Tokenizing Output ...
05/25/2022 12:51:51 - INFO - __main__ - Loaded 3500 examples from test data
05/25/2022 12:53:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down64shot/singletask-dbpedia_14/dbpedia_14_64_87_0.2_8_predictions.txt
05/25/2022 12:53:49 - INFO - __main__ - Classification-F1 on test data: 0.6049
05/25/2022 12:53:50 - INFO - __main__ - prefix=dbpedia_14_64_87, lr=0.2, bsz=8, dev_performance=0.7778592540769156, test_performance=0.6048687825683338
