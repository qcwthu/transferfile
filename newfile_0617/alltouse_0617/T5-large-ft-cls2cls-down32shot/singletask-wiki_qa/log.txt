05/21/2022 21:20:18 - INFO - __main__ - Namespace(task_dir='data_32/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:20:18 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa
05/21/2022 21:20:18 - INFO - __main__ - Namespace(task_dir='data_32/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:20:18 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa
05/21/2022 21:20:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:20:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:20:19 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:20:19 - INFO - __main__ - Using 2 gpus
05/21/2022 21:20:19 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:20:19 - INFO - __main__ - Using 2 gpus
05/21/2022 21:20:19 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_32_100', 'wiki_qa_32_13', 'wiki_qa_32_21', 'wiki_qa_32_42', 'wiki_qa_32_87']
05/21/2022 21:20:19 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_32_100', 'wiki_qa_32_13', 'wiki_qa_32_21', 'wiki_qa_32_42', 'wiki_qa_32_87']
05/21/2022 21:20:24 - INFO - __main__ - Running ... prefix=wiki_qa_32_100, lr=0.0005, bsz=8 ...
05/31/2022 06:14:25 - INFO - __main__ - Namespace(task_dir='data_32/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/31/2022 06:14:25 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa
05/31/2022 06:14:25 - INFO - __main__ - Namespace(task_dir='data_32/wiki_qa/', task_name='wiki_qa', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/31/2022 06:14:25 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa
05/31/2022 06:14:26 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/31/2022 06:14:26 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/31/2022 06:14:26 - INFO - __main__ - args.device: cuda:0
05/31/2022 06:14:26 - INFO - __main__ - Using 2 gpus
05/31/2022 06:14:26 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_32_100', 'wiki_qa_32_13', 'wiki_qa_32_21', 'wiki_qa_32_42', 'wiki_qa_32_87']
05/31/2022 06:14:26 - INFO - __main__ - args.device: cuda:1
05/31/2022 06:14:26 - INFO - __main__ - Using 2 gpus
05/31/2022 06:14:26 - INFO - __main__ - Fine-tuning the following samples: ['wiki_qa_32_100', 'wiki_qa_32_13', 'wiki_qa_32_21', 'wiki_qa_32_42', 'wiki_qa_32_87']
05/31/2022 06:14:31 - INFO - __main__ - Running ... prefix=wiki_qa_32_100, lr=0.0005, bsz=8 ...
05/31/2022 06:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:14:32 - INFO - __main__ - Printing 3 examples
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:14:32 - INFO - __main__ - Printing 3 examples
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:14:32 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:14:32 - INFO - __main__ - Printing 3 examples
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:14:32 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:14:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:14:32 - INFO - __main__ - Printing 3 examples
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:14:32 - INFO - __main__ - ['false']
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:14:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:14:32 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:14:32 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:14:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:14:45 - INFO - __main__ - Starting training!
05/31/2022 06:14:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:14:45 - INFO - __main__ - Starting training!
05/31/2022 06:14:50 - INFO - __main__ - Step 10 Global step 10 Train loss 23.657108 on epoch=2
05/31/2022 06:14:55 - INFO - __main__ - Step 20 Global step 20 Train loss 17.725473 on epoch=4
05/31/2022 06:14:59 - INFO - __main__ - Step 30 Global step 30 Train loss 16.278881 on epoch=7
05/31/2022 06:15:04 - INFO - __main__ - Step 40 Global step 40 Train loss 15.032288 on epoch=9
05/31/2022 06:15:09 - INFO - __main__ - Step 50 Global step 50 Train loss 12.588821 on epoch=12
05/31/2022 06:15:18 - INFO - __main__ - Global step 50 Train loss 17.056515 Classification-F1 0.02088242088242088 on epoch=12
05/31/2022 06:15:24 - INFO - __main__ - Step 60 Global step 60 Train loss 8.951982 on epoch=14
05/31/2022 06:15:29 - INFO - __main__ - Step 70 Global step 70 Train loss 1.851012 on epoch=17
05/31/2022 06:15:34 - INFO - __main__ - Step 80 Global step 80 Train loss 0.809485 on epoch=19
05/31/2022 06:15:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.581056 on epoch=22
05/31/2022 06:15:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.419320 on epoch=24
05/31/2022 06:15:45 - INFO - __main__ - Global step 100 Train loss 2.522571 Classification-F1 0.39756367663344405 on epoch=24
05/31/2022 06:15:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.697285 on epoch=27
05/31/2022 06:15:58 - INFO - __main__ - Step 120 Global step 120 Train loss 0.434591 on epoch=29
05/31/2022 06:16:03 - INFO - __main__ - Step 130 Global step 130 Train loss 0.570008 on epoch=32
05/31/2022 06:16:08 - INFO - __main__ - Step 140 Global step 140 Train loss 0.450910 on epoch=34
05/31/2022 06:16:13 - INFO - __main__ - Step 150 Global step 150 Train loss 0.456685 on epoch=37
05/31/2022 06:16:13 - INFO - __main__ - Global step 150 Train loss 0.521896 Classification-F1 0.3333333333333333 on epoch=37
05/31/2022 06:16:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.532856 on epoch=39
05/31/2022 06:16:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.415241 on epoch=42
05/31/2022 06:16:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.347433 on epoch=44
05/31/2022 06:16:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.367879 on epoch=47
05/31/2022 06:16:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.412159 on epoch=49
05/31/2022 06:16:39 - INFO - __main__ - Global step 200 Train loss 0.415113 Classification-F1 0.3333333333333333 on epoch=49
05/31/2022 06:16:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.380445 on epoch=52
05/31/2022 06:16:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.339887 on epoch=54
05/31/2022 06:16:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.475767 on epoch=57
05/31/2022 06:16:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.385761 on epoch=59
05/31/2022 06:17:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.370873 on epoch=62
05/31/2022 06:17:05 - INFO - __main__ - Global step 250 Train loss 0.390547 Classification-F1 0.3591989987484355 on epoch=62
05/31/2022 06:17:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.438857 on epoch=64
05/31/2022 06:17:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.414217 on epoch=67
05/31/2022 06:17:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.391964 on epoch=69
05/31/2022 06:17:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.386126 on epoch=72
05/31/2022 06:17:30 - INFO - __main__ - Step 300 Global step 300 Train loss 0.282080 on epoch=74
05/31/2022 06:17:31 - INFO - __main__ - Global step 300 Train loss 0.382649 Classification-F1 0.32631578947368417 on epoch=74
05/31/2022 06:17:36 - INFO - __main__ - Step 310 Global step 310 Train loss 0.362203 on epoch=77
05/31/2022 06:17:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.428342 on epoch=79
05/31/2022 06:17:46 - INFO - __main__ - Step 330 Global step 330 Train loss 0.343223 on epoch=82
05/31/2022 06:17:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.290242 on epoch=84
05/31/2022 06:17:56 - INFO - __main__ - Step 350 Global step 350 Train loss 0.291685 on epoch=87
05/31/2022 06:17:57 - INFO - __main__ - Global step 350 Train loss 0.343139 Classification-F1 0.36374269005847953 on epoch=87
05/31/2022 06:18:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.240002 on epoch=89
05/31/2022 06:18:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.331164 on epoch=92
05/31/2022 06:18:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.248927 on epoch=94
05/31/2022 06:18:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.286629 on epoch=97
05/31/2022 06:18:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.181341 on epoch=99
05/31/2022 06:18:23 - INFO - __main__ - Global step 400 Train loss 0.257612 Classification-F1 0.3816425120772947 on epoch=99
05/31/2022 06:18:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.311314 on epoch=102
05/31/2022 06:18:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.153668 on epoch=104
05/31/2022 06:18:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.128261 on epoch=107
05/31/2022 06:18:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.125102 on epoch=109
05/31/2022 06:18:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.126914 on epoch=112
05/31/2022 06:18:48 - INFO - __main__ - Global step 450 Train loss 0.169052 Classification-F1 0.4231177094379639 on epoch=112
05/31/2022 06:18:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.100915 on epoch=114
05/31/2022 06:18:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.071764 on epoch=117
05/31/2022 06:19:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.052078 on epoch=119
05/31/2022 06:19:09 - INFO - __main__ - Step 490 Global step 490 Train loss 0.096464 on epoch=122
05/31/2022 06:19:14 - INFO - __main__ - Step 500 Global step 500 Train loss 0.035489 on epoch=124
05/31/2022 06:19:15 - INFO - __main__ - Global step 500 Train loss 0.071342 Classification-F1 0.51417004048583 on epoch=124
05/31/2022 06:19:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.049182 on epoch=127
05/31/2022 06:19:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.042388 on epoch=129
05/31/2022 06:19:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.060413 on epoch=132
05/31/2022 06:19:36 - INFO - __main__ - Step 540 Global step 540 Train loss 0.034645 on epoch=134
05/31/2022 06:19:41 - INFO - __main__ - Step 550 Global step 550 Train loss 0.037832 on epoch=137
05/31/2022 06:19:42 - INFO - __main__ - Global step 550 Train loss 0.044892 Classification-F1 0.3365811965811966 on epoch=137
05/31/2022 06:19:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.039354 on epoch=139
05/31/2022 06:19:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.021879 on epoch=142
05/31/2022 06:19:57 - INFO - __main__ - Step 580 Global step 580 Train loss 0.026365 on epoch=144
05/31/2022 06:20:02 - INFO - __main__ - Step 590 Global step 590 Train loss 0.087510 on epoch=147
05/31/2022 06:20:07 - INFO - __main__ - Step 600 Global step 600 Train loss 0.019891 on epoch=149
05/31/2022 06:20:07 - INFO - __main__ - Global step 600 Train loss 0.039000 Classification-F1 0.5076923076923077 on epoch=149
05/31/2022 06:20:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.014395 on epoch=152
05/31/2022 06:20:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.003951 on epoch=154
05/31/2022 06:20:22 - INFO - __main__ - Step 630 Global step 630 Train loss 0.014180 on epoch=157
05/31/2022 06:20:27 - INFO - __main__ - Step 640 Global step 640 Train loss 0.004084 on epoch=159
05/31/2022 06:20:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.004869 on epoch=162
05/31/2022 06:20:33 - INFO - __main__ - Global step 650 Train loss 0.008296 Classification-F1 0.5330817610062892 on epoch=162
05/31/2022 06:20:39 - INFO - __main__ - Step 660 Global step 660 Train loss 0.004149 on epoch=164
05/31/2022 06:20:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.005916 on epoch=167
05/31/2022 06:20:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.006861 on epoch=169
05/31/2022 06:20:54 - INFO - __main__ - Step 690 Global step 690 Train loss 0.008303 on epoch=172
05/31/2022 06:20:59 - INFO - __main__ - Step 700 Global step 700 Train loss 0.003868 on epoch=174
05/31/2022 06:21:00 - INFO - __main__ - Global step 700 Train loss 0.005819 Classification-F1 0.5155067155067155 on epoch=174
05/31/2022 06:21:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.005413 on epoch=177
05/31/2022 06:21:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.006785 on epoch=179
05/31/2022 06:21:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.006753 on epoch=182
05/31/2022 06:21:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.015820 on epoch=184
05/31/2022 06:21:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.002300 on epoch=187
05/31/2022 06:21:25 - INFO - __main__ - Global step 750 Train loss 0.007414 Classification-F1 0.5933528836754642 on epoch=187
05/31/2022 06:21:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.022885 on epoch=189
05/31/2022 06:21:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.007640 on epoch=192
05/31/2022 06:21:41 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003298 on epoch=194
05/31/2022 06:21:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000982 on epoch=197
05/31/2022 06:21:51 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000523 on epoch=199
05/31/2022 06:21:52 - INFO - __main__ - Global step 800 Train loss 0.007065 Classification-F1 0.6014943960149439 on epoch=199
05/31/2022 06:21:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002171 on epoch=202
05/31/2022 06:22:03 - INFO - __main__ - Step 820 Global step 820 Train loss 0.001522 on epoch=204
05/31/2022 06:22:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.020220 on epoch=207
05/31/2022 06:22:13 - INFO - __main__ - Step 840 Global step 840 Train loss 0.002027 on epoch=209
05/31/2022 06:22:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001395 on epoch=212
05/31/2022 06:22:19 - INFO - __main__ - Global step 850 Train loss 0.005467 Classification-F1 0.5458771715194519 on epoch=212
05/31/2022 06:22:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000795 on epoch=214
05/31/2022 06:22:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.007795 on epoch=217
05/31/2022 06:22:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000683 on epoch=219
05/31/2022 06:22:39 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000524 on epoch=222
05/31/2022 06:22:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001261 on epoch=224
05/31/2022 06:22:44 - INFO - __main__ - Global step 900 Train loss 0.002212 Classification-F1 0.6113360323886641 on epoch=224
05/31/2022 06:22:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.013979 on epoch=227
05/31/2022 06:22:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.012698 on epoch=229
05/31/2022 06:23:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001803 on epoch=232
05/31/2022 06:23:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.012374 on epoch=234
05/31/2022 06:23:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001941 on epoch=237
05/31/2022 06:23:11 - INFO - __main__ - Global step 950 Train loss 0.008559 Classification-F1 0.5249204665959704 on epoch=237
05/31/2022 06:23:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001000 on epoch=239
05/31/2022 06:23:21 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001326 on epoch=242
05/31/2022 06:23:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001693 on epoch=244
05/31/2022 06:23:31 - INFO - __main__ - Step 990 Global step 990 Train loss 0.004723 on epoch=247
05/31/2022 06:23:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000526 on epoch=249
05/31/2022 06:23:37 - INFO - __main__ - Global step 1000 Train loss 0.001853 Classification-F1 0.6362737830491723 on epoch=249
05/31/2022 06:23:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:23:38 - INFO - __main__ - Printing 3 examples
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:23:38 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:23:38 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:23:38 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:23:38 - INFO - __main__ - Printing 3 examples
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:23:38 - INFO - __main__ - ['false']
05/31/2022 06:23:38 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:23:38 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:23:38 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:23:38 - INFO - __main__ - save last model!
05/31/2022 06:23:45 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 06:23:46 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 06:23:46 - INFO - __main__ - Printing 3 examples
05/31/2022 06:23:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 06:23:46 - INFO - __main__ - ['false']
05/31/2022 06:23:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 06:23:46 - INFO - __main__ - ['false']
05/31/2022 06:23:46 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 06:23:46 - INFO - __main__ - ['false']
05/31/2022 06:23:46 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:23:47 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:23:50 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 06:23:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:23:50 - INFO - __main__ - Starting training!
05/31/2022 06:24:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_100_0.0005_8_predictions.txt
05/31/2022 06:24:18 - INFO - __main__ - Classification-F1 on test data: 0.1036
05/31/2022 06:24:19 - INFO - __main__ - prefix=wiki_qa_32_100, lr=0.0005, bsz=8, dev_performance=0.6362737830491723, test_performance=0.10359571294336797
05/31/2022 06:24:19 - INFO - __main__ - Running ... prefix=wiki_qa_32_100, lr=0.0003, bsz=8 ...
05/31/2022 06:24:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:24:20 - INFO - __main__ - Printing 3 examples
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:24:20 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:24:20 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:24:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:24:20 - INFO - __main__ - Printing 3 examples
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:24:20 - INFO - __main__ - ['false']
05/31/2022 06:24:20 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:24:20 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:24:20 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:24:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:24:32 - INFO - __main__ - Starting training!
05/31/2022 06:24:36 - INFO - __main__ - Step 10 Global step 10 Train loss 23.937248 on epoch=2
05/31/2022 06:24:41 - INFO - __main__ - Step 20 Global step 20 Train loss 17.999342 on epoch=4
05/31/2022 06:24:46 - INFO - __main__ - Step 30 Global step 30 Train loss 17.005688 on epoch=7
05/31/2022 06:24:51 - INFO - __main__ - Step 40 Global step 40 Train loss 16.335310 on epoch=9
05/31/2022 06:24:56 - INFO - __main__ - Step 50 Global step 50 Train loss 14.558864 on epoch=12
05/31/2022 06:24:57 - INFO - __main__ - Global step 50 Train loss 17.967293 Classification-F1 0.0 on epoch=12
05/31/2022 06:25:03 - INFO - __main__ - Step 60 Global step 60 Train loss 13.944899 on epoch=14
05/31/2022 06:25:08 - INFO - __main__ - Step 70 Global step 70 Train loss 12.132083 on epoch=17
05/31/2022 06:25:13 - INFO - __main__ - Step 80 Global step 80 Train loss 10.234933 on epoch=19
05/31/2022 06:25:18 - INFO - __main__ - Step 90 Global step 90 Train loss 1.528864 on epoch=22
05/31/2022 06:25:23 - INFO - __main__ - Step 100 Global step 100 Train loss 0.784757 on epoch=24
05/31/2022 06:25:23 - INFO - __main__ - Global step 100 Train loss 7.725107 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 06:25:29 - INFO - __main__ - Step 110 Global step 110 Train loss 0.888516 on epoch=27
05/31/2022 06:25:34 - INFO - __main__ - Step 120 Global step 120 Train loss 0.485691 on epoch=29
05/31/2022 06:25:39 - INFO - __main__ - Step 130 Global step 130 Train loss 0.873363 on epoch=32
05/31/2022 06:25:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.528136 on epoch=34
05/31/2022 06:25:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.389304 on epoch=37
05/31/2022 06:25:50 - INFO - __main__ - Global step 150 Train loss 0.633002 Classification-F1 0.3333333333333333 on epoch=37
05/31/2022 06:25:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.311054 on epoch=39
05/31/2022 06:26:00 - INFO - __main__ - Step 170 Global step 170 Train loss 0.458934 on epoch=42
05/31/2022 06:26:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.339034 on epoch=44
05/31/2022 06:26:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.365446 on epoch=47
05/31/2022 06:26:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.570212 on epoch=49
05/31/2022 06:26:17 - INFO - __main__ - Global step 200 Train loss 0.408936 Classification-F1 0.3333333333333333 on epoch=49
05/31/2022 06:26:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.460794 on epoch=52
05/31/2022 06:26:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.395430 on epoch=54
05/31/2022 06:26:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.396345 on epoch=57
05/31/2022 06:26:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.394149 on epoch=59
05/31/2022 06:26:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.418091 on epoch=62
05/31/2022 06:26:43 - INFO - __main__ - Global step 250 Train loss 0.412962 Classification-F1 0.3333333333333333 on epoch=62
05/31/2022 06:26:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.371377 on epoch=64
05/31/2022 06:26:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.364477 on epoch=67
05/31/2022 06:26:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.367944 on epoch=69
05/31/2022 06:27:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.399056 on epoch=72
05/31/2022 06:27:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.336060 on epoch=74
05/31/2022 06:27:09 - INFO - __main__ - Global step 300 Train loss 0.367783 Classification-F1 0.3333333333333333 on epoch=74
05/31/2022 06:27:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.394429 on epoch=77
05/31/2022 06:27:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.339009 on epoch=79
05/31/2022 06:27:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.388818 on epoch=82
05/31/2022 06:27:29 - INFO - __main__ - Step 340 Global step 340 Train loss 0.417985 on epoch=84
05/31/2022 06:27:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.436682 on epoch=87
05/31/2022 06:27:35 - INFO - __main__ - Global step 350 Train loss 0.395384 Classification-F1 0.3333333333333333 on epoch=87
05/31/2022 06:27:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.376741 on epoch=89
05/31/2022 06:27:45 - INFO - __main__ - Step 370 Global step 370 Train loss 0.372604 on epoch=92
05/31/2022 06:27:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.368723 on epoch=94
05/31/2022 06:27:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.338931 on epoch=97
05/31/2022 06:28:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.435709 on epoch=99
05/31/2022 06:28:01 - INFO - __main__ - Global step 400 Train loss 0.378542 Classification-F1 0.4748717948717949 on epoch=99
05/31/2022 06:28:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.334913 on epoch=102
05/31/2022 06:28:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.307313 on epoch=104
05/31/2022 06:28:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.426319 on epoch=107
05/31/2022 06:28:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.387642 on epoch=109
05/31/2022 06:28:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.448161 on epoch=112
05/31/2022 06:28:28 - INFO - __main__ - Global step 450 Train loss 0.380870 Classification-F1 0.3333333333333333 on epoch=112
05/31/2022 06:28:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.340792 on epoch=114
05/31/2022 06:28:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.341800 on epoch=117
05/31/2022 06:28:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.382645 on epoch=119
05/31/2022 06:28:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.353793 on epoch=122
05/31/2022 06:28:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.324934 on epoch=124
05/31/2022 06:28:54 - INFO - __main__ - Global step 500 Train loss 0.348793 Classification-F1 0.4589371980676329 on epoch=124
05/31/2022 06:28:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.386442 on epoch=127
05/31/2022 06:29:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.351431 on epoch=129
05/31/2022 06:29:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.332492 on epoch=132
05/31/2022 06:29:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.329443 on epoch=134
05/31/2022 06:29:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.302198 on epoch=137
05/31/2022 06:29:19 - INFO - __main__ - Global step 550 Train loss 0.340401 Classification-F1 0.3333333333333333 on epoch=137
05/31/2022 06:29:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.364890 on epoch=139
05/31/2022 06:29:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.429345 on epoch=142
05/31/2022 06:29:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.333808 on epoch=144
05/31/2022 06:29:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.278326 on epoch=147
05/31/2022 06:29:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.368386 on epoch=149
05/31/2022 06:29:46 - INFO - __main__ - Global step 600 Train loss 0.354951 Classification-F1 0.5270935960591133 on epoch=149
05/31/2022 06:29:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.330460 on epoch=152
05/31/2022 06:29:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.236151 on epoch=154
05/31/2022 06:30:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.270472 on epoch=157
05/31/2022 06:30:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.279015 on epoch=159
05/31/2022 06:30:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.236487 on epoch=162
05/31/2022 06:30:12 - INFO - __main__ - Global step 650 Train loss 0.270517 Classification-F1 0.503078982597055 on epoch=162
05/31/2022 06:30:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.212822 on epoch=164
05/31/2022 06:30:22 - INFO - __main__ - Step 670 Global step 670 Train loss 0.237450 on epoch=167
05/31/2022 06:30:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.241209 on epoch=169
05/31/2022 06:30:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.228792 on epoch=172
05/31/2022 06:30:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.184048 on epoch=174
05/31/2022 06:30:38 - INFO - __main__ - Global step 700 Train loss 0.220864 Classification-F1 0.38918345705196183 on epoch=174
05/31/2022 06:30:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.221920 on epoch=177
05/31/2022 06:30:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.181920 on epoch=179
05/31/2022 06:30:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.204701 on epoch=182
05/31/2022 06:30:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.226488 on epoch=184
05/31/2022 06:31:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.221698 on epoch=187
05/31/2022 06:31:04 - INFO - __main__ - Global step 750 Train loss 0.211345 Classification-F1 0.5373493975903615 on epoch=187
05/31/2022 06:31:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.087339 on epoch=189
05/31/2022 06:31:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.107398 on epoch=192
05/31/2022 06:31:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.109026 on epoch=194
05/31/2022 06:31:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.162967 on epoch=197
05/31/2022 06:31:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.131715 on epoch=199
05/31/2022 06:31:31 - INFO - __main__ - Global step 800 Train loss 0.119689 Classification-F1 0.5270935960591133 on epoch=199
05/31/2022 06:31:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.090866 on epoch=202
05/31/2022 06:31:41 - INFO - __main__ - Step 820 Global step 820 Train loss 0.045079 on epoch=204
05/31/2022 06:31:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.017617 on epoch=207
05/31/2022 06:31:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.020119 on epoch=209
05/31/2022 06:31:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.024605 on epoch=212
05/31/2022 06:31:57 - INFO - __main__ - Global step 850 Train loss 0.039657 Classification-F1 0.5238095238095238 on epoch=212
05/31/2022 06:32:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.028920 on epoch=214
05/31/2022 06:32:07 - INFO - __main__ - Step 870 Global step 870 Train loss 0.005004 on epoch=217
05/31/2022 06:32:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.022287 on epoch=219
05/31/2022 06:32:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.011522 on epoch=222
05/31/2022 06:32:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.041278 on epoch=224
05/31/2022 06:32:23 - INFO - __main__ - Global step 900 Train loss 0.021802 Classification-F1 0.4519207242476144 on epoch=224
05/31/2022 06:32:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.009723 on epoch=227
05/31/2022 06:32:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.004720 on epoch=229
05/31/2022 06:32:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.007894 on epoch=232
05/31/2022 06:32:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.008137 on epoch=234
05/31/2022 06:32:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.013824 on epoch=237
05/31/2022 06:32:48 - INFO - __main__ - Global step 950 Train loss 0.008860 Classification-F1 0.5515515515515517 on epoch=237
05/31/2022 06:32:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.008927 on epoch=239
05/31/2022 06:32:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.005178 on epoch=242
05/31/2022 06:33:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.023928 on epoch=244
05/31/2022 06:33:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.007860 on epoch=247
05/31/2022 06:33:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002882 on epoch=249
05/31/2022 06:33:15 - INFO - __main__ - Global step 1000 Train loss 0.009755 Classification-F1 0.436950146627566 on epoch=249
05/31/2022 06:33:15 - INFO - __main__ - save last model!
05/31/2022 06:33:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:33:15 - INFO - __main__ - Printing 3 examples
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:33:15 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:33:15 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:33:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:33:15 - INFO - __main__ - Printing 3 examples
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:33:15 - INFO - __main__ - ['false']
05/31/2022 06:33:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:33:15 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:33:16 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:33:22 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 06:33:23 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 06:33:23 - INFO - __main__ - Printing 3 examples
05/31/2022 06:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 06:33:23 - INFO - __main__ - ['false']
05/31/2022 06:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 06:33:23 - INFO - __main__ - ['false']
05/31/2022 06:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 06:33:23 - INFO - __main__ - ['false']
05/31/2022 06:33:23 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:33:24 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:33:27 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 06:33:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:33:27 - INFO - __main__ - Starting training!
05/31/2022 06:33:55 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_100_0.0003_8_predictions.txt
05/31/2022 06:33:55 - INFO - __main__ - Classification-F1 on test data: 0.3109
05/31/2022 06:33:55 - INFO - __main__ - prefix=wiki_qa_32_100, lr=0.0003, bsz=8, dev_performance=0.5515515515515517, test_performance=0.3109103349167155
05/31/2022 06:33:55 - INFO - __main__ - Running ... prefix=wiki_qa_32_100, lr=0.0002, bsz=8 ...
05/31/2022 06:33:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:33:56 - INFO - __main__ - Printing 3 examples
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:33:56 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:33:56 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:33:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:33:56 - INFO - __main__ - Printing 3 examples
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:33:56 - INFO - __main__ - ['false']
05/31/2022 06:33:56 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:33:56 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:33:56 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:34:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:34:08 - INFO - __main__ - Starting training!
05/31/2022 06:34:12 - INFO - __main__ - Step 10 Global step 10 Train loss 23.497862 on epoch=2
05/31/2022 06:34:17 - INFO - __main__ - Step 20 Global step 20 Train loss 19.447638 on epoch=4
05/31/2022 06:34:22 - INFO - __main__ - Step 30 Global step 30 Train loss 17.724186 on epoch=7
05/31/2022 06:34:28 - INFO - __main__ - Step 40 Global step 40 Train loss 16.774364 on epoch=9
05/31/2022 06:34:33 - INFO - __main__ - Step 50 Global step 50 Train loss 15.917035 on epoch=12
05/31/2022 06:34:43 - INFO - __main__ - Global step 50 Train loss 18.672216 Classification-F1 0.0 on epoch=12
05/31/2022 06:34:49 - INFO - __main__ - Step 60 Global step 60 Train loss 15.227740 on epoch=14
05/31/2022 06:34:54 - INFO - __main__ - Step 70 Global step 70 Train loss 14.134439 on epoch=17
05/31/2022 06:34:59 - INFO - __main__ - Step 80 Global step 80 Train loss 13.267400 on epoch=19
05/31/2022 06:35:04 - INFO - __main__ - Step 90 Global step 90 Train loss 11.258261 on epoch=22
05/31/2022 06:35:09 - INFO - __main__ - Step 100 Global step 100 Train loss 3.840793 on epoch=24
05/31/2022 06:35:09 - INFO - __main__ - Global step 100 Train loss 11.545727 Classification-F1 0.41075141075141075 on epoch=24
05/31/2022 06:35:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.653276 on epoch=27
05/31/2022 06:35:20 - INFO - __main__ - Step 120 Global step 120 Train loss 0.682711 on epoch=29
05/31/2022 06:35:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.421935 on epoch=32
05/31/2022 06:35:30 - INFO - __main__ - Step 140 Global step 140 Train loss 0.391386 on epoch=34
05/31/2022 06:35:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.377164 on epoch=37
05/31/2022 06:35:36 - INFO - __main__ - Global step 150 Train loss 0.505294 Classification-F1 0.5273745861981156 on epoch=37
05/31/2022 06:35:41 - INFO - __main__ - Step 160 Global step 160 Train loss 0.390190 on epoch=39
05/31/2022 06:35:46 - INFO - __main__ - Step 170 Global step 170 Train loss 0.298760 on epoch=42
05/31/2022 06:35:51 - INFO - __main__ - Step 180 Global step 180 Train loss 0.420542 on epoch=44
05/31/2022 06:35:56 - INFO - __main__ - Step 190 Global step 190 Train loss 0.307139 on epoch=47
05/31/2022 06:36:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.164417 on epoch=49
05/31/2022 06:36:02 - INFO - __main__ - Global step 200 Train loss 0.316209 Classification-F1 0.32631578947368417 on epoch=49
05/31/2022 06:36:07 - INFO - __main__ - Step 210 Global step 210 Train loss 0.151632 on epoch=52
05/31/2022 06:36:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.164314 on epoch=54
05/31/2022 06:36:17 - INFO - __main__ - Step 230 Global step 230 Train loss 0.098122 on epoch=57
05/31/2022 06:36:22 - INFO - __main__ - Step 240 Global step 240 Train loss 0.087335 on epoch=59
05/31/2022 06:36:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.123411 on epoch=62
05/31/2022 06:36:28 - INFO - __main__ - Global step 250 Train loss 0.124963 Classification-F1 0.5666666666666667 on epoch=62
05/31/2022 06:36:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.072749 on epoch=64
05/31/2022 06:36:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.021015 on epoch=67
05/31/2022 06:36:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.024749 on epoch=69
05/31/2022 06:36:48 - INFO - __main__ - Step 290 Global step 290 Train loss 0.012589 on epoch=72
05/31/2022 06:36:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.007271 on epoch=74
05/31/2022 06:36:54 - INFO - __main__ - Global step 300 Train loss 0.027675 Classification-F1 0.5927889713679746 on epoch=74
05/31/2022 06:37:00 - INFO - __main__ - Step 310 Global step 310 Train loss 0.009856 on epoch=77
05/31/2022 06:37:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.008077 on epoch=79
05/31/2022 06:37:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.007541 on epoch=82
05/31/2022 06:37:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.006188 on epoch=84
05/31/2022 06:37:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.012564 on epoch=87
05/31/2022 06:37:21 - INFO - __main__ - Global step 350 Train loss 0.008845 Classification-F1 0.4867834867834868 on epoch=87
05/31/2022 06:37:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.004033 on epoch=89
05/31/2022 06:37:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.002971 on epoch=92
05/31/2022 06:37:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.004241 on epoch=94
05/31/2022 06:37:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.004602 on epoch=97
05/31/2022 06:37:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.000903 on epoch=99
05/31/2022 06:37:47 - INFO - __main__ - Global step 400 Train loss 0.003350 Classification-F1 0.5021607605877269 on epoch=99
05/31/2022 06:37:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000572 on epoch=102
05/31/2022 06:37:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.001373 on epoch=104
05/31/2022 06:38:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.000575 on epoch=107
05/31/2022 06:38:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.000478 on epoch=109
05/31/2022 06:38:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.001314 on epoch=112
05/31/2022 06:38:12 - INFO - __main__ - Global step 450 Train loss 0.000862 Classification-F1 0.4867834867834868 on epoch=112
05/31/2022 06:38:17 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000557 on epoch=114
05/31/2022 06:38:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.005891 on epoch=117
05/31/2022 06:38:27 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000570 on epoch=119
05/31/2022 06:38:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000845 on epoch=122
05/31/2022 06:38:37 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000358 on epoch=124
05/31/2022 06:38:38 - INFO - __main__ - Global step 500 Train loss 0.001644 Classification-F1 0.5622435020519836 on epoch=124
05/31/2022 06:38:43 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000056 on epoch=127
05/31/2022 06:38:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000777 on epoch=129
05/31/2022 06:38:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.001022 on epoch=132
05/31/2022 06:38:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.001781 on epoch=134
05/31/2022 06:39:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000677 on epoch=137
05/31/2022 06:39:04 - INFO - __main__ - Global step 550 Train loss 0.000862 Classification-F1 0.6333333333333333 on epoch=137
05/31/2022 06:39:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000737 on epoch=139
05/31/2022 06:39:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000103 on epoch=142
05/31/2022 06:39:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000551 on epoch=144
05/31/2022 06:39:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000486 on epoch=147
05/31/2022 06:39:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000115 on epoch=149
05/31/2022 06:39:31 - INFO - __main__ - Global step 600 Train loss 0.000398 Classification-F1 0.6389743589743591 on epoch=149
05/31/2022 06:39:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000134 on epoch=152
05/31/2022 06:39:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000155 on epoch=154
05/31/2022 06:39:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000044 on epoch=157
05/31/2022 06:39:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000289 on epoch=159
05/31/2022 06:39:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000656 on epoch=162
05/31/2022 06:39:57 - INFO - __main__ - Global step 650 Train loss 0.000255 Classification-F1 0.5972640218878249 on epoch=162
05/31/2022 06:40:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000053 on epoch=164
05/31/2022 06:40:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000258 on epoch=167
05/31/2022 06:40:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000836 on epoch=169
05/31/2022 06:40:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000091 on epoch=172
05/31/2022 06:40:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000084 on epoch=174
05/31/2022 06:40:23 - INFO - __main__ - Global step 700 Train loss 0.000264 Classification-F1 0.4867834867834868 on epoch=174
05/31/2022 06:40:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000157 on epoch=177
05/31/2022 06:40:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000277 on epoch=179
05/31/2022 06:40:38 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000012 on epoch=182
05/31/2022 06:40:43 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000032 on epoch=184
05/31/2022 06:40:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000020 on epoch=187
05/31/2022 06:40:49 - INFO - __main__ - Global step 750 Train loss 0.000100 Classification-F1 0.5021607605877269 on epoch=187
05/31/2022 06:40:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000018 on epoch=189
05/31/2022 06:40:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000455 on epoch=192
05/31/2022 06:41:04 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000025 on epoch=194
05/31/2022 06:41:09 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000091 on epoch=197
05/31/2022 06:41:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.010706 on epoch=199
05/31/2022 06:41:14 - INFO - __main__ - Global step 800 Train loss 0.002259 Classification-F1 0.4867834867834868 on epoch=199
05/31/2022 06:41:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000503 on epoch=202
05/31/2022 06:41:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000351 on epoch=204
05/31/2022 06:41:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000506 on epoch=207
05/31/2022 06:41:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000102 on epoch=209
05/31/2022 06:41:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000397 on epoch=212
05/31/2022 06:41:40 - INFO - __main__ - Global step 850 Train loss 0.000372 Classification-F1 0.5844155844155844 on epoch=212
05/31/2022 06:41:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000061 on epoch=214
05/31/2022 06:41:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000167 on epoch=217
05/31/2022 06:41:56 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000024 on epoch=219
05/31/2022 06:42:01 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000223 on epoch=222
05/31/2022 06:42:06 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000023 on epoch=224
05/31/2022 06:42:06 - INFO - __main__ - Global step 900 Train loss 0.000099 Classification-F1 0.6437246963562753 on epoch=224
05/31/2022 06:42:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000052 on epoch=227
05/31/2022 06:42:17 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000020 on epoch=229
05/31/2022 06:42:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000015 on epoch=232
05/31/2022 06:42:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000021 on epoch=234
05/31/2022 06:42:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000026 on epoch=237
05/31/2022 06:42:33 - INFO - __main__ - Global step 950 Train loss 0.000027 Classification-F1 0.6437246963562753 on epoch=237
05/31/2022 06:42:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000025 on epoch=239
05/31/2022 06:42:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000015 on epoch=242
05/31/2022 06:42:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000029 on epoch=244
05/31/2022 06:42:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000039 on epoch=247
05/31/2022 06:42:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000048 on epoch=249
05/31/2022 06:42:59 - INFO - __main__ - Global step 1000 Train loss 0.000031 Classification-F1 0.6577540106951872 on epoch=249
05/31/2022 06:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:43:00 - INFO - __main__ - Printing 3 examples
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:43:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:43:00 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:43:00 - INFO - __main__ - Printing 3 examples
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:43:00 - INFO - __main__ - ['false']
05/31/2022 06:43:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:43:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:43:00 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:43:00 - INFO - __main__ - save last model!
05/31/2022 06:43:07 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 06:43:07 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 06:43:07 - INFO - __main__ - Printing 3 examples
05/31/2022 06:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 06:43:07 - INFO - __main__ - ['false']
05/31/2022 06:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 06:43:07 - INFO - __main__ - ['false']
05/31/2022 06:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 06:43:07 - INFO - __main__ - ['false']
05/31/2022 06:43:07 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:43:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:43:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:43:11 - INFO - __main__ - Starting training!
05/31/2022 06:43:11 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 06:43:40 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_100_0.0002_8_predictions.txt
05/31/2022 06:43:40 - INFO - __main__ - Classification-F1 on test data: 0.4090
05/31/2022 06:43:41 - INFO - __main__ - prefix=wiki_qa_32_100, lr=0.0002, bsz=8, dev_performance=0.6577540106951872, test_performance=0.409033632484214
05/31/2022 06:43:41 - INFO - __main__ - Running ... prefix=wiki_qa_32_100, lr=0.0001, bsz=8 ...
05/31/2022 06:43:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:43:41 - INFO - __main__ - Printing 3 examples
05/31/2022 06:43:41 - INFO - __main__ -  [wiki_qa] question: what version minecraft free [SEP] answer: Minecraft is a sandbox indie game originally created by Swedish programmer Markus "Notch" Persson and later developed and published by Mojang .
05/31/2022 06:43:41 - INFO - __main__ - ['false']
05/31/2022 06:43:41 - INFO - __main__ -  [wiki_qa] question: what year did the beatles came out with the song i wanna hold your hand [SEP] answer: It was also the group's first American number one, entering the Billboard Hot 100 chart on 18 January 1964 at number forty-five and starting the British invasion of the American music industry.
05/31/2022 06:43:41 - INFO - __main__ - ['false']
05/31/2022 06:43:41 - INFO - __main__ -  [wiki_qa] question: what is Roxio DLA [SEP] answer: As a replacement for DLA, it remedies compatibility issues Internet Explorer 8 .
05/31/2022 06:43:41 - INFO - __main__ - ['false']
05/31/2022 06:43:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:43:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:43:42 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:43:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:43:42 - INFO - __main__ - Printing 3 examples
05/31/2022 06:43:42 - INFO - __main__ -  [wiki_qa] question: What is June known for? [SEP] answer: June in the Northern Hemisphere is the seasonal equivalent to December in the Southern Hemisphere and vice versa.
05/31/2022 06:43:42 - INFO - __main__ - ['false']
05/31/2022 06:43:42 - INFO - __main__ -  [wiki_qa] question: what not to say to eating disorder [SEP] answer: One study showed that girls with ADHD have a greater chance of getting an eating disorder than those not affected by ADHD.
05/31/2022 06:43:42 - INFO - __main__ - ['false']
05/31/2022 06:43:42 - INFO - __main__ -  [wiki_qa] question: how much money does steve jobs make a year [SEP] answer: Jobs brought Apple from near bankruptcy to profitability by 1998.
05/31/2022 06:43:42 - INFO - __main__ - ['false']
05/31/2022 06:43:42 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:43:42 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:43:42 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:43:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:43:54 - INFO - __main__ - Starting training!
05/31/2022 06:43:58 - INFO - __main__ - Step 10 Global step 10 Train loss 23.413815 on epoch=2
05/31/2022 06:44:03 - INFO - __main__ - Step 20 Global step 20 Train loss 19.930325 on epoch=4
05/31/2022 06:44:08 - INFO - __main__ - Step 30 Global step 30 Train loss 18.721134 on epoch=7
05/31/2022 06:44:13 - INFO - __main__ - Step 40 Global step 40 Train loss 17.157759 on epoch=9
05/31/2022 06:44:18 - INFO - __main__ - Step 50 Global step 50 Train loss 18.018534 on epoch=12
05/31/2022 06:44:32 - INFO - __main__ - Global step 50 Train loss 19.448315 Classification-F1 0.0 on epoch=12
05/31/2022 06:44:37 - INFO - __main__ - Step 60 Global step 60 Train loss 18.103785 on epoch=14
05/31/2022 06:44:42 - INFO - __main__ - Step 70 Global step 70 Train loss 17.245121 on epoch=17
05/31/2022 06:44:47 - INFO - __main__ - Step 80 Global step 80 Train loss 16.304136 on epoch=19
05/31/2022 06:44:52 - INFO - __main__ - Step 90 Global step 90 Train loss 15.741681 on epoch=22
05/31/2022 06:44:57 - INFO - __main__ - Step 100 Global step 100 Train loss 15.907288 on epoch=24
05/31/2022 06:45:05 - INFO - __main__ - Global step 100 Train loss 16.660402 Classification-F1 0.0 on epoch=24
05/31/2022 06:45:10 - INFO - __main__ - Step 110 Global step 110 Train loss 15.088816 on epoch=27
05/31/2022 06:45:15 - INFO - __main__ - Step 120 Global step 120 Train loss 14.949007 on epoch=29
05/31/2022 06:45:20 - INFO - __main__ - Step 130 Global step 130 Train loss 14.134218 on epoch=32
05/31/2022 06:45:25 - INFO - __main__ - Step 140 Global step 140 Train loss 13.923245 on epoch=34
05/31/2022 06:45:30 - INFO - __main__ - Step 150 Global step 150 Train loss 13.268860 on epoch=37
05/31/2022 06:45:33 - INFO - __main__ - Global step 150 Train loss 14.272830 Classification-F1 0.0 on epoch=37
05/31/2022 06:45:38 - INFO - __main__ - Step 160 Global step 160 Train loss 13.159223 on epoch=39
05/31/2022 06:45:43 - INFO - __main__ - Step 170 Global step 170 Train loss 12.705019 on epoch=42
05/31/2022 06:45:48 - INFO - __main__ - Step 180 Global step 180 Train loss 12.047994 on epoch=44
05/31/2022 06:45:53 - INFO - __main__ - Step 190 Global step 190 Train loss 11.477697 on epoch=47
05/31/2022 06:45:58 - INFO - __main__ - Step 200 Global step 200 Train loss 9.140158 on epoch=49
05/31/2022 06:46:00 - INFO - __main__ - Global step 200 Train loss 11.706018 Classification-F1 0.023391812865497078 on epoch=49
05/31/2022 06:46:05 - INFO - __main__ - Step 210 Global step 210 Train loss 2.634429 on epoch=52
05/31/2022 06:46:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.818190 on epoch=54
05/31/2022 06:46:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.704999 on epoch=57
05/31/2022 06:46:20 - INFO - __main__ - Step 240 Global step 240 Train loss 0.757492 on epoch=59
05/31/2022 06:46:25 - INFO - __main__ - Step 250 Global step 250 Train loss 0.753573 on epoch=62
05/31/2022 06:46:26 - INFO - __main__ - Global step 250 Train loss 1.133737 Classification-F1 0.503078982597055 on epoch=62
05/31/2022 06:46:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.734816 on epoch=64
05/31/2022 06:46:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.500642 on epoch=67
05/31/2022 06:46:41 - INFO - __main__ - Step 280 Global step 280 Train loss 0.578293 on epoch=69
05/31/2022 06:46:47 - INFO - __main__ - Step 290 Global step 290 Train loss 0.418624 on epoch=72
05/31/2022 06:46:52 - INFO - __main__ - Step 300 Global step 300 Train loss 0.413133 on epoch=74
05/31/2022 06:46:52 - INFO - __main__ - Global step 300 Train loss 0.529101 Classification-F1 0.3333333333333333 on epoch=74
05/31/2022 06:46:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.383903 on epoch=77
05/31/2022 06:47:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.595378 on epoch=79
05/31/2022 06:47:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.431601 on epoch=82
05/31/2022 06:47:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.322502 on epoch=84
05/31/2022 06:47:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.365230 on epoch=87
05/31/2022 06:47:18 - INFO - __main__ - Global step 350 Train loss 0.419723 Classification-F1 0.4796747967479674 on epoch=87
05/31/2022 06:47:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.329866 on epoch=89
05/31/2022 06:47:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.410651 on epoch=92
05/31/2022 06:47:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.291850 on epoch=94
05/31/2022 06:47:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.316017 on epoch=97
05/31/2022 06:47:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.329829 on epoch=99
05/31/2022 06:47:44 - INFO - __main__ - Global step 400 Train loss 0.335643 Classification-F1 0.3671451355661882 on epoch=99
05/31/2022 06:47:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.253373 on epoch=102
05/31/2022 06:47:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.211532 on epoch=104
05/31/2022 06:47:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.162932 on epoch=107
05/31/2022 06:48:04 - INFO - __main__ - Step 440 Global step 440 Train loss 0.165166 on epoch=109
05/31/2022 06:48:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.179240 on epoch=112
05/31/2022 06:48:09 - INFO - __main__ - Global step 450 Train loss 0.194448 Classification-F1 0.5780219780219781 on epoch=112
05/31/2022 06:48:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.176205 on epoch=114
05/31/2022 06:48:20 - INFO - __main__ - Step 470 Global step 470 Train loss 0.132340 on epoch=117
05/31/2022 06:48:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.102622 on epoch=119
05/31/2022 06:48:30 - INFO - __main__ - Step 490 Global step 490 Train loss 0.127377 on epoch=122
05/31/2022 06:48:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.130064 on epoch=124
05/31/2022 06:48:36 - INFO - __main__ - Global step 500 Train loss 0.133722 Classification-F1 0.551443790299972 on epoch=124
05/31/2022 06:48:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.055437 on epoch=127
05/31/2022 06:48:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.077948 on epoch=129
05/31/2022 06:48:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.058410 on epoch=132
05/31/2022 06:48:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.069572 on epoch=134
05/31/2022 06:49:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.083601 on epoch=137
05/31/2022 06:49:02 - INFO - __main__ - Global step 550 Train loss 0.068993 Classification-F1 0.5458771715194519 on epoch=137
05/31/2022 06:49:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.059826 on epoch=139
05/31/2022 06:49:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.042687 on epoch=142
05/31/2022 06:49:17 - INFO - __main__ - Step 580 Global step 580 Train loss 0.103572 on epoch=144
05/31/2022 06:49:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.023896 on epoch=147
05/31/2022 06:49:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.021959 on epoch=149
05/31/2022 06:49:28 - INFO - __main__ - Global step 600 Train loss 0.050388 Classification-F1 0.5465587044534412 on epoch=149
05/31/2022 06:49:33 - INFO - __main__ - Step 610 Global step 610 Train loss 0.038720 on epoch=152
05/31/2022 06:49:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.024958 on epoch=154
05/31/2022 06:49:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.094816 on epoch=157
05/31/2022 06:49:48 - INFO - __main__ - Step 640 Global step 640 Train loss 0.042797 on epoch=159
05/31/2022 06:49:53 - INFO - __main__ - Step 650 Global step 650 Train loss 0.053820 on epoch=162
05/31/2022 06:49:53 - INFO - __main__ - Global step 650 Train loss 0.051022 Classification-F1 0.5652830188679245 on epoch=162
05/31/2022 06:49:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.076109 on epoch=164
05/31/2022 06:50:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.051104 on epoch=167
05/31/2022 06:50:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.020476 on epoch=169
05/31/2022 06:50:13 - INFO - __main__ - Step 690 Global step 690 Train loss 0.055023 on epoch=172
05/31/2022 06:50:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.191705 on epoch=174
05/31/2022 06:50:19 - INFO - __main__ - Global step 700 Train loss 0.078883 Classification-F1 0.5873015873015872 on epoch=174
05/31/2022 06:50:25 - INFO - __main__ - Step 710 Global step 710 Train loss 0.067841 on epoch=177
05/31/2022 06:50:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.036305 on epoch=179
05/31/2022 06:50:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.048884 on epoch=182
05/31/2022 06:50:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.465847 on epoch=184
05/31/2022 06:50:45 - INFO - __main__ - Step 750 Global step 750 Train loss 0.269100 on epoch=187
05/31/2022 06:50:45 - INFO - __main__ - Global step 750 Train loss 0.177595 Classification-F1 0.6113360323886641 on epoch=187
05/31/2022 06:50:51 - INFO - __main__ - Step 760 Global step 760 Train loss 0.298446 on epoch=189
05/31/2022 06:50:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.102717 on epoch=192
05/31/2022 06:51:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.125391 on epoch=194
05/31/2022 06:51:06 - INFO - __main__ - Step 790 Global step 790 Train loss 0.133869 on epoch=197
05/31/2022 06:51:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.108731 on epoch=199
05/31/2022 06:51:12 - INFO - __main__ - Global step 800 Train loss 0.153831 Classification-F1 0.6046454163577959 on epoch=199
05/31/2022 06:51:17 - INFO - __main__ - Step 810 Global step 810 Train loss 0.080128 on epoch=202
05/31/2022 06:51:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.018023 on epoch=204
05/31/2022 06:51:27 - INFO - __main__ - Step 830 Global step 830 Train loss 0.016505 on epoch=207
05/31/2022 06:51:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.051697 on epoch=209
05/31/2022 06:51:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.047783 on epoch=212
05/31/2022 06:51:37 - INFO - __main__ - Global step 850 Train loss 0.042827 Classification-F1 0.6190476190476191 on epoch=212
05/31/2022 06:51:43 - INFO - __main__ - Step 860 Global step 860 Train loss 0.014381 on epoch=214
05/31/2022 06:51:48 - INFO - __main__ - Step 870 Global step 870 Train loss 0.031651 on epoch=217
05/31/2022 06:51:53 - INFO - __main__ - Step 880 Global step 880 Train loss 0.033579 on epoch=219
05/31/2022 06:51:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.007222 on epoch=222
05/31/2022 06:52:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.025492 on epoch=224
05/31/2022 06:52:04 - INFO - __main__ - Global step 900 Train loss 0.022465 Classification-F1 0.6235294117647059 on epoch=224
05/31/2022 06:52:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.018469 on epoch=227
05/31/2022 06:52:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.011428 on epoch=229
05/31/2022 06:52:19 - INFO - __main__ - Step 930 Global step 930 Train loss 0.006307 on epoch=232
05/31/2022 06:52:24 - INFO - __main__ - Step 940 Global step 940 Train loss 0.006515 on epoch=234
05/31/2022 06:52:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.037713 on epoch=237
05/31/2022 06:52:30 - INFO - __main__ - Global step 950 Train loss 0.016087 Classification-F1 0.5835835835835835 on epoch=237
05/31/2022 06:52:35 - INFO - __main__ - Step 960 Global step 960 Train loss 0.006806 on epoch=239
05/31/2022 06:52:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.013516 on epoch=242
05/31/2022 06:52:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.045750 on epoch=244
05/31/2022 06:52:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.002593 on epoch=247
05/31/2022 06:52:55 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.021158 on epoch=249
05/31/2022 06:52:56 - INFO - __main__ - Global step 1000 Train loss 0.017965 Classification-F1 0.6014943960149439 on epoch=249
05/31/2022 06:52:56 - INFO - __main__ - save last model!
05/31/2022 06:52:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:52:56 - INFO - __main__ - Printing 3 examples
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:52:56 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:52:56 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:52:56 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:52:56 - INFO - __main__ - Printing 3 examples
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 06:52:56 - INFO - __main__ - ['false']
05/31/2022 06:52:56 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:52:56 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:52:56 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:53:02 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 06:53:03 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 06:53:03 - INFO - __main__ - Printing 3 examples
05/31/2022 06:53:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 06:53:03 - INFO - __main__ - ['false']
05/31/2022 06:53:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 06:53:03 - INFO - __main__ - ['false']
05/31/2022 06:53:03 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 06:53:03 - INFO - __main__ - ['false']
05/31/2022 06:53:03 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:53:05 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:53:07 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 06:53:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:53:09 - INFO - __main__ - Starting training!
05/31/2022 06:53:35 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_100_0.0001_8_predictions.txt
05/31/2022 06:53:35 - INFO - __main__ - Classification-F1 on test data: 0.4389
05/31/2022 06:53:36 - INFO - __main__ - prefix=wiki_qa_32_100, lr=0.0001, bsz=8, dev_performance=0.6235294117647059, test_performance=0.4389149287865408
05/31/2022 06:53:36 - INFO - __main__ - Running ... prefix=wiki_qa_32_13, lr=0.0005, bsz=8 ...
05/31/2022 06:53:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:53:37 - INFO - __main__ - Printing 3 examples
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:53:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:53:37 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 06:53:37 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 06:53:37 - INFO - __main__ - Printing 3 examples
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 06:53:37 - INFO - __main__ - ['false']
05/31/2022 06:53:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 06:53:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 06:53:37 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 06:53:48 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 06:53:49 - INFO - __main__ - Starting training!
05/31/2022 06:53:53 - INFO - __main__ - Step 10 Global step 10 Train loss 22.892452 on epoch=2
05/31/2022 06:53:58 - INFO - __main__ - Step 20 Global step 20 Train loss 17.542013 on epoch=4
05/31/2022 06:54:03 - INFO - __main__ - Step 30 Global step 30 Train loss 17.120739 on epoch=7
05/31/2022 06:54:09 - INFO - __main__ - Step 40 Global step 40 Train loss 15.604555 on epoch=9
05/31/2022 06:54:14 - INFO - __main__ - Step 50 Global step 50 Train loss 12.842824 on epoch=12
05/31/2022 06:54:29 - INFO - __main__ - Global step 50 Train loss 17.200518 Classification-F1 0.005420054200542005 on epoch=12
05/31/2022 06:54:34 - INFO - __main__ - Step 60 Global step 60 Train loss 7.286824 on epoch=14
05/31/2022 06:54:39 - INFO - __main__ - Step 70 Global step 70 Train loss 2.632205 on epoch=17
05/31/2022 06:54:45 - INFO - __main__ - Step 80 Global step 80 Train loss 3.682602 on epoch=19
05/31/2022 06:54:50 - INFO - __main__ - Step 90 Global step 90 Train loss 2.686131 on epoch=22
05/31/2022 06:54:56 - INFO - __main__ - Step 100 Global step 100 Train loss 2.306537 on epoch=24
05/31/2022 06:54:56 - INFO - __main__ - Global step 100 Train loss 3.718859 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 06:55:02 - INFO - __main__ - Step 110 Global step 110 Train loss 2.649090 on epoch=27
05/31/2022 06:55:08 - INFO - __main__ - Step 120 Global step 120 Train loss 1.850326 on epoch=29
05/31/2022 06:55:13 - INFO - __main__ - Step 130 Global step 130 Train loss 1.094490 on epoch=32
05/31/2022 06:55:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.533338 on epoch=34
05/31/2022 06:55:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.415975 on epoch=37
05/31/2022 06:55:24 - INFO - __main__ - Global step 150 Train loss 1.308644 Classification-F1 0.3333333333333333 on epoch=37
05/31/2022 06:55:30 - INFO - __main__ - Step 160 Global step 160 Train loss 0.555809 on epoch=39
05/31/2022 06:55:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.357746 on epoch=42
05/31/2022 06:55:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.381406 on epoch=44
05/31/2022 06:55:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.411157 on epoch=47
05/31/2022 06:55:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.422168 on epoch=49
05/31/2022 06:55:52 - INFO - __main__ - Global step 200 Train loss 0.425657 Classification-F1 0.3333333333333333 on epoch=49
05/31/2022 06:55:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.426453 on epoch=52
05/31/2022 06:56:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.426702 on epoch=54
05/31/2022 06:56:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.430128 on epoch=57
05/31/2022 06:56:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.376385 on epoch=59
05/31/2022 06:56:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.476143 on epoch=62
05/31/2022 06:56:19 - INFO - __main__ - Global step 250 Train loss 0.427162 Classification-F1 0.3333333333333333 on epoch=62
05/31/2022 06:56:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.463233 on epoch=64
05/31/2022 06:56:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.387616 on epoch=67
05/31/2022 06:56:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.381135 on epoch=69
05/31/2022 06:56:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.380429 on epoch=72
05/31/2022 06:56:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.380882 on epoch=74
05/31/2022 06:56:46 - INFO - __main__ - Global step 300 Train loss 0.398659 Classification-F1 0.3333333333333333 on epoch=74
05/31/2022 06:56:51 - INFO - __main__ - Step 310 Global step 310 Train loss 0.485506 on epoch=77
05/31/2022 06:56:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.354354 on epoch=79
05/31/2022 06:57:01 - INFO - __main__ - Step 330 Global step 330 Train loss 0.383427 on epoch=82
05/31/2022 06:57:07 - INFO - __main__ - Step 340 Global step 340 Train loss 0.496667 on epoch=84
05/31/2022 06:57:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.395584 on epoch=87
05/31/2022 06:57:13 - INFO - __main__ - Global step 350 Train loss 0.423108 Classification-F1 0.3591989987484355 on epoch=87
05/31/2022 06:57:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.377014 on epoch=89
05/31/2022 06:57:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.453499 on epoch=92
05/31/2022 06:57:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.387627 on epoch=94
05/31/2022 06:57:34 - INFO - __main__ - Step 390 Global step 390 Train loss 0.404738 on epoch=97
05/31/2022 06:57:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.425191 on epoch=99
05/31/2022 06:57:40 - INFO - __main__ - Global step 400 Train loss 0.409614 Classification-F1 0.3191489361702127 on epoch=99
05/31/2022 06:57:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.358923 on epoch=102
05/31/2022 06:57:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.380729 on epoch=104
05/31/2022 06:57:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.338762 on epoch=107
05/31/2022 06:58:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.366501 on epoch=109
05/31/2022 06:58:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.402323 on epoch=112
05/31/2022 06:58:08 - INFO - __main__ - Global step 450 Train loss 0.369448 Classification-F1 0.32631578947368417 on epoch=112
05/31/2022 06:58:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.388727 on epoch=114
05/31/2022 06:58:18 - INFO - __main__ - Step 470 Global step 470 Train loss 0.357949 on epoch=117
05/31/2022 06:58:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.396547 on epoch=119
05/31/2022 06:58:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.314775 on epoch=122
05/31/2022 06:58:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.336945 on epoch=124
05/31/2022 06:58:35 - INFO - __main__ - Global step 500 Train loss 0.358988 Classification-F1 0.36374269005847953 on epoch=124
05/31/2022 06:58:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.372160 on epoch=127
05/31/2022 06:58:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.450310 on epoch=129
05/31/2022 06:58:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.310028 on epoch=132
05/31/2022 06:58:56 - INFO - __main__ - Step 540 Global step 540 Train loss 0.271339 on epoch=134
05/31/2022 06:59:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.334069 on epoch=137
05/31/2022 06:59:02 - INFO - __main__ - Global step 550 Train loss 0.347581 Classification-F1 0.4545454545454546 on epoch=137
05/31/2022 06:59:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.308909 on epoch=139
05/31/2022 06:59:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.257965 on epoch=142
05/31/2022 06:59:19 - INFO - __main__ - Step 580 Global step 580 Train loss 1.832214 on epoch=144
05/31/2022 06:59:24 - INFO - __main__ - Step 590 Global step 590 Train loss 1.846651 on epoch=147
05/31/2022 06:59:30 - INFO - __main__ - Step 600 Global step 600 Train loss 1.390702 on epoch=149
05/31/2022 06:59:30 - INFO - __main__ - Global step 600 Train loss 1.127288 Classification-F1 0.3333333333333333 on epoch=149
05/31/2022 06:59:35 - INFO - __main__ - Step 610 Global step 610 Train loss 1.299359 on epoch=152
05/31/2022 06:59:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.950057 on epoch=154
05/31/2022 06:59:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.796232 on epoch=157
05/31/2022 06:59:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.888163 on epoch=159
05/31/2022 06:59:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.436419 on epoch=162
05/31/2022 06:59:57 - INFO - __main__ - Global step 650 Train loss 0.874046 Classification-F1 0.3333333333333333 on epoch=162
05/31/2022 07:00:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.545605 on epoch=164
05/31/2022 07:00:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.496556 on epoch=167
05/31/2022 07:00:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.463744 on epoch=169
05/31/2022 07:00:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.485758 on epoch=172
05/31/2022 07:00:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.467067 on epoch=174
05/31/2022 07:00:24 - INFO - __main__ - Global step 700 Train loss 0.491746 Classification-F1 0.3333333333333333 on epoch=174
05/31/2022 07:00:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.411590 on epoch=177
05/31/2022 07:00:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.406231 on epoch=179
05/31/2022 07:00:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.452403 on epoch=182
05/31/2022 07:00:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.448973 on epoch=184
05/31/2022 07:00:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.365130 on epoch=187
05/31/2022 07:00:52 - INFO - __main__ - Global step 750 Train loss 0.416866 Classification-F1 0.3333333333333333 on epoch=187
05/31/2022 07:00:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.379027 on epoch=189
05/31/2022 07:01:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.476924 on epoch=192
05/31/2022 07:01:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.473871 on epoch=194
05/31/2022 07:01:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.424772 on epoch=197
05/31/2022 07:01:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.414360 on epoch=199
05/31/2022 07:01:19 - INFO - __main__ - Global step 800 Train loss 0.433791 Classification-F1 0.3333333333333333 on epoch=199
05/31/2022 07:01:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.403410 on epoch=202
05/31/2022 07:01:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.413252 on epoch=204
05/31/2022 07:01:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.386678 on epoch=207
05/31/2022 07:01:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.477903 on epoch=209
05/31/2022 07:01:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.381876 on epoch=212
05/31/2022 07:01:46 - INFO - __main__ - Global step 850 Train loss 0.412624 Classification-F1 0.3333333333333333 on epoch=212
05/31/2022 07:01:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.392989 on epoch=214
05/31/2022 07:01:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.376423 on epoch=217
05/31/2022 07:02:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.383697 on epoch=219
05/31/2022 07:02:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.386716 on epoch=222
05/31/2022 07:02:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.565678 on epoch=224
05/31/2022 07:02:13 - INFO - __main__ - Global step 900 Train loss 0.421101 Classification-F1 0.4519207242476144 on epoch=224
05/31/2022 07:02:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.336350 on epoch=227
05/31/2022 07:02:24 - INFO - __main__ - Step 920 Global step 920 Train loss 0.385775 on epoch=229
05/31/2022 07:02:29 - INFO - __main__ - Step 930 Global step 930 Train loss 0.355341 on epoch=232
05/31/2022 07:02:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.376764 on epoch=234
05/31/2022 07:02:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.373624 on epoch=237
05/31/2022 07:02:40 - INFO - __main__ - Global step 950 Train loss 0.365570 Classification-F1 0.4092307692307692 on epoch=237
05/31/2022 07:02:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.385060 on epoch=239
05/31/2022 07:02:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.344323 on epoch=242
05/31/2022 07:02:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.345450 on epoch=244
05/31/2022 07:03:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.336924 on epoch=247
05/31/2022 07:03:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.385039 on epoch=249
05/31/2022 07:03:07 - INFO - __main__ - Global step 1000 Train loss 0.359359 Classification-F1 0.38918345705196183 on epoch=249
05/31/2022 07:03:07 - INFO - __main__ - save last model!
05/31/2022 07:03:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:03:08 - INFO - __main__ - Printing 3 examples
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:03:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:03:08 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:03:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:03:08 - INFO - __main__ - Printing 3 examples
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:03:08 - INFO - __main__ - ['false']
05/31/2022 07:03:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:03:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:03:08 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:03:14 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:03:15 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:03:15 - INFO - __main__ - Printing 3 examples
05/31/2022 07:03:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:03:15 - INFO - __main__ - ['false']
05/31/2022 07:03:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:03:15 - INFO - __main__ - ['false']
05/31/2022 07:03:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:03:15 - INFO - __main__ - ['false']
05/31/2022 07:03:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:03:16 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:03:19 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:03:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:03:21 - INFO - __main__ - Starting training!
05/31/2022 07:03:48 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_13_0.0005_8_predictions.txt
05/31/2022 07:03:48 - INFO - __main__ - Classification-F1 on test data: 0.2155
05/31/2022 07:03:48 - INFO - __main__ - prefix=wiki_qa_32_13, lr=0.0005, bsz=8, dev_performance=0.4545454545454546, test_performance=0.21550897063430155
05/31/2022 07:03:48 - INFO - __main__ - Running ... prefix=wiki_qa_32_13, lr=0.0003, bsz=8 ...
05/31/2022 07:03:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:03:49 - INFO - __main__ - Printing 3 examples
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:03:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:03:49 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:03:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:03:49 - INFO - __main__ - Printing 3 examples
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:03:49 - INFO - __main__ - ['false']
05/31/2022 07:03:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:03:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:03:49 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:04:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:04:01 - INFO - __main__ - Starting training!
05/31/2022 07:04:06 - INFO - __main__ - Step 10 Global step 10 Train loss 23.880093 on epoch=2
05/31/2022 07:04:11 - INFO - __main__ - Step 20 Global step 20 Train loss 19.743580 on epoch=4
05/31/2022 07:04:16 - INFO - __main__ - Step 30 Global step 30 Train loss 17.402317 on epoch=7
05/31/2022 07:04:21 - INFO - __main__ - Step 40 Global step 40 Train loss 16.067280 on epoch=9
05/31/2022 07:04:27 - INFO - __main__ - Step 50 Global step 50 Train loss 14.786540 on epoch=12
05/31/2022 07:04:28 - INFO - __main__ - Global step 50 Train loss 18.375963 Classification-F1 0.0 on epoch=12
05/31/2022 07:04:34 - INFO - __main__ - Step 60 Global step 60 Train loss 14.932986 on epoch=14
05/31/2022 07:04:39 - INFO - __main__ - Step 70 Global step 70 Train loss 13.384771 on epoch=17
05/31/2022 07:04:45 - INFO - __main__ - Step 80 Global step 80 Train loss 9.681436 on epoch=19
05/31/2022 07:04:50 - INFO - __main__ - Step 90 Global step 90 Train loss 2.488400 on epoch=22
05/31/2022 07:04:55 - INFO - __main__ - Step 100 Global step 100 Train loss 0.646683 on epoch=24
05/31/2022 07:04:56 - INFO - __main__ - Global step 100 Train loss 8.226855 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 07:05:02 - INFO - __main__ - Step 110 Global step 110 Train loss 0.575401 on epoch=27
05/31/2022 07:05:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.372979 on epoch=29
05/31/2022 07:05:12 - INFO - __main__ - Step 130 Global step 130 Train loss 0.478852 on epoch=32
05/31/2022 07:05:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.378822 on epoch=34
05/31/2022 07:05:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.523311 on epoch=37
05/31/2022 07:05:24 - INFO - __main__ - Global step 150 Train loss 0.465873 Classification-F1 0.3671451355661882 on epoch=37
05/31/2022 07:05:29 - INFO - __main__ - Step 160 Global step 160 Train loss 1.212444 on epoch=39
05/31/2022 07:05:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.506464 on epoch=42
05/31/2022 07:05:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.340773 on epoch=44
05/31/2022 07:05:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.361897 on epoch=47
05/31/2022 07:05:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.162713 on epoch=49
05/31/2022 07:05:51 - INFO - __main__ - Global step 200 Train loss 0.516858 Classification-F1 0.5390377412849323 on epoch=49
05/31/2022 07:05:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.153680 on epoch=52
05/31/2022 07:06:03 - INFO - __main__ - Step 220 Global step 220 Train loss 0.129387 on epoch=54
05/31/2022 07:06:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.155365 on epoch=57
05/31/2022 07:06:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.079119 on epoch=59
05/31/2022 07:06:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.044951 on epoch=62
05/31/2022 07:06:19 - INFO - __main__ - Global step 250 Train loss 0.112500 Classification-F1 0.5238095238095238 on epoch=62
05/31/2022 07:06:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.044673 on epoch=64
05/31/2022 07:06:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.072633 on epoch=67
05/31/2022 07:06:35 - INFO - __main__ - Step 280 Global step 280 Train loss 0.046939 on epoch=69
05/31/2022 07:06:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.027426 on epoch=72
05/31/2022 07:06:46 - INFO - __main__ - Step 300 Global step 300 Train loss 0.028759 on epoch=74
05/31/2022 07:06:46 - INFO - __main__ - Global step 300 Train loss 0.044086 Classification-F1 0.48747093774218553 on epoch=74
05/31/2022 07:06:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.033985 on epoch=77
05/31/2022 07:06:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.017848 on epoch=79
05/31/2022 07:07:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.009633 on epoch=82
05/31/2022 07:07:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.006320 on epoch=84
05/31/2022 07:07:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.003250 on epoch=87
05/31/2022 07:07:14 - INFO - __main__ - Global step 350 Train loss 0.014207 Classification-F1 0.5333333333333333 on epoch=87
05/31/2022 07:07:19 - INFO - __main__ - Step 360 Global step 360 Train loss 0.017810 on epoch=89
05/31/2022 07:07:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.002119 on epoch=92
05/31/2022 07:07:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.001173 on epoch=94
05/31/2022 07:07:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.002829 on epoch=97
05/31/2022 07:07:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.001602 on epoch=99
05/31/2022 07:07:41 - INFO - __main__ - Global step 400 Train loss 0.005106 Classification-F1 0.5038759689922481 on epoch=99
05/31/2022 07:07:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000727 on epoch=102
05/31/2022 07:07:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.000646 on epoch=104
05/31/2022 07:07:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.002029 on epoch=107
05/31/2022 07:08:02 - INFO - __main__ - Step 440 Global step 440 Train loss 0.000514 on epoch=109
05/31/2022 07:08:07 - INFO - __main__ - Step 450 Global step 450 Train loss 0.000804 on epoch=112
05/31/2022 07:08:08 - INFO - __main__ - Global step 450 Train loss 0.000944 Classification-F1 0.5249204665959704 on epoch=112
05/31/2022 07:08:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000610 on epoch=114
05/31/2022 07:08:19 - INFO - __main__ - Step 470 Global step 470 Train loss 0.024635 on epoch=117
05/31/2022 07:08:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.171922 on epoch=119
05/31/2022 07:08:29 - INFO - __main__ - Step 490 Global step 490 Train loss 0.003228 on epoch=122
05/31/2022 07:08:34 - INFO - __main__ - Step 500 Global step 500 Train loss 0.009179 on epoch=124
05/31/2022 07:08:35 - INFO - __main__ - Global step 500 Train loss 0.041915 Classification-F1 0.5460992907801419 on epoch=124
05/31/2022 07:08:41 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001458 on epoch=127
05/31/2022 07:08:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.014145 on epoch=129
05/31/2022 07:08:52 - INFO - __main__ - Step 530 Global step 530 Train loss 0.014577 on epoch=132
05/31/2022 07:08:57 - INFO - __main__ - Step 540 Global step 540 Train loss 0.001825 on epoch=134
05/31/2022 07:09:02 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000445 on epoch=137
05/31/2022 07:09:03 - INFO - __main__ - Global step 550 Train loss 0.006490 Classification-F1 0.5273745861981156 on epoch=137
05/31/2022 07:09:08 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005129 on epoch=139
05/31/2022 07:09:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.004448 on epoch=142
05/31/2022 07:09:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001507 on epoch=144
05/31/2022 07:09:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.001148 on epoch=147
05/31/2022 07:09:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.003543 on epoch=149
05/31/2022 07:09:30 - INFO - __main__ - Global step 600 Train loss 0.003155 Classification-F1 0.5536037199690003 on epoch=149
05/31/2022 07:09:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.001285 on epoch=152
05/31/2022 07:09:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000752 on epoch=154
05/31/2022 07:09:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.001097 on epoch=157
05/31/2022 07:09:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.039541 on epoch=159
05/31/2022 07:09:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000095 on epoch=162
05/31/2022 07:09:58 - INFO - __main__ - Global step 650 Train loss 0.008554 Classification-F1 0.5497835497835498 on epoch=162
05/31/2022 07:10:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000111 on epoch=164
05/31/2022 07:10:08 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000044 on epoch=167
05/31/2022 07:10:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000027 on epoch=169
05/31/2022 07:10:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000084 on epoch=172
05/31/2022 07:10:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000136 on epoch=174
05/31/2022 07:10:25 - INFO - __main__ - Global step 700 Train loss 0.000080 Classification-F1 0.5652830188679245 on epoch=174
05/31/2022 07:10:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000166 on epoch=177
05/31/2022 07:10:36 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000029 on epoch=179
05/31/2022 07:10:42 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000051 on epoch=182
05/31/2022 07:10:47 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000044 on epoch=184
05/31/2022 07:10:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000058 on epoch=187
05/31/2022 07:10:53 - INFO - __main__ - Global step 750 Train loss 0.000070 Classification-F1 0.5652830188679245 on epoch=187
05/31/2022 07:10:58 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000060 on epoch=189
05/31/2022 07:11:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000295 on epoch=192
05/31/2022 07:11:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000177 on epoch=194
05/31/2022 07:11:14 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000145 on epoch=197
05/31/2022 07:11:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000058 on epoch=199
05/31/2022 07:11:20 - INFO - __main__ - Global step 800 Train loss 0.000147 Classification-F1 0.5789473684210527 on epoch=199
05/31/2022 07:11:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000028 on epoch=202
05/31/2022 07:11:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000210 on epoch=204
05/31/2022 07:11:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.045233 on epoch=207
05/31/2022 07:11:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000276 on epoch=209
05/31/2022 07:11:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000138 on epoch=212
05/31/2022 07:11:48 - INFO - __main__ - Global step 850 Train loss 0.009177 Classification-F1 0.5733333333333335 on epoch=212
05/31/2022 07:11:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000060 on epoch=214
05/31/2022 07:11:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000056 on epoch=217
05/31/2022 07:12:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000064 on epoch=219
05/31/2022 07:12:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000435 on epoch=222
05/31/2022 07:12:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000038 on epoch=224
05/31/2022 07:12:15 - INFO - __main__ - Global step 900 Train loss 0.000131 Classification-F1 0.5373493975903615 on epoch=224
05/31/2022 07:12:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000022 on epoch=227
05/31/2022 07:12:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001089 on epoch=229
05/31/2022 07:12:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000111 on epoch=232
05/31/2022 07:12:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000558 on epoch=234
05/31/2022 07:12:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000224 on epoch=237
05/31/2022 07:12:42 - INFO - __main__ - Global step 950 Train loss 0.000401 Classification-F1 0.5076923076923077 on epoch=237
05/31/2022 07:12:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000044 on epoch=239
05/31/2022 07:12:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000064 on epoch=242
05/31/2022 07:12:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000051 on epoch=244
05/31/2022 07:13:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000583 on epoch=247
05/31/2022 07:13:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000043 on epoch=249
05/31/2022 07:13:10 - INFO - __main__ - Global step 1000 Train loss 0.000157 Classification-F1 0.46843853820598 on epoch=249
05/31/2022 07:13:10 - INFO - __main__ - save last model!
05/31/2022 07:13:10 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:13:10 - INFO - __main__ - Printing 3 examples
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:13:10 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:13:10 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:13:10 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:13:10 - INFO - __main__ - Printing 3 examples
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:13:10 - INFO - __main__ - ['false']
05/31/2022 07:13:10 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:13:10 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:13:10 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:13:16 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:13:17 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:13:17 - INFO - __main__ - Printing 3 examples
05/31/2022 07:13:17 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:13:17 - INFO - __main__ - ['false']
05/31/2022 07:13:17 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:13:17 - INFO - __main__ - ['false']
05/31/2022 07:13:17 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:13:17 - INFO - __main__ - ['false']
05/31/2022 07:13:17 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:13:19 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:13:21 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:13:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:13:21 - INFO - __main__ - Starting training!
05/31/2022 07:13:50 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_13_0.0003_8_predictions.txt
05/31/2022 07:13:50 - INFO - __main__ - Classification-F1 on test data: 0.3750
05/31/2022 07:13:50 - INFO - __main__ - prefix=wiki_qa_32_13, lr=0.0003, bsz=8, dev_performance=0.5789473684210527, test_performance=0.3749576181733273
05/31/2022 07:13:50 - INFO - __main__ - Running ... prefix=wiki_qa_32_13, lr=0.0002, bsz=8 ...
05/31/2022 07:13:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:13:51 - INFO - __main__ - Printing 3 examples
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:13:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:13:51 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:13:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:13:51 - INFO - __main__ - Printing 3 examples
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:13:51 - INFO - __main__ - ['false']
05/31/2022 07:13:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:13:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:13:51 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:14:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:14:03 - INFO - __main__ - Starting training!
05/31/2022 07:14:07 - INFO - __main__ - Step 10 Global step 10 Train loss 23.916536 on epoch=2
05/31/2022 07:14:13 - INFO - __main__ - Step 20 Global step 20 Train loss 19.650841 on epoch=4
05/31/2022 07:14:18 - INFO - __main__ - Step 30 Global step 30 Train loss 18.063654 on epoch=7
05/31/2022 07:14:23 - INFO - __main__ - Step 40 Global step 40 Train loss 17.619341 on epoch=9
05/31/2022 07:14:28 - INFO - __main__ - Step 50 Global step 50 Train loss 16.211388 on epoch=12
05/31/2022 07:14:39 - INFO - __main__ - Global step 50 Train loss 19.092352 Classification-F1 0.0 on epoch=12
05/31/2022 07:14:45 - INFO - __main__ - Step 60 Global step 60 Train loss 16.310780 on epoch=14
05/31/2022 07:14:50 - INFO - __main__ - Step 70 Global step 70 Train loss 14.515027 on epoch=17
05/31/2022 07:14:56 - INFO - __main__ - Step 80 Global step 80 Train loss 14.524439 on epoch=19
05/31/2022 07:15:01 - INFO - __main__ - Step 90 Global step 90 Train loss 14.190458 on epoch=22
05/31/2022 07:15:06 - INFO - __main__ - Step 100 Global step 100 Train loss 12.796798 on epoch=24
05/31/2022 07:15:11 - INFO - __main__ - Global step 100 Train loss 14.467500 Classification-F1 0.0 on epoch=24
05/31/2022 07:15:16 - INFO - __main__ - Step 110 Global step 110 Train loss 11.743816 on epoch=27
05/31/2022 07:15:22 - INFO - __main__ - Step 120 Global step 120 Train loss 10.579989 on epoch=29
05/31/2022 07:15:27 - INFO - __main__ - Step 130 Global step 130 Train loss 8.075823 on epoch=32
05/31/2022 07:15:32 - INFO - __main__ - Step 140 Global step 140 Train loss 5.089758 on epoch=34
05/31/2022 07:15:37 - INFO - __main__ - Step 150 Global step 150 Train loss 2.261634 on epoch=37
05/31/2022 07:15:38 - INFO - __main__ - Global step 150 Train loss 7.550204 Classification-F1 0.3333333333333333 on epoch=37
05/31/2022 07:15:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.935527 on epoch=39
05/31/2022 07:15:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.446633 on epoch=42
05/31/2022 07:15:55 - INFO - __main__ - Step 180 Global step 180 Train loss 0.516176 on epoch=44
05/31/2022 07:16:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.453270 on epoch=47
05/31/2022 07:16:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.340017 on epoch=49
05/31/2022 07:16:06 - INFO - __main__ - Global step 200 Train loss 0.538325 Classification-F1 0.3992490613266583 on epoch=49
05/31/2022 07:16:12 - INFO - __main__ - Step 210 Global step 210 Train loss 0.267508 on epoch=52
05/31/2022 07:16:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.301464 on epoch=54
05/31/2022 07:16:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.178943 on epoch=57
05/31/2022 07:16:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.190976 on epoch=59
05/31/2022 07:16:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.159764 on epoch=62
05/31/2022 07:16:33 - INFO - __main__ - Global step 250 Train loss 0.219731 Classification-F1 0.6528028933092225 on epoch=62
05/31/2022 07:16:40 - INFO - __main__ - Step 260 Global step 260 Train loss 0.142216 on epoch=64
05/31/2022 07:16:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.047452 on epoch=67
05/31/2022 07:16:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.102957 on epoch=69
05/31/2022 07:16:55 - INFO - __main__ - Step 290 Global step 290 Train loss 0.067591 on epoch=72
05/31/2022 07:17:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.047535 on epoch=74
05/31/2022 07:17:01 - INFO - __main__ - Global step 300 Train loss 0.081550 Classification-F1 0.6389743589743591 on epoch=74
05/31/2022 07:17:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.017161 on epoch=77
05/31/2022 07:17:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.051836 on epoch=79
05/31/2022 07:17:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.044902 on epoch=82
05/31/2022 07:17:23 - INFO - __main__ - Step 340 Global step 340 Train loss 0.035496 on epoch=84
05/31/2022 07:17:28 - INFO - __main__ - Step 350 Global step 350 Train loss 0.013961 on epoch=87
05/31/2022 07:17:28 - INFO - __main__ - Global step 350 Train loss 0.032671 Classification-F1 0.5588547189819725 on epoch=87
05/31/2022 07:17:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.007527 on epoch=89
05/31/2022 07:17:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.009987 on epoch=92
05/31/2022 07:17:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.011507 on epoch=94
05/31/2022 07:17:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.008621 on epoch=97
05/31/2022 07:17:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.005596 on epoch=99
05/31/2022 07:17:55 - INFO - __main__ - Global step 400 Train loss 0.008648 Classification-F1 0.6618867924528302 on epoch=99
05/31/2022 07:18:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.004576 on epoch=102
05/31/2022 07:18:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.017172 on epoch=104
05/31/2022 07:18:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.002517 on epoch=107
05/31/2022 07:18:17 - INFO - __main__ - Step 440 Global step 440 Train loss 0.002776 on epoch=109
05/31/2022 07:18:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.003741 on epoch=112
05/31/2022 07:18:23 - INFO - __main__ - Global step 450 Train loss 0.006157 Classification-F1 0.5666666666666667 on epoch=112
05/31/2022 07:18:28 - INFO - __main__ - Step 460 Global step 460 Train loss 0.001843 on epoch=114
05/31/2022 07:18:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.002660 on epoch=117
05/31/2022 07:18:39 - INFO - __main__ - Step 480 Global step 480 Train loss 0.002980 on epoch=119
05/31/2022 07:18:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.006112 on epoch=122
05/31/2022 07:18:50 - INFO - __main__ - Step 500 Global step 500 Train loss 0.002092 on epoch=124
05/31/2022 07:18:50 - INFO - __main__ - Global step 500 Train loss 0.003137 Classification-F1 0.5373493975903615 on epoch=124
05/31/2022 07:18:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000879 on epoch=127
05/31/2022 07:19:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000634 on epoch=129
05/31/2022 07:19:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.011569 on epoch=132
05/31/2022 07:19:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.005038 on epoch=134
05/31/2022 07:19:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000752 on epoch=137
05/31/2022 07:19:17 - INFO - __main__ - Global step 550 Train loss 0.003774 Classification-F1 0.6532019704433498 on epoch=137
05/31/2022 07:19:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.004011 on epoch=139
05/31/2022 07:19:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.013285 on epoch=142
05/31/2022 07:19:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001894 on epoch=144
05/31/2022 07:19:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.002807 on epoch=147
05/31/2022 07:19:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000916 on epoch=149
05/31/2022 07:19:44 - INFO - __main__ - Global step 600 Train loss 0.004582 Classification-F1 0.5155592935239698 on epoch=149
05/31/2022 07:19:49 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000468 on epoch=152
05/31/2022 07:19:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000224 on epoch=154
05/31/2022 07:20:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000736 on epoch=157
05/31/2022 07:20:05 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000266 on epoch=159
05/31/2022 07:20:10 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000085 on epoch=162
05/31/2022 07:20:11 - INFO - __main__ - Global step 650 Train loss 0.000356 Classification-F1 0.6333333333333333 on epoch=162
05/31/2022 07:20:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000295 on epoch=164
05/31/2022 07:20:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000065 on epoch=167
05/31/2022 07:20:26 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000208 on epoch=169
05/31/2022 07:20:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.005705 on epoch=172
05/31/2022 07:20:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000930 on epoch=174
05/31/2022 07:20:38 - INFO - __main__ - Global step 700 Train loss 0.001440 Classification-F1 0.571619812583668 on epoch=174
05/31/2022 07:20:43 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000140 on epoch=177
05/31/2022 07:20:48 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000706 on epoch=179
05/31/2022 07:20:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.002731 on epoch=182
05/31/2022 07:20:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000270 on epoch=184
05/31/2022 07:21:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000218 on epoch=187
05/31/2022 07:21:05 - INFO - __main__ - Global step 750 Train loss 0.000813 Classification-F1 0.5927889713679746 on epoch=187
05/31/2022 07:21:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000043 on epoch=189
05/31/2022 07:21:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000118 on epoch=192
05/31/2022 07:21:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000100 on epoch=194
05/31/2022 07:21:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000180 on epoch=197
05/31/2022 07:21:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000087 on epoch=199
05/31/2022 07:21:32 - INFO - __main__ - Global step 800 Train loss 0.000106 Classification-F1 0.5497835497835498 on epoch=199
05/31/2022 07:21:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000313 on epoch=202
05/31/2022 07:21:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000174 on epoch=204
05/31/2022 07:21:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000228 on epoch=207
05/31/2022 07:21:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000278 on epoch=209
05/31/2022 07:21:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000166 on epoch=212
05/31/2022 07:21:59 - INFO - __main__ - Global step 850 Train loss 0.000232 Classification-F1 0.571619812583668 on epoch=212
05/31/2022 07:22:04 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000131 on epoch=214
05/31/2022 07:22:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000125 on epoch=217
05/31/2022 07:22:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.002759 on epoch=219
05/31/2022 07:22:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000215 on epoch=222
05/31/2022 07:22:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000434 on epoch=224
05/31/2022 07:22:26 - INFO - __main__ - Global step 900 Train loss 0.000733 Classification-F1 0.6437246963562753 on epoch=224
05/31/2022 07:22:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000191 on epoch=227
05/31/2022 07:22:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000181 on epoch=229
05/31/2022 07:22:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000089 on epoch=232
05/31/2022 07:22:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000133 on epoch=234
05/31/2022 07:22:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000093 on epoch=237
05/31/2022 07:22:53 - INFO - __main__ - Global step 950 Train loss 0.000137 Classification-F1 0.6389743589743591 on epoch=237
05/31/2022 07:22:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000041 on epoch=239
05/31/2022 07:23:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000050 on epoch=242
05/31/2022 07:23:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000063 on epoch=244
05/31/2022 07:23:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000072 on epoch=247
05/31/2022 07:23:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000103 on epoch=249
05/31/2022 07:23:20 - INFO - __main__ - Global step 1000 Train loss 0.000066 Classification-F1 0.6251591545709192 on epoch=249
05/31/2022 07:23:20 - INFO - __main__ - save last model!
05/31/2022 07:23:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:23:21 - INFO - __main__ - Printing 3 examples
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:23:21 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:23:21 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:23:21 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:23:21 - INFO - __main__ - Printing 3 examples
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:23:21 - INFO - __main__ - ['false']
05/31/2022 07:23:21 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:23:21 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:23:21 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:23:27 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:23:28 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:23:28 - INFO - __main__ - Printing 3 examples
05/31/2022 07:23:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:23:28 - INFO - __main__ - ['false']
05/31/2022 07:23:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:23:28 - INFO - __main__ - ['false']
05/31/2022 07:23:28 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:23:28 - INFO - __main__ - ['false']
05/31/2022 07:23:28 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:23:29 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:23:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:23:31 - INFO - __main__ - Starting training!
05/31/2022 07:23:32 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:24:00 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_13_0.0002_8_predictions.txt
05/31/2022 07:24:00 - INFO - __main__ - Classification-F1 on test data: 0.3980
05/31/2022 07:24:01 - INFO - __main__ - prefix=wiki_qa_32_13, lr=0.0002, bsz=8, dev_performance=0.6618867924528302, test_performance=0.3980081284956307
05/31/2022 07:24:01 - INFO - __main__ - Running ... prefix=wiki_qa_32_13, lr=0.0001, bsz=8 ...
05/31/2022 07:24:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:24:02 - INFO - __main__ - Printing 3 examples
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: what part of the government governs the US post office? [SEP] answer: It is one of the few government agencies explicitly authorized by the United States Constitution .
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: what record company was john lennon with [SEP] answer: Lennon revealed a rebellious nature and acerbic wit in his music, writing, drawings, on film and in interviews.
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: where do most political candidates get their money [SEP] answer: In democracies , political campaigns often refer to electoral campaigns, wherein representatives are chosen or referendums are decided.
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:24:02 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:24:02 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:24:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:24:02 - INFO - __main__ - Printing 3 examples
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: who discovered planet neptune [SEP] answer: Traditionally, ocean scientists have relied on infrequent ship cruises or space-based satellites to carry out their research, while the NEPTUNE project uses a remotely operated crawler.
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: what is only constitutional leadership position in house of representatives [SEP] answer: Each representative serves for a two-year term.
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ -  [wiki_qa] question: what kind of potential is created after a neuron is excited [SEP] answer: There are, however, many exceptions to these rules: neurons that lack dendrites, neurons that have no axon, synapses that connect an axon to another axon or a dendrite to another dendrite, etc.
05/31/2022 07:24:02 - INFO - __main__ - ['false']
05/31/2022 07:24:02 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:24:02 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:24:02 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:24:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:24:14 - INFO - __main__ - Starting training!
05/31/2022 07:24:18 - INFO - __main__ - Step 10 Global step 10 Train loss 22.553068 on epoch=2
05/31/2022 07:24:23 - INFO - __main__ - Step 20 Global step 20 Train loss 21.094179 on epoch=4
05/31/2022 07:24:29 - INFO - __main__ - Step 30 Global step 30 Train loss 18.261635 on epoch=7
05/31/2022 07:24:34 - INFO - __main__ - Step 40 Global step 40 Train loss 18.992004 on epoch=9
05/31/2022 07:24:39 - INFO - __main__ - Step 50 Global step 50 Train loss 18.457251 on epoch=12
05/31/2022 07:24:50 - INFO - __main__ - Global step 50 Train loss 19.871628 Classification-F1 0.0 on epoch=12
05/31/2022 07:24:56 - INFO - __main__ - Step 60 Global step 60 Train loss 16.253965 on epoch=14
05/31/2022 07:25:01 - INFO - __main__ - Step 70 Global step 70 Train loss 16.645344 on epoch=17
05/31/2022 07:25:06 - INFO - __main__ - Step 80 Global step 80 Train loss 17.153461 on epoch=19
05/31/2022 07:25:11 - INFO - __main__ - Step 90 Global step 90 Train loss 16.239117 on epoch=22
05/31/2022 07:25:17 - INFO - __main__ - Step 100 Global step 100 Train loss 15.706118 on epoch=24
05/31/2022 07:25:21 - INFO - __main__ - Global step 100 Train loss 16.399603 Classification-F1 0.0 on epoch=24
05/31/2022 07:25:27 - INFO - __main__ - Step 110 Global step 110 Train loss 15.355336 on epoch=27
05/31/2022 07:25:32 - INFO - __main__ - Step 120 Global step 120 Train loss 15.056841 on epoch=29
05/31/2022 07:25:37 - INFO - __main__ - Step 130 Global step 130 Train loss 14.677821 on epoch=32
05/31/2022 07:25:42 - INFO - __main__ - Step 140 Global step 140 Train loss 14.445745 on epoch=34
05/31/2022 07:25:48 - INFO - __main__ - Step 150 Global step 150 Train loss 14.646898 on epoch=37
05/31/2022 07:25:49 - INFO - __main__ - Global step 150 Train loss 14.836529 Classification-F1 0.0 on epoch=37
05/31/2022 07:25:54 - INFO - __main__ - Step 160 Global step 160 Train loss 13.312704 on epoch=39
05/31/2022 07:26:00 - INFO - __main__ - Step 170 Global step 170 Train loss 13.272466 on epoch=42
05/31/2022 07:26:05 - INFO - __main__ - Step 180 Global step 180 Train loss 13.083282 on epoch=44
05/31/2022 07:26:10 - INFO - __main__ - Step 190 Global step 190 Train loss 12.189096 on epoch=47
05/31/2022 07:26:15 - INFO - __main__ - Step 200 Global step 200 Train loss 10.869201 on epoch=49
05/31/2022 07:26:17 - INFO - __main__ - Global step 200 Train loss 12.545352 Classification-F1 0.0017825311942959003 on epoch=49
05/31/2022 07:26:23 - INFO - __main__ - Step 210 Global step 210 Train loss 10.014432 on epoch=52
05/31/2022 07:26:28 - INFO - __main__ - Step 220 Global step 220 Train loss 8.516960 on epoch=54
05/31/2022 07:26:33 - INFO - __main__ - Step 230 Global step 230 Train loss 6.584793 on epoch=57
05/31/2022 07:26:39 - INFO - __main__ - Step 240 Global step 240 Train loss 3.909004 on epoch=59
05/31/2022 07:26:44 - INFO - __main__ - Step 250 Global step 250 Train loss 4.104409 on epoch=62
05/31/2022 07:26:44 - INFO - __main__ - Global step 250 Train loss 6.625919 Classification-F1 0.3333333333333333 on epoch=62
05/31/2022 07:26:50 - INFO - __main__ - Step 260 Global step 260 Train loss 2.358950 on epoch=64
05/31/2022 07:26:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.779042 on epoch=67
05/31/2022 07:27:01 - INFO - __main__ - Step 280 Global step 280 Train loss 0.651282 on epoch=69
05/31/2022 07:27:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.504306 on epoch=72
05/31/2022 07:27:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.425501 on epoch=74
05/31/2022 07:27:12 - INFO - __main__ - Global step 300 Train loss 0.943816 Classification-F1 0.4589371980676329 on epoch=74
05/31/2022 07:27:18 - INFO - __main__ - Step 310 Global step 310 Train loss 0.518229 on epoch=77
05/31/2022 07:27:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.366245 on epoch=79
05/31/2022 07:27:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.429656 on epoch=82
05/31/2022 07:27:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.458398 on epoch=84
05/31/2022 07:27:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.476392 on epoch=87
05/31/2022 07:27:39 - INFO - __main__ - Global step 350 Train loss 0.449784 Classification-F1 0.47602339181286546 on epoch=87
05/31/2022 07:27:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.317211 on epoch=89
05/31/2022 07:27:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.240762 on epoch=92
05/31/2022 07:27:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.322457 on epoch=94
05/31/2022 07:28:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.256774 on epoch=97
05/31/2022 07:28:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.257775 on epoch=99
05/31/2022 07:28:07 - INFO - __main__ - Global step 400 Train loss 0.278996 Classification-F1 0.4589371980676329 on epoch=99
05/31/2022 07:28:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.205301 on epoch=102
05/31/2022 07:28:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.135246 on epoch=104
05/31/2022 07:28:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.200197 on epoch=107
05/31/2022 07:28:28 - INFO - __main__ - Step 440 Global step 440 Train loss 0.127169 on epoch=109
05/31/2022 07:28:33 - INFO - __main__ - Step 450 Global step 450 Train loss 0.093515 on epoch=112
05/31/2022 07:28:34 - INFO - __main__ - Global step 450 Train loss 0.152286 Classification-F1 0.4545454545454546 on epoch=112
05/31/2022 07:28:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.099139 on epoch=114
05/31/2022 07:28:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.063917 on epoch=117
05/31/2022 07:28:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.103572 on epoch=119
05/31/2022 07:28:54 - INFO - __main__ - Step 490 Global step 490 Train loss 0.037714 on epoch=122
05/31/2022 07:29:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.047517 on epoch=124
05/31/2022 07:29:00 - INFO - __main__ - Global step 500 Train loss 0.070372 Classification-F1 0.5038759689922481 on epoch=124
05/31/2022 07:29:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.042746 on epoch=127
05/31/2022 07:29:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.043566 on epoch=129
05/31/2022 07:29:17 - INFO - __main__ - Step 530 Global step 530 Train loss 0.044276 on epoch=132
05/31/2022 07:29:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.033089 on epoch=134
05/31/2022 07:29:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.041192 on epoch=137
05/31/2022 07:29:28 - INFO - __main__ - Global step 550 Train loss 0.040974 Classification-F1 0.46843853820598 on epoch=137
05/31/2022 07:29:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.023183 on epoch=139
05/31/2022 07:29:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.010893 on epoch=142
05/31/2022 07:29:43 - INFO - __main__ - Step 580 Global step 580 Train loss 0.016315 on epoch=144
05/31/2022 07:29:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.014922 on epoch=147
05/31/2022 07:29:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.036272 on epoch=149
05/31/2022 07:29:55 - INFO - __main__ - Global step 600 Train loss 0.020317 Classification-F1 0.44379029997196523 on epoch=149
05/31/2022 07:30:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.025975 on epoch=152
05/31/2022 07:30:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.011089 on epoch=154
05/31/2022 07:30:10 - INFO - __main__ - Step 630 Global step 630 Train loss 0.006080 on epoch=157
05/31/2022 07:30:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.018820 on epoch=159
05/31/2022 07:30:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.006231 on epoch=162
05/31/2022 07:30:22 - INFO - __main__ - Global step 650 Train loss 0.013639 Classification-F1 0.39047619047619053 on epoch=162
05/31/2022 07:30:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.005731 on epoch=164
05/31/2022 07:30:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.012551 on epoch=167
05/31/2022 07:30:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.009284 on epoch=169
05/31/2022 07:30:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.011079 on epoch=172
05/31/2022 07:30:48 - INFO - __main__ - Step 700 Global step 700 Train loss 0.003501 on epoch=174
05/31/2022 07:30:49 - INFO - __main__ - Global step 700 Train loss 0.008429 Classification-F1 0.42840679919331603 on epoch=174
05/31/2022 07:30:54 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001616 on epoch=177
05/31/2022 07:30:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.002508 on epoch=179
05/31/2022 07:31:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.005077 on epoch=182
05/31/2022 07:31:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.004208 on epoch=184
05/31/2022 07:31:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.033888 on epoch=187
05/31/2022 07:31:16 - INFO - __main__ - Global step 750 Train loss 0.009459 Classification-F1 0.3816425120772947 on epoch=187
05/31/2022 07:31:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001740 on epoch=189
05/31/2022 07:31:27 - INFO - __main__ - Step 770 Global step 770 Train loss 0.006474 on epoch=192
05/31/2022 07:31:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.002537 on epoch=194
05/31/2022 07:31:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.004731 on epoch=197
05/31/2022 07:31:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.002262 on epoch=199
05/31/2022 07:31:43 - INFO - __main__ - Global step 800 Train loss 0.003549 Classification-F1 0.42840679919331603 on epoch=199
05/31/2022 07:31:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.059085 on epoch=202
05/31/2022 07:31:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.002024 on epoch=204
05/31/2022 07:31:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000348 on epoch=207
05/31/2022 07:32:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.005367 on epoch=209
05/31/2022 07:32:09 - INFO - __main__ - Step 850 Global step 850 Train loss 0.001746 on epoch=212
05/31/2022 07:32:10 - INFO - __main__ - Global step 850 Train loss 0.013714 Classification-F1 0.4545454545454546 on epoch=212
05/31/2022 07:32:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.003500 on epoch=214
05/31/2022 07:32:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.013206 on epoch=217
05/31/2022 07:32:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.020567 on epoch=219
05/31/2022 07:32:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001428 on epoch=222
05/31/2022 07:32:37 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001934 on epoch=224
05/31/2022 07:32:37 - INFO - __main__ - Global step 900 Train loss 0.008127 Classification-F1 0.4652837798905215 on epoch=224
05/31/2022 07:32:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.002680 on epoch=227
05/31/2022 07:32:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.011324 on epoch=229
05/31/2022 07:32:53 - INFO - __main__ - Step 930 Global step 930 Train loss 0.099585 on epoch=232
05/31/2022 07:32:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.005161 on epoch=234
05/31/2022 07:33:04 - INFO - __main__ - Step 950 Global step 950 Train loss 0.006540 on epoch=237
05/31/2022 07:33:05 - INFO - __main__ - Global step 950 Train loss 0.025058 Classification-F1 0.4385964912280702 on epoch=237
05/31/2022 07:33:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.117807 on epoch=239
05/31/2022 07:33:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.081943 on epoch=242
05/31/2022 07:33:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.004418 on epoch=244
05/31/2022 07:33:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.009715 on epoch=247
05/31/2022 07:33:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.019535 on epoch=249
05/31/2022 07:33:32 - INFO - __main__ - Global step 1000 Train loss 0.046683 Classification-F1 0.571619812583668 on epoch=249
05/31/2022 07:33:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:33:32 - INFO - __main__ - Printing 3 examples
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:33:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:33:32 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:33:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:33:32 - INFO - __main__ - Printing 3 examples
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:33:32 - INFO - __main__ - ['false']
05/31/2022 07:33:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:33:32 - INFO - __main__ - save last model!
05/31/2022 07:33:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:33:32 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:33:39 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:33:40 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:33:40 - INFO - __main__ - Printing 3 examples
05/31/2022 07:33:40 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:33:40 - INFO - __main__ - ['false']
05/31/2022 07:33:40 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:33:40 - INFO - __main__ - ['false']
05/31/2022 07:33:40 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:33:40 - INFO - __main__ - ['false']
05/31/2022 07:33:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:33:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:33:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:33:43 - INFO - __main__ - Starting training!
05/31/2022 07:33:44 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:34:13 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_13_0.0001_8_predictions.txt
05/31/2022 07:34:13 - INFO - __main__ - Classification-F1 on test data: 0.3278
05/31/2022 07:34:13 - INFO - __main__ - prefix=wiki_qa_32_13, lr=0.0001, bsz=8, dev_performance=0.571619812583668, test_performance=0.32776884553884106
05/31/2022 07:34:13 - INFO - __main__ - Running ... prefix=wiki_qa_32_21, lr=0.0005, bsz=8 ...
05/31/2022 07:34:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:34:14 - INFO - __main__ - Printing 3 examples
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:34:14 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:34:14 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:34:14 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:34:14 - INFO - __main__ - Printing 3 examples
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:34:14 - INFO - __main__ - ['false']
05/31/2022 07:34:14 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:34:14 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:34:14 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:34:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:34:26 - INFO - __main__ - Starting training!
05/31/2022 07:34:30 - INFO - __main__ - Step 10 Global step 10 Train loss 22.140604 on epoch=2
05/31/2022 07:34:35 - INFO - __main__ - Step 20 Global step 20 Train loss 17.157486 on epoch=4
05/31/2022 07:34:40 - INFO - __main__ - Step 30 Global step 30 Train loss 15.211853 on epoch=7
05/31/2022 07:34:45 - INFO - __main__ - Step 40 Global step 40 Train loss 13.906012 on epoch=9
05/31/2022 07:34:50 - INFO - __main__ - Step 50 Global step 50 Train loss 7.549495 on epoch=12
05/31/2022 07:34:51 - INFO - __main__ - Global step 50 Train loss 15.193089 Classification-F1 0.3333333333333333 on epoch=12
05/31/2022 07:34:56 - INFO - __main__ - Step 60 Global step 60 Train loss 1.858119 on epoch=14
05/31/2022 07:35:01 - INFO - __main__ - Step 70 Global step 70 Train loss 0.493417 on epoch=17
05/31/2022 07:35:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.274546 on epoch=19
05/31/2022 07:35:11 - INFO - __main__ - Step 90 Global step 90 Train loss 0.197325 on epoch=22
05/31/2022 07:35:16 - INFO - __main__ - Step 100 Global step 100 Train loss 0.337651 on epoch=24
05/31/2022 07:35:17 - INFO - __main__ - Global step 100 Train loss 0.632212 Classification-F1 0.6061538461538463 on epoch=24
05/31/2022 07:35:23 - INFO - __main__ - Step 110 Global step 110 Train loss 0.054241 on epoch=27
05/31/2022 07:35:27 - INFO - __main__ - Step 120 Global step 120 Train loss 0.025826 on epoch=29
05/31/2022 07:35:32 - INFO - __main__ - Step 130 Global step 130 Train loss 0.044079 on epoch=32
05/31/2022 07:35:37 - INFO - __main__ - Step 140 Global step 140 Train loss 0.015918 on epoch=34
05/31/2022 07:35:42 - INFO - __main__ - Step 150 Global step 150 Train loss 0.003890 on epoch=37
05/31/2022 07:35:43 - INFO - __main__ - Global step 150 Train loss 0.028791 Classification-F1 0.6437246963562753 on epoch=37
05/31/2022 07:35:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.008503 on epoch=39
05/31/2022 07:35:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.003117 on epoch=42
05/31/2022 07:35:58 - INFO - __main__ - Step 180 Global step 180 Train loss 0.001062 on epoch=44
05/31/2022 07:36:03 - INFO - __main__ - Step 190 Global step 190 Train loss 0.001150 on epoch=47
05/31/2022 07:36:08 - INFO - __main__ - Step 200 Global step 200 Train loss 0.001114 on epoch=49
05/31/2022 07:36:09 - INFO - __main__ - Global step 200 Train loss 0.002989 Classification-F1 0.6476476476476476 on epoch=49
05/31/2022 07:36:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.002050 on epoch=52
05/31/2022 07:36:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.001237 on epoch=54
05/31/2022 07:36:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.000402 on epoch=57
05/31/2022 07:36:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.000520 on epoch=59
05/31/2022 07:36:35 - INFO - __main__ - Step 250 Global step 250 Train loss 0.000934 on epoch=62
05/31/2022 07:36:35 - INFO - __main__ - Global step 250 Train loss 0.001029 Classification-F1 0.6618867924528302 on epoch=62
05/31/2022 07:36:41 - INFO - __main__ - Step 260 Global step 260 Train loss 0.000525 on epoch=64
05/31/2022 07:36:46 - INFO - __main__ - Step 270 Global step 270 Train loss 0.067368 on epoch=67
05/31/2022 07:36:51 - INFO - __main__ - Step 280 Global step 280 Train loss 1.287278 on epoch=69
05/31/2022 07:36:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.971702 on epoch=72
05/31/2022 07:37:01 - INFO - __main__ - Step 300 Global step 300 Train loss 0.576356 on epoch=74
05/31/2022 07:37:01 - INFO - __main__ - Global step 300 Train loss 0.580646 Classification-F1 0.47885474126608885 on epoch=74
05/31/2022 07:37:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.212776 on epoch=77
05/31/2022 07:37:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.019144 on epoch=79
05/31/2022 07:37:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.004478 on epoch=82
05/31/2022 07:37:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.003454 on epoch=84
05/31/2022 07:37:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.001720 on epoch=87
05/31/2022 07:37:27 - INFO - __main__ - Global step 350 Train loss 0.048314 Classification-F1 0.5974842767295597 on epoch=87
05/31/2022 07:37:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.001070 on epoch=89
05/31/2022 07:37:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.000702 on epoch=92
05/31/2022 07:37:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.000609 on epoch=94
05/31/2022 07:37:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.001167 on epoch=97
05/31/2022 07:37:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.000397 on epoch=99
05/31/2022 07:37:52 - INFO - __main__ - Global step 400 Train loss 0.000789 Classification-F1 0.6251591545709192 on epoch=99
05/31/2022 07:37:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.000479 on epoch=102
05/31/2022 07:38:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.000406 on epoch=104
05/31/2022 07:38:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.000504 on epoch=107
05/31/2022 07:38:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.000236 on epoch=109
05/31/2022 07:38:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.000318 on epoch=112
05/31/2022 07:38:18 - INFO - __main__ - Global step 450 Train loss 0.000388 Classification-F1 0.6251591545709192 on epoch=112
05/31/2022 07:38:23 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000304 on epoch=114
05/31/2022 07:38:28 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000219 on epoch=117
05/31/2022 07:38:33 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000260 on epoch=119
05/31/2022 07:38:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000170 on epoch=122
05/31/2022 07:38:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000326 on epoch=124
05/31/2022 07:38:43 - INFO - __main__ - Global step 500 Train loss 0.000256 Classification-F1 0.6251591545709192 on epoch=124
05/31/2022 07:38:48 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000565 on epoch=127
05/31/2022 07:38:53 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000114 on epoch=129
05/31/2022 07:38:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000161 on epoch=132
05/31/2022 07:39:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000119 on epoch=134
05/31/2022 07:39:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000097 on epoch=137
05/31/2022 07:39:09 - INFO - __main__ - Global step 550 Train loss 0.000211 Classification-F1 0.6251591545709192 on epoch=137
05/31/2022 07:39:14 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000469 on epoch=139
05/31/2022 07:39:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000087 on epoch=142
05/31/2022 07:39:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000134 on epoch=144
05/31/2022 07:39:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000050 on epoch=147
05/31/2022 07:39:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000081 on epoch=149
05/31/2022 07:39:34 - INFO - __main__ - Global step 600 Train loss 0.000164 Classification-F1 0.6476476476476476 on epoch=149
05/31/2022 07:39:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000099 on epoch=152
05/31/2022 07:39:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000032 on epoch=154
05/31/2022 07:39:49 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000080 on epoch=157
05/31/2022 07:39:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000042 on epoch=159
05/31/2022 07:39:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000080 on epoch=162
05/31/2022 07:40:00 - INFO - __main__ - Global step 650 Train loss 0.000067 Classification-F1 0.6113360323886641 on epoch=162
05/31/2022 07:40:05 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000046 on epoch=164
05/31/2022 07:40:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000021 on epoch=167
05/31/2022 07:40:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000057 on epoch=169
05/31/2022 07:40:20 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000022 on epoch=172
05/31/2022 07:40:25 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000019 on epoch=174
05/31/2022 07:40:25 - INFO - __main__ - Global step 700 Train loss 0.000033 Classification-F1 0.6113360323886641 on epoch=174
05/31/2022 07:40:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000021 on epoch=177
05/31/2022 07:40:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000033 on epoch=179
05/31/2022 07:40:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000044 on epoch=182
05/31/2022 07:40:46 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000020 on epoch=184
05/31/2022 07:40:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000018 on epoch=187
05/31/2022 07:40:51 - INFO - __main__ - Global step 750 Train loss 0.000027 Classification-F1 0.6251591545709192 on epoch=187
05/31/2022 07:40:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000023 on epoch=189
05/31/2022 07:41:01 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000012 on epoch=192
05/31/2022 07:41:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000020 on epoch=194
05/31/2022 07:41:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000030 on epoch=197
05/31/2022 07:41:17 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000077 on epoch=199
05/31/2022 07:41:17 - INFO - __main__ - Global step 800 Train loss 0.000032 Classification-F1 0.6251591545709192 on epoch=199
05/31/2022 07:41:22 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000010 on epoch=202
05/31/2022 07:41:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000012 on epoch=204
05/31/2022 07:41:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000032 on epoch=207
05/31/2022 07:41:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000026 on epoch=209
05/31/2022 07:41:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000045 on epoch=212
05/31/2022 07:41:43 - INFO - __main__ - Global step 850 Train loss 0.000025 Classification-F1 0.6251591545709192 on epoch=212
05/31/2022 07:41:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000012 on epoch=214
05/31/2022 07:41:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000009 on epoch=217
05/31/2022 07:41:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000006 on epoch=219
05/31/2022 07:42:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000014 on epoch=222
05/31/2022 07:42:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000013 on epoch=224
05/31/2022 07:42:08 - INFO - __main__ - Global step 900 Train loss 0.000011 Classification-F1 0.6296855345911949 on epoch=224
05/31/2022 07:42:13 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000015 on epoch=227
05/31/2022 07:42:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000031 on epoch=229
05/31/2022 07:42:23 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000010 on epoch=232
05/31/2022 07:42:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000011 on epoch=234
05/31/2022 07:42:33 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000014 on epoch=237
05/31/2022 07:42:34 - INFO - __main__ - Global step 950 Train loss 0.000016 Classification-F1 0.6251591545709192 on epoch=237
05/31/2022 07:42:39 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000015 on epoch=239
05/31/2022 07:42:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000008 on epoch=242
05/31/2022 07:42:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000004 on epoch=244
05/31/2022 07:42:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000005 on epoch=247
05/31/2022 07:42:59 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000009 on epoch=249
05/31/2022 07:43:00 - INFO - __main__ - Global step 1000 Train loss 0.000008 Classification-F1 0.6251591545709192 on epoch=249
05/31/2022 07:43:00 - INFO - __main__ - save last model!
05/31/2022 07:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:43:00 - INFO - __main__ - Printing 3 examples
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:43:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:43:00 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:43:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:43:00 - INFO - __main__ - Printing 3 examples
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:43:00 - INFO - __main__ - ['false']
05/31/2022 07:43:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:43:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:43:00 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:43:07 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:43:07 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:43:07 - INFO - __main__ - Printing 3 examples
05/31/2022 07:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:43:07 - INFO - __main__ - ['false']
05/31/2022 07:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:43:07 - INFO - __main__ - ['false']
05/31/2022 07:43:07 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:43:07 - INFO - __main__ - ['false']
05/31/2022 07:43:07 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:43:09 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:43:11 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:43:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:43:13 - INFO - __main__ - Starting training!
05/31/2022 07:43:40 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_21_0.0005_8_predictions.txt
05/31/2022 07:43:40 - INFO - __main__ - Classification-F1 on test data: 0.3581
05/31/2022 07:43:40 - INFO - __main__ - prefix=wiki_qa_32_21, lr=0.0005, bsz=8, dev_performance=0.6618867924528302, test_performance=0.3581047750029529
05/31/2022 07:43:40 - INFO - __main__ - Running ... prefix=wiki_qa_32_21, lr=0.0003, bsz=8 ...
05/31/2022 07:43:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:43:41 - INFO - __main__ - Printing 3 examples
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:43:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:43:41 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:43:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:43:41 - INFO - __main__ - Printing 3 examples
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:43:41 - INFO - __main__ - ['false']
05/31/2022 07:43:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:43:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:43:41 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:43:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:43:53 - INFO - __main__ - Starting training!
05/31/2022 07:43:58 - INFO - __main__ - Step 10 Global step 10 Train loss 22.636564 on epoch=2
05/31/2022 07:44:03 - INFO - __main__ - Step 20 Global step 20 Train loss 18.635357 on epoch=4
05/31/2022 07:44:08 - INFO - __main__ - Step 30 Global step 30 Train loss 17.398632 on epoch=7
05/31/2022 07:44:13 - INFO - __main__ - Step 40 Global step 40 Train loss 15.745067 on epoch=9
05/31/2022 07:44:18 - INFO - __main__ - Step 50 Global step 50 Train loss 14.588404 on epoch=12
05/31/2022 07:44:27 - INFO - __main__ - Global step 50 Train loss 17.800804 Classification-F1 0.0 on epoch=12
05/31/2022 07:44:33 - INFO - __main__ - Step 60 Global step 60 Train loss 12.802910 on epoch=14
05/31/2022 07:44:38 - INFO - __main__ - Step 70 Global step 70 Train loss 5.044930 on epoch=17
05/31/2022 07:44:43 - INFO - __main__ - Step 80 Global step 80 Train loss 1.292862 on epoch=19
05/31/2022 07:44:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.178465 on epoch=22
05/31/2022 07:44:53 - INFO - __main__ - Step 100 Global step 100 Train loss 0.449546 on epoch=24
05/31/2022 07:44:54 - INFO - __main__ - Global step 100 Train loss 4.153742 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 07:45:00 - INFO - __main__ - Step 110 Global step 110 Train loss 0.391064 on epoch=27
05/31/2022 07:45:05 - INFO - __main__ - Step 120 Global step 120 Train loss 0.455853 on epoch=29
05/31/2022 07:45:10 - INFO - __main__ - Step 130 Global step 130 Train loss 0.367332 on epoch=32
05/31/2022 07:45:15 - INFO - __main__ - Step 140 Global step 140 Train loss 0.280369 on epoch=34
05/31/2022 07:45:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.364103 on epoch=37
05/31/2022 07:45:21 - INFO - __main__ - Global step 150 Train loss 0.371744 Classification-F1 0.5835835835835835 on epoch=37
05/31/2022 07:45:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.187029 on epoch=39
05/31/2022 07:45:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.121713 on epoch=42
05/31/2022 07:45:37 - INFO - __main__ - Step 180 Global step 180 Train loss 0.034446 on epoch=44
05/31/2022 07:45:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.042575 on epoch=47
05/31/2022 07:45:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.046876 on epoch=49
05/31/2022 07:45:48 - INFO - __main__ - Global step 200 Train loss 0.086528 Classification-F1 0.3671451355661882 on epoch=49
05/31/2022 07:45:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.608155 on epoch=52
05/31/2022 07:45:59 - INFO - __main__ - Step 220 Global step 220 Train loss 1.363892 on epoch=54
05/31/2022 07:46:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.686025 on epoch=57
05/31/2022 07:46:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.521760 on epoch=59
05/31/2022 07:46:15 - INFO - __main__ - Step 250 Global step 250 Train loss 0.385924 on epoch=62
05/31/2022 07:46:25 - INFO - __main__ - Global step 250 Train loss 0.713151 Classification-F1 0.2175438596491228 on epoch=62
05/31/2022 07:46:30 - INFO - __main__ - Step 260 Global step 260 Train loss 0.438905 on epoch=64
05/31/2022 07:46:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.513073 on epoch=67
05/31/2022 07:46:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.172938 on epoch=69
05/31/2022 07:46:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.140963 on epoch=72
05/31/2022 07:46:51 - INFO - __main__ - Step 300 Global step 300 Train loss 0.368793 on epoch=74
05/31/2022 07:46:51 - INFO - __main__ - Global step 300 Train loss 0.326934 Classification-F1 0.5038759689922481 on epoch=74
05/31/2022 07:46:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.309936 on epoch=77
05/31/2022 07:47:02 - INFO - __main__ - Step 320 Global step 320 Train loss 0.201506 on epoch=79
05/31/2022 07:47:07 - INFO - __main__ - Step 330 Global step 330 Train loss 0.562275 on epoch=82
05/31/2022 07:47:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.239475 on epoch=84
05/31/2022 07:47:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.293743 on epoch=87
05/31/2022 07:47:18 - INFO - __main__ - Global step 350 Train loss 0.321387 Classification-F1 0.47813194959229055 on epoch=87
05/31/2022 07:47:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.190894 on epoch=89
05/31/2022 07:47:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.220469 on epoch=92
05/31/2022 07:47:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.149178 on epoch=94
05/31/2022 07:47:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.117075 on epoch=97
05/31/2022 07:47:43 - INFO - __main__ - Step 400 Global step 400 Train loss 0.116685 on epoch=99
05/31/2022 07:47:44 - INFO - __main__ - Global step 400 Train loss 0.158860 Classification-F1 0.5021607605877269 on epoch=99
05/31/2022 07:47:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.086662 on epoch=102
05/31/2022 07:47:54 - INFO - __main__ - Step 420 Global step 420 Train loss 0.135929 on epoch=104
05/31/2022 07:48:00 - INFO - __main__ - Step 430 Global step 430 Train loss 0.299706 on epoch=107
05/31/2022 07:48:05 - INFO - __main__ - Step 440 Global step 440 Train loss 0.123576 on epoch=109
05/31/2022 07:48:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.177579 on epoch=112
05/31/2022 07:48:11 - INFO - __main__ - Global step 450 Train loss 0.164690 Classification-F1 0.4493927125506073 on epoch=112
05/31/2022 07:48:16 - INFO - __main__ - Step 460 Global step 460 Train loss 0.090214 on epoch=114
05/31/2022 07:48:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.108014 on epoch=117
05/31/2022 07:48:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.094045 on epoch=119
05/31/2022 07:48:31 - INFO - __main__ - Step 490 Global step 490 Train loss 0.097725 on epoch=122
05/31/2022 07:48:36 - INFO - __main__ - Step 500 Global step 500 Train loss 0.053241 on epoch=124
05/31/2022 07:48:37 - INFO - __main__ - Global step 500 Train loss 0.088648 Classification-F1 0.4817813765182186 on epoch=124
05/31/2022 07:48:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.127711 on epoch=127
05/31/2022 07:48:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.066098 on epoch=129
05/31/2022 07:48:53 - INFO - __main__ - Step 530 Global step 530 Train loss 0.072773 on epoch=132
05/31/2022 07:48:58 - INFO - __main__ - Step 540 Global step 540 Train loss 0.012498 on epoch=134
05/31/2022 07:49:03 - INFO - __main__ - Step 550 Global step 550 Train loss 0.032006 on epoch=137
05/31/2022 07:49:04 - INFO - __main__ - Global step 550 Train loss 0.062217 Classification-F1 0.5696139476961395 on epoch=137
05/31/2022 07:49:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.010698 on epoch=139
05/31/2022 07:49:14 - INFO - __main__ - Step 570 Global step 570 Train loss 0.033146 on epoch=142
05/31/2022 07:49:19 - INFO - __main__ - Step 580 Global step 580 Train loss 0.014775 on epoch=144
05/31/2022 07:49:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.023940 on epoch=147
05/31/2022 07:49:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.010943 on epoch=149
05/31/2022 07:49:30 - INFO - __main__ - Global step 600 Train loss 0.018700 Classification-F1 0.6069761729304839 on epoch=149
05/31/2022 07:49:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.010255 on epoch=152
05/31/2022 07:49:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000933 on epoch=154
05/31/2022 07:49:46 - INFO - __main__ - Step 630 Global step 630 Train loss 0.011304 on epoch=157
05/31/2022 07:49:51 - INFO - __main__ - Step 640 Global step 640 Train loss 0.077855 on epoch=159
05/31/2022 07:49:56 - INFO - __main__ - Step 650 Global step 650 Train loss 0.017000 on epoch=162
05/31/2022 07:49:57 - INFO - __main__ - Global step 650 Train loss 0.023469 Classification-F1 0.24417960088691798 on epoch=162
05/31/2022 07:50:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.007458 on epoch=164
05/31/2022 07:50:07 - INFO - __main__ - Step 670 Global step 670 Train loss 0.031460 on epoch=167
05/31/2022 07:50:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.002901 on epoch=169
05/31/2022 07:50:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.002522 on epoch=172
05/31/2022 07:50:23 - INFO - __main__ - Step 700 Global step 700 Train loss 0.016059 on epoch=174
05/31/2022 07:50:23 - INFO - __main__ - Global step 700 Train loss 0.012080 Classification-F1 0.43712273641851107 on epoch=174
05/31/2022 07:50:29 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001528 on epoch=177
05/31/2022 07:50:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.018431 on epoch=179
05/31/2022 07:50:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.002986 on epoch=182
05/31/2022 07:50:44 - INFO - __main__ - Step 740 Global step 740 Train loss 0.005013 on epoch=184
05/31/2022 07:50:49 - INFO - __main__ - Step 750 Global step 750 Train loss 0.011282 on epoch=187
05/31/2022 07:50:50 - INFO - __main__ - Global step 750 Train loss 0.007848 Classification-F1 0.2923096382494308 on epoch=187
05/31/2022 07:50:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001228 on epoch=189
05/31/2022 07:51:00 - INFO - __main__ - Step 770 Global step 770 Train loss 0.004515 on epoch=192
05/31/2022 07:51:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.003473 on epoch=194
05/31/2022 07:51:10 - INFO - __main__ - Step 790 Global step 790 Train loss 0.004541 on epoch=197
05/31/2022 07:51:16 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004813 on epoch=199
05/31/2022 07:51:16 - INFO - __main__ - Global step 800 Train loss 0.003714 Classification-F1 0.3222222222222222 on epoch=199
05/31/2022 07:51:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.069907 on epoch=202
05/31/2022 07:51:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.006091 on epoch=204
05/31/2022 07:51:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000586 on epoch=207
05/31/2022 07:51:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000374 on epoch=209
05/31/2022 07:51:42 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000850 on epoch=212
05/31/2022 07:51:43 - INFO - __main__ - Global step 850 Train loss 0.015562 Classification-F1 0.5097603162836669 on epoch=212
05/31/2022 07:51:48 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000556 on epoch=214
05/31/2022 07:51:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.007214 on epoch=217
05/31/2022 07:51:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.001539 on epoch=219
05/31/2022 07:52:03 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001194 on epoch=222
05/31/2022 07:52:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000925 on epoch=224
05/31/2022 07:52:09 - INFO - __main__ - Global step 900 Train loss 0.002286 Classification-F1 0.5974842767295597 on epoch=224
05/31/2022 07:52:14 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000422 on epoch=227
05/31/2022 07:52:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000636 on epoch=229
05/31/2022 07:52:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.039816 on epoch=232
05/31/2022 07:52:29 - INFO - __main__ - Step 940 Global step 940 Train loss 0.241402 on epoch=234
05/31/2022 07:52:35 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000530 on epoch=237
05/31/2022 07:52:35 - INFO - __main__ - Global step 950 Train loss 0.056561 Classification-F1 0.42291347951725305 on epoch=237
05/31/2022 07:52:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.005981 on epoch=239
05/31/2022 07:52:46 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000619 on epoch=242
05/31/2022 07:52:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000982 on epoch=244
05/31/2022 07:52:56 - INFO - __main__ - Step 990 Global step 990 Train loss 0.025411 on epoch=247
05/31/2022 07:53:01 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.021345 on epoch=249
05/31/2022 07:53:02 - INFO - __main__ - Global step 1000 Train loss 0.010868 Classification-F1 0.5273745861981156 on epoch=249
05/31/2022 07:53:02 - INFO - __main__ - save last model!
05/31/2022 07:53:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:53:02 - INFO - __main__ - Printing 3 examples
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:53:02 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:53:02 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:53:02 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:53:02 - INFO - __main__ - Printing 3 examples
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:53:02 - INFO - __main__ - ['false']
05/31/2022 07:53:02 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:53:02 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:53:02 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:53:08 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 07:53:09 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 07:53:09 - INFO - __main__ - Printing 3 examples
05/31/2022 07:53:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 07:53:09 - INFO - __main__ - ['false']
05/31/2022 07:53:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 07:53:09 - INFO - __main__ - ['false']
05/31/2022 07:53:09 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 07:53:09 - INFO - __main__ - ['false']
05/31/2022 07:53:09 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:53:10 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:53:13 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 07:53:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:53:13 - INFO - __main__ - Starting training!
05/31/2022 07:53:42 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_21_0.0003_8_predictions.txt
05/31/2022 07:53:42 - INFO - __main__ - Classification-F1 on test data: 0.1048
05/31/2022 07:53:43 - INFO - __main__ - prefix=wiki_qa_32_21, lr=0.0003, bsz=8, dev_performance=0.6069761729304839, test_performance=0.1048360314637737
05/31/2022 07:53:43 - INFO - __main__ - Running ... prefix=wiki_qa_32_21, lr=0.0002, bsz=8 ...
05/31/2022 07:53:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:53:44 - INFO - __main__ - Printing 3 examples
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:53:44 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:53:44 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 07:53:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 07:53:44 - INFO - __main__ - Printing 3 examples
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 07:53:44 - INFO - __main__ - ['false']
05/31/2022 07:53:44 - INFO - __main__ - Tokenizing Input ...
05/31/2022 07:53:44 - INFO - __main__ - Tokenizing Output ...
05/31/2022 07:53:44 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 07:53:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 07:53:56 - INFO - __main__ - Starting training!
05/31/2022 07:54:00 - INFO - __main__ - Step 10 Global step 10 Train loss 24.160849 on epoch=2
05/31/2022 07:54:05 - INFO - __main__ - Step 20 Global step 20 Train loss 19.201399 on epoch=4
05/31/2022 07:54:10 - INFO - __main__ - Step 30 Global step 30 Train loss 18.659069 on epoch=7
05/31/2022 07:54:15 - INFO - __main__ - Step 40 Global step 40 Train loss 16.584518 on epoch=9
05/31/2022 07:54:20 - INFO - __main__ - Step 50 Global step 50 Train loss 16.447258 on epoch=12
05/31/2022 07:54:31 - INFO - __main__ - Global step 50 Train loss 19.010618 Classification-F1 0.0 on epoch=12
05/31/2022 07:54:37 - INFO - __main__ - Step 60 Global step 60 Train loss 15.313498 on epoch=14
05/31/2022 07:54:42 - INFO - __main__ - Step 70 Global step 70 Train loss 14.639954 on epoch=17
05/31/2022 07:54:47 - INFO - __main__ - Step 80 Global step 80 Train loss 13.168935 on epoch=19
05/31/2022 07:54:52 - INFO - __main__ - Step 90 Global step 90 Train loss 13.007655 on epoch=22
05/31/2022 07:54:57 - INFO - __main__ - Step 100 Global step 100 Train loss 9.049582 on epoch=24
05/31/2022 07:54:58 - INFO - __main__ - Global step 100 Train loss 13.035925 Classification-F1 0.22880712037338538 on epoch=24
05/31/2022 07:55:03 - INFO - __main__ - Step 110 Global step 110 Train loss 2.787587 on epoch=27
05/31/2022 07:55:08 - INFO - __main__ - Step 120 Global step 120 Train loss 2.513599 on epoch=29
05/31/2022 07:55:13 - INFO - __main__ - Step 130 Global step 130 Train loss 0.922872 on epoch=32
05/31/2022 07:55:18 - INFO - __main__ - Step 140 Global step 140 Train loss 0.477541 on epoch=34
05/31/2022 07:55:23 - INFO - __main__ - Step 150 Global step 150 Train loss 0.547720 on epoch=37
05/31/2022 07:55:23 - INFO - __main__ - Global step 150 Train loss 1.449864 Classification-F1 0.5921568627450979 on epoch=37
05/31/2022 07:55:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.484938 on epoch=39
05/31/2022 07:55:34 - INFO - __main__ - Step 170 Global step 170 Train loss 0.562570 on epoch=42
05/31/2022 07:55:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.390141 on epoch=44
05/31/2022 07:55:44 - INFO - __main__ - Step 190 Global step 190 Train loss 0.441298 on epoch=47
05/31/2022 07:55:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.440259 on epoch=49
05/31/2022 07:55:50 - INFO - __main__ - Global step 200 Train loss 0.463841 Classification-F1 0.3511520737327189 on epoch=49
05/31/2022 07:55:55 - INFO - __main__ - Step 210 Global step 210 Train loss 0.367569 on epoch=52
05/31/2022 07:56:00 - INFO - __main__ - Step 220 Global step 220 Train loss 0.428599 on epoch=54
05/31/2022 07:56:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.411769 on epoch=57
05/31/2022 07:56:10 - INFO - __main__ - Step 240 Global step 240 Train loss 0.413931 on epoch=59
05/31/2022 07:56:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.381834 on epoch=62
05/31/2022 07:56:16 - INFO - __main__ - Global step 250 Train loss 0.400740 Classification-F1 0.3671451355661882 on epoch=62
05/31/2022 07:56:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.377345 on epoch=64
05/31/2022 07:56:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.402159 on epoch=67
05/31/2022 07:56:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.398384 on epoch=69
05/31/2022 07:56:37 - INFO - __main__ - Step 290 Global step 290 Train loss 0.401100 on epoch=72
05/31/2022 07:56:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.370082 on epoch=74
05/31/2022 07:56:43 - INFO - __main__ - Global step 300 Train loss 0.389814 Classification-F1 0.429800307219662 on epoch=74
05/31/2022 07:56:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.369887 on epoch=77
05/31/2022 07:56:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.373560 on epoch=79
05/31/2022 07:56:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.447249 on epoch=82
05/31/2022 07:57:03 - INFO - __main__ - Step 340 Global step 340 Train loss 0.486732 on epoch=84
05/31/2022 07:57:08 - INFO - __main__ - Step 350 Global step 350 Train loss 0.356224 on epoch=87
05/31/2022 07:57:18 - INFO - __main__ - Global step 350 Train loss 0.406730 Classification-F1 0.2911297852474323 on epoch=87
05/31/2022 07:57:23 - INFO - __main__ - Step 360 Global step 360 Train loss 0.368313 on epoch=89
05/31/2022 07:57:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.433612 on epoch=92
05/31/2022 07:57:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.355792 on epoch=94
05/31/2022 07:57:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.414276 on epoch=97
05/31/2022 07:57:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.355988 on epoch=99
05/31/2022 07:57:52 - INFO - __main__ - Global step 400 Train loss 0.385596 Classification-F1 0.4385964912280702 on epoch=99
05/31/2022 07:57:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.447643 on epoch=102
05/31/2022 07:58:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.392792 on epoch=104
05/31/2022 07:58:08 - INFO - __main__ - Step 430 Global step 430 Train loss 0.370538 on epoch=107
05/31/2022 07:58:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.417890 on epoch=109
05/31/2022 07:58:18 - INFO - __main__ - Step 450 Global step 450 Train loss 0.360120 on epoch=112
05/31/2022 07:58:19 - INFO - __main__ - Global step 450 Train loss 0.397797 Classification-F1 0.45440454662877805 on epoch=112
05/31/2022 07:58:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.370277 on epoch=114
05/31/2022 07:58:29 - INFO - __main__ - Step 470 Global step 470 Train loss 0.344178 on epoch=117
05/31/2022 07:58:34 - INFO - __main__ - Step 480 Global step 480 Train loss 0.350288 on epoch=119
05/31/2022 07:58:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.330518 on epoch=122
05/31/2022 07:58:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.379385 on epoch=124
05/31/2022 07:58:45 - INFO - __main__ - Global step 500 Train loss 0.354929 Classification-F1 0.3816425120772947 on epoch=124
05/31/2022 07:58:50 - INFO - __main__ - Step 510 Global step 510 Train loss 0.321023 on epoch=127
05/31/2022 07:58:55 - INFO - __main__ - Step 520 Global step 520 Train loss 0.388907 on epoch=129
05/31/2022 07:59:00 - INFO - __main__ - Step 530 Global step 530 Train loss 0.339198 on epoch=132
05/31/2022 07:59:05 - INFO - __main__ - Step 540 Global step 540 Train loss 0.346580 on epoch=134
05/31/2022 07:59:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.351691 on epoch=137
05/31/2022 07:59:11 - INFO - __main__ - Global step 550 Train loss 0.349480 Classification-F1 0.3511520737327189 on epoch=137
05/31/2022 07:59:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.336823 on epoch=139
05/31/2022 07:59:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.332165 on epoch=142
05/31/2022 07:59:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.341136 on epoch=144
05/31/2022 07:59:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.310052 on epoch=147
05/31/2022 07:59:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.322291 on epoch=149
05/31/2022 07:59:38 - INFO - __main__ - Global step 600 Train loss 0.328493 Classification-F1 0.3333333333333333 on epoch=149
05/31/2022 07:59:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.342453 on epoch=152
05/31/2022 07:59:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.274592 on epoch=154
05/31/2022 07:59:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.337462 on epoch=157
05/31/2022 07:59:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.326820 on epoch=159
05/31/2022 08:00:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.318769 on epoch=162
05/31/2022 08:00:13 - INFO - __main__ - Global step 650 Train loss 0.320019 Classification-F1 0.29398148148148145 on epoch=162
05/31/2022 08:00:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.283732 on epoch=164
05/31/2022 08:00:23 - INFO - __main__ - Step 670 Global step 670 Train loss 0.335478 on epoch=167
05/31/2022 08:00:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.280085 on epoch=169
05/31/2022 08:00:33 - INFO - __main__ - Step 690 Global step 690 Train loss 0.277082 on epoch=172
05/31/2022 08:00:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.274905 on epoch=174
05/31/2022 08:00:48 - INFO - __main__ - Global step 700 Train loss 0.290256 Classification-F1 0.3365811965811966 on epoch=174
05/31/2022 08:00:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.317698 on epoch=177
05/31/2022 08:00:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.302460 on epoch=179
05/31/2022 08:01:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.278601 on epoch=182
05/31/2022 08:01:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.292706 on epoch=184
05/31/2022 08:01:13 - INFO - __main__ - Step 750 Global step 750 Train loss 0.319620 on epoch=187
05/31/2022 08:01:23 - INFO - __main__ - Global step 750 Train loss 0.302217 Classification-F1 0.34577114427860695 on epoch=187
05/31/2022 08:01:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.279249 on epoch=189
05/31/2022 08:01:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.269317 on epoch=192
05/31/2022 08:01:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.277161 on epoch=194
05/31/2022 08:01:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.277362 on epoch=197
05/31/2022 08:01:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.258276 on epoch=199
05/31/2022 08:01:59 - INFO - __main__ - Global step 800 Train loss 0.272273 Classification-F1 0.35415625520573046 on epoch=199
05/31/2022 08:02:04 - INFO - __main__ - Step 810 Global step 810 Train loss 0.232550 on epoch=202
05/31/2022 08:02:09 - INFO - __main__ - Step 820 Global step 820 Train loss 0.190749 on epoch=204
05/31/2022 08:02:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.233385 on epoch=207
05/31/2022 08:02:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.274508 on epoch=209
05/31/2022 08:02:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.334222 on epoch=212
05/31/2022 08:02:25 - INFO - __main__ - Global step 850 Train loss 0.253083 Classification-F1 0.5272229822161423 on epoch=212
05/31/2022 08:02:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.305095 on epoch=214
05/31/2022 08:02:35 - INFO - __main__ - Step 870 Global step 870 Train loss 0.179715 on epoch=217
05/31/2022 08:02:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.203904 on epoch=219
05/31/2022 08:02:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.148925 on epoch=222
05/31/2022 08:02:50 - INFO - __main__ - Step 900 Global step 900 Train loss 0.181945 on epoch=224
05/31/2022 08:02:51 - INFO - __main__ - Global step 900 Train loss 0.203917 Classification-F1 0.5555555555555556 on epoch=224
05/31/2022 08:02:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.142604 on epoch=227
05/31/2022 08:03:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.196673 on epoch=229
05/31/2022 08:03:06 - INFO - __main__ - Step 930 Global step 930 Train loss 0.086453 on epoch=232
05/31/2022 08:03:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.204546 on epoch=234
05/31/2022 08:03:16 - INFO - __main__ - Step 950 Global step 950 Train loss 0.127348 on epoch=237
05/31/2022 08:03:17 - INFO - __main__ - Global step 950 Train loss 0.151525 Classification-F1 0.5270935960591133 on epoch=237
05/31/2022 08:03:22 - INFO - __main__ - Step 960 Global step 960 Train loss 0.152650 on epoch=239
05/31/2022 08:03:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.070224 on epoch=242
05/31/2022 08:03:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.086330 on epoch=244
05/31/2022 08:03:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.091734 on epoch=247
05/31/2022 08:03:42 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.101504 on epoch=249
05/31/2022 08:03:43 - INFO - __main__ - Global step 1000 Train loss 0.100488 Classification-F1 0.4202898550724638 on epoch=249
05/31/2022 08:03:43 - INFO - __main__ - save last model!
05/31/2022 08:03:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:03:44 - INFO - __main__ - Printing 3 examples
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:03:44 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:03:44 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:03:44 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:03:44 - INFO - __main__ - Printing 3 examples
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 08:03:44 - INFO - __main__ - ['false']
05/31/2022 08:03:44 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:03:44 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:03:44 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:03:50 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:03:51 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:03:51 - INFO - __main__ - Printing 3 examples
05/31/2022 08:03:51 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:03:51 - INFO - __main__ - ['false']
05/31/2022 08:03:51 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:03:51 - INFO - __main__ - ['false']
05/31/2022 08:03:51 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:03:51 - INFO - __main__ - ['false']
05/31/2022 08:03:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:03:52 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:03:55 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:03:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:03:57 - INFO - __main__ - Starting training!
05/31/2022 08:04:23 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_21_0.0002_8_predictions.txt
05/31/2022 08:04:23 - INFO - __main__ - Classification-F1 on test data: 0.2396
05/31/2022 08:04:23 - INFO - __main__ - prefix=wiki_qa_32_21, lr=0.0002, bsz=8, dev_performance=0.5921568627450979, test_performance=0.23958919717555097
05/31/2022 08:04:23 - INFO - __main__ - Running ... prefix=wiki_qa_32_21, lr=0.0001, bsz=8 ...
05/31/2022 08:04:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:04:24 - INFO - __main__ - Printing 3 examples
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: how fire extinguisher works [SEP] answer: Typically, a fire extinguisher consists of a hand-held cylindrical pressure vessel containing an agent which can be discharged to extinguish a fire .
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: what is another name for cpu [SEP] answer: The term has been in use in the computer industry at least since the early 1960s.
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: what is vitamin a for [SEP] answer: In foods of animal origin, the major form of vitamin A is an ester , primarily retinyl palmitate , which is converted to retinol (chemically an alcohol ) in the small intestine.
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:04:24 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:04:24 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:04:24 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:04:24 - INFO - __main__ - Printing 3 examples
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: how many redwall books are there [SEP] answer: Redwall, by Brian Jacques , is a series of children's fantasy novels.
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: how are glacier caves formed? [SEP] answer: A partly submerged glacier cave on Perito Moreno Glacier .
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ -  [wiki_qa] question: how many 1969 dodge coronets were made? [SEP] answer: In the 1960s, the name was transferred to Dodge's mid-size entry.
05/31/2022 08:04:24 - INFO - __main__ - ['false']
05/31/2022 08:04:24 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:04:24 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:04:24 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:04:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:04:36 - INFO - __main__ - Starting training!
05/31/2022 08:04:40 - INFO - __main__ - Step 10 Global step 10 Train loss 23.361893 on epoch=2
05/31/2022 08:04:45 - INFO - __main__ - Step 20 Global step 20 Train loss 20.716841 on epoch=4
05/31/2022 08:04:50 - INFO - __main__ - Step 30 Global step 30 Train loss 19.182932 on epoch=7
05/31/2022 08:04:55 - INFO - __main__ - Step 40 Global step 40 Train loss 17.937969 on epoch=9
05/31/2022 08:05:00 - INFO - __main__ - Step 50 Global step 50 Train loss 17.239262 on epoch=12
05/31/2022 08:05:09 - INFO - __main__ - Global step 50 Train loss 19.687780 Classification-F1 0.0 on epoch=12
05/31/2022 08:05:15 - INFO - __main__ - Step 60 Global step 60 Train loss 16.831564 on epoch=14
05/31/2022 08:05:20 - INFO - __main__ - Step 70 Global step 70 Train loss 16.463490 on epoch=17
05/31/2022 08:05:25 - INFO - __main__ - Step 80 Global step 80 Train loss 16.403311 on epoch=19
05/31/2022 08:05:30 - INFO - __main__ - Step 90 Global step 90 Train loss 16.887146 on epoch=22
05/31/2022 08:05:35 - INFO - __main__ - Step 100 Global step 100 Train loss 16.167133 on epoch=24
05/31/2022 08:05:46 - INFO - __main__ - Global step 100 Train loss 16.550529 Classification-F1 0.0 on epoch=24
05/31/2022 08:05:51 - INFO - __main__ - Step 110 Global step 110 Train loss 14.795552 on epoch=27
05/31/2022 08:05:56 - INFO - __main__ - Step 120 Global step 120 Train loss 15.434206 on epoch=29
05/31/2022 08:06:01 - INFO - __main__ - Step 130 Global step 130 Train loss 14.980969 on epoch=32
05/31/2022 08:06:06 - INFO - __main__ - Step 140 Global step 140 Train loss 14.135916 on epoch=34
05/31/2022 08:06:11 - INFO - __main__ - Step 150 Global step 150 Train loss 13.771548 on epoch=37
05/31/2022 08:06:21 - INFO - __main__ - Global step 150 Train loss 14.623639 Classification-F1 0.0 on epoch=37
05/31/2022 08:06:26 - INFO - __main__ - Step 160 Global step 160 Train loss 12.083103 on epoch=39
05/31/2022 08:06:31 - INFO - __main__ - Step 170 Global step 170 Train loss 12.896370 on epoch=42
05/31/2022 08:06:36 - INFO - __main__ - Step 180 Global step 180 Train loss 11.795547 on epoch=44
05/31/2022 08:06:41 - INFO - __main__ - Step 190 Global step 190 Train loss 10.536393 on epoch=47
05/31/2022 08:06:46 - INFO - __main__ - Step 200 Global step 200 Train loss 8.702818 on epoch=49
05/31/2022 08:06:47 - INFO - __main__ - Global step 200 Train loss 11.202847 Classification-F1 0.05263157894736842 on epoch=49
05/31/2022 08:06:52 - INFO - __main__ - Step 210 Global step 210 Train loss 2.758543 on epoch=52
05/31/2022 08:06:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.992486 on epoch=54
05/31/2022 08:07:03 - INFO - __main__ - Step 230 Global step 230 Train loss 0.723561 on epoch=57
05/31/2022 08:07:08 - INFO - __main__ - Step 240 Global step 240 Train loss 0.684954 on epoch=59
05/31/2022 08:07:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.531049 on epoch=62
05/31/2022 08:07:13 - INFO - __main__ - Global step 250 Train loss 1.138118 Classification-F1 0.39047619047619053 on epoch=62
05/31/2022 08:07:19 - INFO - __main__ - Step 260 Global step 260 Train loss 0.496239 on epoch=64
05/31/2022 08:07:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.483173 on epoch=67
05/31/2022 08:07:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.493615 on epoch=69
05/31/2022 08:07:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.577199 on epoch=72
05/31/2022 08:07:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.398643 on epoch=74
05/31/2022 08:07:40 - INFO - __main__ - Global step 300 Train loss 0.489774 Classification-F1 0.551443790299972 on epoch=74
05/31/2022 08:07:45 - INFO - __main__ - Step 310 Global step 310 Train loss 0.406295 on epoch=77
05/31/2022 08:07:50 - INFO - __main__ - Step 320 Global step 320 Train loss 0.470024 on epoch=79
05/31/2022 08:07:56 - INFO - __main__ - Step 330 Global step 330 Train loss 0.619298 on epoch=82
05/31/2022 08:08:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.393618 on epoch=84
05/31/2022 08:08:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.550312 on epoch=87
05/31/2022 08:08:06 - INFO - __main__ - Global step 350 Train loss 0.487910 Classification-F1 0.6156156156156156 on epoch=87
05/31/2022 08:08:12 - INFO - __main__ - Step 360 Global step 360 Train loss 0.268390 on epoch=89
05/31/2022 08:08:17 - INFO - __main__ - Step 370 Global step 370 Train loss 0.337778 on epoch=92
05/31/2022 08:08:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.291023 on epoch=94
05/31/2022 08:08:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.287859 on epoch=97
05/31/2022 08:08:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.315600 on epoch=99
05/31/2022 08:08:33 - INFO - __main__ - Global step 400 Train loss 0.300130 Classification-F1 0.6995305164319249 on epoch=99
05/31/2022 08:08:38 - INFO - __main__ - Step 410 Global step 410 Train loss 0.342595 on epoch=102
05/31/2022 08:08:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.298446 on epoch=104
05/31/2022 08:08:48 - INFO - __main__ - Step 430 Global step 430 Train loss 0.224889 on epoch=107
05/31/2022 08:08:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.184823 on epoch=109
05/31/2022 08:08:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.210659 on epoch=112
05/31/2022 08:08:59 - INFO - __main__ - Global step 450 Train loss 0.252282 Classification-F1 0.703052503052503 on epoch=112
05/31/2022 08:09:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.339997 on epoch=114
05/31/2022 08:09:10 - INFO - __main__ - Step 470 Global step 470 Train loss 0.130599 on epoch=117
05/31/2022 08:09:15 - INFO - __main__ - Step 480 Global step 480 Train loss 0.115100 on epoch=119
05/31/2022 08:09:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.136947 on epoch=122
05/31/2022 08:09:25 - INFO - __main__ - Step 500 Global step 500 Train loss 0.107936 on epoch=124
05/31/2022 08:09:26 - INFO - __main__ - Global step 500 Train loss 0.166116 Classification-F1 0.5021607605877269 on epoch=124
05/31/2022 08:09:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.108225 on epoch=127
05/31/2022 08:09:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.083530 on epoch=129
05/31/2022 08:09:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.053215 on epoch=132
05/31/2022 08:09:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.058528 on epoch=134
05/31/2022 08:09:51 - INFO - __main__ - Step 550 Global step 550 Train loss 0.039053 on epoch=137
05/31/2022 08:09:52 - INFO - __main__ - Global step 550 Train loss 0.068510 Classification-F1 0.5866701110824076 on epoch=137
05/31/2022 08:09:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.069841 on epoch=139
05/31/2022 08:10:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.033560 on epoch=142
05/31/2022 08:10:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.060308 on epoch=144
05/31/2022 08:10:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.039273 on epoch=147
05/31/2022 08:10:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.040288 on epoch=149
05/31/2022 08:10:18 - INFO - __main__ - Global step 600 Train loss 0.048654 Classification-F1 0.47602339181286546 on epoch=149
05/31/2022 08:10:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.039565 on epoch=152
05/31/2022 08:10:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.036815 on epoch=154
05/31/2022 08:10:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.046834 on epoch=157
05/31/2022 08:10:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.018880 on epoch=159
05/31/2022 08:10:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.031042 on epoch=162
05/31/2022 08:10:44 - INFO - __main__ - Global step 650 Train loss 0.034627 Classification-F1 0.6577540106951872 on epoch=162
05/31/2022 08:10:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.014374 on epoch=164
05/31/2022 08:10:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.013637 on epoch=167
05/31/2022 08:10:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.030494 on epoch=169
05/31/2022 08:11:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.010412 on epoch=172
05/31/2022 08:11:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.005242 on epoch=174
05/31/2022 08:11:10 - INFO - __main__ - Global step 700 Train loss 0.014832 Classification-F1 0.6528028933092225 on epoch=174
05/31/2022 08:11:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.032585 on epoch=177
05/31/2022 08:11:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.010673 on epoch=179
05/31/2022 08:11:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.031500 on epoch=182
05/31/2022 08:11:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.010536 on epoch=184
05/31/2022 08:11:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.004830 on epoch=187
05/31/2022 08:11:35 - INFO - __main__ - Global step 750 Train loss 0.018025 Classification-F1 0.5622435020519836 on epoch=187
05/31/2022 08:11:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.003638 on epoch=189
05/31/2022 08:11:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.005467 on epoch=192
05/31/2022 08:11:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.004059 on epoch=194
05/31/2022 08:11:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.005545 on epoch=197
05/31/2022 08:12:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.002250 on epoch=199
05/31/2022 08:12:01 - INFO - __main__ - Global step 800 Train loss 0.004192 Classification-F1 0.6577540106951872 on epoch=199
05/31/2022 08:12:06 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002536 on epoch=202
05/31/2022 08:12:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.026047 on epoch=204
05/31/2022 08:12:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.001684 on epoch=207
05/31/2022 08:12:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.004434 on epoch=209
05/31/2022 08:12:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000948 on epoch=212
05/31/2022 08:12:27 - INFO - __main__ - Global step 850 Train loss 0.007130 Classification-F1 0.6577540106951872 on epoch=212
05/31/2022 08:12:32 - INFO - __main__ - Step 860 Global step 860 Train loss 0.003407 on epoch=214
05/31/2022 08:12:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000879 on epoch=217
05/31/2022 08:12:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.005283 on epoch=219
05/31/2022 08:12:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001874 on epoch=222
05/31/2022 08:12:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001829 on epoch=224
05/31/2022 08:12:53 - INFO - __main__ - Global step 900 Train loss 0.002654 Classification-F1 0.6666666666666667 on epoch=224
05/31/2022 08:12:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.005053 on epoch=227
05/31/2022 08:13:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.001208 on epoch=229
05/31/2022 08:13:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.006768 on epoch=232
05/31/2022 08:13:13 - INFO - __main__ - Step 940 Global step 940 Train loss 0.007662 on epoch=234
05/31/2022 08:13:18 - INFO - __main__ - Step 950 Global step 950 Train loss 0.010641 on epoch=237
05/31/2022 08:13:19 - INFO - __main__ - Global step 950 Train loss 0.006266 Classification-F1 0.6666666666666667 on epoch=237
05/31/2022 08:13:24 - INFO - __main__ - Step 960 Global step 960 Train loss 0.001448 on epoch=239
05/31/2022 08:13:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001106 on epoch=242
05/31/2022 08:13:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000569 on epoch=244
05/31/2022 08:13:39 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001043 on epoch=247
05/31/2022 08:13:44 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000420 on epoch=249
05/31/2022 08:13:45 - INFO - __main__ - Global step 1000 Train loss 0.000917 Classification-F1 0.6469661150512215 on epoch=249
05/31/2022 08:13:45 - INFO - __main__ - save last model!
05/31/2022 08:13:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:13:46 - INFO - __main__ - Printing 3 examples
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:13:46 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:13:46 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:13:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:13:46 - INFO - __main__ - Printing 3 examples
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:13:46 - INFO - __main__ - ['false']
05/31/2022 08:13:46 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:13:46 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:13:46 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:13:52 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:13:52 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:13:52 - INFO - __main__ - Printing 3 examples
05/31/2022 08:13:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:13:52 - INFO - __main__ - ['false']
05/31/2022 08:13:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:13:52 - INFO - __main__ - ['false']
05/31/2022 08:13:52 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:13:52 - INFO - __main__ - ['false']
05/31/2022 08:13:52 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:13:54 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:13:56 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:13:57 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:13:57 - INFO - __main__ - Starting training!
05/31/2022 08:14:25 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_21_0.0001_8_predictions.txt
05/31/2022 08:14:25 - INFO - __main__ - Classification-F1 on test data: 0.3118
05/31/2022 08:14:25 - INFO - __main__ - prefix=wiki_qa_32_21, lr=0.0001, bsz=8, dev_performance=0.703052503052503, test_performance=0.3117968422914124
05/31/2022 08:14:25 - INFO - __main__ - Running ... prefix=wiki_qa_32_42, lr=0.0005, bsz=8 ...
05/31/2022 08:14:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:14:26 - INFO - __main__ - Printing 3 examples
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:14:26 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:14:26 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:14:26 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:14:26 - INFO - __main__ - Printing 3 examples
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:14:26 - INFO - __main__ - ['false']
05/31/2022 08:14:26 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:14:26 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:14:26 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:14:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:14:38 - INFO - __main__ - Starting training!
05/31/2022 08:14:42 - INFO - __main__ - Step 10 Global step 10 Train loss 22.977955 on epoch=2
05/31/2022 08:14:47 - INFO - __main__ - Step 20 Global step 20 Train loss 17.213432 on epoch=4
05/31/2022 08:14:52 - INFO - __main__ - Step 30 Global step 30 Train loss 15.486156 on epoch=7
05/31/2022 08:14:57 - INFO - __main__ - Step 40 Global step 40 Train loss 13.827330 on epoch=9
05/31/2022 08:15:02 - INFO - __main__ - Step 50 Global step 50 Train loss 5.989923 on epoch=12
05/31/2022 08:15:03 - INFO - __main__ - Global step 50 Train loss 15.098959 Classification-F1 0.3591989987484355 on epoch=12
05/31/2022 08:15:08 - INFO - __main__ - Step 60 Global step 60 Train loss 3.971630 on epoch=14
05/31/2022 08:15:13 - INFO - __main__ - Step 70 Global step 70 Train loss 0.758522 on epoch=17
05/31/2022 08:15:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.715223 on epoch=19
05/31/2022 08:15:23 - INFO - __main__ - Step 90 Global step 90 Train loss 0.421143 on epoch=22
05/31/2022 08:15:28 - INFO - __main__ - Step 100 Global step 100 Train loss 0.394963 on epoch=24
05/31/2022 08:15:29 - INFO - __main__ - Global step 100 Train loss 1.252296 Classification-F1 0.4330011074197121 on epoch=24
05/31/2022 08:15:35 - INFO - __main__ - Step 110 Global step 110 Train loss 0.447116 on epoch=27
05/31/2022 08:15:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.608610 on epoch=29
05/31/2022 08:15:45 - INFO - __main__ - Step 130 Global step 130 Train loss 0.399380 on epoch=32
05/31/2022 08:15:50 - INFO - __main__ - Step 140 Global step 140 Train loss 0.456902 on epoch=34
05/31/2022 08:15:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.302115 on epoch=37
05/31/2022 08:15:55 - INFO - __main__ - Global step 150 Train loss 0.442825 Classification-F1 0.3671451355661882 on epoch=37
05/31/2022 08:16:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.371125 on epoch=39
05/31/2022 08:16:06 - INFO - __main__ - Step 170 Global step 170 Train loss 0.295039 on epoch=42
05/31/2022 08:16:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.249602 on epoch=44
05/31/2022 08:16:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.203265 on epoch=47
05/31/2022 08:16:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.254084 on epoch=49
05/31/2022 08:16:21 - INFO - __main__ - Global step 200 Train loss 0.274623 Classification-F1 0.46843853820598 on epoch=49
05/31/2022 08:16:27 - INFO - __main__ - Step 210 Global step 210 Train loss 0.222554 on epoch=52
05/31/2022 08:16:32 - INFO - __main__ - Step 220 Global step 220 Train loss 0.082907 on epoch=54
05/31/2022 08:16:37 - INFO - __main__ - Step 230 Global step 230 Train loss 0.053957 on epoch=57
05/31/2022 08:16:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.034717 on epoch=59
05/31/2022 08:16:47 - INFO - __main__ - Step 250 Global step 250 Train loss 0.035229 on epoch=62
05/31/2022 08:16:48 - INFO - __main__ - Global step 250 Train loss 0.085873 Classification-F1 0.6085148030340103 on epoch=62
05/31/2022 08:16:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.028393 on epoch=64
05/31/2022 08:16:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.010075 on epoch=67
05/31/2022 08:17:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.062679 on epoch=69
05/31/2022 08:17:09 - INFO - __main__ - Step 290 Global step 290 Train loss 0.150109 on epoch=72
05/31/2022 08:17:14 - INFO - __main__ - Step 300 Global step 300 Train loss 0.200626 on epoch=74
05/31/2022 08:17:14 - INFO - __main__ - Global step 300 Train loss 0.090376 Classification-F1 0.5145583557621727 on epoch=74
05/31/2022 08:17:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.012907 on epoch=77
05/31/2022 08:17:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.009147 on epoch=79
05/31/2022 08:17:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.013355 on epoch=82
05/31/2022 08:17:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.010941 on epoch=84
05/31/2022 08:17:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.003729 on epoch=87
05/31/2022 08:17:40 - INFO - __main__ - Global step 350 Train loss 0.010016 Classification-F1 0.5097603162836669 on epoch=87
05/31/2022 08:17:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.007048 on epoch=89
05/31/2022 08:17:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.003566 on epoch=92
05/31/2022 08:17:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.018163 on epoch=94
05/31/2022 08:18:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.073077 on epoch=97
05/31/2022 08:18:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.008994 on epoch=99
05/31/2022 08:18:06 - INFO - __main__ - Global step 400 Train loss 0.022170 Classification-F1 0.4980392156862745 on epoch=99
05/31/2022 08:18:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.008602 on epoch=102
05/31/2022 08:18:16 - INFO - __main__ - Step 420 Global step 420 Train loss 0.014508 on epoch=104
05/31/2022 08:18:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.014306 on epoch=107
05/31/2022 08:18:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.008659 on epoch=109
05/31/2022 08:18:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.002569 on epoch=112
05/31/2022 08:18:32 - INFO - __main__ - Global step 450 Train loss 0.009729 Classification-F1 0.5155592935239698 on epoch=112
05/31/2022 08:18:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.103183 on epoch=114
05/31/2022 08:18:42 - INFO - __main__ - Step 470 Global step 470 Train loss 0.001257 on epoch=117
05/31/2022 08:18:47 - INFO - __main__ - Step 480 Global step 480 Train loss 0.001030 on epoch=119
05/31/2022 08:18:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002008 on epoch=122
05/31/2022 08:18:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000553 on epoch=124
05/31/2022 08:18:58 - INFO - __main__ - Global step 500 Train loss 0.021606 Classification-F1 0.4980392156862745 on epoch=124
05/31/2022 08:19:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000414 on epoch=127
05/31/2022 08:19:08 - INFO - __main__ - Step 520 Global step 520 Train loss 0.003295 on epoch=129
05/31/2022 08:19:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000734 on epoch=132
05/31/2022 08:19:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.001057 on epoch=134
05/31/2022 08:19:23 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000643 on epoch=137
05/31/2022 08:19:24 - INFO - __main__ - Global step 550 Train loss 0.001228 Classification-F1 0.4995112414467253 on epoch=137
05/31/2022 08:19:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000295 on epoch=139
05/31/2022 08:19:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000182 on epoch=142
05/31/2022 08:19:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000374 on epoch=144
05/31/2022 08:19:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000232 on epoch=147
05/31/2022 08:19:48 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000430 on epoch=149
05/31/2022 08:19:49 - INFO - __main__ - Global step 600 Train loss 0.000303 Classification-F1 0.4980392156862745 on epoch=149
05/31/2022 08:19:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000116 on epoch=152
05/31/2022 08:19:59 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000253 on epoch=154
05/31/2022 08:20:04 - INFO - __main__ - Step 630 Global step 630 Train loss 0.001724 on epoch=157
05/31/2022 08:20:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000046 on epoch=159
05/31/2022 08:20:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000226 on epoch=162
05/31/2022 08:20:14 - INFO - __main__ - Global step 650 Train loss 0.000473 Classification-F1 0.46666666666666656 on epoch=162
05/31/2022 08:20:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000076 on epoch=164
05/31/2022 08:20:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001886 on epoch=167
05/31/2022 08:20:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.022281 on epoch=169
05/31/2022 08:20:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.001181 on epoch=172
05/31/2022 08:20:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000274 on epoch=174
05/31/2022 08:20:40 - INFO - __main__ - Global step 700 Train loss 0.005140 Classification-F1 0.5873015873015872 on epoch=174
05/31/2022 08:20:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001382 on epoch=177
05/31/2022 08:20:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000531 on epoch=179
05/31/2022 08:20:54 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000711 on epoch=182
05/31/2022 08:20:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000455 on epoch=184
05/31/2022 08:21:04 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000094 on epoch=187
05/31/2022 08:21:05 - INFO - __main__ - Global step 750 Train loss 0.000634 Classification-F1 0.5097603162836669 on epoch=187
05/31/2022 08:21:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000144 on epoch=189
05/31/2022 08:21:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000114 on epoch=192
05/31/2022 08:21:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000458 on epoch=194
05/31/2022 08:21:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000122 on epoch=197
05/31/2022 08:21:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000674 on epoch=199
05/31/2022 08:21:30 - INFO - __main__ - Global step 800 Train loss 0.000302 Classification-F1 0.5155067155067155 on epoch=199
05/31/2022 08:21:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000039 on epoch=202
05/31/2022 08:21:40 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000064 on epoch=204
05/31/2022 08:21:45 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000023 on epoch=207
05/31/2022 08:21:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000150 on epoch=209
05/31/2022 08:21:55 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000037 on epoch=212
05/31/2022 08:21:56 - INFO - __main__ - Global step 850 Train loss 0.000063 Classification-F1 0.5238095238095238 on epoch=212
05/31/2022 08:22:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000016 on epoch=214
05/31/2022 08:22:06 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000024 on epoch=217
05/31/2022 08:22:11 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000198 on epoch=219
05/31/2022 08:22:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.006463 on epoch=222
05/31/2022 08:22:21 - INFO - __main__ - Step 900 Global step 900 Train loss 0.025638 on epoch=224
05/31/2022 08:22:21 - INFO - __main__ - Global step 900 Train loss 0.006468 Classification-F1 0.3218085106382979 on epoch=224
05/31/2022 08:22:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000567 on epoch=227
05/31/2022 08:22:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000143 on epoch=229
05/31/2022 08:22:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001426 on epoch=232
05/31/2022 08:22:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000616 on epoch=234
05/31/2022 08:22:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000254 on epoch=237
05/31/2022 08:22:47 - INFO - __main__ - Global step 950 Train loss 0.000601 Classification-F1 0.4947797300738477 on epoch=237
05/31/2022 08:22:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000323 on epoch=239
05/31/2022 08:22:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000060 on epoch=242
05/31/2022 08:23:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000097 on epoch=244
05/31/2022 08:23:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000028 on epoch=247
05/31/2022 08:23:12 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000508 on epoch=249
05/31/2022 08:23:12 - INFO - __main__ - Global step 1000 Train loss 0.000203 Classification-F1 0.577195987276731 on epoch=249
05/31/2022 08:23:12 - INFO - __main__ - save last model!
05/31/2022 08:23:13 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:23:13 - INFO - __main__ - Printing 3 examples
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:23:13 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:23:13 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:23:13 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:23:13 - INFO - __main__ - Printing 3 examples
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:23:13 - INFO - __main__ - ['false']
05/31/2022 08:23:13 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:23:13 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:23:13 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:23:19 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:23:20 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:23:20 - INFO - __main__ - Printing 3 examples
05/31/2022 08:23:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:23:20 - INFO - __main__ - ['false']
05/31/2022 08:23:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:23:20 - INFO - __main__ - ['false']
05/31/2022 08:23:20 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:23:20 - INFO - __main__ - ['false']
05/31/2022 08:23:20 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:23:21 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:23:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:23:24 - INFO - __main__ - Starting training!
05/31/2022 08:23:24 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:24:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_42_0.0005_8_predictions.txt
05/31/2022 08:24:02 - INFO - __main__ - Classification-F1 on test data: 0.0742
05/31/2022 08:24:03 - INFO - __main__ - prefix=wiki_qa_32_42, lr=0.0005, bsz=8, dev_performance=0.6085148030340103, test_performance=0.07421534957138727
05/31/2022 08:24:03 - INFO - __main__ - Running ... prefix=wiki_qa_32_42, lr=0.0003, bsz=8 ...
05/31/2022 08:24:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:24:04 - INFO - __main__ - Printing 3 examples
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:24:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:24:04 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:24:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:24:04 - INFO - __main__ - Printing 3 examples
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:24:04 - INFO - __main__ - ['false']
05/31/2022 08:24:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:24:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:24:04 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:24:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:24:16 - INFO - __main__ - Starting training!
05/31/2022 08:24:20 - INFO - __main__ - Step 10 Global step 10 Train loss 23.303844 on epoch=2
05/31/2022 08:24:24 - INFO - __main__ - Step 20 Global step 20 Train loss 19.203299 on epoch=4
05/31/2022 08:24:29 - INFO - __main__ - Step 30 Global step 30 Train loss 17.108143 on epoch=7
05/31/2022 08:24:34 - INFO - __main__ - Step 40 Global step 40 Train loss 16.209723 on epoch=9
05/31/2022 08:24:39 - INFO - __main__ - Step 50 Global step 50 Train loss 14.890680 on epoch=12
05/31/2022 08:24:54 - INFO - __main__ - Global step 50 Train loss 18.143137 Classification-F1 0.0 on epoch=12
05/31/2022 08:25:00 - INFO - __main__ - Step 60 Global step 60 Train loss 13.474484 on epoch=14
05/31/2022 08:25:05 - INFO - __main__ - Step 70 Global step 70 Train loss 10.626085 on epoch=17
05/31/2022 08:25:10 - INFO - __main__ - Step 80 Global step 80 Train loss 2.685727 on epoch=19
05/31/2022 08:25:15 - INFO - __main__ - Step 90 Global step 90 Train loss 0.946641 on epoch=22
05/31/2022 08:25:20 - INFO - __main__ - Step 100 Global step 100 Train loss 0.792402 on epoch=24
05/31/2022 08:25:20 - INFO - __main__ - Global step 100 Train loss 5.705069 Classification-F1 0.4487674487674488 on epoch=24
05/31/2022 08:25:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.991423 on epoch=27
05/31/2022 08:25:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.387939 on epoch=29
05/31/2022 08:25:36 - INFO - __main__ - Step 130 Global step 130 Train loss 0.305261 on epoch=32
05/31/2022 08:25:41 - INFO - __main__ - Step 140 Global step 140 Train loss 0.517393 on epoch=34
05/31/2022 08:25:46 - INFO - __main__ - Step 150 Global step 150 Train loss 0.306013 on epoch=37
05/31/2022 08:25:46 - INFO - __main__ - Global step 150 Train loss 0.501606 Classification-F1 0.5373493975903615 on epoch=37
05/31/2022 08:25:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.285535 on epoch=39
05/31/2022 08:25:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.188896 on epoch=42
05/31/2022 08:26:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.202558 on epoch=44
05/31/2022 08:26:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.145722 on epoch=47
05/31/2022 08:26:12 - INFO - __main__ - Step 200 Global step 200 Train loss 0.095658 on epoch=49
05/31/2022 08:26:13 - INFO - __main__ - Global step 200 Train loss 0.183674 Classification-F1 0.6652552926525529 on epoch=49
05/31/2022 08:26:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.350706 on epoch=52
05/31/2022 08:26:23 - INFO - __main__ - Step 220 Global step 220 Train loss 0.569016 on epoch=54
05/31/2022 08:26:28 - INFO - __main__ - Step 230 Global step 230 Train loss 0.475187 on epoch=57
05/31/2022 08:26:33 - INFO - __main__ - Step 240 Global step 240 Train loss 0.285176 on epoch=59
05/31/2022 08:26:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.247386 on epoch=62
05/31/2022 08:26:39 - INFO - __main__ - Global step 250 Train loss 0.385494 Classification-F1 0.3333333333333333 on epoch=62
05/31/2022 08:26:44 - INFO - __main__ - Step 260 Global step 260 Train loss 0.278721 on epoch=64
05/31/2022 08:26:49 - INFO - __main__ - Step 270 Global step 270 Train loss 0.274626 on epoch=67
05/31/2022 08:26:54 - INFO - __main__ - Step 280 Global step 280 Train loss 0.396413 on epoch=69
05/31/2022 08:26:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.311161 on epoch=72
05/31/2022 08:27:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.268988 on epoch=74
05/31/2022 08:27:05 - INFO - __main__ - Global step 300 Train loss 0.305982 Classification-F1 0.3816425120772947 on epoch=74
05/31/2022 08:27:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.310771 on epoch=77
05/31/2022 08:27:15 - INFO - __main__ - Step 320 Global step 320 Train loss 0.230787 on epoch=79
05/31/2022 08:27:20 - INFO - __main__ - Step 330 Global step 330 Train loss 0.291783 on epoch=82
05/31/2022 08:27:25 - INFO - __main__ - Step 340 Global step 340 Train loss 0.147835 on epoch=84
05/31/2022 08:27:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.237889 on epoch=87
05/31/2022 08:27:30 - INFO - __main__ - Global step 350 Train loss 0.243813 Classification-F1 0.41075141075141075 on epoch=87
05/31/2022 08:27:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.175835 on epoch=89
05/31/2022 08:27:40 - INFO - __main__ - Step 370 Global step 370 Train loss 0.173337 on epoch=92
05/31/2022 08:27:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.113409 on epoch=94
05/31/2022 08:27:50 - INFO - __main__ - Step 390 Global step 390 Train loss 0.074900 on epoch=97
05/31/2022 08:27:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.121896 on epoch=99
05/31/2022 08:27:56 - INFO - __main__ - Global step 400 Train loss 0.131876 Classification-F1 0.4385964912280702 on epoch=99
05/31/2022 08:28:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.094239 on epoch=102
05/31/2022 08:28:06 - INFO - __main__ - Step 420 Global step 420 Train loss 0.257921 on epoch=104
05/31/2022 08:28:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.039982 on epoch=107
05/31/2022 08:28:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.074336 on epoch=109
05/31/2022 08:28:21 - INFO - __main__ - Step 450 Global step 450 Train loss 0.074940 on epoch=112
05/31/2022 08:28:21 - INFO - __main__ - Global step 450 Train loss 0.108284 Classification-F1 0.6190476190476191 on epoch=112
05/31/2022 08:28:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.037875 on epoch=114
05/31/2022 08:28:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.044283 on epoch=117
05/31/2022 08:28:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.055064 on epoch=119
05/31/2022 08:28:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.065333 on epoch=122
05/31/2022 08:28:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.044881 on epoch=124
05/31/2022 08:28:47 - INFO - __main__ - Global step 500 Train loss 0.049487 Classification-F1 0.5373493975903615 on epoch=124
05/31/2022 08:28:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.047443 on epoch=127
05/31/2022 08:28:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.042284 on epoch=129
05/31/2022 08:29:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.060354 on epoch=132
05/31/2022 08:29:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.013431 on epoch=134
05/31/2022 08:29:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.074168 on epoch=137
05/31/2022 08:29:13 - INFO - __main__ - Global step 550 Train loss 0.047536 Classification-F1 0.5730170496664195 on epoch=137
05/31/2022 08:29:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.025619 on epoch=139
05/31/2022 08:29:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.012289 on epoch=142
05/31/2022 08:29:28 - INFO - __main__ - Step 580 Global step 580 Train loss 0.036132 on epoch=144
05/31/2022 08:29:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.009311 on epoch=147
05/31/2022 08:29:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.010842 on epoch=149
05/31/2022 08:29:38 - INFO - __main__ - Global step 600 Train loss 0.018839 Classification-F1 0.5901477832512315 on epoch=149
05/31/2022 08:29:43 - INFO - __main__ - Step 610 Global step 610 Train loss 0.051133 on epoch=152
05/31/2022 08:29:48 - INFO - __main__ - Step 620 Global step 620 Train loss 0.027838 on epoch=154
05/31/2022 08:29:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.050944 on epoch=157
05/31/2022 08:29:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.007253 on epoch=159
05/31/2022 08:30:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.003087 on epoch=162
05/31/2022 08:30:04 - INFO - __main__ - Global step 650 Train loss 0.028051 Classification-F1 0.6014943960149439 on epoch=162
05/31/2022 08:30:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.020099 on epoch=164
05/31/2022 08:30:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.010307 on epoch=167
05/31/2022 08:30:19 - INFO - __main__ - Step 680 Global step 680 Train loss 0.012275 on epoch=169
05/31/2022 08:30:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.017980 on epoch=172
05/31/2022 08:30:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.072298 on epoch=174
05/31/2022 08:30:30 - INFO - __main__ - Global step 700 Train loss 0.026592 Classification-F1 0.38714090287277697 on epoch=174
05/31/2022 08:30:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002803 on epoch=177
05/31/2022 08:30:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.051455 on epoch=179
05/31/2022 08:30:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.001605 on epoch=182
05/31/2022 08:30:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.001541 on epoch=184
05/31/2022 08:30:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.002351 on epoch=187
05/31/2022 08:30:56 - INFO - __main__ - Global step 750 Train loss 0.011951 Classification-F1 0.4812085482682388 on epoch=187
05/31/2022 08:31:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.013765 on epoch=189
05/31/2022 08:31:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.048306 on epoch=192
05/31/2022 08:31:11 - INFO - __main__ - Step 780 Global step 780 Train loss 0.001748 on epoch=194
05/31/2022 08:31:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.009705 on epoch=197
05/31/2022 08:31:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004188 on epoch=199
05/31/2022 08:31:21 - INFO - __main__ - Global step 800 Train loss 0.015542 Classification-F1 0.5607843137254902 on epoch=199
05/31/2022 08:31:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000809 on epoch=202
05/31/2022 08:31:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000445 on epoch=204
05/31/2022 08:31:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.001069 on epoch=207
05/31/2022 08:31:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001088 on epoch=209
05/31/2022 08:31:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000882 on epoch=212
05/31/2022 08:31:47 - INFO - __main__ - Global step 850 Train loss 0.000859 Classification-F1 0.5097603162836669 on epoch=212
05/31/2022 08:31:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000395 on epoch=214
05/31/2022 08:31:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.003908 on epoch=217
05/31/2022 08:32:02 - INFO - __main__ - Step 880 Global step 880 Train loss 0.014840 on epoch=219
05/31/2022 08:32:07 - INFO - __main__ - Step 890 Global step 890 Train loss 0.003834 on epoch=222
05/31/2022 08:32:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.038920 on epoch=224
05/31/2022 08:32:13 - INFO - __main__ - Global step 900 Train loss 0.012379 Classification-F1 0.5465587044534412 on epoch=224
05/31/2022 08:32:18 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000492 on epoch=227
05/31/2022 08:32:23 - INFO - __main__ - Step 920 Global step 920 Train loss 0.002011 on epoch=229
05/31/2022 08:32:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000502 on epoch=232
05/31/2022 08:32:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.001050 on epoch=234
05/31/2022 08:32:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001642 on epoch=237
05/31/2022 08:32:39 - INFO - __main__ - Global step 950 Train loss 0.001140 Classification-F1 0.5458771715194519 on epoch=237
05/31/2022 08:32:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000341 on epoch=239
05/31/2022 08:32:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000470 on epoch=242
05/31/2022 08:32:53 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001200 on epoch=244
05/31/2022 08:32:58 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000489 on epoch=247
05/31/2022 08:33:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000440 on epoch=249
05/31/2022 08:33:04 - INFO - __main__ - Global step 1000 Train loss 0.000588 Classification-F1 0.5625 on epoch=249
05/31/2022 08:33:04 - INFO - __main__ - save last model!
05/31/2022 08:33:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:33:04 - INFO - __main__ - Printing 3 examples
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:33:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:33:04 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:33:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:33:04 - INFO - __main__ - Printing 3 examples
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:33:04 - INFO - __main__ - ['false']
05/31/2022 08:33:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:33:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:33:05 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:33:11 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:33:12 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:33:12 - INFO - __main__ - Printing 3 examples
05/31/2022 08:33:12 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:33:12 - INFO - __main__ - ['false']
05/31/2022 08:33:12 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:33:12 - INFO - __main__ - ['false']
05/31/2022 08:33:12 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:33:12 - INFO - __main__ - ['false']
05/31/2022 08:33:12 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:33:13 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:33:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:33:15 - INFO - __main__ - Starting training!
05/31/2022 08:33:16 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:33:44 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_42_0.0003_8_predictions.txt
05/31/2022 08:33:44 - INFO - __main__ - Classification-F1 on test data: 0.3502
05/31/2022 08:33:45 - INFO - __main__ - prefix=wiki_qa_32_42, lr=0.0003, bsz=8, dev_performance=0.6652552926525529, test_performance=0.3502194974908507
05/31/2022 08:33:45 - INFO - __main__ - Running ... prefix=wiki_qa_32_42, lr=0.0002, bsz=8 ...
05/31/2022 08:33:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:33:46 - INFO - __main__ - Printing 3 examples
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:33:46 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:33:46 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:33:46 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:33:46 - INFO - __main__ - Printing 3 examples
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:33:46 - INFO - __main__ - ['false']
05/31/2022 08:33:46 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:33:46 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:33:46 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:33:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:33:58 - INFO - __main__ - Starting training!
05/31/2022 08:34:02 - INFO - __main__ - Step 10 Global step 10 Train loss 22.679077 on epoch=2
05/31/2022 08:34:07 - INFO - __main__ - Step 20 Global step 20 Train loss 19.555206 on epoch=4
05/31/2022 08:34:12 - INFO - __main__ - Step 30 Global step 30 Train loss 17.801809 on epoch=7
05/31/2022 08:34:17 - INFO - __main__ - Step 40 Global step 40 Train loss 16.599630 on epoch=9
05/31/2022 08:34:22 - INFO - __main__ - Step 50 Global step 50 Train loss 15.615575 on epoch=12
05/31/2022 08:34:33 - INFO - __main__ - Global step 50 Train loss 18.450258 Classification-F1 0.0 on epoch=12
05/31/2022 08:34:39 - INFO - __main__ - Step 60 Global step 60 Train loss 15.641546 on epoch=14
05/31/2022 08:34:44 - INFO - __main__ - Step 70 Global step 70 Train loss 15.349406 on epoch=17
05/31/2022 08:34:49 - INFO - __main__ - Step 80 Global step 80 Train loss 13.978661 on epoch=19
05/31/2022 08:34:54 - INFO - __main__ - Step 90 Global step 90 Train loss 13.350182 on epoch=22
05/31/2022 08:34:59 - INFO - __main__ - Step 100 Global step 100 Train loss 11.701156 on epoch=24
05/31/2022 08:35:05 - INFO - __main__ - Global step 100 Train loss 14.004190 Classification-F1 0.0 on epoch=24
05/31/2022 08:35:10 - INFO - __main__ - Step 110 Global step 110 Train loss 9.264047 on epoch=27
05/31/2022 08:35:15 - INFO - __main__ - Step 120 Global step 120 Train loss 3.038523 on epoch=29
05/31/2022 08:35:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.666912 on epoch=32
05/31/2022 08:35:25 - INFO - __main__ - Step 140 Global step 140 Train loss 0.543010 on epoch=34
05/31/2022 08:35:30 - INFO - __main__ - Step 150 Global step 150 Train loss 0.538622 on epoch=37
05/31/2022 08:35:31 - INFO - __main__ - Global step 150 Train loss 2.810223 Classification-F1 0.3591989987484355 on epoch=37
05/31/2022 08:35:36 - INFO - __main__ - Step 160 Global step 160 Train loss 0.338823 on epoch=39
05/31/2022 08:35:41 - INFO - __main__ - Step 170 Global step 170 Train loss 0.327624 on epoch=42
05/31/2022 08:35:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.221536 on epoch=44
05/31/2022 08:35:51 - INFO - __main__ - Step 190 Global step 190 Train loss 0.216212 on epoch=47
05/31/2022 08:35:56 - INFO - __main__ - Step 200 Global step 200 Train loss 0.115172 on epoch=49
05/31/2022 08:35:57 - INFO - __main__ - Global step 200 Train loss 0.243873 Classification-F1 0.4545454545454546 on epoch=49
05/31/2022 08:36:03 - INFO - __main__ - Step 210 Global step 210 Train loss 0.129601 on epoch=52
05/31/2022 08:36:08 - INFO - __main__ - Step 220 Global step 220 Train loss 0.147074 on epoch=54
05/31/2022 08:36:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.082401 on epoch=57
05/31/2022 08:36:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.056233 on epoch=59
05/31/2022 08:36:23 - INFO - __main__ - Step 250 Global step 250 Train loss 0.139133 on epoch=62
05/31/2022 08:36:23 - INFO - __main__ - Global step 250 Train loss 0.110889 Classification-F1 0.5373493975903615 on epoch=62
05/31/2022 08:36:29 - INFO - __main__ - Step 260 Global step 260 Train loss 0.046885 on epoch=64
05/31/2022 08:36:34 - INFO - __main__ - Step 270 Global step 270 Train loss 0.077815 on epoch=67
05/31/2022 08:36:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.021908 on epoch=69
05/31/2022 08:36:44 - INFO - __main__ - Step 290 Global step 290 Train loss 0.014405 on epoch=72
05/31/2022 08:36:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.008029 on epoch=74
05/31/2022 08:36:50 - INFO - __main__ - Global step 300 Train loss 0.033809 Classification-F1 0.6971357409713574 on epoch=74
05/31/2022 08:36:55 - INFO - __main__ - Step 310 Global step 310 Train loss 0.038009 on epoch=77
05/31/2022 08:37:00 - INFO - __main__ - Step 320 Global step 320 Train loss 0.005285 on epoch=79
05/31/2022 08:37:05 - INFO - __main__ - Step 330 Global step 330 Train loss 0.011642 on epoch=82
05/31/2022 08:37:10 - INFO - __main__ - Step 340 Global step 340 Train loss 0.008483 on epoch=84
05/31/2022 08:37:15 - INFO - __main__ - Step 350 Global step 350 Train loss 0.011858 on epoch=87
05/31/2022 08:37:16 - INFO - __main__ - Global step 350 Train loss 0.015055 Classification-F1 0.41075141075141075 on epoch=87
05/31/2022 08:37:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.001448 on epoch=89
05/31/2022 08:37:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.069708 on epoch=92
05/31/2022 08:37:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.075820 on epoch=94
05/31/2022 08:37:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.008024 on epoch=97
05/31/2022 08:37:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.019339 on epoch=99
05/31/2022 08:37:41 - INFO - __main__ - Global step 400 Train loss 0.034868 Classification-F1 0.5925642984466514 on epoch=99
05/31/2022 08:37:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.003001 on epoch=102
05/31/2022 08:37:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.001264 on epoch=104
05/31/2022 08:37:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.001264 on epoch=107
05/31/2022 08:38:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.000275 on epoch=109
05/31/2022 08:38:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.012690 on epoch=112
05/31/2022 08:38:07 - INFO - __main__ - Global step 450 Train loss 0.003699 Classification-F1 0.5038759689922481 on epoch=112
05/31/2022 08:38:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.003176 on epoch=114
05/31/2022 08:38:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000642 on epoch=117
05/31/2022 08:38:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.000418 on epoch=119
05/31/2022 08:38:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.001250 on epoch=122
05/31/2022 08:38:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.001250 on epoch=124
05/31/2022 08:38:32 - INFO - __main__ - Global step 500 Train loss 0.001347 Classification-F1 0.5497835497835498 on epoch=124
05/31/2022 08:38:37 - INFO - __main__ - Step 510 Global step 510 Train loss 0.001517 on epoch=127
05/31/2022 08:38:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.020602 on epoch=129
05/31/2022 08:38:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.011073 on epoch=132
05/31/2022 08:38:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000874 on epoch=134
05/31/2022 08:38:57 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000643 on epoch=137
05/31/2022 08:38:58 - INFO - __main__ - Global step 550 Train loss 0.006942 Classification-F1 0.6679021497405486 on epoch=137
05/31/2022 08:39:03 - INFO - __main__ - Step 560 Global step 560 Train loss 0.001544 on epoch=139
05/31/2022 08:39:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000337 on epoch=142
05/31/2022 08:39:13 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000590 on epoch=144
05/31/2022 08:39:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.003773 on epoch=147
05/31/2022 08:39:23 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000355 on epoch=149
05/31/2022 08:39:23 - INFO - __main__ - Global step 600 Train loss 0.001320 Classification-F1 0.6862745098039216 on epoch=149
05/31/2022 08:39:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000743 on epoch=152
05/31/2022 08:39:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.143880 on epoch=154
05/31/2022 08:39:38 - INFO - __main__ - Step 630 Global step 630 Train loss 0.002007 on epoch=157
05/31/2022 08:39:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.004214 on epoch=159
05/31/2022 08:39:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.006516 on epoch=162
05/31/2022 08:39:49 - INFO - __main__ - Global step 650 Train loss 0.031472 Classification-F1 0.7013018914271678 on epoch=162
05/31/2022 08:39:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.004852 on epoch=164
05/31/2022 08:40:00 - INFO - __main__ - Step 670 Global step 670 Train loss 0.005057 on epoch=167
05/31/2022 08:40:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000904 on epoch=169
05/31/2022 08:40:10 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000447 on epoch=172
05/31/2022 08:40:15 - INFO - __main__ - Step 700 Global step 700 Train loss 0.001404 on epoch=174
05/31/2022 08:40:15 - INFO - __main__ - Global step 700 Train loss 0.002533 Classification-F1 0.7142857142857143 on epoch=174
05/31/2022 08:40:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000460 on epoch=177
05/31/2022 08:40:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000111 on epoch=179
05/31/2022 08:40:31 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000294 on epoch=182
05/31/2022 08:40:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.012843 on epoch=184
05/31/2022 08:40:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000919 on epoch=187
05/31/2022 08:40:42 - INFO - __main__ - Global step 750 Train loss 0.002925 Classification-F1 0.6405372405372406 on epoch=187
05/31/2022 08:40:47 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000214 on epoch=189
05/31/2022 08:40:52 - INFO - __main__ - Step 770 Global step 770 Train loss 0.001385 on epoch=192
05/31/2022 08:40:57 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000284 on epoch=194
05/31/2022 08:41:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000115 on epoch=197
05/31/2022 08:41:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000203 on epoch=199
05/31/2022 08:41:07 - INFO - __main__ - Global step 800 Train loss 0.000440 Classification-F1 0.7290161892901619 on epoch=199
05/31/2022 08:41:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.022596 on epoch=202
05/31/2022 08:41:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.007327 on epoch=204
05/31/2022 08:41:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000093 on epoch=207
05/31/2022 08:41:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000202 on epoch=209
05/31/2022 08:41:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000060 on epoch=212
05/31/2022 08:41:34 - INFO - __main__ - Global step 850 Train loss 0.006055 Classification-F1 0.716256157635468 on epoch=212
05/31/2022 08:41:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000083 on epoch=214
05/31/2022 08:41:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000183 on epoch=217
05/31/2022 08:41:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000251 on epoch=219
05/31/2022 08:41:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000107 on epoch=222
05/31/2022 08:41:58 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000169 on epoch=224
05/31/2022 08:41:59 - INFO - __main__ - Global step 900 Train loss 0.000159 Classification-F1 0.6995305164319249 on epoch=224
05/31/2022 08:42:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000671 on epoch=227
05/31/2022 08:42:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000092 on epoch=229
05/31/2022 08:42:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000076 on epoch=232
05/31/2022 08:42:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000467 on epoch=234
05/31/2022 08:42:24 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000253 on epoch=237
05/31/2022 08:42:25 - INFO - __main__ - Global step 950 Train loss 0.000312 Classification-F1 0.7013018914271678 on epoch=237
05/31/2022 08:42:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000066 on epoch=239
05/31/2022 08:42:35 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000071 on epoch=242
05/31/2022 08:42:40 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001713 on epoch=244
05/31/2022 08:42:45 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000052 on epoch=247
05/31/2022 08:42:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000043 on epoch=249
05/31/2022 08:42:50 - INFO - __main__ - Global step 1000 Train loss 0.000389 Classification-F1 0.716256157635468 on epoch=249
05/31/2022 08:42:50 - INFO - __main__ - save last model!
05/31/2022 08:42:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:42:51 - INFO - __main__ - Printing 3 examples
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:42:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:42:51 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:42:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:42:51 - INFO - __main__ - Printing 3 examples
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:42:51 - INFO - __main__ - ['false']
05/31/2022 08:42:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:42:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:42:51 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:42:57 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:42:58 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:42:58 - INFO - __main__ - Printing 3 examples
05/31/2022 08:42:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:42:58 - INFO - __main__ - ['false']
05/31/2022 08:42:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:42:58 - INFO - __main__ - ['false']
05/31/2022 08:42:58 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:42:58 - INFO - __main__ - ['false']
05/31/2022 08:42:58 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:42:59 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:43:02 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:43:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:43:04 - INFO - __main__ - Starting training!
05/31/2022 08:43:31 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_42_0.0002_8_predictions.txt
05/31/2022 08:43:31 - INFO - __main__ - Classification-F1 on test data: 0.3432
05/31/2022 08:43:31 - INFO - __main__ - prefix=wiki_qa_32_42, lr=0.0002, bsz=8, dev_performance=0.7290161892901619, test_performance=0.34317568428211964
05/31/2022 08:43:31 - INFO - __main__ - Running ... prefix=wiki_qa_32_42, lr=0.0001, bsz=8 ...
05/31/2022 08:43:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:43:32 - INFO - __main__ - Printing 3 examples
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: who is leaving criminal minds [SEP] answer: Criminal Minds is an American police procedural television program that premiered September 22, 2005, on CBS .
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: how many states have open carry gun laws [SEP] answer: This has been marked by a number of organized events intended to increase the visibility of open carry and public awareness about the practice.
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: how many countries have english as an official language [SEP] answer: Notable exceptions include Rwanda , which was a former Belgian colony and Eritrea , which was an Italian colony where the British Empire spanned its control only in World War II and shortly after( 1941-1952).
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:43:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:43:32 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:43:32 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:43:32 - INFO - __main__ - Printing 3 examples
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: who is the book the catcher in the rye by? [SEP] answer: Originally published for adults, it has since become popular with adolescent readers for its themes of teenage angst and alienation.
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: what kind of transportation was there in the middle ages [SEP] answer: Horses in the Middle Ages differed in size, build and breed from the modern horse , and were, on average, smaller.
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ -  [wiki_qa] question: what cable company carry comcast sportsnet [SEP] answer: Comcast has been the subject of criticism for activities including its stance on net neutrality, as well as poor results on customer satisfaction surveys.
05/31/2022 08:43:32 - INFO - __main__ - ['false']
05/31/2022 08:43:32 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:43:32 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:43:32 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:43:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:43:44 - INFO - __main__ - Starting training!
05/31/2022 08:43:48 - INFO - __main__ - Step 10 Global step 10 Train loss 23.340393 on epoch=2
05/31/2022 08:43:53 - INFO - __main__ - Step 20 Global step 20 Train loss 20.550978 on epoch=4
05/31/2022 08:43:58 - INFO - __main__ - Step 30 Global step 30 Train loss 19.856611 on epoch=7
05/31/2022 08:44:03 - INFO - __main__ - Step 40 Global step 40 Train loss 17.400875 on epoch=9
05/31/2022 08:44:08 - INFO - __main__ - Step 50 Global step 50 Train loss 18.588890 on epoch=12
05/31/2022 08:44:25 - INFO - __main__ - Global step 50 Train loss 19.947552 Classification-F1 0.0 on epoch=12
05/31/2022 08:44:30 - INFO - __main__ - Step 60 Global step 60 Train loss 16.802088 on epoch=14
05/31/2022 08:44:35 - INFO - __main__ - Step 70 Global step 70 Train loss 16.442112 on epoch=17
05/31/2022 08:44:40 - INFO - __main__ - Step 80 Global step 80 Train loss 16.434750 on epoch=19
05/31/2022 08:44:45 - INFO - __main__ - Step 90 Global step 90 Train loss 15.832416 on epoch=22
05/31/2022 08:44:50 - INFO - __main__ - Step 100 Global step 100 Train loss 14.835449 on epoch=24
05/31/2022 08:45:02 - INFO - __main__ - Global step 100 Train loss 16.069363 Classification-F1 0.0 on epoch=24
05/31/2022 08:45:07 - INFO - __main__ - Step 110 Global step 110 Train loss 16.085173 on epoch=27
05/31/2022 08:45:12 - INFO - __main__ - Step 120 Global step 120 Train loss 15.344011 on epoch=29
05/31/2022 08:45:18 - INFO - __main__ - Step 130 Global step 130 Train loss 14.566080 on epoch=32
05/31/2022 08:45:23 - INFO - __main__ - Step 140 Global step 140 Train loss 13.944633 on epoch=34
05/31/2022 08:45:28 - INFO - __main__ - Step 150 Global step 150 Train loss 13.936084 on epoch=37
05/31/2022 08:45:37 - INFO - __main__ - Global step 150 Train loss 14.775196 Classification-F1 0.0 on epoch=37
05/31/2022 08:45:42 - INFO - __main__ - Step 160 Global step 160 Train loss 13.529004 on epoch=39
05/31/2022 08:45:47 - INFO - __main__ - Step 170 Global step 170 Train loss 13.522946 on epoch=42
05/31/2022 08:45:52 - INFO - __main__ - Step 180 Global step 180 Train loss 12.263529 on epoch=44
05/31/2022 08:45:57 - INFO - __main__ - Step 190 Global step 190 Train loss 11.715349 on epoch=47
05/31/2022 08:46:02 - INFO - __main__ - Step 200 Global step 200 Train loss 11.521100 on epoch=49
05/31/2022 08:46:10 - INFO - __main__ - Global step 200 Train loss 12.510387 Classification-F1 0.0 on epoch=49
05/31/2022 08:46:15 - INFO - __main__ - Step 210 Global step 210 Train loss 10.540051 on epoch=52
05/31/2022 08:46:20 - INFO - __main__ - Step 220 Global step 220 Train loss 8.939943 on epoch=54
05/31/2022 08:46:25 - INFO - __main__ - Step 230 Global step 230 Train loss 7.322945 on epoch=57
05/31/2022 08:46:30 - INFO - __main__ - Step 240 Global step 240 Train loss 5.374189 on epoch=59
05/31/2022 08:46:35 - INFO - __main__ - Step 250 Global step 250 Train loss 4.208323 on epoch=62
05/31/2022 08:46:36 - INFO - __main__ - Global step 250 Train loss 7.277091 Classification-F1 0.3333333333333333 on epoch=62
05/31/2022 08:46:41 - INFO - __main__ - Step 260 Global step 260 Train loss 3.729780 on epoch=64
05/31/2022 08:46:46 - INFO - __main__ - Step 270 Global step 270 Train loss 3.176832 on epoch=67
05/31/2022 08:46:52 - INFO - __main__ - Step 280 Global step 280 Train loss 4.358920 on epoch=69
05/31/2022 08:46:57 - INFO - __main__ - Step 290 Global step 290 Train loss 1.720829 on epoch=72
05/31/2022 08:47:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.728263 on epoch=74
05/31/2022 08:47:02 - INFO - __main__ - Global step 300 Train loss 2.742924 Classification-F1 0.32631578947368417 on epoch=74
05/31/2022 08:47:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.513743 on epoch=77
05/31/2022 08:47:12 - INFO - __main__ - Step 320 Global step 320 Train loss 0.859648 on epoch=79
05/31/2022 08:47:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.703223 on epoch=82
05/31/2022 08:47:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.453736 on epoch=84
05/31/2022 08:47:27 - INFO - __main__ - Step 350 Global step 350 Train loss 0.410132 on epoch=87
05/31/2022 08:47:28 - INFO - __main__ - Global step 350 Train loss 0.588096 Classification-F1 0.4909862142099682 on epoch=87
05/31/2022 08:47:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.355293 on epoch=89
05/31/2022 08:47:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.376984 on epoch=92
05/31/2022 08:47:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.289893 on epoch=94
05/31/2022 08:47:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.267546 on epoch=97
05/31/2022 08:47:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.289153 on epoch=99
05/31/2022 08:47:55 - INFO - __main__ - Global step 400 Train loss 0.315774 Classification-F1 0.3671451355661882 on epoch=99
05/31/2022 08:48:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.228221 on epoch=102
05/31/2022 08:48:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.298934 on epoch=104
05/31/2022 08:48:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.164712 on epoch=107
05/31/2022 08:48:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.154193 on epoch=109
05/31/2022 08:48:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.157443 on epoch=112
05/31/2022 08:48:21 - INFO - __main__ - Global step 450 Train loss 0.200701 Classification-F1 0.5652830188679245 on epoch=112
05/31/2022 08:48:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.105065 on epoch=114
05/31/2022 08:48:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.105424 on epoch=117
05/31/2022 08:48:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.132898 on epoch=119
05/31/2022 08:48:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.153477 on epoch=122
05/31/2022 08:48:47 - INFO - __main__ - Step 500 Global step 500 Train loss 0.146986 on epoch=124
05/31/2022 08:48:47 - INFO - __main__ - Global step 500 Train loss 0.128770 Classification-F1 0.5730170496664195 on epoch=124
05/31/2022 08:48:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.062725 on epoch=127
05/31/2022 08:48:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.041383 on epoch=129
05/31/2022 08:49:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.073833 on epoch=132
05/31/2022 08:49:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.050587 on epoch=134
05/31/2022 08:49:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.058611 on epoch=137
05/31/2022 08:49:14 - INFO - __main__ - Global step 550 Train loss 0.057428 Classification-F1 0.5797215655371684 on epoch=137
05/31/2022 08:49:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.041451 on epoch=139
05/31/2022 08:49:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.135674 on epoch=142
05/31/2022 08:49:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.040704 on epoch=144
05/31/2022 08:49:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.024013 on epoch=147
05/31/2022 08:49:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.012069 on epoch=149
05/31/2022 08:49:41 - INFO - __main__ - Global step 600 Train loss 0.050782 Classification-F1 0.5467643467643467 on epoch=149
05/31/2022 08:49:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.041665 on epoch=152
05/31/2022 08:49:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.067079 on epoch=154
05/31/2022 08:49:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.037790 on epoch=157
05/31/2022 08:50:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.028825 on epoch=159
05/31/2022 08:50:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.036327 on epoch=162
05/31/2022 08:50:07 - INFO - __main__ - Global step 650 Train loss 0.042337 Classification-F1 0.5780219780219781 on epoch=162
05/31/2022 08:50:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.010556 on epoch=164
05/31/2022 08:50:17 - INFO - __main__ - Step 670 Global step 670 Train loss 0.034435 on epoch=167
05/31/2022 08:50:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.032920 on epoch=169
05/31/2022 08:50:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.035305 on epoch=172
05/31/2022 08:50:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.016087 on epoch=174
05/31/2022 08:50:33 - INFO - __main__ - Global step 700 Train loss 0.025861 Classification-F1 0.5625 on epoch=174
05/31/2022 08:50:38 - INFO - __main__ - Step 710 Global step 710 Train loss 0.017330 on epoch=177
05/31/2022 08:50:43 - INFO - __main__ - Step 720 Global step 720 Train loss 0.012239 on epoch=179
05/31/2022 08:50:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.023959 on epoch=182
05/31/2022 08:50:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.009175 on epoch=184
05/31/2022 08:50:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.023249 on epoch=187
05/31/2022 08:50:59 - INFO - __main__ - Global step 750 Train loss 0.017191 Classification-F1 0.5696139476961395 on epoch=187
05/31/2022 08:51:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.008134 on epoch=189
05/31/2022 08:51:09 - INFO - __main__ - Step 770 Global step 770 Train loss 0.003028 on epoch=192
05/31/2022 08:51:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.012384 on epoch=194
05/31/2022 08:51:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.009107 on epoch=197
05/31/2022 08:51:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004388 on epoch=199
05/31/2022 08:51:25 - INFO - __main__ - Global step 800 Train loss 0.007408 Classification-F1 0.5921568627450979 on epoch=199
05/31/2022 08:51:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.002984 on epoch=202
05/31/2022 08:51:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.013194 on epoch=204
05/31/2022 08:51:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.004533 on epoch=207
05/31/2022 08:51:46 - INFO - __main__ - Step 840 Global step 840 Train loss 0.002471 on epoch=209
05/31/2022 08:51:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.013460 on epoch=212
05/31/2022 08:51:52 - INFO - __main__ - Global step 850 Train loss 0.007329 Classification-F1 0.6014943960149439 on epoch=212
05/31/2022 08:51:57 - INFO - __main__ - Step 860 Global step 860 Train loss 0.004665 on epoch=214
05/31/2022 08:52:02 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001423 on epoch=217
05/31/2022 08:52:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000649 on epoch=219
05/31/2022 08:52:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.014981 on epoch=222
05/31/2022 08:52:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.028782 on epoch=224
05/31/2022 08:52:18 - INFO - __main__ - Global step 900 Train loss 0.010100 Classification-F1 0.5933528836754642 on epoch=224
05/31/2022 08:52:23 - INFO - __main__ - Step 910 Global step 910 Train loss 0.064348 on epoch=227
05/31/2022 08:52:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.011590 on epoch=229
05/31/2022 08:52:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.015216 on epoch=232
05/31/2022 08:52:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.002965 on epoch=234
05/31/2022 08:52:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.022861 on epoch=237
05/31/2022 08:52:44 - INFO - __main__ - Global step 950 Train loss 0.023396 Classification-F1 0.59375 on epoch=237
05/31/2022 08:52:49 - INFO - __main__ - Step 960 Global step 960 Train loss 0.003383 on epoch=239
05/31/2022 08:52:54 - INFO - __main__ - Step 970 Global step 970 Train loss 0.006166 on epoch=242
05/31/2022 08:53:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.042653 on epoch=244
05/31/2022 08:53:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.004806 on epoch=247
05/31/2022 08:53:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.014738 on epoch=249
05/31/2022 08:53:11 - INFO - __main__ - Global step 1000 Train loss 0.014349 Classification-F1 0.5925642984466514 on epoch=249
05/31/2022 08:53:11 - INFO - __main__ - save last model!
05/31/2022 08:53:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:53:11 - INFO - __main__ - Printing 3 examples
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:53:11 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:53:11 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:53:11 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:53:11 - INFO - __main__ - Printing 3 examples
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 08:53:11 - INFO - __main__ - ['false']
05/31/2022 08:53:11 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:53:11 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:53:11 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:53:17 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 08:53:18 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 08:53:18 - INFO - __main__ - Printing 3 examples
05/31/2022 08:53:18 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 08:53:18 - INFO - __main__ - ['false']
05/31/2022 08:53:18 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 08:53:18 - INFO - __main__ - ['false']
05/31/2022 08:53:18 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 08:53:18 - INFO - __main__ - ['false']
05/31/2022 08:53:18 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:53:20 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:53:22 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 08:53:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:53:24 - INFO - __main__ - Starting training!
05/31/2022 08:53:51 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_42_0.0001_8_predictions.txt
05/31/2022 08:53:51 - INFO - __main__ - Classification-F1 on test data: 0.3443
05/31/2022 08:53:51 - INFO - __main__ - prefix=wiki_qa_32_42, lr=0.0001, bsz=8, dev_performance=0.6014943960149439, test_performance=0.34428358983519125
05/31/2022 08:53:51 - INFO - __main__ - Running ... prefix=wiki_qa_32_87, lr=0.0005, bsz=8 ...
05/31/2022 08:53:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:53:52 - INFO - __main__ - Printing 3 examples
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:53:52 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:53:52 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 08:53:52 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 08:53:52 - INFO - __main__ - Printing 3 examples
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 08:53:52 - INFO - __main__ - ['false']
05/31/2022 08:53:52 - INFO - __main__ - Tokenizing Input ...
05/31/2022 08:53:52 - INFO - __main__ - Tokenizing Output ...
05/31/2022 08:53:53 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 08:54:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 08:54:05 - INFO - __main__ - Starting training!
05/31/2022 08:54:09 - INFO - __main__ - Step 10 Global step 10 Train loss 23.349154 on epoch=2
05/31/2022 08:54:14 - INFO - __main__ - Step 20 Global step 20 Train loss 17.570477 on epoch=4
05/31/2022 08:54:19 - INFO - __main__ - Step 30 Global step 30 Train loss 16.297131 on epoch=7
05/31/2022 08:54:24 - INFO - __main__ - Step 40 Global step 40 Train loss 14.473749 on epoch=9
05/31/2022 08:54:29 - INFO - __main__ - Step 50 Global step 50 Train loss 12.376612 on epoch=12
05/31/2022 08:54:33 - INFO - __main__ - Global step 50 Train loss 16.813423 Classification-F1 0.0 on epoch=12
05/31/2022 08:54:38 - INFO - __main__ - Step 60 Global step 60 Train loss 8.224017 on epoch=14
05/31/2022 08:54:43 - INFO - __main__ - Step 70 Global step 70 Train loss 1.689844 on epoch=17
05/31/2022 08:54:49 - INFO - __main__ - Step 80 Global step 80 Train loss 0.603535 on epoch=19
05/31/2022 08:54:54 - INFO - __main__ - Step 90 Global step 90 Train loss 0.773700 on epoch=22
05/31/2022 08:54:59 - INFO - __main__ - Step 100 Global step 100 Train loss 0.577631 on epoch=24
05/31/2022 08:54:59 - INFO - __main__ - Global step 100 Train loss 2.373746 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 08:55:05 - INFO - __main__ - Step 110 Global step 110 Train loss 0.578512 on epoch=27
05/31/2022 08:55:10 - INFO - __main__ - Step 120 Global step 120 Train loss 0.572171 on epoch=29
05/31/2022 08:55:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.451346 on epoch=32
05/31/2022 08:55:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.453698 on epoch=34
05/31/2022 08:55:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.545292 on epoch=37
05/31/2022 08:55:26 - INFO - __main__ - Global step 150 Train loss 0.520204 Classification-F1 0.16731016731016732 on epoch=37
05/31/2022 08:55:31 - INFO - __main__ - Step 160 Global step 160 Train loss 0.745933 on epoch=39
05/31/2022 08:55:36 - INFO - __main__ - Step 170 Global step 170 Train loss 0.480442 on epoch=42
05/31/2022 08:55:41 - INFO - __main__ - Step 180 Global step 180 Train loss 0.515305 on epoch=44
05/31/2022 08:55:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.448963 on epoch=47
05/31/2022 08:55:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.464914 on epoch=49
05/31/2022 08:55:52 - INFO - __main__ - Global step 200 Train loss 0.531111 Classification-F1 0.3333333333333333 on epoch=49
05/31/2022 08:55:57 - INFO - __main__ - Step 210 Global step 210 Train loss 0.403224 on epoch=52
05/31/2022 08:56:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.480991 on epoch=54
05/31/2022 08:56:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.483710 on epoch=57
05/31/2022 08:56:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.578756 on epoch=59
05/31/2022 08:56:17 - INFO - __main__ - Step 250 Global step 250 Train loss 0.528861 on epoch=62
05/31/2022 08:56:18 - INFO - __main__ - Global step 250 Train loss 0.495108 Classification-F1 0.6014943960149439 on epoch=62
05/31/2022 08:56:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.439580 on epoch=64
05/31/2022 08:56:29 - INFO - __main__ - Step 270 Global step 270 Train loss 0.382114 on epoch=67
05/31/2022 08:56:34 - INFO - __main__ - Step 280 Global step 280 Train loss 0.389385 on epoch=69
05/31/2022 08:56:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.454231 on epoch=72
05/31/2022 08:56:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.400958 on epoch=74
05/31/2022 08:56:45 - INFO - __main__ - Global step 300 Train loss 0.413254 Classification-F1 0.5607843137254902 on epoch=74
05/31/2022 08:56:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.441263 on epoch=77
05/31/2022 08:56:55 - INFO - __main__ - Step 320 Global step 320 Train loss 0.440726 on epoch=79
05/31/2022 08:57:00 - INFO - __main__ - Step 330 Global step 330 Train loss 0.424491 on epoch=82
05/31/2022 08:57:05 - INFO - __main__ - Step 340 Global step 340 Train loss 0.408717 on epoch=84
05/31/2022 08:57:10 - INFO - __main__ - Step 350 Global step 350 Train loss 0.447555 on epoch=87
05/31/2022 08:57:11 - INFO - __main__ - Global step 350 Train loss 0.432551 Classification-F1 0.5373493975903615 on epoch=87
05/31/2022 08:57:16 - INFO - __main__ - Step 360 Global step 360 Train loss 0.409140 on epoch=89
05/31/2022 08:57:21 - INFO - __main__ - Step 370 Global step 370 Train loss 0.404124 on epoch=92
05/31/2022 08:57:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.397547 on epoch=94
05/31/2022 08:57:31 - INFO - __main__ - Step 390 Global step 390 Train loss 0.379563 on epoch=97
05/31/2022 08:57:36 - INFO - __main__ - Step 400 Global step 400 Train loss 0.361860 on epoch=99
05/31/2022 08:57:37 - INFO - __main__ - Global step 400 Train loss 0.390447 Classification-F1 0.3333333333333333 on epoch=99
05/31/2022 08:57:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.411543 on epoch=102
05/31/2022 08:57:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.392689 on epoch=104
05/31/2022 08:57:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.399178 on epoch=107
05/31/2022 08:57:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.384850 on epoch=109
05/31/2022 08:58:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.391528 on epoch=112
05/31/2022 08:58:03 - INFO - __main__ - Global step 450 Train loss 0.395958 Classification-F1 0.39047619047619053 on epoch=112
05/31/2022 08:58:08 - INFO - __main__ - Step 460 Global step 460 Train loss 0.444478 on epoch=114
05/31/2022 08:58:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.363961 on epoch=117
05/31/2022 08:58:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.362148 on epoch=119
05/31/2022 08:58:23 - INFO - __main__ - Step 490 Global step 490 Train loss 0.354837 on epoch=122
05/31/2022 08:58:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.371780 on epoch=124
05/31/2022 08:58:29 - INFO - __main__ - Global step 500 Train loss 0.379441 Classification-F1 0.3333333333333333 on epoch=124
05/31/2022 08:58:34 - INFO - __main__ - Step 510 Global step 510 Train loss 0.400996 on epoch=127
05/31/2022 08:58:39 - INFO - __main__ - Step 520 Global step 520 Train loss 0.352491 on epoch=129
05/31/2022 08:58:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.397068 on epoch=132
05/31/2022 08:58:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.391824 on epoch=134
05/31/2022 08:58:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.359549 on epoch=137
05/31/2022 08:58:55 - INFO - __main__ - Global step 550 Train loss 0.380386 Classification-F1 0.3671451355661882 on epoch=137
05/31/2022 08:59:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.354946 on epoch=139
05/31/2022 08:59:05 - INFO - __main__ - Step 570 Global step 570 Train loss 0.470055 on epoch=142
05/31/2022 08:59:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.354120 on epoch=144
05/31/2022 08:59:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.393813 on epoch=147
05/31/2022 08:59:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.405844 on epoch=149
05/31/2022 08:59:21 - INFO - __main__ - Global step 600 Train loss 0.395756 Classification-F1 0.3333333333333333 on epoch=149
05/31/2022 08:59:26 - INFO - __main__ - Step 610 Global step 610 Train loss 0.363520 on epoch=152
05/31/2022 08:59:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.436069 on epoch=154
05/31/2022 08:59:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.341759 on epoch=157
05/31/2022 08:59:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.371335 on epoch=159
05/31/2022 08:59:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.398499 on epoch=162
05/31/2022 08:59:47 - INFO - __main__ - Global step 650 Train loss 0.382236 Classification-F1 0.3671451355661882 on epoch=162
05/31/2022 08:59:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.360098 on epoch=164
05/31/2022 08:59:57 - INFO - __main__ - Step 670 Global step 670 Train loss 0.614400 on epoch=167
05/31/2022 09:00:02 - INFO - __main__ - Step 680 Global step 680 Train loss 0.351693 on epoch=169
05/31/2022 09:00:07 - INFO - __main__ - Step 690 Global step 690 Train loss 0.387480 on epoch=172
05/31/2022 09:00:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.408307 on epoch=174
05/31/2022 09:00:13 - INFO - __main__ - Global step 700 Train loss 0.424396 Classification-F1 0.49220246238030096 on epoch=174
05/31/2022 09:00:18 - INFO - __main__ - Step 710 Global step 710 Train loss 0.340109 on epoch=177
05/31/2022 09:00:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.338896 on epoch=179
05/31/2022 09:00:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.308764 on epoch=182
05/31/2022 09:00:33 - INFO - __main__ - Step 740 Global step 740 Train loss 0.252077 on epoch=184
05/31/2022 09:00:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.340239 on epoch=187
05/31/2022 09:00:39 - INFO - __main__ - Global step 750 Train loss 0.316017 Classification-F1 0.48747093774218553 on epoch=187
05/31/2022 09:00:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.247697 on epoch=189
05/31/2022 09:00:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.215082 on epoch=192
05/31/2022 09:00:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.262010 on epoch=194
05/31/2022 09:00:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.197896 on epoch=197
05/31/2022 09:01:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.246208 on epoch=199
05/31/2022 09:01:05 - INFO - __main__ - Global step 800 Train loss 0.233779 Classification-F1 0.503078982597055 on epoch=199
05/31/2022 09:01:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.125007 on epoch=202
05/31/2022 09:01:15 - INFO - __main__ - Step 820 Global step 820 Train loss 0.125643 on epoch=204
05/31/2022 09:01:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.471316 on epoch=207
05/31/2022 09:01:25 - INFO - __main__ - Step 840 Global step 840 Train loss 1.980093 on epoch=209
05/31/2022 09:01:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.227115 on epoch=212
05/31/2022 09:01:31 - INFO - __main__ - Global step 850 Train loss 0.585835 Classification-F1 0.44379029997196523 on epoch=212
05/31/2022 09:01:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.400455 on epoch=214
05/31/2022 09:01:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.287467 on epoch=217
05/31/2022 09:01:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.235799 on epoch=219
05/31/2022 09:01:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.775830 on epoch=222
05/31/2022 09:01:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.336024 on epoch=224
05/31/2022 09:01:57 - INFO - __main__ - Global step 900 Train loss 0.407115 Classification-F1 0.3671451355661882 on epoch=224
05/31/2022 09:02:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.268284 on epoch=227
05/31/2022 09:02:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.260595 on epoch=229
05/31/2022 09:02:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.206796 on epoch=232
05/31/2022 09:02:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.137905 on epoch=234
05/31/2022 09:02:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.105897 on epoch=237
05/31/2022 09:02:23 - INFO - __main__ - Global step 950 Train loss 0.195895 Classification-F1 0.5272229822161423 on epoch=237
05/31/2022 09:02:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.127148 on epoch=239
05/31/2022 09:02:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.121013 on epoch=242
05/31/2022 09:02:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.049840 on epoch=244
05/31/2022 09:02:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.097072 on epoch=247
05/31/2022 09:02:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.073553 on epoch=249
05/31/2022 09:02:49 - INFO - __main__ - Global step 1000 Train loss 0.093725 Classification-F1 0.6092796092796093 on epoch=249
05/31/2022 09:02:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:02:50 - INFO - __main__ - Printing 3 examples
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:02:50 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:02:50 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:02:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:02:50 - INFO - __main__ - Printing 3 examples
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:02:50 - INFO - __main__ - ['false']
05/31/2022 09:02:50 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:02:50 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:02:50 - INFO - __main__ - save last model!
05/31/2022 09:02:50 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:02:57 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 09:02:57 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 09:02:57 - INFO - __main__ - Printing 3 examples
05/31/2022 09:02:57 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 09:02:57 - INFO - __main__ - ['false']
05/31/2022 09:02:57 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 09:02:57 - INFO - __main__ - ['false']
05/31/2022 09:02:57 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 09:02:57 - INFO - __main__ - ['false']
05/31/2022 09:02:57 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:02:59 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:03:01 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 09:03:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:03:03 - INFO - __main__ - Starting training!
05/31/2022 09:03:30 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_87_0.0005_8_predictions.txt
05/31/2022 09:03:30 - INFO - __main__ - Classification-F1 on test data: 0.3595
05/31/2022 09:03:30 - INFO - __main__ - prefix=wiki_qa_32_87, lr=0.0005, bsz=8, dev_performance=0.6092796092796093, test_performance=0.3594924418701977
05/31/2022 09:03:30 - INFO - __main__ - Running ... prefix=wiki_qa_32_87, lr=0.0003, bsz=8 ...
05/31/2022 09:03:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:03:31 - INFO - __main__ - Printing 3 examples
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:03:31 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:03:31 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:03:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:03:31 - INFO - __main__ - Printing 3 examples
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:03:31 - INFO - __main__ - ['false']
05/31/2022 09:03:31 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:03:31 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:03:31 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:03:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:03:43 - INFO - __main__ - Starting training!
05/31/2022 09:03:47 - INFO - __main__ - Step 10 Global step 10 Train loss 23.644619 on epoch=2
05/31/2022 09:03:52 - INFO - __main__ - Step 20 Global step 20 Train loss 18.836390 on epoch=4
05/31/2022 09:03:58 - INFO - __main__ - Step 30 Global step 30 Train loss 18.172897 on epoch=7
05/31/2022 09:04:03 - INFO - __main__ - Step 40 Global step 40 Train loss 16.203587 on epoch=9
05/31/2022 09:04:08 - INFO - __main__ - Step 50 Global step 50 Train loss 14.969455 on epoch=12
05/31/2022 09:04:16 - INFO - __main__ - Global step 50 Train loss 18.365389 Classification-F1 0.0 on epoch=12
05/31/2022 09:04:22 - INFO - __main__ - Step 60 Global step 60 Train loss 12.921539 on epoch=14
05/31/2022 09:04:27 - INFO - __main__ - Step 70 Global step 70 Train loss 11.490202 on epoch=17
05/31/2022 09:04:32 - INFO - __main__ - Step 80 Global step 80 Train loss 7.310895 on epoch=19
05/31/2022 09:04:37 - INFO - __main__ - Step 90 Global step 90 Train loss 5.622002 on epoch=22
05/31/2022 09:04:42 - INFO - __main__ - Step 100 Global step 100 Train loss 5.132002 on epoch=24
05/31/2022 09:04:43 - INFO - __main__ - Global step 100 Train loss 8.495328 Classification-F1 0.3333333333333333 on epoch=24
05/31/2022 09:04:48 - INFO - __main__ - Step 110 Global step 110 Train loss 2.964907 on epoch=27
05/31/2022 09:04:53 - INFO - __main__ - Step 120 Global step 120 Train loss 2.475942 on epoch=29
05/31/2022 09:04:58 - INFO - __main__ - Step 130 Global step 130 Train loss 2.005204 on epoch=32
05/31/2022 09:05:03 - INFO - __main__ - Step 140 Global step 140 Train loss 1.155185 on epoch=34
05/31/2022 09:05:08 - INFO - __main__ - Step 150 Global step 150 Train loss 1.200122 on epoch=37
05/31/2022 09:05:09 - INFO - __main__ - Global step 150 Train loss 1.960272 Classification-F1 0.4874874874874875 on epoch=37
05/31/2022 09:05:14 - INFO - __main__ - Step 160 Global step 160 Train loss 0.700049 on epoch=39
05/31/2022 09:05:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.597041 on epoch=42
05/31/2022 09:05:24 - INFO - __main__ - Step 180 Global step 180 Train loss 0.413449 on epoch=44
05/31/2022 09:05:30 - INFO - __main__ - Step 190 Global step 190 Train loss 0.394420 on epoch=47
05/31/2022 09:05:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.431486 on epoch=49
05/31/2022 09:05:35 - INFO - __main__ - Global step 200 Train loss 0.507289 Classification-F1 0.5097603162836669 on epoch=49
05/31/2022 09:05:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.428580 on epoch=52
05/31/2022 09:05:46 - INFO - __main__ - Step 220 Global step 220 Train loss 0.330790 on epoch=54
05/31/2022 09:05:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.410652 on epoch=57
05/31/2022 09:05:56 - INFO - __main__ - Step 240 Global step 240 Train loss 0.360892 on epoch=59
05/31/2022 09:06:01 - INFO - __main__ - Step 250 Global step 250 Train loss 0.374129 on epoch=62
05/31/2022 09:06:02 - INFO - __main__ - Global step 250 Train loss 0.381008 Classification-F1 0.4385964912280702 on epoch=62
05/31/2022 09:06:07 - INFO - __main__ - Step 260 Global step 260 Train loss 0.344419 on epoch=64
05/31/2022 09:06:12 - INFO - __main__ - Step 270 Global step 270 Train loss 0.328305 on epoch=67
05/31/2022 09:06:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.336215 on epoch=69
05/31/2022 09:06:23 - INFO - __main__ - Step 290 Global step 290 Train loss 0.316427 on epoch=72
05/31/2022 09:06:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.291965 on epoch=74
05/31/2022 09:06:29 - INFO - __main__ - Global step 300 Train loss 0.323467 Classification-F1 0.3333333333333333 on epoch=74
05/31/2022 09:06:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.321083 on epoch=77
05/31/2022 09:06:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.279543 on epoch=79
05/31/2022 09:06:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.284588 on epoch=82
05/31/2022 09:06:49 - INFO - __main__ - Step 340 Global step 340 Train loss 0.468409 on epoch=84
05/31/2022 09:06:54 - INFO - __main__ - Step 350 Global step 350 Train loss 0.434296 on epoch=87
05/31/2022 09:06:55 - INFO - __main__ - Global step 350 Train loss 0.357584 Classification-F1 0.5755342667649226 on epoch=87
05/31/2022 09:07:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.342230 on epoch=89
05/31/2022 09:07:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.316269 on epoch=92
05/31/2022 09:07:11 - INFO - __main__ - Step 380 Global step 380 Train loss 0.193891 on epoch=94
05/31/2022 09:07:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.168748 on epoch=97
05/31/2022 09:07:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.173512 on epoch=99
05/31/2022 09:07:23 - INFO - __main__ - Global step 400 Train loss 0.238930 Classification-F1 0.5866701110824076 on epoch=99
05/31/2022 09:07:28 - INFO - __main__ - Step 410 Global step 410 Train loss 0.139058 on epoch=102
05/31/2022 09:07:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.126405 on epoch=104
05/31/2022 09:07:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.216033 on epoch=107
05/31/2022 09:07:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.378426 on epoch=109
05/31/2022 09:07:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.176772 on epoch=112
05/31/2022 09:07:50 - INFO - __main__ - Global step 450 Train loss 0.207339 Classification-F1 0.6384180790960452 on epoch=112
05/31/2022 09:07:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.123072 on epoch=114
05/31/2022 09:08:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.079847 on epoch=117
05/31/2022 09:08:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.050535 on epoch=119
05/31/2022 09:08:11 - INFO - __main__ - Step 490 Global step 490 Train loss 0.050279 on epoch=122
05/31/2022 09:08:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.100170 on epoch=124
05/31/2022 09:08:16 - INFO - __main__ - Global step 500 Train loss 0.080781 Classification-F1 0.4619708994708995 on epoch=124
05/31/2022 09:08:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.027559 on epoch=127
05/31/2022 09:08:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.026803 on epoch=129
05/31/2022 09:08:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.025836 on epoch=132
05/31/2022 09:08:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.017791 on epoch=134
05/31/2022 09:08:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.044111 on epoch=137
05/31/2022 09:08:52 - INFO - __main__ - Global step 550 Train loss 0.028420 Classification-F1 0.43712273641851107 on epoch=137
05/31/2022 09:08:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.068691 on epoch=139
05/31/2022 09:09:02 - INFO - __main__ - Step 570 Global step 570 Train loss 0.317086 on epoch=142
05/31/2022 09:09:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.163122 on epoch=144
05/31/2022 09:09:12 - INFO - __main__ - Step 590 Global step 590 Train loss 0.280875 on epoch=147
05/31/2022 09:09:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.185461 on epoch=149
05/31/2022 09:09:18 - INFO - __main__ - Global step 600 Train loss 0.203047 Classification-F1 0.539313399778516 on epoch=149
05/31/2022 09:09:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.243994 on epoch=152
05/31/2022 09:09:28 - INFO - __main__ - Step 620 Global step 620 Train loss 0.167528 on epoch=154
05/31/2022 09:09:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.313112 on epoch=157
05/31/2022 09:09:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.164673 on epoch=159
05/31/2022 09:09:43 - INFO - __main__ - Step 650 Global step 650 Train loss 0.114043 on epoch=162
05/31/2022 09:09:44 - INFO - __main__ - Global step 650 Train loss 0.200670 Classification-F1 0.5755342667649226 on epoch=162
05/31/2022 09:09:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.157169 on epoch=164
05/31/2022 09:09:54 - INFO - __main__ - Step 670 Global step 670 Train loss 0.176389 on epoch=167
05/31/2022 09:09:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.184365 on epoch=169
05/31/2022 09:10:04 - INFO - __main__ - Step 690 Global step 690 Train loss 0.095977 on epoch=172
05/31/2022 09:10:09 - INFO - __main__ - Step 700 Global step 700 Train loss 0.080393 on epoch=174
05/31/2022 09:10:10 - INFO - __main__ - Global step 700 Train loss 0.138859 Classification-F1 0.3172761664564943 on epoch=174
05/31/2022 09:10:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.085171 on epoch=177
05/31/2022 09:10:20 - INFO - __main__ - Step 720 Global step 720 Train loss 0.112461 on epoch=179
05/31/2022 09:10:25 - INFO - __main__ - Step 730 Global step 730 Train loss 0.036171 on epoch=182
05/31/2022 09:10:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.028532 on epoch=184
05/31/2022 09:10:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.049893 on epoch=187
05/31/2022 09:10:36 - INFO - __main__ - Global step 750 Train loss 0.062446 Classification-F1 0.5586206896551724 on epoch=187
05/31/2022 09:10:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.032452 on epoch=189
05/31/2022 09:10:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.053928 on epoch=192
05/31/2022 09:10:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.021650 on epoch=194
05/31/2022 09:10:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.023201 on epoch=197
05/31/2022 09:11:01 - INFO - __main__ - Step 800 Global step 800 Train loss 0.044386 on epoch=199
05/31/2022 09:11:02 - INFO - __main__ - Global step 800 Train loss 0.035123 Classification-F1 0.3893617021276596 on epoch=199
05/31/2022 09:11:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.039574 on epoch=202
05/31/2022 09:11:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.013415 on epoch=204
05/31/2022 09:11:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.024440 on epoch=207
05/31/2022 09:11:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.011530 on epoch=209
05/31/2022 09:11:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.003955 on epoch=212
05/31/2022 09:11:28 - INFO - __main__ - Global step 850 Train loss 0.018583 Classification-F1 0.32500000000000007 on epoch=212
05/31/2022 09:11:33 - INFO - __main__ - Step 860 Global step 860 Train loss 0.003947 on epoch=214
05/31/2022 09:11:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.008193 on epoch=217
05/31/2022 09:11:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.014754 on epoch=219
05/31/2022 09:11:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.013032 on epoch=222
05/31/2022 09:11:53 - INFO - __main__ - Step 900 Global step 900 Train loss 0.003712 on epoch=224
05/31/2022 09:11:54 - INFO - __main__ - Global step 900 Train loss 0.008728 Classification-F1 0.6559139784946237 on epoch=224
05/31/2022 09:12:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.008784 on epoch=227
05/31/2022 09:12:05 - INFO - __main__ - Step 920 Global step 920 Train loss 0.004256 on epoch=229
05/31/2022 09:12:10 - INFO - __main__ - Step 930 Global step 930 Train loss 0.052071 on epoch=232
05/31/2022 09:12:15 - INFO - __main__ - Step 940 Global step 940 Train loss 0.005913 on epoch=234
05/31/2022 09:12:20 - INFO - __main__ - Step 950 Global step 950 Train loss 0.003214 on epoch=237
05/31/2022 09:12:20 - INFO - __main__ - Global step 950 Train loss 0.014848 Classification-F1 0.6405372405372406 on epoch=237
05/31/2022 09:12:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.003088 on epoch=239
05/31/2022 09:12:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.037324 on epoch=242
05/31/2022 09:12:36 - INFO - __main__ - Step 980 Global step 980 Train loss 0.015008 on epoch=244
05/31/2022 09:12:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.047558 on epoch=247
05/31/2022 09:12:46 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.011433 on epoch=249
05/31/2022 09:12:46 - INFO - __main__ - Global step 1000 Train loss 0.022882 Classification-F1 0.6549019607843137 on epoch=249
05/31/2022 09:12:46 - INFO - __main__ - save last model!
05/31/2022 09:12:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:12:47 - INFO - __main__ - Printing 3 examples
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:12:47 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:12:47 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:12:47 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:12:47 - INFO - __main__ - Printing 3 examples
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:12:47 - INFO - __main__ - ['false']
05/31/2022 09:12:47 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:12:47 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:12:47 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:12:54 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 09:12:54 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 09:12:54 - INFO - __main__ - Printing 3 examples
05/31/2022 09:12:54 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 09:12:54 - INFO - __main__ - ['false']
05/31/2022 09:12:54 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 09:12:54 - INFO - __main__ - ['false']
05/31/2022 09:12:54 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 09:12:54 - INFO - __main__ - ['false']
05/31/2022 09:12:54 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:12:56 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:12:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:12:58 - INFO - __main__ - Starting training!
05/31/2022 09:12:58 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 09:13:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_87_0.0003_8_predictions.txt
05/31/2022 09:13:39 - INFO - __main__ - Classification-F1 on test data: 0.0381
05/31/2022 09:13:40 - INFO - __main__ - prefix=wiki_qa_32_87, lr=0.0003, bsz=8, dev_performance=0.6559139784946237, test_performance=0.03813628100246721
05/31/2022 09:13:40 - INFO - __main__ - Running ... prefix=wiki_qa_32_87, lr=0.0002, bsz=8 ...
05/31/2022 09:13:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:13:40 - INFO - __main__ - Printing 3 examples
05/31/2022 09:13:40 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:13:40 - INFO - __main__ - ['false']
05/31/2022 09:13:40 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:13:40 - INFO - __main__ - ['false']
05/31/2022 09:13:40 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:13:40 - INFO - __main__ - ['false']
05/31/2022 09:13:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:13:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:13:41 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:13:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:13:41 - INFO - __main__ - Printing 3 examples
05/31/2022 09:13:41 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:13:41 - INFO - __main__ - ['false']
05/31/2022 09:13:41 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:13:41 - INFO - __main__ - ['false']
05/31/2022 09:13:41 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:13:41 - INFO - __main__ - ['false']
05/31/2022 09:13:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:13:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:13:41 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:13:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:13:52 - INFO - __main__ - Starting training!
05/31/2022 09:13:56 - INFO - __main__ - Step 10 Global step 10 Train loss 24.828621 on epoch=2
05/31/2022 09:14:01 - INFO - __main__ - Step 20 Global step 20 Train loss 20.575253 on epoch=4
05/31/2022 09:14:06 - INFO - __main__ - Step 30 Global step 30 Train loss 18.620289 on epoch=7
05/31/2022 09:14:11 - INFO - __main__ - Step 40 Global step 40 Train loss 18.040140 on epoch=9
05/31/2022 09:14:16 - INFO - __main__ - Step 50 Global step 50 Train loss 16.013393 on epoch=12
05/31/2022 09:14:28 - INFO - __main__ - Global step 50 Train loss 19.615538 Classification-F1 0.0 on epoch=12
05/31/2022 09:14:34 - INFO - __main__ - Step 60 Global step 60 Train loss 15.612394 on epoch=14
05/31/2022 09:14:39 - INFO - __main__ - Step 70 Global step 70 Train loss 15.303268 on epoch=17
05/31/2022 09:14:44 - INFO - __main__ - Step 80 Global step 80 Train loss 14.614603 on epoch=19
05/31/2022 09:14:49 - INFO - __main__ - Step 90 Global step 90 Train loss 13.493655 on epoch=22
05/31/2022 09:14:54 - INFO - __main__ - Step 100 Global step 100 Train loss 11.395258 on epoch=24
05/31/2022 09:15:18 - INFO - __main__ - Global step 100 Train loss 14.083836 Classification-F1 0.0 on epoch=24
05/31/2022 09:15:23 - INFO - __main__ - Step 110 Global step 110 Train loss 4.641425 on epoch=27
05/31/2022 09:15:28 - INFO - __main__ - Step 120 Global step 120 Train loss 1.068821 on epoch=29
05/31/2022 09:15:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.704721 on epoch=32
05/31/2022 09:15:38 - INFO - __main__ - Step 140 Global step 140 Train loss 0.641625 on epoch=34
05/31/2022 09:15:43 - INFO - __main__ - Step 150 Global step 150 Train loss 0.700134 on epoch=37
05/31/2022 09:15:44 - INFO - __main__ - Global step 150 Train loss 1.551345 Classification-F1 0.3816425120772947 on epoch=37
05/31/2022 09:15:49 - INFO - __main__ - Step 160 Global step 160 Train loss 0.534036 on epoch=39
05/31/2022 09:15:54 - INFO - __main__ - Step 170 Global step 170 Train loss 0.399065 on epoch=42
05/31/2022 09:15:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.323865 on epoch=44
05/31/2022 09:16:05 - INFO - __main__ - Step 190 Global step 190 Train loss 0.375243 on epoch=47
05/31/2022 09:16:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.275319 on epoch=49
05/31/2022 09:16:10 - INFO - __main__ - Global step 200 Train loss 0.381506 Classification-F1 0.3333333333333333 on epoch=49
05/31/2022 09:16:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.495058 on epoch=52
05/31/2022 09:16:20 - INFO - __main__ - Step 220 Global step 220 Train loss 0.179260 on epoch=54
05/31/2022 09:16:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.169552 on epoch=57
05/31/2022 09:16:30 - INFO - __main__ - Step 240 Global step 240 Train loss 0.091484 on epoch=59
05/31/2022 09:16:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.098500 on epoch=62
05/31/2022 09:16:36 - INFO - __main__ - Global step 250 Train loss 0.206771 Classification-F1 0.5696139476961395 on epoch=62
05/31/2022 09:16:42 - INFO - __main__ - Step 260 Global step 260 Train loss 0.073828 on epoch=64
05/31/2022 09:16:47 - INFO - __main__ - Step 270 Global step 270 Train loss 0.066206 on epoch=67
05/31/2022 09:16:52 - INFO - __main__ - Step 280 Global step 280 Train loss 0.042017 on epoch=69
05/31/2022 09:16:57 - INFO - __main__ - Step 290 Global step 290 Train loss 0.056215 on epoch=72
05/31/2022 09:17:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.035316 on epoch=74
05/31/2022 09:17:03 - INFO - __main__ - Global step 300 Train loss 0.054717 Classification-F1 0.5844155844155844 on epoch=74
05/31/2022 09:17:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.014044 on epoch=77
05/31/2022 09:17:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.021787 on epoch=79
05/31/2022 09:17:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.028166 on epoch=82
05/31/2022 09:17:24 - INFO - __main__ - Step 340 Global step 340 Train loss 0.004855 on epoch=84
05/31/2022 09:17:29 - INFO - __main__ - Step 350 Global step 350 Train loss 0.013925 on epoch=87
05/31/2022 09:17:29 - INFO - __main__ - Global step 350 Train loss 0.016556 Classification-F1 0.5155592935239698 on epoch=87
05/31/2022 09:17:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.010959 on epoch=89
05/31/2022 09:17:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.019508 on epoch=92
05/31/2022 09:17:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.002139 on epoch=94
05/31/2022 09:17:49 - INFO - __main__ - Step 390 Global step 390 Train loss 0.019312 on epoch=97
05/31/2022 09:17:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.003109 on epoch=99
05/31/2022 09:17:55 - INFO - __main__ - Global step 400 Train loss 0.011005 Classification-F1 0.5497835497835498 on epoch=99
05/31/2022 09:18:00 - INFO - __main__ - Step 410 Global step 410 Train loss 0.001456 on epoch=102
05/31/2022 09:18:05 - INFO - __main__ - Step 420 Global step 420 Train loss 0.002237 on epoch=104
05/31/2022 09:18:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.002503 on epoch=107
05/31/2022 09:18:15 - INFO - __main__ - Step 440 Global step 440 Train loss 0.002654 on epoch=109
05/31/2022 09:18:20 - INFO - __main__ - Step 450 Global step 450 Train loss 0.001341 on epoch=112
05/31/2022 09:18:21 - INFO - __main__ - Global step 450 Train loss 0.002038 Classification-F1 0.5588547189819725 on epoch=112
05/31/2022 09:18:26 - INFO - __main__ - Step 460 Global step 460 Train loss 0.000816 on epoch=114
05/31/2022 09:18:31 - INFO - __main__ - Step 470 Global step 470 Train loss 0.000846 on epoch=117
05/31/2022 09:18:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.001886 on epoch=119
05/31/2022 09:18:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.000631 on epoch=122
05/31/2022 09:18:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000435 on epoch=124
05/31/2022 09:18:47 - INFO - __main__ - Global step 500 Train loss 0.000923 Classification-F1 0.619736502195815 on epoch=124
05/31/2022 09:18:53 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000611 on epoch=127
05/31/2022 09:18:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000959 on epoch=129
05/31/2022 09:19:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.001287 on epoch=132
05/31/2022 09:19:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000403 on epoch=134
05/31/2022 09:19:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000921 on epoch=137
05/31/2022 09:19:14 - INFO - __main__ - Global step 550 Train loss 0.000836 Classification-F1 0.6000000000000001 on epoch=137
05/31/2022 09:19:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000278 on epoch=139
05/31/2022 09:19:24 - INFO - __main__ - Step 570 Global step 570 Train loss 0.009354 on epoch=142
05/31/2022 09:19:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.000570 on epoch=144
05/31/2022 09:19:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000403 on epoch=147
05/31/2022 09:19:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000268 on epoch=149
05/31/2022 09:19:40 - INFO - __main__ - Global step 600 Train loss 0.002174 Classification-F1 0.5272229822161423 on epoch=149
05/31/2022 09:19:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.001245 on epoch=152
05/31/2022 09:19:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001457 on epoch=154
05/31/2022 09:19:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000615 on epoch=157
05/31/2022 09:20:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000300 on epoch=159
05/31/2022 09:20:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000234 on epoch=162
05/31/2022 09:20:06 - INFO - __main__ - Global step 650 Train loss 0.000770 Classification-F1 0.5134502923976608 on epoch=162
05/31/2022 09:20:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000738 on epoch=164
05/31/2022 09:20:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000441 on epoch=167
05/31/2022 09:20:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.001183 on epoch=169
05/31/2022 09:20:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000146 on epoch=172
05/31/2022 09:20:31 - INFO - __main__ - Step 700 Global step 700 Train loss 0.004235 on epoch=174
05/31/2022 09:20:31 - INFO - __main__ - Global step 700 Train loss 0.001349 Classification-F1 0.5390377412849323 on epoch=174
05/31/2022 09:20:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.003617 on epoch=177
05/31/2022 09:20:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000238 on epoch=179
05/31/2022 09:20:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.001668 on epoch=182
05/31/2022 09:20:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000255 on epoch=184
05/31/2022 09:20:57 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000171 on epoch=187
05/31/2022 09:20:57 - INFO - __main__ - Global step 750 Train loss 0.001190 Classification-F1 0.539313399778516 on epoch=187
05/31/2022 09:21:02 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000223 on epoch=189
05/31/2022 09:21:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000923 on epoch=192
05/31/2022 09:21:13 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000759 on epoch=194
05/31/2022 09:21:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000325 on epoch=197
05/31/2022 09:21:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000122 on epoch=199
05/31/2022 09:21:23 - INFO - __main__ - Global step 800 Train loss 0.000470 Classification-F1 0.619736502195815 on epoch=199
05/31/2022 09:21:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000096 on epoch=202
05/31/2022 09:21:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000020 on epoch=204
05/31/2022 09:21:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000076 on epoch=207
05/31/2022 09:21:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000108 on epoch=209
05/31/2022 09:21:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000170 on epoch=212
05/31/2022 09:21:49 - INFO - __main__ - Global step 850 Train loss 0.000094 Classification-F1 0.619736502195815 on epoch=212
05/31/2022 09:21:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000256 on epoch=214
05/31/2022 09:21:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000069 on epoch=217
05/31/2022 09:22:04 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000040 on epoch=219
05/31/2022 09:22:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000042 on epoch=222
05/31/2022 09:22:14 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000016 on epoch=224
05/31/2022 09:22:15 - INFO - __main__ - Global step 900 Train loss 0.000085 Classification-F1 0.5927889713679746 on epoch=224
05/31/2022 09:22:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000009 on epoch=227
05/31/2022 09:22:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000074 on epoch=229
05/31/2022 09:22:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000979 on epoch=232
05/31/2022 09:22:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.019216 on epoch=234
05/31/2022 09:22:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000244 on epoch=237
05/31/2022 09:22:41 - INFO - __main__ - Global step 950 Train loss 0.004105 Classification-F1 0.5666666666666667 on epoch=237
05/31/2022 09:22:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000315 on epoch=239
05/31/2022 09:22:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000311 on epoch=242
05/31/2022 09:22:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000035 on epoch=244
05/31/2022 09:23:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000121 on epoch=247
05/31/2022 09:23:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000037 on epoch=249
05/31/2022 09:23:07 - INFO - __main__ - Global step 1000 Train loss 0.000164 Classification-F1 0.5536037199690003 on epoch=249
05/31/2022 09:23:07 - INFO - __main__ - save last model!
05/31/2022 09:23:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:23:07 - INFO - __main__ - Printing 3 examples
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:23:07 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:23:07 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:23:07 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:23:07 - INFO - __main__ - Printing 3 examples
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:23:07 - INFO - __main__ - ['false']
05/31/2022 09:23:07 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:23:07 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:23:07 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:23:14 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 09:23:15 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 09:23:15 - INFO - __main__ - Printing 3 examples
05/31/2022 09:23:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 09:23:15 - INFO - __main__ - ['false']
05/31/2022 09:23:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 09:23:15 - INFO - __main__ - ['false']
05/31/2022 09:23:15 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 09:23:15 - INFO - __main__ - ['false']
05/31/2022 09:23:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:23:16 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:23:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:23:18 - INFO - __main__ - Starting training!
05/31/2022 09:23:19 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 09:23:47 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_87_0.0002_8_predictions.txt
05/31/2022 09:23:47 - INFO - __main__ - Classification-F1 on test data: 0.3176
05/31/2022 09:23:48 - INFO - __main__ - prefix=wiki_qa_32_87, lr=0.0002, bsz=8, dev_performance=0.619736502195815, test_performance=0.3175930203320254
05/31/2022 09:23:48 - INFO - __main__ - Running ... prefix=wiki_qa_32_87, lr=0.0001, bsz=8 ...
05/31/2022 09:23:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:23:49 - INFO - __main__ - Printing 3 examples
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: what are the 4 eras of time which one do we live in [SEP] answer: The geologic time scale is a system of chronological measurement that relates stratigraphy to time, and is used by geologists , paleontologists , and other earth scientists to describe the timing and relationships between events that have occurred throughout Earth's history .
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: what is soulja boy's latest song [SEP] answer: However, his next two albums, iSouljaBoyTellem (2008) and The DeAndre Way (2010) did not match the commercial success of his debut, the latter only selling 100,000 copies, despite the success of several singles across both albums, such as " Kiss Me Thru the Phone " and " Turn My Swag On " (iSouljaBoyTellem) and " Pretty Boy Swag " (The DeAndre Way).
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: what does a roman numeral L stand for? [SEP] answer: The Roman numeral system is a cousin of Etruscan numerals .
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:23:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:23:49 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 09:23:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 09:23:49 - INFO - __main__ - Printing 3 examples
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: what did mia hamm do his work [SEP] answer: Hamm was named the women's FIFA World Player of the Year the first two times that award was given (in 2001 and 2002), and is listed as one of FIFA 's 125 best living players (as chosen by Pel ).
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: who invented the biological system of nomenclature used to classify plants and animals [SEP] answer: These groupings have since been revised to improve consistency with the Darwinian principle of common descent .
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ -  [wiki_qa] question: what cars have smart key systems [SEP] answer: A smart key is an electronic access and authorization system which is available as an option or standard in several cars.
05/31/2022 09:23:49 - INFO - __main__ - ['false']
05/31/2022 09:23:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:23:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:23:49 - INFO - __main__ - Loaded 64 examples from dev data
05/31/2022 09:24:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 09:24:01 - INFO - __main__ - Starting training!
05/31/2022 09:24:05 - INFO - __main__ - Step 10 Global step 10 Train loss 25.065943 on epoch=2
05/31/2022 09:24:09 - INFO - __main__ - Step 20 Global step 20 Train loss 20.330627 on epoch=4
05/31/2022 09:24:14 - INFO - __main__ - Step 30 Global step 30 Train loss 18.284046 on epoch=7
05/31/2022 09:24:19 - INFO - __main__ - Step 40 Global step 40 Train loss 19.284195 on epoch=9
05/31/2022 09:24:24 - INFO - __main__ - Step 50 Global step 50 Train loss 18.218565 on epoch=12
05/31/2022 09:24:37 - INFO - __main__ - Global step 50 Train loss 20.236675 Classification-F1 0.0 on epoch=12
05/31/2022 09:24:42 - INFO - __main__ - Step 60 Global step 60 Train loss 17.360092 on epoch=14
05/31/2022 09:24:47 - INFO - __main__ - Step 70 Global step 70 Train loss 16.744965 on epoch=17
05/31/2022 09:24:52 - INFO - __main__ - Step 80 Global step 80 Train loss 16.807125 on epoch=19
05/31/2022 09:24:57 - INFO - __main__ - Step 90 Global step 90 Train loss 16.788769 on epoch=22
05/31/2022 09:25:02 - INFO - __main__ - Step 100 Global step 100 Train loss 16.332315 on epoch=24
05/31/2022 09:25:11 - INFO - __main__ - Global step 100 Train loss 16.806652 Classification-F1 0.0 on epoch=24
05/31/2022 09:25:16 - INFO - __main__ - Step 110 Global step 110 Train loss 15.035166 on epoch=27
05/31/2022 09:25:22 - INFO - __main__ - Step 120 Global step 120 Train loss 15.056028 on epoch=29
05/31/2022 09:25:27 - INFO - __main__ - Step 130 Global step 130 Train loss 14.222685 on epoch=32
05/31/2022 09:25:32 - INFO - __main__ - Step 140 Global step 140 Train loss 14.684941 on epoch=34
05/31/2022 09:25:37 - INFO - __main__ - Step 150 Global step 150 Train loss 13.558205 on epoch=37
05/31/2022 09:25:45 - INFO - __main__ - Global step 150 Train loss 14.511405 Classification-F1 0.0 on epoch=37
05/31/2022 09:25:50 - INFO - __main__ - Step 160 Global step 160 Train loss 12.729946 on epoch=39
05/31/2022 09:25:55 - INFO - __main__ - Step 170 Global step 170 Train loss 12.415018 on epoch=42
05/31/2022 09:26:01 - INFO - __main__ - Step 180 Global step 180 Train loss 13.290117 on epoch=44
05/31/2022 09:26:06 - INFO - __main__ - Step 190 Global step 190 Train loss 12.856003 on epoch=47
05/31/2022 09:26:11 - INFO - __main__ - Step 200 Global step 200 Train loss 10.711576 on epoch=49
05/31/2022 09:26:19 - INFO - __main__ - Global step 200 Train loss 12.400531 Classification-F1 0.0 on epoch=49
05/31/2022 09:26:24 - INFO - __main__ - Step 210 Global step 210 Train loss 10.025606 on epoch=52
05/31/2022 09:26:29 - INFO - __main__ - Step 220 Global step 220 Train loss 7.205877 on epoch=54
05/31/2022 09:26:34 - INFO - __main__ - Step 230 Global step 230 Train loss 2.906837 on epoch=57
05/31/2022 09:26:39 - INFO - __main__ - Step 240 Global step 240 Train loss 2.163785 on epoch=59
05/31/2022 09:26:44 - INFO - __main__ - Step 250 Global step 250 Train loss 1.117352 on epoch=62
05/31/2022 09:26:44 - INFO - __main__ - Global step 250 Train loss 4.683892 Classification-F1 0.429800307219662 on epoch=62
05/31/2022 09:26:50 - INFO - __main__ - Step 260 Global step 260 Train loss 0.922053 on epoch=64
05/31/2022 09:26:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.514006 on epoch=67
05/31/2022 09:27:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.435661 on epoch=69
05/31/2022 09:27:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.481834 on epoch=72
05/31/2022 09:27:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.424794 on epoch=74
05/31/2022 09:27:11 - INFO - __main__ - Global step 300 Train loss 0.555669 Classification-F1 0.6322845417236662 on epoch=74
05/31/2022 09:27:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.321179 on epoch=77
05/31/2022 09:27:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.334094 on epoch=79
05/31/2022 09:27:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.340598 on epoch=82
05/31/2022 09:27:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.264990 on epoch=84
05/31/2022 09:27:37 - INFO - __main__ - Step 350 Global step 350 Train loss 0.164172 on epoch=87
05/31/2022 09:27:38 - INFO - __main__ - Global step 350 Train loss 0.285007 Classification-F1 0.6871945259042034 on epoch=87
05/31/2022 09:27:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.153483 on epoch=89
05/31/2022 09:27:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.111174 on epoch=92
05/31/2022 09:27:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.172378 on epoch=94
05/31/2022 09:27:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.113980 on epoch=97
05/31/2022 09:28:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.088567 on epoch=99
05/31/2022 09:28:04 - INFO - __main__ - Global step 400 Train loss 0.127916 Classification-F1 0.5390377412849323 on epoch=99
05/31/2022 09:28:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.070701 on epoch=102
05/31/2022 09:28:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.056938 on epoch=104
05/31/2022 09:28:19 - INFO - __main__ - Step 430 Global step 430 Train loss 0.062419 on epoch=107
05/31/2022 09:28:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.134783 on epoch=109
05/31/2022 09:28:29 - INFO - __main__ - Step 450 Global step 450 Train loss 0.065327 on epoch=112
05/31/2022 09:28:30 - INFO - __main__ - Global step 450 Train loss 0.078034 Classification-F1 0.6046454163577959 on epoch=112
05/31/2022 09:28:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.086244 on epoch=114
05/31/2022 09:28:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.017514 on epoch=117
05/31/2022 09:28:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.025467 on epoch=119
05/31/2022 09:28:50 - INFO - __main__ - Step 490 Global step 490 Train loss 0.041290 on epoch=122
05/31/2022 09:28:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.027702 on epoch=124
05/31/2022 09:28:56 - INFO - __main__ - Global step 500 Train loss 0.039644 Classification-F1 0.6384180790960452 on epoch=124
05/31/2022 09:29:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.017069 on epoch=127
05/31/2022 09:29:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.016932 on epoch=129
05/31/2022 09:29:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.009604 on epoch=132
05/31/2022 09:29:16 - INFO - __main__ - Step 540 Global step 540 Train loss 0.035336 on epoch=134
05/31/2022 09:29:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.025355 on epoch=137
05/31/2022 09:29:22 - INFO - __main__ - Global step 550 Train loss 0.020859 Classification-F1 0.6469661150512215 on epoch=137
05/31/2022 09:29:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.014215 on epoch=139
05/31/2022 09:29:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.008054 on epoch=142
05/31/2022 09:29:37 - INFO - __main__ - Step 580 Global step 580 Train loss 0.018717 on epoch=144
05/31/2022 09:29:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.022534 on epoch=147
05/31/2022 09:29:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.010838 on epoch=149
05/31/2022 09:29:48 - INFO - __main__ - Global step 600 Train loss 0.014871 Classification-F1 0.6133438402941949 on epoch=149
05/31/2022 09:29:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.006200 on epoch=152
05/31/2022 09:29:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.015171 on epoch=154
05/31/2022 09:30:03 - INFO - __main__ - Step 630 Global step 630 Train loss 0.006144 on epoch=157
05/31/2022 09:30:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.003299 on epoch=159
05/31/2022 09:30:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.005257 on epoch=162
05/31/2022 09:30:14 - INFO - __main__ - Global step 650 Train loss 0.007214 Classification-F1 0.6069761729304839 on epoch=162
05/31/2022 09:30:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.001985 on epoch=164
05/31/2022 09:30:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.005234 on epoch=167
05/31/2022 09:30:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.006994 on epoch=169
05/31/2022 09:30:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.013566 on epoch=172
05/31/2022 09:30:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.016852 on epoch=174
05/31/2022 09:30:40 - INFO - __main__ - Global step 700 Train loss 0.008926 Classification-F1 0.6156156156156156 on epoch=174
05/31/2022 09:30:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002890 on epoch=177
05/31/2022 09:30:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.011681 on epoch=179
05/31/2022 09:30:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.001750 on epoch=182
05/31/2022 09:31:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000891 on epoch=184
05/31/2022 09:31:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.002843 on epoch=187
05/31/2022 09:31:06 - INFO - __main__ - Global step 750 Train loss 0.004011 Classification-F1 0.5927889713679746 on epoch=187
05/31/2022 09:31:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.004986 on epoch=189
05/31/2022 09:31:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.003797 on epoch=192
05/31/2022 09:31:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000771 on epoch=194
05/31/2022 09:31:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000394 on epoch=197
05/31/2022 09:31:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.001880 on epoch=199
05/31/2022 09:31:32 - INFO - __main__ - Global step 800 Train loss 0.002366 Classification-F1 0.6267232237539766 on epoch=199
05/31/2022 09:31:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000347 on epoch=202
05/31/2022 09:31:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.003777 on epoch=204
05/31/2022 09:31:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000724 on epoch=207
05/31/2022 09:31:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001703 on epoch=209
05/31/2022 09:31:57 - INFO - __main__ - Step 850 Global step 850 Train loss 0.003565 on epoch=212
05/31/2022 09:31:58 - INFO - __main__ - Global step 850 Train loss 0.002023 Classification-F1 0.6532019704433498 on epoch=212
05/31/2022 09:32:03 - INFO - __main__ - Step 860 Global step 860 Train loss 0.008123 on epoch=214
05/31/2022 09:32:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.003414 on epoch=217
05/31/2022 09:32:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000524 on epoch=219
05/31/2022 09:32:18 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000894 on epoch=222
05/31/2022 09:32:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.003649 on epoch=224
05/31/2022 09:32:23 - INFO - __main__ - Global step 900 Train loss 0.003321 Classification-F1 0.6133438402941949 on epoch=224
05/31/2022 09:32:28 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000334 on epoch=227
05/31/2022 09:32:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000116 on epoch=229
05/31/2022 09:32:38 - INFO - __main__ - Step 930 Global step 930 Train loss 0.004096 on epoch=232
05/31/2022 09:32:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000308 on epoch=234
05/31/2022 09:32:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000769 on epoch=237
05/31/2022 09:32:49 - INFO - __main__ - Global step 950 Train loss 0.001125 Classification-F1 0.6862745098039216 on epoch=237
05/31/2022 09:32:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000444 on epoch=239
05/31/2022 09:32:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.003902 on epoch=242
05/31/2022 09:33:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001021 on epoch=244
05/31/2022 09:33:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000718 on epoch=247
05/31/2022 09:33:14 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000357 on epoch=249
05/31/2022 09:33:15 - INFO - __main__ - Global step 1000 Train loss 0.001288 Classification-F1 0.6652552926525529 on epoch=249
05/31/2022 09:33:15 - INFO - __main__ - save last model!
05/31/2022 09:33:22 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 09:33:23 - INFO - __main__ - Start tokenizing ... 2733 instances
05/31/2022 09:33:23 - INFO - __main__ - Printing 3 examples
05/31/2022 09:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Cross section of sclerenchyma fibers in plant ground tissue
05/31/2022 09:33:23 - INFO - __main__ - ['false']
05/31/2022 09:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: Microscopic view of a histologic specimen of human lung tissue stained with hematoxylin and eosin .
05/31/2022 09:33:23 - INFO - __main__ - ['false']
05/31/2022 09:33:23 - INFO - __main__ -  [wiki_qa] question: How are epithelial tissues joined together? [SEP] answer: In Biology , Tissue is a cellular organizational level intermediate between cells and a complete organism .
05/31/2022 09:33:23 - INFO - __main__ - ['false']
05/31/2022 09:33:23 - INFO - __main__ - Tokenizing Input ...
05/31/2022 09:33:24 - INFO - __main__ - Tokenizing Output ...
05/31/2022 09:33:27 - INFO - __main__ - Loaded 2733 examples from test data
05/31/2022 09:33:55 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-wiki_qa/wiki_qa_32_87_0.0001_8_predictions.txt
05/31/2022 09:33:55 - INFO - __main__ - Classification-F1 on test data: 0.4239
05/31/2022 09:33:56 - INFO - __main__ - prefix=wiki_qa_32_87, lr=0.0001, bsz=8, dev_performance=0.6871945259042034, test_performance=0.423907138613021
