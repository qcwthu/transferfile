05/21/2022 21:21:48 - INFO - __main__ - Namespace(task_dir='data_32/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:21:48 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion
05/21/2022 21:21:48 - INFO - __main__ - Namespace(task_dir='data_32/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/21/2022 21:21:48 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion
05/21/2022 21:21:50 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/21/2022 21:21:50 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/21/2022 21:21:50 - INFO - __main__ - args.device: cuda:0
05/21/2022 21:21:50 - INFO - __main__ - Using 2 gpus
05/21/2022 21:21:50 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_32_100', 'ethos-religion_32_13', 'ethos-religion_32_21', 'ethos-religion_32_42', 'ethos-religion_32_87']
05/21/2022 21:21:50 - INFO - __main__ - args.device: cuda:1
05/21/2022 21:21:50 - INFO - __main__ - Using 2 gpus
05/21/2022 21:21:50 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_32_100', 'ethos-religion_32_13', 'ethos-religion_32_21', 'ethos-religion_32_42', 'ethos-religion_32_87']
05/21/2022 21:21:55 - INFO - __main__ - Running ... prefix=ethos-religion_32_100, lr=0.0005, bsz=8 ...
05/31/2022 18:17:20 - INFO - __main__ - Namespace(task_dir='data_32/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/31/2022 18:17:20 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion
05/31/2022 18:17:20 - INFO - __main__ - Namespace(task_dir='data_32/ethos-religion/', task_name='ethos-religion', identifier='T5-large-ft-cls2cls-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=32, learning_rate=3e-05, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=300.0, warmup_steps=50, total_steps=1000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.0005, 0.0003, 0.0002, 0.0001], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, model='google/t5-v1_1-large', cuda='2,3')
05/31/2022 18:17:20 - INFO - __main__ - models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion
05/31/2022 18:17:22 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/31/2022 18:17:22 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/31/2022 18:17:22 - INFO - __main__ - args.device: cuda:0
05/31/2022 18:17:22 - INFO - __main__ - args.device: cuda:1
05/31/2022 18:17:22 - INFO - __main__ - Using 2 gpus
05/31/2022 18:17:22 - INFO - __main__ - Using 2 gpus
05/31/2022 18:17:22 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_32_100', 'ethos-religion_32_13', 'ethos-religion_32_21', 'ethos-religion_32_42', 'ethos-religion_32_87']
05/31/2022 18:17:22 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_32_100', 'ethos-religion_32_13', 'ethos-religion_32_21', 'ethos-religion_32_42', 'ethos-religion_32_87']
05/31/2022 18:17:26 - INFO - __main__ - Running ... prefix=ethos-religion_32_100, lr=0.0005, bsz=8 ...
05/31/2022 18:17:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:17:27 - INFO - __main__ - Printing 3 examples
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:17:27 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:17:27 - INFO - __main__ - Printing 3 examples
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:17:27 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:17:27 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:17:27 - INFO - __main__ - Printing 3 examples
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:17:27 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:17:27 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:17:27 - INFO - __main__ - Printing 3 examples
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:17:27 - INFO - __main__ - ['false']
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:17:27 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:17:27 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:17:27 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:17:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:17:40 - INFO - __main__ - Starting training!
05/31/2022 18:17:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:17:41 - INFO - __main__ - Starting training!
05/31/2022 18:17:46 - INFO - __main__ - Step 10 Global step 10 Train loss 24.051306 on epoch=2
05/31/2022 18:17:50 - INFO - __main__ - Step 20 Global step 20 Train loss 18.626987 on epoch=4
05/31/2022 18:17:55 - INFO - __main__ - Step 30 Global step 30 Train loss 16.004362 on epoch=7
05/31/2022 18:18:00 - INFO - __main__ - Step 40 Global step 40 Train loss 15.162130 on epoch=9
05/31/2022 18:18:05 - INFO - __main__ - Step 50 Global step 50 Train loss 12.743509 on epoch=12
05/31/2022 18:18:06 - INFO - __main__ - Global step 50 Train loss 17.317659 Classification-F1 0.0 on epoch=12
05/31/2022 18:18:12 - INFO - __main__ - Step 60 Global step 60 Train loss 9.740458 on epoch=14
05/31/2022 18:18:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.711285 on epoch=17
05/31/2022 18:18:22 - INFO - __main__ - Step 80 Global step 80 Train loss 0.662101 on epoch=19
05/31/2022 18:18:27 - INFO - __main__ - Step 90 Global step 90 Train loss 0.648199 on epoch=22
05/31/2022 18:18:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.567532 on epoch=24
05/31/2022 18:18:33 - INFO - __main__ - Global step 100 Train loss 2.665915 Classification-F1 0.3404255319148936 on epoch=24
05/31/2022 18:18:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.589692 on epoch=27
05/31/2022 18:18:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.409316 on epoch=29
05/31/2022 18:18:51 - INFO - __main__ - Step 130 Global step 130 Train loss 0.512691 on epoch=32
05/31/2022 18:18:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.315024 on epoch=34
05/31/2022 18:19:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.301146 on epoch=37
05/31/2022 18:19:02 - INFO - __main__ - Global step 150 Train loss 0.425574 Classification-F1 0.6794557823129252 on epoch=37
05/31/2022 18:19:08 - INFO - __main__ - Step 160 Global step 160 Train loss 0.203650 on epoch=39
05/31/2022 18:19:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.276010 on epoch=42
05/31/2022 18:19:18 - INFO - __main__ - Step 180 Global step 180 Train loss 1.064299 on epoch=44
05/31/2022 18:19:23 - INFO - __main__ - Step 190 Global step 190 Train loss 1.253521 on epoch=47
05/31/2022 18:19:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.537779 on epoch=49
05/31/2022 18:19:29 - INFO - __main__ - Global step 200 Train loss 0.667052 Classification-F1 0.5094306363476115 on epoch=49
05/31/2022 18:19:34 - INFO - __main__ - Step 210 Global step 210 Train loss 0.420763 on epoch=52
05/31/2022 18:19:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.458362 on epoch=54
05/31/2022 18:19:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.515024 on epoch=57
05/31/2022 18:19:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.233883 on epoch=59
05/31/2022 18:19:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.339965 on epoch=62
05/31/2022 18:19:55 - INFO - __main__ - Global step 250 Train loss 0.393599 Classification-F1 0.7350427350427351 on epoch=62
05/31/2022 18:20:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.533862 on epoch=64
05/31/2022 18:20:07 - INFO - __main__ - Step 270 Global step 270 Train loss 0.216664 on epoch=67
05/31/2022 18:20:12 - INFO - __main__ - Step 280 Global step 280 Train loss 0.137894 on epoch=69
05/31/2022 18:20:17 - INFO - __main__ - Step 290 Global step 290 Train loss 0.202610 on epoch=72
05/31/2022 18:20:22 - INFO - __main__ - Step 300 Global step 300 Train loss 0.095355 on epoch=74
05/31/2022 18:20:23 - INFO - __main__ - Global step 300 Train loss 0.237277 Classification-F1 0.8544980443285528 on epoch=74
05/31/2022 18:20:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.152679 on epoch=77
05/31/2022 18:20:34 - INFO - __main__ - Step 320 Global step 320 Train loss 0.110467 on epoch=79
05/31/2022 18:20:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.118414 on epoch=82
05/31/2022 18:20:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.090046 on epoch=84
05/31/2022 18:20:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.077175 on epoch=87
05/31/2022 18:20:50 - INFO - __main__ - Global step 350 Train loss 0.109756 Classification-F1 0.8538884524744697 on epoch=87
05/31/2022 18:20:56 - INFO - __main__ - Step 360 Global step 360 Train loss 0.099100 on epoch=89
05/31/2022 18:21:01 - INFO - __main__ - Step 370 Global step 370 Train loss 0.076715 on epoch=92
05/31/2022 18:21:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.045168 on epoch=94
05/31/2022 18:21:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.106530 on epoch=97
05/31/2022 18:21:16 - INFO - __main__ - Step 400 Global step 400 Train loss 0.022792 on epoch=99
05/31/2022 18:21:17 - INFO - __main__ - Global step 400 Train loss 0.070061 Classification-F1 0.9193338537600833 on epoch=99
05/31/2022 18:21:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.024774 on epoch=102
05/31/2022 18:21:28 - INFO - __main__ - Step 420 Global step 420 Train loss 0.085975 on epoch=104
05/31/2022 18:21:33 - INFO - __main__ - Step 430 Global step 430 Train loss 0.049947 on epoch=107
05/31/2022 18:21:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.040691 on epoch=109
05/31/2022 18:21:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.003128 on epoch=112
05/31/2022 18:21:44 - INFO - __main__ - Global step 450 Train loss 0.040903 Classification-F1 0.8187616263619453 on epoch=112
05/31/2022 18:21:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.017267 on epoch=114
05/31/2022 18:21:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.034473 on epoch=117
05/31/2022 18:21:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.014650 on epoch=119
05/31/2022 18:22:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.009822 on epoch=122
05/31/2022 18:22:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.043966 on epoch=124
05/31/2022 18:22:10 - INFO - __main__ - Global step 500 Train loss 0.024036 Classification-F1 0.9354838709677419 on epoch=124
05/31/2022 18:22:16 - INFO - __main__ - Step 510 Global step 510 Train loss 0.010746 on epoch=127
05/31/2022 18:22:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.030434 on epoch=129
05/31/2022 18:22:26 - INFO - __main__ - Step 530 Global step 530 Train loss 0.011952 on epoch=132
05/31/2022 18:22:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000964 on epoch=134
05/31/2022 18:22:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.003032 on epoch=137
05/31/2022 18:22:37 - INFO - __main__ - Global step 550 Train loss 0.011425 Classification-F1 0.9191655801825294 on epoch=137
05/31/2022 18:22:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.004209 on epoch=139
05/31/2022 18:22:47 - INFO - __main__ - Step 570 Global step 570 Train loss 0.025716 on epoch=142
05/31/2022 18:22:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.003263 on epoch=144
05/31/2022 18:22:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000687 on epoch=147
05/31/2022 18:23:02 - INFO - __main__ - Step 600 Global step 600 Train loss 0.024660 on epoch=149
05/31/2022 18:23:03 - INFO - __main__ - Global step 600 Train loss 0.011707 Classification-F1 0.9516003122560499 on epoch=149
05/31/2022 18:23:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.002299 on epoch=152
05/31/2022 18:23:14 - INFO - __main__ - Step 620 Global step 620 Train loss 0.003726 on epoch=154
05/31/2022 18:23:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.006180 on epoch=157
05/31/2022 18:23:24 - INFO - __main__ - Step 640 Global step 640 Train loss 0.066186 on epoch=159
05/31/2022 18:23:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.001174 on epoch=162
05/31/2022 18:23:30 - INFO - __main__ - Global step 650 Train loss 0.015913 Classification-F1 0.9354166666666667 on epoch=162
05/31/2022 18:23:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000404 on epoch=164
05/31/2022 18:23:40 - INFO - __main__ - Step 670 Global step 670 Train loss 0.003338 on epoch=167
05/31/2022 18:23:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.004683 on epoch=169
05/31/2022 18:23:50 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000174 on epoch=172
05/31/2022 18:23:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.093874 on epoch=174
05/31/2022 18:23:56 - INFO - __main__ - Global step 700 Train loss 0.020495 Classification-F1 0.8870673952641166 on epoch=174
05/31/2022 18:24:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.006742 on epoch=177
05/31/2022 18:24:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.026843 on epoch=179
05/31/2022 18:24:11 - INFO - __main__ - Step 730 Global step 730 Train loss 0.012398 on epoch=182
05/31/2022 18:24:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.042161 on epoch=184
05/31/2022 18:24:22 - INFO - __main__ - Step 750 Global step 750 Train loss 0.037679 on epoch=187
05/31/2022 18:24:22 - INFO - __main__ - Global step 750 Train loss 0.025165 Classification-F1 0.8012820512820513 on epoch=187
05/31/2022 18:24:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.003946 on epoch=189
05/31/2022 18:24:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000269 on epoch=192
05/31/2022 18:24:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.126110 on epoch=194
05/31/2022 18:24:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.001047 on epoch=197
05/31/2022 18:24:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004534 on epoch=199
05/31/2022 18:24:48 - INFO - __main__ - Global step 800 Train loss 0.027181 Classification-F1 0.9191655801825294 on epoch=199
05/31/2022 18:24:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.004553 on epoch=202
05/31/2022 18:24:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.009334 on epoch=204
05/31/2022 18:25:04 - INFO - __main__ - Step 830 Global step 830 Train loss 0.033427 on epoch=207
05/31/2022 18:25:09 - INFO - __main__ - Step 840 Global step 840 Train loss 0.014236 on epoch=209
05/31/2022 18:25:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.006517 on epoch=212
05/31/2022 18:25:14 - INFO - __main__ - Global step 850 Train loss 0.013613 Classification-F1 0.9032258064516129 on epoch=212
05/31/2022 18:25:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.029998 on epoch=214
05/31/2022 18:25:24 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000951 on epoch=217
05/31/2022 18:25:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.001962 on epoch=219
05/31/2022 18:25:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.014716 on epoch=222
05/31/2022 18:25:40 - INFO - __main__ - Step 900 Global step 900 Train loss 0.003292 on epoch=224
05/31/2022 18:25:41 - INFO - __main__ - Global step 900 Train loss 0.010184 Classification-F1 0.9354166666666667 on epoch=224
05/31/2022 18:25:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.001514 on epoch=227
05/31/2022 18:25:51 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000937 on epoch=229
05/31/2022 18:25:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001220 on epoch=232
05/31/2022 18:26:01 - INFO - __main__ - Step 940 Global step 940 Train loss 0.004714 on epoch=234
05/31/2022 18:26:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.002063 on epoch=237
05/31/2022 18:26:07 - INFO - __main__ - Global step 950 Train loss 0.002090 Classification-F1 0.9032258064516129 on epoch=237
05/31/2022 18:26:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000509 on epoch=239
05/31/2022 18:26:17 - INFO - __main__ - Step 970 Global step 970 Train loss 0.013834 on epoch=242
05/31/2022 18:26:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000335 on epoch=244
05/31/2022 18:26:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000941 on epoch=247
05/31/2022 18:26:32 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.018755 on epoch=249
05/31/2022 18:26:33 - INFO - __main__ - Global step 1000 Train loss 0.006875 Classification-F1 0.9028213166144201 on epoch=249
05/31/2022 18:26:33 - INFO - __main__ - save last model!
05/31/2022 18:26:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:26:33 - INFO - __main__ - Printing 3 examples
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:26:33 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:26:33 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:26:33 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:26:33 - INFO - __main__ - Printing 3 examples
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:26:33 - INFO - __main__ - ['false']
05/31/2022 18:26:33 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:26:33 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:26:33 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:26:39 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 18:26:40 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 18:26:40 - INFO - __main__ - Printing 3 examples
05/31/2022 18:26:40 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 18:26:40 - INFO - __main__ - ['false']
05/31/2022 18:26:40 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 18:26:40 - INFO - __main__ - ['false']
05/31/2022 18:26:40 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 18:26:40 - INFO - __main__ - ['true']
05/31/2022 18:26:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:26:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:26:40 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 18:26:42 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_100_0.0005_8_predictions.txt
05/31/2022 18:26:42 - INFO - __main__ - Classification-F1 on test data: 0.8688
05/31/2022 18:26:42 - INFO - __main__ - prefix=ethos-religion_32_100, lr=0.0005, bsz=8, dev_performance=0.9516003122560499, test_performance=0.8688222482827945
05/31/2022 18:26:42 - INFO - __main__ - Running ... prefix=ethos-religion_32_100, lr=0.0003, bsz=8 ...
05/31/2022 18:26:43 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:26:43 - INFO - __main__ - Printing 3 examples
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:26:43 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:26:43 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:26:43 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:26:43 - INFO - __main__ - Printing 3 examples
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:26:43 - INFO - __main__ - ['false']
05/31/2022 18:26:43 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:26:43 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:26:43 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:26:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:26:44 - INFO - __main__ - Starting training!
05/31/2022 18:26:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:26:54 - INFO - __main__ - Starting training!
05/31/2022 18:26:58 - INFO - __main__ - Step 10 Global step 10 Train loss 23.110657 on epoch=2
05/31/2022 18:27:03 - INFO - __main__ - Step 20 Global step 20 Train loss 19.172667 on epoch=4
05/31/2022 18:27:08 - INFO - __main__ - Step 30 Global step 30 Train loss 16.791409 on epoch=7
05/31/2022 18:27:13 - INFO - __main__ - Step 40 Global step 40 Train loss 16.802906 on epoch=9
05/31/2022 18:27:18 - INFO - __main__ - Step 50 Global step 50 Train loss 14.889117 on epoch=12
05/31/2022 18:27:19 - INFO - __main__ - Global step 50 Train loss 18.153351 Classification-F1 0.0 on epoch=12
05/31/2022 18:27:25 - INFO - __main__ - Step 60 Global step 60 Train loss 14.042814 on epoch=14
05/31/2022 18:27:30 - INFO - __main__ - Step 70 Global step 70 Train loss 12.892244 on epoch=17
05/31/2022 18:27:35 - INFO - __main__ - Step 80 Global step 80 Train loss 10.447729 on epoch=19
05/31/2022 18:27:40 - INFO - __main__ - Step 90 Global step 90 Train loss 5.628340 on epoch=22
05/31/2022 18:27:45 - INFO - __main__ - Step 100 Global step 100 Train loss 1.848418 on epoch=24
05/31/2022 18:27:45 - INFO - __main__ - Global step 100 Train loss 8.971910 Classification-F1 0.24614305750350632 on epoch=24
05/31/2022 18:27:51 - INFO - __main__ - Step 110 Global step 110 Train loss 2.216868 on epoch=27
05/31/2022 18:27:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.112681 on epoch=29
05/31/2022 18:28:01 - INFO - __main__ - Step 130 Global step 130 Train loss 0.675776 on epoch=32
05/31/2022 18:28:06 - INFO - __main__ - Step 140 Global step 140 Train loss 0.492172 on epoch=34
05/31/2022 18:28:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.410029 on epoch=37
05/31/2022 18:28:12 - INFO - __main__ - Global step 150 Train loss 0.981505 Classification-F1 0.4799627213420317 on epoch=37
05/31/2022 18:28:18 - INFO - __main__ - Step 160 Global step 160 Train loss 0.285861 on epoch=39
05/31/2022 18:28:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.557438 on epoch=42
05/31/2022 18:28:28 - INFO - __main__ - Step 180 Global step 180 Train loss 0.429320 on epoch=44
05/31/2022 18:28:33 - INFO - __main__ - Step 190 Global step 190 Train loss 0.942157 on epoch=47
05/31/2022 18:28:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.550382 on epoch=49
05/31/2022 18:28:39 - INFO - __main__ - Global step 200 Train loss 0.553032 Classification-F1 0.43084455324357407 on epoch=49
05/31/2022 18:28:44 - INFO - __main__ - Step 210 Global step 210 Train loss 0.276963 on epoch=52
05/31/2022 18:28:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.240542 on epoch=54
05/31/2022 18:28:54 - INFO - __main__ - Step 230 Global step 230 Train loss 0.194374 on epoch=57
05/31/2022 18:28:59 - INFO - __main__ - Step 240 Global step 240 Train loss 0.172268 on epoch=59
05/31/2022 18:29:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.206506 on epoch=62
05/31/2022 18:29:05 - INFO - __main__ - Global step 250 Train loss 0.218131 Classification-F1 0.7858091947913899 on epoch=62
05/31/2022 18:29:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.155697 on epoch=64
05/31/2022 18:29:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.170098 on epoch=67
05/31/2022 18:29:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.168712 on epoch=69
05/31/2022 18:29:25 - INFO - __main__ - Step 290 Global step 290 Train loss 0.114531 on epoch=72
05/31/2022 18:29:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.160230 on epoch=74
05/31/2022 18:29:31 - INFO - __main__ - Global step 300 Train loss 0.153854 Classification-F1 0.8056426332288401 on epoch=74
05/31/2022 18:29:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.247518 on epoch=77
05/31/2022 18:29:42 - INFO - __main__ - Step 320 Global step 320 Train loss 0.105128 on epoch=79
05/31/2022 18:29:47 - INFO - __main__ - Step 330 Global step 330 Train loss 0.120611 on epoch=82
05/31/2022 18:29:52 - INFO - __main__ - Step 340 Global step 340 Train loss 0.099117 on epoch=84
05/31/2022 18:29:57 - INFO - __main__ - Step 350 Global step 350 Train loss 0.117239 on epoch=87
05/31/2022 18:29:58 - INFO - __main__ - Global step 350 Train loss 0.137923 Classification-F1 0.8371848739495799 on epoch=87
05/31/2022 18:30:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.057490 on epoch=89
05/31/2022 18:30:09 - INFO - __main__ - Step 370 Global step 370 Train loss 0.073853 on epoch=92
05/31/2022 18:30:14 - INFO - __main__ - Step 380 Global step 380 Train loss 0.046782 on epoch=94
05/31/2022 18:30:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.071190 on epoch=97
05/31/2022 18:30:24 - INFO - __main__ - Step 400 Global step 400 Train loss 0.061090 on epoch=99
05/31/2022 18:30:25 - INFO - __main__ - Global step 400 Train loss 0.062081 Classification-F1 0.9191655801825294 on epoch=99
05/31/2022 18:30:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.062643 on epoch=102
05/31/2022 18:30:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.040044 on epoch=104
05/31/2022 18:30:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.046455 on epoch=107
05/31/2022 18:30:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.019485 on epoch=109
05/31/2022 18:30:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.058242 on epoch=112
05/31/2022 18:30:52 - INFO - __main__ - Global step 450 Train loss 0.045374 Classification-F1 0.9028213166144201 on epoch=112
05/31/2022 18:30:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.086506 on epoch=114
05/31/2022 18:31:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.165034 on epoch=117
05/31/2022 18:31:07 - INFO - __main__ - Step 480 Global step 480 Train loss 0.014172 on epoch=119
05/31/2022 18:31:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.029800 on epoch=122
05/31/2022 18:31:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.125996 on epoch=124
05/31/2022 18:31:18 - INFO - __main__ - Global step 500 Train loss 0.084302 Classification-F1 0.9032258064516129 on epoch=124
05/31/2022 18:31:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.021839 on epoch=127
05/31/2022 18:31:28 - INFO - __main__ - Step 520 Global step 520 Train loss 0.021094 on epoch=129
05/31/2022 18:31:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.033571 on epoch=132
05/31/2022 18:31:38 - INFO - __main__ - Step 540 Global step 540 Train loss 0.003413 on epoch=134
05/31/2022 18:31:44 - INFO - __main__ - Step 550 Global step 550 Train loss 0.076428 on epoch=137
05/31/2022 18:31:44 - INFO - __main__ - Global step 550 Train loss 0.031269 Classification-F1 0.9028213166144201 on epoch=137
05/31/2022 18:31:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005242 on epoch=139
05/31/2022 18:31:54 - INFO - __main__ - Step 570 Global step 570 Train loss 0.003615 on epoch=142
05/31/2022 18:32:00 - INFO - __main__ - Step 580 Global step 580 Train loss 0.005991 on epoch=144
05/31/2022 18:32:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.004714 on epoch=147
05/31/2022 18:32:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.085211 on epoch=149
05/31/2022 18:32:10 - INFO - __main__ - Global step 600 Train loss 0.020955 Classification-F1 0.9354166666666667 on epoch=149
05/31/2022 18:32:16 - INFO - __main__ - Step 610 Global step 610 Train loss 0.003271 on epoch=152
05/31/2022 18:32:21 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001793 on epoch=154
05/31/2022 18:32:26 - INFO - __main__ - Step 630 Global step 630 Train loss 0.018105 on epoch=157
05/31/2022 18:32:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.015074 on epoch=159
05/31/2022 18:32:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.055300 on epoch=162
05/31/2022 18:32:37 - INFO - __main__ - Global step 650 Train loss 0.018709 Classification-F1 0.9354838709677419 on epoch=162
05/31/2022 18:32:43 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002710 on epoch=164
05/31/2022 18:32:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.008416 on epoch=167
05/31/2022 18:32:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.031722 on epoch=169
05/31/2022 18:32:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.004089 on epoch=172
05/31/2022 18:33:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000614 on epoch=174
05/31/2022 18:33:04 - INFO - __main__ - Global step 700 Train loss 0.009510 Classification-F1 0.9516003122560499 on epoch=174
05/31/2022 18:33:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000274 on epoch=177
05/31/2022 18:33:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000320 on epoch=179
05/31/2022 18:33:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.006904 on epoch=182
05/31/2022 18:33:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000135 on epoch=184
05/31/2022 18:33:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001401 on epoch=187
05/31/2022 18:33:31 - INFO - __main__ - Global step 750 Train loss 0.001807 Classification-F1 0.903125 on epoch=187
05/31/2022 18:33:36 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000269 on epoch=189
05/31/2022 18:33:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.001399 on epoch=192
05/31/2022 18:33:46 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000076 on epoch=194
05/31/2022 18:33:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.004652 on epoch=197
05/31/2022 18:33:57 - INFO - __main__ - Step 800 Global step 800 Train loss 0.024734 on epoch=199
05/31/2022 18:33:57 - INFO - __main__ - Global step 800 Train loss 0.006226 Classification-F1 0.9191655801825294 on epoch=199
05/31/2022 18:34:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.048052 on epoch=202
05/31/2022 18:34:07 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000642 on epoch=204
05/31/2022 18:34:12 - INFO - __main__ - Step 830 Global step 830 Train loss 0.003931 on epoch=207
05/31/2022 18:34:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.066113 on epoch=209
05/31/2022 18:34:22 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000317 on epoch=212
05/31/2022 18:34:23 - INFO - __main__ - Global step 850 Train loss 0.023811 Classification-F1 0.9354838709677419 on epoch=212
05/31/2022 18:34:28 - INFO - __main__ - Step 860 Global step 860 Train loss 0.002070 on epoch=214
05/31/2022 18:34:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000071 on epoch=217
05/31/2022 18:34:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000064 on epoch=219
05/31/2022 18:34:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001182 on epoch=222
05/31/2022 18:34:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000115 on epoch=224
05/31/2022 18:34:49 - INFO - __main__ - Global step 900 Train loss 0.000700 Classification-F1 0.9354166666666667 on epoch=224
05/31/2022 18:34:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.010646 on epoch=227
05/31/2022 18:35:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.003407 on epoch=229
05/31/2022 18:35:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000075 on epoch=232
05/31/2022 18:35:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000129 on epoch=234
05/31/2022 18:35:15 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000303 on epoch=237
05/31/2022 18:35:16 - INFO - __main__ - Global step 950 Train loss 0.002912 Classification-F1 0.9354166666666667 on epoch=237
05/31/2022 18:35:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000149 on epoch=239
05/31/2022 18:35:26 - INFO - __main__ - Step 970 Global step 970 Train loss 0.009494 on epoch=242
05/31/2022 18:35:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000134 on epoch=244
05/31/2022 18:35:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.001146 on epoch=247
05/31/2022 18:35:41 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000096 on epoch=249
05/31/2022 18:35:42 - INFO - __main__ - Global step 1000 Train loss 0.002204 Classification-F1 0.9354166666666667 on epoch=249
05/31/2022 18:35:42 - INFO - __main__ - save last model!
05/31/2022 18:35:42 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:35:42 - INFO - __main__ - Printing 3 examples
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:35:42 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:35:42 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:35:42 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:35:42 - INFO - __main__ - Printing 3 examples
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:35:42 - INFO - __main__ - ['false']
05/31/2022 18:35:42 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:35:42 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:35:42 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:35:49 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 18:35:50 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 18:35:50 - INFO - __main__ - Printing 3 examples
05/31/2022 18:35:50 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 18:35:50 - INFO - __main__ - ['false']
05/31/2022 18:35:50 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 18:35:50 - INFO - __main__ - ['false']
05/31/2022 18:35:50 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 18:35:50 - INFO - __main__ - ['true']
05/31/2022 18:35:50 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:35:50 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:35:50 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 18:35:51 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_100_0.0003_8_predictions.txt
05/31/2022 18:35:51 - INFO - __main__ - Classification-F1 on test data: 0.8316
05/31/2022 18:35:52 - INFO - __main__ - prefix=ethos-religion_32_100, lr=0.0003, bsz=8, dev_performance=0.9516003122560499, test_performance=0.8316129032258064
05/31/2022 18:35:52 - INFO - __main__ - Running ... prefix=ethos-religion_32_100, lr=0.0002, bsz=8 ...
05/31/2022 18:35:53 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:35:53 - INFO - __main__ - Printing 3 examples
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:35:53 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:35:53 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:35:53 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:35:53 - INFO - __main__ - Printing 3 examples
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:35:53 - INFO - __main__ - ['false']
05/31/2022 18:35:53 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:35:53 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:35:53 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:35:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:35:53 - INFO - __main__ - Starting training!
05/31/2022 18:36:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:36:04 - INFO - __main__ - Starting training!
05/31/2022 18:36:08 - INFO - __main__ - Step 10 Global step 10 Train loss 23.767267 on epoch=2
05/31/2022 18:36:13 - INFO - __main__ - Step 20 Global step 20 Train loss 20.120417 on epoch=4
05/31/2022 18:36:18 - INFO - __main__ - Step 30 Global step 30 Train loss 18.639711 on epoch=7
05/31/2022 18:36:23 - INFO - __main__ - Step 40 Global step 40 Train loss 17.222178 on epoch=9
05/31/2022 18:36:28 - INFO - __main__ - Step 50 Global step 50 Train loss 16.621120 on epoch=12
05/31/2022 18:36:46 - INFO - __main__ - Global step 50 Train loss 19.274137 Classification-F1 0.0 on epoch=12
05/31/2022 18:36:52 - INFO - __main__ - Step 60 Global step 60 Train loss 15.348259 on epoch=14
05/31/2022 18:36:57 - INFO - __main__ - Step 70 Global step 70 Train loss 15.385521 on epoch=17
05/31/2022 18:37:02 - INFO - __main__ - Step 80 Global step 80 Train loss 14.441752 on epoch=19
05/31/2022 18:37:07 - INFO - __main__ - Step 90 Global step 90 Train loss 13.552492 on epoch=22
05/31/2022 18:37:12 - INFO - __main__ - Step 100 Global step 100 Train loss 12.533041 on epoch=24
05/31/2022 18:37:28 - INFO - __main__ - Global step 100 Train loss 14.252212 Classification-F1 0.0 on epoch=24
05/31/2022 18:37:33 - INFO - __main__ - Step 110 Global step 110 Train loss 10.894670 on epoch=27
05/31/2022 18:37:38 - INFO - __main__ - Step 120 Global step 120 Train loss 8.396668 on epoch=29
05/31/2022 18:37:43 - INFO - __main__ - Step 130 Global step 130 Train loss 5.210410 on epoch=32
05/31/2022 18:37:48 - INFO - __main__ - Step 140 Global step 140 Train loss 2.294888 on epoch=34
05/31/2022 18:37:53 - INFO - __main__ - Step 150 Global step 150 Train loss 2.038336 on epoch=37
05/31/2022 18:37:54 - INFO - __main__ - Global step 150 Train loss 5.766995 Classification-F1 0.15176151761517617 on epoch=37
05/31/2022 18:38:01 - INFO - __main__ - Step 160 Global step 160 Train loss 2.170781 on epoch=39
05/31/2022 18:38:06 - INFO - __main__ - Step 170 Global step 170 Train loss 1.335858 on epoch=42
05/31/2022 18:38:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.896754 on epoch=44
05/31/2022 18:38:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.841976 on epoch=47
05/31/2022 18:38:21 - INFO - __main__ - Step 200 Global step 200 Train loss 0.533692 on epoch=49
05/31/2022 18:38:22 - INFO - __main__ - Global step 200 Train loss 1.155812 Classification-F1 0.318512381478413 on epoch=49
05/31/2022 18:38:28 - INFO - __main__ - Step 210 Global step 210 Train loss 0.384250 on epoch=52
05/31/2022 18:38:33 - INFO - __main__ - Step 220 Global step 220 Train loss 0.407320 on epoch=54
05/31/2022 18:38:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.443750 on epoch=57
05/31/2022 18:38:43 - INFO - __main__ - Step 240 Global step 240 Train loss 0.428222 on epoch=59
05/31/2022 18:38:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.424638 on epoch=62
05/31/2022 18:38:49 - INFO - __main__ - Global step 250 Train loss 0.417636 Classification-F1 0.5221897422269466 on epoch=62
05/31/2022 18:38:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.411718 on epoch=64
05/31/2022 18:39:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.456441 on epoch=67
05/31/2022 18:39:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.415972 on epoch=69
05/31/2022 18:39:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.411374 on epoch=72
05/31/2022 18:39:15 - INFO - __main__ - Step 300 Global step 300 Train loss 0.368936 on epoch=74
05/31/2022 18:39:16 - INFO - __main__ - Global step 300 Train loss 0.412888 Classification-F1 0.6590730557737627 on epoch=74
05/31/2022 18:39:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.282795 on epoch=77
05/31/2022 18:39:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.350975 on epoch=79
05/31/2022 18:39:32 - INFO - __main__ - Step 330 Global step 330 Train loss 0.413574 on epoch=82
05/31/2022 18:39:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.303234 on epoch=84
05/31/2022 18:39:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.264384 on epoch=87
05/31/2022 18:39:43 - INFO - __main__ - Global step 350 Train loss 0.322992 Classification-F1 0.6402321083172147 on epoch=87
05/31/2022 18:39:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.279494 on epoch=89
05/31/2022 18:39:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.281391 on epoch=92
05/31/2022 18:39:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.240759 on epoch=94
05/31/2022 18:40:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.259902 on epoch=97
05/31/2022 18:40:09 - INFO - __main__ - Step 400 Global step 400 Train loss 0.267478 on epoch=99
05/31/2022 18:40:09 - INFO - __main__ - Global step 400 Train loss 0.265805 Classification-F1 0.7394957983193278 on epoch=99
05/31/2022 18:40:15 - INFO - __main__ - Step 410 Global step 410 Train loss 0.280257 on epoch=102
05/31/2022 18:40:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.218017 on epoch=104
05/31/2022 18:40:26 - INFO - __main__ - Step 430 Global step 430 Train loss 0.175719 on epoch=107
05/31/2022 18:40:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.204953 on epoch=109
05/31/2022 18:40:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.155159 on epoch=112
05/31/2022 18:40:37 - INFO - __main__ - Global step 450 Train loss 0.206821 Classification-F1 0.8538884524744697 on epoch=112
05/31/2022 18:40:42 - INFO - __main__ - Step 460 Global step 460 Train loss 0.152207 on epoch=114
05/31/2022 18:40:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.121681 on epoch=117
05/31/2022 18:40:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.176419 on epoch=119
05/31/2022 18:40:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.178218 on epoch=122
05/31/2022 18:41:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.155620 on epoch=124
05/31/2022 18:41:04 - INFO - __main__ - Global step 500 Train loss 0.156829 Classification-F1 0.7069327731092436 on epoch=124
05/31/2022 18:41:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.149290 on epoch=127
05/31/2022 18:41:14 - INFO - __main__ - Step 520 Global step 520 Train loss 0.116447 on epoch=129
05/31/2022 18:41:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.117811 on epoch=132
05/31/2022 18:41:24 - INFO - __main__ - Step 540 Global step 540 Train loss 0.093580 on epoch=134
05/31/2022 18:41:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.144628 on epoch=137
05/31/2022 18:41:30 - INFO - __main__ - Global step 550 Train loss 0.124351 Classification-F1 0.7898305084745763 on epoch=137
05/31/2022 18:41:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.072530 on epoch=139
05/31/2022 18:41:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.105983 on epoch=142
05/31/2022 18:41:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.053338 on epoch=144
05/31/2022 18:41:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.100684 on epoch=147
05/31/2022 18:41:56 - INFO - __main__ - Step 600 Global step 600 Train loss 0.121656 on epoch=149
05/31/2022 18:41:57 - INFO - __main__ - Global step 600 Train loss 0.090838 Classification-F1 0.8708333333333333 on epoch=149
05/31/2022 18:42:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.075784 on epoch=152
05/31/2022 18:42:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.070924 on epoch=154
05/31/2022 18:42:13 - INFO - __main__ - Step 630 Global step 630 Train loss 0.058928 on epoch=157
05/31/2022 18:42:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.075858 on epoch=159
05/31/2022 18:42:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.048691 on epoch=162
05/31/2022 18:42:24 - INFO - __main__ - Global step 650 Train loss 0.066037 Classification-F1 0.8202898550724638 on epoch=162
05/31/2022 18:42:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.100162 on epoch=164
05/31/2022 18:42:35 - INFO - __main__ - Step 670 Global step 670 Train loss 0.051864 on epoch=167
05/31/2022 18:42:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.116802 on epoch=169
05/31/2022 18:42:45 - INFO - __main__ - Step 690 Global step 690 Train loss 0.041137 on epoch=172
05/31/2022 18:42:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.021317 on epoch=174
05/31/2022 18:42:51 - INFO - __main__ - Global step 700 Train loss 0.066256 Classification-F1 0.8870673952641166 on epoch=174
05/31/2022 18:42:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.062472 on epoch=177
05/31/2022 18:43:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.052052 on epoch=179
05/31/2022 18:43:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.032150 on epoch=182
05/31/2022 18:43:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.025940 on epoch=184
05/31/2022 18:43:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.011530 on epoch=187
05/31/2022 18:43:18 - INFO - __main__ - Global step 750 Train loss 0.036829 Classification-F1 0.8544980443285528 on epoch=187
05/31/2022 18:43:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.035863 on epoch=189
05/31/2022 18:43:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.047898 on epoch=192
05/31/2022 18:43:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.021301 on epoch=194
05/31/2022 18:43:38 - INFO - __main__ - Step 790 Global step 790 Train loss 0.027969 on epoch=197
05/31/2022 18:43:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.014313 on epoch=199
05/31/2022 18:43:44 - INFO - __main__ - Global step 800 Train loss 0.029469 Classification-F1 0.8214192196910186 on epoch=199
05/31/2022 18:43:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.008802 on epoch=202
05/31/2022 18:43:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.006117 on epoch=204
05/31/2022 18:43:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.041086 on epoch=207
05/31/2022 18:44:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.004022 on epoch=209
05/31/2022 18:44:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.036510 on epoch=212
05/31/2022 18:44:10 - INFO - __main__ - Global step 850 Train loss 0.019308 Classification-F1 0.8538884524744697 on epoch=212
05/31/2022 18:44:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.046109 on epoch=214
05/31/2022 18:44:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.041646 on epoch=217
05/31/2022 18:44:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.015635 on epoch=219
05/31/2022 18:44:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.019709 on epoch=222
05/31/2022 18:44:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.004098 on epoch=224
05/31/2022 18:44:37 - INFO - __main__ - Global step 900 Train loss 0.025439 Classification-F1 0.8371848739495799 on epoch=224
05/31/2022 18:44:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.011832 on epoch=227
05/31/2022 18:44:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.002822 on epoch=229
05/31/2022 18:44:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.019444 on epoch=232
05/31/2022 18:44:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.001642 on epoch=234
05/31/2022 18:45:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.020854 on epoch=237
05/31/2022 18:45:03 - INFO - __main__ - Global step 950 Train loss 0.011319 Classification-F1 0.8870673952641166 on epoch=237
05/31/2022 18:45:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000875 on epoch=239
05/31/2022 18:45:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001638 on epoch=242
05/31/2022 18:45:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.004369 on epoch=244
05/31/2022 18:45:24 - INFO - __main__ - Step 990 Global step 990 Train loss 0.008448 on epoch=247
05/31/2022 18:45:29 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.015968 on epoch=249
05/31/2022 18:45:30 - INFO - __main__ - Global step 1000 Train loss 0.006259 Classification-F1 0.8870673952641166 on epoch=249
05/31/2022 18:45:30 - INFO - __main__ - save last model!
05/31/2022 18:45:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:45:30 - INFO - __main__ - Printing 3 examples
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:45:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:45:30 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:45:30 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:45:30 - INFO - __main__ - Printing 3 examples
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:45:30 - INFO - __main__ - ['false']
05/31/2022 18:45:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:45:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:45:30 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:45:36 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 18:45:37 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 18:45:37 - INFO - __main__ - Printing 3 examples
05/31/2022 18:45:37 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 18:45:37 - INFO - __main__ - ['false']
05/31/2022 18:45:37 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 18:45:37 - INFO - __main__ - ['false']
05/31/2022 18:45:37 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 18:45:37 - INFO - __main__ - ['true']
05/31/2022 18:45:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:45:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:45:37 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 18:45:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_100_0.0002_8_predictions.txt
05/31/2022 18:45:39 - INFO - __main__ - Classification-F1 on test data: 0.8562
05/31/2022 18:45:39 - INFO - __main__ - prefix=ethos-religion_32_100, lr=0.0002, bsz=8, dev_performance=0.8870673952641166, test_performance=0.8561507936507936
05/31/2022 18:45:39 - INFO - __main__ - Running ... prefix=ethos-religion_32_100, lr=0.0001, bsz=8 ...
05/31/2022 18:45:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:45:40 - INFO - __main__ - Printing 3 examples
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:45:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:45:40 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:45:40 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:45:40 - INFO - __main__ - Printing 3 examples
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] Send all these whiny black crybabies back to central Apefrica to live for just one month. They would be crying to come back to America where White people pamper and coddle them. Let's try the experiment one time.
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ -  [ethos-religion] The world would be better without white people because they stole from the black Egyptians in the before christ ages they was poor we wasnt whites  ruins everything for black people/White people have pig dicks and no shape no hips or no booty they have to get plastic surgery as us blacks get it from our mother whites brought skin cancer to america so learn some facts before you try to run us out america when we was here before yall racist ass smelly crackers and dont say you will beat my ass because you cant and if you wanna find out drop your adress√∞¬ü¬Ü¬ó√Ø¬∏¬è√∞¬ü¬í¬Ø√∞¬ü¬ô¬Ç
05/31/2022 18:45:40 - INFO - __main__ - ['false']
05/31/2022 18:45:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:45:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:45:40 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:45:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:45:43 - INFO - __main__ - Starting training!
05/31/2022 18:45:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:45:51 - INFO - __main__ - Starting training!
05/31/2022 18:45:55 - INFO - __main__ - Step 10 Global step 10 Train loss 24.388069 on epoch=2
05/31/2022 18:46:00 - INFO - __main__ - Step 20 Global step 20 Train loss 21.558294 on epoch=4
05/31/2022 18:46:05 - INFO - __main__ - Step 30 Global step 30 Train loss 20.069469 on epoch=7
05/31/2022 18:46:10 - INFO - __main__ - Step 40 Global step 40 Train loss 18.943363 on epoch=9
05/31/2022 18:46:15 - INFO - __main__ - Step 50 Global step 50 Train loss 17.807167 on epoch=12
05/31/2022 18:46:35 - INFO - __main__ - Global step 50 Train loss 20.553272 Classification-F1 0.0 on epoch=12
05/31/2022 18:46:41 - INFO - __main__ - Step 60 Global step 60 Train loss 18.216375 on epoch=14
05/31/2022 18:46:46 - INFO - __main__ - Step 70 Global step 70 Train loss 17.481966 on epoch=17
05/31/2022 18:46:51 - INFO - __main__ - Step 80 Global step 80 Train loss 17.619076 on epoch=19
05/31/2022 18:46:57 - INFO - __main__ - Step 90 Global step 90 Train loss 16.883358 on epoch=22
05/31/2022 18:47:02 - INFO - __main__ - Step 100 Global step 100 Train loss 16.898708 on epoch=24
05/31/2022 18:47:19 - INFO - __main__ - Global step 100 Train loss 17.419897 Classification-F1 0.0 on epoch=24
05/31/2022 18:47:24 - INFO - __main__ - Step 110 Global step 110 Train loss 15.518774 on epoch=27
05/31/2022 18:47:30 - INFO - __main__ - Step 120 Global step 120 Train loss 15.362040 on epoch=29
05/31/2022 18:47:35 - INFO - __main__ - Step 130 Global step 130 Train loss 15.755659 on epoch=32
05/31/2022 18:47:40 - INFO - __main__ - Step 140 Global step 140 Train loss 15.050308 on epoch=34
05/31/2022 18:47:45 - INFO - __main__ - Step 150 Global step 150 Train loss 15.067032 on epoch=37
05/31/2022 18:47:58 - INFO - __main__ - Global step 150 Train loss 15.350761 Classification-F1 0.0 on epoch=37
05/31/2022 18:48:03 - INFO - __main__ - Step 160 Global step 160 Train loss 13.846048 on epoch=39
05/31/2022 18:48:08 - INFO - __main__ - Step 170 Global step 170 Train loss 14.199392 on epoch=42
05/31/2022 18:48:13 - INFO - __main__ - Step 180 Global step 180 Train loss 13.401746 on epoch=44
05/31/2022 18:48:18 - INFO - __main__ - Step 190 Global step 190 Train loss 12.747725 on epoch=47
05/31/2022 18:48:23 - INFO - __main__ - Step 200 Global step 200 Train loss 12.466978 on epoch=49
05/31/2022 18:48:32 - INFO - __main__ - Global step 200 Train loss 13.332378 Classification-F1 0.0 on epoch=49
05/31/2022 18:48:37 - INFO - __main__ - Step 210 Global step 210 Train loss 12.349218 on epoch=52
05/31/2022 18:48:42 - INFO - __main__ - Step 220 Global step 220 Train loss 11.189959 on epoch=54
05/31/2022 18:48:47 - INFO - __main__ - Step 230 Global step 230 Train loss 11.194252 on epoch=57
05/31/2022 18:48:53 - INFO - __main__ - Step 240 Global step 240 Train loss 9.959867 on epoch=59
05/31/2022 18:48:58 - INFO - __main__ - Step 250 Global step 250 Train loss 9.251706 on epoch=62
05/31/2022 18:49:03 - INFO - __main__ - Global step 250 Train loss 10.789001 Classification-F1 0.0 on epoch=62
05/31/2022 18:49:08 - INFO - __main__ - Step 260 Global step 260 Train loss 6.716357 on epoch=64
05/31/2022 18:49:13 - INFO - __main__ - Step 270 Global step 270 Train loss 5.489102 on epoch=67
05/31/2022 18:49:18 - INFO - __main__ - Step 280 Global step 280 Train loss 3.885242 on epoch=69
05/31/2022 18:49:23 - INFO - __main__ - Step 290 Global step 290 Train loss 1.741882 on epoch=72
05/31/2022 18:49:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.956649 on epoch=74
05/31/2022 18:49:29 - INFO - __main__ - Global step 300 Train loss 3.757846 Classification-F1 0.5772727272727273 on epoch=74
05/31/2022 18:49:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.491141 on epoch=77
05/31/2022 18:49:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.458080 on epoch=79
05/31/2022 18:49:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.450877 on epoch=82
05/31/2022 18:49:50 - INFO - __main__ - Step 340 Global step 340 Train loss 0.391058 on epoch=84
05/31/2022 18:49:55 - INFO - __main__ - Step 350 Global step 350 Train loss 0.575190 on epoch=87
05/31/2022 18:49:56 - INFO - __main__ - Global step 350 Train loss 0.473269 Classification-F1 0.7654054054054054 on epoch=87
05/31/2022 18:50:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.377097 on epoch=89
05/31/2022 18:50:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.340822 on epoch=92
05/31/2022 18:50:12 - INFO - __main__ - Step 380 Global step 380 Train loss 0.224389 on epoch=94
05/31/2022 18:50:17 - INFO - __main__ - Step 390 Global step 390 Train loss 0.188285 on epoch=97
05/31/2022 18:50:22 - INFO - __main__ - Step 400 Global step 400 Train loss 0.245721 on epoch=99
05/31/2022 18:50:23 - INFO - __main__ - Global step 400 Train loss 0.275263 Classification-F1 0.8870673952641166 on epoch=99
05/31/2022 18:50:29 - INFO - __main__ - Step 410 Global step 410 Train loss 0.189768 on epoch=102
05/31/2022 18:50:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.201197 on epoch=104
05/31/2022 18:50:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.213351 on epoch=107
05/31/2022 18:50:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.173038 on epoch=109
05/31/2022 18:50:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.205482 on epoch=112
05/31/2022 18:50:50 - INFO - __main__ - Global step 450 Train loss 0.196567 Classification-F1 0.8708333333333333 on epoch=112
05/31/2022 18:50:55 - INFO - __main__ - Step 460 Global step 460 Train loss 0.207396 on epoch=114
05/31/2022 18:51:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.131235 on epoch=117
05/31/2022 18:51:05 - INFO - __main__ - Step 480 Global step 480 Train loss 0.146482 on epoch=119
05/31/2022 18:51:10 - INFO - __main__ - Step 490 Global step 490 Train loss 0.126327 on epoch=122
05/31/2022 18:51:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.078089 on epoch=124
05/31/2022 18:51:16 - INFO - __main__ - Global step 500 Train loss 0.137906 Classification-F1 0.886831812255541 on epoch=124
05/31/2022 18:51:21 - INFO - __main__ - Step 510 Global step 510 Train loss 0.128834 on epoch=127
05/31/2022 18:51:27 - INFO - __main__ - Step 520 Global step 520 Train loss 0.094544 on epoch=129
05/31/2022 18:51:32 - INFO - __main__ - Step 530 Global step 530 Train loss 0.111097 on epoch=132
05/31/2022 18:51:37 - INFO - __main__ - Step 540 Global step 540 Train loss 0.099639 on epoch=134
05/31/2022 18:51:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.193154 on epoch=137
05/31/2022 18:51:43 - INFO - __main__ - Global step 550 Train loss 0.125454 Classification-F1 0.8697478991596639 on epoch=137
05/31/2022 18:51:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.114644 on epoch=139
05/31/2022 18:51:53 - INFO - __main__ - Step 570 Global step 570 Train loss 0.128161 on epoch=142
05/31/2022 18:51:58 - INFO - __main__ - Step 580 Global step 580 Train loss 0.109195 on epoch=144
05/31/2022 18:52:03 - INFO - __main__ - Step 590 Global step 590 Train loss 0.032644 on epoch=147
05/31/2022 18:52:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.170435 on epoch=149
05/31/2022 18:52:09 - INFO - __main__ - Global step 600 Train loss 0.111016 Classification-F1 0.9193338537600833 on epoch=149
05/31/2022 18:52:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.078589 on epoch=152
05/31/2022 18:52:20 - INFO - __main__ - Step 620 Global step 620 Train loss 0.068174 on epoch=154
05/31/2022 18:52:25 - INFO - __main__ - Step 630 Global step 630 Train loss 0.080906 on epoch=157
05/31/2022 18:52:30 - INFO - __main__ - Step 640 Global step 640 Train loss 0.063806 on epoch=159
05/31/2022 18:52:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.143117 on epoch=162
05/31/2022 18:52:36 - INFO - __main__ - Global step 650 Train loss 0.086918 Classification-F1 0.8359788359788359 on epoch=162
05/31/2022 18:52:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.243811 on epoch=164
05/31/2022 18:52:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.051835 on epoch=167
05/31/2022 18:52:51 - INFO - __main__ - Step 680 Global step 680 Train loss 0.046549 on epoch=169
05/31/2022 18:52:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.058460 on epoch=172
05/31/2022 18:53:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.036414 on epoch=174
05/31/2022 18:53:02 - INFO - __main__ - Global step 700 Train loss 0.087414 Classification-F1 0.9193338537600833 on epoch=174
05/31/2022 18:53:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.070866 on epoch=177
05/31/2022 18:53:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.090912 on epoch=179
05/31/2022 18:53:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.078692 on epoch=182
05/31/2022 18:53:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.016197 on epoch=184
05/31/2022 18:53:28 - INFO - __main__ - Step 750 Global step 750 Train loss 0.037435 on epoch=187
05/31/2022 18:53:29 - INFO - __main__ - Global step 750 Train loss 0.058821 Classification-F1 0.9193338537600833 on epoch=187
05/31/2022 18:53:34 - INFO - __main__ - Step 760 Global step 760 Train loss 0.113080 on epoch=189
05/31/2022 18:53:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.041490 on epoch=192
05/31/2022 18:53:44 - INFO - __main__ - Step 780 Global step 780 Train loss 0.016296 on epoch=194
05/31/2022 18:53:49 - INFO - __main__ - Step 790 Global step 790 Train loss 0.017156 on epoch=197
05/31/2022 18:53:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.019055 on epoch=199
05/31/2022 18:53:55 - INFO - __main__ - Global step 800 Train loss 0.041415 Classification-F1 0.9354166666666667 on epoch=199
05/31/2022 18:54:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.008805 on epoch=202
05/31/2022 18:54:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.057082 on epoch=204
05/31/2022 18:54:11 - INFO - __main__ - Step 830 Global step 830 Train loss 0.037424 on epoch=207
05/31/2022 18:54:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.014093 on epoch=209
05/31/2022 18:54:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.048595 on epoch=212
05/31/2022 18:54:22 - INFO - __main__ - Global step 850 Train loss 0.033200 Classification-F1 0.9191655801825294 on epoch=212
05/31/2022 18:54:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.013064 on epoch=214
05/31/2022 18:54:32 - INFO - __main__ - Step 870 Global step 870 Train loss 0.108569 on epoch=217
05/31/2022 18:54:37 - INFO - __main__ - Step 880 Global step 880 Train loss 0.022171 on epoch=219
05/31/2022 18:54:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.011366 on epoch=222
05/31/2022 18:54:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.026299 on epoch=224
05/31/2022 18:54:48 - INFO - __main__ - Global step 900 Train loss 0.036294 Classification-F1 0.9028213166144201 on epoch=224
05/31/2022 18:54:53 - INFO - __main__ - Step 910 Global step 910 Train loss 0.018966 on epoch=227
05/31/2022 18:54:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.196944 on epoch=229
05/31/2022 18:55:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.019448 on epoch=232
05/31/2022 18:55:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.021681 on epoch=234
05/31/2022 18:55:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.026802 on epoch=237
05/31/2022 18:55:14 - INFO - __main__ - Global step 950 Train loss 0.056768 Classification-F1 0.8870673952641166 on epoch=237
05/31/2022 18:55:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.004678 on epoch=239
05/31/2022 18:55:25 - INFO - __main__ - Step 970 Global step 970 Train loss 0.026878 on epoch=242
05/31/2022 18:55:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.006860 on epoch=244
05/31/2022 18:55:35 - INFO - __main__ - Step 990 Global step 990 Train loss 0.011927 on epoch=247
05/31/2022 18:55:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.006943 on epoch=249
05/31/2022 18:55:41 - INFO - __main__ - Global step 1000 Train loss 0.011457 Classification-F1 0.9032258064516129 on epoch=249
05/31/2022 18:55:41 - INFO - __main__ - save last model!
05/31/2022 18:55:41 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:55:41 - INFO - __main__ - Printing 3 examples
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:55:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:55:41 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:55:41 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:55:41 - INFO - __main__ - Printing 3 examples
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 18:55:41 - INFO - __main__ - ['false']
05/31/2022 18:55:41 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:55:41 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:55:41 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:55:48 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 18:55:48 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 18:55:48 - INFO - __main__ - Printing 3 examples
05/31/2022 18:55:48 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 18:55:48 - INFO - __main__ - ['false']
05/31/2022 18:55:48 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 18:55:48 - INFO - __main__ - ['false']
05/31/2022 18:55:48 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 18:55:48 - INFO - __main__ - ['true']
05/31/2022 18:55:48 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:55:48 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:55:48 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 18:55:50 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_100_0.0001_8_predictions.txt
05/31/2022 18:55:50 - INFO - __main__ - Classification-F1 on test data: 0.9202
05/31/2022 18:55:50 - INFO - __main__ - prefix=ethos-religion_32_100, lr=0.0001, bsz=8, dev_performance=0.9354166666666667, test_performance=0.9202273977626995
05/31/2022 18:55:50 - INFO - __main__ - Running ... prefix=ethos-religion_32_13, lr=0.0005, bsz=8 ...
05/31/2022 18:55:51 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 18:55:51 - INFO - __main__ - Printing 3 examples
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:55:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:55:51 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 18:55:51 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 18:55:51 - INFO - __main__ - Printing 3 examples
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 18:55:51 - INFO - __main__ - ['false']
05/31/2022 18:55:51 - INFO - __main__ - Tokenizing Input ...
05/31/2022 18:55:51 - INFO - __main__ - Tokenizing Output ...
05/31/2022 18:55:51 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 18:55:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:55:54 - INFO - __main__ - Starting training!
05/31/2022 18:56:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 18:56:04 - INFO - __main__ - Starting training!
05/31/2022 18:56:08 - INFO - __main__ - Step 10 Global step 10 Train loss 24.820768 on epoch=2
05/31/2022 18:56:13 - INFO - __main__ - Step 20 Global step 20 Train loss 19.123379 on epoch=4
05/31/2022 18:56:18 - INFO - __main__ - Step 30 Global step 30 Train loss 16.352097 on epoch=7
05/31/2022 18:56:23 - INFO - __main__ - Step 40 Global step 40 Train loss 14.019287 on epoch=9
05/31/2022 18:56:29 - INFO - __main__ - Step 50 Global step 50 Train loss 12.960318 on epoch=12
05/31/2022 18:56:44 - INFO - __main__ - Global step 50 Train loss 17.455170 Classification-F1 0.0 on epoch=12
05/31/2022 18:56:50 - INFO - __main__ - Step 60 Global step 60 Train loss 7.764486 on epoch=14
05/31/2022 18:56:55 - INFO - __main__ - Step 70 Global step 70 Train loss 3.553496 on epoch=17
05/31/2022 18:57:00 - INFO - __main__ - Step 80 Global step 80 Train loss 1.535220 on epoch=19
05/31/2022 18:57:05 - INFO - __main__ - Step 90 Global step 90 Train loss 0.630539 on epoch=22
05/31/2022 18:57:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.457615 on epoch=24
05/31/2022 18:57:11 - INFO - __main__ - Global step 100 Train loss 2.788271 Classification-F1 0.4095238095238095 on epoch=24
05/31/2022 18:57:17 - INFO - __main__ - Step 110 Global step 110 Train loss 0.324759 on epoch=27
05/31/2022 18:57:22 - INFO - __main__ - Step 120 Global step 120 Train loss 1.420671 on epoch=29
05/31/2022 18:57:27 - INFO - __main__ - Step 130 Global step 130 Train loss 2.293471 on epoch=32
05/31/2022 18:57:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.575617 on epoch=34
05/31/2022 18:57:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.185307 on epoch=37
05/31/2022 18:57:38 - INFO - __main__ - Global step 150 Train loss 0.959965 Classification-F1 0.8359788359788359 on epoch=37
05/31/2022 18:57:44 - INFO - __main__ - Step 160 Global step 160 Train loss 0.265052 on epoch=39
05/31/2022 18:57:49 - INFO - __main__ - Step 170 Global step 170 Train loss 0.091574 on epoch=42
05/31/2022 18:57:54 - INFO - __main__ - Step 180 Global step 180 Train loss 0.082998 on epoch=44
05/31/2022 18:58:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.063147 on epoch=47
05/31/2022 18:58:05 - INFO - __main__ - Step 200 Global step 200 Train loss 0.059560 on epoch=49
05/31/2022 18:58:06 - INFO - __main__ - Global step 200 Train loss 0.112466 Classification-F1 0.8697478991596639 on epoch=49
05/31/2022 18:58:11 - INFO - __main__ - Step 210 Global step 210 Train loss 0.098026 on epoch=52
05/31/2022 18:58:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.125239 on epoch=54
05/31/2022 18:58:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.061603 on epoch=57
05/31/2022 18:58:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.034255 on epoch=59
05/31/2022 18:58:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.059376 on epoch=62
05/31/2022 18:58:33 - INFO - __main__ - Global step 250 Train loss 0.075700 Classification-F1 0.9354166666666667 on epoch=62
05/31/2022 18:58:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.343156 on epoch=64
05/31/2022 18:58:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.140728 on epoch=67
05/31/2022 18:58:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.029567 on epoch=69
05/31/2022 18:58:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.060416 on epoch=72
05/31/2022 18:58:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.049183 on epoch=74
05/31/2022 18:59:00 - INFO - __main__ - Global step 300 Train loss 0.124610 Classification-F1 0.9193338537600833 on epoch=74
05/31/2022 18:59:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.031818 on epoch=77
05/31/2022 18:59:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.059158 on epoch=79
05/31/2022 18:59:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.108562 on epoch=82
05/31/2022 18:59:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.053208 on epoch=84
05/31/2022 18:59:26 - INFO - __main__ - Step 350 Global step 350 Train loss 0.044100 on epoch=87
05/31/2022 18:59:26 - INFO - __main__ - Global step 350 Train loss 0.059369 Classification-F1 0.886831812255541 on epoch=87
05/31/2022 18:59:32 - INFO - __main__ - Step 360 Global step 360 Train loss 0.012800 on epoch=89
05/31/2022 18:59:37 - INFO - __main__ - Step 370 Global step 370 Train loss 0.012911 on epoch=92
05/31/2022 18:59:42 - INFO - __main__ - Step 380 Global step 380 Train loss 0.027834 on epoch=94
05/31/2022 18:59:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.019998 on epoch=97
05/31/2022 18:59:52 - INFO - __main__ - Step 400 Global step 400 Train loss 0.014198 on epoch=99
05/31/2022 18:59:53 - INFO - __main__ - Global step 400 Train loss 0.017548 Classification-F1 0.967741935483871 on epoch=99
05/31/2022 18:59:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.008475 on epoch=102
05/31/2022 19:00:04 - INFO - __main__ - Step 420 Global step 420 Train loss 0.018845 on epoch=104
05/31/2022 19:00:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.034892 on epoch=107
05/31/2022 19:00:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.004724 on epoch=109
05/31/2022 19:00:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.012663 on epoch=112
05/31/2022 19:00:20 - INFO - __main__ - Global step 450 Train loss 0.015920 Classification-F1 0.9514993481095178 on epoch=112
05/31/2022 19:00:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.002543 on epoch=114
05/31/2022 19:00:30 - INFO - __main__ - Step 470 Global step 470 Train loss 0.057806 on epoch=117
05/31/2022 19:00:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.033222 on epoch=119
05/31/2022 19:00:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.019143 on epoch=122
05/31/2022 19:00:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.000128 on epoch=124
05/31/2022 19:00:47 - INFO - __main__ - Global step 500 Train loss 0.022568 Classification-F1 0.967741935483871 on epoch=124
05/31/2022 19:00:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000410 on epoch=127
05/31/2022 19:00:57 - INFO - __main__ - Step 520 Global step 520 Train loss 0.000089 on epoch=129
05/31/2022 19:01:02 - INFO - __main__ - Step 530 Global step 530 Train loss 0.004385 on epoch=132
05/31/2022 19:01:07 - INFO - __main__ - Step 540 Global step 540 Train loss 0.000190 on epoch=134
05/31/2022 19:01:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000228 on epoch=137
05/31/2022 19:01:13 - INFO - __main__ - Global step 550 Train loss 0.001060 Classification-F1 0.967741935483871 on epoch=137
05/31/2022 19:01:18 - INFO - __main__ - Step 560 Global step 560 Train loss 0.000109 on epoch=139
05/31/2022 19:01:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.001643 on epoch=142
05/31/2022 19:01:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.001053 on epoch=144
05/31/2022 19:01:34 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000039 on epoch=147
05/31/2022 19:01:39 - INFO - __main__ - Step 600 Global step 600 Train loss 0.000102 on epoch=149
05/31/2022 19:01:40 - INFO - __main__ - Global step 600 Train loss 0.000589 Classification-F1 0.967741935483871 on epoch=149
05/31/2022 19:01:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.009645 on epoch=152
05/31/2022 19:01:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000288 on epoch=154
05/31/2022 19:01:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.018190 on epoch=157
05/31/2022 19:02:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.002206 on epoch=159
05/31/2022 19:02:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000091 on epoch=162
05/31/2022 19:02:06 - INFO - __main__ - Global step 650 Train loss 0.006084 Classification-F1 0.9514993481095178 on epoch=162
05/31/2022 19:02:11 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000080 on epoch=164
05/31/2022 19:02:16 - INFO - __main__ - Step 670 Global step 670 Train loss 0.000112 on epoch=167
05/31/2022 19:02:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000703 on epoch=169
05/31/2022 19:02:27 - INFO - __main__ - Step 690 Global step 690 Train loss 0.001384 on epoch=172
05/31/2022 19:02:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000123 on epoch=174
05/31/2022 19:02:32 - INFO - __main__ - Global step 700 Train loss 0.000480 Classification-F1 0.9677083333333334 on epoch=174
05/31/2022 19:02:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000038 on epoch=177
05/31/2022 19:02:42 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000241 on epoch=179
05/31/2022 19:02:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000036 on epoch=182
05/31/2022 19:02:53 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000151 on epoch=184
05/31/2022 19:02:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000550 on epoch=187
05/31/2022 19:02:58 - INFO - __main__ - Global step 750 Train loss 0.000203 Classification-F1 0.967741935483871 on epoch=187
05/31/2022 19:03:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000020 on epoch=189
05/31/2022 19:03:08 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000007 on epoch=192
05/31/2022 19:03:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.169765 on epoch=194
05/31/2022 19:03:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000166 on epoch=197
05/31/2022 19:03:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000137 on epoch=199
05/31/2022 19:03:24 - INFO - __main__ - Global step 800 Train loss 0.034019 Classification-F1 0.9516003122560499 on epoch=199
05/31/2022 19:03:29 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000568 on epoch=202
05/31/2022 19:03:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000072 on epoch=204
05/31/2022 19:03:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000237 on epoch=207
05/31/2022 19:03:45 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000100 on epoch=209
05/31/2022 19:03:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000056 on epoch=212
05/31/2022 19:03:50 - INFO - __main__ - Global step 850 Train loss 0.000206 Classification-F1 0.9516003122560499 on epoch=212
05/31/2022 19:03:55 - INFO - __main__ - Step 860 Global step 860 Train loss 0.034514 on epoch=214
05/31/2022 19:04:01 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000223 on epoch=217
05/31/2022 19:04:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000079 on epoch=219
05/31/2022 19:04:11 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000108 on epoch=222
05/31/2022 19:04:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000068 on epoch=224
05/31/2022 19:04:17 - INFO - __main__ - Global step 900 Train loss 0.006998 Classification-F1 0.9516003122560499 on epoch=224
05/31/2022 19:04:22 - INFO - __main__ - Step 910 Global step 910 Train loss 0.031780 on epoch=227
05/31/2022 19:04:27 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000325 on epoch=229
05/31/2022 19:04:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000070 on epoch=232
05/31/2022 19:04:37 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000685 on epoch=234
05/31/2022 19:04:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000047 on epoch=237
05/31/2022 19:04:43 - INFO - __main__ - Global step 950 Train loss 0.006582 Classification-F1 0.967741935483871 on epoch=237
05/31/2022 19:04:48 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000028 on epoch=239
05/31/2022 19:04:53 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000022 on epoch=242
05/31/2022 19:04:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000081 on epoch=244
05/31/2022 19:05:03 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000189 on epoch=247
05/31/2022 19:05:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000153 on epoch=249
05/31/2022 19:05:09 - INFO - __main__ - Global step 1000 Train loss 0.000095 Classification-F1 0.9514993481095178 on epoch=249
05/31/2022 19:05:09 - INFO - __main__ - save last model!
05/31/2022 19:05:09 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:05:09 - INFO - __main__ - Printing 3 examples
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:05:09 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:05:09 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:05:09 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:05:09 - INFO - __main__ - Printing 3 examples
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:05:09 - INFO - __main__ - ['false']
05/31/2022 19:05:09 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:05:09 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:05:09 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:05:16 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:05:16 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:05:16 - INFO - __main__ - Printing 3 examples
05/31/2022 19:05:16 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:05:16 - INFO - __main__ - ['false']
05/31/2022 19:05:16 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:05:16 - INFO - __main__ - ['false']
05/31/2022 19:05:16 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:05:16 - INFO - __main__ - ['true']
05/31/2022 19:05:16 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:05:16 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:05:16 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:05:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_13_0.0005_8_predictions.txt
05/31/2022 19:05:18 - INFO - __main__ - Classification-F1 on test data: 0.9372
05/31/2022 19:05:18 - INFO - __main__ - prefix=ethos-religion_32_13, lr=0.0005, bsz=8, dev_performance=0.967741935483871, test_performance=0.9372294372294372
05/31/2022 19:05:18 - INFO - __main__ - Running ... prefix=ethos-religion_32_13, lr=0.0003, bsz=8 ...
05/31/2022 19:05:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:05:19 - INFO - __main__ - Printing 3 examples
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:05:19 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:05:19 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:05:19 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:05:19 - INFO - __main__ - Printing 3 examples
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:05:19 - INFO - __main__ - ['false']
05/31/2022 19:05:19 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:05:19 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:05:20 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:05:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:05:22 - INFO - __main__ - Starting training!
05/31/2022 19:05:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:05:33 - INFO - __main__ - Starting training!
05/31/2022 19:05:37 - INFO - __main__ - Step 10 Global step 10 Train loss 24.250458 on epoch=2
05/31/2022 19:05:42 - INFO - __main__ - Step 20 Global step 20 Train loss 20.511507 on epoch=4
05/31/2022 19:05:47 - INFO - __main__ - Step 30 Global step 30 Train loss 16.701246 on epoch=7
05/31/2022 19:05:52 - INFO - __main__ - Step 40 Global step 40 Train loss 16.283413 on epoch=9
05/31/2022 19:05:57 - INFO - __main__ - Step 50 Global step 50 Train loss 15.494751 on epoch=12
05/31/2022 19:06:05 - INFO - __main__ - Global step 50 Train loss 18.648273 Classification-F1 0.0 on epoch=12
05/31/2022 19:06:11 - INFO - __main__ - Step 60 Global step 60 Train loss 14.713841 on epoch=14
05/31/2022 19:06:16 - INFO - __main__ - Step 70 Global step 70 Train loss 13.508421 on epoch=17
05/31/2022 19:06:21 - INFO - __main__ - Step 80 Global step 80 Train loss 11.554916 on epoch=19
05/31/2022 19:06:26 - INFO - __main__ - Step 90 Global step 90 Train loss 6.219432 on epoch=22
05/31/2022 19:06:31 - INFO - __main__ - Step 100 Global step 100 Train loss 3.707870 on epoch=24
05/31/2022 19:06:32 - INFO - __main__ - Global step 100 Train loss 9.940895 Classification-F1 0.14666666666666667 on epoch=24
05/31/2022 19:06:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.629543 on epoch=27
05/31/2022 19:06:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.832674 on epoch=29
05/31/2022 19:06:49 - INFO - __main__ - Step 130 Global step 130 Train loss 0.736596 on epoch=32
05/31/2022 19:06:54 - INFO - __main__ - Step 140 Global step 140 Train loss 0.553344 on epoch=34
05/31/2022 19:06:59 - INFO - __main__ - Step 150 Global step 150 Train loss 0.372374 on epoch=37
05/31/2022 19:07:00 - INFO - __main__ - Global step 150 Train loss 0.824906 Classification-F1 0.7469387755102042 on epoch=37
05/31/2022 19:07:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.247987 on epoch=39
05/31/2022 19:07:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.254742 on epoch=42
05/31/2022 19:07:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.233005 on epoch=44
05/31/2022 19:07:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.286684 on epoch=47
05/31/2022 19:07:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.211760 on epoch=49
05/31/2022 19:07:27 - INFO - __main__ - Global step 200 Train loss 0.246836 Classification-F1 0.8202898550724638 on epoch=49
05/31/2022 19:07:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.276824 on epoch=52
05/31/2022 19:07:39 - INFO - __main__ - Step 220 Global step 220 Train loss 0.141240 on epoch=54
05/31/2022 19:07:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.170448 on epoch=57
05/31/2022 19:07:49 - INFO - __main__ - Step 240 Global step 240 Train loss 0.166350 on epoch=59
05/31/2022 19:07:54 - INFO - __main__ - Step 250 Global step 250 Train loss 0.085428 on epoch=62
05/31/2022 19:07:55 - INFO - __main__ - Global step 250 Train loss 0.168058 Classification-F1 0.8704284221525601 on epoch=62
05/31/2022 19:08:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.069823 on epoch=64
05/31/2022 19:08:06 - INFO - __main__ - Step 270 Global step 270 Train loss 0.114298 on epoch=67
05/31/2022 19:08:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.096373 on epoch=69
05/31/2022 19:08:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.090173 on epoch=72
05/31/2022 19:08:21 - INFO - __main__ - Step 300 Global step 300 Train loss 0.043768 on epoch=74
05/31/2022 19:08:22 - INFO - __main__ - Global step 300 Train loss 0.082887 Classification-F1 0.886831812255541 on epoch=74
05/31/2022 19:08:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.063127 on epoch=77
05/31/2022 19:08:33 - INFO - __main__ - Step 320 Global step 320 Train loss 0.126096 on epoch=79
05/31/2022 19:08:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.109570 on epoch=82
05/31/2022 19:08:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.055479 on epoch=84
05/31/2022 19:08:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.066983 on epoch=87
05/31/2022 19:08:49 - INFO - __main__ - Global step 350 Train loss 0.084251 Classification-F1 0.9193338537600833 on epoch=87
05/31/2022 19:08:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.026485 on epoch=89
05/31/2022 19:09:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.020548 on epoch=92
05/31/2022 19:09:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.039369 on epoch=94
05/31/2022 19:09:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.073447 on epoch=97
05/31/2022 19:09:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.021159 on epoch=99
05/31/2022 19:09:16 - INFO - __main__ - Global step 400 Train loss 0.036202 Classification-F1 0.9193338537600833 on epoch=99
05/31/2022 19:09:21 - INFO - __main__ - Step 410 Global step 410 Train loss 0.048060 on epoch=102
05/31/2022 19:09:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.092868 on epoch=104
05/31/2022 19:09:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.035875 on epoch=107
05/31/2022 19:09:36 - INFO - __main__ - Step 440 Global step 440 Train loss 0.014454 on epoch=109
05/31/2022 19:09:41 - INFO - __main__ - Step 450 Global step 450 Train loss 0.015872 on epoch=112
05/31/2022 19:09:42 - INFO - __main__ - Global step 450 Train loss 0.041426 Classification-F1 0.9514993481095178 on epoch=112
05/31/2022 19:09:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.034205 on epoch=114
05/31/2022 19:09:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.029365 on epoch=117
05/31/2022 19:09:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.001892 on epoch=119
05/31/2022 19:10:03 - INFO - __main__ - Step 490 Global step 490 Train loss 0.071878 on epoch=122
05/31/2022 19:10:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.006412 on epoch=124
05/31/2022 19:10:09 - INFO - __main__ - Global step 500 Train loss 0.028750 Classification-F1 0.9032258064516129 on epoch=124
05/31/2022 19:10:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.018844 on epoch=127
05/31/2022 19:10:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.010640 on epoch=129
05/31/2022 19:10:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.016208 on epoch=132
05/31/2022 19:10:29 - INFO - __main__ - Step 540 Global step 540 Train loss 0.002500 on epoch=134
05/31/2022 19:10:35 - INFO - __main__ - Step 550 Global step 550 Train loss 0.002080 on epoch=137
05/31/2022 19:10:35 - INFO - __main__ - Global step 550 Train loss 0.010054 Classification-F1 0.9193338537600833 on epoch=137
05/31/2022 19:10:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.004647 on epoch=139
05/31/2022 19:10:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.008038 on epoch=142
05/31/2022 19:10:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.022212 on epoch=144
05/31/2022 19:10:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.005924 on epoch=147
05/31/2022 19:11:01 - INFO - __main__ - Step 600 Global step 600 Train loss 0.004304 on epoch=149
05/31/2022 19:11:02 - INFO - __main__ - Global step 600 Train loss 0.009025 Classification-F1 0.8870673952641166 on epoch=149
05/31/2022 19:11:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.007125 on epoch=152
05/31/2022 19:11:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.010520 on epoch=154
05/31/2022 19:11:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.000486 on epoch=157
05/31/2022 19:11:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001471 on epoch=159
05/31/2022 19:11:27 - INFO - __main__ - Step 650 Global step 650 Train loss 0.000396 on epoch=162
05/31/2022 19:11:28 - INFO - __main__ - Global step 650 Train loss 0.004000 Classification-F1 0.9514993481095178 on epoch=162
05/31/2022 19:11:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.000988 on epoch=164
05/31/2022 19:11:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.007955 on epoch=167
05/31/2022 19:11:43 - INFO - __main__ - Step 680 Global step 680 Train loss 0.012398 on epoch=169
05/31/2022 19:11:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000716 on epoch=172
05/31/2022 19:11:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000187 on epoch=174
05/31/2022 19:11:55 - INFO - __main__ - Global step 700 Train loss 0.004449 Classification-F1 0.9514993481095178 on epoch=174
05/31/2022 19:12:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000985 on epoch=177
05/31/2022 19:12:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.008739 on epoch=179
05/31/2022 19:12:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000170 on epoch=182
05/31/2022 19:12:16 - INFO - __main__ - Step 740 Global step 740 Train loss 0.002839 on epoch=184
05/31/2022 19:12:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000204 on epoch=187
05/31/2022 19:12:22 - INFO - __main__ - Global step 750 Train loss 0.002587 Classification-F1 0.9514993481095178 on epoch=187
05/31/2022 19:12:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000295 on epoch=189
05/31/2022 19:12:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000096 on epoch=192
05/31/2022 19:12:37 - INFO - __main__ - Step 780 Global step 780 Train loss 0.031190 on epoch=194
05/31/2022 19:12:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000076 on epoch=197
05/31/2022 19:12:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.057688 on epoch=199
05/31/2022 19:12:48 - INFO - __main__ - Global step 800 Train loss 0.017869 Classification-F1 0.9354166666666667 on epoch=199
05/31/2022 19:12:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000116 on epoch=202
05/31/2022 19:12:58 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000714 on epoch=204
05/31/2022 19:13:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000511 on epoch=207
05/31/2022 19:13:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000284 on epoch=209
05/31/2022 19:13:14 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000072 on epoch=212
05/31/2022 19:13:14 - INFO - __main__ - Global step 850 Train loss 0.000339 Classification-F1 0.9516003122560499 on epoch=212
05/31/2022 19:13:20 - INFO - __main__ - Step 860 Global step 860 Train loss 0.001229 on epoch=214
05/31/2022 19:13:25 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000265 on epoch=217
05/31/2022 19:13:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.001146 on epoch=219
05/31/2022 19:13:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000137 on epoch=222
05/31/2022 19:13:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000084 on epoch=224
05/31/2022 19:13:41 - INFO - __main__ - Global step 900 Train loss 0.000572 Classification-F1 0.9516003122560499 on epoch=224
05/31/2022 19:13:46 - INFO - __main__ - Step 910 Global step 910 Train loss 0.012231 on epoch=227
05/31/2022 19:13:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.023109 on epoch=229
05/31/2022 19:13:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000282 on epoch=232
05/31/2022 19:14:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.004236 on epoch=234
05/31/2022 19:14:07 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000525 on epoch=237
05/31/2022 19:14:08 - INFO - __main__ - Global step 950 Train loss 0.008077 Classification-F1 0.9516003122560499 on epoch=237
05/31/2022 19:14:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.004306 on epoch=239
05/31/2022 19:14:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000436 on epoch=242
05/31/2022 19:14:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000048 on epoch=244
05/31/2022 19:14:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000024 on epoch=247
05/31/2022 19:14:33 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000226 on epoch=249
05/31/2022 19:14:34 - INFO - __main__ - Global step 1000 Train loss 0.001008 Classification-F1 0.9677083333333334 on epoch=249
05/31/2022 19:14:35 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:14:35 - INFO - __main__ - Printing 3 examples
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:14:35 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:14:35 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:14:35 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:14:35 - INFO - __main__ - Printing 3 examples
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:14:35 - INFO - __main__ - ['false']
05/31/2022 19:14:35 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:14:35 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:14:35 - INFO - __main__ - save last model!
05/31/2022 19:14:35 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:14:42 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:14:42 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:14:42 - INFO - __main__ - Printing 3 examples
05/31/2022 19:14:42 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:14:42 - INFO - __main__ - ['false']
05/31/2022 19:14:42 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:14:42 - INFO - __main__ - ['false']
05/31/2022 19:14:42 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:14:42 - INFO - __main__ - ['true']
05/31/2022 19:14:42 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:14:43 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:14:43 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:14:44 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_13_0.0003_8_predictions.txt
05/31/2022 19:14:44 - INFO - __main__ - Classification-F1 on test data: 0.9504
05/31/2022 19:14:44 - INFO - __main__ - prefix=ethos-religion_32_13, lr=0.0003, bsz=8, dev_performance=0.9677083333333334, test_performance=0.9504273504273504
05/31/2022 19:14:44 - INFO - __main__ - Running ... prefix=ethos-religion_32_13, lr=0.0002, bsz=8 ...
05/31/2022 19:14:45 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:14:45 - INFO - __main__ - Printing 3 examples
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:14:45 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:14:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:14:45 - INFO - __main__ - Starting training!
05/31/2022 19:14:45 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:14:45 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:14:45 - INFO - __main__ - Printing 3 examples
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:14:45 - INFO - __main__ - ['false']
05/31/2022 19:14:45 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:14:46 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:14:46 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:14:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:14:58 - INFO - __main__ - Starting training!
05/31/2022 19:15:02 - INFO - __main__ - Step 10 Global step 10 Train loss 24.492727 on epoch=2
05/31/2022 19:15:07 - INFO - __main__ - Step 20 Global step 20 Train loss 20.081722 on epoch=4
05/31/2022 19:15:12 - INFO - __main__ - Step 30 Global step 30 Train loss 18.350170 on epoch=7
05/31/2022 19:15:17 - INFO - __main__ - Step 40 Global step 40 Train loss 17.503956 on epoch=9
05/31/2022 19:15:22 - INFO - __main__ - Step 50 Global step 50 Train loss 16.799328 on epoch=12
05/31/2022 19:15:39 - INFO - __main__ - Global step 50 Train loss 19.445581 Classification-F1 0.0 on epoch=12
05/31/2022 19:15:44 - INFO - __main__ - Step 60 Global step 60 Train loss 15.994490 on epoch=14
05/31/2022 19:15:49 - INFO - __main__ - Step 70 Global step 70 Train loss 14.855005 on epoch=17
05/31/2022 19:15:54 - INFO - __main__ - Step 80 Global step 80 Train loss 14.981695 on epoch=19
05/31/2022 19:15:59 - INFO - __main__ - Step 90 Global step 90 Train loss 13.722038 on epoch=22
05/31/2022 19:16:04 - INFO - __main__ - Step 100 Global step 100 Train loss 13.007187 on epoch=24
05/31/2022 19:16:16 - INFO - __main__ - Global step 100 Train loss 14.512081 Classification-F1 0.0 on epoch=24
05/31/2022 19:16:21 - INFO - __main__ - Step 110 Global step 110 Train loss 11.286310 on epoch=27
05/31/2022 19:16:25 - INFO - __main__ - Step 120 Global step 120 Train loss 6.723221 on epoch=29
05/31/2022 19:16:30 - INFO - __main__ - Step 130 Global step 130 Train loss 1.118569 on epoch=32
05/31/2022 19:16:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.475080 on epoch=34
05/31/2022 19:16:40 - INFO - __main__ - Step 150 Global step 150 Train loss 0.515319 on epoch=37
05/31/2022 19:16:41 - INFO - __main__ - Global step 150 Train loss 4.023700 Classification-F1 0.6313513513513515 on epoch=37
05/31/2022 19:16:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.368209 on epoch=39
05/31/2022 19:16:51 - INFO - __main__ - Step 170 Global step 170 Train loss 0.365349 on epoch=42
05/31/2022 19:16:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.347501 on epoch=44
05/31/2022 19:17:01 - INFO - __main__ - Step 190 Global step 190 Train loss 0.280467 on epoch=47
05/31/2022 19:17:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.282733 on epoch=49
05/31/2022 19:17:07 - INFO - __main__ - Global step 200 Train loss 0.328852 Classification-F1 0.7889499869075673 on epoch=49
05/31/2022 19:17:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.249051 on epoch=52
05/31/2022 19:17:17 - INFO - __main__ - Step 220 Global step 220 Train loss 0.139187 on epoch=54
05/31/2022 19:17:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.194175 on epoch=57
05/31/2022 19:17:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.174885 on epoch=59
05/31/2022 19:17:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.254464 on epoch=62
05/31/2022 19:17:33 - INFO - __main__ - Global step 250 Train loss 0.202353 Classification-F1 0.9032258064516129 on epoch=62
05/31/2022 19:17:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.151194 on epoch=64
05/31/2022 19:17:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.147852 on epoch=67
05/31/2022 19:17:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.131277 on epoch=69
05/31/2022 19:17:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.085146 on epoch=72
05/31/2022 19:17:58 - INFO - __main__ - Step 300 Global step 300 Train loss 0.111883 on epoch=74
05/31/2022 19:17:59 - INFO - __main__ - Global step 300 Train loss 0.125470 Classification-F1 0.9028213166144201 on epoch=74
05/31/2022 19:18:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.135281 on epoch=77
05/31/2022 19:18:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.050465 on epoch=79
05/31/2022 19:18:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.105828 on epoch=82
05/31/2022 19:18:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.079645 on epoch=84
05/31/2022 19:18:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.056665 on epoch=87
05/31/2022 19:18:25 - INFO - __main__ - Global step 350 Train loss 0.085577 Classification-F1 0.9516003122560499 on epoch=87
05/31/2022 19:18:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.064183 on epoch=89
05/31/2022 19:18:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.071389 on epoch=92
05/31/2022 19:18:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.086361 on epoch=94
05/31/2022 19:18:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.102811 on epoch=97
05/31/2022 19:18:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.064081 on epoch=99
05/31/2022 19:18:50 - INFO - __main__ - Global step 400 Train loss 0.077765 Classification-F1 0.9516003122560499 on epoch=99
05/31/2022 19:18:55 - INFO - __main__ - Step 410 Global step 410 Train loss 0.092380 on epoch=102
05/31/2022 19:19:00 - INFO - __main__ - Step 420 Global step 420 Train loss 0.059406 on epoch=104
05/31/2022 19:19:05 - INFO - __main__ - Step 430 Global step 430 Train loss 0.065129 on epoch=107
05/31/2022 19:19:10 - INFO - __main__ - Step 440 Global step 440 Train loss 0.018402 on epoch=109
05/31/2022 19:19:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.096493 on epoch=112
05/31/2022 19:19:16 - INFO - __main__ - Global step 450 Train loss 0.066362 Classification-F1 0.9516003122560499 on epoch=112
05/31/2022 19:19:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.018178 on epoch=114
05/31/2022 19:19:26 - INFO - __main__ - Step 470 Global step 470 Train loss 0.045556 on epoch=117
05/31/2022 19:19:31 - INFO - __main__ - Step 480 Global step 480 Train loss 0.010810 on epoch=119
05/31/2022 19:19:36 - INFO - __main__ - Step 490 Global step 490 Train loss 0.007960 on epoch=122
05/31/2022 19:19:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.006280 on epoch=124
05/31/2022 19:19:41 - INFO - __main__ - Global step 500 Train loss 0.017757 Classification-F1 0.9354838709677419 on epoch=124
05/31/2022 19:19:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.027679 on epoch=127
05/31/2022 19:19:52 - INFO - __main__ - Step 520 Global step 520 Train loss 0.012673 on epoch=129
05/31/2022 19:19:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.008252 on epoch=132
05/31/2022 19:20:02 - INFO - __main__ - Step 540 Global step 540 Train loss 0.022566 on epoch=134
05/31/2022 19:20:07 - INFO - __main__ - Step 550 Global step 550 Train loss 0.009429 on epoch=137
05/31/2022 19:20:08 - INFO - __main__ - Global step 550 Train loss 0.016120 Classification-F1 0.967741935483871 on epoch=137
05/31/2022 19:20:13 - INFO - __main__ - Step 560 Global step 560 Train loss 0.014926 on epoch=139
05/31/2022 19:20:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.005336 on epoch=142
05/31/2022 19:20:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.011837 on epoch=144
05/31/2022 19:20:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.028140 on epoch=147
05/31/2022 19:20:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.001026 on epoch=149
05/31/2022 19:20:35 - INFO - __main__ - Global step 600 Train loss 0.012253 Classification-F1 0.9516003122560499 on epoch=149
05/31/2022 19:20:40 - INFO - __main__ - Step 610 Global step 610 Train loss 0.000899 on epoch=152
05/31/2022 19:20:45 - INFO - __main__ - Step 620 Global step 620 Train loss 0.013102 on epoch=154
05/31/2022 19:20:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.019353 on epoch=157
05/31/2022 19:20:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001616 on epoch=159
05/31/2022 19:21:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.001104 on epoch=162
05/31/2022 19:21:02 - INFO - __main__ - Global step 650 Train loss 0.007215 Classification-F1 0.9516003122560499 on epoch=162
05/31/2022 19:21:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.001777 on epoch=164
05/31/2022 19:21:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.005584 on epoch=167
05/31/2022 19:21:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.004698 on epoch=169
05/31/2022 19:21:22 - INFO - __main__ - Step 690 Global step 690 Train loss 0.003615 on epoch=172
05/31/2022 19:21:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000620 on epoch=174
05/31/2022 19:21:28 - INFO - __main__ - Global step 700 Train loss 0.003259 Classification-F1 0.9354838709677419 on epoch=174
05/31/2022 19:21:33 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000236 on epoch=177
05/31/2022 19:21:38 - INFO - __main__ - Step 720 Global step 720 Train loss 0.059958 on epoch=179
05/31/2022 19:21:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000518 on epoch=182
05/31/2022 19:21:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.003523 on epoch=184
05/31/2022 19:21:54 - INFO - __main__ - Step 750 Global step 750 Train loss 0.001706 on epoch=187
05/31/2022 19:21:55 - INFO - __main__ - Global step 750 Train loss 0.013188 Classification-F1 0.9516003122560499 on epoch=187
05/31/2022 19:22:00 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000337 on epoch=189
05/31/2022 19:22:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.001572 on epoch=192
05/31/2022 19:22:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.000566 on epoch=194
05/31/2022 19:22:15 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000249 on epoch=197
05/31/2022 19:22:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.021751 on epoch=199
05/31/2022 19:22:21 - INFO - __main__ - Global step 800 Train loss 0.004895 Classification-F1 0.9677083333333334 on epoch=199
05/31/2022 19:22:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.018961 on epoch=202
05/31/2022 19:22:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.002313 on epoch=204
05/31/2022 19:22:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000290 on epoch=207
05/31/2022 19:22:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000856 on epoch=209
05/31/2022 19:22:47 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000273 on epoch=212
05/31/2022 19:22:47 - INFO - __main__ - Global step 850 Train loss 0.004539 Classification-F1 0.9516003122560499 on epoch=212
05/31/2022 19:22:53 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000321 on epoch=214
05/31/2022 19:22:58 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000177 on epoch=217
05/31/2022 19:23:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000986 on epoch=219
05/31/2022 19:23:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.006558 on epoch=222
05/31/2022 19:23:13 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000112 on epoch=224
05/31/2022 19:23:14 - INFO - __main__ - Global step 900 Train loss 0.001631 Classification-F1 0.9516003122560499 on epoch=224
05/31/2022 19:23:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000033 on epoch=227
05/31/2022 19:23:25 - INFO - __main__ - Step 920 Global step 920 Train loss 0.002685 on epoch=229
05/31/2022 19:23:30 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001183 on epoch=232
05/31/2022 19:23:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000041 on epoch=234
05/31/2022 19:23:40 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001123 on epoch=237
05/31/2022 19:23:41 - INFO - __main__ - Global step 950 Train loss 0.001013 Classification-F1 0.9516003122560499 on epoch=237
05/31/2022 19:23:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000185 on epoch=239
05/31/2022 19:23:51 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000079 on epoch=242
05/31/2022 19:23:56 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000039 on epoch=244
05/31/2022 19:24:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.009665 on epoch=247
05/31/2022 19:24:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000510 on epoch=249
05/31/2022 19:24:07 - INFO - __main__ - Global step 1000 Train loss 0.002096 Classification-F1 0.9516003122560499 on epoch=249
05/31/2022 19:24:07 - INFO - __main__ - save last model!
05/31/2022 19:24:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:24:08 - INFO - __main__ - Printing 3 examples
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:24:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:24:08 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:24:08 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:24:08 - INFO - __main__ - Printing 3 examples
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:24:08 - INFO - __main__ - ['false']
05/31/2022 19:24:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:24:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:24:08 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:24:14 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:24:15 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:24:15 - INFO - __main__ - Printing 3 examples
05/31/2022 19:24:15 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:24:15 - INFO - __main__ - ['false']
05/31/2022 19:24:15 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:24:15 - INFO - __main__ - ['false']
05/31/2022 19:24:15 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:24:15 - INFO - __main__ - ['true']
05/31/2022 19:24:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:24:15 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:24:15 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:24:16 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_13_0.0002_8_predictions.txt
05/31/2022 19:24:16 - INFO - __main__ - Classification-F1 on test data: 0.8919
05/31/2022 19:24:17 - INFO - __main__ - prefix=ethos-religion_32_13, lr=0.0002, bsz=8, dev_performance=0.967741935483871, test_performance=0.8918870939108823
05/31/2022 19:24:17 - INFO - __main__ - Running ... prefix=ethos-religion_32_13, lr=0.0001, bsz=8 ...
05/31/2022 19:24:18 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:24:18 - INFO - __main__ - Printing 3 examples
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] Disability centres all around the world. That’s were our money goes. Let’s take em down
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] FUCK GAYS disgusting
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] transgenders need help...they are sick in the head. Civilization has messed up the world. Soon enough, people will claim to have the right to change to animals and it will be seen as human rights or right to choose
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:24:18 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:24:18 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:24:18 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:24:18 - INFO - __main__ - Printing 3 examples
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] Just a little work on the eyebrows and you could be a waitress by day and an annoying freeloader at some dudes house at night.
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] He is the weirdest autistic I’ve seen in my life
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ -  [ethos-religion] The men are turtles...idiots even in uk… get lost
05/31/2022 19:24:18 - INFO - __main__ - ['false']
05/31/2022 19:24:18 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:24:18 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:24:18 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:24:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:24:20 - INFO - __main__ - Starting training!
05/31/2022 19:24:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:24:29 - INFO - __main__ - Starting training!
05/31/2022 19:24:33 - INFO - __main__ - Step 10 Global step 10 Train loss 24.408182 on epoch=2
05/31/2022 19:24:38 - INFO - __main__ - Step 20 Global step 20 Train loss 22.739416 on epoch=4
05/31/2022 19:24:44 - INFO - __main__ - Step 30 Global step 30 Train loss 18.894970 on epoch=7
05/31/2022 19:24:49 - INFO - __main__ - Step 40 Global step 40 Train loss 18.411085 on epoch=9
05/31/2022 19:24:54 - INFO - __main__ - Step 50 Global step 50 Train loss 18.989197 on epoch=12
05/31/2022 19:25:14 - INFO - __main__ - Global step 50 Train loss 20.688572 Classification-F1 0.0 on epoch=12
05/31/2022 19:25:19 - INFO - __main__ - Step 60 Global step 60 Train loss 16.999008 on epoch=14
05/31/2022 19:25:25 - INFO - __main__ - Step 70 Global step 70 Train loss 17.471889 on epoch=17
05/31/2022 19:25:30 - INFO - __main__ - Step 80 Global step 80 Train loss 16.427481 on epoch=19
05/31/2022 19:25:35 - INFO - __main__ - Step 90 Global step 90 Train loss 16.463617 on epoch=22
05/31/2022 19:25:40 - INFO - __main__ - Step 100 Global step 100 Train loss 15.486855 on epoch=24
05/31/2022 19:25:59 - INFO - __main__ - Global step 100 Train loss 16.569771 Classification-F1 0.0 on epoch=24
05/31/2022 19:26:05 - INFO - __main__ - Step 110 Global step 110 Train loss 14.472193 on epoch=27
05/31/2022 19:26:10 - INFO - __main__ - Step 120 Global step 120 Train loss 14.567241 on epoch=29
05/31/2022 19:26:15 - INFO - __main__ - Step 130 Global step 130 Train loss 14.258769 on epoch=32
05/31/2022 19:26:20 - INFO - __main__ - Step 140 Global step 140 Train loss 14.588388 on epoch=34
05/31/2022 19:26:25 - INFO - __main__ - Step 150 Global step 150 Train loss 13.372339 on epoch=37
05/31/2022 19:26:44 - INFO - __main__ - Global step 150 Train loss 14.251784 Classification-F1 0.0 on epoch=37
05/31/2022 19:26:49 - INFO - __main__ - Step 160 Global step 160 Train loss 12.982361 on epoch=39
05/31/2022 19:26:54 - INFO - __main__ - Step 170 Global step 170 Train loss 11.811199 on epoch=42
05/31/2022 19:26:59 - INFO - __main__ - Step 180 Global step 180 Train loss 12.151532 on epoch=44
05/31/2022 19:27:05 - INFO - __main__ - Step 190 Global step 190 Train loss 11.169310 on epoch=47
05/31/2022 19:27:10 - INFO - __main__ - Step 200 Global step 200 Train loss 10.497583 on epoch=49
05/31/2022 19:27:27 - INFO - __main__ - Global step 200 Train loss 11.722396 Classification-F1 0.0 on epoch=49
05/31/2022 19:27:32 - INFO - __main__ - Step 210 Global step 210 Train loss 10.744993 on epoch=52
05/31/2022 19:27:37 - INFO - __main__ - Step 220 Global step 220 Train loss 8.311688 on epoch=54
05/31/2022 19:27:42 - INFO - __main__ - Step 230 Global step 230 Train loss 7.852551 on epoch=57
05/31/2022 19:27:47 - INFO - __main__ - Step 240 Global step 240 Train loss 5.700110 on epoch=59
05/31/2022 19:27:52 - INFO - __main__ - Step 250 Global step 250 Train loss 4.869166 on epoch=62
05/31/2022 19:27:53 - INFO - __main__ - Global step 250 Train loss 7.495703 Classification-F1 0.16483516483516483 on epoch=62
05/31/2022 19:27:59 - INFO - __main__ - Step 260 Global step 260 Train loss 3.448444 on epoch=64
05/31/2022 19:28:04 - INFO - __main__ - Step 270 Global step 270 Train loss 3.252541 on epoch=67
05/31/2022 19:28:09 - INFO - __main__ - Step 280 Global step 280 Train loss 2.689771 on epoch=69
05/31/2022 19:28:14 - INFO - __main__ - Step 290 Global step 290 Train loss 1.771378 on epoch=72
05/31/2022 19:28:19 - INFO - __main__ - Step 300 Global step 300 Train loss 1.321317 on epoch=74
05/31/2022 19:28:20 - INFO - __main__ - Global step 300 Train loss 2.496690 Classification-F1 0.4626003210272873 on epoch=74
05/31/2022 19:28:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.938038 on epoch=77
05/31/2022 19:28:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.759235 on epoch=79
05/31/2022 19:28:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.549640 on epoch=82
05/31/2022 19:28:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.506738 on epoch=84
05/31/2022 19:28:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.707697 on epoch=87
05/31/2022 19:28:47 - INFO - __main__ - Global step 350 Train loss 0.692269 Classification-F1 0.7528567632208344 on epoch=87
05/31/2022 19:28:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.582201 on epoch=89
05/31/2022 19:28:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.322441 on epoch=92
05/31/2022 19:29:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.351968 on epoch=94
05/31/2022 19:29:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.410139 on epoch=97
05/31/2022 19:29:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.418198 on epoch=99
05/31/2022 19:29:14 - INFO - __main__ - Global step 400 Train loss 0.416989 Classification-F1 0.8214192196910186 on epoch=99
05/31/2022 19:29:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.539230 on epoch=102
05/31/2022 19:29:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.313364 on epoch=104
05/31/2022 19:29:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.619720 on epoch=107
05/31/2022 19:29:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.605579 on epoch=109
05/31/2022 19:29:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.343264 on epoch=112
05/31/2022 19:29:40 - INFO - __main__ - Global step 450 Train loss 0.484232 Classification-F1 0.8202898550724638 on epoch=112
05/31/2022 19:29:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.186582 on epoch=114
05/31/2022 19:29:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.281356 on epoch=117
05/31/2022 19:29:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.224341 on epoch=119
05/31/2022 19:30:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.258202 on epoch=122
05/31/2022 19:30:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.125964 on epoch=124
05/31/2022 19:30:06 - INFO - __main__ - Global step 500 Train loss 0.215289 Classification-F1 0.8704284221525601 on epoch=124
05/31/2022 19:30:12 - INFO - __main__ - Step 510 Global step 510 Train loss 0.164936 on epoch=127
05/31/2022 19:30:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.156189 on epoch=129
05/31/2022 19:30:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.137589 on epoch=132
05/31/2022 19:30:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.184743 on epoch=134
05/31/2022 19:30:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.166805 on epoch=137
05/31/2022 19:30:33 - INFO - __main__ - Global step 550 Train loss 0.162053 Classification-F1 0.9354166666666667 on epoch=137
05/31/2022 19:30:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.136273 on epoch=139
05/31/2022 19:30:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.133631 on epoch=142
05/31/2022 19:30:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.139734 on epoch=144
05/31/2022 19:30:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.238373 on epoch=147
05/31/2022 19:30:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.425054 on epoch=149
05/31/2022 19:31:00 - INFO - __main__ - Global step 600 Train loss 0.214613 Classification-F1 0.903125 on epoch=149
05/31/2022 19:31:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.125548 on epoch=152
05/31/2022 19:31:10 - INFO - __main__ - Step 620 Global step 620 Train loss 0.172747 on epoch=154
05/31/2022 19:31:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.131038 on epoch=157
05/31/2022 19:31:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.097594 on epoch=159
05/31/2022 19:31:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.066836 on epoch=162
05/31/2022 19:31:26 - INFO - __main__ - Global step 650 Train loss 0.118753 Classification-F1 0.886831812255541 on epoch=162
05/31/2022 19:31:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.084655 on epoch=164
05/31/2022 19:31:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.190848 on epoch=167
05/31/2022 19:31:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.083905 on epoch=169
05/31/2022 19:31:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.114493 on epoch=172
05/31/2022 19:31:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.159156 on epoch=174
05/31/2022 19:31:52 - INFO - __main__ - Global step 700 Train loss 0.126611 Classification-F1 0.886831812255541 on epoch=174
05/31/2022 19:31:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.048776 on epoch=177
05/31/2022 19:32:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.071013 on epoch=179
05/31/2022 19:32:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.100592 on epoch=182
05/31/2022 19:32:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.121505 on epoch=184
05/31/2022 19:32:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.047189 on epoch=187
05/31/2022 19:32:18 - INFO - __main__ - Global step 750 Train loss 0.077815 Classification-F1 0.9516003122560499 on epoch=187
05/31/2022 19:32:24 - INFO - __main__ - Step 760 Global step 760 Train loss 0.055272 on epoch=189
05/31/2022 19:32:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.065821 on epoch=192
05/31/2022 19:32:34 - INFO - __main__ - Step 780 Global step 780 Train loss 0.180356 on epoch=194
05/31/2022 19:32:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.044022 on epoch=197
05/31/2022 19:32:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.109147 on epoch=199
05/31/2022 19:32:45 - INFO - __main__ - Global step 800 Train loss 0.090924 Classification-F1 0.9193338537600833 on epoch=199
05/31/2022 19:32:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.074622 on epoch=202
05/31/2022 19:32:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.053530 on epoch=204
05/31/2022 19:33:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.048378 on epoch=207
05/31/2022 19:33:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.041331 on epoch=209
05/31/2022 19:33:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.053939 on epoch=212
05/31/2022 19:33:11 - INFO - __main__ - Global step 850 Train loss 0.054360 Classification-F1 0.9193338537600833 on epoch=212
05/31/2022 19:33:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.065137 on epoch=214
05/31/2022 19:33:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.100461 on epoch=217
05/31/2022 19:33:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.037420 on epoch=219
05/31/2022 19:33:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.035655 on epoch=222
05/31/2022 19:33:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.041175 on epoch=224
05/31/2022 19:33:37 - INFO - __main__ - Global step 900 Train loss 0.055969 Classification-F1 0.903125 on epoch=224
05/31/2022 19:33:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.048749 on epoch=227
05/31/2022 19:33:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.017001 on epoch=229
05/31/2022 19:33:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.062041 on epoch=232
05/31/2022 19:33:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.022866 on epoch=234
05/31/2022 19:34:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.058723 on epoch=237
05/31/2022 19:34:03 - INFO - __main__ - Global step 950 Train loss 0.041876 Classification-F1 0.9516003122560499 on epoch=237
05/31/2022 19:34:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.018235 on epoch=239
05/31/2022 19:34:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.037756 on epoch=242
05/31/2022 19:34:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.039681 on epoch=244
05/31/2022 19:34:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.024566 on epoch=247
05/31/2022 19:34:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.007004 on epoch=249
05/31/2022 19:34:29 - INFO - __main__ - Global step 1000 Train loss 0.025448 Classification-F1 0.903125 on epoch=249
05/31/2022 19:34:29 - INFO - __main__ - save last model!
05/31/2022 19:34:30 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:34:30 - INFO - __main__ - Printing 3 examples
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:34:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:34:30 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:34:30 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:34:30 - INFO - __main__ - Printing 3 examples
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:34:30 - INFO - __main__ - ['false']
05/31/2022 19:34:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:34:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:34:30 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:34:36 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:34:37 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:34:37 - INFO - __main__ - Printing 3 examples
05/31/2022 19:34:37 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:34:37 - INFO - __main__ - ['false']
05/31/2022 19:34:37 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:34:37 - INFO - __main__ - ['false']
05/31/2022 19:34:37 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:34:37 - INFO - __main__ - ['true']
05/31/2022 19:34:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:34:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:34:37 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:34:38 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_13_0.0001_8_predictions.txt
05/31/2022 19:34:38 - INFO - __main__ - Classification-F1 on test data: 0.9202
05/31/2022 19:34:39 - INFO - __main__ - prefix=ethos-religion_32_13, lr=0.0001, bsz=8, dev_performance=0.9516003122560499, test_performance=0.9202273977626995
05/31/2022 19:34:39 - INFO - __main__ - Running ... prefix=ethos-religion_32_21, lr=0.0005, bsz=8 ...
05/31/2022 19:34:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:34:40 - INFO - __main__ - Printing 3 examples
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:34:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:34:40 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:34:40 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:34:40 - INFO - __main__ - Printing 3 examples
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:34:40 - INFO - __main__ - ['false']
05/31/2022 19:34:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:34:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:34:40 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:34:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:34:43 - INFO - __main__ - Starting training!
05/31/2022 19:34:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:34:53 - INFO - __main__ - Starting training!
05/31/2022 19:34:57 - INFO - __main__ - Step 10 Global step 10 Train loss 23.925974 on epoch=2
05/31/2022 19:35:02 - INFO - __main__ - Step 20 Global step 20 Train loss 18.620998 on epoch=4
05/31/2022 19:35:07 - INFO - __main__ - Step 30 Global step 30 Train loss 15.933777 on epoch=7
05/31/2022 19:35:13 - INFO - __main__ - Step 40 Global step 40 Train loss 14.295878 on epoch=9
05/31/2022 19:35:18 - INFO - __main__ - Step 50 Global step 50 Train loss 13.236249 on epoch=12
05/31/2022 19:35:19 - INFO - __main__ - Global step 50 Train loss 17.202576 Classification-F1 0.0 on epoch=12
05/31/2022 19:35:24 - INFO - __main__ - Step 60 Global step 60 Train loss 8.525063 on epoch=14
05/31/2022 19:35:29 - INFO - __main__ - Step 70 Global step 70 Train loss 3.931207 on epoch=17
05/31/2022 19:35:34 - INFO - __main__ - Step 80 Global step 80 Train loss 2.635885 on epoch=19
05/31/2022 19:35:39 - INFO - __main__ - Step 90 Global step 90 Train loss 0.743627 on epoch=22
05/31/2022 19:35:44 - INFO - __main__ - Step 100 Global step 100 Train loss 0.718617 on epoch=24
05/31/2022 19:35:45 - INFO - __main__ - Global step 100 Train loss 3.310879 Classification-F1 0.3404255319148936 on epoch=24
05/31/2022 19:35:51 - INFO - __main__ - Step 110 Global step 110 Train loss 0.477407 on epoch=27
05/31/2022 19:35:56 - INFO - __main__ - Step 120 Global step 120 Train loss 0.440442 on epoch=29
05/31/2022 19:36:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.478046 on epoch=32
05/31/2022 19:36:07 - INFO - __main__ - Step 140 Global step 140 Train loss 0.403724 on epoch=34
05/31/2022 19:36:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.312747 on epoch=37
05/31/2022 19:36:13 - INFO - __main__ - Global step 150 Train loss 0.422473 Classification-F1 0.5262187088274045 on epoch=37
05/31/2022 19:36:19 - INFO - __main__ - Step 160 Global step 160 Train loss 0.392696 on epoch=39
05/31/2022 19:36:24 - INFO - __main__ - Step 170 Global step 170 Train loss 0.328089 on epoch=42
05/31/2022 19:36:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.293129 on epoch=44
05/31/2022 19:36:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.228364 on epoch=47
05/31/2022 19:36:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.224150 on epoch=49
05/31/2022 19:36:40 - INFO - __main__ - Global step 200 Train loss 0.293286 Classification-F1 0.6895915678524375 on epoch=49
05/31/2022 19:36:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.243345 on epoch=52
05/31/2022 19:36:51 - INFO - __main__ - Step 220 Global step 220 Train loss 0.172014 on epoch=54
05/31/2022 19:36:56 - INFO - __main__ - Step 230 Global step 230 Train loss 0.317737 on epoch=57
05/31/2022 19:37:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.217782 on epoch=59
05/31/2022 19:37:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.470659 on epoch=62
05/31/2022 19:37:08 - INFO - __main__ - Global step 250 Train loss 0.284308 Classification-F1 0.6025641025641025 on epoch=62
05/31/2022 19:37:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.170451 on epoch=64
05/31/2022 19:37:18 - INFO - __main__ - Step 270 Global step 270 Train loss 0.196048 on epoch=67
05/31/2022 19:37:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.227735 on epoch=69
05/31/2022 19:37:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.126248 on epoch=72
05/31/2022 19:37:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.144391 on epoch=74
05/31/2022 19:37:34 - INFO - __main__ - Global step 300 Train loss 0.172975 Classification-F1 0.6072398190045248 on epoch=74
05/31/2022 19:37:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.180393 on epoch=77
05/31/2022 19:37:44 - INFO - __main__ - Step 320 Global step 320 Train loss 0.191090 on epoch=79
05/31/2022 19:37:49 - INFO - __main__ - Step 330 Global step 330 Train loss 0.112996 on epoch=82
05/31/2022 19:37:55 - INFO - __main__ - Step 340 Global step 340 Train loss 0.173022 on epoch=84
05/31/2022 19:38:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.125355 on epoch=87
05/31/2022 19:38:01 - INFO - __main__ - Global step 350 Train loss 0.156571 Classification-F1 0.7902680197762166 on epoch=87
05/31/2022 19:38:06 - INFO - __main__ - Step 360 Global step 360 Train loss 0.129573 on epoch=89
05/31/2022 19:38:11 - INFO - __main__ - Step 370 Global step 370 Train loss 0.129840 on epoch=92
05/31/2022 19:38:17 - INFO - __main__ - Step 380 Global step 380 Train loss 0.114670 on epoch=94
05/31/2022 19:38:22 - INFO - __main__ - Step 390 Global step 390 Train loss 0.058266 on epoch=97
05/31/2022 19:38:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.050995 on epoch=99
05/31/2022 19:38:28 - INFO - __main__ - Global step 400 Train loss 0.096669 Classification-F1 0.8064516129032259 on epoch=99
05/31/2022 19:38:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.056301 on epoch=102
05/31/2022 19:38:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.079054 on epoch=104
05/31/2022 19:38:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.038713 on epoch=107
05/31/2022 19:38:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.075016 on epoch=109
05/31/2022 19:38:54 - INFO - __main__ - Step 450 Global step 450 Train loss 0.015451 on epoch=112
05/31/2022 19:38:55 - INFO - __main__ - Global step 450 Train loss 0.052907 Classification-F1 0.8385416666666667 on epoch=112
05/31/2022 19:39:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.069969 on epoch=114
05/31/2022 19:39:06 - INFO - __main__ - Step 470 Global step 470 Train loss 0.027078 on epoch=117
05/31/2022 19:39:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.060963 on epoch=119
05/31/2022 19:39:16 - INFO - __main__ - Step 490 Global step 490 Train loss 0.081914 on epoch=122
05/31/2022 19:39:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.035080 on epoch=124
05/31/2022 19:39:22 - INFO - __main__ - Global step 500 Train loss 0.055001 Classification-F1 0.7889499869075673 on epoch=124
05/31/2022 19:39:27 - INFO - __main__ - Step 510 Global step 510 Train loss 0.023612 on epoch=127
05/31/2022 19:39:32 - INFO - __main__ - Step 520 Global step 520 Train loss 0.007277 on epoch=129
05/31/2022 19:39:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.134351 on epoch=132
05/31/2022 19:39:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.048828 on epoch=134
05/31/2022 19:39:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.047376 on epoch=137
05/31/2022 19:39:49 - INFO - __main__ - Global step 550 Train loss 0.052289 Classification-F1 0.8225344782721832 on epoch=137
05/31/2022 19:39:54 - INFO - __main__ - Step 560 Global step 560 Train loss 0.123658 on epoch=139
05/31/2022 19:39:59 - INFO - __main__ - Step 570 Global step 570 Train loss 0.023505 on epoch=142
05/31/2022 19:40:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.027839 on epoch=144
05/31/2022 19:40:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.011152 on epoch=147
05/31/2022 19:40:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.012883 on epoch=149
05/31/2022 19:40:15 - INFO - __main__ - Global step 600 Train loss 0.039807 Classification-F1 0.835978835978836 on epoch=149
05/31/2022 19:40:20 - INFO - __main__ - Step 610 Global step 610 Train loss 0.027712 on epoch=152
05/31/2022 19:40:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.013729 on epoch=154
05/31/2022 19:40:31 - INFO - __main__ - Step 630 Global step 630 Train loss 0.006440 on epoch=157
05/31/2022 19:40:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001666 on epoch=159
05/31/2022 19:40:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.024630 on epoch=162
05/31/2022 19:40:42 - INFO - __main__ - Global step 650 Train loss 0.014835 Classification-F1 0.8225344782721831 on epoch=162
05/31/2022 19:40:47 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002057 on epoch=164
05/31/2022 19:40:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.001237 on epoch=167
05/31/2022 19:40:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.018608 on epoch=169
05/31/2022 19:41:02 - INFO - __main__ - Step 690 Global step 690 Train loss 0.012995 on epoch=172
05/31/2022 19:41:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.002760 on epoch=174
05/31/2022 19:41:08 - INFO - __main__ - Global step 700 Train loss 0.007531 Classification-F1 0.8544980443285528 on epoch=174
05/31/2022 19:41:14 - INFO - __main__ - Step 710 Global step 710 Train loss 0.002041 on epoch=177
05/31/2022 19:41:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.001922 on epoch=179
05/31/2022 19:41:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000182 on epoch=182
05/31/2022 19:41:29 - INFO - __main__ - Step 740 Global step 740 Train loss 0.002642 on epoch=184
05/31/2022 19:41:35 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000681 on epoch=187
05/31/2022 19:41:35 - INFO - __main__ - Global step 750 Train loss 0.001494 Classification-F1 0.8548009367681498 on epoch=187
05/31/2022 19:41:41 - INFO - __main__ - Step 760 Global step 760 Train loss 0.001232 on epoch=189
05/31/2022 19:41:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000480 on epoch=192
05/31/2022 19:41:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.006482 on epoch=194
05/31/2022 19:41:57 - INFO - __main__ - Step 790 Global step 790 Train loss 0.016910 on epoch=197
05/31/2022 19:42:02 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000816 on epoch=199
05/31/2022 19:42:03 - INFO - __main__ - Global step 800 Train loss 0.005184 Classification-F1 0.87042842215256 on epoch=199
05/31/2022 19:42:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000925 on epoch=202
05/31/2022 19:42:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.052634 on epoch=204
05/31/2022 19:42:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.007707 on epoch=207
05/31/2022 19:42:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.001721 on epoch=209
05/31/2022 19:42:29 - INFO - __main__ - Step 850 Global step 850 Train loss 0.002268 on epoch=212
05/31/2022 19:42:30 - INFO - __main__ - Global step 850 Train loss 0.013051 Classification-F1 0.8225344782721832 on epoch=212
05/31/2022 19:42:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.004847 on epoch=214
05/31/2022 19:42:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.005802 on epoch=217
05/31/2022 19:42:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.002405 on epoch=219
05/31/2022 19:42:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000209 on epoch=222
05/31/2022 19:42:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.001342 on epoch=224
05/31/2022 19:42:56 - INFO - __main__ - Global step 900 Train loss 0.002921 Classification-F1 0.8221642764015644 on epoch=224
05/31/2022 19:43:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.002416 on epoch=227
05/31/2022 19:43:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000237 on epoch=229
05/31/2022 19:43:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001521 on epoch=232
05/31/2022 19:43:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000727 on epoch=234
05/31/2022 19:43:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000107 on epoch=237
05/31/2022 19:43:23 - INFO - __main__ - Global step 950 Train loss 0.001001 Classification-F1 0.8548009367681499 on epoch=237
05/31/2022 19:43:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000356 on epoch=239
05/31/2022 19:43:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.004645 on epoch=242
05/31/2022 19:43:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.029241 on epoch=244
05/31/2022 19:43:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000137 on epoch=247
05/31/2022 19:43:48 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000253 on epoch=249
05/31/2022 19:43:49 - INFO - __main__ - Global step 1000 Train loss 0.006926 Classification-F1 0.7168949771689498 on epoch=249
05/31/2022 19:43:49 - INFO - __main__ - save last model!
05/31/2022 19:43:49 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:43:49 - INFO - __main__ - Printing 3 examples
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:43:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:43:49 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:43:49 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:43:49 - INFO - __main__ - Printing 3 examples
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:43:49 - INFO - __main__ - ['false']
05/31/2022 19:43:49 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:43:49 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:43:49 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:43:56 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:43:57 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:43:57 - INFO - __main__ - Printing 3 examples
05/31/2022 19:43:57 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:43:57 - INFO - __main__ - ['false']
05/31/2022 19:43:57 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:43:57 - INFO - __main__ - ['false']
05/31/2022 19:43:57 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:43:57 - INFO - __main__ - ['true']
05/31/2022 19:43:57 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:43:57 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:43:57 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:43:58 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_21_0.0005_8_predictions.txt
05/31/2022 19:43:58 - INFO - __main__ - Classification-F1 on test data: 0.7698
05/31/2022 19:43:59 - INFO - __main__ - prefix=ethos-religion_32_21, lr=0.0005, bsz=8, dev_performance=0.87042842215256, test_performance=0.7698412698412698
05/31/2022 19:43:59 - INFO - __main__ - Running ... prefix=ethos-religion_32_21, lr=0.0003, bsz=8 ...
05/31/2022 19:44:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:44:00 - INFO - __main__ - Printing 3 examples
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:44:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:44:00 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:44:00 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:44:00 - INFO - __main__ - Printing 3 examples
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:44:00 - INFO - __main__ - ['false']
05/31/2022 19:44:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:44:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:44:00 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:44:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:44:02 - INFO - __main__ - Starting training!
05/31/2022 19:44:11 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:44:12 - INFO - __main__ - Starting training!
05/31/2022 19:44:16 - INFO - __main__ - Step 10 Global step 10 Train loss 25.143663 on epoch=2
05/31/2022 19:44:21 - INFO - __main__ - Step 20 Global step 20 Train loss 18.953184 on epoch=4
05/31/2022 19:44:26 - INFO - __main__ - Step 30 Global step 30 Train loss 18.002964 on epoch=7
05/31/2022 19:44:31 - INFO - __main__ - Step 40 Global step 40 Train loss 17.503595 on epoch=9
05/31/2022 19:44:36 - INFO - __main__ - Step 50 Global step 50 Train loss 15.207088 on epoch=12
05/31/2022 19:44:54 - INFO - __main__ - Global step 50 Train loss 18.962097 Classification-F1 0.0 on epoch=12
05/31/2022 19:45:00 - INFO - __main__ - Step 60 Global step 60 Train loss 13.256185 on epoch=14
05/31/2022 19:45:05 - INFO - __main__ - Step 70 Global step 70 Train loss 13.410477 on epoch=17
05/31/2022 19:45:10 - INFO - __main__ - Step 80 Global step 80 Train loss 9.795425 on epoch=19
05/31/2022 19:45:15 - INFO - __main__ - Step 90 Global step 90 Train loss 4.337603 on epoch=22
05/31/2022 19:45:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.253235 on epoch=24
05/31/2022 19:45:22 - INFO - __main__ - Global step 100 Train loss 8.410584 Classification-F1 0.2097378277153558 on epoch=24
05/31/2022 19:45:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.534111 on epoch=27
05/31/2022 19:45:33 - INFO - __main__ - Step 120 Global step 120 Train loss 0.460406 on epoch=29
05/31/2022 19:45:38 - INFO - __main__ - Step 130 Global step 130 Train loss 0.512111 on epoch=32
05/31/2022 19:45:44 - INFO - __main__ - Step 140 Global step 140 Train loss 0.525380 on epoch=34
05/31/2022 19:45:49 - INFO - __main__ - Step 150 Global step 150 Train loss 0.451730 on epoch=37
05/31/2022 19:45:50 - INFO - __main__ - Global step 150 Train loss 0.496747 Classification-F1 0.529196124639958 on epoch=37
05/31/2022 19:45:55 - INFO - __main__ - Step 160 Global step 160 Train loss 0.470722 on epoch=39
05/31/2022 19:46:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.361768 on epoch=42
05/31/2022 19:46:06 - INFO - __main__ - Step 180 Global step 180 Train loss 0.390667 on epoch=44
05/31/2022 19:46:11 - INFO - __main__ - Step 190 Global step 190 Train loss 0.394762 on epoch=47
05/31/2022 19:46:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.438920 on epoch=49
05/31/2022 19:46:17 - INFO - __main__ - Global step 200 Train loss 0.411368 Classification-F1 0.4326797385620915 on epoch=49
05/31/2022 19:46:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.411415 on epoch=52
05/31/2022 19:46:27 - INFO - __main__ - Step 220 Global step 220 Train loss 0.420273 on epoch=54
05/31/2022 19:46:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.427056 on epoch=57
05/31/2022 19:46:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.380629 on epoch=59
05/31/2022 19:46:43 - INFO - __main__ - Step 250 Global step 250 Train loss 1.554169 on epoch=62
05/31/2022 19:46:44 - INFO - __main__ - Global step 250 Train loss 0.638708 Classification-F1 0.34848484848484845 on epoch=62
05/31/2022 19:46:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.576863 on epoch=64
05/31/2022 19:46:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.421829 on epoch=67
05/31/2022 19:47:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.405543 on epoch=69
05/31/2022 19:47:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.331226 on epoch=72
05/31/2022 19:47:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.414294 on epoch=74
05/31/2022 19:47:11 - INFO - __main__ - Global step 300 Train loss 0.429951 Classification-F1 0.6391534391534391 on epoch=74
05/31/2022 19:47:17 - INFO - __main__ - Step 310 Global step 310 Train loss 0.312610 on epoch=77
05/31/2022 19:47:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.313896 on epoch=79
05/31/2022 19:47:28 - INFO - __main__ - Step 330 Global step 330 Train loss 0.360051 on epoch=82
05/31/2022 19:47:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.358306 on epoch=84
05/31/2022 19:47:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.337263 on epoch=87
05/31/2022 19:47:39 - INFO - __main__ - Global step 350 Train loss 0.336425 Classification-F1 0.6934686442883163 on epoch=87
05/31/2022 19:47:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.339246 on epoch=89
05/31/2022 19:47:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.263638 on epoch=92
05/31/2022 19:47:55 - INFO - __main__ - Step 380 Global step 380 Train loss 0.288085 on epoch=94
05/31/2022 19:48:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.308796 on epoch=97
05/31/2022 19:48:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.289554 on epoch=99
05/31/2022 19:48:06 - INFO - __main__ - Global step 400 Train loss 0.297864 Classification-F1 0.5772727272727273 on epoch=99
05/31/2022 19:48:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.282515 on epoch=102
05/31/2022 19:48:17 - INFO - __main__ - Step 420 Global step 420 Train loss 0.319115 on epoch=104
05/31/2022 19:48:22 - INFO - __main__ - Step 430 Global step 430 Train loss 0.229093 on epoch=107
05/31/2022 19:48:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.255672 on epoch=109
05/31/2022 19:48:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.280975 on epoch=112
05/31/2022 19:48:33 - INFO - __main__ - Global step 450 Train loss 0.273474 Classification-F1 0.757496740547588 on epoch=112
05/31/2022 19:48:39 - INFO - __main__ - Step 460 Global step 460 Train loss 0.243461 on epoch=114
05/31/2022 19:48:44 - INFO - __main__ - Step 470 Global step 470 Train loss 0.248960 on epoch=117
05/31/2022 19:48:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.282701 on epoch=119
05/31/2022 19:48:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.219834 on epoch=122
05/31/2022 19:49:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.206128 on epoch=124
05/31/2022 19:49:01 - INFO - __main__ - Global step 500 Train loss 0.240217 Classification-F1 0.7168949771689498 on epoch=124
05/31/2022 19:49:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.199567 on epoch=127
05/31/2022 19:49:11 - INFO - __main__ - Step 520 Global step 520 Train loss 0.203657 on epoch=129
05/31/2022 19:49:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.232018 on epoch=132
05/31/2022 19:49:21 - INFO - __main__ - Step 540 Global step 540 Train loss 0.170493 on epoch=134
05/31/2022 19:49:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.123843 on epoch=137
05/31/2022 19:49:28 - INFO - __main__ - Global step 550 Train loss 0.185916 Classification-F1 0.8344017094017095 on epoch=137
05/31/2022 19:49:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.169843 on epoch=139
05/31/2022 19:49:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.172847 on epoch=142
05/31/2022 19:49:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.182680 on epoch=144
05/31/2022 19:49:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.222568 on epoch=147
05/31/2022 19:49:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.126977 on epoch=149
05/31/2022 19:49:55 - INFO - __main__ - Global step 600 Train loss 0.174983 Classification-F1 0.8221642764015644 on epoch=149
05/31/2022 19:50:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.113040 on epoch=152
05/31/2022 19:50:05 - INFO - __main__ - Step 620 Global step 620 Train loss 0.170042 on epoch=154
05/31/2022 19:50:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.081903 on epoch=157
05/31/2022 19:50:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.088893 on epoch=159
05/31/2022 19:50:21 - INFO - __main__ - Step 650 Global step 650 Train loss 0.109336 on epoch=162
05/31/2022 19:50:22 - INFO - __main__ - Global step 650 Train loss 0.112643 Classification-F1 0.8529644268774703 on epoch=162
05/31/2022 19:50:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.104176 on epoch=164
05/31/2022 19:50:33 - INFO - __main__ - Step 670 Global step 670 Train loss 0.089347 on epoch=167
05/31/2022 19:50:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.032546 on epoch=169
05/31/2022 19:50:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.103732 on epoch=172
05/31/2022 19:50:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.044971 on epoch=174
05/31/2022 19:50:49 - INFO - __main__ - Global step 700 Train loss 0.074954 Classification-F1 0.719904331650279 on epoch=174
05/31/2022 19:50:55 - INFO - __main__ - Step 710 Global step 710 Train loss 0.077841 on epoch=177
05/31/2022 19:51:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.135801 on epoch=179
05/31/2022 19:51:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.101453 on epoch=182
05/31/2022 19:51:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.051095 on epoch=184
05/31/2022 19:51:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.077142 on epoch=187
05/31/2022 19:51:16 - INFO - __main__ - Global step 750 Train loss 0.088667 Classification-F1 0.7876152832674572 on epoch=187
05/31/2022 19:51:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.042443 on epoch=189
05/31/2022 19:51:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.040613 on epoch=192
05/31/2022 19:51:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.040837 on epoch=194
05/31/2022 19:51:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.031747 on epoch=197
05/31/2022 19:51:42 - INFO - __main__ - Step 800 Global step 800 Train loss 0.041185 on epoch=199
05/31/2022 19:51:43 - INFO - __main__ - Global step 800 Train loss 0.039365 Classification-F1 0.8062499999999999 on epoch=199
05/31/2022 19:51:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.022444 on epoch=202
05/31/2022 19:51:53 - INFO - __main__ - Step 820 Global step 820 Train loss 0.028549 on epoch=204
05/31/2022 19:51:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.091881 on epoch=207
05/31/2022 19:52:03 - INFO - __main__ - Step 840 Global step 840 Train loss 0.040764 on epoch=209
05/31/2022 19:52:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.032473 on epoch=212
05/31/2022 19:52:09 - INFO - __main__ - Global step 850 Train loss 0.043222 Classification-F1 0.8385416666666667 on epoch=212
05/31/2022 19:52:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.076731 on epoch=214
05/31/2022 19:52:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.006759 on epoch=217
05/31/2022 19:52:25 - INFO - __main__ - Step 880 Global step 880 Train loss 0.013465 on epoch=219
05/31/2022 19:52:30 - INFO - __main__ - Step 890 Global step 890 Train loss 0.007554 on epoch=222
05/31/2022 19:52:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.035571 on epoch=224
05/31/2022 19:52:36 - INFO - __main__ - Global step 900 Train loss 0.028016 Classification-F1 0.8863576852579209 on epoch=224
05/31/2022 19:52:41 - INFO - __main__ - Step 910 Global step 910 Train loss 0.025662 on epoch=227
05/31/2022 19:52:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.043384 on epoch=229
05/31/2022 19:52:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.006160 on epoch=232
05/31/2022 19:52:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.013061 on epoch=234
05/31/2022 19:53:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.011957 on epoch=237
05/31/2022 19:53:03 - INFO - __main__ - Global step 950 Train loss 0.020045 Classification-F1 0.8548009367681499 on epoch=237
05/31/2022 19:53:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.048611 on epoch=239
05/31/2022 19:53:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.020514 on epoch=242
05/31/2022 19:53:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.018219 on epoch=244
05/31/2022 19:53:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.021878 on epoch=247
05/31/2022 19:53:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.011588 on epoch=249
05/31/2022 19:53:29 - INFO - __main__ - Global step 1000 Train loss 0.024162 Classification-F1 0.8870673952641166 on epoch=249
05/31/2022 19:53:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:53:29 - INFO - __main__ - Printing 3 examples
05/31/2022 19:53:29 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:53:29 - INFO - __main__ - ['false']
05/31/2022 19:53:29 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:53:29 - INFO - __main__ - ['false']
05/31/2022 19:53:29 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:53:29 - INFO - __main__ - ['false']
05/31/2022 19:53:29 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:53:29 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:53:30 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:53:30 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:53:30 - INFO - __main__ - Printing 3 examples
05/31/2022 19:53:30 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:53:30 - INFO - __main__ - ['false']
05/31/2022 19:53:30 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:53:30 - INFO - __main__ - ['false']
05/31/2022 19:53:30 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:53:30 - INFO - __main__ - ['false']
05/31/2022 19:53:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:53:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:53:30 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:53:30 - INFO - __main__ - save last model!
05/31/2022 19:53:37 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 19:53:37 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 19:53:37 - INFO - __main__ - Printing 3 examples
05/31/2022 19:53:37 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 19:53:37 - INFO - __main__ - ['false']
05/31/2022 19:53:37 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 19:53:37 - INFO - __main__ - ['false']
05/31/2022 19:53:37 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 19:53:37 - INFO - __main__ - ['true']
05/31/2022 19:53:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:53:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:53:38 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 19:53:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_21_0.0003_8_predictions.txt
05/31/2022 19:53:39 - INFO - __main__ - Classification-F1 on test data: 0.8919
05/31/2022 19:53:39 - INFO - __main__ - prefix=ethos-religion_32_21, lr=0.0003, bsz=8, dev_performance=0.8870673952641166, test_performance=0.8918870939108823
05/31/2022 19:53:39 - INFO - __main__ - Running ... prefix=ethos-religion_32_21, lr=0.0002, bsz=8 ...
05/31/2022 19:53:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 19:53:40 - INFO - __main__ - Printing 3 examples
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:53:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:53:40 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 19:53:40 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 19:53:40 - INFO - __main__ - Printing 3 examples
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 19:53:40 - INFO - __main__ - ['false']
05/31/2022 19:53:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 19:53:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 19:53:41 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 19:53:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:53:42 - INFO - __main__ - Starting training!
05/31/2022 19:53:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 19:53:51 - INFO - __main__ - Starting training!
05/31/2022 19:53:56 - INFO - __main__ - Step 10 Global step 10 Train loss 23.600121 on epoch=2
05/31/2022 19:54:01 - INFO - __main__ - Step 20 Global step 20 Train loss 18.964195 on epoch=4
05/31/2022 19:54:06 - INFO - __main__ - Step 30 Global step 30 Train loss 17.681004 on epoch=7
05/31/2022 19:54:11 - INFO - __main__ - Step 40 Global step 40 Train loss 16.252069 on epoch=9
05/31/2022 19:54:16 - INFO - __main__ - Step 50 Global step 50 Train loss 15.808261 on epoch=12
05/31/2022 19:54:37 - INFO - __main__ - Global step 50 Train loss 18.461128 Classification-F1 0.0 on epoch=12
05/31/2022 19:54:42 - INFO - __main__ - Step 60 Global step 60 Train loss 14.947032 on epoch=14
05/31/2022 19:54:47 - INFO - __main__ - Step 70 Global step 70 Train loss 14.627759 on epoch=17
05/31/2022 19:54:53 - INFO - __main__ - Step 80 Global step 80 Train loss 13.798373 on epoch=19
05/31/2022 19:54:58 - INFO - __main__ - Step 90 Global step 90 Train loss 13.285467 on epoch=22
05/31/2022 19:55:03 - INFO - __main__ - Step 100 Global step 100 Train loss 13.029346 on epoch=24
05/31/2022 19:55:19 - INFO - __main__ - Global step 100 Train loss 13.937596 Classification-F1 0.0 on epoch=24
05/31/2022 19:55:24 - INFO - __main__ - Step 110 Global step 110 Train loss 10.880615 on epoch=27
05/31/2022 19:55:29 - INFO - __main__ - Step 120 Global step 120 Train loss 6.727499 on epoch=29
05/31/2022 19:55:34 - INFO - __main__ - Step 130 Global step 130 Train loss 2.938289 on epoch=32
05/31/2022 19:55:39 - INFO - __main__ - Step 140 Global step 140 Train loss 0.667289 on epoch=34
05/31/2022 19:55:45 - INFO - __main__ - Step 150 Global step 150 Train loss 0.537421 on epoch=37
05/31/2022 19:55:45 - INFO - __main__ - Global step 150 Train loss 4.350222 Classification-F1 0.6260964912280702 on epoch=37
05/31/2022 19:55:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.467605 on epoch=39
05/31/2022 19:55:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.222206 on epoch=42
05/31/2022 19:56:02 - INFO - __main__ - Step 180 Global step 180 Train loss 0.210751 on epoch=44
05/31/2022 19:56:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.199866 on epoch=47
05/31/2022 19:56:13 - INFO - __main__ - Step 200 Global step 200 Train loss 0.094348 on epoch=49
05/31/2022 19:56:13 - INFO - __main__ - Global step 200 Train loss 0.238955 Classification-F1 0.9191655801825294 on epoch=49
05/31/2022 19:56:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.091179 on epoch=52
05/31/2022 19:56:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.106991 on epoch=54
05/31/2022 19:56:30 - INFO - __main__ - Step 230 Global step 230 Train loss 0.122221 on epoch=57
05/31/2022 19:56:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.222688 on epoch=59
05/31/2022 19:56:40 - INFO - __main__ - Step 250 Global step 250 Train loss 0.079040 on epoch=62
05/31/2022 19:56:41 - INFO - __main__ - Global step 250 Train loss 0.124424 Classification-F1 0.9028213166144201 on epoch=62
05/31/2022 19:56:46 - INFO - __main__ - Step 260 Global step 260 Train loss 0.072066 on epoch=64
05/31/2022 19:56:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.041339 on epoch=67
05/31/2022 19:56:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.048646 on epoch=69
05/31/2022 19:57:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.066311 on epoch=72
05/31/2022 19:57:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.073793 on epoch=74
05/31/2022 19:57:08 - INFO - __main__ - Global step 300 Train loss 0.060431 Classification-F1 0.87042842215256 on epoch=74
05/31/2022 19:57:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.113451 on epoch=77
05/31/2022 19:57:18 - INFO - __main__ - Step 320 Global step 320 Train loss 0.228198 on epoch=79
05/31/2022 19:57:23 - INFO - __main__ - Step 330 Global step 330 Train loss 0.427274 on epoch=82
05/31/2022 19:57:28 - INFO - __main__ - Step 340 Global step 340 Train loss 0.173535 on epoch=84
05/31/2022 19:57:33 - INFO - __main__ - Step 350 Global step 350 Train loss 0.409114 on epoch=87
05/31/2022 19:57:34 - INFO - __main__ - Global step 350 Train loss 0.270314 Classification-F1 0.43084455324357407 on epoch=87
05/31/2022 19:57:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.498478 on epoch=89
05/31/2022 19:57:44 - INFO - __main__ - Step 370 Global step 370 Train loss 0.509034 on epoch=92
05/31/2022 19:57:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.396826 on epoch=94
05/31/2022 19:57:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.395361 on epoch=97
05/31/2022 19:58:00 - INFO - __main__ - Step 400 Global step 400 Train loss 0.373889 on epoch=99
05/31/2022 19:58:01 - INFO - __main__ - Global step 400 Train loss 0.434718 Classification-F1 0.4689140646587455 on epoch=99
05/31/2022 19:58:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.382573 on epoch=102
05/31/2022 19:58:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.370091 on epoch=104
05/31/2022 19:58:16 - INFO - __main__ - Step 430 Global step 430 Train loss 0.409695 on epoch=107
05/31/2022 19:58:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.362972 on epoch=109
05/31/2022 19:58:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.403216 on epoch=112
05/31/2022 19:58:27 - INFO - __main__ - Global step 450 Train loss 0.385709 Classification-F1 0.6447916666666667 on epoch=112
05/31/2022 19:58:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.357000 on epoch=114
05/31/2022 19:58:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.382270 on epoch=117
05/31/2022 19:58:42 - INFO - __main__ - Step 480 Global step 480 Train loss 0.337037 on epoch=119
05/31/2022 19:58:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.370235 on epoch=122
05/31/2022 19:58:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.348047 on epoch=124
05/31/2022 19:58:54 - INFO - __main__ - Global step 500 Train loss 0.358918 Classification-F1 0.5581140350877193 on epoch=124
05/31/2022 19:58:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.341767 on epoch=127
05/31/2022 19:59:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.397607 on epoch=129
05/31/2022 19:59:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.301277 on epoch=132
05/31/2022 19:59:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.293891 on epoch=134
05/31/2022 19:59:19 - INFO - __main__ - Step 550 Global step 550 Train loss 0.272533 on epoch=137
05/31/2022 19:59:20 - INFO - __main__ - Global step 550 Train loss 0.321415 Classification-F1 0.544519541580958 on epoch=137
05/31/2022 19:59:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.302850 on epoch=139
05/31/2022 19:59:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.265643 on epoch=142
05/31/2022 19:59:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.362027 on epoch=144
05/31/2022 19:59:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.314160 on epoch=147
05/31/2022 19:59:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.275373 on epoch=149
05/31/2022 19:59:47 - INFO - __main__ - Global step 600 Train loss 0.304010 Classification-F1 0.6829545454545455 on epoch=149
05/31/2022 19:59:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.324046 on epoch=152
05/31/2022 19:59:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.242339 on epoch=154
05/31/2022 20:00:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.188583 on epoch=157
05/31/2022 20:00:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.301599 on epoch=159
05/31/2022 20:00:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.195294 on epoch=162
05/31/2022 20:00:13 - INFO - __main__ - Global step 650 Train loss 0.250372 Classification-F1 0.7574967405475879 on epoch=162
05/31/2022 20:00:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.266964 on epoch=164
05/31/2022 20:00:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.208861 on epoch=167
05/31/2022 20:00:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.225460 on epoch=169
05/31/2022 20:00:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.141251 on epoch=172
05/31/2022 20:00:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.203996 on epoch=174
05/31/2022 20:00:40 - INFO - __main__ - Global step 700 Train loss 0.209306 Classification-F1 0.885638998682477 on epoch=174
05/31/2022 20:00:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.131946 on epoch=177
05/31/2022 20:00:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.196468 on epoch=179
05/31/2022 20:00:55 - INFO - __main__ - Step 730 Global step 730 Train loss 0.160827 on epoch=182
05/31/2022 20:01:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.265338 on epoch=184
05/31/2022 20:01:05 - INFO - __main__ - Step 750 Global step 750 Train loss 0.132926 on epoch=187
05/31/2022 20:01:06 - INFO - __main__ - Global step 750 Train loss 0.177501 Classification-F1 0.870967741935484 on epoch=187
05/31/2022 20:01:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.153415 on epoch=189
05/31/2022 20:01:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.147449 on epoch=192
05/31/2022 20:01:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.174381 on epoch=194
05/31/2022 20:01:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.175831 on epoch=197
05/31/2022 20:01:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.188114 on epoch=199
05/31/2022 20:01:33 - INFO - __main__ - Global step 800 Train loss 0.167838 Classification-F1 0.7430229345122962 on epoch=199
05/31/2022 20:01:38 - INFO - __main__ - Step 810 Global step 810 Train loss 0.282825 on epoch=202
05/31/2022 20:01:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.131839 on epoch=204
05/31/2022 20:01:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.154114 on epoch=207
05/31/2022 20:01:54 - INFO - __main__ - Step 840 Global step 840 Train loss 0.108532 on epoch=209
05/31/2022 20:01:59 - INFO - __main__ - Step 850 Global step 850 Train loss 0.095848 on epoch=212
05/31/2022 20:02:00 - INFO - __main__ - Global step 850 Train loss 0.154631 Classification-F1 0.9188269180413722 on epoch=212
05/31/2022 20:02:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.180225 on epoch=214
05/31/2022 20:02:10 - INFO - __main__ - Step 870 Global step 870 Train loss 0.073091 on epoch=217
05/31/2022 20:02:15 - INFO - __main__ - Step 880 Global step 880 Train loss 0.133768 on epoch=219
05/31/2022 20:02:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.130788 on epoch=222
05/31/2022 20:02:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.164195 on epoch=224
05/31/2022 20:02:26 - INFO - __main__ - Global step 900 Train loss 0.136414 Classification-F1 0.8168143969916734 on epoch=224
05/31/2022 20:02:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.062171 on epoch=227
05/31/2022 20:02:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.150180 on epoch=229
05/31/2022 20:02:42 - INFO - __main__ - Step 930 Global step 930 Train loss 0.097299 on epoch=232
05/31/2022 20:02:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.167492 on epoch=234
05/31/2022 20:02:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.047249 on epoch=237
05/31/2022 20:02:53 - INFO - __main__ - Global step 950 Train loss 0.104878 Classification-F1 0.8517140579325007 on epoch=237
05/31/2022 20:02:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.092422 on epoch=239
05/31/2022 20:03:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.138969 on epoch=242
05/31/2022 20:03:09 - INFO - __main__ - Step 980 Global step 980 Train loss 0.078044 on epoch=244
05/31/2022 20:03:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.088749 on epoch=247
05/31/2022 20:03:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.103355 on epoch=249
05/31/2022 20:03:20 - INFO - __main__ - Global step 1000 Train loss 0.100308 Classification-F1 0.9188269180413722 on epoch=249
05/31/2022 20:03:20 - INFO - __main__ - save last model!
05/31/2022 20:03:20 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:03:20 - INFO - __main__ - Printing 3 examples
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:03:20 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:03:20 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:03:20 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:03:20 - INFO - __main__ - Printing 3 examples
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 20:03:20 - INFO - __main__ - ['false']
05/31/2022 20:03:20 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:03:20 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:03:20 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:03:28 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:03:28 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:03:28 - INFO - __main__ - Printing 3 examples
05/31/2022 20:03:28 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:03:28 - INFO - __main__ - ['false']
05/31/2022 20:03:28 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:03:28 - INFO - __main__ - ['false']
05/31/2022 20:03:28 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:03:28 - INFO - __main__ - ['true']
05/31/2022 20:03:28 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:03:29 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:03:29 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:03:30 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_21_0.0002_8_predictions.txt
05/31/2022 20:03:30 - INFO - __main__ - Classification-F1 on test data: 0.8783
05/31/2022 20:03:30 - INFO - __main__ - prefix=ethos-religion_32_21, lr=0.0002, bsz=8, dev_performance=0.9191655801825294, test_performance=0.8783216783216783
05/31/2022 20:03:30 - INFO - __main__ - Running ... prefix=ethos-religion_32_21, lr=0.0001, bsz=8 ...
05/31/2022 20:03:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:03:31 - INFO - __main__ - Starting training!
05/31/2022 20:03:31 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:03:31 - INFO - __main__ - Printing 3 examples
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] You are so lucky you have a girlfriend. I bet your asian penis is smaller than my thumb
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] FUCK THAT HOMO DUMB ASS PRICK!  SHOULDA LET HIM GET FUCKING EATEN!  ASSHOKE FUCKING WORTHLESS DICK.... NOBODY WOULD HAVE MISSED HIM!
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] Hope you fucking die bitches gay people should not exist all you do is lick one another's ass
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:03:31 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:03:31 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:03:31 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:03:31 - INFO - __main__ - Printing 3 examples
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] why the hell is this Norwegian speaking about our LAWS? SPEAK FOR YOUR OWN Scandinavian scam
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
05/31/2022 20:03:31 - INFO - __main__ - ['false']
05/31/2022 20:03:31 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:03:31 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:03:32 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:03:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:03:44 - INFO - __main__ - Starting training!
05/31/2022 20:03:48 - INFO - __main__ - Step 10 Global step 10 Train loss 23.352270 on epoch=2
05/31/2022 20:03:53 - INFO - __main__ - Step 20 Global step 20 Train loss 22.234524 on epoch=4
05/31/2022 20:03:58 - INFO - __main__ - Step 30 Global step 30 Train loss 19.251764 on epoch=7
05/31/2022 20:04:03 - INFO - __main__ - Step 40 Global step 40 Train loss 18.417179 on epoch=9
05/31/2022 20:04:08 - INFO - __main__ - Step 50 Global step 50 Train loss 18.458567 on epoch=12
05/31/2022 20:04:28 - INFO - __main__ - Global step 50 Train loss 20.342861 Classification-F1 0.0 on epoch=12
05/31/2022 20:04:33 - INFO - __main__ - Step 60 Global step 60 Train loss 18.090801 on epoch=14
05/31/2022 20:04:38 - INFO - __main__ - Step 70 Global step 70 Train loss 17.312241 on epoch=17
05/31/2022 20:04:43 - INFO - __main__ - Step 80 Global step 80 Train loss 16.747168 on epoch=19
05/31/2022 20:04:48 - INFO - __main__ - Step 90 Global step 90 Train loss 16.997995 on epoch=22
05/31/2022 20:04:53 - INFO - __main__ - Step 100 Global step 100 Train loss 15.790468 on epoch=24
05/31/2022 20:05:11 - INFO - __main__ - Global step 100 Train loss 16.987734 Classification-F1 0.0 on epoch=24
05/31/2022 20:05:16 - INFO - __main__ - Step 110 Global step 110 Train loss 16.057714 on epoch=27
05/31/2022 20:05:21 - INFO - __main__ - Step 120 Global step 120 Train loss 16.054928 on epoch=29
05/31/2022 20:05:26 - INFO - __main__ - Step 130 Global step 130 Train loss 14.693464 on epoch=32
05/31/2022 20:05:31 - INFO - __main__ - Step 140 Global step 140 Train loss 14.938757 on epoch=34
05/31/2022 20:05:36 - INFO - __main__ - Step 150 Global step 150 Train loss 14.446802 on epoch=37
05/31/2022 20:05:52 - INFO - __main__ - Global step 150 Train loss 15.238335 Classification-F1 0.0 on epoch=37
05/31/2022 20:05:57 - INFO - __main__ - Step 160 Global step 160 Train loss 14.308184 on epoch=39
05/31/2022 20:06:02 - INFO - __main__ - Step 170 Global step 170 Train loss 14.271884 on epoch=42
05/31/2022 20:06:07 - INFO - __main__ - Step 180 Global step 180 Train loss 13.525208 on epoch=44
05/31/2022 20:06:12 - INFO - __main__ - Step 190 Global step 190 Train loss 12.440611 on epoch=47
05/31/2022 20:06:17 - INFO - __main__ - Step 200 Global step 200 Train loss 13.336084 on epoch=49
05/31/2022 20:06:31 - INFO - __main__ - Global step 200 Train loss 13.576393 Classification-F1 0.0 on epoch=49
05/31/2022 20:06:36 - INFO - __main__ - Step 210 Global step 210 Train loss 11.620577 on epoch=52
05/31/2022 20:06:41 - INFO - __main__ - Step 220 Global step 220 Train loss 11.422373 on epoch=54
05/31/2022 20:06:46 - INFO - __main__ - Step 230 Global step 230 Train loss 11.044380 on epoch=57
05/31/2022 20:06:51 - INFO - __main__ - Step 240 Global step 240 Train loss 9.897858 on epoch=59
05/31/2022 20:06:56 - INFO - __main__ - Step 250 Global step 250 Train loss 9.318480 on epoch=62
05/31/2022 20:07:06 - INFO - __main__ - Global step 250 Train loss 10.660733 Classification-F1 0.0 on epoch=62
05/31/2022 20:07:11 - INFO - __main__ - Step 260 Global step 260 Train loss 8.112254 on epoch=64
05/31/2022 20:07:16 - INFO - __main__ - Step 270 Global step 270 Train loss 6.719487 on epoch=67
05/31/2022 20:07:21 - INFO - __main__ - Step 280 Global step 280 Train loss 5.945062 on epoch=69
05/31/2022 20:07:26 - INFO - __main__ - Step 290 Global step 290 Train loss 4.139863 on epoch=72
05/31/2022 20:07:31 - INFO - __main__ - Step 300 Global step 300 Train loss 4.208085 on epoch=74
05/31/2022 20:07:32 - INFO - __main__ - Global step 300 Train loss 5.824950 Classification-F1 0.3404255319148936 on epoch=74
05/31/2022 20:07:38 - INFO - __main__ - Step 310 Global step 310 Train loss 3.680285 on epoch=77
05/31/2022 20:07:43 - INFO - __main__ - Step 320 Global step 320 Train loss 2.661118 on epoch=79
05/31/2022 20:07:48 - INFO - __main__ - Step 330 Global step 330 Train loss 3.372213 on epoch=82
05/31/2022 20:07:53 - INFO - __main__ - Step 340 Global step 340 Train loss 2.920453 on epoch=84
05/31/2022 20:07:58 - INFO - __main__ - Step 350 Global step 350 Train loss 3.040832 on epoch=87
05/31/2022 20:07:59 - INFO - __main__ - Global step 350 Train loss 3.134980 Classification-F1 0.31507622811970637 on epoch=87
05/31/2022 20:08:04 - INFO - __main__ - Step 360 Global step 360 Train loss 2.447564 on epoch=89
05/31/2022 20:08:09 - INFO - __main__ - Step 370 Global step 370 Train loss 3.247242 on epoch=92
05/31/2022 20:08:14 - INFO - __main__ - Step 380 Global step 380 Train loss 2.721284 on epoch=94
05/31/2022 20:08:19 - INFO - __main__ - Step 390 Global step 390 Train loss 2.607141 on epoch=97
05/31/2022 20:08:24 - INFO - __main__ - Step 400 Global step 400 Train loss 2.513693 on epoch=99
05/31/2022 20:08:25 - INFO - __main__ - Global step 400 Train loss 2.707385 Classification-F1 0.389592123769339 on epoch=99
05/31/2022 20:08:31 - INFO - __main__ - Step 410 Global step 410 Train loss 2.001328 on epoch=102
05/31/2022 20:08:36 - INFO - __main__ - Step 420 Global step 420 Train loss 1.993931 on epoch=104
05/31/2022 20:08:41 - INFO - __main__ - Step 430 Global step 430 Train loss 2.244825 on epoch=107
05/31/2022 20:08:46 - INFO - __main__ - Step 440 Global step 440 Train loss 1.921312 on epoch=109
05/31/2022 20:08:52 - INFO - __main__ - Step 450 Global step 450 Train loss 1.932718 on epoch=112
05/31/2022 20:08:52 - INFO - __main__ - Global step 450 Train loss 2.018823 Classification-F1 0.6973873097904106 on epoch=112
05/31/2022 20:08:58 - INFO - __main__ - Step 460 Global step 460 Train loss 2.077272 on epoch=114
05/31/2022 20:09:03 - INFO - __main__ - Step 470 Global step 470 Train loss 1.990957 on epoch=117
05/31/2022 20:09:09 - INFO - __main__ - Step 480 Global step 480 Train loss 1.141553 on epoch=119
05/31/2022 20:09:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.890995 on epoch=122
05/31/2022 20:09:19 - INFO - __main__ - Step 500 Global step 500 Train loss 0.994914 on epoch=124
05/31/2022 20:09:20 - INFO - __main__ - Global step 500 Train loss 1.419138 Classification-F1 0.6447916666666667 on epoch=124
05/31/2022 20:09:25 - INFO - __main__ - Step 510 Global step 510 Train loss 0.937748 on epoch=127
05/31/2022 20:09:30 - INFO - __main__ - Step 520 Global step 520 Train loss 0.696110 on epoch=129
05/31/2022 20:09:35 - INFO - __main__ - Step 530 Global step 530 Train loss 0.597530 on epoch=132
05/31/2022 20:09:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.386443 on epoch=134
05/31/2022 20:09:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.284404 on epoch=137
05/31/2022 20:09:46 - INFO - __main__ - Global step 550 Train loss 0.580447 Classification-F1 0.6590730557737627 on epoch=137
05/31/2022 20:09:52 - INFO - __main__ - Step 560 Global step 560 Train loss 0.348297 on epoch=139
05/31/2022 20:09:57 - INFO - __main__ - Step 570 Global step 570 Train loss 0.336194 on epoch=142
05/31/2022 20:10:02 - INFO - __main__ - Step 580 Global step 580 Train loss 0.285520 on epoch=144
05/31/2022 20:10:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.239234 on epoch=147
05/31/2022 20:10:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.236833 on epoch=149
05/31/2022 20:10:13 - INFO - __main__ - Global step 600 Train loss 0.289216 Classification-F1 0.7876152832674571 on epoch=149
05/31/2022 20:10:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.244443 on epoch=152
05/31/2022 20:10:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.221667 on epoch=154
05/31/2022 20:10:29 - INFO - __main__ - Step 630 Global step 630 Train loss 0.104749 on epoch=157
05/31/2022 20:10:34 - INFO - __main__ - Step 640 Global step 640 Train loss 0.312378 on epoch=159
05/31/2022 20:10:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.125764 on epoch=162
05/31/2022 20:10:40 - INFO - __main__ - Global step 650 Train loss 0.201800 Classification-F1 0.8202898550724638 on epoch=162
05/31/2022 20:10:46 - INFO - __main__ - Step 660 Global step 660 Train loss 0.148494 on epoch=164
05/31/2022 20:10:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.106803 on epoch=167
05/31/2022 20:10:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.084854 on epoch=169
05/31/2022 20:11:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.099446 on epoch=172
05/31/2022 20:11:07 - INFO - __main__ - Step 700 Global step 700 Train loss 0.231068 on epoch=174
05/31/2022 20:11:07 - INFO - __main__ - Global step 700 Train loss 0.134133 Classification-F1 0.835978835978836 on epoch=174
05/31/2022 20:11:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.202797 on epoch=177
05/31/2022 20:11:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.149931 on epoch=179
05/31/2022 20:11:23 - INFO - __main__ - Step 730 Global step 730 Train loss 0.110429 on epoch=182
05/31/2022 20:11:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.125126 on epoch=184
05/31/2022 20:11:34 - INFO - __main__ - Step 750 Global step 750 Train loss 0.135555 on epoch=187
05/31/2022 20:11:34 - INFO - __main__ - Global step 750 Train loss 0.144768 Classification-F1 0.7732497387669801 on epoch=187
05/31/2022 20:11:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.103578 on epoch=189
05/31/2022 20:11:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.111415 on epoch=192
05/31/2022 20:11:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.074635 on epoch=194
05/31/2022 20:11:55 - INFO - __main__ - Step 790 Global step 790 Train loss 0.079205 on epoch=197
05/31/2022 20:12:00 - INFO - __main__ - Step 800 Global step 800 Train loss 0.087445 on epoch=199
05/31/2022 20:12:01 - INFO - __main__ - Global step 800 Train loss 0.091256 Classification-F1 0.8538884524744697 on epoch=199
05/31/2022 20:12:07 - INFO - __main__ - Step 810 Global step 810 Train loss 0.066142 on epoch=202
05/31/2022 20:12:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.071858 on epoch=204
05/31/2022 20:12:17 - INFO - __main__ - Step 830 Global step 830 Train loss 0.104606 on epoch=207
05/31/2022 20:12:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.083729 on epoch=209
05/31/2022 20:12:28 - INFO - __main__ - Step 850 Global step 850 Train loss 0.082280 on epoch=212
05/31/2022 20:12:29 - INFO - __main__ - Global step 850 Train loss 0.081723 Classification-F1 0.902310924369748 on epoch=212
05/31/2022 20:12:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.092139 on epoch=214
05/31/2022 20:12:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.125698 on epoch=217
05/31/2022 20:12:45 - INFO - __main__ - Step 880 Global step 880 Train loss 0.056265 on epoch=219
05/31/2022 20:12:50 - INFO - __main__ - Step 890 Global step 890 Train loss 0.071015 on epoch=222
05/31/2022 20:12:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.022760 on epoch=224
05/31/2022 20:12:56 - INFO - __main__ - Global step 900 Train loss 0.073575 Classification-F1 0.8697478991596639 on epoch=224
05/31/2022 20:13:01 - INFO - __main__ - Step 910 Global step 910 Train loss 0.050559 on epoch=227
05/31/2022 20:13:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.050013 on epoch=229
05/31/2022 20:13:11 - INFO - __main__ - Step 930 Global step 930 Train loss 0.106382 on epoch=232
05/31/2022 20:13:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.035265 on epoch=234
05/31/2022 20:13:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.049004 on epoch=237
05/31/2022 20:13:23 - INFO - __main__ - Global step 950 Train loss 0.058245 Classification-F1 0.87042842215256 on epoch=237
05/31/2022 20:13:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.057679 on epoch=239
05/31/2022 20:13:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.013632 on epoch=242
05/31/2022 20:13:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.016701 on epoch=244
05/31/2022 20:13:43 - INFO - __main__ - Step 990 Global step 990 Train loss 0.044396 on epoch=247
05/31/2022 20:13:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.036709 on epoch=249
05/31/2022 20:13:50 - INFO - __main__ - Global step 1000 Train loss 0.033823 Classification-F1 0.8708333333333333 on epoch=249
05/31/2022 20:13:50 - INFO - __main__ - save last model!
05/31/2022 20:13:50 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:13:50 - INFO - __main__ - Printing 3 examples
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:13:50 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:13:50 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:13:50 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:13:50 - INFO - __main__ - Printing 3 examples
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:13:50 - INFO - __main__ - ['false']
05/31/2022 20:13:50 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:13:50 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:13:50 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:13:56 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:13:57 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:13:57 - INFO - __main__ - Printing 3 examples
05/31/2022 20:13:57 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:13:57 - INFO - __main__ - ['false']
05/31/2022 20:13:57 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:13:57 - INFO - __main__ - ['false']
05/31/2022 20:13:57 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:13:57 - INFO - __main__ - ['true']
05/31/2022 20:13:57 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:13:57 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:13:57 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:13:59 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_21_0.0001_8_predictions.txt
05/31/2022 20:13:59 - INFO - __main__ - Classification-F1 on test data: 0.8919
05/31/2022 20:13:59 - INFO - __main__ - prefix=ethos-religion_32_21, lr=0.0001, bsz=8, dev_performance=0.902310924369748, test_performance=0.8918870939108823
05/31/2022 20:13:59 - INFO - __main__ - Running ... prefix=ethos-religion_32_42, lr=0.0005, bsz=8 ...
05/31/2022 20:14:00 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:14:00 - INFO - __main__ - Printing 3 examples
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:14:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:14:00 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:14:00 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:14:00 - INFO - __main__ - Printing 3 examples
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:14:00 - INFO - __main__ - ['false']
05/31/2022 20:14:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:14:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:14:00 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:14:00 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:14:01 - INFO - __main__ - Starting training!
05/31/2022 20:14:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:14:13 - INFO - __main__ - Starting training!
05/31/2022 20:14:17 - INFO - __main__ - Step 10 Global step 10 Train loss 24.881695 on epoch=2
05/31/2022 20:14:21 - INFO - __main__ - Step 20 Global step 20 Train loss 19.607975 on epoch=4
05/31/2022 20:14:26 - INFO - __main__ - Step 30 Global step 30 Train loss 17.170727 on epoch=7
05/31/2022 20:14:31 - INFO - __main__ - Step 40 Global step 40 Train loss 16.478149 on epoch=9
05/31/2022 20:14:36 - INFO - __main__ - Step 50 Global step 50 Train loss 14.129847 on epoch=12
05/31/2022 20:14:48 - INFO - __main__ - Global step 50 Train loss 18.453680 Classification-F1 0.0 on epoch=12
05/31/2022 20:14:54 - INFO - __main__ - Step 60 Global step 60 Train loss 12.614582 on epoch=14
05/31/2022 20:14:59 - INFO - __main__ - Step 70 Global step 70 Train loss 9.207828 on epoch=17
05/31/2022 20:15:04 - INFO - __main__ - Step 80 Global step 80 Train loss 5.338834 on epoch=19
05/31/2022 20:15:09 - INFO - __main__ - Step 90 Global step 90 Train loss 2.983335 on epoch=22
05/31/2022 20:15:14 - INFO - __main__ - Step 100 Global step 100 Train loss 2.356201 on epoch=24
05/31/2022 20:15:15 - INFO - __main__ - Global step 100 Train loss 6.500155 Classification-F1 0.4244725738396624 on epoch=24
05/31/2022 20:15:21 - INFO - __main__ - Step 110 Global step 110 Train loss 1.594174 on epoch=27
05/31/2022 20:15:26 - INFO - __main__ - Step 120 Global step 120 Train loss 1.191132 on epoch=29
05/31/2022 20:15:31 - INFO - __main__ - Step 130 Global step 130 Train loss 1.113134 on epoch=32
05/31/2022 20:15:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.930643 on epoch=34
05/31/2022 20:15:41 - INFO - __main__ - Step 150 Global step 150 Train loss 0.563669 on epoch=37
05/31/2022 20:15:42 - INFO - __main__ - Global step 150 Train loss 1.078550 Classification-F1 0.3404255319148936 on epoch=37
05/31/2022 20:15:47 - INFO - __main__ - Step 160 Global step 160 Train loss 0.682514 on epoch=39
05/31/2022 20:15:52 - INFO - __main__ - Step 170 Global step 170 Train loss 0.584669 on epoch=42
05/31/2022 20:15:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.579500 on epoch=44
05/31/2022 20:16:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.433679 on epoch=47
05/31/2022 20:16:07 - INFO - __main__ - Step 200 Global step 200 Train loss 0.508677 on epoch=49
05/31/2022 20:16:08 - INFO - __main__ - Global step 200 Train loss 0.557808 Classification-F1 0.3404255319148936 on epoch=49
05/31/2022 20:16:13 - INFO - __main__ - Step 210 Global step 210 Train loss 0.442577 on epoch=52
05/31/2022 20:16:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.470990 on epoch=54
05/31/2022 20:16:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.492229 on epoch=57
05/31/2022 20:16:28 - INFO - __main__ - Step 240 Global step 240 Train loss 0.386939 on epoch=59
05/31/2022 20:16:33 - INFO - __main__ - Step 250 Global step 250 Train loss 0.415460 on epoch=62
05/31/2022 20:16:34 - INFO - __main__ - Global step 250 Train loss 0.441639 Classification-F1 0.43465045592705165 on epoch=62
05/31/2022 20:16:39 - INFO - __main__ - Step 260 Global step 260 Train loss 0.470409 on epoch=64
05/31/2022 20:16:44 - INFO - __main__ - Step 270 Global step 270 Train loss 0.466203 on epoch=67
05/31/2022 20:16:49 - INFO - __main__ - Step 280 Global step 280 Train loss 0.349211 on epoch=69
05/31/2022 20:16:54 - INFO - __main__ - Step 290 Global step 290 Train loss 0.447836 on epoch=72
05/31/2022 20:16:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.463539 on epoch=74
05/31/2022 20:17:00 - INFO - __main__ - Global step 300 Train loss 0.439440 Classification-F1 0.4244725738396624 on epoch=74
05/31/2022 20:17:05 - INFO - __main__ - Step 310 Global step 310 Train loss 0.378598 on epoch=77
05/31/2022 20:17:10 - INFO - __main__ - Step 320 Global step 320 Train loss 0.437113 on epoch=79
05/31/2022 20:17:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.358188 on epoch=82
05/31/2022 20:17:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.433953 on epoch=84
05/31/2022 20:17:25 - INFO - __main__ - Step 350 Global step 350 Train loss 0.390137 on epoch=87
05/31/2022 20:17:26 - INFO - __main__ - Global step 350 Train loss 0.399598 Classification-F1 0.4244725738396624 on epoch=87
05/31/2022 20:17:30 - INFO - __main__ - Step 360 Global step 360 Train loss 0.356960 on epoch=89
05/31/2022 20:17:35 - INFO - __main__ - Step 370 Global step 370 Train loss 0.364611 on epoch=92
05/31/2022 20:17:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.415782 on epoch=94
05/31/2022 20:17:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.414584 on epoch=97
05/31/2022 20:17:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.371288 on epoch=99
05/31/2022 20:17:51 - INFO - __main__ - Global step 400 Train loss 0.384645 Classification-F1 0.4911616161616162 on epoch=99
05/31/2022 20:17:57 - INFO - __main__ - Step 410 Global step 410 Train loss 0.414015 on epoch=102
05/31/2022 20:18:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.321367 on epoch=104
05/31/2022 20:18:07 - INFO - __main__ - Step 430 Global step 430 Train loss 0.355465 on epoch=107
05/31/2022 20:18:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.341474 on epoch=109
05/31/2022 20:18:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.290679 on epoch=112
05/31/2022 20:18:17 - INFO - __main__ - Global step 450 Train loss 0.344600 Classification-F1 0.4103260869565218 on epoch=112
05/31/2022 20:18:22 - INFO - __main__ - Step 460 Global step 460 Train loss 0.315078 on epoch=114
05/31/2022 20:18:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.282472 on epoch=117
05/31/2022 20:18:32 - INFO - __main__ - Step 480 Global step 480 Train loss 0.261888 on epoch=119
05/31/2022 20:18:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.392726 on epoch=122
05/31/2022 20:18:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.321514 on epoch=124
05/31/2022 20:18:43 - INFO - __main__ - Global step 500 Train loss 0.314736 Classification-F1 0.735042735042735 on epoch=124
05/31/2022 20:18:49 - INFO - __main__ - Step 510 Global step 510 Train loss 0.250610 on epoch=127
05/31/2022 20:18:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.232080 on epoch=129
05/31/2022 20:18:58 - INFO - __main__ - Step 530 Global step 530 Train loss 0.166309 on epoch=132
05/31/2022 20:19:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.254484 on epoch=134
05/31/2022 20:19:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.217690 on epoch=137
05/31/2022 20:19:09 - INFO - __main__ - Global step 550 Train loss 0.224235 Classification-F1 0.8046218487394958 on epoch=137
05/31/2022 20:19:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.262625 on epoch=139
05/31/2022 20:19:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.202798 on epoch=142
05/31/2022 20:19:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.270069 on epoch=144
05/31/2022 20:19:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.301706 on epoch=147
05/31/2022 20:19:35 - INFO - __main__ - Step 600 Global step 600 Train loss 0.262093 on epoch=149
05/31/2022 20:19:36 - INFO - __main__ - Global step 600 Train loss 0.259858 Classification-F1 0.6895915678524376 on epoch=149
05/31/2022 20:19:41 - INFO - __main__ - Step 610 Global step 610 Train loss 0.162864 on epoch=152
05/31/2022 20:19:46 - INFO - __main__ - Step 620 Global step 620 Train loss 0.271741 on epoch=154
05/31/2022 20:19:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.133802 on epoch=157
05/31/2022 20:19:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.116160 on epoch=159
05/31/2022 20:20:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.120343 on epoch=162
05/31/2022 20:20:02 - INFO - __main__ - Global step 650 Train loss 0.160982 Classification-F1 0.8012820512820513 on epoch=162
05/31/2022 20:20:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.071494 on epoch=164
05/31/2022 20:20:13 - INFO - __main__ - Step 670 Global step 670 Train loss 0.116054 on epoch=167
05/31/2022 20:20:18 - INFO - __main__ - Step 680 Global step 680 Train loss 0.144003 on epoch=169
05/31/2022 20:20:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.032248 on epoch=172
05/31/2022 20:20:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.015743 on epoch=174
05/31/2022 20:20:29 - INFO - __main__ - Global step 700 Train loss 0.075908 Classification-F1 0.8221642764015645 on epoch=174
05/31/2022 20:20:35 - INFO - __main__ - Step 710 Global step 710 Train loss 0.091515 on epoch=177
05/31/2022 20:20:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.060467 on epoch=179
05/31/2022 20:20:45 - INFO - __main__ - Step 730 Global step 730 Train loss 0.084114 on epoch=182
05/31/2022 20:20:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.021720 on epoch=184
05/31/2022 20:20:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.046726 on epoch=187
05/31/2022 20:20:56 - INFO - __main__ - Global step 750 Train loss 0.060909 Classification-F1 0.8225344782721832 on epoch=187
05/31/2022 20:21:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.082860 on epoch=189
05/31/2022 20:21:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.062105 on epoch=192
05/31/2022 20:21:12 - INFO - __main__ - Step 780 Global step 780 Train loss 0.057216 on epoch=194
05/31/2022 20:21:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.010238 on epoch=197
05/31/2022 20:21:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.022196 on epoch=199
05/31/2022 20:21:23 - INFO - __main__ - Global step 800 Train loss 0.046923 Classification-F1 0.7835079237174323 on epoch=199
05/31/2022 20:21:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.035848 on epoch=202
05/31/2022 20:21:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.030711 on epoch=204
05/31/2022 20:21:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.013059 on epoch=207
05/31/2022 20:21:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.003055 on epoch=209
05/31/2022 20:21:48 - INFO - __main__ - Step 850 Global step 850 Train loss 0.033304 on epoch=212
05/31/2022 20:21:49 - INFO - __main__ - Global step 850 Train loss 0.023196 Classification-F1 0.8225344782721831 on epoch=212
05/31/2022 20:21:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.011608 on epoch=214
05/31/2022 20:21:59 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001502 on epoch=217
05/31/2022 20:22:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.002188 on epoch=219
05/31/2022 20:22:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.001737 on epoch=222
05/31/2022 20:22:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.002086 on epoch=224
05/31/2022 20:22:16 - INFO - __main__ - Global step 900 Train loss 0.003824 Classification-F1 0.7902680197762166 on epoch=224
05/31/2022 20:22:21 - INFO - __main__ - Step 910 Global step 910 Train loss 0.009285 on epoch=227
05/31/2022 20:22:26 - INFO - __main__ - Step 920 Global step 920 Train loss 0.003741 on epoch=229
05/31/2022 20:22:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001105 on epoch=232
05/31/2022 20:22:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.003659 on epoch=234
05/31/2022 20:22:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001324 on epoch=237
05/31/2022 20:22:42 - INFO - __main__ - Global step 950 Train loss 0.003823 Classification-F1 0.7902680197762166 on epoch=237
05/31/2022 20:22:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.002174 on epoch=239
05/31/2022 20:22:52 - INFO - __main__ - Step 970 Global step 970 Train loss 0.001189 on epoch=242
05/31/2022 20:22:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.001629 on epoch=244
05/31/2022 20:23:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.015882 on epoch=247
05/31/2022 20:23:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000827 on epoch=249
05/31/2022 20:23:08 - INFO - __main__ - Global step 1000 Train loss 0.004340 Classification-F1 0.8387096774193549 on epoch=249
05/31/2022 20:23:08 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:23:08 - INFO - __main__ - Printing 3 examples
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:23:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:23:08 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:23:08 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:23:08 - INFO - __main__ - Printing 3 examples
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:23:08 - INFO - __main__ - ['false']
05/31/2022 20:23:08 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:23:08 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:23:08 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:23:08 - INFO - __main__ - save last model!
05/31/2022 20:23:15 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:23:16 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:23:16 - INFO - __main__ - Printing 3 examples
05/31/2022 20:23:16 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:23:16 - INFO - __main__ - ['false']
05/31/2022 20:23:16 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:23:16 - INFO - __main__ - ['false']
05/31/2022 20:23:16 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:23:16 - INFO - __main__ - ['true']
05/31/2022 20:23:16 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:23:16 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:23:16 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:23:18 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_42_0.0005_8_predictions.txt
05/31/2022 20:23:18 - INFO - __main__ - Classification-F1 on test data: 0.8562
05/31/2022 20:23:18 - INFO - __main__ - prefix=ethos-religion_32_42, lr=0.0005, bsz=8, dev_performance=0.8387096774193549, test_performance=0.8561507936507936
05/31/2022 20:23:18 - INFO - __main__ - Running ... prefix=ethos-religion_32_42, lr=0.0003, bsz=8 ...
05/31/2022 20:23:19 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:23:19 - INFO - __main__ - Printing 3 examples
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:23:19 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:23:19 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:23:19 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:23:19 - INFO - __main__ - Printing 3 examples
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:23:19 - INFO - __main__ - ['false']
05/31/2022 20:23:19 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:23:19 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:23:19 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:23:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:23:19 - INFO - __main__ - Starting training!
05/31/2022 20:23:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:23:30 - INFO - __main__ - Starting training!
05/31/2022 20:23:34 - INFO - __main__ - Step 10 Global step 10 Train loss 24.569860 on epoch=2
05/31/2022 20:23:39 - INFO - __main__ - Step 20 Global step 20 Train loss 20.160028 on epoch=4
05/31/2022 20:23:44 - INFO - __main__ - Step 30 Global step 30 Train loss 17.374575 on epoch=7
05/31/2022 20:23:49 - INFO - __main__ - Step 40 Global step 40 Train loss 16.103640 on epoch=9
05/31/2022 20:23:55 - INFO - __main__ - Step 50 Global step 50 Train loss 15.712611 on epoch=12
05/31/2022 20:24:07 - INFO - __main__ - Global step 50 Train loss 18.784143 Classification-F1 0.0 on epoch=12
05/31/2022 20:24:13 - INFO - __main__ - Step 60 Global step 60 Train loss 14.005608 on epoch=14
05/31/2022 20:24:18 - INFO - __main__ - Step 70 Global step 70 Train loss 12.522624 on epoch=17
05/31/2022 20:24:23 - INFO - __main__ - Step 80 Global step 80 Train loss 9.431519 on epoch=19
05/31/2022 20:24:28 - INFO - __main__ - Step 90 Global step 90 Train loss 3.491716 on epoch=22
05/31/2022 20:24:33 - INFO - __main__ - Step 100 Global step 100 Train loss 1.887969 on epoch=24
05/31/2022 20:24:34 - INFO - __main__ - Global step 100 Train loss 8.267887 Classification-F1 0.452020202020202 on epoch=24
05/31/2022 20:24:40 - INFO - __main__ - Step 110 Global step 110 Train loss 0.635253 on epoch=27
05/31/2022 20:24:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.794400 on epoch=29
05/31/2022 20:24:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.574905 on epoch=32
05/31/2022 20:24:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.446462 on epoch=34
05/31/2022 20:25:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.536557 on epoch=37
05/31/2022 20:25:01 - INFO - __main__ - Global step 150 Train loss 0.597515 Classification-F1 0.44255744255744256 on epoch=37
05/31/2022 20:25:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.317162 on epoch=39
05/31/2022 20:25:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.321094 on epoch=42
05/31/2022 20:25:16 - INFO - __main__ - Step 180 Global step 180 Train loss 0.407964 on epoch=44
05/31/2022 20:25:21 - INFO - __main__ - Step 190 Global step 190 Train loss 0.247363 on epoch=47
05/31/2022 20:25:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.301731 on epoch=49
05/31/2022 20:25:27 - INFO - __main__ - Global step 200 Train loss 0.319063 Classification-F1 0.6829545454545455 on epoch=49
05/31/2022 20:25:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.280795 on epoch=52
05/31/2022 20:25:38 - INFO - __main__ - Step 220 Global step 220 Train loss 0.205697 on epoch=54
05/31/2022 20:25:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.125474 on epoch=57
05/31/2022 20:25:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.205065 on epoch=59
05/31/2022 20:25:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.220552 on epoch=62
05/31/2022 20:25:54 - INFO - __main__ - Global step 250 Train loss 0.207517 Classification-F1 0.9032258064516129 on epoch=62
05/31/2022 20:26:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.103089 on epoch=64
05/31/2022 20:26:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.178198 on epoch=67
05/31/2022 20:26:10 - INFO - __main__ - Step 280 Global step 280 Train loss 0.107276 on epoch=69
05/31/2022 20:26:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.100563 on epoch=72
05/31/2022 20:26:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.054746 on epoch=74
05/31/2022 20:26:21 - INFO - __main__ - Global step 300 Train loss 0.108774 Classification-F1 0.7469387755102042 on epoch=74
05/31/2022 20:26:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.093536 on epoch=77
05/31/2022 20:26:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.067763 on epoch=79
05/31/2022 20:26:36 - INFO - __main__ - Step 330 Global step 330 Train loss 0.030543 on epoch=82
05/31/2022 20:26:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.032443 on epoch=84
05/31/2022 20:26:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.028663 on epoch=87
05/31/2022 20:26:47 - INFO - __main__ - Global step 350 Train loss 0.050590 Classification-F1 0.9191655801825294 on epoch=87
05/31/2022 20:26:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.068791 on epoch=89
05/31/2022 20:26:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.017548 on epoch=92
05/31/2022 20:27:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.061882 on epoch=94
05/31/2022 20:27:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.093660 on epoch=97
05/31/2022 20:27:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.029890 on epoch=99
05/31/2022 20:27:14 - INFO - __main__ - Global step 400 Train loss 0.054354 Classification-F1 0.9191655801825294 on epoch=99
05/31/2022 20:27:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.031955 on epoch=102
05/31/2022 20:27:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.136642 on epoch=104
05/31/2022 20:27:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.008004 on epoch=107
05/31/2022 20:27:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.084176 on epoch=109
05/31/2022 20:27:39 - INFO - __main__ - Step 450 Global step 450 Train loss 0.008132 on epoch=112
05/31/2022 20:27:40 - INFO - __main__ - Global step 450 Train loss 0.053782 Classification-F1 0.9516003122560499 on epoch=112
05/31/2022 20:27:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.010796 on epoch=114
05/31/2022 20:27:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.032409 on epoch=117
05/31/2022 20:27:56 - INFO - __main__ - Step 480 Global step 480 Train loss 0.043818 on epoch=119
05/31/2022 20:28:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.009549 on epoch=122
05/31/2022 20:28:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.005961 on epoch=124
05/31/2022 20:28:07 - INFO - __main__ - Global step 500 Train loss 0.020507 Classification-F1 0.9838667707520166 on epoch=124
05/31/2022 20:28:13 - INFO - __main__ - Step 510 Global step 510 Train loss 0.000320 on epoch=127
05/31/2022 20:28:18 - INFO - __main__ - Step 520 Global step 520 Train loss 0.001630 on epoch=129
05/31/2022 20:28:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.000863 on epoch=132
05/31/2022 20:28:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.003739 on epoch=134
05/31/2022 20:28:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.031795 on epoch=137
05/31/2022 20:28:34 - INFO - __main__ - Global step 550 Train loss 0.007670 Classification-F1 0.9677083333333334 on epoch=137
05/31/2022 20:28:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.007447 on epoch=139
05/31/2022 20:28:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.000632 on epoch=142
05/31/2022 20:28:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.003851 on epoch=144
05/31/2022 20:28:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.003635 on epoch=147
05/31/2022 20:28:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.004278 on epoch=149
05/31/2022 20:29:00 - INFO - __main__ - Global step 600 Train loss 0.003969 Classification-F1 0.9677083333333334 on epoch=149
05/31/2022 20:29:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.011132 on epoch=152
05/31/2022 20:29:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.001577 on epoch=154
05/31/2022 20:29:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.018489 on epoch=157
05/31/2022 20:29:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.001761 on epoch=159
05/31/2022 20:29:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.018551 on epoch=162
05/31/2022 20:29:26 - INFO - __main__ - Global step 650 Train loss 0.010302 Classification-F1 0.9188269180413722 on epoch=162
05/31/2022 20:29:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.004363 on epoch=164
05/31/2022 20:29:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.005191 on epoch=167
05/31/2022 20:29:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.000813 on epoch=169
05/31/2022 20:29:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.000066 on epoch=172
05/31/2022 20:29:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.000503 on epoch=174
05/31/2022 20:29:52 - INFO - __main__ - Global step 700 Train loss 0.002187 Classification-F1 0.9838667707520166 on epoch=174
05/31/2022 20:29:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.001114 on epoch=177
05/31/2022 20:30:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.000526 on epoch=179
05/31/2022 20:30:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000088 on epoch=182
05/31/2022 20:30:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000121 on epoch=184
05/31/2022 20:30:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.023430 on epoch=187
05/31/2022 20:30:19 - INFO - __main__ - Global step 750 Train loss 0.005056 Classification-F1 0.9838667707520166 on epoch=187
05/31/2022 20:30:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.007824 on epoch=189
05/31/2022 20:30:28 - INFO - __main__ - Step 770 Global step 770 Train loss 0.012550 on epoch=192
05/31/2022 20:30:33 - INFO - __main__ - Step 780 Global step 780 Train loss 0.026613 on epoch=194
05/31/2022 20:30:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000225 on epoch=197
05/31/2022 20:30:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.004136 on epoch=199
05/31/2022 20:30:45 - INFO - __main__ - Global step 800 Train loss 0.010270 Classification-F1 0.6395205358716728 on epoch=199
05/31/2022 20:30:50 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000140 on epoch=202
05/31/2022 20:30:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000099 on epoch=204
05/31/2022 20:31:00 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000016 on epoch=207
05/31/2022 20:31:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000044 on epoch=209
05/31/2022 20:31:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000014 on epoch=212
05/31/2022 20:31:11 - INFO - __main__ - Global step 850 Train loss 0.000063 Classification-F1 0.9838667707520166 on epoch=212
05/31/2022 20:31:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000026 on epoch=214
05/31/2022 20:31:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.000349 on epoch=217
05/31/2022 20:31:26 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000028 on epoch=219
05/31/2022 20:31:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000084 on epoch=222
05/31/2022 20:31:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000423 on epoch=224
05/31/2022 20:31:37 - INFO - __main__ - Global step 900 Train loss 0.000182 Classification-F1 0.9838667707520166 on epoch=224
05/31/2022 20:31:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000058 on epoch=227
05/31/2022 20:31:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.000027 on epoch=229
05/31/2022 20:31:52 - INFO - __main__ - Step 930 Global step 930 Train loss 0.000059 on epoch=232
05/31/2022 20:31:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000082 on epoch=234
05/31/2022 20:32:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.001062 on epoch=237
05/31/2022 20:32:03 - INFO - __main__ - Global step 950 Train loss 0.000258 Classification-F1 0.9838667707520166 on epoch=237
05/31/2022 20:32:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.000010 on epoch=239
05/31/2022 20:32:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000047 on epoch=242
05/31/2022 20:32:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000078 on epoch=244
05/31/2022 20:32:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000008 on epoch=247
05/31/2022 20:32:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000018 on epoch=249
05/31/2022 20:32:29 - INFO - __main__ - Global step 1000 Train loss 0.000032 Classification-F1 0.9838667707520166 on epoch=249
05/31/2022 20:32:29 - INFO - __main__ - save last model!
05/31/2022 20:32:29 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:32:29 - INFO - __main__ - Printing 3 examples
05/31/2022 20:32:29 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:32:29 - INFO - __main__ - ['false']
05/31/2022 20:32:29 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:32:29 - INFO - __main__ - ['false']
05/31/2022 20:32:29 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:32:29 - INFO - __main__ - ['false']
05/31/2022 20:32:29 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:32:29 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:32:30 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:32:30 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:32:30 - INFO - __main__ - Printing 3 examples
05/31/2022 20:32:30 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:32:30 - INFO - __main__ - ['false']
05/31/2022 20:32:30 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:32:30 - INFO - __main__ - ['false']
05/31/2022 20:32:30 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:32:30 - INFO - __main__ - ['false']
05/31/2022 20:32:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:32:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:32:30 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:32:36 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:32:37 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:32:37 - INFO - __main__ - Printing 3 examples
05/31/2022 20:32:37 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:32:37 - INFO - __main__ - ['false']
05/31/2022 20:32:37 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:32:37 - INFO - __main__ - ['false']
05/31/2022 20:32:37 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:32:37 - INFO - __main__ - ['true']
05/31/2022 20:32:37 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:32:37 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:32:37 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:32:39 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_42_0.0003_8_predictions.txt
05/31/2022 20:32:39 - INFO - __main__ - Classification-F1 on test data: 0.9228
05/31/2022 20:32:39 - INFO - __main__ - prefix=ethos-religion_32_42, lr=0.0003, bsz=8, dev_performance=0.9838667707520166, test_performance=0.9227764956506302
05/31/2022 20:32:39 - INFO - __main__ - Running ... prefix=ethos-religion_32_42, lr=0.0002, bsz=8 ...
05/31/2022 20:32:40 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:32:40 - INFO - __main__ - Printing 3 examples
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:32:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:32:40 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:32:40 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:32:40 - INFO - __main__ - Printing 3 examples
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:32:40 - INFO - __main__ - ['false']
05/31/2022 20:32:40 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:32:40 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:32:40 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:32:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:32:42 - INFO - __main__ - Starting training!
05/31/2022 20:32:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:32:51 - INFO - __main__ - Starting training!
05/31/2022 20:32:56 - INFO - __main__ - Step 10 Global step 10 Train loss 24.996790 on epoch=2
05/31/2022 20:33:00 - INFO - __main__ - Step 20 Global step 20 Train loss 21.547359 on epoch=4
05/31/2022 20:33:05 - INFO - __main__ - Step 30 Global step 30 Train loss 18.155262 on epoch=7
05/31/2022 20:33:10 - INFO - __main__ - Step 40 Global step 40 Train loss 18.159664 on epoch=9
05/31/2022 20:33:15 - INFO - __main__ - Step 50 Global step 50 Train loss 17.188742 on epoch=12
05/31/2022 20:33:28 - INFO - __main__ - Global step 50 Train loss 20.009563 Classification-F1 0.0 on epoch=12
05/31/2022 20:33:33 - INFO - __main__ - Step 60 Global step 60 Train loss 16.919149 on epoch=14
05/31/2022 20:33:39 - INFO - __main__ - Step 70 Global step 70 Train loss 15.328016 on epoch=17
05/31/2022 20:33:44 - INFO - __main__ - Step 80 Global step 80 Train loss 14.644785 on epoch=19
05/31/2022 20:33:49 - INFO - __main__ - Step 90 Global step 90 Train loss 13.449071 on epoch=22
05/31/2022 20:33:54 - INFO - __main__ - Step 100 Global step 100 Train loss 13.546904 on epoch=24
05/31/2022 20:34:02 - INFO - __main__ - Global step 100 Train loss 14.777585 Classification-F1 0.0 on epoch=24
05/31/2022 20:34:07 - INFO - __main__ - Step 110 Global step 110 Train loss 13.143054 on epoch=27
05/31/2022 20:34:12 - INFO - __main__ - Step 120 Global step 120 Train loss 10.441349 on epoch=29
05/31/2022 20:34:17 - INFO - __main__ - Step 130 Global step 130 Train loss 9.735987 on epoch=32
05/31/2022 20:34:22 - INFO - __main__ - Step 140 Global step 140 Train loss 5.645986 on epoch=34
05/31/2022 20:34:27 - INFO - __main__ - Step 150 Global step 150 Train loss 5.644446 on epoch=37
05/31/2022 20:34:48 - INFO - __main__ - Global step 150 Train loss 8.922164 Classification-F1 0.07235142118863049 on epoch=37
05/31/2022 20:34:54 - INFO - __main__ - Step 160 Global step 160 Train loss 3.454104 on epoch=39
05/31/2022 20:34:59 - INFO - __main__ - Step 170 Global step 170 Train loss 3.302117 on epoch=42
05/31/2022 20:35:04 - INFO - __main__ - Step 180 Global step 180 Train loss 2.092391 on epoch=44
05/31/2022 20:35:09 - INFO - __main__ - Step 190 Global step 190 Train loss 2.075290 on epoch=47
05/31/2022 20:35:14 - INFO - __main__ - Step 200 Global step 200 Train loss 0.570103 on epoch=49
05/31/2022 20:35:15 - INFO - __main__ - Global step 200 Train loss 2.298801 Classification-F1 0.5464994775339602 on epoch=49
05/31/2022 20:35:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.644184 on epoch=52
05/31/2022 20:35:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.598018 on epoch=54
05/31/2022 20:35:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.541178 on epoch=57
05/31/2022 20:35:37 - INFO - __main__ - Step 240 Global step 240 Train loss 0.485099 on epoch=59
05/31/2022 20:35:42 - INFO - __main__ - Step 250 Global step 250 Train loss 0.574451 on epoch=62
05/31/2022 20:35:43 - INFO - __main__ - Global step 250 Train loss 0.568586 Classification-F1 0.4029201615408512 on epoch=62
05/31/2022 20:35:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.467240 on epoch=64
05/31/2022 20:35:53 - INFO - __main__ - Step 270 Global step 270 Train loss 0.595309 on epoch=67
05/31/2022 20:35:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.414733 on epoch=69
05/31/2022 20:36:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.508729 on epoch=72
05/31/2022 20:36:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.447886 on epoch=74
05/31/2022 20:36:09 - INFO - __main__ - Global step 300 Train loss 0.486780 Classification-F1 0.5068181818181818 on epoch=74
05/31/2022 20:36:14 - INFO - __main__ - Step 310 Global step 310 Train loss 0.434812 on epoch=77
05/31/2022 20:36:19 - INFO - __main__ - Step 320 Global step 320 Train loss 0.457364 on epoch=79
05/31/2022 20:36:24 - INFO - __main__ - Step 330 Global step 330 Train loss 0.556630 on epoch=82
05/31/2022 20:36:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.529729 on epoch=84
05/31/2022 20:36:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.446353 on epoch=87
05/31/2022 20:36:36 - INFO - __main__ - Global step 350 Train loss 0.484978 Classification-F1 0.44704570791527315 on epoch=87
05/31/2022 20:36:41 - INFO - __main__ - Step 360 Global step 360 Train loss 0.430664 on epoch=89
05/31/2022 20:36:46 - INFO - __main__ - Step 370 Global step 370 Train loss 0.397875 on epoch=92
05/31/2022 20:36:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.380830 on epoch=94
05/31/2022 20:36:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.384041 on epoch=97
05/31/2022 20:37:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.420908 on epoch=99
05/31/2022 20:37:02 - INFO - __main__ - Global step 400 Train loss 0.402864 Classification-F1 0.4789915966386554 on epoch=99
05/31/2022 20:37:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.406133 on epoch=102
05/31/2022 20:37:12 - INFO - __main__ - Step 420 Global step 420 Train loss 0.403385 on epoch=104
05/31/2022 20:37:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.380741 on epoch=107
05/31/2022 20:37:22 - INFO - __main__ - Step 440 Global step 440 Train loss 0.429834 on epoch=109
05/31/2022 20:37:27 - INFO - __main__ - Step 450 Global step 450 Train loss 0.420273 on epoch=112
05/31/2022 20:37:28 - INFO - __main__ - Global step 450 Train loss 0.408073 Classification-F1 0.38792102206736356 on epoch=112
05/31/2022 20:37:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.371449 on epoch=114
05/31/2022 20:37:38 - INFO - __main__ - Step 470 Global step 470 Train loss 0.435331 on epoch=117
05/31/2022 20:37:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.394722 on epoch=119
05/31/2022 20:37:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.364220 on epoch=122
05/31/2022 20:37:53 - INFO - __main__ - Step 500 Global step 500 Train loss 0.422483 on epoch=124
05/31/2022 20:37:54 - INFO - __main__ - Global step 500 Train loss 0.397641 Classification-F1 0.4202111613876319 on epoch=124
05/31/2022 20:37:59 - INFO - __main__ - Step 510 Global step 510 Train loss 0.380979 on epoch=127
05/31/2022 20:38:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.387554 on epoch=129
05/31/2022 20:38:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.376025 on epoch=132
05/31/2022 20:38:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.379397 on epoch=134
05/31/2022 20:38:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.366850 on epoch=137
05/31/2022 20:38:20 - INFO - __main__ - Global step 550 Train loss 0.378161 Classification-F1 0.44232804232804235 on epoch=137
05/31/2022 20:38:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.411598 on epoch=139
05/31/2022 20:38:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.351580 on epoch=142
05/31/2022 20:38:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.393077 on epoch=144
05/31/2022 20:38:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.374275 on epoch=147
05/31/2022 20:38:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.390180 on epoch=149
05/31/2022 20:38:47 - INFO - __main__ - Global step 600 Train loss 0.384142 Classification-F1 0.5161649944258639 on epoch=149
05/31/2022 20:38:52 - INFO - __main__ - Step 610 Global step 610 Train loss 0.364438 on epoch=152
05/31/2022 20:38:57 - INFO - __main__ - Step 620 Global step 620 Train loss 0.392442 on epoch=154
05/31/2022 20:39:02 - INFO - __main__ - Step 630 Global step 630 Train loss 0.432943 on epoch=157
05/31/2022 20:39:07 - INFO - __main__ - Step 640 Global step 640 Train loss 0.376085 on epoch=159
05/31/2022 20:39:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.363305 on epoch=162
05/31/2022 20:39:13 - INFO - __main__ - Global step 650 Train loss 0.385843 Classification-F1 0.4244725738396624 on epoch=162
05/31/2022 20:39:19 - INFO - __main__ - Step 660 Global step 660 Train loss 0.410283 on epoch=164
05/31/2022 20:39:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.345956 on epoch=167
05/31/2022 20:39:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.341430 on epoch=169
05/31/2022 20:39:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.379654 on epoch=172
05/31/2022 20:39:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.401258 on epoch=174
05/31/2022 20:39:40 - INFO - __main__ - Global step 700 Train loss 0.375716 Classification-F1 0.4911616161616162 on epoch=174
05/31/2022 20:39:45 - INFO - __main__ - Step 710 Global step 710 Train loss 0.379398 on epoch=177
05/31/2022 20:39:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.346870 on epoch=179
05/31/2022 20:39:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.342201 on epoch=182
05/31/2022 20:40:01 - INFO - __main__ - Step 740 Global step 740 Train loss 0.383244 on epoch=184
05/31/2022 20:40:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.373745 on epoch=187
05/31/2022 20:40:07 - INFO - __main__ - Global step 750 Train loss 0.365092 Classification-F1 0.45614035087719296 on epoch=187
05/31/2022 20:40:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.359744 on epoch=189
05/31/2022 20:40:17 - INFO - __main__ - Step 770 Global step 770 Train loss 0.319944 on epoch=192
05/31/2022 20:40:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.335230 on epoch=194
05/31/2022 20:40:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.378580 on epoch=197
05/31/2022 20:40:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.323922 on epoch=199
05/31/2022 20:40:33 - INFO - __main__ - Global step 800 Train loss 0.343484 Classification-F1 0.6092436974789917 on epoch=199
05/31/2022 20:40:40 - INFO - __main__ - Step 810 Global step 810 Train loss 0.320904 on epoch=202
05/31/2022 20:40:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.296898 on epoch=204
05/31/2022 20:40:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.343009 on epoch=207
05/31/2022 20:40:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.292352 on epoch=209
05/31/2022 20:41:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.321319 on epoch=212
05/31/2022 20:41:01 - INFO - __main__ - Global step 850 Train loss 0.314896 Classification-F1 0.5978378378378377 on epoch=212
05/31/2022 20:41:06 - INFO - __main__ - Step 860 Global step 860 Train loss 0.276784 on epoch=214
05/31/2022 20:41:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.309094 on epoch=217
05/31/2022 20:41:16 - INFO - __main__ - Step 880 Global step 880 Train loss 0.324433 on epoch=219
05/31/2022 20:41:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.334380 on epoch=222
05/31/2022 20:41:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.283623 on epoch=224
05/31/2022 20:41:28 - INFO - __main__ - Global step 900 Train loss 0.305663 Classification-F1 0.5639943741209564 on epoch=224
05/31/2022 20:41:33 - INFO - __main__ - Step 910 Global step 910 Train loss 0.286318 on epoch=227
05/31/2022 20:41:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.305441 on epoch=229
05/31/2022 20:41:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.246993 on epoch=232
05/31/2022 20:41:48 - INFO - __main__ - Step 940 Global step 940 Train loss 0.253664 on epoch=234
05/31/2022 20:41:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.271582 on epoch=237
05/31/2022 20:41:54 - INFO - __main__ - Global step 950 Train loss 0.272800 Classification-F1 0.7898305084745764 on epoch=237
05/31/2022 20:42:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.258807 on epoch=239
05/31/2022 20:42:05 - INFO - __main__ - Step 970 Global step 970 Train loss 0.241365 on epoch=242
05/31/2022 20:42:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.225314 on epoch=244
05/31/2022 20:42:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.251358 on epoch=247
05/31/2022 20:42:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.196280 on epoch=249
05/31/2022 20:42:22 - INFO - __main__ - Global step 1000 Train loss 0.234625 Classification-F1 0.8225344782721831 on epoch=249
05/31/2022 20:42:22 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:42:22 - INFO - __main__ - Printing 3 examples
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:42:22 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:42:22 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:42:22 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:42:22 - INFO - __main__ - Printing 3 examples
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:42:22 - INFO - __main__ - ['false']
05/31/2022 20:42:22 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:42:22 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:42:22 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:42:23 - INFO - __main__ - save last model!
05/31/2022 20:42:30 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:42:30 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:42:30 - INFO - __main__ - Printing 3 examples
05/31/2022 20:42:30 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:42:30 - INFO - __main__ - ['false']
05/31/2022 20:42:30 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:42:30 - INFO - __main__ - ['false']
05/31/2022 20:42:30 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:42:30 - INFO - __main__ - ['true']
05/31/2022 20:42:30 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:42:30 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:42:31 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:42:32 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_42_0.0002_8_predictions.txt
05/31/2022 20:42:32 - INFO - __main__ - Classification-F1 on test data: 0.7585
05/31/2022 20:42:32 - INFO - __main__ - prefix=ethos-religion_32_42, lr=0.0002, bsz=8, dev_performance=0.8225344782721831, test_performance=0.758530612244898
05/31/2022 20:42:32 - INFO - __main__ - Running ... prefix=ethos-religion_32_42, lr=0.0001, bsz=8 ...
05/31/2022 20:42:33 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:42:33 - INFO - __main__ - Printing 3 examples
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] Women deserve to be abused, I guess.
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] How can Europe allow millions of rapists animals to go there ?
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] The only thing more repulsive than a nigger is a nigger faggot. Self-hating whites shower images of cross-dressed niggers with praise because the modern left fetishizes all forms of depravity.
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:42:33 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:42:33 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:42:33 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:42:33 - INFO - __main__ - Printing 3 examples
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] How is it to have a kid acting like a sloth or like a pug dog? Isn’t it hard? In your place I’d put it in a dedicated institute for problematics and pay a visit each year at max
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] Watching this kid trying to step up and walk with that crutches is the best thing in the world. So idiot
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ -  [ethos-religion] Put a woman to abuse that fat woman and don’t put a kind guy
05/31/2022 20:42:33 - INFO - __main__ - ['false']
05/31/2022 20:42:33 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:42:33 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:42:34 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:42:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:42:35 - INFO - __main__ - Starting training!
05/31/2022 20:42:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:42:44 - INFO - __main__ - Starting training!
05/31/2022 20:42:49 - INFO - __main__ - Step 10 Global step 10 Train loss 24.116018 on epoch=2
05/31/2022 20:42:54 - INFO - __main__ - Step 20 Global step 20 Train loss 21.106224 on epoch=4
05/31/2022 20:42:59 - INFO - __main__ - Step 30 Global step 30 Train loss 19.463490 on epoch=7
05/31/2022 20:43:04 - INFO - __main__ - Step 40 Global step 40 Train loss 18.771404 on epoch=9
05/31/2022 20:43:09 - INFO - __main__ - Step 50 Global step 50 Train loss 18.790453 on epoch=12
05/31/2022 20:43:29 - INFO - __main__ - Global step 50 Train loss 20.449518 Classification-F1 0.0 on epoch=12
05/31/2022 20:43:35 - INFO - __main__ - Step 60 Global step 60 Train loss 17.814831 on epoch=14
05/31/2022 20:43:40 - INFO - __main__ - Step 70 Global step 70 Train loss 17.387487 on epoch=17
05/31/2022 20:43:46 - INFO - __main__ - Step 80 Global step 80 Train loss 17.211662 on epoch=19
05/31/2022 20:43:51 - INFO - __main__ - Step 90 Global step 90 Train loss 17.243647 on epoch=22
05/31/2022 20:43:56 - INFO - __main__ - Step 100 Global step 100 Train loss 16.004009 on epoch=24
05/31/2022 20:43:57 - INFO - __main__ - Global step 100 Train loss 17.132326 Classification-F1 0.0 on epoch=24
05/31/2022 20:44:02 - INFO - __main__ - Step 110 Global step 110 Train loss 15.707533 on epoch=27
05/31/2022 20:44:07 - INFO - __main__ - Step 120 Global step 120 Train loss 15.202481 on epoch=29
05/31/2022 20:44:12 - INFO - __main__ - Step 130 Global step 130 Train loss 15.231486 on epoch=32
05/31/2022 20:44:17 - INFO - __main__ - Step 140 Global step 140 Train loss 14.115405 on epoch=34
05/31/2022 20:44:23 - INFO - __main__ - Step 150 Global step 150 Train loss 14.294026 on epoch=37
05/31/2022 20:44:24 - INFO - __main__ - Global step 150 Train loss 14.910186 Classification-F1 0.0 on epoch=37
05/31/2022 20:44:29 - INFO - __main__ - Step 160 Global step 160 Train loss 13.937304 on epoch=39
05/31/2022 20:44:34 - INFO - __main__ - Step 170 Global step 170 Train loss 14.250422 on epoch=42
05/31/2022 20:44:39 - INFO - __main__ - Step 180 Global step 180 Train loss 12.801111 on epoch=44
05/31/2022 20:44:44 - INFO - __main__ - Step 190 Global step 190 Train loss 11.800626 on epoch=47
05/31/2022 20:44:49 - INFO - __main__ - Step 200 Global step 200 Train loss 11.743072 on epoch=49
05/31/2022 20:44:50 - INFO - __main__ - Global step 200 Train loss 12.906507 Classification-F1 0.0 on epoch=49
05/31/2022 20:44:55 - INFO - __main__ - Step 210 Global step 210 Train loss 10.475496 on epoch=52
05/31/2022 20:45:00 - INFO - __main__ - Step 220 Global step 220 Train loss 10.972063 on epoch=54
05/31/2022 20:45:06 - INFO - __main__ - Step 230 Global step 230 Train loss 9.485058 on epoch=57
05/31/2022 20:45:11 - INFO - __main__ - Step 240 Global step 240 Train loss 8.925784 on epoch=59
05/31/2022 20:45:16 - INFO - __main__ - Step 250 Global step 250 Train loss 6.416265 on epoch=62
05/31/2022 20:45:17 - INFO - __main__ - Global step 250 Train loss 9.254933 Classification-F1 0.0918918918918919 on epoch=62
05/31/2022 20:45:24 - INFO - __main__ - Step 260 Global step 260 Train loss 6.457304 on epoch=64
05/31/2022 20:45:29 - INFO - __main__ - Step 270 Global step 270 Train loss 3.759639 on epoch=67
05/31/2022 20:45:34 - INFO - __main__ - Step 280 Global step 280 Train loss 1.879334 on epoch=69
05/31/2022 20:45:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.790110 on epoch=72
05/31/2022 20:45:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.815762 on epoch=74
05/31/2022 20:45:46 - INFO - __main__ - Global step 300 Train loss 2.740430 Classification-F1 0.4029201615408512 on epoch=74
05/31/2022 20:45:52 - INFO - __main__ - Step 310 Global step 310 Train loss 0.758213 on epoch=77
05/31/2022 20:45:57 - INFO - __main__ - Step 320 Global step 320 Train loss 0.737247 on epoch=79
05/31/2022 20:46:03 - INFO - __main__ - Step 330 Global step 330 Train loss 0.509957 on epoch=82
05/31/2022 20:46:08 - INFO - __main__ - Step 340 Global step 340 Train loss 0.595649 on epoch=84
05/31/2022 20:46:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.827773 on epoch=87
05/31/2022 20:46:14 - INFO - __main__ - Global step 350 Train loss 0.685768 Classification-F1 0.7654054054054055 on epoch=87
05/31/2022 20:46:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.642421 on epoch=89
05/31/2022 20:46:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.571741 on epoch=92
05/31/2022 20:46:31 - INFO - __main__ - Step 380 Global step 380 Train loss 0.619983 on epoch=94
05/31/2022 20:46:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.361982 on epoch=97
05/31/2022 20:46:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.261345 on epoch=99
05/31/2022 20:46:42 - INFO - __main__ - Global step 400 Train loss 0.491494 Classification-F1 0.7416666666666667 on epoch=99
05/31/2022 20:46:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.560621 on epoch=102
05/31/2022 20:46:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.622825 on epoch=104
05/31/2022 20:46:56 - INFO - __main__ - Step 430 Global step 430 Train loss 0.661598 on epoch=107
05/31/2022 20:47:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.542770 on epoch=109
05/31/2022 20:47:06 - INFO - __main__ - Step 450 Global step 450 Train loss 0.397799 on epoch=112
05/31/2022 20:47:07 - INFO - __main__ - Global step 450 Train loss 0.557123 Classification-F1 0.7889499869075675 on epoch=112
05/31/2022 20:47:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.268481 on epoch=114
05/31/2022 20:47:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.445183 on epoch=117
05/31/2022 20:47:22 - INFO - __main__ - Step 480 Global step 480 Train loss 0.267458 on epoch=119
05/31/2022 20:47:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.250579 on epoch=122
05/31/2022 20:47:32 - INFO - __main__ - Step 500 Global step 500 Train loss 0.311391 on epoch=124
05/31/2022 20:47:33 - INFO - __main__ - Global step 500 Train loss 0.308618 Classification-F1 0.7732497387669801 on epoch=124
05/31/2022 20:47:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.356329 on epoch=127
05/31/2022 20:47:43 - INFO - __main__ - Step 520 Global step 520 Train loss 0.290215 on epoch=129
05/31/2022 20:47:48 - INFO - __main__ - Step 530 Global step 530 Train loss 0.346721 on epoch=132
05/31/2022 20:47:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.325278 on epoch=134
05/31/2022 20:47:58 - INFO - __main__ - Step 550 Global step 550 Train loss 0.244527 on epoch=137
05/31/2022 20:47:58 - INFO - __main__ - Global step 550 Train loss 0.312614 Classification-F1 0.8168143969916734 on epoch=137
05/31/2022 20:48:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.362304 on epoch=139
05/31/2022 20:48:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.420293 on epoch=142
05/31/2022 20:48:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.347048 on epoch=144
05/31/2022 20:48:19 - INFO - __main__ - Step 590 Global step 590 Train loss 0.418000 on epoch=147
05/31/2022 20:48:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.470409 on epoch=149
05/31/2022 20:48:25 - INFO - __main__ - Global step 600 Train loss 0.403611 Classification-F1 0.5588932806324111 on epoch=149
05/31/2022 20:48:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.336955 on epoch=152
05/31/2022 20:48:35 - INFO - __main__ - Step 620 Global step 620 Train loss 0.378820 on epoch=154
05/31/2022 20:48:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.334650 on epoch=157
05/31/2022 20:48:45 - INFO - __main__ - Step 640 Global step 640 Train loss 0.379795 on epoch=159
05/31/2022 20:48:50 - INFO - __main__ - Step 650 Global step 650 Train loss 0.353546 on epoch=162
05/31/2022 20:48:51 - INFO - __main__ - Global step 650 Train loss 0.356753 Classification-F1 0.6447916666666667 on epoch=162
05/31/2022 20:48:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.309357 on epoch=164
05/31/2022 20:49:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.322829 on epoch=167
05/31/2022 20:49:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.333891 on epoch=169
05/31/2022 20:49:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.364259 on epoch=172
05/31/2022 20:49:16 - INFO - __main__ - Step 700 Global step 700 Train loss 0.408499 on epoch=174
05/31/2022 20:49:17 - INFO - __main__ - Global step 700 Train loss 0.347767 Classification-F1 0.6092436974789917 on epoch=174
05/31/2022 20:49:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.325547 on epoch=177
05/31/2022 20:49:27 - INFO - __main__ - Step 720 Global step 720 Train loss 0.342796 on epoch=179
05/31/2022 20:49:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.293307 on epoch=182
05/31/2022 20:49:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.394722 on epoch=184
05/31/2022 20:49:42 - INFO - __main__ - Step 750 Global step 750 Train loss 0.339276 on epoch=187
05/31/2022 20:49:43 - INFO - __main__ - Global step 750 Train loss 0.339129 Classification-F1 0.6356837606837606 on epoch=187
05/31/2022 20:49:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.333881 on epoch=189
05/31/2022 20:49:53 - INFO - __main__ - Step 770 Global step 770 Train loss 0.275724 on epoch=192
05/31/2022 20:49:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.302243 on epoch=194
05/31/2022 20:50:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.318403 on epoch=197
05/31/2022 20:50:07 - INFO - __main__ - Step 800 Global step 800 Train loss 0.290110 on epoch=199
05/31/2022 20:50:08 - INFO - __main__ - Global step 800 Train loss 0.304072 Classification-F1 0.7047619047619047 on epoch=199
05/31/2022 20:50:13 - INFO - __main__ - Step 810 Global step 810 Train loss 0.353992 on epoch=202
05/31/2022 20:50:18 - INFO - __main__ - Step 820 Global step 820 Train loss 0.305176 on epoch=204
05/31/2022 20:50:23 - INFO - __main__ - Step 830 Global step 830 Train loss 0.270742 on epoch=207
05/31/2022 20:50:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.298761 on epoch=209
05/31/2022 20:50:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.324189 on epoch=212
05/31/2022 20:50:34 - INFO - __main__ - Global step 850 Train loss 0.310572 Classification-F1 0.7257351027842831 on epoch=212
05/31/2022 20:50:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.207984 on epoch=214
05/31/2022 20:50:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.268944 on epoch=217
05/31/2022 20:50:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.261151 on epoch=219
05/31/2022 20:50:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.227771 on epoch=222
05/31/2022 20:50:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.260680 on epoch=224
05/31/2022 20:51:00 - INFO - __main__ - Global step 900 Train loss 0.245306 Classification-F1 0.7739583333333333 on epoch=224
05/31/2022 20:51:05 - INFO - __main__ - Step 910 Global step 910 Train loss 0.215276 on epoch=227
05/31/2022 20:51:10 - INFO - __main__ - Step 920 Global step 920 Train loss 0.237732 on epoch=229
05/31/2022 20:51:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.227988 on epoch=232
05/31/2022 20:51:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.202985 on epoch=234
05/31/2022 20:51:26 - INFO - __main__ - Step 950 Global step 950 Train loss 0.224721 on epoch=237
05/31/2022 20:51:27 - INFO - __main__ - Global step 950 Train loss 0.221740 Classification-F1 0.8056426332288401 on epoch=237
05/31/2022 20:51:32 - INFO - __main__ - Step 960 Global step 960 Train loss 0.220660 on epoch=239
05/31/2022 20:51:38 - INFO - __main__ - Step 970 Global step 970 Train loss 0.213436 on epoch=242
05/31/2022 20:51:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.184472 on epoch=244
05/31/2022 20:51:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.189881 on epoch=247
05/31/2022 20:51:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.265013 on epoch=249
05/31/2022 20:51:53 - INFO - __main__ - Global step 1000 Train loss 0.214692 Classification-F1 0.724011521340665 on epoch=249
05/31/2022 20:51:53 - INFO - __main__ - save last model!
05/31/2022 20:51:54 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:51:54 - INFO - __main__ - Printing 3 examples
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:51:54 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:51:54 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:51:54 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:51:54 - INFO - __main__ - Printing 3 examples
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 20:51:54 - INFO - __main__ - ['false']
05/31/2022 20:51:54 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:51:54 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:51:54 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:52:00 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 20:52:01 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 20:52:01 - INFO - __main__ - Printing 3 examples
05/31/2022 20:52:01 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 20:52:01 - INFO - __main__ - ['false']
05/31/2022 20:52:01 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 20:52:01 - INFO - __main__ - ['false']
05/31/2022 20:52:01 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 20:52:01 - INFO - __main__ - ['true']
05/31/2022 20:52:01 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:52:01 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:52:01 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 20:52:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_42_0.0001_8_predictions.txt
05/31/2022 20:52:02 - INFO - __main__ - Classification-F1 on test data: 0.9504
05/31/2022 20:52:03 - INFO - __main__ - prefix=ethos-religion_32_42, lr=0.0001, bsz=8, dev_performance=0.8168143969916734, test_performance=0.9504273504273504
05/31/2022 20:52:03 - INFO - __main__ - Running ... prefix=ethos-religion_32_87, lr=0.0005, bsz=8 ...
05/31/2022 20:52:04 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 20:52:04 - INFO - __main__ - Printing 3 examples
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:52:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:52:04 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 20:52:04 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 20:52:04 - INFO - __main__ - Printing 3 examples
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 20:52:04 - INFO - __main__ - ['false']
05/31/2022 20:52:04 - INFO - __main__ - Tokenizing Input ...
05/31/2022 20:52:04 - INFO - __main__ - Tokenizing Output ...
05/31/2022 20:52:04 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 20:52:05 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:52:05 - INFO - __main__ - Starting training!
05/31/2022 20:52:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 20:52:15 - INFO - __main__ - Starting training!
05/31/2022 20:52:19 - INFO - __main__ - Step 10 Global step 10 Train loss 24.620548 on epoch=2
05/31/2022 20:52:24 - INFO - __main__ - Step 20 Global step 20 Train loss 18.575972 on epoch=4
05/31/2022 20:52:29 - INFO - __main__ - Step 30 Global step 30 Train loss 16.237003 on epoch=7
05/31/2022 20:52:35 - INFO - __main__ - Step 40 Global step 40 Train loss 14.386215 on epoch=9
05/31/2022 20:52:40 - INFO - __main__ - Step 50 Global step 50 Train loss 11.578713 on epoch=12
05/31/2022 20:52:40 - INFO - __main__ - Global step 50 Train loss 17.079691 Classification-F1 0.0 on epoch=12
05/31/2022 20:52:46 - INFO - __main__ - Step 60 Global step 60 Train loss 7.713377 on epoch=14
05/31/2022 20:52:51 - INFO - __main__ - Step 70 Global step 70 Train loss 4.252206 on epoch=17
05/31/2022 20:52:56 - INFO - __main__ - Step 80 Global step 80 Train loss 1.943243 on epoch=19
05/31/2022 20:53:01 - INFO - __main__ - Step 90 Global step 90 Train loss 1.850797 on epoch=22
05/31/2022 20:53:06 - INFO - __main__ - Step 100 Global step 100 Train loss 2.624076 on epoch=24
05/31/2022 20:53:07 - INFO - __main__ - Global step 100 Train loss 3.676740 Classification-F1 0.3404255319148936 on epoch=24
05/31/2022 20:53:13 - INFO - __main__ - Step 110 Global step 110 Train loss 2.137786 on epoch=27
05/31/2022 20:53:19 - INFO - __main__ - Step 120 Global step 120 Train loss 2.980568 on epoch=29
05/31/2022 20:53:24 - INFO - __main__ - Step 130 Global step 130 Train loss 1.044471 on epoch=32
05/31/2022 20:53:29 - INFO - __main__ - Step 140 Global step 140 Train loss 1.816169 on epoch=34
05/31/2022 20:53:34 - INFO - __main__ - Step 150 Global step 150 Train loss 2.620521 on epoch=37
05/31/2022 20:53:35 - INFO - __main__ - Global step 150 Train loss 2.119903 Classification-F1 0.3404255319148936 on epoch=37
05/31/2022 20:53:40 - INFO - __main__ - Step 160 Global step 160 Train loss 2.326285 on epoch=39
05/31/2022 20:53:45 - INFO - __main__ - Step 170 Global step 170 Train loss 1.841162 on epoch=42
05/31/2022 20:53:50 - INFO - __main__ - Step 180 Global step 180 Train loss 1.863837 on epoch=44
05/31/2022 20:53:55 - INFO - __main__ - Step 190 Global step 190 Train loss 1.195812 on epoch=47
05/31/2022 20:54:00 - INFO - __main__ - Step 200 Global step 200 Train loss 1.414465 on epoch=49
05/31/2022 20:54:01 - INFO - __main__ - Global step 200 Train loss 1.728312 Classification-F1 0.6418067226890756 on epoch=49
05/31/2022 20:54:07 - INFO - __main__ - Step 210 Global step 210 Train loss 1.387439 on epoch=52
05/31/2022 20:54:12 - INFO - __main__ - Step 220 Global step 220 Train loss 1.269680 on epoch=54
05/31/2022 20:54:17 - INFO - __main__ - Step 230 Global step 230 Train loss 1.070260 on epoch=57
05/31/2022 20:54:22 - INFO - __main__ - Step 240 Global step 240 Train loss 1.025419 on epoch=59
05/31/2022 20:54:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.901925 on epoch=62
05/31/2022 20:54:28 - INFO - __main__ - Global step 250 Train loss 1.130944 Classification-F1 0.39215686274509803 on epoch=62
05/31/2022 20:54:33 - INFO - __main__ - Step 260 Global step 260 Train loss 0.838311 on epoch=64
05/31/2022 20:54:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.792456 on epoch=67
05/31/2022 20:54:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.717517 on epoch=69
05/31/2022 20:54:49 - INFO - __main__ - Step 290 Global step 290 Train loss 0.629178 on epoch=72
05/31/2022 20:54:54 - INFO - __main__ - Step 300 Global step 300 Train loss 0.678815 on epoch=74
05/31/2022 20:54:54 - INFO - __main__ - Global step 300 Train loss 0.731255 Classification-F1 0.3404255319148936 on epoch=74
05/31/2022 20:54:59 - INFO - __main__ - Step 310 Global step 310 Train loss 0.479110 on epoch=77
05/31/2022 20:55:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.541741 on epoch=79
05/31/2022 20:55:10 - INFO - __main__ - Step 330 Global step 330 Train loss 0.488906 on epoch=82
05/31/2022 20:55:15 - INFO - __main__ - Step 340 Global step 340 Train loss 0.521658 on epoch=84
05/31/2022 20:55:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.454978 on epoch=87
05/31/2022 20:55:21 - INFO - __main__ - Global step 350 Train loss 0.497278 Classification-F1 0.32608695652173914 on epoch=87
05/31/2022 20:55:26 - INFO - __main__ - Step 360 Global step 360 Train loss 0.419113 on epoch=89
05/31/2022 20:55:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.443618 on epoch=92
05/31/2022 20:55:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.393895 on epoch=94
05/31/2022 20:55:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.489644 on epoch=97
05/31/2022 20:55:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.455166 on epoch=99
05/31/2022 20:55:46 - INFO - __main__ - Global step 400 Train loss 0.440287 Classification-F1 0.47159090909090906 on epoch=99
05/31/2022 20:55:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.399839 on epoch=102
05/31/2022 20:55:57 - INFO - __main__ - Step 420 Global step 420 Train loss 0.412695 on epoch=104
05/31/2022 20:56:02 - INFO - __main__ - Step 430 Global step 430 Train loss 0.422399 on epoch=107
05/31/2022 20:56:07 - INFO - __main__ - Step 440 Global step 440 Train loss 0.472122 on epoch=109
05/31/2022 20:56:12 - INFO - __main__ - Step 450 Global step 450 Train loss 0.426312 on epoch=112
05/31/2022 20:56:12 - INFO - __main__ - Global step 450 Train loss 0.426674 Classification-F1 0.3404255319148936 on epoch=112
05/31/2022 20:56:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.419183 on epoch=114
05/31/2022 20:56:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.414546 on epoch=117
05/31/2022 20:56:28 - INFO - __main__ - Step 480 Global step 480 Train loss 0.430815 on epoch=119
05/31/2022 20:56:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.385068 on epoch=122
05/31/2022 20:56:38 - INFO - __main__ - Step 500 Global step 500 Train loss 0.366968 on epoch=124
05/31/2022 20:56:39 - INFO - __main__ - Global step 500 Train loss 0.403316 Classification-F1 0.4103260869565218 on epoch=124
05/31/2022 20:56:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.387727 on epoch=127
05/31/2022 20:56:49 - INFO - __main__ - Step 520 Global step 520 Train loss 0.426360 on epoch=129
05/31/2022 20:56:54 - INFO - __main__ - Step 530 Global step 530 Train loss 0.470604 on epoch=132
05/31/2022 20:57:00 - INFO - __main__ - Step 540 Global step 540 Train loss 0.384859 on epoch=134
05/31/2022 20:57:05 - INFO - __main__ - Step 550 Global step 550 Train loss 0.375769 on epoch=137
05/31/2022 20:57:05 - INFO - __main__ - Global step 550 Train loss 0.409064 Classification-F1 0.5570052811432121 on epoch=137
05/31/2022 20:57:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.333136 on epoch=139
05/31/2022 20:57:15 - INFO - __main__ - Step 570 Global step 570 Train loss 0.347906 on epoch=142
05/31/2022 20:57:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.383470 on epoch=144
05/31/2022 20:57:26 - INFO - __main__ - Step 590 Global step 590 Train loss 0.333160 on epoch=147
05/31/2022 20:57:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.342258 on epoch=149
05/31/2022 20:57:31 - INFO - __main__ - Global step 600 Train loss 0.347986 Classification-F1 0.8046218487394958 on epoch=149
05/31/2022 20:57:38 - INFO - __main__ - Step 610 Global step 610 Train loss 0.324263 on epoch=152
05/31/2022 20:57:43 - INFO - __main__ - Step 620 Global step 620 Train loss 0.353083 on epoch=154
05/31/2022 20:57:48 - INFO - __main__ - Step 630 Global step 630 Train loss 0.309570 on epoch=157
05/31/2022 20:57:53 - INFO - __main__ - Step 640 Global step 640 Train loss 0.273969 on epoch=159
05/31/2022 20:57:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.330706 on epoch=162
05/31/2022 20:57:59 - INFO - __main__ - Global step 650 Train loss 0.318318 Classification-F1 0.6502820306204674 on epoch=162
05/31/2022 20:58:04 - INFO - __main__ - Step 660 Global step 660 Train loss 0.281390 on epoch=164
05/31/2022 20:58:09 - INFO - __main__ - Step 670 Global step 670 Train loss 0.297263 on epoch=167
05/31/2022 20:58:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.241410 on epoch=169
05/31/2022 20:58:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.292927 on epoch=172
05/31/2022 20:58:24 - INFO - __main__ - Step 700 Global step 700 Train loss 0.182908 on epoch=174
05/31/2022 20:58:25 - INFO - __main__ - Global step 700 Train loss 0.259180 Classification-F1 0.7902680197762164 on epoch=174
05/31/2022 20:58:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.212528 on epoch=177
05/31/2022 20:58:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.149371 on epoch=179
05/31/2022 20:58:40 - INFO - __main__ - Step 730 Global step 730 Train loss 0.176222 on epoch=182
05/31/2022 20:58:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.161449 on epoch=184
05/31/2022 20:58:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.116945 on epoch=187
05/31/2022 20:58:51 - INFO - __main__ - Global step 750 Train loss 0.163303 Classification-F1 0.8380355276907001 on epoch=187
05/31/2022 20:58:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.187789 on epoch=189
05/31/2022 20:59:02 - INFO - __main__ - Step 770 Global step 770 Train loss 0.101279 on epoch=192
05/31/2022 20:59:07 - INFO - __main__ - Step 780 Global step 780 Train loss 0.064503 on epoch=194
05/31/2022 20:59:13 - INFO - __main__ - Step 790 Global step 790 Train loss 0.159745 on epoch=197
05/31/2022 20:59:18 - INFO - __main__ - Step 800 Global step 800 Train loss 0.075157 on epoch=199
05/31/2022 20:59:19 - INFO - __main__ - Global step 800 Train loss 0.117695 Classification-F1 0.87042842215256 on epoch=199
05/31/2022 20:59:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.054347 on epoch=202
05/31/2022 20:59:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.036518 on epoch=204
05/31/2022 20:59:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.031160 on epoch=207
05/31/2022 20:59:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.075511 on epoch=209
05/31/2022 20:59:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.131407 on epoch=212
05/31/2022 20:59:46 - INFO - __main__ - Global step 850 Train loss 0.065789 Classification-F1 0.8225344782721832 on epoch=212
05/31/2022 20:59:51 - INFO - __main__ - Step 860 Global step 860 Train loss 0.044032 on epoch=214
05/31/2022 20:59:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.013398 on epoch=217
05/31/2022 21:00:01 - INFO - __main__ - Step 880 Global step 880 Train loss 0.037543 on epoch=219
05/31/2022 21:00:06 - INFO - __main__ - Step 890 Global step 890 Train loss 0.175299 on epoch=222
05/31/2022 21:00:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.028227 on epoch=224
05/31/2022 21:00:12 - INFO - __main__ - Global step 900 Train loss 0.059700 Classification-F1 0.8387096774193549 on epoch=224
05/31/2022 21:00:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.010071 on epoch=227
05/31/2022 21:00:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.009271 on epoch=229
05/31/2022 21:00:28 - INFO - __main__ - Step 930 Global step 930 Train loss 0.003647 on epoch=232
05/31/2022 21:00:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.017145 on epoch=234
05/31/2022 21:00:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.002138 on epoch=237
05/31/2022 21:00:39 - INFO - __main__ - Global step 950 Train loss 0.008454 Classification-F1 0.6794557823129252 on epoch=237
05/31/2022 21:00:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.024419 on epoch=239
05/31/2022 21:00:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.027227 on epoch=242
05/31/2022 21:00:54 - INFO - __main__ - Step 980 Global step 980 Train loss 0.016579 on epoch=244
05/31/2022 21:00:59 - INFO - __main__ - Step 990 Global step 990 Train loss 0.004988 on epoch=247
05/31/2022 21:01:04 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.022027 on epoch=249
05/31/2022 21:01:05 - INFO - __main__ - Global step 1000 Train loss 0.019048 Classification-F1 0.6600877192982456 on epoch=249
05/31/2022 21:01:05 - INFO - __main__ - save last model!
05/31/2022 21:01:06 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:01:06 - INFO - __main__ - Printing 3 examples
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:01:06 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:01:06 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:01:06 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:01:06 - INFO - __main__ - Printing 3 examples
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:01:06 - INFO - __main__ - ['false']
05/31/2022 21:01:06 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:01:06 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:01:06 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:01:12 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 21:01:13 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 21:01:13 - INFO - __main__ - Printing 3 examples
05/31/2022 21:01:13 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 21:01:13 - INFO - __main__ - ['false']
05/31/2022 21:01:13 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 21:01:13 - INFO - __main__ - ['false']
05/31/2022 21:01:13 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 21:01:13 - INFO - __main__ - ['true']
05/31/2022 21:01:13 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:01:13 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:01:13 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 21:01:14 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_87_0.0005_8_predictions.txt
05/31/2022 21:01:14 - INFO - __main__ - Classification-F1 on test data: 0.8317
05/31/2022 21:01:14 - INFO - __main__ - prefix=ethos-religion_32_87, lr=0.0005, bsz=8, dev_performance=0.87042842215256, test_performance=0.831656346749226
05/31/2022 21:01:14 - INFO - __main__ - Running ... prefix=ethos-religion_32_87, lr=0.0003, bsz=8 ...
05/31/2022 21:01:15 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:01:15 - INFO - __main__ - Printing 3 examples
05/31/2022 21:01:15 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:01:15 - INFO - __main__ - ['false']
05/31/2022 21:01:15 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:01:15 - INFO - __main__ - ['false']
05/31/2022 21:01:15 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:01:15 - INFO - __main__ - ['false']
05/31/2022 21:01:15 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:01:15 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:01:16 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:01:16 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:01:16 - INFO - __main__ - Printing 3 examples
05/31/2022 21:01:16 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:01:16 - INFO - __main__ - ['false']
05/31/2022 21:01:16 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:01:16 - INFO - __main__ - ['false']
05/31/2022 21:01:16 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:01:16 - INFO - __main__ - ['false']
05/31/2022 21:01:16 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:01:16 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:01:16 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:01:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:01:17 - INFO - __main__ - Starting training!
05/31/2022 21:01:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:01:26 - INFO - __main__ - Starting training!
05/31/2022 21:01:31 - INFO - __main__ - Step 10 Global step 10 Train loss 22.734310 on epoch=2
05/31/2022 21:01:35 - INFO - __main__ - Step 20 Global step 20 Train loss 19.399757 on epoch=4
05/31/2022 21:01:40 - INFO - __main__ - Step 30 Global step 30 Train loss 16.679865 on epoch=7
05/31/2022 21:01:46 - INFO - __main__ - Step 40 Global step 40 Train loss 16.038311 on epoch=9
05/31/2022 21:01:51 - INFO - __main__ - Step 50 Global step 50 Train loss 14.933866 on epoch=12
05/31/2022 21:02:06 - INFO - __main__ - Global step 50 Train loss 17.957222 Classification-F1 0.0 on epoch=12
05/31/2022 21:02:12 - INFO - __main__ - Step 60 Global step 60 Train loss 13.204068 on epoch=14
05/31/2022 21:02:17 - INFO - __main__ - Step 70 Global step 70 Train loss 12.775798 on epoch=17
05/31/2022 21:02:22 - INFO - __main__ - Step 80 Global step 80 Train loss 9.387671 on epoch=19
05/31/2022 21:02:27 - INFO - __main__ - Step 90 Global step 90 Train loss 2.790427 on epoch=22
05/31/2022 21:02:32 - INFO - __main__ - Step 100 Global step 100 Train loss 0.756701 on epoch=24
05/31/2022 21:02:33 - INFO - __main__ - Global step 100 Train loss 7.782933 Classification-F1 0.3404255319148936 on epoch=24
05/31/2022 21:02:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.705180 on epoch=27
05/31/2022 21:02:45 - INFO - __main__ - Step 120 Global step 120 Train loss 0.712604 on epoch=29
05/31/2022 21:02:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.384373 on epoch=32
05/31/2022 21:02:55 - INFO - __main__ - Step 140 Global step 140 Train loss 0.358896 on epoch=34
05/31/2022 21:03:00 - INFO - __main__ - Step 150 Global step 150 Train loss 0.331973 on epoch=37
05/31/2022 21:03:01 - INFO - __main__ - Global step 150 Train loss 0.498605 Classification-F1 0.7654054054054054 on epoch=37
05/31/2022 21:03:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.428107 on epoch=39
05/31/2022 21:03:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.222130 on epoch=42
05/31/2022 21:03:18 - INFO - __main__ - Step 180 Global step 180 Train loss 0.196578 on epoch=44
05/31/2022 21:03:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.172404 on epoch=47
05/31/2022 21:03:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.286984 on epoch=49
05/31/2022 21:03:29 - INFO - __main__ - Global step 200 Train loss 0.261241 Classification-F1 0.8538884524744697 on epoch=49
05/31/2022 21:03:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.165550 on epoch=52
05/31/2022 21:03:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.120069 on epoch=54
05/31/2022 21:03:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.099316 on epoch=57
05/31/2022 21:03:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.102197 on epoch=59
05/31/2022 21:03:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.103564 on epoch=62
05/31/2022 21:03:57 - INFO - __main__ - Global step 250 Train loss 0.118139 Classification-F1 0.870967741935484 on epoch=62
05/31/2022 21:04:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.091658 on epoch=64
05/31/2022 21:04:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.091472 on epoch=67
05/31/2022 21:04:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.059249 on epoch=69
05/31/2022 21:04:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.108394 on epoch=72
05/31/2022 21:04:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.101081 on epoch=74
05/31/2022 21:04:24 - INFO - __main__ - Global step 300 Train loss 0.090371 Classification-F1 0.8697478991596639 on epoch=74
05/31/2022 21:04:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.080283 on epoch=77
05/31/2022 21:04:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.095763 on epoch=79
05/31/2022 21:04:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.046860 on epoch=82
05/31/2022 21:04:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.101232 on epoch=84
05/31/2022 21:04:50 - INFO - __main__ - Step 350 Global step 350 Train loss 0.074091 on epoch=87
05/31/2022 21:04:51 - INFO - __main__ - Global step 350 Train loss 0.079646 Classification-F1 0.903125 on epoch=87
05/31/2022 21:04:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.068671 on epoch=89
05/31/2022 21:05:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.044373 on epoch=92
05/31/2022 21:05:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.057891 on epoch=94
05/31/2022 21:05:12 - INFO - __main__ - Step 390 Global step 390 Train loss 0.082665 on epoch=97
05/31/2022 21:05:18 - INFO - __main__ - Step 400 Global step 400 Train loss 0.044862 on epoch=99
05/31/2022 21:05:18 - INFO - __main__ - Global step 400 Train loss 0.059692 Classification-F1 0.8380355276907001 on epoch=99
05/31/2022 21:05:23 - INFO - __main__ - Step 410 Global step 410 Train loss 0.031657 on epoch=102
05/31/2022 21:05:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.046372 on epoch=104
05/31/2022 21:05:34 - INFO - __main__ - Step 430 Global step 430 Train loss 0.012083 on epoch=107
05/31/2022 21:05:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.058459 on epoch=109
05/31/2022 21:05:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.062331 on epoch=112
05/31/2022 21:05:45 - INFO - __main__ - Global step 450 Train loss 0.042180 Classification-F1 0.8529644268774703 on epoch=112
05/31/2022 21:05:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.010060 on epoch=114
05/31/2022 21:05:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.003018 on epoch=117
05/31/2022 21:06:00 - INFO - __main__ - Step 480 Global step 480 Train loss 0.004766 on epoch=119
05/31/2022 21:06:06 - INFO - __main__ - Step 490 Global step 490 Train loss 0.002150 on epoch=122
05/31/2022 21:06:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.009295 on epoch=124
05/31/2022 21:06:12 - INFO - __main__ - Global step 500 Train loss 0.005858 Classification-F1 0.8187616263619453 on epoch=124
05/31/2022 21:06:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.074798 on epoch=127
05/31/2022 21:06:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.014180 on epoch=129
05/31/2022 21:06:27 - INFO - __main__ - Step 530 Global step 530 Train loss 0.002762 on epoch=132
05/31/2022 21:06:32 - INFO - __main__ - Step 540 Global step 540 Train loss 0.022559 on epoch=134
05/31/2022 21:06:37 - INFO - __main__ - Step 550 Global step 550 Train loss 0.000149 on epoch=137
05/31/2022 21:06:38 - INFO - __main__ - Global step 550 Train loss 0.022890 Classification-F1 0.8529644268774703 on epoch=137
05/31/2022 21:06:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.005627 on epoch=139
05/31/2022 21:06:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.026208 on epoch=142
05/31/2022 21:06:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.005914 on epoch=144
05/31/2022 21:06:59 - INFO - __main__ - Step 590 Global step 590 Train loss 0.000186 on epoch=147
05/31/2022 21:07:04 - INFO - __main__ - Step 600 Global step 600 Train loss 0.006202 on epoch=149
05/31/2022 21:07:05 - INFO - __main__ - Global step 600 Train loss 0.008827 Classification-F1 0.8359788359788359 on epoch=149
05/31/2022 21:07:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.018983 on epoch=152
05/31/2022 21:07:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.000267 on epoch=154
05/31/2022 21:07:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.005324 on epoch=157
05/31/2022 21:07:25 - INFO - __main__ - Step 640 Global step 640 Train loss 0.000809 on epoch=159
05/31/2022 21:07:30 - INFO - __main__ - Step 650 Global step 650 Train loss 0.002597 on epoch=162
05/31/2022 21:07:31 - INFO - __main__ - Global step 650 Train loss 0.005596 Classification-F1 0.8544980443285528 on epoch=162
05/31/2022 21:07:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.002621 on epoch=164
05/31/2022 21:07:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.044870 on epoch=167
05/31/2022 21:07:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.002253 on epoch=169
05/31/2022 21:07:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.025143 on epoch=172
05/31/2022 21:07:56 - INFO - __main__ - Step 700 Global step 700 Train loss 0.003369 on epoch=174
05/31/2022 21:07:57 - INFO - __main__ - Global step 700 Train loss 0.015651 Classification-F1 0.8387096774193549 on epoch=174
05/31/2022 21:08:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.000151 on epoch=177
05/31/2022 21:08:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.039137 on epoch=179
05/31/2022 21:08:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.000091 on epoch=182
05/31/2022 21:08:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.000042 on epoch=184
05/31/2022 21:08:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.000283 on epoch=187
05/31/2022 21:08:23 - INFO - __main__ - Global step 750 Train loss 0.007941 Classification-F1 0.8544980443285528 on epoch=187
05/31/2022 21:08:28 - INFO - __main__ - Step 760 Global step 760 Train loss 0.000093 on epoch=189
05/31/2022 21:08:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.000049 on epoch=192
05/31/2022 21:08:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.008574 on epoch=194
05/31/2022 21:08:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.000483 on epoch=197
05/31/2022 21:08:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.000048 on epoch=199
05/31/2022 21:08:50 - INFO - __main__ - Global step 800 Train loss 0.001849 Classification-F1 0.8380355276907001 on epoch=199
05/31/2022 21:08:55 - INFO - __main__ - Step 810 Global step 810 Train loss 0.000021 on epoch=202
05/31/2022 21:09:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.000055 on epoch=204
05/31/2022 21:09:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.000089 on epoch=207
05/31/2022 21:09:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.000266 on epoch=209
05/31/2022 21:09:16 - INFO - __main__ - Step 850 Global step 850 Train loss 0.000223 on epoch=212
05/31/2022 21:09:16 - INFO - __main__ - Global step 850 Train loss 0.000131 Classification-F1 0.8708333333333332 on epoch=212
05/31/2022 21:09:21 - INFO - __main__ - Step 860 Global step 860 Train loss 0.000051 on epoch=214
05/31/2022 21:09:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.001566 on epoch=217
05/31/2022 21:09:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.000071 on epoch=219
05/31/2022 21:09:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.000075 on epoch=222
05/31/2022 21:09:42 - INFO - __main__ - Step 900 Global step 900 Train loss 0.000271 on epoch=224
05/31/2022 21:09:43 - INFO - __main__ - Global step 900 Train loss 0.000407 Classification-F1 0.9028213166144201 on epoch=224
05/31/2022 21:09:48 - INFO - __main__ - Step 910 Global step 910 Train loss 0.000032 on epoch=227
05/31/2022 21:09:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.005663 on epoch=229
05/31/2022 21:09:58 - INFO - __main__ - Step 930 Global step 930 Train loss 0.002448 on epoch=232
05/31/2022 21:10:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.007080 on epoch=234
05/31/2022 21:10:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000289 on epoch=237
05/31/2022 21:10:09 - INFO - __main__ - Global step 950 Train loss 0.003103 Classification-F1 0.8697478991596639 on epoch=237
05/31/2022 21:10:14 - INFO - __main__ - Step 960 Global step 960 Train loss 0.002173 on epoch=239
05/31/2022 21:10:19 - INFO - __main__ - Step 970 Global step 970 Train loss 0.000119 on epoch=242
05/31/2022 21:10:25 - INFO - __main__ - Step 980 Global step 980 Train loss 0.012861 on epoch=244
05/31/2022 21:10:30 - INFO - __main__ - Step 990 Global step 990 Train loss 0.000070 on epoch=247
05/31/2022 21:10:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.000292 on epoch=249
05/31/2022 21:10:36 - INFO - __main__ - Global step 1000 Train loss 0.003103 Classification-F1 0.9354838709677419 on epoch=249
05/31/2022 21:10:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:10:36 - INFO - __main__ - Printing 3 examples
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:10:36 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:10:36 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:10:36 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:10:36 - INFO - __main__ - Printing 3 examples
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:10:36 - INFO - __main__ - ['false']
05/31/2022 21:10:36 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:10:36 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:10:36 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:10:37 - INFO - __main__ - save last model!
05/31/2022 21:10:44 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 21:10:44 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 21:10:44 - INFO - __main__ - Printing 3 examples
05/31/2022 21:10:44 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 21:10:44 - INFO - __main__ - ['false']
05/31/2022 21:10:44 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 21:10:44 - INFO - __main__ - ['false']
05/31/2022 21:10:44 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 21:10:44 - INFO - __main__ - ['true']
05/31/2022 21:10:44 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:10:45 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:10:45 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 21:10:46 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_87_0.0003_8_predictions.txt
05/31/2022 21:10:46 - INFO - __main__ - Classification-F1 on test data: 0.8651
05/31/2022 21:10:47 - INFO - __main__ - prefix=ethos-religion_32_87, lr=0.0003, bsz=8, dev_performance=0.9354838709677419, test_performance=0.8651162790697674
05/31/2022 21:10:47 - INFO - __main__ - Running ... prefix=ethos-religion_32_87, lr=0.0002, bsz=8 ...
05/31/2022 21:10:48 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:10:48 - INFO - __main__ - Printing 3 examples
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:10:48 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:10:48 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:10:48 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:10:48 - INFO - __main__ - Printing 3 examples
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:10:48 - INFO - __main__ - ['false']
05/31/2022 21:10:48 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:10:48 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:10:48 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:10:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:10:49 - INFO - __main__ - Starting training!
05/31/2022 21:10:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:10:58 - INFO - __main__ - Starting training!
05/31/2022 21:11:03 - INFO - __main__ - Step 10 Global step 10 Train loss 24.841425 on epoch=2
05/31/2022 21:11:08 - INFO - __main__ - Step 20 Global step 20 Train loss 21.405491 on epoch=4
05/31/2022 21:11:13 - INFO - __main__ - Step 30 Global step 30 Train loss 19.015730 on epoch=7
05/31/2022 21:11:18 - INFO - __main__ - Step 40 Global step 40 Train loss 18.084412 on epoch=9
05/31/2022 21:11:23 - INFO - __main__ - Step 50 Global step 50 Train loss 16.484983 on epoch=12
05/31/2022 21:11:42 - INFO - __main__ - Global step 50 Train loss 19.966408 Classification-F1 0.0 on epoch=12
05/31/2022 21:11:48 - INFO - __main__ - Step 60 Global step 60 Train loss 15.630295 on epoch=14
05/31/2022 21:11:53 - INFO - __main__ - Step 70 Global step 70 Train loss 15.529894 on epoch=17
05/31/2022 21:11:58 - INFO - __main__ - Step 80 Global step 80 Train loss 14.783154 on epoch=19
05/31/2022 21:12:03 - INFO - __main__ - Step 90 Global step 90 Train loss 13.807610 on epoch=22
05/31/2022 21:12:09 - INFO - __main__ - Step 100 Global step 100 Train loss 12.955248 on epoch=24
05/31/2022 21:12:23 - INFO - __main__ - Global step 100 Train loss 14.541239 Classification-F1 0.0 on epoch=24
05/31/2022 21:12:29 - INFO - __main__ - Step 110 Global step 110 Train loss 11.508274 on epoch=27
05/31/2022 21:12:34 - INFO - __main__ - Step 120 Global step 120 Train loss 10.260559 on epoch=29
05/31/2022 21:12:39 - INFO - __main__ - Step 130 Global step 130 Train loss 7.796305 on epoch=32
05/31/2022 21:12:44 - INFO - __main__ - Step 140 Global step 140 Train loss 4.599393 on epoch=34
05/31/2022 21:12:49 - INFO - __main__ - Step 150 Global step 150 Train loss 1.134284 on epoch=37
05/31/2022 21:12:50 - INFO - __main__ - Global step 150 Train loss 7.059763 Classification-F1 0.4837783519954062 on epoch=37
05/31/2022 21:12:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.890939 on epoch=39
05/31/2022 21:13:01 - INFO - __main__ - Step 170 Global step 170 Train loss 0.616922 on epoch=42
05/31/2022 21:13:06 - INFO - __main__ - Step 180 Global step 180 Train loss 2.007844 on epoch=44
05/31/2022 21:13:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.426020 on epoch=47
05/31/2022 21:13:17 - INFO - __main__ - Step 200 Global step 200 Train loss 1.490660 on epoch=49
05/31/2022 21:13:17 - INFO - __main__ - Global step 200 Train loss 1.286477 Classification-F1 0.456140350877193 on epoch=49
05/31/2022 21:13:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.582908 on epoch=52
05/31/2022 21:13:28 - INFO - __main__ - Step 220 Global step 220 Train loss 2.547521 on epoch=54
05/31/2022 21:13:33 - INFO - __main__ - Step 230 Global step 230 Train loss 2.040709 on epoch=57
05/31/2022 21:13:38 - INFO - __main__ - Step 240 Global step 240 Train loss 0.437779 on epoch=59
05/31/2022 21:13:43 - INFO - __main__ - Step 250 Global step 250 Train loss 0.462033 on epoch=62
05/31/2022 21:13:44 - INFO - __main__ - Global step 250 Train loss 1.214190 Classification-F1 0.4352042315603879 on epoch=62
05/31/2022 21:13:49 - INFO - __main__ - Step 260 Global step 260 Train loss 0.368415 on epoch=64
05/31/2022 21:13:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.409574 on epoch=67
05/31/2022 21:13:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.392290 on epoch=69
05/31/2022 21:14:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.417371 on epoch=72
05/31/2022 21:14:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.359315 on epoch=74
05/31/2022 21:14:10 - INFO - __main__ - Global step 300 Train loss 0.389393 Classification-F1 0.4626003210272873 on epoch=74
05/31/2022 21:14:16 - INFO - __main__ - Step 310 Global step 310 Train loss 0.404470 on epoch=77
05/31/2022 21:14:21 - INFO - __main__ - Step 320 Global step 320 Train loss 0.325023 on epoch=79
05/31/2022 21:14:26 - INFO - __main__ - Step 330 Global step 330 Train loss 0.333633 on epoch=82
05/31/2022 21:14:31 - INFO - __main__ - Step 340 Global step 340 Train loss 0.325174 on epoch=84
05/31/2022 21:14:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.310860 on epoch=87
05/31/2022 21:14:37 - INFO - __main__ - Global step 350 Train loss 0.339832 Classification-F1 0.6418067226890756 on epoch=87
05/31/2022 21:14:43 - INFO - __main__ - Step 360 Global step 360 Train loss 0.328961 on epoch=89
05/31/2022 21:14:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.314766 on epoch=92
05/31/2022 21:14:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.257523 on epoch=94
05/31/2022 21:14:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.361425 on epoch=97
05/31/2022 21:15:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.308813 on epoch=99
05/31/2022 21:15:04 - INFO - __main__ - Global step 400 Train loss 0.314298 Classification-F1 0.6539994685091682 on epoch=99
05/31/2022 21:15:10 - INFO - __main__ - Step 410 Global step 410 Train loss 0.273019 on epoch=102
05/31/2022 21:15:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.280863 on epoch=104
05/31/2022 21:15:20 - INFO - __main__ - Step 430 Global step 430 Train loss 0.281363 on epoch=107
05/31/2022 21:15:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.195649 on epoch=109
05/31/2022 21:15:31 - INFO - __main__ - Step 450 Global step 450 Train loss 0.219312 on epoch=112
05/31/2022 21:15:32 - INFO - __main__ - Global step 450 Train loss 0.250041 Classification-F1 0.7419354838709677 on epoch=112
05/31/2022 21:15:37 - INFO - __main__ - Step 460 Global step 460 Train loss 0.203864 on epoch=114
05/31/2022 21:15:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.151845 on epoch=117
05/31/2022 21:15:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.190360 on epoch=119
05/31/2022 21:15:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.129164 on epoch=122
05/31/2022 21:15:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.154862 on epoch=124
05/31/2022 21:15:59 - INFO - __main__ - Global step 500 Train loss 0.166019 Classification-F1 0.719904331650279 on epoch=124
05/31/2022 21:16:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.096297 on epoch=127
05/31/2022 21:16:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.115889 on epoch=129
05/31/2022 21:16:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.088589 on epoch=132
05/31/2022 21:16:20 - INFO - __main__ - Step 540 Global step 540 Train loss 0.121461 on epoch=134
05/31/2022 21:16:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.109044 on epoch=137
05/31/2022 21:16:25 - INFO - __main__ - Global step 550 Train loss 0.106256 Classification-F1 0.8056426332288402 on epoch=137
05/31/2022 21:16:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.093030 on epoch=139
05/31/2022 21:16:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.102681 on epoch=142
05/31/2022 21:16:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.054760 on epoch=144
05/31/2022 21:16:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.058766 on epoch=147
05/31/2022 21:16:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.075623 on epoch=149
05/31/2022 21:16:53 - INFO - __main__ - Global step 600 Train loss 0.076972 Classification-F1 0.8385416666666667 on epoch=149
05/31/2022 21:16:58 - INFO - __main__ - Step 610 Global step 610 Train loss 0.071310 on epoch=152
05/31/2022 21:17:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.084883 on epoch=154
05/31/2022 21:17:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.098980 on epoch=157
05/31/2022 21:17:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.053251 on epoch=159
05/31/2022 21:17:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.044724 on epoch=162
05/31/2022 21:17:20 - INFO - __main__ - Global step 650 Train loss 0.070629 Classification-F1 0.7580015612802498 on epoch=162
05/31/2022 21:17:25 - INFO - __main__ - Step 660 Global step 660 Train loss 0.159694 on epoch=164
05/31/2022 21:17:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.092911 on epoch=167
05/31/2022 21:17:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.065361 on epoch=169
05/31/2022 21:17:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.062835 on epoch=172
05/31/2022 21:17:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.059088 on epoch=174
05/31/2022 21:17:46 - INFO - __main__ - Global step 700 Train loss 0.087978 Classification-F1 0.8221642764015645 on epoch=174
05/31/2022 21:17:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.041431 on epoch=177
05/31/2022 21:17:56 - INFO - __main__ - Step 720 Global step 720 Train loss 0.038797 on epoch=179
05/31/2022 21:18:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.062319 on epoch=182
05/31/2022 21:18:06 - INFO - __main__ - Step 740 Global step 740 Train loss 0.025199 on epoch=184
05/31/2022 21:18:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.024031 on epoch=187
05/31/2022 21:18:12 - INFO - __main__ - Global step 750 Train loss 0.038355 Classification-F1 0.8064516129032259 on epoch=187
05/31/2022 21:18:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.008515 on epoch=189
05/31/2022 21:18:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.016696 on epoch=192
05/31/2022 21:18:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.008690 on epoch=194
05/31/2022 21:18:33 - INFO - __main__ - Step 790 Global step 790 Train loss 0.035388 on epoch=197
05/31/2022 21:18:38 - INFO - __main__ - Step 800 Global step 800 Train loss 0.055919 on epoch=199
05/31/2022 21:18:39 - INFO - __main__ - Global step 800 Train loss 0.025042 Classification-F1 0.5988748241912799 on epoch=199
05/31/2022 21:18:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.004706 on epoch=202
05/31/2022 21:18:49 - INFO - __main__ - Step 820 Global step 820 Train loss 0.020633 on epoch=204
05/31/2022 21:18:54 - INFO - __main__ - Step 830 Global step 830 Train loss 0.053747 on epoch=207
05/31/2022 21:18:59 - INFO - __main__ - Step 840 Global step 840 Train loss 0.003400 on epoch=209
05/31/2022 21:19:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.019698 on epoch=212
05/31/2022 21:19:05 - INFO - __main__ - Global step 850 Train loss 0.020437 Classification-F1 0.8062500000000001 on epoch=212
05/31/2022 21:19:10 - INFO - __main__ - Step 860 Global step 860 Train loss 0.019065 on epoch=214
05/31/2022 21:19:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.010261 on epoch=217
05/31/2022 21:19:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.003097 on epoch=219
05/31/2022 21:19:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.002147 on epoch=222
05/31/2022 21:19:31 - INFO - __main__ - Step 900 Global step 900 Train loss 0.016572 on epoch=224
05/31/2022 21:19:32 - INFO - __main__ - Global step 900 Train loss 0.010229 Classification-F1 0.7739583333333333 on epoch=224
05/31/2022 21:19:37 - INFO - __main__ - Step 910 Global step 910 Train loss 0.003005 on epoch=227
05/31/2022 21:19:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.015971 on epoch=229
05/31/2022 21:19:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.001894 on epoch=232
05/31/2022 21:19:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.000806 on epoch=234
05/31/2022 21:19:57 - INFO - __main__ - Step 950 Global step 950 Train loss 0.000407 on epoch=237
05/31/2022 21:19:58 - INFO - __main__ - Global step 950 Train loss 0.004417 Classification-F1 0.7902680197762166 on epoch=237
05/31/2022 21:20:03 - INFO - __main__ - Step 960 Global step 960 Train loss 0.002030 on epoch=239
05/31/2022 21:20:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.009976 on epoch=242
05/31/2022 21:20:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.000822 on epoch=244
05/31/2022 21:20:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.007206 on epoch=247
05/31/2022 21:20:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.002013 on epoch=249
05/31/2022 21:20:24 - INFO - __main__ - Global step 1000 Train loss 0.004409 Classification-F1 0.8548009367681498 on epoch=249
05/31/2022 21:20:25 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:20:25 - INFO - __main__ - Printing 3 examples
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:20:25 - INFO - __main__ - save last model!
05/31/2022 21:20:25 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:20:25 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:20:25 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:20:25 - INFO - __main__ - Printing 3 examples
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:20:25 - INFO - __main__ - ['false']
05/31/2022 21:20:25 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:20:25 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:20:25 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:20:32 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 21:20:33 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 21:20:33 - INFO - __main__ - Printing 3 examples
05/31/2022 21:20:33 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 21:20:33 - INFO - __main__ - ['false']
05/31/2022 21:20:33 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 21:20:33 - INFO - __main__ - ['false']
05/31/2022 21:20:33 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 21:20:33 - INFO - __main__ - ['true']
05/31/2022 21:20:33 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:20:33 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:20:33 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 21:20:34 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_87_0.0002_8_predictions.txt
05/31/2022 21:20:34 - INFO - __main__ - Classification-F1 on test data: 0.8522
05/31/2022 21:20:35 - INFO - __main__ - prefix=ethos-religion_32_87, lr=0.0002, bsz=8, dev_performance=0.8548009367681498, test_performance=0.8522418478260869
05/31/2022 21:20:35 - INFO - __main__ - Running ... prefix=ethos-religion_32_87, lr=0.0001, bsz=8 ...
05/31/2022 21:20:36 - INFO - __main__ - Start tokenizing ... 64 instances
05/31/2022 21:20:36 - INFO - __main__ - Printing 3 examples
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] Shemales are paranormal creatures. We shouldn't let them be free. Neither be captured. Just dead and buried already
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] Honestly, go fuck yourself! bitch!
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] After traumatic brain injury turned gay. I don't know which is worst. Suicide is the way.
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:20:36 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:20:36 - INFO - __main__ - Loaded 64 examples from train data
05/31/2022 21:20:36 - INFO - __main__ - Start tokenizing ... 62 instances
05/31/2022 21:20:36 - INFO - __main__ - Printing 3 examples
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] kneel down, white boy. its the era of brown people now
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] why does that african american monkey hold gun like that?
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ -  [ethos-religion] I honestly hate China. U can disagree but after This I cant. Its a horrible place and Its horrible people
05/31/2022 21:20:36 - INFO - __main__ - ['false']
05/31/2022 21:20:36 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:20:36 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:20:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:20:36 - INFO - __main__ - Starting training!
05/31/2022 21:20:36 - INFO - __main__ - Loaded 62 examples from dev data
05/31/2022 21:20:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.87M parameters
05/31/2022 21:20:49 - INFO - __main__ - Starting training!
05/31/2022 21:20:53 - INFO - __main__ - Step 10 Global step 10 Train loss 24.468849 on epoch=2
05/31/2022 21:20:58 - INFO - __main__ - Step 20 Global step 20 Train loss 21.058079 on epoch=4
05/31/2022 21:21:03 - INFO - __main__ - Step 30 Global step 30 Train loss 19.645290 on epoch=7
05/31/2022 21:21:08 - INFO - __main__ - Step 40 Global step 40 Train loss 19.011297 on epoch=9
05/31/2022 21:21:13 - INFO - __main__ - Step 50 Global step 50 Train loss 18.383167 on epoch=12
05/31/2022 21:21:33 - INFO - __main__ - Global step 50 Train loss 20.513338 Classification-F1 0.0 on epoch=12
05/31/2022 21:21:38 - INFO - __main__ - Step 60 Global step 60 Train loss 18.403698 on epoch=14
05/31/2022 21:21:43 - INFO - __main__ - Step 70 Global step 70 Train loss 16.496531 on epoch=17
05/31/2022 21:21:48 - INFO - __main__ - Step 80 Global step 80 Train loss 17.342342 on epoch=19
05/31/2022 21:21:53 - INFO - __main__ - Step 90 Global step 90 Train loss 15.981893 on epoch=22
05/31/2022 21:21:58 - INFO - __main__ - Step 100 Global step 100 Train loss 16.249111 on epoch=24
05/31/2022 21:22:18 - INFO - __main__ - Global step 100 Train loss 16.894712 Classification-F1 0.0 on epoch=24
05/31/2022 21:22:23 - INFO - __main__ - Step 110 Global step 110 Train loss 15.579714 on epoch=27
05/31/2022 21:22:28 - INFO - __main__ - Step 120 Global step 120 Train loss 15.348015 on epoch=29
05/31/2022 21:22:33 - INFO - __main__ - Step 130 Global step 130 Train loss 15.214192 on epoch=32
05/31/2022 21:22:38 - INFO - __main__ - Step 140 Global step 140 Train loss 14.888376 on epoch=34
05/31/2022 21:22:43 - INFO - __main__ - Step 150 Global step 150 Train loss 13.657430 on epoch=37
05/31/2022 21:23:02 - INFO - __main__ - Global step 150 Train loss 14.937545 Classification-F1 0.0 on epoch=37
05/31/2022 21:23:07 - INFO - __main__ - Step 160 Global step 160 Train loss 12.659199 on epoch=39
05/31/2022 21:23:12 - INFO - __main__ - Step 170 Global step 170 Train loss 13.701490 on epoch=42
05/31/2022 21:23:17 - INFO - __main__ - Step 180 Global step 180 Train loss 13.151950 on epoch=44
05/31/2022 21:23:22 - INFO - __main__ - Step 190 Global step 190 Train loss 12.290809 on epoch=47
05/31/2022 21:23:27 - INFO - __main__ - Step 200 Global step 200 Train loss 12.250410 on epoch=49
05/31/2022 21:23:45 - INFO - __main__ - Global step 200 Train loss 12.810773 Classification-F1 0.0 on epoch=49
05/31/2022 21:23:50 - INFO - __main__ - Step 210 Global step 210 Train loss 11.308943 on epoch=52
05/31/2022 21:23:55 - INFO - __main__ - Step 220 Global step 220 Train loss 10.298296 on epoch=54
05/31/2022 21:24:00 - INFO - __main__ - Step 230 Global step 230 Train loss 9.318377 on epoch=57
05/31/2022 21:24:05 - INFO - __main__ - Step 240 Global step 240 Train loss 8.086848 on epoch=59
05/31/2022 21:24:10 - INFO - __main__ - Step 250 Global step 250 Train loss 5.803343 on epoch=62
05/31/2022 21:24:11 - INFO - __main__ - Global step 250 Train loss 8.963161 Classification-F1 0.21455938697318008 on epoch=62
05/31/2022 21:24:17 - INFO - __main__ - Step 260 Global step 260 Train loss 4.416801 on epoch=64
05/31/2022 21:24:22 - INFO - __main__ - Step 270 Global step 270 Train loss 4.711381 on epoch=67
05/31/2022 21:24:27 - INFO - __main__ - Step 280 Global step 280 Train loss 3.350301 on epoch=69
05/31/2022 21:24:32 - INFO - __main__ - Step 290 Global step 290 Train loss 3.755590 on epoch=72
05/31/2022 21:24:37 - INFO - __main__ - Step 300 Global step 300 Train loss 3.600800 on epoch=74
05/31/2022 21:24:38 - INFO - __main__ - Global step 300 Train loss 3.966975 Classification-F1 0.3404255319148936 on epoch=74
05/31/2022 21:24:44 - INFO - __main__ - Step 310 Global step 310 Train loss 3.234331 on epoch=77
05/31/2022 21:24:49 - INFO - __main__ - Step 320 Global step 320 Train loss 2.883899 on epoch=79
05/31/2022 21:24:54 - INFO - __main__ - Step 330 Global step 330 Train loss 3.666342 on epoch=82
05/31/2022 21:24:59 - INFO - __main__ - Step 340 Global step 340 Train loss 3.460740 on epoch=84
05/31/2022 21:25:04 - INFO - __main__ - Step 350 Global step 350 Train loss 3.245553 on epoch=87
05/31/2022 21:25:06 - INFO - __main__ - Global step 350 Train loss 3.298173 Classification-F1 0.33333333333333337 on epoch=87
05/31/2022 21:25:11 - INFO - __main__ - Step 360 Global step 360 Train loss 2.873415 on epoch=89
05/31/2022 21:25:16 - INFO - __main__ - Step 370 Global step 370 Train loss 2.435755 on epoch=92
05/31/2022 21:25:22 - INFO - __main__ - Step 380 Global step 380 Train loss 3.120994 on epoch=94
05/31/2022 21:25:27 - INFO - __main__ - Step 390 Global step 390 Train loss 3.063859 on epoch=97
05/31/2022 21:25:32 - INFO - __main__ - Step 400 Global step 400 Train loss 2.456054 on epoch=99
05/31/2022 21:25:33 - INFO - __main__ - Global step 400 Train loss 2.790015 Classification-F1 0.3404255319148936 on epoch=99
05/31/2022 21:25:38 - INFO - __main__ - Step 410 Global step 410 Train loss 3.565369 on epoch=102
05/31/2022 21:25:43 - INFO - __main__ - Step 420 Global step 420 Train loss 3.048483 on epoch=104
05/31/2022 21:25:48 - INFO - __main__ - Step 430 Global step 430 Train loss 2.580195 on epoch=107
05/31/2022 21:25:53 - INFO - __main__ - Step 440 Global step 440 Train loss 2.983047 on epoch=109
05/31/2022 21:25:58 - INFO - __main__ - Step 450 Global step 450 Train loss 2.572793 on epoch=112
05/31/2022 21:25:59 - INFO - __main__ - Global step 450 Train loss 2.949978 Classification-F1 0.5161649944258639 on epoch=112
05/31/2022 21:26:05 - INFO - __main__ - Step 460 Global step 460 Train loss 2.109979 on epoch=114
05/31/2022 21:26:10 - INFO - __main__ - Step 470 Global step 470 Train loss 2.228022 on epoch=117
05/31/2022 21:26:15 - INFO - __main__ - Step 480 Global step 480 Train loss 2.534510 on epoch=119
05/31/2022 21:26:20 - INFO - __main__ - Step 490 Global step 490 Train loss 2.168305 on epoch=122
05/31/2022 21:26:25 - INFO - __main__ - Step 500 Global step 500 Train loss 1.666679 on epoch=124
05/31/2022 21:26:26 - INFO - __main__ - Global step 500 Train loss 2.141499 Classification-F1 0.430844553243574 on epoch=124
05/31/2022 21:26:31 - INFO - __main__ - Step 510 Global step 510 Train loss 2.403563 on epoch=127
05/31/2022 21:26:36 - INFO - __main__ - Step 520 Global step 520 Train loss 2.526812 on epoch=129
05/31/2022 21:26:41 - INFO - __main__ - Step 530 Global step 530 Train loss 1.916723 on epoch=132
05/31/2022 21:26:46 - INFO - __main__ - Step 540 Global step 540 Train loss 2.096818 on epoch=134
05/31/2022 21:26:51 - INFO - __main__ - Step 550 Global step 550 Train loss 1.982666 on epoch=137
05/31/2022 21:26:52 - INFO - __main__ - Global step 550 Train loss 2.185316 Classification-F1 0.5068181818181818 on epoch=137
05/31/2022 21:26:57 - INFO - __main__ - Step 560 Global step 560 Train loss 2.134809 on epoch=139
05/31/2022 21:27:02 - INFO - __main__ - Step 570 Global step 570 Train loss 1.937275 on epoch=142
05/31/2022 21:27:08 - INFO - __main__ - Step 580 Global step 580 Train loss 1.764579 on epoch=144
05/31/2022 21:27:13 - INFO - __main__ - Step 590 Global step 590 Train loss 1.703912 on epoch=147
05/31/2022 21:27:18 - INFO - __main__ - Step 600 Global step 600 Train loss 2.062638 on epoch=149
05/31/2022 21:27:19 - INFO - __main__ - Global step 600 Train loss 1.920642 Classification-F1 0.6648648648648648 on epoch=149
05/31/2022 21:27:24 - INFO - __main__ - Step 610 Global step 610 Train loss 2.038771 on epoch=152
05/31/2022 21:27:29 - INFO - __main__ - Step 620 Global step 620 Train loss 1.744509 on epoch=154
05/31/2022 21:27:34 - INFO - __main__ - Step 630 Global step 630 Train loss 1.790614 on epoch=157
05/31/2022 21:27:40 - INFO - __main__ - Step 640 Global step 640 Train loss 2.089751 on epoch=159
05/31/2022 21:27:45 - INFO - __main__ - Step 650 Global step 650 Train loss 1.444975 on epoch=162
05/31/2022 21:27:46 - INFO - __main__ - Global step 650 Train loss 1.821724 Classification-F1 0.5324283559577678 on epoch=162
05/31/2022 21:27:51 - INFO - __main__ - Step 660 Global step 660 Train loss 1.517063 on epoch=164
05/31/2022 21:27:56 - INFO - __main__ - Step 670 Global step 670 Train loss 1.603377 on epoch=167
05/31/2022 21:28:01 - INFO - __main__ - Step 680 Global step 680 Train loss 1.813121 on epoch=169
05/31/2022 21:28:06 - INFO - __main__ - Step 690 Global step 690 Train loss 1.798499 on epoch=172
05/31/2022 21:28:11 - INFO - __main__ - Step 700 Global step 700 Train loss 1.267654 on epoch=174
05/31/2022 21:28:12 - INFO - __main__ - Global step 700 Train loss 1.599942 Classification-F1 0.4878306878306879 on epoch=174
05/31/2022 21:28:17 - INFO - __main__ - Step 710 Global step 710 Train loss 1.164410 on epoch=177
05/31/2022 21:28:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.770382 on epoch=179
05/31/2022 21:28:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.649678 on epoch=182
05/31/2022 21:28:32 - INFO - __main__ - Step 740 Global step 740 Train loss 0.400478 on epoch=184
05/31/2022 21:28:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.426048 on epoch=187
05/31/2022 21:28:38 - INFO - __main__ - Global step 750 Train loss 0.682199 Classification-F1 0.8202898550724638 on epoch=187
05/31/2022 21:28:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.338000 on epoch=189
05/31/2022 21:28:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.179175 on epoch=192
05/31/2022 21:28:54 - INFO - __main__ - Step 780 Global step 780 Train loss 0.272787 on epoch=194
05/31/2022 21:28:59 - INFO - __main__ - Step 790 Global step 790 Train loss 0.237643 on epoch=197
05/31/2022 21:29:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.317445 on epoch=199
05/31/2022 21:29:05 - INFO - __main__ - Global step 800 Train loss 0.269010 Classification-F1 0.8708333333333332 on epoch=199
05/31/2022 21:29:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.236784 on epoch=202
05/31/2022 21:29:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.235779 on epoch=204
05/31/2022 21:29:21 - INFO - __main__ - Step 830 Global step 830 Train loss 0.146095 on epoch=207
05/31/2022 21:29:26 - INFO - __main__ - Step 840 Global step 840 Train loss 0.175058 on epoch=209
05/31/2022 21:29:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.119064 on epoch=212
05/31/2022 21:29:32 - INFO - __main__ - Global step 850 Train loss 0.182556 Classification-F1 0.886831812255541 on epoch=212
05/31/2022 21:29:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.104862 on epoch=214
05/31/2022 21:29:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.134438 on epoch=217
05/31/2022 21:29:48 - INFO - __main__ - Step 880 Global step 880 Train loss 0.154499 on epoch=219
05/31/2022 21:29:53 - INFO - __main__ - Step 890 Global step 890 Train loss 0.105850 on epoch=222
05/31/2022 21:29:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.093986 on epoch=224
05/31/2022 21:29:59 - INFO - __main__ - Global step 900 Train loss 0.118727 Classification-F1 0.870967741935484 on epoch=224
05/31/2022 21:30:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.109648 on epoch=227
05/31/2022 21:30:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.096081 on epoch=229
05/31/2022 21:30:15 - INFO - __main__ - Step 930 Global step 930 Train loss 0.088095 on epoch=232
05/31/2022 21:30:20 - INFO - __main__ - Step 940 Global step 940 Train loss 0.202097 on epoch=234
05/31/2022 21:30:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.193725 on epoch=237
05/31/2022 21:30:26 - INFO - __main__ - Global step 950 Train loss 0.137929 Classification-F1 0.8708333333333332 on epoch=237
05/31/2022 21:30:31 - INFO - __main__ - Step 960 Global step 960 Train loss 0.148673 on epoch=239
05/31/2022 21:30:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.053048 on epoch=242
05/31/2022 21:30:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.102215 on epoch=244
05/31/2022 21:30:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.100266 on epoch=247
05/31/2022 21:30:51 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.086386 on epoch=249
05/31/2022 21:30:52 - INFO - __main__ - Global step 1000 Train loss 0.098118 Classification-F1 0.8371848739495799 on epoch=249
05/31/2022 21:30:52 - INFO - __main__ - save last model!
05/31/2022 21:30:59 - INFO - __main__ - Loading checkpoint on the fly
05/31/2022 21:31:00 - INFO - __main__ - Start tokenizing ... 87 instances
05/31/2022 21:31:00 - INFO - __main__ - Printing 3 examples
05/31/2022 21:31:00 - INFO - __main__ -  [ethos-religion] Hopefully the non-white parasites will flee to a new host nation. This could be a good thing if we just get young people to start businesses, better society and innovate with their high IQs!
05/31/2022 21:31:00 - INFO - __main__ - ['false']
05/31/2022 21:31:00 - INFO - __main__ -  [ethos-religion] Looks like the gay poster boy with syphilis
05/31/2022 21:31:00 - INFO - __main__ - ['false']
05/31/2022 21:31:00 - INFO - __main__ -  [ethos-religion] Jewish piece of shits like him should get hanged
05/31/2022 21:31:00 - INFO - __main__ - ['true']
05/31/2022 21:31:00 - INFO - __main__ - Tokenizing Input ...
05/31/2022 21:31:00 - INFO - __main__ - Tokenizing Output ...
05/31/2022 21:31:00 - INFO - __main__ - Loaded 87 examples from test data
05/31/2022 21:31:02 - INFO - __main__ - Saved prediction in models/T5-large-ft-cls2cls-down32shot/singletask-ethos-religion/ethos-religion_32_87_0.0001_8_predictions.txt
05/31/2022 21:31:02 - INFO - __main__ - Classification-F1 on test data: 0.8227
05/31/2022 21:31:02 - INFO - __main__ - prefix=ethos-religion_32_87, lr=0.0001, bsz=8, dev_performance=0.886831812255541, test_performance=0.8226902173913044
