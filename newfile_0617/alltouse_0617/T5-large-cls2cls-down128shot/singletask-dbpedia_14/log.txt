05/25/2022 23:36:06 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/25/2022 23:36:06 - INFO - __main__ - models/T5-large-cls2cls-down128shot/singletask-dbpedia_14
05/25/2022 23:36:06 - INFO - __main__ - Namespace(task_dir='data_128/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-cls2cls-down128shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-cls2cls-down128shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='None', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='6,7')
05/25/2022 23:36:06 - INFO - __main__ - models/T5-large-cls2cls-down128shot/singletask-dbpedia_14
05/25/2022 23:36:08 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/25/2022 23:36:08 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/25/2022 23:36:08 - INFO - __main__ - args.device: cuda:1
05/25/2022 23:36:08 - INFO - __main__ - Using 2 gpus
05/25/2022 23:36:08 - INFO - __main__ - args.device: cuda:0
05/25/2022 23:36:08 - INFO - __main__ - Using 2 gpus
05/25/2022 23:36:08 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/25/2022 23:36:08 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_128_100', 'dbpedia_14_128_13', 'dbpedia_14_128_21', 'dbpedia_14_128_42', 'dbpedia_14_128_87']
05/25/2022 23:36:12 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.5, bsz=8 ...
05/25/2022 23:36:13 - INFO - __main__ - Start tokenizing ... 1792 instances
05/25/2022 23:36:13 - INFO - __main__ - Printing 3 examples
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 23:36:13 - INFO - __main__ - Start tokenizing ... 1792 instances
05/25/2022 23:36:13 - INFO - __main__ - Printing 3 examples
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/25/2022 23:36:13 - INFO - __main__ - ['Animal']
05/25/2022 23:36:13 - INFO - __main__ - Tokenizing Input ...
05/25/2022 23:36:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 23:36:14 - INFO - __main__ - Tokenizing Output ...
05/25/2022 23:36:16 - INFO - __main__ - Loaded 1792 examples from train data
05/25/2022 23:36:16 - INFO - __main__ - Loaded 1792 examples from train data
05/25/2022 23:36:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/25/2022 23:36:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/25/2022 23:36:16 - INFO - __main__ - Printing 3 examples
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ - Printing 3 examples
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/25/2022 23:36:16 - INFO - __main__ - ['Animal']
05/25/2022 23:36:16 - INFO - __main__ - Tokenizing Input ...
05/25/2022 23:36:16 - INFO - __main__ - Tokenizing Input ...
05/25/2022 23:36:17 - INFO - __main__ - Tokenizing Output ...
05/25/2022 23:36:17 - INFO - __main__ - Tokenizing Output ...
05/25/2022 23:36:19 - INFO - __main__ - Loaded 1792 examples from dev data
05/25/2022 23:36:19 - INFO - __main__ - Loaded 1792 examples from dev data
05/25/2022 23:36:36 - INFO - __main__ - try to initialize prompt embeddings
05/25/2022 23:36:36 - INFO - __main__ - task name: dbpedia_14
05/25/2022 23:36:37 - INFO - __main__ - try to initialize prompt embeddings
05/25/2022 23:36:37 - INFO - __main__ - task name: dbpedia_14
05/25/2022 23:36:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 23:36:37 - INFO - __main__ - Starting training!
05/25/2022 23:36:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/25/2022 23:36:37 - INFO - __main__ - Starting training!
05/25/2022 23:36:41 - INFO - __main__ - Step 10 Global step 10 Train loss 7.02 on epoch=0
05/25/2022 23:36:44 - INFO - __main__ - Step 20 Global step 20 Train loss 4.97 on epoch=0
05/25/2022 23:36:46 - INFO - __main__ - Step 30 Global step 30 Train loss 3.33 on epoch=0
05/25/2022 23:36:49 - INFO - __main__ - Step 40 Global step 40 Train loss 2.34 on epoch=0
05/25/2022 23:36:51 - INFO - __main__ - Step 50 Global step 50 Train loss 1.83 on epoch=0
05/25/2022 23:37:36 - INFO - __main__ - Global step 50 Train loss 3.90 Classification-F1 0.20872451334273512 on epoch=0
05/25/2022 23:37:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20872451334273512 on epoch=0, global_step=50
05/25/2022 23:37:39 - INFO - __main__ - Step 60 Global step 60 Train loss 1.36 on epoch=0
05/25/2022 23:37:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.28 on epoch=0
05/25/2022 23:37:44 - INFO - __main__ - Step 80 Global step 80 Train loss 1.09 on epoch=0
05/25/2022 23:37:46 - INFO - __main__ - Step 90 Global step 90 Train loss 1.06 on epoch=0
05/25/2022 23:37:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.95 on epoch=0
05/25/2022 23:38:54 - INFO - __main__ - Global step 100 Train loss 1.15 Classification-F1 0.26281821599863264 on epoch=0
05/25/2022 23:38:54 - INFO - __main__ - Saving model with best Classification-F1: 0.20872451334273512 -> 0.26281821599863264 on epoch=0, global_step=100
05/25/2022 23:38:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=0
05/25/2022 23:38:59 - INFO - __main__ - Step 120 Global step 120 Train loss 0.79 on epoch=1
05/25/2022 23:39:02 - INFO - __main__ - Step 130 Global step 130 Train loss 0.73 on epoch=1
05/25/2022 23:39:05 - INFO - __main__ - Step 140 Global step 140 Train loss 0.73 on epoch=1
05/25/2022 23:39:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=1
05/25/2022 23:40:03 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.33425550050261027 on epoch=1
05/25/2022 23:40:03 - INFO - __main__ - Saving model with best Classification-F1: 0.26281821599863264 -> 0.33425550050261027 on epoch=1, global_step=150
05/25/2022 23:40:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=1
05/25/2022 23:40:09 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=1
05/25/2022 23:40:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=1
05/25/2022 23:40:14 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=1
05/25/2022 23:40:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=1
05/25/2022 23:41:14 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.46625028822908027 on epoch=1
05/25/2022 23:41:14 - INFO - __main__ - Saving model with best Classification-F1: 0.33425550050261027 -> 0.46625028822908027 on epoch=1, global_step=200
05/25/2022 23:41:17 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=1
05/25/2022 23:41:19 - INFO - __main__ - Step 220 Global step 220 Train loss 0.57 on epoch=1
05/25/2022 23:41:22 - INFO - __main__ - Step 230 Global step 230 Train loss 0.46 on epoch=2
05/25/2022 23:41:25 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=2
05/25/2022 23:41:27 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=2
05/25/2022 23:42:21 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.5237696641080889 on epoch=2
05/25/2022 23:42:21 - INFO - __main__ - Saving model with best Classification-F1: 0.46625028822908027 -> 0.5237696641080889 on epoch=2, global_step=250
05/25/2022 23:42:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=2
05/25/2022 23:42:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=2
05/25/2022 23:42:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=2
05/25/2022 23:42:31 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=2
05/25/2022 23:42:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=2
05/25/2022 23:43:35 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.6603169016961662 on epoch=2
05/25/2022 23:43:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5237696641080889 -> 0.6603169016961662 on epoch=2, global_step=300
05/25/2022 23:43:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=2
05/25/2022 23:43:40 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=2
05/25/2022 23:43:43 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=2
05/25/2022 23:43:45 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=3
05/25/2022 23:43:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=3
05/25/2022 23:44:45 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.6502201504944806 on epoch=3
05/25/2022 23:44:48 - INFO - __main__ - Step 360 Global step 360 Train loss 0.51 on epoch=3
05/25/2022 23:44:51 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=3
05/25/2022 23:44:53 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=3
05/25/2022 23:44:56 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=3
05/25/2022 23:44:59 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=3
05/25/2022 23:45:46 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.2843468680724121 on epoch=3
05/25/2022 23:45:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=3
05/25/2022 23:45:52 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=3
05/25/2022 23:45:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=3
05/25/2022 23:45:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.27 on epoch=3
05/25/2022 23:46:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.38 on epoch=4
05/25/2022 23:46:50 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.3779900463467601 on epoch=4
05/25/2022 23:46:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=4
05/25/2022 23:46:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=4
05/25/2022 23:46:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=4
05/25/2022 23:47:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=4
05/25/2022 23:47:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=4
05/25/2022 23:48:01 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.3840423750481755 on epoch=4
05/25/2022 23:48:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=4
05/25/2022 23:48:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=4
05/25/2022 23:48:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=4
05/25/2022 23:48:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.31 on epoch=4
05/25/2022 23:48:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=4
05/25/2022 23:49:06 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.4463019205172853 on epoch=4
05/25/2022 23:49:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.25 on epoch=4
05/25/2022 23:49:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
05/25/2022 23:49:14 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=5
05/25/2022 23:49:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=5
05/25/2022 23:49:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=5
05/25/2022 23:50:11 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.34200381015121034 on epoch=5
05/25/2022 23:50:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.23 on epoch=5
05/25/2022 23:50:16 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=5
05/25/2022 23:50:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=5
05/25/2022 23:50:21 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=5
05/25/2022 23:50:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=5
05/25/2022 23:51:15 - INFO - __main__ - Global step 650 Train loss 0.23 Classification-F1 0.5630042123866807 on epoch=5
05/25/2022 23:51:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=5
05/25/2022 23:51:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
05/25/2022 23:51:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=6
05/25/2022 23:51:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=6
05/25/2022 23:51:28 - INFO - __main__ - Step 700 Global step 700 Train loss 0.25 on epoch=6
05/25/2022 23:52:19 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.3981572247579327 on epoch=6
05/25/2022 23:52:22 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=6
05/25/2022 23:52:25 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=6
05/25/2022 23:52:27 - INFO - __main__ - Step 730 Global step 730 Train loss 0.14 on epoch=6
05/25/2022 23:52:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=6
05/25/2022 23:52:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
05/25/2022 23:53:24 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.36980255466507617 on epoch=6
05/25/2022 23:53:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=6
05/25/2022 23:53:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=6
05/25/2022 23:53:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=6
05/25/2022 23:53:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=7
05/25/2022 23:53:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
05/25/2022 23:54:29 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.5667136739361399 on epoch=7
05/25/2022 23:54:32 - INFO - __main__ - Step 810 Global step 810 Train loss 0.24 on epoch=7
05/25/2022 23:54:35 - INFO - __main__ - Step 820 Global step 820 Train loss 0.13 on epoch=7
05/25/2022 23:54:37 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=7
05/25/2022 23:54:40 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=7
05/25/2022 23:54:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=7
05/25/2022 23:55:32 - INFO - __main__ - Global step 850 Train loss 0.16 Classification-F1 0.47074728191333776 on epoch=7
05/25/2022 23:55:35 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=7
05/25/2022 23:55:38 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=7
05/25/2022 23:55:40 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=7
05/25/2022 23:55:43 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
05/25/2022 23:55:46 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
05/25/2022 23:56:34 - INFO - __main__ - Global step 900 Train loss 0.15 Classification-F1 0.48232086422061793 on epoch=8
05/25/2022 23:56:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
05/25/2022 23:56:39 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=8
05/25/2022 23:56:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=8
05/25/2022 23:56:44 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
05/25/2022 23:56:47 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=8
05/25/2022 23:57:35 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.4194976251208646 on epoch=8
05/25/2022 23:57:38 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
05/25/2022 23:57:40 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
05/25/2022 23:57:43 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=8
05/25/2022 23:57:46 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=8
05/25/2022 23:57:49 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=8
05/25/2022 23:58:39 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5386128914012368 on epoch=8
05/25/2022 23:58:42 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=9
05/25/2022 23:58:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=9
05/25/2022 23:58:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=9
05/25/2022 23:58:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=9
05/25/2022 23:58:53 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=9
05/25/2022 23:59:42 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.5083250475984253 on epoch=9
05/25/2022 23:59:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.04 on epoch=9
05/25/2022 23:59:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.09 on epoch=9
05/25/2022 23:59:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=9
05/25/2022 23:59:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/25/2022 23:59:56 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
05/26/2022 00:00:45 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.5887896030862376 on epoch=9
05/26/2022 00:00:48 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=9
05/26/2022 00:00:50 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=9
05/26/2022 00:00:53 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
05/26/2022 00:00:56 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/26/2022 00:00:58 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
05/26/2022 00:01:47 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.45805582513291837 on epoch=10
05/26/2022 00:01:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.09 on epoch=10
05/26/2022 00:01:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
05/26/2022 00:01:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
05/26/2022 00:01:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=10
05/26/2022 00:02:00 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/26/2022 00:02:48 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.48798726489227956 on epoch=10
05/26/2022 00:02:51 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=10
05/26/2022 00:02:54 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=10
05/26/2022 00:02:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/26/2022 00:02:59 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=11
05/26/2022 00:03:02 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
05/26/2022 00:03:51 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.5940851273207285 on epoch=11
05/26/2022 00:03:54 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/26/2022 00:03:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=11
05/26/2022 00:03:59 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
05/26/2022 00:04:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
05/26/2022 00:04:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
05/26/2022 00:04:52 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5779673332225786 on epoch=11
05/26/2022 00:04:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 00:04:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/26/2022 00:05:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.19 on epoch=11
05/26/2022 00:05:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=11
05/26/2022 00:05:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
05/26/2022 00:05:53 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.5119654020312882 on epoch=12
05/26/2022 00:05:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=12
05/26/2022 00:05:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/26/2022 00:06:01 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
05/26/2022 00:06:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=12
05/26/2022 00:06:06 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
05/26/2022 00:06:54 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6752023619516506 on epoch=12
05/26/2022 00:06:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6603169016961662 -> 0.6752023619516506 on epoch=12, global_step=1400
05/26/2022 00:06:57 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
05/26/2022 00:07:00 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=12
05/26/2022 00:07:02 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=12
05/26/2022 00:07:05 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=12
05/26/2022 00:07:08 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=12
05/26/2022 00:07:54 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.5027175463977449 on epoch=12
05/26/2022 00:07:57 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
05/26/2022 00:07:59 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=13
05/26/2022 00:08:02 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=13
05/26/2022 00:08:05 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/26/2022 00:08:07 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
05/26/2022 00:08:54 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6578260742029427 on epoch=13
05/26/2022 00:08:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
05/26/2022 00:08:59 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=13
05/26/2022 00:09:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=13
05/26/2022 00:09:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=13
05/26/2022 00:09:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=13
05/26/2022 00:09:54 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5129751370458172 on epoch=13
05/26/2022 00:09:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/26/2022 00:10:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/26/2022 00:10:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
05/26/2022 00:10:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/26/2022 00:10:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
05/26/2022 00:10:55 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.616712433590585 on epoch=14
05/26/2022 00:10:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/26/2022 00:11:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=14
05/26/2022 00:11:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=14
05/26/2022 00:11:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/26/2022 00:11:08 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
05/26/2022 00:11:54 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.46004733743450194 on epoch=14
05/26/2022 00:11:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=14
05/26/2022 00:12:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=14
05/26/2022 00:12:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=14
05/26/2022 00:12:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/26/2022 00:12:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=15
05/26/2022 00:12:54 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5654173716680839 on epoch=15
05/26/2022 00:12:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=15
05/26/2022 00:12:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
05/26/2022 00:13:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/26/2022 00:13:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/26/2022 00:13:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
05/26/2022 00:13:55 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.6162996737868343 on epoch=15
05/26/2022 00:13:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/26/2022 00:14:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
05/26/2022 00:14:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=15
05/26/2022 00:14:06 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
05/26/2022 00:14:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=16
05/26/2022 00:14:54 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.4715753127398215 on epoch=16
05/26/2022 00:14:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
05/26/2022 00:14:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=16
05/26/2022 00:15:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=16
05/26/2022 00:15:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/26/2022 00:15:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/26/2022 00:15:53 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5893337067032012 on epoch=16
05/26/2022 00:15:56 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
05/26/2022 00:15:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=16
05/26/2022 00:16:01 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=16
05/26/2022 00:16:04 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/26/2022 00:16:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/26/2022 00:16:52 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.4560138755657996 on epoch=16
05/26/2022 00:16:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
05/26/2022 00:16:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
05/26/2022 00:17:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.12 on epoch=17
05/26/2022 00:17:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/26/2022 00:17:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=17
05/26/2022 00:17:52 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6272760629138459 on epoch=17
05/26/2022 00:17:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/26/2022 00:17:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
05/26/2022 00:18:00 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
05/26/2022 00:18:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=17
05/26/2022 00:18:05 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=17
05/26/2022 00:18:53 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.47971534744469724 on epoch=17
05/26/2022 00:18:56 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/26/2022 00:18:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/26/2022 00:19:01 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.07 on epoch=18
05/26/2022 00:19:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=18
05/26/2022 00:19:06 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
05/26/2022 00:19:53 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.5281377837038123 on epoch=18
05/26/2022 00:19:55 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/26/2022 00:19:58 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 00:20:00 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
05/26/2022 00:20:03 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 00:20:06 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/26/2022 00:20:54 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.4726488245385565 on epoch=18
05/26/2022 00:20:56 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=18
05/26/2022 00:20:59 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
05/26/2022 00:21:02 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
05/26/2022 00:21:04 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=19
05/26/2022 00:21:07 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=19
05/26/2022 00:21:54 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.6152722839395092 on epoch=19
05/26/2022 00:21:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
05/26/2022 00:21:59 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 00:22:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 00:22:04 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
05/26/2022 00:22:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/26/2022 00:22:54 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8567796453024539 on epoch=19
05/26/2022 00:22:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6752023619516506 -> 0.8567796453024539 on epoch=19, global_step=2200
05/26/2022 00:22:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 00:23:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/26/2022 00:23:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/26/2022 00:23:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/26/2022 00:23:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/26/2022 00:23:53 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7836509569945114 on epoch=20
05/26/2022 00:23:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=20
05/26/2022 00:23:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=20
05/26/2022 00:24:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
05/26/2022 00:24:04 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=20
05/26/2022 00:24:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
05/26/2022 00:24:52 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7078232197591957 on epoch=20
05/26/2022 00:24:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=20
05/26/2022 00:24:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/26/2022 00:25:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=20
05/26/2022 00:25:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=20
05/26/2022 00:25:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
05/26/2022 00:25:51 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6690237877682915 on epoch=20
05/26/2022 00:25:53 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=21
05/26/2022 00:25:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=21
05/26/2022 00:25:58 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=21
05/26/2022 00:26:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 00:26:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/26/2022 00:26:49 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.5776772814415014 on epoch=21
05/26/2022 00:26:52 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=21
05/26/2022 00:26:54 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/26/2022 00:26:57 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
05/26/2022 00:26:59 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
05/26/2022 00:27:02 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=21
05/26/2022 00:27:46 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.6291172397622085 on epoch=21
05/26/2022 00:27:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=21
05/26/2022 00:27:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/26/2022 00:27:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/26/2022 00:27:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
05/26/2022 00:27:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
05/26/2022 00:28:45 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7608286048630098 on epoch=22
05/26/2022 00:28:47 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
05/26/2022 00:28:50 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=22
05/26/2022 00:28:53 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/26/2022 00:28:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/26/2022 00:28:58 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/26/2022 00:29:44 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.6862024425480409 on epoch=22
05/26/2022 00:29:47 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/26/2022 00:29:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/26/2022 00:29:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
05/26/2022 00:29:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
05/26/2022 00:29:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/26/2022 00:30:42 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.5220545154622539 on epoch=23
05/26/2022 00:30:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/26/2022 00:30:47 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 00:30:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
05/26/2022 00:30:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 00:30:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=23
05/26/2022 00:31:43 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.653399041748367 on epoch=23
05/26/2022 00:31:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/26/2022 00:31:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=23
05/26/2022 00:31:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=23
05/26/2022 00:31:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
05/26/2022 00:31:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=24
05/26/2022 00:32:42 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6338959292937053 on epoch=24
05/26/2022 00:32:44 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=24
05/26/2022 00:32:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
05/26/2022 00:32:49 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/26/2022 00:32:52 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=24
05/26/2022 00:32:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
05/26/2022 00:33:42 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6344273356699917 on epoch=24
05/26/2022 00:33:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/26/2022 00:33:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/26/2022 00:33:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/26/2022 00:33:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=24
05/26/2022 00:33:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 00:34:41 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.6400304726024133 on epoch=24
05/26/2022 00:34:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/26/2022 00:34:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/26/2022 00:34:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.08 on epoch=25
05/26/2022 00:34:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
05/26/2022 00:34:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
05/26/2022 00:35:41 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.676433122556269 on epoch=25
05/26/2022 00:35:43 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/26/2022 00:35:46 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=25
05/26/2022 00:35:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/26/2022 00:35:51 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.12 on epoch=25
05/26/2022 00:35:54 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
05/26/2022 00:36:41 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.6831944460153534 on epoch=25
05/26/2022 00:36:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/26/2022 00:36:46 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/26/2022 00:36:49 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 00:36:51 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
05/26/2022 00:36:54 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/26/2022 00:37:40 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8588584434323967 on epoch=26
05/26/2022 00:37:40 - INFO - __main__ - Saving model with best Classification-F1: 0.8567796453024539 -> 0.8588584434323967 on epoch=26, global_step=2950
05/26/2022 00:37:43 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
05/26/2022 00:37:46 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 00:37:48 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
05/26/2022 00:37:51 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/26/2022 00:37:54 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/26/2022 00:37:55 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 00:37:55 - INFO - __main__ - Printing 3 examples
05/26/2022 00:37:55 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 00:37:55 - INFO - __main__ - ['Animal']
05/26/2022 00:37:55 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 00:37:55 - INFO - __main__ - ['Animal']
05/26/2022 00:37:55 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 00:37:55 - INFO - __main__ - ['Animal']
05/26/2022 00:37:55 - INFO - __main__ - Tokenizing Input ...
05/26/2022 00:37:56 - INFO - __main__ - Tokenizing Output ...
05/26/2022 00:37:58 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 00:37:58 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 00:37:58 - INFO - __main__ - Printing 3 examples
05/26/2022 00:37:58 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 00:37:58 - INFO - __main__ - ['Animal']
05/26/2022 00:37:58 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 00:37:58 - INFO - __main__ - ['Animal']
05/26/2022 00:37:58 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 00:37:58 - INFO - __main__ - ['Animal']
05/26/2022 00:37:58 - INFO - __main__ - Tokenizing Input ...
05/26/2022 00:37:58 - INFO - __main__ - Tokenizing Output ...
05/26/2022 00:38:00 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 00:38:16 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 00:38:16 - INFO - __main__ - task name: dbpedia_14
05/26/2022 00:38:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 00:38:17 - INFO - __main__ - Starting training!
05/26/2022 00:38:40 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.858469359077962 on epoch=26
05/26/2022 00:38:40 - INFO - __main__ - save last model!
05/26/2022 00:38:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 00:38:40 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 00:38:40 - INFO - __main__ - Printing 3 examples
05/26/2022 00:38:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 00:38:40 - INFO - __main__ - ['Animal']
05/26/2022 00:38:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 00:38:40 - INFO - __main__ - ['Animal']
05/26/2022 00:38:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 00:38:40 - INFO - __main__ - ['Village']
05/26/2022 00:38:40 - INFO - __main__ - Tokenizing Input ...
05/26/2022 00:38:42 - INFO - __main__ - Tokenizing Output ...
05/26/2022 00:38:46 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 00:40:50 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.5_8_predictions.txt
05/26/2022 00:40:51 - INFO - __main__ - Classification-F1 on test data: 0.6205
05/26/2022 00:40:51 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.5, bsz=8, dev_performance=0.8588584434323967, test_performance=0.6204637078910555
05/26/2022 00:40:51 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.4, bsz=8 ...
05/26/2022 00:40:52 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 00:40:52 - INFO - __main__ - Printing 3 examples
05/26/2022 00:40:52 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 00:40:52 - INFO - __main__ - ['Animal']
05/26/2022 00:40:52 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 00:40:52 - INFO - __main__ - ['Animal']
05/26/2022 00:40:52 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 00:40:52 - INFO - __main__ - ['Animal']
05/26/2022 00:40:52 - INFO - __main__ - Tokenizing Input ...
05/26/2022 00:40:53 - INFO - __main__ - Tokenizing Output ...
05/26/2022 00:40:55 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 00:40:55 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 00:40:55 - INFO - __main__ - Printing 3 examples
05/26/2022 00:40:55 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 00:40:55 - INFO - __main__ - ['Animal']
05/26/2022 00:40:55 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 00:40:55 - INFO - __main__ - ['Animal']
05/26/2022 00:40:55 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 00:40:55 - INFO - __main__ - ['Animal']
05/26/2022 00:40:55 - INFO - __main__ - Tokenizing Input ...
05/26/2022 00:40:56 - INFO - __main__ - Tokenizing Output ...
05/26/2022 00:40:57 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 00:41:13 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 00:41:13 - INFO - __main__ - task name: dbpedia_14
05/26/2022 00:41:14 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 00:41:14 - INFO - __main__ - Starting training!
05/26/2022 00:41:17 - INFO - __main__ - Step 10 Global step 10 Train loss 6.93 on epoch=0
05/26/2022 00:41:20 - INFO - __main__ - Step 20 Global step 20 Train loss 5.37 on epoch=0
05/26/2022 00:41:23 - INFO - __main__ - Step 30 Global step 30 Train loss 3.78 on epoch=0
05/26/2022 00:41:25 - INFO - __main__ - Step 40 Global step 40 Train loss 2.71 on epoch=0
05/26/2022 00:41:28 - INFO - __main__ - Step 50 Global step 50 Train loss 2.08 on epoch=0
05/26/2022 00:43:20 - INFO - __main__ - Global step 50 Train loss 4.17 Classification-F1 0.05968455848907972 on epoch=0
05/26/2022 00:43:20 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.05968455848907972 on epoch=0, global_step=50
05/26/2022 00:43:23 - INFO - __main__ - Step 60 Global step 60 Train loss 1.77 on epoch=0
05/26/2022 00:43:26 - INFO - __main__ - Step 70 Global step 70 Train loss 1.39 on epoch=0
05/26/2022 00:43:28 - INFO - __main__ - Step 80 Global step 80 Train loss 1.19 on epoch=0
05/26/2022 00:43:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.17 on epoch=0
05/26/2022 00:43:33 - INFO - __main__ - Step 100 Global step 100 Train loss 1.05 on epoch=0
05/26/2022 00:44:34 - INFO - __main__ - Global step 100 Train loss 1.31 Classification-F1 0.27899102420453825 on epoch=0
05/26/2022 00:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.05968455848907972 -> 0.27899102420453825 on epoch=0, global_step=100
05/26/2022 00:44:37 - INFO - __main__ - Step 110 Global step 110 Train loss 1.03 on epoch=0
05/26/2022 00:44:40 - INFO - __main__ - Step 120 Global step 120 Train loss 0.83 on epoch=1
05/26/2022 00:44:42 - INFO - __main__ - Step 130 Global step 130 Train loss 0.99 on epoch=1
05/26/2022 00:44:45 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=1
05/26/2022 00:44:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=1
05/26/2022 00:45:49 - INFO - __main__ - Global step 150 Train loss 0.89 Classification-F1 0.364233828271464 on epoch=1
05/26/2022 00:45:49 - INFO - __main__ - Saving model with best Classification-F1: 0.27899102420453825 -> 0.364233828271464 on epoch=1, global_step=150
05/26/2022 00:45:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=1
05/26/2022 00:45:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=1
05/26/2022 00:45:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.84 on epoch=1
05/26/2022 00:46:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.76 on epoch=1
05/26/2022 00:46:03 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=1
05/26/2022 00:46:57 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.4023574960872988 on epoch=1
05/26/2022 00:46:57 - INFO - __main__ - Saving model with best Classification-F1: 0.364233828271464 -> 0.4023574960872988 on epoch=1, global_step=200
05/26/2022 00:46:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.72 on epoch=1
05/26/2022 00:47:02 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=1
05/26/2022 00:47:05 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=2
05/26/2022 00:47:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=2
05/26/2022 00:47:10 - INFO - __main__ - Step 250 Global step 250 Train loss 0.56 on epoch=2
05/26/2022 00:48:11 - INFO - __main__ - Global step 250 Train loss 0.60 Classification-F1 0.35815966197236865 on epoch=2
05/26/2022 00:48:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=2
05/26/2022 00:48:16 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=2
05/26/2022 00:48:19 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=2
05/26/2022 00:48:21 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=2
05/26/2022 00:48:24 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=2
05/26/2022 00:49:25 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.47417065230746225 on epoch=2
05/26/2022 00:49:25 - INFO - __main__ - Saving model with best Classification-F1: 0.4023574960872988 -> 0.47417065230746225 on epoch=2, global_step=300
05/26/2022 00:49:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=2
05/26/2022 00:49:31 - INFO - __main__ - Step 320 Global step 320 Train loss 0.49 on epoch=2
05/26/2022 00:49:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=2
05/26/2022 00:49:36 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=3
05/26/2022 00:49:39 - INFO - __main__ - Step 350 Global step 350 Train loss 0.43 on epoch=3
05/26/2022 00:50:30 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.39914748458776905 on epoch=3
05/26/2022 00:50:33 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=3
05/26/2022 00:50:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=3
05/26/2022 00:50:38 - INFO - __main__ - Step 380 Global step 380 Train loss 0.33 on epoch=3
05/26/2022 00:50:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.43 on epoch=3
05/26/2022 00:50:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.41 on epoch=3
05/26/2022 00:51:36 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.48930056035404923 on epoch=3
05/26/2022 00:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.47417065230746225 -> 0.48930056035404923 on epoch=3, global_step=400
05/26/2022 00:51:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=3
05/26/2022 00:51:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=3
05/26/2022 00:51:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=3
05/26/2022 00:51:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=3
05/26/2022 00:51:49 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=4
05/26/2022 00:52:44 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.5474110338462956 on epoch=4
05/26/2022 00:52:44 - INFO - __main__ - Saving model with best Classification-F1: 0.48930056035404923 -> 0.5474110338462956 on epoch=4, global_step=450
05/26/2022 00:52:46 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=4
05/26/2022 00:52:49 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=4
05/26/2022 00:52:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=4
05/26/2022 00:52:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=4
05/26/2022 00:52:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.34 on epoch=4
05/26/2022 00:53:57 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.49250760935927557 on epoch=4
05/26/2022 00:54:00 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=4
05/26/2022 00:54:03 - INFO - __main__ - Step 520 Global step 520 Train loss 0.36 on epoch=4
05/26/2022 00:54:05 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=4
05/26/2022 00:54:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.20 on epoch=4
05/26/2022 00:54:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=4
05/26/2022 00:55:03 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6112811366784919 on epoch=4
05/26/2022 00:55:03 - INFO - __main__ - Saving model with best Classification-F1: 0.5474110338462956 -> 0.6112811366784919 on epoch=4, global_step=550
05/26/2022 00:55:06 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=4
05/26/2022 00:55:09 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=5
05/26/2022 00:55:11 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=5
05/26/2022 00:55:14 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=5
05/26/2022 00:55:17 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=5
05/26/2022 00:56:11 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.299825516995475 on epoch=5
05/26/2022 00:56:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.21 on epoch=5
05/26/2022 00:56:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=5
05/26/2022 00:56:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=5
05/26/2022 00:56:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=5
05/26/2022 00:56:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=5
05/26/2022 00:57:20 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.4611498908098013 on epoch=5
05/26/2022 00:57:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=5
05/26/2022 00:57:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
05/26/2022 00:57:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=6
05/26/2022 00:57:31 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=6
05/26/2022 00:57:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=6
05/26/2022 00:58:29 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.5266487294669466 on epoch=6
05/26/2022 00:58:32 - INFO - __main__ - Step 710 Global step 710 Train loss 0.10 on epoch=6
05/26/2022 00:58:35 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=6
05/26/2022 00:58:37 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=6
05/26/2022 00:58:40 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=6
05/26/2022 00:58:43 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=6
05/26/2022 00:59:37 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.40831254485144813 on epoch=6
05/26/2022 00:59:40 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=6
05/26/2022 00:59:42 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=6
05/26/2022 00:59:45 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/26/2022 00:59:47 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=7
05/26/2022 00:59:50 - INFO - __main__ - Step 800 Global step 800 Train loss 0.07 on epoch=7
05/26/2022 01:00:41 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.42751682926371964 on epoch=7
05/26/2022 01:00:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=7
05/26/2022 01:00:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=7
05/26/2022 01:00:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=7
05/26/2022 01:00:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=7
05/26/2022 01:00:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=7
05/26/2022 01:01:43 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.3756893432459251 on epoch=7
05/26/2022 01:01:46 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=7
05/26/2022 01:01:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=7
05/26/2022 01:01:51 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=7
05/26/2022 01:01:54 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
05/26/2022 01:01:56 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=8
05/26/2022 01:02:48 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.37930100922338567 on epoch=8
05/26/2022 01:02:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
05/26/2022 01:02:53 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=8
05/26/2022 01:02:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=8
05/26/2022 01:02:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
05/26/2022 01:03:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=8
05/26/2022 01:03:57 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.5517518880597307 on epoch=8
05/26/2022 01:03:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=8
05/26/2022 01:04:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=8
05/26/2022 01:04:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
05/26/2022 01:04:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=8
05/26/2022 01:04:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=8
05/26/2022 01:05:01 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5216416564596505 on epoch=8
05/26/2022 01:05:04 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=9
05/26/2022 01:05:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=9
05/26/2022 01:05:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=9
05/26/2022 01:05:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=9
05/26/2022 01:05:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=9
05/26/2022 01:06:06 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5447221084829837 on epoch=9
05/26/2022 01:06:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=9
05/26/2022 01:06:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=9
05/26/2022 01:06:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=9
05/26/2022 01:06:17 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=9
05/26/2022 01:06:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=9
05/26/2022 01:07:07 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.5131192530921173 on epoch=9
05/26/2022 01:07:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=9
05/26/2022 01:07:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=9
05/26/2022 01:07:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/26/2022 01:07:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/26/2022 01:07:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=10
05/26/2022 01:08:09 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.4555740861438464 on epoch=10
05/26/2022 01:08:11 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
05/26/2022 01:08:14 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
05/26/2022 01:08:16 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=10
05/26/2022 01:08:19 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
05/26/2022 01:08:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/26/2022 01:09:14 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.650485583761896 on epoch=10
05/26/2022 01:09:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6112811366784919 -> 0.650485583761896 on epoch=10, global_step=1200
05/26/2022 01:09:17 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
05/26/2022 01:09:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=10
05/26/2022 01:09:22 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
05/26/2022 01:09:25 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=11
05/26/2022 01:09:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
05/26/2022 01:10:22 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.5524556717508977 on epoch=11
05/26/2022 01:10:25 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=11
05/26/2022 01:10:27 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/26/2022 01:10:30 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
05/26/2022 01:10:33 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
05/26/2022 01:10:35 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=11
05/26/2022 01:11:28 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.44450412655414534 on epoch=11
05/26/2022 01:11:30 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 01:11:33 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=11
05/26/2022 01:11:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=11
05/26/2022 01:11:38 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
05/26/2022 01:11:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=12
05/26/2022 01:12:34 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.55463247950785 on epoch=12
05/26/2022 01:12:36 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=12
05/26/2022 01:12:39 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/26/2022 01:12:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.03 on epoch=12
05/26/2022 01:12:44 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=12
05/26/2022 01:12:47 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
05/26/2022 01:13:38 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6314562943783982 on epoch=12
05/26/2022 01:13:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
05/26/2022 01:13:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=12
05/26/2022 01:13:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=12
05/26/2022 01:13:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=12
05/26/2022 01:13:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
05/26/2022 01:14:40 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.5375597634442031 on epoch=12
05/26/2022 01:14:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=13
05/26/2022 01:14:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=13
05/26/2022 01:14:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
05/26/2022 01:14:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/26/2022 01:14:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
05/26/2022 01:15:43 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.5840387331438064 on epoch=13
05/26/2022 01:15:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=13
05/26/2022 01:15:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
05/26/2022 01:15:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=13
05/26/2022 01:15:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/26/2022 01:15:57 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=13
05/26/2022 01:16:48 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.4782565233420529 on epoch=13
05/26/2022 01:16:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=13
05/26/2022 01:16:54 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/26/2022 01:16:56 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=14
05/26/2022 01:16:59 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/26/2022 01:17:01 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
05/26/2022 01:17:53 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.5066224481661856 on epoch=14
05/26/2022 01:17:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
05/26/2022 01:17:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
05/26/2022 01:18:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/26/2022 01:18:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/26/2022 01:18:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/26/2022 01:18:59 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5325953883172143 on epoch=14
05/26/2022 01:19:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=14
05/26/2022 01:19:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/26/2022 01:19:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=14
05/26/2022 01:19:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=15
05/26/2022 01:19:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/26/2022 01:20:03 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6495070791980689 on epoch=15
05/26/2022 01:20:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=15
05/26/2022 01:20:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
05/26/2022 01:20:11 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=15
05/26/2022 01:20:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/26/2022 01:20:16 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=15
05/26/2022 01:21:04 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5776000515487343 on epoch=15
05/26/2022 01:21:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/26/2022 01:21:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
05/26/2022 01:21:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=15
05/26/2022 01:21:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=15
05/26/2022 01:21:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/26/2022 01:22:06 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.529101513193079 on epoch=16
05/26/2022 01:22:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=16
05/26/2022 01:22:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=16
05/26/2022 01:22:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
05/26/2022 01:22:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/26/2022 01:22:19 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/26/2022 01:23:04 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.42224636082456957 on epoch=16
05/26/2022 01:23:07 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=16
05/26/2022 01:23:09 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
05/26/2022 01:23:12 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
05/26/2022 01:23:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=16
05/26/2022 01:23:17 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=16
05/26/2022 01:24:04 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.440316784002618 on epoch=16
05/26/2022 01:24:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
05/26/2022 01:24:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=17
05/26/2022 01:24:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
05/26/2022 01:24:15 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=17
05/26/2022 01:24:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
05/26/2022 01:25:07 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.5519531078644551 on epoch=17
05/26/2022 01:25:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/26/2022 01:25:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
05/26/2022 01:25:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/26/2022 01:25:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/26/2022 01:25:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=17
05/26/2022 01:26:06 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.4182223616471835 on epoch=17
05/26/2022 01:26:09 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
05/26/2022 01:26:11 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
05/26/2022 01:26:14 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/26/2022 01:26:17 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
05/26/2022 01:26:19 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=18
05/26/2022 01:27:07 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.4144339641983527 on epoch=18
05/26/2022 01:27:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=18
05/26/2022 01:27:12 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=18
05/26/2022 01:27:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
05/26/2022 01:27:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=18
05/26/2022 01:27:20 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 01:28:08 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.5736870591858844 on epoch=18
05/26/2022 01:28:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=18
05/26/2022 01:28:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=18
05/26/2022 01:28:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/26/2022 01:28:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=19
05/26/2022 01:28:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=19
05/26/2022 01:29:05 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.5776243174627028 on epoch=19
05/26/2022 01:29:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
05/26/2022 01:29:10 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/26/2022 01:29:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 01:29:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
05/26/2022 01:29:18 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/26/2022 01:30:06 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.5529821883964531 on epoch=19
05/26/2022 01:30:08 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 01:30:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/26/2022 01:30:14 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
05/26/2022 01:30:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
05/26/2022 01:30:19 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/26/2022 01:31:07 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.5049756938566217 on epoch=20
05/26/2022 01:31:10 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
05/26/2022 01:31:12 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
05/26/2022 01:31:15 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/26/2022 01:31:17 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=20
05/26/2022 01:31:20 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/26/2022 01:32:09 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.47076353898237006 on epoch=20
05/26/2022 01:32:11 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/26/2022 01:32:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 01:32:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=20
05/26/2022 01:32:19 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/26/2022 01:32:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
05/26/2022 01:33:06 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.568580514001799 on epoch=20
05/26/2022 01:33:08 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/26/2022 01:33:11 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=21
05/26/2022 01:33:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/26/2022 01:33:16 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 01:33:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
05/26/2022 01:34:02 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.4629023809950724 on epoch=21
05/26/2022 01:34:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
05/26/2022 01:34:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/26/2022 01:34:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/26/2022 01:34:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
05/26/2022 01:34:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=21
05/26/2022 01:34:59 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.46795705197685683 on epoch=21
05/26/2022 01:35:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=21
05/26/2022 01:35:05 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
05/26/2022 01:35:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/26/2022 01:35:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
05/26/2022 01:35:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/26/2022 01:35:58 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6216315320441462 on epoch=22
05/26/2022 01:36:01 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
05/26/2022 01:36:04 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/26/2022 01:36:06 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/26/2022 01:36:09 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.09 on epoch=22
05/26/2022 01:36:12 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=22
05/26/2022 01:36:59 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.52915764394277 on epoch=22
05/26/2022 01:37:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.08 on epoch=22
05/26/2022 01:37:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=22
05/26/2022 01:37:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/26/2022 01:37:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/26/2022 01:37:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/26/2022 01:38:01 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.5508758846095683 on epoch=23
05/26/2022 01:38:03 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/26/2022 01:38:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 01:38:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
05/26/2022 01:38:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.10 on epoch=23
05/26/2022 01:38:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/26/2022 01:39:04 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.45789624200994844 on epoch=23
05/26/2022 01:39:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/26/2022 01:39:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
05/26/2022 01:39:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/26/2022 01:39:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
05/26/2022 01:39:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/26/2022 01:40:06 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.5187637274449698 on epoch=24
05/26/2022 01:40:08 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=24
05/26/2022 01:40:11 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
05/26/2022 01:40:13 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/26/2022 01:40:16 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/26/2022 01:40:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
05/26/2022 01:41:06 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5516365100917257 on epoch=24
05/26/2022 01:41:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 01:41:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/26/2022 01:41:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=24
05/26/2022 01:41:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/26/2022 01:41:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
05/26/2022 01:42:06 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.48207248312472745 on epoch=24
05/26/2022 01:42:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/26/2022 01:42:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
05/26/2022 01:42:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
05/26/2022 01:42:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/26/2022 01:42:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=25
05/26/2022 01:43:04 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.4450197901688089 on epoch=25
05/26/2022 01:43:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=25
05/26/2022 01:43:10 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=25
05/26/2022 01:43:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/26/2022 01:43:15 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
05/26/2022 01:43:18 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
05/26/2022 01:44:03 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.4857027381856865 on epoch=25
05/26/2022 01:44:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/26/2022 01:44:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=26
05/26/2022 01:44:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=26
05/26/2022 01:44:14 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=26
05/26/2022 01:44:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/26/2022 01:45:00 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.47332622187191875 on epoch=26
05/26/2022 01:45:03 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
05/26/2022 01:45:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
05/26/2022 01:45:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
05/26/2022 01:45:11 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/26/2022 01:45:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
05/26/2022 01:45:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 01:45:15 - INFO - __main__ - Printing 3 examples
05/26/2022 01:45:15 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 01:45:15 - INFO - __main__ - ['Animal']
05/26/2022 01:45:15 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 01:45:15 - INFO - __main__ - ['Animal']
05/26/2022 01:45:15 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 01:45:15 - INFO - __main__ - ['Animal']
05/26/2022 01:45:15 - INFO - __main__ - Tokenizing Input ...
05/26/2022 01:45:15 - INFO - __main__ - Tokenizing Output ...
05/26/2022 01:45:17 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 01:45:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 01:45:17 - INFO - __main__ - Printing 3 examples
05/26/2022 01:45:17 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 01:45:17 - INFO - __main__ - ['Animal']
05/26/2022 01:45:17 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 01:45:17 - INFO - __main__ - ['Animal']
05/26/2022 01:45:17 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 01:45:17 - INFO - __main__ - ['Animal']
05/26/2022 01:45:17 - INFO - __main__ - Tokenizing Input ...
05/26/2022 01:45:18 - INFO - __main__ - Tokenizing Output ...
05/26/2022 01:45:20 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 01:45:38 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 01:45:38 - INFO - __main__ - task name: dbpedia_14
05/26/2022 01:45:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 01:45:39 - INFO - __main__ - Starting training!
05/26/2022 01:46:02 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5404002656115181 on epoch=26
05/26/2022 01:46:02 - INFO - __main__ - save last model!
05/26/2022 01:46:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 01:46:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 01:46:02 - INFO - __main__ - Printing 3 examples
05/26/2022 01:46:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 01:46:02 - INFO - __main__ - ['Animal']
05/26/2022 01:46:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 01:46:02 - INFO - __main__ - ['Animal']
05/26/2022 01:46:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 01:46:02 - INFO - __main__ - ['Village']
05/26/2022 01:46:02 - INFO - __main__ - Tokenizing Input ...
05/26/2022 01:46:04 - INFO - __main__ - Tokenizing Output ...
05/26/2022 01:46:07 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 01:47:58 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.4_8_predictions.txt
05/26/2022 01:47:58 - INFO - __main__ - Classification-F1 on test data: 0.4400
05/26/2022 01:47:59 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.4, bsz=8, dev_performance=0.650485583761896, test_performance=0.440026882702648
05/26/2022 01:47:59 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.3, bsz=8 ...
05/26/2022 01:47:59 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 01:47:59 - INFO - __main__ - Printing 3 examples
05/26/2022 01:47:59 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 01:47:59 - INFO - __main__ - ['Animal']
05/26/2022 01:47:59 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 01:47:59 - INFO - __main__ - ['Animal']
05/26/2022 01:47:59 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 01:47:59 - INFO - __main__ - ['Animal']
05/26/2022 01:47:59 - INFO - __main__ - Tokenizing Input ...
05/26/2022 01:48:00 - INFO - __main__ - Tokenizing Output ...
05/26/2022 01:48:02 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 01:48:02 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 01:48:02 - INFO - __main__ - Printing 3 examples
05/26/2022 01:48:02 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 01:48:02 - INFO - __main__ - ['Animal']
05/26/2022 01:48:02 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 01:48:02 - INFO - __main__ - ['Animal']
05/26/2022 01:48:02 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 01:48:02 - INFO - __main__ - ['Animal']
05/26/2022 01:48:02 - INFO - __main__ - Tokenizing Input ...
05/26/2022 01:48:03 - INFO - __main__ - Tokenizing Output ...
05/26/2022 01:48:05 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 01:48:20 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 01:48:20 - INFO - __main__ - task name: dbpedia_14
05/26/2022 01:48:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 01:48:21 - INFO - __main__ - Starting training!
05/26/2022 01:48:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.23 on epoch=0
05/26/2022 01:48:27 - INFO - __main__ - Step 20 Global step 20 Train loss 5.92 on epoch=0
05/26/2022 01:48:29 - INFO - __main__ - Step 30 Global step 30 Train loss 4.52 on epoch=0
05/26/2022 01:48:32 - INFO - __main__ - Step 40 Global step 40 Train loss 3.41 on epoch=0
05/26/2022 01:48:34 - INFO - __main__ - Step 50 Global step 50 Train loss 2.69 on epoch=0
05/26/2022 01:51:08 - INFO - __main__ - Global step 50 Train loss 4.76 Classification-F1 0.019341125087306576 on epoch=0
05/26/2022 01:51:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.019341125087306576 on epoch=0, global_step=50
05/26/2022 01:51:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.15 on epoch=0
05/26/2022 01:51:13 - INFO - __main__ - Step 70 Global step 70 Train loss 1.88 on epoch=0
05/26/2022 01:51:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.63 on epoch=0
05/26/2022 01:51:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.44 on epoch=0
05/26/2022 01:51:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.21 on epoch=0
05/26/2022 01:52:20 - INFO - __main__ - Global step 100 Train loss 1.66 Classification-F1 0.22765600092632177 on epoch=0
05/26/2022 01:52:20 - INFO - __main__ - Saving model with best Classification-F1: 0.019341125087306576 -> 0.22765600092632177 on epoch=0, global_step=100
05/26/2022 01:52:22 - INFO - __main__ - Step 110 Global step 110 Train loss 1.08 on epoch=0
05/26/2022 01:52:25 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=1
05/26/2022 01:52:27 - INFO - __main__ - Step 130 Global step 130 Train loss 1.05 on epoch=1
05/26/2022 01:52:30 - INFO - __main__ - Step 140 Global step 140 Train loss 1.02 on epoch=1
05/26/2022 01:52:33 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=1
05/26/2022 01:53:31 - INFO - __main__ - Global step 150 Train loss 1.01 Classification-F1 0.30545254322886756 on epoch=1
05/26/2022 01:53:31 - INFO - __main__ - Saving model with best Classification-F1: 0.22765600092632177 -> 0.30545254322886756 on epoch=1, global_step=150
05/26/2022 01:53:34 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=1
05/26/2022 01:53:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.80 on epoch=1
05/26/2022 01:53:39 - INFO - __main__ - Step 180 Global step 180 Train loss 0.86 on epoch=1
05/26/2022 01:53:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=1
05/26/2022 01:53:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.80 on epoch=1
05/26/2022 01:54:42 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.36506598468027046 on epoch=1
05/26/2022 01:54:42 - INFO - __main__ - Saving model with best Classification-F1: 0.30545254322886756 -> 0.36506598468027046 on epoch=1, global_step=200
05/26/2022 01:54:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=1
05/26/2022 01:54:47 - INFO - __main__ - Step 220 Global step 220 Train loss 0.75 on epoch=1
05/26/2022 01:54:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.66 on epoch=2
05/26/2022 01:54:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=2
05/26/2022 01:54:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.66 on epoch=2
05/26/2022 01:55:51 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.4366427839539839 on epoch=2
05/26/2022 01:55:51 - INFO - __main__ - Saving model with best Classification-F1: 0.36506598468027046 -> 0.4366427839539839 on epoch=2, global_step=250
05/26/2022 01:55:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.59 on epoch=2
05/26/2022 01:55:56 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=2
05/26/2022 01:55:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.59 on epoch=2
05/26/2022 01:56:01 - INFO - __main__ - Step 290 Global step 290 Train loss 0.66 on epoch=2
05/26/2022 01:56:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.56 on epoch=2
05/26/2022 01:57:00 - INFO - __main__ - Global step 300 Train loss 0.59 Classification-F1 0.4380388721085929 on epoch=2
05/26/2022 01:57:00 - INFO - __main__ - Saving model with best Classification-F1: 0.4366427839539839 -> 0.4380388721085929 on epoch=2, global_step=300
05/26/2022 01:57:03 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=2
05/26/2022 01:57:05 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=2
05/26/2022 01:57:08 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=2
05/26/2022 01:57:11 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/26/2022 01:57:13 - INFO - __main__ - Step 350 Global step 350 Train loss 0.51 on epoch=3
05/26/2022 01:58:08 - INFO - __main__ - Global step 350 Train loss 0.56 Classification-F1 0.4517231559613089 on epoch=3
05/26/2022 01:58:08 - INFO - __main__ - Saving model with best Classification-F1: 0.4380388721085929 -> 0.4517231559613089 on epoch=3, global_step=350
05/26/2022 01:58:11 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=3
05/26/2022 01:58:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=3
05/26/2022 01:58:16 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=3
05/26/2022 01:58:19 - INFO - __main__ - Step 390 Global step 390 Train loss 0.61 on epoch=3
05/26/2022 01:58:21 - INFO - __main__ - Step 400 Global step 400 Train loss 0.57 on epoch=3
05/26/2022 01:59:15 - INFO - __main__ - Global step 400 Train loss 0.52 Classification-F1 0.46155382241259296 on epoch=3
05/26/2022 01:59:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4517231559613089 -> 0.46155382241259296 on epoch=3, global_step=400
05/26/2022 01:59:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=3
05/26/2022 01:59:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=3
05/26/2022 01:59:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.54 on epoch=3
05/26/2022 01:59:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=3
05/26/2022 01:59:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.50 on epoch=4
05/26/2022 02:00:22 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.517241823347539 on epoch=4
05/26/2022 02:00:22 - INFO - __main__ - Saving model with best Classification-F1: 0.46155382241259296 -> 0.517241823347539 on epoch=4, global_step=450
05/26/2022 02:00:25 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=4
05/26/2022 02:00:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=4
05/26/2022 02:00:30 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=4
05/26/2022 02:00:33 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=4
05/26/2022 02:00:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=4
05/26/2022 02:01:28 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.3899133643025251 on epoch=4
05/26/2022 02:01:31 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=4
05/26/2022 02:01:34 - INFO - __main__ - Step 520 Global step 520 Train loss 0.41 on epoch=4
05/26/2022 02:01:36 - INFO - __main__ - Step 530 Global step 530 Train loss 0.30 on epoch=4
05/26/2022 02:01:39 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=4
05/26/2022 02:01:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=4
05/26/2022 02:02:36 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.49529228490107735 on epoch=4
05/26/2022 02:02:39 - INFO - __main__ - Step 560 Global step 560 Train loss 0.34 on epoch=4
05/26/2022 02:02:41 - INFO - __main__ - Step 570 Global step 570 Train loss 0.37 on epoch=5
05/26/2022 02:02:44 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=5
05/26/2022 02:02:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.35 on epoch=5
05/26/2022 02:02:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.32 on epoch=5
05/26/2022 02:03:44 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.38080885918395285 on epoch=5
05/26/2022 02:03:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=5
05/26/2022 02:03:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=5
05/26/2022 02:03:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=5
05/26/2022 02:03:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=5
05/26/2022 02:03:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.30 on epoch=5
05/26/2022 02:04:52 - INFO - __main__ - Global step 650 Train loss 0.33 Classification-F1 0.43909728112419727 on epoch=5
05/26/2022 02:04:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.42 on epoch=5
05/26/2022 02:04:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=5
05/26/2022 02:05:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=6
05/26/2022 02:05:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.24 on epoch=6
05/26/2022 02:05:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=6
05/26/2022 02:06:01 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.5780701850474649 on epoch=6
05/26/2022 02:06:01 - INFO - __main__ - Saving model with best Classification-F1: 0.517241823347539 -> 0.5780701850474649 on epoch=6, global_step=700
05/26/2022 02:06:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=6
05/26/2022 02:06:06 - INFO - __main__ - Step 720 Global step 720 Train loss 0.34 on epoch=6
05/26/2022 02:06:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=6
05/26/2022 02:06:11 - INFO - __main__ - Step 740 Global step 740 Train loss 0.37 on epoch=6
05/26/2022 02:06:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=6
05/26/2022 02:07:09 - INFO - __main__ - Global step 750 Train loss 0.30 Classification-F1 0.4093246869245652 on epoch=6
05/26/2022 02:07:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=6
05/26/2022 02:07:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.27 on epoch=6
05/26/2022 02:07:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.28 on epoch=6
05/26/2022 02:07:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=7
05/26/2022 02:07:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.21 on epoch=7
05/26/2022 02:08:14 - INFO - __main__ - Global step 800 Train loss 0.23 Classification-F1 0.5084749830151309 on epoch=7
05/26/2022 02:08:16 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=7
05/26/2022 02:08:19 - INFO - __main__ - Step 820 Global step 820 Train loss 0.28 on epoch=7
05/26/2022 02:08:22 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=7
05/26/2022 02:08:24 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=7
05/26/2022 02:08:27 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=7
05/26/2022 02:09:28 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.6806502716216508 on epoch=7
05/26/2022 02:09:28 - INFO - __main__ - Saving model with best Classification-F1: 0.5780701850474649 -> 0.6806502716216508 on epoch=7, global_step=850
05/26/2022 02:09:30 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=7
05/26/2022 02:09:33 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=7
05/26/2022 02:09:36 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=7
05/26/2022 02:09:38 - INFO - __main__ - Step 890 Global step 890 Train loss 0.20 on epoch=7
05/26/2022 02:09:41 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=8
05/26/2022 02:10:52 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.4190626138148092 on epoch=8
05/26/2022 02:10:54 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=8
05/26/2022 02:10:57 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=8
05/26/2022 02:11:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.22 on epoch=8
05/26/2022 02:11:02 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=8
05/26/2022 02:11:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=8
05/26/2022 02:12:03 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.5052283294675469 on epoch=8
05/26/2022 02:12:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
05/26/2022 02:12:09 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=8
05/26/2022 02:12:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=8
05/26/2022 02:12:14 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=8
05/26/2022 02:12:17 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.20 on epoch=8
05/26/2022 02:13:16 - INFO - __main__ - Global step 1000 Train loss 0.19 Classification-F1 0.5077450679391252 on epoch=8
05/26/2022 02:13:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=9
05/26/2022 02:13:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=9
05/26/2022 02:13:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=9
05/26/2022 02:13:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=9
05/26/2022 02:13:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.16 on epoch=9
05/26/2022 02:14:22 - INFO - __main__ - Global step 1050 Train loss 0.17 Classification-F1 0.5125917130932357 on epoch=9
05/26/2022 02:14:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=9
05/26/2022 02:14:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=9
05/26/2022 02:14:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=9
05/26/2022 02:14:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/26/2022 02:14:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
05/26/2022 02:15:29 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.5124563569007079 on epoch=9
05/26/2022 02:15:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.13 on epoch=9
05/26/2022 02:15:35 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=9
05/26/2022 02:15:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
05/26/2022 02:15:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=10
05/26/2022 02:15:43 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/26/2022 02:16:37 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.5792391673637179 on epoch=10
05/26/2022 02:16:39 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=10
05/26/2022 02:16:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=10
05/26/2022 02:16:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=10
05/26/2022 02:16:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.14 on epoch=10
05/26/2022 02:16:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=10
05/26/2022 02:17:46 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.5878459055696668 on epoch=10
05/26/2022 02:17:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
05/26/2022 02:17:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=10
05/26/2022 02:17:54 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/26/2022 02:17:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=11
05/26/2022 02:18:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=11
05/26/2022 02:18:53 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.6787361455935013 on epoch=11
05/26/2022 02:18:56 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=11
05/26/2022 02:18:58 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=11
05/26/2022 02:19:01 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=11
05/26/2022 02:19:04 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
05/26/2022 02:19:06 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=11
05/26/2022 02:19:59 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.5060172889033965 on epoch=11
05/26/2022 02:20:02 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=11
05/26/2022 02:20:05 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=11
05/26/2022 02:20:07 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=11
05/26/2022 02:20:10 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=11
05/26/2022 02:20:13 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/26/2022 02:21:05 - INFO - __main__ - Global step 1350 Train loss 0.13 Classification-F1 0.5736359971619459 on epoch=12
05/26/2022 02:21:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
05/26/2022 02:21:11 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.21 on epoch=12
05/26/2022 02:21:13 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=12
05/26/2022 02:21:16 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=12
05/26/2022 02:21:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
05/26/2022 02:22:10 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.5589511864502407 on epoch=12
05/26/2022 02:22:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=12
05/26/2022 02:22:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=12
05/26/2022 02:22:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=12
05/26/2022 02:22:21 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=12
05/26/2022 02:22:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=12
05/26/2022 02:23:15 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.5456368073433001 on epoch=12
05/26/2022 02:23:18 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=13
05/26/2022 02:23:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
05/26/2022 02:23:23 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=13
05/26/2022 02:23:26 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/26/2022 02:23:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=13
05/26/2022 02:24:18 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6451950295362135 on epoch=13
05/26/2022 02:24:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
05/26/2022 02:24:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=13
05/26/2022 02:24:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=13
05/26/2022 02:24:29 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=13
05/26/2022 02:24:32 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=13
05/26/2022 02:25:20 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.6637313668060816 on epoch=13
05/26/2022 02:25:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=13
05/26/2022 02:25:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=14
05/26/2022 02:25:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
05/26/2022 02:25:31 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/26/2022 02:25:34 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
05/26/2022 02:26:22 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.502388321216618 on epoch=14
05/26/2022 02:26:25 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=14
05/26/2022 02:26:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/26/2022 02:26:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=14
05/26/2022 02:26:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
05/26/2022 02:26:36 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/26/2022 02:27:23 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.5461998728488527 on epoch=14
05/26/2022 02:27:26 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
05/26/2022 02:27:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/26/2022 02:27:31 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/26/2022 02:27:34 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/26/2022 02:27:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=15
05/26/2022 02:28:24 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.5033866481992489 on epoch=15
05/26/2022 02:28:26 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=15
05/26/2022 02:28:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
05/26/2022 02:28:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=15
05/26/2022 02:28:34 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=15
05/26/2022 02:28:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
05/26/2022 02:29:24 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6485265151546694 on epoch=15
05/26/2022 02:29:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=15
05/26/2022 02:29:29 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=15
05/26/2022 02:29:32 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=15
05/26/2022 02:29:34 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.07 on epoch=15
05/26/2022 02:29:37 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/26/2022 02:30:24 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6521539272686147 on epoch=16
05/26/2022 02:30:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
05/26/2022 02:30:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.08 on epoch=16
05/26/2022 02:30:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 02:30:35 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/26/2022 02:30:37 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=16
05/26/2022 02:31:23 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.663714602523638 on epoch=16
05/26/2022 02:31:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=16
05/26/2022 02:31:29 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=16
05/26/2022 02:31:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
05/26/2022 02:31:34 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
05/26/2022 02:31:37 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/26/2022 02:32:24 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.8037088651665719 on epoch=16
05/26/2022 02:32:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6806502716216508 -> 0.8037088651665719 on epoch=16, global_step=1900
05/26/2022 02:32:27 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/26/2022 02:32:30 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/26/2022 02:32:32 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
05/26/2022 02:32:35 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=17
05/26/2022 02:32:37 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/26/2022 02:33:25 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.672351794008544 on epoch=17
05/26/2022 02:33:27 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/26/2022 02:33:30 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/26/2022 02:33:33 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=17
05/26/2022 02:33:35 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/26/2022 02:33:38 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
05/26/2022 02:34:24 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.5455803809674992 on epoch=17
05/26/2022 02:34:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=17
05/26/2022 02:34:29 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=18
05/26/2022 02:34:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
05/26/2022 02:34:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=18
05/26/2022 02:34:37 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/26/2022 02:35:23 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5364139922147474 on epoch=18
05/26/2022 02:35:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=18
05/26/2022 02:35:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=18
05/26/2022 02:35:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
05/26/2022 02:35:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 02:35:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=18
05/26/2022 02:36:23 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.5708543741494331 on epoch=18
05/26/2022 02:36:25 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=18
05/26/2022 02:36:28 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=18
05/26/2022 02:36:31 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/26/2022 02:36:34 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/26/2022 02:36:36 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=19
05/26/2022 02:37:23 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.720359115473312 on epoch=19
05/26/2022 02:37:25 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
05/26/2022 02:37:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 02:37:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
05/26/2022 02:37:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=19
05/26/2022 02:37:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/26/2022 02:38:22 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.5330474690357138 on epoch=19
05/26/2022 02:38:25 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
05/26/2022 02:38:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=19
05/26/2022 02:38:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/26/2022 02:38:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=19
05/26/2022 02:38:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=20
05/26/2022 02:39:21 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.646761250018088 on epoch=20
05/26/2022 02:39:24 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
05/26/2022 02:39:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=20
05/26/2022 02:39:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
05/26/2022 02:39:32 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
05/26/2022 02:39:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/26/2022 02:40:19 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.723720243682088 on epoch=20
05/26/2022 02:40:22 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=20
05/26/2022 02:40:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=20
05/26/2022 02:40:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.11 on epoch=20
05/26/2022 02:40:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/26/2022 02:40:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
05/26/2022 02:41:18 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7231748459019044 on epoch=20
05/26/2022 02:41:20 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/26/2022 02:41:23 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=21
05/26/2022 02:41:26 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=21
05/26/2022 02:41:28 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 02:41:31 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/26/2022 02:42:15 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.6145485538681623 on epoch=21
05/26/2022 02:42:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/26/2022 02:42:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/26/2022 02:42:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/26/2022 02:42:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
05/26/2022 02:42:29 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/26/2022 02:43:12 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.47280072599075174 on epoch=21
05/26/2022 02:43:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/26/2022 02:43:17 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/26/2022 02:43:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=22
05/26/2022 02:43:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=22
05/26/2022 02:43:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=22
05/26/2022 02:44:10 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.5716138716830043 on epoch=22
05/26/2022 02:44:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
05/26/2022 02:44:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
05/26/2022 02:44:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=22
05/26/2022 02:44:21 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/26/2022 02:44:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=22
05/26/2022 02:45:09 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6398525475387635 on epoch=22
05/26/2022 02:45:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/26/2022 02:45:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=22
05/26/2022 02:45:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=23
05/26/2022 02:45:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/26/2022 02:45:23 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.10 on epoch=23
05/26/2022 02:46:08 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.7191362619281534 on epoch=23
05/26/2022 02:46:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/26/2022 02:46:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 02:46:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
05/26/2022 02:46:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/26/2022 02:46:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=23
05/26/2022 02:47:09 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7690967593620779 on epoch=23
05/26/2022 02:47:11 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/26/2022 02:47:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=23
05/26/2022 02:47:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=23
05/26/2022 02:47:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/26/2022 02:47:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
05/26/2022 02:48:10 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7238067569665974 on epoch=24
05/26/2022 02:48:13 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/26/2022 02:48:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.11 on epoch=24
05/26/2022 02:48:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 02:48:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/26/2022 02:48:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/26/2022 02:49:11 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6945718918955666 on epoch=24
05/26/2022 02:49:14 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=24
05/26/2022 02:49:16 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=24
05/26/2022 02:49:19 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=24
05/26/2022 02:49:22 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/26/2022 02:49:24 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 02:50:11 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7585441709040034 on epoch=24
05/26/2022 02:50:13 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.10 on epoch=25
05/26/2022 02:50:16 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=25
05/26/2022 02:50:18 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=25
05/26/2022 02:50:21 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=25
05/26/2022 02:50:24 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
05/26/2022 02:51:11 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.5801406130701939 on epoch=25
05/26/2022 02:51:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 02:51:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/26/2022 02:51:19 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
05/26/2022 02:51:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=25
05/26/2022 02:51:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
05/26/2022 02:52:12 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.6729079490235969 on epoch=25
05/26/2022 02:52:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=25
05/26/2022 02:52:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/26/2022 02:52:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/26/2022 02:52:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
05/26/2022 02:52:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/26/2022 02:53:13 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.6131116319861462 on epoch=26
05/26/2022 02:53:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/26/2022 02:53:18 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=26
05/26/2022 02:53:21 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=26
05/26/2022 02:53:23 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/26/2022 02:53:26 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
05/26/2022 02:53:27 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 02:53:27 - INFO - __main__ - Printing 3 examples
05/26/2022 02:53:27 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 02:53:27 - INFO - __main__ - ['Animal']
05/26/2022 02:53:27 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 02:53:27 - INFO - __main__ - ['Animal']
05/26/2022 02:53:27 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 02:53:27 - INFO - __main__ - ['Animal']
05/26/2022 02:53:27 - INFO - __main__ - Tokenizing Input ...
05/26/2022 02:53:28 - INFO - __main__ - Tokenizing Output ...
05/26/2022 02:53:30 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 02:53:30 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 02:53:30 - INFO - __main__ - Printing 3 examples
05/26/2022 02:53:30 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 02:53:30 - INFO - __main__ - ['Animal']
05/26/2022 02:53:30 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 02:53:30 - INFO - __main__ - ['Animal']
05/26/2022 02:53:30 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 02:53:30 - INFO - __main__ - ['Animal']
05/26/2022 02:53:30 - INFO - __main__ - Tokenizing Input ...
05/26/2022 02:53:31 - INFO - __main__ - Tokenizing Output ...
05/26/2022 02:53:33 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 02:53:49 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 02:53:49 - INFO - __main__ - task name: dbpedia_14
05/26/2022 02:53:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 02:53:50 - INFO - __main__ - Starting training!
05/26/2022 02:54:14 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.6523235817691396 on epoch=26
05/26/2022 02:54:14 - INFO - __main__ - save last model!
05/26/2022 02:54:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 02:54:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 02:54:14 - INFO - __main__ - Printing 3 examples
05/26/2022 02:54:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 02:54:14 - INFO - __main__ - ['Animal']
05/26/2022 02:54:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 02:54:14 - INFO - __main__ - ['Animal']
05/26/2022 02:54:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 02:54:14 - INFO - __main__ - ['Village']
05/26/2022 02:54:14 - INFO - __main__ - Tokenizing Input ...
05/26/2022 02:54:16 - INFO - __main__ - Tokenizing Output ...
05/26/2022 02:54:20 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 02:56:31 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.3_8_predictions.txt
05/26/2022 02:56:31 - INFO - __main__ - Classification-F1 on test data: 0.5704
05/26/2022 02:56:32 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.3, bsz=8, dev_performance=0.8037088651665719, test_performance=0.5704134187081217
05/26/2022 02:56:32 - INFO - __main__ - Running ... prefix=dbpedia_14_128_100, lr=0.2, bsz=8 ...
05/26/2022 02:56:33 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 02:56:33 - INFO - __main__ - Printing 3 examples
05/26/2022 02:56:33 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/26/2022 02:56:33 - INFO - __main__ - ['Animal']
05/26/2022 02:56:33 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/26/2022 02:56:33 - INFO - __main__ - ['Animal']
05/26/2022 02:56:33 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/26/2022 02:56:33 - INFO - __main__ - ['Animal']
05/26/2022 02:56:33 - INFO - __main__ - Tokenizing Input ...
05/26/2022 02:56:33 - INFO - __main__ - Tokenizing Output ...
05/26/2022 02:56:35 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 02:56:35 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 02:56:35 - INFO - __main__ - Printing 3 examples
05/26/2022 02:56:35 - INFO - __main__ -  [dbpedia_14] Palaephatus fusciterminus is a moth of the Palaephatidae family. It is found in the Valdivian forests of southern Argentina and Chile.The length of the forewings is 10-12 mm for males and 10.5-11.5 mm for females. Adults have a buff to brown head and thorax and dark brownish fuscous forewings with a pale buff hindmargin. They are on wing from October to March possibly in multiple generations per year.
05/26/2022 02:56:35 - INFO - __main__ - ['Animal']
05/26/2022 02:56:35 - INFO - __main__ -  [dbpedia_14] Labus is an indomalayan genus of potter wasps.
05/26/2022 02:56:35 - INFO - __main__ - ['Animal']
05/26/2022 02:56:35 - INFO - __main__ -  [dbpedia_14] Trifurcula beirnei is a moth of the Nepticulidae family. It is found in Great Britain Denmark and parts of Germany and Poland Austria the Czech Republic Slovakia and Hungary. It is also found in the Volga and Ural region of Russia.The wingspan is 8–11 mm. Adults are on wing from the end of June to late September.The larvae feed on Genista species including Genista tinctoria Genista germanica and Genista pilosa.
05/26/2022 02:56:35 - INFO - __main__ - ['Animal']
05/26/2022 02:56:35 - INFO - __main__ - Tokenizing Input ...
05/26/2022 02:56:36 - INFO - __main__ - Tokenizing Output ...
05/26/2022 02:56:38 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 02:56:57 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 02:56:57 - INFO - __main__ - task name: dbpedia_14
05/26/2022 02:56:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 02:56:58 - INFO - __main__ - Starting training!
05/26/2022 02:57:01 - INFO - __main__ - Step 10 Global step 10 Train loss 7.34 on epoch=0
05/26/2022 02:57:04 - INFO - __main__ - Step 20 Global step 20 Train loss 6.65 on epoch=0
05/26/2022 02:57:06 - INFO - __main__ - Step 30 Global step 30 Train loss 5.69 on epoch=0
05/26/2022 02:57:09 - INFO - __main__ - Step 40 Global step 40 Train loss 4.65 on epoch=0
05/26/2022 02:57:12 - INFO - __main__ - Step 50 Global step 50 Train loss 4.15 on epoch=0
05/26/2022 03:08:59 - INFO - __main__ - Global step 50 Train loss 5.69 Classification-F1 0.00028191982506781945 on epoch=0
05/26/2022 03:08:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.00028191982506781945 on epoch=0, global_step=50
05/26/2022 03:09:01 - INFO - __main__ - Step 60 Global step 60 Train loss 3.58 on epoch=0
05/26/2022 03:09:04 - INFO - __main__ - Step 70 Global step 70 Train loss 3.15 on epoch=0
05/26/2022 03:09:07 - INFO - __main__ - Step 80 Global step 80 Train loss 3.00 on epoch=0
05/26/2022 03:09:09 - INFO - __main__ - Step 90 Global step 90 Train loss 2.65 on epoch=0
05/26/2022 03:09:12 - INFO - __main__ - Step 100 Global step 100 Train loss 2.34 on epoch=0
05/26/2022 03:11:26 - INFO - __main__ - Global step 100 Train loss 2.94 Classification-F1 0.03532079393839401 on epoch=0
05/26/2022 03:11:26 - INFO - __main__ - Saving model with best Classification-F1: 0.00028191982506781945 -> 0.03532079393839401 on epoch=0, global_step=100
05/26/2022 03:11:29 - INFO - __main__ - Step 110 Global step 110 Train loss 1.97 on epoch=0
05/26/2022 03:11:32 - INFO - __main__ - Step 120 Global step 120 Train loss 1.98 on epoch=1
05/26/2022 03:11:34 - INFO - __main__ - Step 130 Global step 130 Train loss 1.74 on epoch=1
05/26/2022 03:11:37 - INFO - __main__ - Step 140 Global step 140 Train loss 1.63 on epoch=1
05/26/2022 03:11:39 - INFO - __main__ - Step 150 Global step 150 Train loss 1.49 on epoch=1
05/26/2022 03:13:02 - INFO - __main__ - Global step 150 Train loss 1.76 Classification-F1 0.10111870976762341 on epoch=1
05/26/2022 03:13:02 - INFO - __main__ - Saving model with best Classification-F1: 0.03532079393839401 -> 0.10111870976762341 on epoch=1, global_step=150
05/26/2022 03:13:05 - INFO - __main__ - Step 160 Global step 160 Train loss 1.45 on epoch=1
05/26/2022 03:13:07 - INFO - __main__ - Step 170 Global step 170 Train loss 1.28 on epoch=1
05/26/2022 03:13:10 - INFO - __main__ - Step 180 Global step 180 Train loss 1.30 on epoch=1
05/26/2022 03:13:12 - INFO - __main__ - Step 190 Global step 190 Train loss 1.21 on epoch=1
05/26/2022 03:13:15 - INFO - __main__ - Step 200 Global step 200 Train loss 1.14 on epoch=1
05/26/2022 03:14:25 - INFO - __main__ - Global step 200 Train loss 1.28 Classification-F1 0.18078235531970488 on epoch=1
05/26/2022 03:14:25 - INFO - __main__ - Saving model with best Classification-F1: 0.10111870976762341 -> 0.18078235531970488 on epoch=1, global_step=200
05/26/2022 03:14:28 - INFO - __main__ - Step 210 Global step 210 Train loss 1.08 on epoch=1
05/26/2022 03:14:30 - INFO - __main__ - Step 220 Global step 220 Train loss 0.96 on epoch=1
05/26/2022 03:14:33 - INFO - __main__ - Step 230 Global step 230 Train loss 0.98 on epoch=2
05/26/2022 03:14:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.92 on epoch=2
05/26/2022 03:14:38 - INFO - __main__ - Step 250 Global step 250 Train loss 0.93 on epoch=2
05/26/2022 03:15:35 - INFO - __main__ - Global step 250 Train loss 0.97 Classification-F1 0.22029727138857652 on epoch=2
05/26/2022 03:15:35 - INFO - __main__ - Saving model with best Classification-F1: 0.18078235531970488 -> 0.22029727138857652 on epoch=2, global_step=250
05/26/2022 03:15:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.86 on epoch=2
05/26/2022 03:15:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=2
05/26/2022 03:15:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.84 on epoch=2
05/26/2022 03:15:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.78 on epoch=2
05/26/2022 03:15:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.88 on epoch=2
05/26/2022 03:16:47 - INFO - __main__ - Global step 300 Train loss 0.84 Classification-F1 0.30285300814255034 on epoch=2
05/26/2022 03:16:48 - INFO - __main__ - Saving model with best Classification-F1: 0.22029727138857652 -> 0.30285300814255034 on epoch=2, global_step=300
05/26/2022 03:16:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.77 on epoch=2
05/26/2022 03:16:53 - INFO - __main__ - Step 320 Global step 320 Train loss 0.76 on epoch=2
05/26/2022 03:16:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.74 on epoch=2
05/26/2022 03:16:58 - INFO - __main__ - Step 340 Global step 340 Train loss 0.62 on epoch=3
05/26/2022 03:17:01 - INFO - __main__ - Step 350 Global step 350 Train loss 0.72 on epoch=3
05/26/2022 03:17:57 - INFO - __main__ - Global step 350 Train loss 0.72 Classification-F1 0.3917720062494084 on epoch=3
05/26/2022 03:17:57 - INFO - __main__ - Saving model with best Classification-F1: 0.30285300814255034 -> 0.3917720062494084 on epoch=3, global_step=350
05/26/2022 03:17:59 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=3
05/26/2022 03:18:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=3
05/26/2022 03:18:04 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=3
05/26/2022 03:18:07 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=3
05/26/2022 03:18:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.64 on epoch=3
05/26/2022 03:19:04 - INFO - __main__ - Global step 400 Train loss 0.62 Classification-F1 0.4566509191752355 on epoch=3
05/26/2022 03:19:04 - INFO - __main__ - Saving model with best Classification-F1: 0.3917720062494084 -> 0.4566509191752355 on epoch=3, global_step=400
05/26/2022 03:19:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.70 on epoch=3
05/26/2022 03:19:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.60 on epoch=3
05/26/2022 03:19:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.72 on epoch=3
05/26/2022 03:19:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.57 on epoch=3
05/26/2022 03:19:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.63 on epoch=4
05/26/2022 03:20:10 - INFO - __main__ - Global step 450 Train loss 0.64 Classification-F1 0.3690966949914439 on epoch=4
05/26/2022 03:20:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=4
05/26/2022 03:20:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.52 on epoch=4
05/26/2022 03:20:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.59 on epoch=4
05/26/2022 03:20:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.50 on epoch=4
05/26/2022 03:20:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=4
05/26/2022 03:21:20 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.4912648870236569 on epoch=4
05/26/2022 03:21:20 - INFO - __main__ - Saving model with best Classification-F1: 0.4566509191752355 -> 0.4912648870236569 on epoch=4, global_step=500
05/26/2022 03:21:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.53 on epoch=4
05/26/2022 03:21:25 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=4
05/26/2022 03:21:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.55 on epoch=4
05/26/2022 03:21:30 - INFO - __main__ - Step 540 Global step 540 Train loss 0.53 on epoch=4
05/26/2022 03:21:33 - INFO - __main__ - Step 550 Global step 550 Train loss 0.51 on epoch=4
05/26/2022 03:22:33 - INFO - __main__ - Global step 550 Train loss 0.54 Classification-F1 0.6237400111831287 on epoch=4
05/26/2022 03:22:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4912648870236569 -> 0.6237400111831287 on epoch=4, global_step=550
05/26/2022 03:22:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=4
05/26/2022 03:22:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=5
05/26/2022 03:22:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=5
05/26/2022 03:22:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=5
05/26/2022 03:22:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=5
05/26/2022 03:23:42 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.5970657243398457 on epoch=5
05/26/2022 03:23:45 - INFO - __main__ - Step 610 Global step 610 Train loss 0.43 on epoch=5
05/26/2022 03:23:47 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=5
05/26/2022 03:23:50 - INFO - __main__ - Step 630 Global step 630 Train loss 0.55 on epoch=5
05/26/2022 03:23:52 - INFO - __main__ - Step 640 Global step 640 Train loss 0.50 on epoch=5
05/26/2022 03:23:55 - INFO - __main__ - Step 650 Global step 650 Train loss 0.49 on epoch=5
05/26/2022 03:24:56 - INFO - __main__ - Global step 650 Train loss 0.48 Classification-F1 0.5111616095206264 on epoch=5
05/26/2022 03:24:58 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=5
05/26/2022 03:25:01 - INFO - __main__ - Step 670 Global step 670 Train loss 0.42 on epoch=5
05/26/2022 03:25:03 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=6
05/26/2022 03:25:06 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=6
05/26/2022 03:25:08 - INFO - __main__ - Step 700 Global step 700 Train loss 0.48 on epoch=6
05/26/2022 03:26:07 - INFO - __main__ - Global step 700 Train loss 0.43 Classification-F1 0.5583259912315692 on epoch=6
05/26/2022 03:26:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=6
05/26/2022 03:26:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.46 on epoch=6
05/26/2022 03:26:15 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=6
05/26/2022 03:26:18 - INFO - __main__ - Step 740 Global step 740 Train loss 0.51 on epoch=6
05/26/2022 03:26:20 - INFO - __main__ - Step 750 Global step 750 Train loss 0.41 on epoch=6
05/26/2022 03:27:15 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.5998752612731357 on epoch=6
05/26/2022 03:27:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.39 on epoch=6
05/26/2022 03:27:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.32 on epoch=6
05/26/2022 03:27:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=6
05/26/2022 03:27:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=7
05/26/2022 03:27:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.35 on epoch=7
05/26/2022 03:28:29 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.7248544948993121 on epoch=7
05/26/2022 03:28:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6237400111831287 -> 0.7248544948993121 on epoch=7, global_step=800
05/26/2022 03:28:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.33 on epoch=7
05/26/2022 03:28:34 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=7
05/26/2022 03:28:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=7
05/26/2022 03:28:39 - INFO - __main__ - Step 840 Global step 840 Train loss 0.31 on epoch=7
05/26/2022 03:28:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.35 on epoch=7
05/26/2022 03:29:35 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.7018040795488079 on epoch=7
05/26/2022 03:29:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.33 on epoch=7
05/26/2022 03:29:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=7
05/26/2022 03:29:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.31 on epoch=7
05/26/2022 03:29:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.34 on epoch=7
05/26/2022 03:29:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.27 on epoch=8
05/26/2022 03:30:41 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.6940291116638776 on epoch=8
05/26/2022 03:30:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=8
05/26/2022 03:30:46 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=8
05/26/2022 03:30:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.30 on epoch=8
05/26/2022 03:30:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.29 on epoch=8
05/26/2022 03:30:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=8
05/26/2022 03:31:55 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.6962528511495885 on epoch=8
05/26/2022 03:31:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=8
05/26/2022 03:32:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.29 on epoch=8
05/26/2022 03:32:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=8
05/26/2022 03:32:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=8
05/26/2022 03:32:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.32 on epoch=8
05/26/2022 03:33:05 - INFO - __main__ - Global step 1000 Train loss 0.28 Classification-F1 0.6671935990825963 on epoch=8
05/26/2022 03:33:08 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.26 on epoch=9
05/26/2022 03:33:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.17 on epoch=9
05/26/2022 03:33:13 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=9
05/26/2022 03:33:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.23 on epoch=9
05/26/2022 03:33:18 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=9
05/26/2022 03:34:17 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.7327867446215434 on epoch=9
05/26/2022 03:34:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7248544948993121 -> 0.7327867446215434 on epoch=9, global_step=1050
05/26/2022 03:34:19 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.29 on epoch=9
05/26/2022 03:34:22 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.21 on epoch=9
05/26/2022 03:34:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=9
05/26/2022 03:34:27 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.19 on epoch=9
05/26/2022 03:34:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.28 on epoch=9
05/26/2022 03:35:28 - INFO - __main__ - Global step 1100 Train loss 0.24 Classification-F1 0.5416384419867009 on epoch=9
05/26/2022 03:35:31 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=9
05/26/2022 03:35:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=9
05/26/2022 03:35:36 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=10
05/26/2022 03:35:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=10
05/26/2022 03:35:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.31 on epoch=10
05/26/2022 03:36:36 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.4418631900609675 on epoch=10
05/26/2022 03:36:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=10
05/26/2022 03:36:41 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=10
05/26/2022 03:36:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=10
05/26/2022 03:36:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
05/26/2022 03:36:49 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=10
05/26/2022 03:37:47 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.6132219852908888 on epoch=10
05/26/2022 03:37:49 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.19 on epoch=10
05/26/2022 03:37:52 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=10
05/26/2022 03:37:55 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=10
05/26/2022 03:37:57 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=11
05/26/2022 03:38:00 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=11
05/26/2022 03:38:55 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.6142073436134556 on epoch=11
05/26/2022 03:38:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.24 on epoch=11
05/26/2022 03:39:00 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=11
05/26/2022 03:39:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=11
05/26/2022 03:39:05 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=11
05/26/2022 03:39:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.26 on epoch=11
05/26/2022 03:40:05 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.6387004991047676 on epoch=11
05/26/2022 03:40:07 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=11
05/26/2022 03:40:10 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=11
05/26/2022 03:40:13 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.14 on epoch=11
05/26/2022 03:40:15 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=11
05/26/2022 03:40:18 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/26/2022 03:41:11 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.50867017204295 on epoch=12
05/26/2022 03:41:14 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
05/26/2022 03:41:16 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=12
05/26/2022 03:41:19 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=12
05/26/2022 03:41:22 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=12
05/26/2022 03:41:24 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=12
05/26/2022 03:42:21 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.6953996774177725 on epoch=12
05/26/2022 03:42:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=12
05/26/2022 03:42:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=12
05/26/2022 03:42:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.17 on epoch=12
05/26/2022 03:42:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.19 on epoch=12
05/26/2022 03:42:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=12
05/26/2022 03:43:29 - INFO - __main__ - Global step 1450 Train loss 0.18 Classification-F1 0.6081109071108968 on epoch=12
05/26/2022 03:43:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=13
05/26/2022 03:43:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=13
05/26/2022 03:43:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.24 on epoch=13
05/26/2022 03:43:40 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=13
05/26/2022 03:43:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.17 on epoch=13
05/26/2022 03:44:35 - INFO - __main__ - Global step 1500 Train loss 0.16 Classification-F1 0.6700819177751318 on epoch=13
05/26/2022 03:44:38 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.22 on epoch=13
05/26/2022 03:44:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.16 on epoch=13
05/26/2022 03:44:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.21 on epoch=13
05/26/2022 03:44:46 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=13
05/26/2022 03:44:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=13
05/26/2022 03:45:46 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.6809483159987909 on epoch=13
05/26/2022 03:45:48 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=13
05/26/2022 03:45:51 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
05/26/2022 03:45:53 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=14
05/26/2022 03:45:56 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=14
05/26/2022 03:45:59 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.21 on epoch=14
05/26/2022 03:46:55 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.6478373500436339 on epoch=14
05/26/2022 03:46:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
05/26/2022 03:47:00 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=14
05/26/2022 03:47:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=14
05/26/2022 03:47:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=14
05/26/2022 03:47:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
05/26/2022 03:47:58 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.5856990605645309 on epoch=14
05/26/2022 03:48:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.32 on epoch=14
05/26/2022 03:48:03 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.13 on epoch=14
05/26/2022 03:48:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=14
05/26/2022 03:48:08 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.12 on epoch=15
05/26/2022 03:48:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.16 on epoch=15
05/26/2022 03:49:02 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.6006960393223488 on epoch=15
05/26/2022 03:49:04 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=15
05/26/2022 03:49:07 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=15
05/26/2022 03:49:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=15
05/26/2022 03:49:12 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/26/2022 03:49:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=15
05/26/2022 03:50:08 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.7239564722126614 on epoch=15
05/26/2022 03:50:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=15
05/26/2022 03:50:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
05/26/2022 03:50:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=15
05/26/2022 03:50:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=15
05/26/2022 03:50:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/26/2022 03:51:12 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.678749276907047 on epoch=16
05/26/2022 03:51:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.13 on epoch=16
05/26/2022 03:51:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.30 on epoch=16
05/26/2022 03:51:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=16
05/26/2022 03:51:22 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.15 on epoch=16
05/26/2022 03:51:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=16
05/26/2022 03:52:18 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.5415001565805556 on epoch=16
05/26/2022 03:52:21 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.15 on epoch=16
05/26/2022 03:52:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=16
05/26/2022 03:52:26 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.16 on epoch=16
05/26/2022 03:52:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=16
05/26/2022 03:52:31 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=16
05/26/2022 03:53:30 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6213419807213347 on epoch=16
05/26/2022 03:53:33 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=17
05/26/2022 03:53:35 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=17
05/26/2022 03:53:38 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
05/26/2022 03:53:40 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.17 on epoch=17
05/26/2022 03:53:43 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
05/26/2022 03:54:37 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.6019737737852238 on epoch=17
05/26/2022 03:54:39 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=17
05/26/2022 03:54:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=17
05/26/2022 03:54:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=17
05/26/2022 03:54:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=17
05/26/2022 03:54:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=17
05/26/2022 03:55:42 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.6781875260423564 on epoch=17
05/26/2022 03:55:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=17
05/26/2022 03:55:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/26/2022 03:55:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=18
05/26/2022 03:55:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.17 on epoch=18
05/26/2022 03:55:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
05/26/2022 03:56:45 - INFO - __main__ - Global step 2050 Train loss 0.10 Classification-F1 0.5871448517657119 on epoch=18
05/26/2022 03:56:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=18
05/26/2022 03:56:50 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
05/26/2022 03:56:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.14 on epoch=18
05/26/2022 03:56:55 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=18
05/26/2022 03:56:58 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=18
05/26/2022 03:57:50 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.5429295353345228 on epoch=18
05/26/2022 03:57:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
05/26/2022 03:57:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=18
05/26/2022 03:57:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=19
05/26/2022 03:58:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=19
05/26/2022 03:58:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
05/26/2022 03:58:51 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.5638303840816554 on epoch=19
05/26/2022 03:58:54 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.12 on epoch=19
05/26/2022 03:58:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=19
05/26/2022 03:58:59 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=19
05/26/2022 03:59:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
05/26/2022 03:59:04 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.15 on epoch=19
05/26/2022 03:59:57 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.6498889289509829 on epoch=19
05/26/2022 03:59:59 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/26/2022 04:00:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
05/26/2022 04:00:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
05/26/2022 04:00:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/26/2022 04:00:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.09 on epoch=20
05/26/2022 04:01:04 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.7152054993677406 on epoch=20
05/26/2022 04:01:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=20
05/26/2022 04:01:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=20
05/26/2022 04:01:11 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=20
05/26/2022 04:01:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
05/26/2022 04:01:16 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.07 on epoch=20
05/26/2022 04:02:10 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.6788685343620721 on epoch=20
05/26/2022 04:02:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.16 on epoch=20
05/26/2022 04:02:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/26/2022 04:02:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=20
05/26/2022 04:02:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/26/2022 04:02:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=20
05/26/2022 04:03:15 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.5375932468468722 on epoch=20
05/26/2022 04:03:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=21
05/26/2022 04:03:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
05/26/2022 04:03:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.12 on epoch=21
05/26/2022 04:03:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=21
05/26/2022 04:03:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.17 on epoch=21
05/26/2022 04:04:16 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.5762752362078041 on epoch=21
05/26/2022 04:04:18 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/26/2022 04:04:21 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=21
05/26/2022 04:04:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=21
05/26/2022 04:04:26 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=21
05/26/2022 04:04:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.11 on epoch=21
05/26/2022 04:05:21 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.5739332025827234 on epoch=21
05/26/2022 04:05:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/26/2022 04:05:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
05/26/2022 04:05:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.08 on epoch=22
05/26/2022 04:05:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=22
05/26/2022 04:05:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/26/2022 04:06:22 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.49887154343791845 on epoch=22
05/26/2022 04:06:24 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.08 on epoch=22
05/26/2022 04:06:27 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.13 on epoch=22
05/26/2022 04:06:29 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=22
05/26/2022 04:06:32 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=22
05/26/2022 04:06:34 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=22
05/26/2022 04:07:24 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.5488035552821092 on epoch=22
05/26/2022 04:07:26 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=22
05/26/2022 04:07:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.10 on epoch=22
05/26/2022 04:07:31 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/26/2022 04:07:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=23
05/26/2022 04:07:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.16 on epoch=23
05/26/2022 04:08:27 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.5230780344787498 on epoch=23
05/26/2022 04:08:29 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
05/26/2022 04:08:32 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=23
05/26/2022 04:08:34 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=23
05/26/2022 04:08:37 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=23
05/26/2022 04:08:40 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=23
05/26/2022 04:09:30 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.5631651540134205 on epoch=23
05/26/2022 04:09:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=23
05/26/2022 04:09:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.13 on epoch=23
05/26/2022 04:09:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.10 on epoch=23
05/26/2022 04:09:40 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=24
05/26/2022 04:09:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=24
05/26/2022 04:10:30 - INFO - __main__ - Global step 2700 Train loss 0.10 Classification-F1 0.5087155297230918 on epoch=24
05/26/2022 04:10:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.15 on epoch=24
05/26/2022 04:10:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.13 on epoch=24
05/26/2022 04:10:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=24
05/26/2022 04:10:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=24
05/26/2022 04:10:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
05/26/2022 04:11:38 - INFO - __main__ - Global step 2750 Train loss 0.11 Classification-F1 0.628085975542354 on epoch=24
05/26/2022 04:11:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=24
05/26/2022 04:11:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/26/2022 04:11:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.12 on epoch=24
05/26/2022 04:11:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=24
05/26/2022 04:11:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
05/26/2022 04:12:41 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.5341365644428014 on epoch=24
05/26/2022 04:12:43 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=25
05/26/2022 04:12:46 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=25
05/26/2022 04:12:48 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
05/26/2022 04:12:51 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.10 on epoch=25
05/26/2022 04:12:54 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.12 on epoch=25
05/26/2022 04:13:42 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.5842687506210787 on epoch=25
05/26/2022 04:13:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=25
05/26/2022 04:13:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=25
05/26/2022 04:13:50 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=25
05/26/2022 04:13:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.15 on epoch=25
05/26/2022 04:13:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=25
05/26/2022 04:14:47 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.5529569530356094 on epoch=25
05/26/2022 04:14:49 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=25
05/26/2022 04:14:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=26
05/26/2022 04:14:54 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
05/26/2022 04:14:57 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=26
05/26/2022 04:15:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=26
05/26/2022 04:15:47 - INFO - __main__ - Global step 2950 Train loss 0.07 Classification-F1 0.5216834329669792 on epoch=26
05/26/2022 04:15:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.10 on epoch=26
05/26/2022 04:15:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.11 on epoch=26
05/26/2022 04:15:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=26
05/26/2022 04:15:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=26
05/26/2022 04:16:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
05/26/2022 04:16:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 04:16:01 - INFO - __main__ - Printing 3 examples
05/26/2022 04:16:01 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 04:16:01 - INFO - __main__ - ['Animal']
05/26/2022 04:16:01 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 04:16:01 - INFO - __main__ - ['Animal']
05/26/2022 04:16:01 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 04:16:01 - INFO - __main__ - ['Animal']
05/26/2022 04:16:01 - INFO - __main__ - Tokenizing Input ...
05/26/2022 04:16:02 - INFO - __main__ - Tokenizing Output ...
05/26/2022 04:16:04 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 04:16:04 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 04:16:04 - INFO - __main__ - Printing 3 examples
05/26/2022 04:16:04 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 04:16:04 - INFO - __main__ - ['Animal']
05/26/2022 04:16:04 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 04:16:04 - INFO - __main__ - ['Animal']
05/26/2022 04:16:04 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 04:16:04 - INFO - __main__ - ['Animal']
05/26/2022 04:16:04 - INFO - __main__ - Tokenizing Input ...
05/26/2022 04:16:05 - INFO - __main__ - Tokenizing Output ...
05/26/2022 04:16:07 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 04:16:22 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 04:16:22 - INFO - __main__ - task name: dbpedia_14
05/26/2022 04:16:23 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 04:16:23 - INFO - __main__ - Starting training!
05/26/2022 04:16:52 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.7644078277438779 on epoch=26
05/26/2022 04:16:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7327867446215434 -> 0.7644078277438779 on epoch=26, global_step=3000
05/26/2022 04:16:52 - INFO - __main__ - save last model!
05/26/2022 04:16:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 04:16:52 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 04:16:52 - INFO - __main__ - Printing 3 examples
05/26/2022 04:16:52 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 04:16:52 - INFO - __main__ - ['Animal']
05/26/2022 04:16:52 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 04:16:52 - INFO - __main__ - ['Animal']
05/26/2022 04:16:52 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 04:16:52 - INFO - __main__ - ['Village']
05/26/2022 04:16:52 - INFO - __main__ - Tokenizing Input ...
05/26/2022 04:16:54 - INFO - __main__ - Tokenizing Output ...
05/26/2022 04:16:57 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 04:19:08 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_100_0.2_8_predictions.txt
05/26/2022 04:19:08 - INFO - __main__ - Classification-F1 on test data: 0.6219
05/26/2022 04:19:09 - INFO - __main__ - prefix=dbpedia_14_128_100, lr=0.2, bsz=8, dev_performance=0.7644078277438779, test_performance=0.6219070916439413
05/26/2022 04:19:09 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.5, bsz=8 ...
05/26/2022 04:19:10 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 04:19:10 - INFO - __main__ - Printing 3 examples
05/26/2022 04:19:10 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 04:19:10 - INFO - __main__ - ['Animal']
05/26/2022 04:19:10 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 04:19:10 - INFO - __main__ - ['Animal']
05/26/2022 04:19:10 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 04:19:10 - INFO - __main__ - ['Animal']
05/26/2022 04:19:10 - INFO - __main__ - Tokenizing Input ...
05/26/2022 04:19:11 - INFO - __main__ - Tokenizing Output ...
05/26/2022 04:19:12 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 04:19:12 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 04:19:12 - INFO - __main__ - Printing 3 examples
05/26/2022 04:19:12 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 04:19:12 - INFO - __main__ - ['Animal']
05/26/2022 04:19:12 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 04:19:12 - INFO - __main__ - ['Animal']
05/26/2022 04:19:12 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 04:19:12 - INFO - __main__ - ['Animal']
05/26/2022 04:19:12 - INFO - __main__ - Tokenizing Input ...
05/26/2022 04:19:13 - INFO - __main__ - Tokenizing Output ...
05/26/2022 04:19:15 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 04:19:34 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 04:19:34 - INFO - __main__ - task name: dbpedia_14
05/26/2022 04:19:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 04:19:35 - INFO - __main__ - Starting training!
05/26/2022 04:19:38 - INFO - __main__ - Step 10 Global step 10 Train loss 6.38 on epoch=0
05/26/2022 04:19:41 - INFO - __main__ - Step 20 Global step 20 Train loss 4.36 on epoch=0
05/26/2022 04:19:43 - INFO - __main__ - Step 30 Global step 30 Train loss 3.17 on epoch=0
05/26/2022 04:19:46 - INFO - __main__ - Step 40 Global step 40 Train loss 2.49 on epoch=0
05/26/2022 04:19:49 - INFO - __main__ - Step 50 Global step 50 Train loss 2.22 on epoch=0
05/26/2022 04:20:29 - INFO - __main__ - Global step 50 Train loss 3.72 Classification-F1 0.07989486158351054 on epoch=0
05/26/2022 04:20:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.07989486158351054 on epoch=0, global_step=50
05/26/2022 04:20:32 - INFO - __main__ - Step 60 Global step 60 Train loss 1.87 on epoch=0
05/26/2022 04:20:34 - INFO - __main__ - Step 70 Global step 70 Train loss 1.51 on epoch=0
05/26/2022 04:20:37 - INFO - __main__ - Step 80 Global step 80 Train loss 1.33 on epoch=0
05/26/2022 04:20:40 - INFO - __main__ - Step 90 Global step 90 Train loss 1.23 on epoch=0
05/26/2022 04:20:42 - INFO - __main__ - Step 100 Global step 100 Train loss 1.07 on epoch=0
05/26/2022 04:21:42 - INFO - __main__ - Global step 100 Train loss 1.40 Classification-F1 0.24891323716899452 on epoch=0
05/26/2022 04:21:42 - INFO - __main__ - Saving model with best Classification-F1: 0.07989486158351054 -> 0.24891323716899452 on epoch=0, global_step=100
05/26/2022 04:21:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.15 on epoch=0
05/26/2022 04:21:47 - INFO - __main__ - Step 120 Global step 120 Train loss 0.99 on epoch=1
05/26/2022 04:21:50 - INFO - __main__ - Step 130 Global step 130 Train loss 0.87 on epoch=1
05/26/2022 04:21:52 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=1
05/26/2022 04:21:55 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=1
05/26/2022 04:23:12 - INFO - __main__ - Global step 150 Train loss 0.95 Classification-F1 0.2779442489365584 on epoch=1
05/26/2022 04:23:12 - INFO - __main__ - Saving model with best Classification-F1: 0.24891323716899452 -> 0.2779442489365584 on epoch=1, global_step=150
05/26/2022 04:23:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.85 on epoch=1
05/26/2022 04:23:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.76 on epoch=1
05/26/2022 04:23:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=1
05/26/2022 04:23:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=1
05/26/2022 04:23:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=1
05/26/2022 04:24:24 - INFO - __main__ - Global step 200 Train loss 0.73 Classification-F1 0.3413184274161656 on epoch=1
05/26/2022 04:24:24 - INFO - __main__ - Saving model with best Classification-F1: 0.2779442489365584 -> 0.3413184274161656 on epoch=1, global_step=200
05/26/2022 04:24:26 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=1
05/26/2022 04:24:29 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=1
05/26/2022 04:24:32 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=2
05/26/2022 04:24:35 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=2
05/26/2022 04:24:37 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=2
05/26/2022 04:25:35 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.3378313621793886 on epoch=2
05/26/2022 04:25:38 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=2
05/26/2022 04:25:41 - INFO - __main__ - Step 270 Global step 270 Train loss 0.61 on epoch=2
05/26/2022 04:25:43 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=2
05/26/2022 04:25:46 - INFO - __main__ - Step 290 Global step 290 Train loss 0.50 on epoch=2
05/26/2022 04:25:49 - INFO - __main__ - Step 300 Global step 300 Train loss 0.41 on epoch=2
05/26/2022 04:26:40 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.48269637814466954 on epoch=2
05/26/2022 04:26:40 - INFO - __main__ - Saving model with best Classification-F1: 0.3413184274161656 -> 0.48269637814466954 on epoch=2, global_step=300
05/26/2022 04:26:43 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=2
05/26/2022 04:26:45 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=2
05/26/2022 04:26:48 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=2
05/26/2022 04:26:51 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=3
05/26/2022 04:26:53 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=3
05/26/2022 04:27:51 - INFO - __main__ - Global step 350 Train loss 0.44 Classification-F1 0.43725244629048093 on epoch=3
05/26/2022 04:27:54 - INFO - __main__ - Step 360 Global step 360 Train loss 0.31 on epoch=3
05/26/2022 04:27:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=3
05/26/2022 04:27:59 - INFO - __main__ - Step 380 Global step 380 Train loss 0.23 on epoch=3
05/26/2022 04:28:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=3
05/26/2022 04:28:04 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=3
05/26/2022 04:29:02 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.5302495250820393 on epoch=3
05/26/2022 04:29:02 - INFO - __main__ - Saving model with best Classification-F1: 0.48269637814466954 -> 0.5302495250820393 on epoch=3, global_step=400
05/26/2022 04:29:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=3
05/26/2022 04:29:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.27 on epoch=3
05/26/2022 04:29:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.42 on epoch=3
05/26/2022 04:29:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=3
05/26/2022 04:29:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=4
05/26/2022 04:30:11 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.34253030727807077 on epoch=4
05/26/2022 04:30:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.28 on epoch=4
05/26/2022 04:30:16 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=4
05/26/2022 04:30:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=4
05/26/2022 04:30:21 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=4
05/26/2022 04:30:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=4
05/26/2022 04:31:17 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.578800720642388 on epoch=4
05/26/2022 04:31:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5302495250820393 -> 0.578800720642388 on epoch=4, global_step=500
05/26/2022 04:31:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=4
05/26/2022 04:31:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=4
05/26/2022 04:31:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=4
05/26/2022 04:31:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.40 on epoch=4
05/26/2022 04:31:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=4
05/26/2022 04:32:28 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.7212938983541249 on epoch=4
05/26/2022 04:32:28 - INFO - __main__ - Saving model with best Classification-F1: 0.578800720642388 -> 0.7212938983541249 on epoch=4, global_step=550
05/26/2022 04:32:31 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=4
05/26/2022 04:32:33 - INFO - __main__ - Step 570 Global step 570 Train loss 0.16 on epoch=5
05/26/2022 04:32:36 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=5
05/26/2022 04:32:39 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
05/26/2022 04:32:41 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
05/26/2022 04:33:33 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.5097291188974022 on epoch=5
05/26/2022 04:33:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=5
05/26/2022 04:33:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.25 on epoch=5
05/26/2022 04:33:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=5
05/26/2022 04:33:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
05/26/2022 04:33:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=5
05/26/2022 04:34:42 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.598972124171573 on epoch=5
05/26/2022 04:34:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=5
05/26/2022 04:34:47 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=5
05/26/2022 04:34:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=6
05/26/2022 04:34:52 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=6
05/26/2022 04:34:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=6
05/26/2022 04:35:49 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.5223025669592097 on epoch=6
05/26/2022 04:35:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=6
05/26/2022 04:35:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=6
05/26/2022 04:35:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=6
05/26/2022 04:36:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=6
05/26/2022 04:36:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=6
05/26/2022 04:36:51 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.5065214090543604 on epoch=6
05/26/2022 04:36:54 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=6
05/26/2022 04:36:56 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=6
05/26/2022 04:36:59 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=6
05/26/2022 04:37:02 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=7
05/26/2022 04:37:04 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=7
05/26/2022 04:37:55 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.4444274866155284 on epoch=7
05/26/2022 04:37:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=7
05/26/2022 04:38:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=7
05/26/2022 04:38:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=7
05/26/2022 04:38:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.22 on epoch=7
05/26/2022 04:38:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=7
05/26/2022 04:39:13 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.4604787682940516 on epoch=7
05/26/2022 04:39:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=7
05/26/2022 04:39:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=7
05/26/2022 04:39:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=7
05/26/2022 04:39:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=7
05/26/2022 04:39:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=8
05/26/2022 04:40:14 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5609132838597002 on epoch=8
05/26/2022 04:40:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=8
05/26/2022 04:40:19 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
05/26/2022 04:40:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=8
05/26/2022 04:40:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=8
05/26/2022 04:40:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=8
05/26/2022 04:41:22 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.5458471056243929 on epoch=8
05/26/2022 04:41:25 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=8
05/26/2022 04:41:27 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=8
05/26/2022 04:41:30 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=8
05/26/2022 04:41:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=8
05/26/2022 04:41:35 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.23 on epoch=8
05/26/2022 04:42:24 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.40189509279414115 on epoch=8
05/26/2022 04:42:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=9
05/26/2022 04:42:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=9
05/26/2022 04:42:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
05/26/2022 04:42:35 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=9
05/26/2022 04:42:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=9
05/26/2022 04:43:23 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.4258804904903305 on epoch=9
05/26/2022 04:43:26 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.18 on epoch=9
05/26/2022 04:43:28 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=9
05/26/2022 04:43:31 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=9
05/26/2022 04:43:33 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/26/2022 04:43:36 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=9
05/26/2022 04:44:23 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.3781194798933922 on epoch=9
05/26/2022 04:44:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=9
05/26/2022 04:44:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=9
05/26/2022 04:44:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
05/26/2022 04:44:33 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/26/2022 04:44:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/26/2022 04:45:22 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.4336165468300724 on epoch=10
05/26/2022 04:45:25 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
05/26/2022 04:45:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=10
05/26/2022 04:45:30 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=10
05/26/2022 04:45:33 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=10
05/26/2022 04:45:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/26/2022 04:46:22 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.3840329650066674 on epoch=10
05/26/2022 04:46:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=10
05/26/2022 04:46:27 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.17 on epoch=10
05/26/2022 04:46:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=10
05/26/2022 04:46:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/26/2022 04:46:35 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=11
05/26/2022 04:47:27 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.3420681518451611 on epoch=11
05/26/2022 04:47:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/26/2022 04:47:32 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=11
05/26/2022 04:47:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
05/26/2022 04:47:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=11
05/26/2022 04:47:40 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/26/2022 04:48:30 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.5028600445195474 on epoch=11
05/26/2022 04:48:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 04:48:35 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/26/2022 04:48:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=11
05/26/2022 04:48:40 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=11
05/26/2022 04:48:43 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=12
05/26/2022 04:49:33 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.3623267235077788 on epoch=12
05/26/2022 04:49:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
05/26/2022 04:49:38 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=12
05/26/2022 04:49:41 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=12
05/26/2022 04:49:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=12
05/26/2022 04:49:46 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.16 on epoch=12
05/26/2022 04:50:37 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6265872146261524 on epoch=12
05/26/2022 04:50:40 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=12
05/26/2022 04:50:42 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=12
05/26/2022 04:50:45 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/26/2022 04:50:47 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=12
05/26/2022 04:50:50 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=12
05/26/2022 04:51:42 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.5503995464695367 on epoch=12
05/26/2022 04:51:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=13
05/26/2022 04:51:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=13
05/26/2022 04:51:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=13
05/26/2022 04:51:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=13
05/26/2022 04:51:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
05/26/2022 04:52:43 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.467144335731272 on epoch=13
05/26/2022 04:52:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=13
05/26/2022 04:52:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/26/2022 04:52:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.13 on epoch=13
05/26/2022 04:52:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
05/26/2022 04:52:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=13
05/26/2022 04:53:43 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.590225604085002 on epoch=13
05/26/2022 04:53:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=13
05/26/2022 04:53:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=14
05/26/2022 04:53:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
05/26/2022 04:53:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=14
05/26/2022 04:53:57 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.13 on epoch=14
05/26/2022 04:54:41 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.4231631667178205 on epoch=14
05/26/2022 04:54:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=14
05/26/2022 04:54:47 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.27 on epoch=14
05/26/2022 04:54:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=14
05/26/2022 04:54:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=14
05/26/2022 04:54:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=14
05/26/2022 04:55:41 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.4919042459328364 on epoch=14
05/26/2022 04:55:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=14
05/26/2022 04:55:46 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=14
05/26/2022 04:55:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=14
05/26/2022 04:55:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
05/26/2022 04:55:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=15
05/26/2022 04:56:42 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.5428230252887489 on epoch=15
05/26/2022 04:56:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=15
05/26/2022 04:56:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
05/26/2022 04:56:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.25 on epoch=15
05/26/2022 04:56:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=15
05/26/2022 04:56:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=15
05/26/2022 04:57:42 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.5245726194401754 on epoch=15
05/26/2022 04:57:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=15
05/26/2022 04:57:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.14 on epoch=15
05/26/2022 04:57:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/26/2022 04:57:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.11 on epoch=15
05/26/2022 04:57:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/26/2022 04:58:43 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.42488741589069284 on epoch=16
05/26/2022 04:58:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/26/2022 04:58:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=16
05/26/2022 04:58:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=16
05/26/2022 04:58:53 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=16
05/26/2022 04:58:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=16
05/26/2022 04:59:50 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.4616542769071157 on epoch=16
05/26/2022 04:59:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=16
05/26/2022 04:59:55 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=16
05/26/2022 04:59:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=16
05/26/2022 05:00:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=16
05/26/2022 05:00:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=16
05/26/2022 05:01:01 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.5492491411161304 on epoch=16
05/26/2022 05:01:03 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=17
05/26/2022 05:01:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
05/26/2022 05:01:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=17
05/26/2022 05:01:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
05/26/2022 05:01:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=17
05/26/2022 05:02:06 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.684016262082552 on epoch=17
05/26/2022 05:02:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.17 on epoch=17
05/26/2022 05:02:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=17
05/26/2022 05:02:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=17
05/26/2022 05:02:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/26/2022 05:02:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.13 on epoch=17
05/26/2022 05:03:10 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.5013175606954386 on epoch=17
05/26/2022 05:03:13 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
05/26/2022 05:03:15 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/26/2022 05:03:18 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/26/2022 05:03:21 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=18
05/26/2022 05:03:23 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=18
05/26/2022 05:04:19 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.42070710745143614 on epoch=18
05/26/2022 05:04:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=18
05/26/2022 05:04:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=18
05/26/2022 05:04:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=18
05/26/2022 05:04:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/26/2022 05:04:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/26/2022 05:05:21 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.5137675034340038 on epoch=18
05/26/2022 05:05:24 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=18
05/26/2022 05:05:27 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/26/2022 05:05:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.13 on epoch=19
05/26/2022 05:05:32 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
05/26/2022 05:05:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
05/26/2022 05:06:32 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.5223732455855017 on epoch=19
05/26/2022 05:06:34 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
05/26/2022 05:06:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=19
05/26/2022 05:06:39 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=19
05/26/2022 05:06:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/26/2022 05:06:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/26/2022 05:07:38 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.6274325415847934 on epoch=19
05/26/2022 05:07:40 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
05/26/2022 05:07:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
05/26/2022 05:07:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=19
05/26/2022 05:07:48 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=19
05/26/2022 05:07:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/26/2022 05:08:44 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.48766527914801294 on epoch=20
05/26/2022 05:08:46 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=20
05/26/2022 05:08:49 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=20
05/26/2022 05:08:51 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
05/26/2022 05:08:54 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/26/2022 05:08:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/26/2022 05:09:52 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.49268110158619444 on epoch=20
05/26/2022 05:09:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=20
05/26/2022 05:09:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=20
05/26/2022 05:10:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=20
05/26/2022 05:10:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=20
05/26/2022 05:10:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
05/26/2022 05:10:56 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.43496025738414446 on epoch=20
05/26/2022 05:10:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
05/26/2022 05:11:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=21
05/26/2022 05:11:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/26/2022 05:11:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
05/26/2022 05:11:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
05/26/2022 05:11:56 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.4430565396982012 on epoch=21
05/26/2022 05:11:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=21
05/26/2022 05:12:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/26/2022 05:12:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=21
05/26/2022 05:12:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=21
05/26/2022 05:12:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.14 on epoch=21
05/26/2022 05:12:57 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.5101694991182805 on epoch=21
05/26/2022 05:13:00 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.11 on epoch=21
05/26/2022 05:13:02 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/26/2022 05:13:05 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=22
05/26/2022 05:13:07 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=22
05/26/2022 05:13:10 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
05/26/2022 05:13:55 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.42071118119366313 on epoch=22
05/26/2022 05:13:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/26/2022 05:14:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/26/2022 05:14:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=22
05/26/2022 05:14:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=22
05/26/2022 05:14:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/26/2022 05:15:00 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6812044027222414 on epoch=22
05/26/2022 05:15:02 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.14 on epoch=22
05/26/2022 05:15:05 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/26/2022 05:15:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=23
05/26/2022 05:15:10 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/26/2022 05:15:13 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/26/2022 05:16:03 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.38448810468363237 on epoch=23
05/26/2022 05:16:06 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=23
05/26/2022 05:16:08 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
05/26/2022 05:16:11 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.13 on epoch=23
05/26/2022 05:16:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 05:16:16 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/26/2022 05:17:08 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6827098752906885 on epoch=23
05/26/2022 05:17:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/26/2022 05:17:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.12 on epoch=23
05/26/2022 05:17:16 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=23
05/26/2022 05:17:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=24
05/26/2022 05:17:21 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
05/26/2022 05:18:13 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.5496756793211772 on epoch=24
05/26/2022 05:18:16 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/26/2022 05:18:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
05/26/2022 05:18:21 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 05:18:24 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/26/2022 05:18:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/26/2022 05:19:14 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.5645277311460198 on epoch=24
05/26/2022 05:19:16 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 05:19:19 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/26/2022 05:19:22 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=24
05/26/2022 05:19:24 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=24
05/26/2022 05:19:27 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 05:20:14 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.5138826833104586 on epoch=24
05/26/2022 05:20:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/26/2022 05:20:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
05/26/2022 05:20:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=25
05/26/2022 05:20:25 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=25
05/26/2022 05:20:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/26/2022 05:21:15 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.488179903531238 on epoch=25
05/26/2022 05:21:18 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/26/2022 05:21:20 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/26/2022 05:21:23 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
05/26/2022 05:21:25 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
05/26/2022 05:21:28 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.18 on epoch=25
05/26/2022 05:22:17 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.49979434064335665 on epoch=25
05/26/2022 05:22:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/26/2022 05:22:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/26/2022 05:22:25 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
05/26/2022 05:22:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
05/26/2022 05:22:30 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
05/26/2022 05:23:17 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.4290763672929664 on epoch=26
05/26/2022 05:23:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
05/26/2022 05:23:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=26
05/26/2022 05:23:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/26/2022 05:23:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/26/2022 05:23:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=26
05/26/2022 05:23:31 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 05:23:31 - INFO - __main__ - Printing 3 examples
05/26/2022 05:23:31 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 05:23:31 - INFO - __main__ - ['Animal']
05/26/2022 05:23:31 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 05:23:31 - INFO - __main__ - ['Animal']
05/26/2022 05:23:31 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 05:23:31 - INFO - __main__ - ['Animal']
05/26/2022 05:23:31 - INFO - __main__ - Tokenizing Input ...
05/26/2022 05:23:32 - INFO - __main__ - Tokenizing Output ...
05/26/2022 05:23:34 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 05:23:34 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 05:23:34 - INFO - __main__ - Printing 3 examples
05/26/2022 05:23:34 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 05:23:34 - INFO - __main__ - ['Animal']
05/26/2022 05:23:34 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 05:23:34 - INFO - __main__ - ['Animal']
05/26/2022 05:23:34 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 05:23:34 - INFO - __main__ - ['Animal']
05/26/2022 05:23:34 - INFO - __main__ - Tokenizing Input ...
05/26/2022 05:23:35 - INFO - __main__ - Tokenizing Output ...
05/26/2022 05:23:37 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 05:23:52 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 05:23:52 - INFO - __main__ - task name: dbpedia_14
05/26/2022 05:23:53 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 05:23:53 - INFO - __main__ - Starting training!
05/26/2022 05:24:20 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.5456271895886838 on epoch=26
05/26/2022 05:24:20 - INFO - __main__ - save last model!
05/26/2022 05:24:21 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 05:24:21 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 05:24:21 - INFO - __main__ - Printing 3 examples
05/26/2022 05:24:21 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 05:24:21 - INFO - __main__ - ['Animal']
05/26/2022 05:24:21 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 05:24:21 - INFO - __main__ - ['Animal']
05/26/2022 05:24:21 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 05:24:21 - INFO - __main__ - ['Village']
05/26/2022 05:24:21 - INFO - __main__ - Tokenizing Input ...
05/26/2022 05:24:22 - INFO - __main__ - Tokenizing Output ...
05/26/2022 05:24:26 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 05:26:33 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.5_8_predictions.txt
05/26/2022 05:26:33 - INFO - __main__ - Classification-F1 on test data: 0.4144
05/26/2022 05:26:33 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.5, bsz=8, dev_performance=0.7212938983541249, test_performance=0.4143929889790586
05/26/2022 05:26:33 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.4, bsz=8 ...
05/26/2022 05:26:34 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 05:26:34 - INFO - __main__ - Printing 3 examples
05/26/2022 05:26:34 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 05:26:34 - INFO - __main__ - ['Animal']
05/26/2022 05:26:34 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 05:26:34 - INFO - __main__ - ['Animal']
05/26/2022 05:26:34 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 05:26:34 - INFO - __main__ - ['Animal']
05/26/2022 05:26:34 - INFO - __main__ - Tokenizing Input ...
05/26/2022 05:26:35 - INFO - __main__ - Tokenizing Output ...
05/26/2022 05:26:37 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 05:26:37 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 05:26:37 - INFO - __main__ - Printing 3 examples
05/26/2022 05:26:37 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 05:26:37 - INFO - __main__ - ['Animal']
05/26/2022 05:26:37 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 05:26:37 - INFO - __main__ - ['Animal']
05/26/2022 05:26:37 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 05:26:37 - INFO - __main__ - ['Animal']
05/26/2022 05:26:37 - INFO - __main__ - Tokenizing Input ...
05/26/2022 05:26:38 - INFO - __main__ - Tokenizing Output ...
05/26/2022 05:26:40 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 05:26:56 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 05:26:56 - INFO - __main__ - task name: dbpedia_14
05/26/2022 05:26:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 05:26:57 - INFO - __main__ - Starting training!
05/26/2022 05:27:00 - INFO - __main__ - Step 10 Global step 10 Train loss 6.55 on epoch=0
05/26/2022 05:27:02 - INFO - __main__ - Step 20 Global step 20 Train loss 5.07 on epoch=0
05/26/2022 05:27:05 - INFO - __main__ - Step 30 Global step 30 Train loss 3.47 on epoch=0
05/26/2022 05:27:07 - INFO - __main__ - Step 40 Global step 40 Train loss 2.72 on epoch=0
05/26/2022 05:27:10 - INFO - __main__ - Step 50 Global step 50 Train loss 2.20 on epoch=0
05/26/2022 05:28:24 - INFO - __main__ - Global step 50 Train loss 4.00 Classification-F1 0.08413626235490784 on epoch=0
05/26/2022 05:28:24 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08413626235490784 on epoch=0, global_step=50
05/26/2022 05:28:27 - INFO - __main__ - Step 60 Global step 60 Train loss 1.52 on epoch=0
05/26/2022 05:28:30 - INFO - __main__ - Step 70 Global step 70 Train loss 1.24 on epoch=0
05/26/2022 05:28:32 - INFO - __main__ - Step 80 Global step 80 Train loss 1.17 on epoch=0
05/26/2022 05:28:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.13 on epoch=0
05/26/2022 05:28:37 - INFO - __main__ - Step 100 Global step 100 Train loss 0.96 on epoch=0
05/26/2022 05:29:37 - INFO - __main__ - Global step 100 Train loss 1.20 Classification-F1 0.23612888787314082 on epoch=0
05/26/2022 05:29:37 - INFO - __main__ - Saving model with best Classification-F1: 0.08413626235490784 -> 0.23612888787314082 on epoch=0, global_step=100
05/26/2022 05:29:39 - INFO - __main__ - Step 110 Global step 110 Train loss 1.05 on epoch=0
05/26/2022 05:29:42 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=1
05/26/2022 05:29:44 - INFO - __main__ - Step 130 Global step 130 Train loss 0.66 on epoch=1
05/26/2022 05:29:47 - INFO - __main__ - Step 140 Global step 140 Train loss 0.70 on epoch=1
05/26/2022 05:29:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.75 on epoch=1
05/26/2022 05:30:57 - INFO - __main__ - Global step 150 Train loss 0.80 Classification-F1 0.2827281943063985 on epoch=1
05/26/2022 05:30:57 - INFO - __main__ - Saving model with best Classification-F1: 0.23612888787314082 -> 0.2827281943063985 on epoch=1, global_step=150
05/26/2022 05:31:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.74 on epoch=1
05/26/2022 05:31:02 - INFO - __main__ - Step 170 Global step 170 Train loss 0.77 on epoch=1
05/26/2022 05:31:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=1
05/26/2022 05:31:07 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=1
05/26/2022 05:31:10 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=1
05/26/2022 05:32:16 - INFO - __main__ - Global step 200 Train loss 0.73 Classification-F1 0.25417599174962857 on epoch=1
05/26/2022 05:32:18 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=1
05/26/2022 05:32:21 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=1
05/26/2022 05:32:23 - INFO - __main__ - Step 230 Global step 230 Train loss 0.50 on epoch=2
05/26/2022 05:32:26 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=2
05/26/2022 05:32:29 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=2
05/26/2022 05:33:23 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.3596322730064506 on epoch=2
05/26/2022 05:33:23 - INFO - __main__ - Saving model with best Classification-F1: 0.2827281943063985 -> 0.3596322730064506 on epoch=2, global_step=250
05/26/2022 05:33:26 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=2
05/26/2022 05:33:28 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=2
05/26/2022 05:33:31 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=2
05/26/2022 05:33:34 - INFO - __main__ - Step 290 Global step 290 Train loss 0.48 on epoch=2
05/26/2022 05:33:36 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=2
05/26/2022 05:34:32 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.2960318024765004 on epoch=2
05/26/2022 05:34:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=2
05/26/2022 05:34:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=2
05/26/2022 05:34:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=2
05/26/2022 05:34:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=3
05/26/2022 05:34:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=3
05/26/2022 05:35:55 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.334054482224814 on epoch=3
05/26/2022 05:35:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.36 on epoch=3
05/26/2022 05:36:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.49 on epoch=3
05/26/2022 05:36:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.43 on epoch=3
05/26/2022 05:36:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=3
05/26/2022 05:36:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=3
05/26/2022 05:37:02 - INFO - __main__ - Global step 400 Train loss 0.42 Classification-F1 0.5121894542729922 on epoch=3
05/26/2022 05:37:02 - INFO - __main__ - Saving model with best Classification-F1: 0.3596322730064506 -> 0.5121894542729922 on epoch=3, global_step=400
05/26/2022 05:37:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.39 on epoch=3
05/26/2022 05:37:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=3
05/26/2022 05:37:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=3
05/26/2022 05:37:13 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=3
05/26/2022 05:37:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=4
05/26/2022 05:38:18 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.4939381632022387 on epoch=4
05/26/2022 05:38:20 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=4
05/26/2022 05:38:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.29 on epoch=4
05/26/2022 05:38:25 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=4
05/26/2022 05:38:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=4
05/26/2022 05:38:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.42 on epoch=4
05/26/2022 05:39:39 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.5073842950446165 on epoch=4
05/26/2022 05:39:42 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
05/26/2022 05:39:44 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=4
05/26/2022 05:39:47 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=4
05/26/2022 05:39:49 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=4
05/26/2022 05:39:52 - INFO - __main__ - Step 550 Global step 550 Train loss 0.31 on epoch=4
05/26/2022 05:40:58 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.5666581567130292 on epoch=4
05/26/2022 05:40:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5121894542729922 -> 0.5666581567130292 on epoch=4, global_step=550
05/26/2022 05:41:01 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=4
05/26/2022 05:41:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
05/26/2022 05:41:06 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=5
05/26/2022 05:41:08 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=5
05/26/2022 05:41:11 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=5
05/26/2022 05:42:08 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.41347638950100624 on epoch=5
05/26/2022 05:42:10 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=5
05/26/2022 05:42:13 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=5
05/26/2022 05:42:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.21 on epoch=5
05/26/2022 05:42:18 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
05/26/2022 05:42:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=5
05/26/2022 05:43:20 - INFO - __main__ - Global step 650 Train loss 0.24 Classification-F1 0.3963290377944529 on epoch=5
05/26/2022 05:43:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=5
05/26/2022 05:43:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=5
05/26/2022 05:43:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=6
05/26/2022 05:43:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=6
05/26/2022 05:43:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=6
05/26/2022 05:44:25 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.4132092220364457 on epoch=6
05/26/2022 05:44:27 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=6
05/26/2022 05:44:30 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=6
05/26/2022 05:44:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.27 on epoch=6
05/26/2022 05:44:35 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=6
05/26/2022 05:44:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=6
05/26/2022 05:45:30 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.5893812592262355 on epoch=6
05/26/2022 05:45:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5666581567130292 -> 0.5893812592262355 on epoch=6, global_step=750
05/26/2022 05:45:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.23 on epoch=6
05/26/2022 05:45:35 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=6
05/26/2022 05:45:38 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=6
05/26/2022 05:45:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=7
05/26/2022 05:45:43 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/26/2022 05:46:38 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.5069157223983556 on epoch=7
05/26/2022 05:46:41 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=7
05/26/2022 05:46:43 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=7
05/26/2022 05:46:46 - INFO - __main__ - Step 830 Global step 830 Train loss 0.10 on epoch=7
05/26/2022 05:46:48 - INFO - __main__ - Step 840 Global step 840 Train loss 0.24 on epoch=7
05/26/2022 05:46:51 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
05/26/2022 05:47:50 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.5980796089733639 on epoch=7
05/26/2022 05:47:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5893812592262355 -> 0.5980796089733639 on epoch=7, global_step=850
05/26/2022 05:47:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=7
05/26/2022 05:47:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=7
05/26/2022 05:47:58 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
05/26/2022 05:48:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=7
05/26/2022 05:48:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=8
05/26/2022 05:48:55 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.6096519714410755 on epoch=8
05/26/2022 05:48:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5980796089733639 -> 0.6096519714410755 on epoch=8, global_step=900
05/26/2022 05:48:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=8
05/26/2022 05:49:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=8
05/26/2022 05:49:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=8
05/26/2022 05:49:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
05/26/2022 05:49:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=8
05/26/2022 05:49:58 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.5025972931175218 on epoch=8
05/26/2022 05:50:00 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=8
05/26/2022 05:50:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=8
05/26/2022 05:50:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
05/26/2022 05:50:08 - INFO - __main__ - Step 990 Global step 990 Train loss 0.23 on epoch=8
05/26/2022 05:50:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=8
05/26/2022 05:51:01 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5971807528262092 on epoch=8
05/26/2022 05:51:03 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=9
05/26/2022 05:51:06 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=9
05/26/2022 05:51:09 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=9
05/26/2022 05:51:11 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=9
05/26/2022 05:51:14 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=9
05/26/2022 05:52:06 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.4339036688299999 on epoch=9
05/26/2022 05:52:09 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=9
05/26/2022 05:52:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/26/2022 05:52:14 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
05/26/2022 05:52:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=9
05/26/2022 05:52:19 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
05/26/2022 05:53:15 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.5770818285160716 on epoch=9
05/26/2022 05:53:18 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=9
05/26/2022 05:53:21 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=9
05/26/2022 05:53:23 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.04 on epoch=10
05/26/2022 05:53:26 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/26/2022 05:53:28 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=10
05/26/2022 05:54:20 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.4085101690049096 on epoch=10
05/26/2022 05:54:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=10
05/26/2022 05:54:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
05/26/2022 05:54:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=10
05/26/2022 05:54:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
05/26/2022 05:54:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=10
05/26/2022 05:55:27 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.6188941481761572 on epoch=10
05/26/2022 05:55:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6096519714410755 -> 0.6188941481761572 on epoch=10, global_step=1200
05/26/2022 05:55:30 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
05/26/2022 05:55:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=10
05/26/2022 05:55:35 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=10
05/26/2022 05:55:38 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=11
05/26/2022 05:55:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/26/2022 05:56:33 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6951662486057899 on epoch=11
05/26/2022 05:56:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6188941481761572 -> 0.6951662486057899 on epoch=11, global_step=1250
05/26/2022 05:56:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/26/2022 05:56:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
05/26/2022 05:56:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=11
05/26/2022 05:56:44 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=11
05/26/2022 05:56:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=11
05/26/2022 05:57:33 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.4401036415375249 on epoch=11
05/26/2022 05:57:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=11
05/26/2022 05:57:38 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=11
05/26/2022 05:57:41 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=11
05/26/2022 05:57:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=11
05/26/2022 05:57:46 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=12
05/26/2022 05:58:44 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.6258706121949852 on epoch=12
05/26/2022 05:58:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
05/26/2022 05:58:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.13 on epoch=12
05/26/2022 05:58:52 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=12
05/26/2022 05:58:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=12
05/26/2022 05:58:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
05/26/2022 05:59:48 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.596415426006398 on epoch=12
05/26/2022 05:59:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=12
05/26/2022 05:59:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=12
05/26/2022 05:59:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
05/26/2022 05:59:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=12
05/26/2022 06:00:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
05/26/2022 06:00:52 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.5744514109604819 on epoch=12
05/26/2022 06:00:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
05/26/2022 06:00:58 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=13
05/26/2022 06:01:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
05/26/2022 06:01:03 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=13
05/26/2022 06:01:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=13
05/26/2022 06:01:54 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5153586070841994 on epoch=13
05/26/2022 06:01:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=13
05/26/2022 06:02:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=13
05/26/2022 06:02:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=13
05/26/2022 06:02:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=13
05/26/2022 06:02:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=13
05/26/2022 06:02:59 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.5736118451102108 on epoch=13
05/26/2022 06:03:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=13
05/26/2022 06:03:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/26/2022 06:03:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=14
05/26/2022 06:03:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/26/2022 06:03:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=14
05/26/2022 06:04:09 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.4863930261400199 on epoch=14
05/26/2022 06:04:12 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/26/2022 06:04:14 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=14
05/26/2022 06:04:17 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=14
05/26/2022 06:04:20 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/26/2022 06:04:22 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=14
05/26/2022 06:05:13 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.521893245032701 on epoch=14
05/26/2022 06:05:16 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=14
05/26/2022 06:05:18 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/26/2022 06:05:21 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=14
05/26/2022 06:05:24 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
05/26/2022 06:05:26 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/26/2022 06:06:19 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.48780655378142607 on epoch=15
05/26/2022 06:06:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=15
05/26/2022 06:06:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=15
05/26/2022 06:06:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=15
05/26/2022 06:06:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=15
05/26/2022 06:06:32 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=15
05/26/2022 06:07:22 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.527297543790175 on epoch=15
05/26/2022 06:07:25 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/26/2022 06:07:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=15
05/26/2022 06:07:30 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=15
05/26/2022 06:07:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=15
05/26/2022 06:07:35 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=16
05/26/2022 06:08:27 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.6288542882522312 on epoch=16
05/26/2022 06:08:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=16
05/26/2022 06:08:32 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
05/26/2022 06:08:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
05/26/2022 06:08:37 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/26/2022 06:08:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
05/26/2022 06:09:29 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5264672087379882 on epoch=16
05/26/2022 06:09:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.05 on epoch=16
05/26/2022 06:09:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/26/2022 06:09:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=16
05/26/2022 06:09:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=16
05/26/2022 06:09:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=16
05/26/2022 06:10:32 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.5551033892042571 on epoch=16
05/26/2022 06:10:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=17
05/26/2022 06:10:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/26/2022 06:10:40 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=17
05/26/2022 06:10:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
05/26/2022 06:10:45 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=17
05/26/2022 06:11:35 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.5045077190186783 on epoch=17
05/26/2022 06:11:38 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
05/26/2022 06:11:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/26/2022 06:11:43 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/26/2022 06:11:46 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/26/2022 06:11:48 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.17 on epoch=17
05/26/2022 06:12:42 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.4663082310329588 on epoch=17
05/26/2022 06:12:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/26/2022 06:12:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/26/2022 06:12:50 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=18
05/26/2022 06:12:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/26/2022 06:12:55 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=18
05/26/2022 06:13:47 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.5213291310351036 on epoch=18
05/26/2022 06:13:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=18
05/26/2022 06:13:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.14 on epoch=18
05/26/2022 06:13:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
05/26/2022 06:13:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=18
05/26/2022 06:14:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=18
05/26/2022 06:14:52 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6443498637862849 on epoch=18
05/26/2022 06:14:55 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=18
05/26/2022 06:14:58 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
05/26/2022 06:15:01 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/26/2022 06:15:03 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/26/2022 06:15:06 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
05/26/2022 06:15:56 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.45252624239789074 on epoch=19
05/26/2022 06:15:59 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.05 on epoch=19
05/26/2022 06:16:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=19
05/26/2022 06:16:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=19
05/26/2022 06:16:07 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=19
05/26/2022 06:16:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
05/26/2022 06:16:59 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.4201997202146622 on epoch=19
05/26/2022 06:17:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/26/2022 06:17:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
05/26/2022 06:17:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=19
05/26/2022 06:17:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=19
05/26/2022 06:17:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
05/26/2022 06:18:04 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.4117577539094837 on epoch=20
05/26/2022 06:18:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=20
05/26/2022 06:18:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=20
05/26/2022 06:18:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
05/26/2022 06:18:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.12 on epoch=20
05/26/2022 06:18:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/26/2022 06:19:09 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.4683407903360434 on epoch=20
05/26/2022 06:19:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=20
05/26/2022 06:19:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 06:19:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=20
05/26/2022 06:19:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
05/26/2022 06:19:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
05/26/2022 06:20:16 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.4727672533744552 on epoch=20
05/26/2022 06:20:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/26/2022 06:20:22 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/26/2022 06:20:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
05/26/2022 06:20:27 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=21
05/26/2022 06:20:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=21
05/26/2022 06:21:17 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.4663986273519548 on epoch=21
05/26/2022 06:21:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/26/2022 06:21:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/26/2022 06:21:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=21
05/26/2022 06:21:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=21
05/26/2022 06:21:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.09 on epoch=21
05/26/2022 06:22:18 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.5785911988473182 on epoch=21
05/26/2022 06:22:21 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=21
05/26/2022 06:22:23 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
05/26/2022 06:22:26 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=22
05/26/2022 06:22:28 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
05/26/2022 06:22:31 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=22
05/26/2022 06:23:17 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.5858414742042075 on epoch=22
05/26/2022 06:23:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/26/2022 06:23:22 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.10 on epoch=22
05/26/2022 06:23:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
05/26/2022 06:23:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/26/2022 06:23:30 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=22
05/26/2022 06:24:21 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6289441810215414 on epoch=22
05/26/2022 06:24:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.15 on epoch=22
05/26/2022 06:24:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/26/2022 06:24:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/26/2022 06:24:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/26/2022 06:24:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/26/2022 06:25:25 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.5566490545476196 on epoch=23
05/26/2022 06:25:28 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=23
05/26/2022 06:25:30 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=23
05/26/2022 06:25:33 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=23
05/26/2022 06:25:36 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 06:25:38 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/26/2022 06:26:27 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6542480176712875 on epoch=23
05/26/2022 06:26:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/26/2022 06:26:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=23
05/26/2022 06:26:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
05/26/2022 06:26:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/26/2022 06:26:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/26/2022 06:27:33 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6901442761752508 on epoch=24
05/26/2022 06:27:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/26/2022 06:27:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=24
05/26/2022 06:27:41 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/26/2022 06:27:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/26/2022 06:27:46 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/26/2022 06:28:35 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.5748541783540824 on epoch=24
05/26/2022 06:28:37 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/26/2022 06:28:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 06:28:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=24
05/26/2022 06:28:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=24
05/26/2022 06:28:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 06:29:38 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.5835446505077919 on epoch=24
05/26/2022 06:29:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/26/2022 06:29:44 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
05/26/2022 06:29:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=25
05/26/2022 06:29:49 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 06:29:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/26/2022 06:30:40 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6159337881320748 on epoch=25
05/26/2022 06:30:42 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 06:30:45 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/26/2022 06:30:48 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=25
05/26/2022 06:30:50 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/26/2022 06:30:53 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/26/2022 06:31:43 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.5344714859020349 on epoch=25
05/26/2022 06:31:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/26/2022 06:31:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/26/2022 06:31:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/26/2022 06:31:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 06:31:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
05/26/2022 06:32:45 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.4772921651014854 on epoch=26
05/26/2022 06:32:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/26/2022 06:32:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=26
05/26/2022 06:32:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=26
05/26/2022 06:32:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/26/2022 06:32:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=26
05/26/2022 06:32:59 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 06:32:59 - INFO - __main__ - Printing 3 examples
05/26/2022 06:32:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 06:32:59 - INFO - __main__ - ['Animal']
05/26/2022 06:32:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 06:32:59 - INFO - __main__ - ['Animal']
05/26/2022 06:32:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 06:32:59 - INFO - __main__ - ['Animal']
05/26/2022 06:32:59 - INFO - __main__ - Tokenizing Input ...
05/26/2022 06:33:00 - INFO - __main__ - Tokenizing Output ...
05/26/2022 06:33:02 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 06:33:02 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 06:33:02 - INFO - __main__ - Printing 3 examples
05/26/2022 06:33:02 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 06:33:02 - INFO - __main__ - ['Animal']
05/26/2022 06:33:02 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 06:33:02 - INFO - __main__ - ['Animal']
05/26/2022 06:33:02 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 06:33:02 - INFO - __main__ - ['Animal']
05/26/2022 06:33:02 - INFO - __main__ - Tokenizing Input ...
05/26/2022 06:33:03 - INFO - __main__ - Tokenizing Output ...
05/26/2022 06:33:05 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 06:33:23 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 06:33:23 - INFO - __main__ - task name: dbpedia_14
05/26/2022 06:33:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 06:33:24 - INFO - __main__ - Starting training!
05/26/2022 06:33:47 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.48266078332583157 on epoch=26
05/26/2022 06:33:47 - INFO - __main__ - save last model!
05/26/2022 06:33:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 06:33:47 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 06:33:47 - INFO - __main__ - Printing 3 examples
05/26/2022 06:33:47 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 06:33:47 - INFO - __main__ - ['Animal']
05/26/2022 06:33:47 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 06:33:47 - INFO - __main__ - ['Animal']
05/26/2022 06:33:47 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 06:33:47 - INFO - __main__ - ['Village']
05/26/2022 06:33:47 - INFO - __main__ - Tokenizing Input ...
05/26/2022 06:33:49 - INFO - __main__ - Tokenizing Output ...
05/26/2022 06:33:52 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 06:35:41 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.4_8_predictions.txt
05/26/2022 06:35:41 - INFO - __main__ - Classification-F1 on test data: 0.3642
05/26/2022 06:35:41 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.4, bsz=8, dev_performance=0.6951662486057899, test_performance=0.36420180919376294
05/26/2022 06:35:41 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.3, bsz=8 ...
05/26/2022 06:35:42 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 06:35:42 - INFO - __main__ - Printing 3 examples
05/26/2022 06:35:42 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 06:35:42 - INFO - __main__ - ['Animal']
05/26/2022 06:35:42 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 06:35:42 - INFO - __main__ - ['Animal']
05/26/2022 06:35:42 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 06:35:42 - INFO - __main__ - ['Animal']
05/26/2022 06:35:42 - INFO - __main__ - Tokenizing Input ...
05/26/2022 06:35:43 - INFO - __main__ - Tokenizing Output ...
05/26/2022 06:35:45 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 06:35:45 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 06:35:45 - INFO - __main__ - Printing 3 examples
05/26/2022 06:35:45 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 06:35:45 - INFO - __main__ - ['Animal']
05/26/2022 06:35:45 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 06:35:45 - INFO - __main__ - ['Animal']
05/26/2022 06:35:45 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 06:35:45 - INFO - __main__ - ['Animal']
05/26/2022 06:35:45 - INFO - __main__ - Tokenizing Input ...
05/26/2022 06:35:46 - INFO - __main__ - Tokenizing Output ...
05/26/2022 06:35:47 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 06:36:06 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 06:36:06 - INFO - __main__ - task name: dbpedia_14
05/26/2022 06:36:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 06:36:07 - INFO - __main__ - Starting training!
05/26/2022 06:36:10 - INFO - __main__ - Step 10 Global step 10 Train loss 6.89 on epoch=0
05/26/2022 06:36:13 - INFO - __main__ - Step 20 Global step 20 Train loss 5.92 on epoch=0
05/26/2022 06:36:15 - INFO - __main__ - Step 30 Global step 30 Train loss 4.55 on epoch=0
05/26/2022 06:36:18 - INFO - __main__ - Step 40 Global step 40 Train loss 3.67 on epoch=0
05/26/2022 06:36:21 - INFO - __main__ - Step 50 Global step 50 Train loss 3.03 on epoch=0
05/26/2022 06:37:22 - INFO - __main__ - Global step 50 Train loss 4.81 Classification-F1 0.054488264860019425 on epoch=0
05/26/2022 06:37:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.054488264860019425 on epoch=0, global_step=50
05/26/2022 06:37:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.38 on epoch=0
05/26/2022 06:37:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.99 on epoch=0
05/26/2022 06:37:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.69 on epoch=0
05/26/2022 06:37:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.58 on epoch=0
05/26/2022 06:37:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.40 on epoch=0
05/26/2022 06:38:32 - INFO - __main__ - Global step 100 Train loss 1.81 Classification-F1 0.24712511598785533 on epoch=0
05/26/2022 06:38:32 - INFO - __main__ - Saving model with best Classification-F1: 0.054488264860019425 -> 0.24712511598785533 on epoch=0, global_step=100
05/26/2022 06:38:34 - INFO - __main__ - Step 110 Global step 110 Train loss 1.16 on epoch=0
05/26/2022 06:38:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.13 on epoch=1
05/26/2022 06:38:40 - INFO - __main__ - Step 130 Global step 130 Train loss 0.98 on epoch=1
05/26/2022 06:38:42 - INFO - __main__ - Step 140 Global step 140 Train loss 0.95 on epoch=1
05/26/2022 06:38:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.09 on epoch=1
05/26/2022 06:39:38 - INFO - __main__ - Global step 150 Train loss 1.06 Classification-F1 0.29961568116779874 on epoch=1
05/26/2022 06:39:38 - INFO - __main__ - Saving model with best Classification-F1: 0.24712511598785533 -> 0.29961568116779874 on epoch=1, global_step=150
05/26/2022 06:39:40 - INFO - __main__ - Step 160 Global step 160 Train loss 1.09 on epoch=1
05/26/2022 06:39:43 - INFO - __main__ - Step 170 Global step 170 Train loss 0.95 on epoch=1
05/26/2022 06:39:46 - INFO - __main__ - Step 180 Global step 180 Train loss 0.82 on epoch=1
05/26/2022 06:39:48 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=1
05/26/2022 06:39:51 - INFO - __main__ - Step 200 Global step 200 Train loss 0.92 on epoch=1
05/26/2022 06:40:54 - INFO - __main__ - Global step 200 Train loss 0.93 Classification-F1 0.2914687640957522 on epoch=1
05/26/2022 06:40:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.88 on epoch=1
05/26/2022 06:40:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.95 on epoch=1
05/26/2022 06:41:02 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=2
05/26/2022 06:41:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=2
05/26/2022 06:41:07 - INFO - __main__ - Step 250 Global step 250 Train loss 0.74 on epoch=2
05/26/2022 06:42:05 - INFO - __main__ - Global step 250 Train loss 0.81 Classification-F1 0.3699393343569344 on epoch=2
05/26/2022 06:42:05 - INFO - __main__ - Saving model with best Classification-F1: 0.29961568116779874 -> 0.3699393343569344 on epoch=2, global_step=250
05/26/2022 06:42:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=2
05/26/2022 06:42:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=2
05/26/2022 06:42:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.79 on epoch=2
05/26/2022 06:42:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=2
05/26/2022 06:42:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.70 on epoch=2
05/26/2022 06:43:17 - INFO - __main__ - Global step 300 Train loss 0.72 Classification-F1 0.4505025061020698 on epoch=2
05/26/2022 06:43:17 - INFO - __main__ - Saving model with best Classification-F1: 0.3699393343569344 -> 0.4505025061020698 on epoch=2, global_step=300
05/26/2022 06:43:19 - INFO - __main__ - Step 310 Global step 310 Train loss 0.65 on epoch=2
05/26/2022 06:43:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=2
05/26/2022 06:43:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.72 on epoch=2
05/26/2022 06:43:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=3
05/26/2022 06:43:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.53 on epoch=3
05/26/2022 06:44:28 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.5745885715654915 on epoch=3
05/26/2022 06:44:28 - INFO - __main__ - Saving model with best Classification-F1: 0.4505025061020698 -> 0.5745885715654915 on epoch=3, global_step=350
05/26/2022 06:44:31 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=3
05/26/2022 06:44:33 - INFO - __main__ - Step 370 Global step 370 Train loss 0.71 on epoch=3
05/26/2022 06:44:36 - INFO - __main__ - Step 380 Global step 380 Train loss 0.59 on epoch=3
05/26/2022 06:44:38 - INFO - __main__ - Step 390 Global step 390 Train loss 0.65 on epoch=3
05/26/2022 06:44:41 - INFO - __main__ - Step 400 Global step 400 Train loss 0.66 on epoch=3
05/26/2022 06:45:43 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.5495203283679839 on epoch=3
05/26/2022 06:45:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.60 on epoch=3
05/26/2022 06:45:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.60 on epoch=3
05/26/2022 06:45:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.60 on epoch=3
05/26/2022 06:45:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.54 on epoch=3
05/26/2022 06:45:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.45 on epoch=4
05/26/2022 06:46:54 - INFO - __main__ - Global step 450 Train loss 0.56 Classification-F1 0.5008960063035641 on epoch=4
05/26/2022 06:46:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.46 on epoch=4
05/26/2022 06:46:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.40 on epoch=4
05/26/2022 06:47:02 - INFO - __main__ - Step 480 Global step 480 Train loss 0.62 on epoch=4
05/26/2022 06:47:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=4
05/26/2022 06:47:07 - INFO - __main__ - Step 500 Global step 500 Train loss 0.60 on epoch=4
05/26/2022 06:47:59 - INFO - __main__ - Global step 500 Train loss 0.50 Classification-F1 0.5215454385529 on epoch=4
05/26/2022 06:48:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.42 on epoch=4
05/26/2022 06:48:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.46 on epoch=4
05/26/2022 06:48:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=4
05/26/2022 06:48:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.56 on epoch=4
05/26/2022 06:48:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=4
05/26/2022 06:49:07 - INFO - __main__ - Global step 550 Train loss 0.46 Classification-F1 0.5389940834868735 on epoch=4
05/26/2022 06:49:10 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=4
05/26/2022 06:49:13 - INFO - __main__ - Step 570 Global step 570 Train loss 0.47 on epoch=5
05/26/2022 06:49:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=5
05/26/2022 06:49:18 - INFO - __main__ - Step 590 Global step 590 Train loss 0.49 on epoch=5
05/26/2022 06:49:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=5
05/26/2022 06:50:13 - INFO - __main__ - Global step 600 Train loss 0.42 Classification-F1 0.4995454607311018 on epoch=5
05/26/2022 06:50:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.55 on epoch=5
05/26/2022 06:50:18 - INFO - __main__ - Step 620 Global step 620 Train loss 0.42 on epoch=5
05/26/2022 06:50:21 - INFO - __main__ - Step 630 Global step 630 Train loss 0.33 on epoch=5
05/26/2022 06:50:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=5
05/26/2022 06:50:26 - INFO - __main__ - Step 650 Global step 650 Train loss 0.47 on epoch=5
05/26/2022 06:51:21 - INFO - __main__ - Global step 650 Train loss 0.43 Classification-F1 0.45239037141857313 on epoch=5
05/26/2022 06:51:24 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=5
05/26/2022 06:51:27 - INFO - __main__ - Step 670 Global step 670 Train loss 0.38 on epoch=5
05/26/2022 06:51:29 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=6
05/26/2022 06:51:32 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=6
05/26/2022 06:51:34 - INFO - __main__ - Step 700 Global step 700 Train loss 0.39 on epoch=6
05/26/2022 06:52:27 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.5581070452520682 on epoch=6
05/26/2022 06:52:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=6
05/26/2022 06:52:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=6
05/26/2022 06:52:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=6
05/26/2022 06:52:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=6
05/26/2022 06:52:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=6
05/26/2022 06:53:34 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.6629647236237254 on epoch=6
05/26/2022 06:53:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5745885715654915 -> 0.6629647236237254 on epoch=6, global_step=750
05/26/2022 06:53:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=6
05/26/2022 06:53:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=6
05/26/2022 06:53:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=6
05/26/2022 06:53:45 - INFO - __main__ - Step 790 Global step 790 Train loss 0.25 on epoch=7
05/26/2022 06:53:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=7
05/26/2022 06:54:43 - INFO - __main__ - Global step 800 Train loss 0.30 Classification-F1 0.3869522698311469 on epoch=7
05/26/2022 06:54:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.29 on epoch=7
05/26/2022 06:54:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.29 on epoch=7
05/26/2022 06:54:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=7
05/26/2022 06:54:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=7
05/26/2022 06:54:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=7
05/26/2022 06:55:50 - INFO - __main__ - Global step 850 Train loss 0.28 Classification-F1 0.5015146007595538 on epoch=7
05/26/2022 06:55:52 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=7
05/26/2022 06:55:55 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=7
05/26/2022 06:55:57 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=7
05/26/2022 06:56:00 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=7
05/26/2022 06:56:03 - INFO - __main__ - Step 900 Global step 900 Train loss 0.21 on epoch=8
05/26/2022 06:56:52 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.5195098361824522 on epoch=8
05/26/2022 06:56:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=8
05/26/2022 06:56:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=8
05/26/2022 06:57:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=8
05/26/2022 06:57:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.21 on epoch=8
05/26/2022 06:57:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=8
05/26/2022 06:57:58 - INFO - __main__ - Global step 950 Train loss 0.24 Classification-F1 0.6076896568382254 on epoch=8
05/26/2022 06:58:01 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=8
05/26/2022 06:58:03 - INFO - __main__ - Step 970 Global step 970 Train loss 0.23 on epoch=8
05/26/2022 06:58:06 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=8
05/26/2022 06:58:09 - INFO - __main__ - Step 990 Global step 990 Train loss 0.37 on epoch=8
05/26/2022 06:58:11 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=8
05/26/2022 06:59:06 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.6139266383632714 on epoch=8
05/26/2022 06:59:09 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=9
05/26/2022 06:59:11 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=9
05/26/2022 06:59:14 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.23 on epoch=9
05/26/2022 06:59:16 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.26 on epoch=9
05/26/2022 06:59:19 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.17 on epoch=9
05/26/2022 07:00:12 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.6903375079097522 on epoch=9
05/26/2022 07:00:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6629647236237254 -> 0.6903375079097522 on epoch=9, global_step=1050
05/26/2022 07:00:15 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=9
05/26/2022 07:00:17 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=9
05/26/2022 07:00:20 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.22 on epoch=9
05/26/2022 07:00:22 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=9
05/26/2022 07:00:25 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.30 on epoch=9
05/26/2022 07:01:19 - INFO - __main__ - Global step 1100 Train loss 0.23 Classification-F1 0.49495922830331357 on epoch=9
05/26/2022 07:01:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=9
05/26/2022 07:01:24 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=9
05/26/2022 07:01:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=10
05/26/2022 07:01:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=10
05/26/2022 07:01:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=10
05/26/2022 07:02:22 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.5670297545586841 on epoch=10
05/26/2022 07:02:24 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=10
05/26/2022 07:02:27 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.24 on epoch=10
05/26/2022 07:02:29 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.26 on epoch=10
05/26/2022 07:02:32 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=10
05/26/2022 07:02:35 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.17 on epoch=10
05/26/2022 07:03:28 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.6774786607622292 on epoch=10
05/26/2022 07:03:31 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=10
05/26/2022 07:03:33 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=10
05/26/2022 07:03:36 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=10
05/26/2022 07:03:39 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=11
05/26/2022 07:03:41 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=11
05/26/2022 07:04:32 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.5515768621079363 on epoch=11
05/26/2022 07:04:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.21 on epoch=11
05/26/2022 07:04:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.15 on epoch=11
05/26/2022 07:04:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.13 on epoch=11
05/26/2022 07:04:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=11
05/26/2022 07:04:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=11
05/26/2022 07:05:35 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.6480092631858657 on epoch=11
05/26/2022 07:05:38 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=11
05/26/2022 07:05:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=11
05/26/2022 07:05:43 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.22 on epoch=11
05/26/2022 07:05:46 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=11
05/26/2022 07:05:48 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=12
05/26/2022 07:06:41 - INFO - __main__ - Global step 1350 Train loss 0.19 Classification-F1 0.6173697562904839 on epoch=12
05/26/2022 07:06:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.13 on epoch=12
05/26/2022 07:06:46 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.20 on epoch=12
05/26/2022 07:06:49 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=12
05/26/2022 07:06:51 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.12 on epoch=12
05/26/2022 07:06:54 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.20 on epoch=12
05/26/2022 07:07:51 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.7125630013684038 on epoch=12
05/26/2022 07:07:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6903375079097522 -> 0.7125630013684038 on epoch=12, global_step=1400
05/26/2022 07:07:53 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.18 on epoch=12
05/26/2022 07:07:56 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=12
05/26/2022 07:07:58 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=12
05/26/2022 07:08:01 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.29 on epoch=12
05/26/2022 07:08:04 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
05/26/2022 07:09:01 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.712305046387983 on epoch=12
05/26/2022 07:09:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/26/2022 07:09:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
05/26/2022 07:09:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=13
05/26/2022 07:09:11 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.23 on epoch=13
05/26/2022 07:09:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
05/26/2022 07:10:04 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.6047545683277519 on epoch=13
05/26/2022 07:10:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=13
05/26/2022 07:10:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=13
05/26/2022 07:10:12 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=13
05/26/2022 07:10:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=13
05/26/2022 07:10:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.19 on epoch=13
05/26/2022 07:11:08 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5651904750249516 on epoch=13
05/26/2022 07:11:11 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.09 on epoch=13
05/26/2022 07:11:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=14
05/26/2022 07:11:16 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=14
05/26/2022 07:11:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=14
05/26/2022 07:11:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.19 on epoch=14
05/26/2022 07:12:13 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.6384480702092482 on epoch=14
05/26/2022 07:12:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=14
05/26/2022 07:12:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=14
05/26/2022 07:12:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=14
05/26/2022 07:12:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=14
05/26/2022 07:12:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/26/2022 07:13:19 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.8988540444720515 on epoch=14
05/26/2022 07:13:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7125630013684038 -> 0.8988540444720515 on epoch=14, global_step=1650
05/26/2022 07:13:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.19 on epoch=14
05/26/2022 07:13:24 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=14
05/26/2022 07:13:27 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=14
05/26/2022 07:13:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/26/2022 07:13:32 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/26/2022 07:14:25 - INFO - __main__ - Global step 1700 Train loss 0.12 Classification-F1 0.6178000111269564 on epoch=15
05/26/2022 07:14:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.18 on epoch=15
05/26/2022 07:14:30 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
05/26/2022 07:14:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=15
05/26/2022 07:14:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.10 on epoch=15
05/26/2022 07:14:38 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=15
05/26/2022 07:15:31 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.8523594917083901 on epoch=15
05/26/2022 07:15:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=15
05/26/2022 07:15:36 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=15
05/26/2022 07:15:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/26/2022 07:15:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=15
05/26/2022 07:15:44 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/26/2022 07:16:39 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7215849112990906 on epoch=16
05/26/2022 07:16:42 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/26/2022 07:16:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.19 on epoch=16
05/26/2022 07:16:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=16
05/26/2022 07:16:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=16
05/26/2022 07:16:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.15 on epoch=16
05/26/2022 07:17:45 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.7213717994126448 on epoch=16
05/26/2022 07:17:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=16
05/26/2022 07:17:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=16
05/26/2022 07:17:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
05/26/2022 07:17:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.12 on epoch=16
05/26/2022 07:17:59 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
05/26/2022 07:18:49 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.6725915417998016 on epoch=16
05/26/2022 07:18:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/26/2022 07:18:55 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=17
05/26/2022 07:18:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=17
05/26/2022 07:19:00 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=17
05/26/2022 07:19:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/26/2022 07:19:54 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5911062035097663 on epoch=17
05/26/2022 07:19:57 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=17
05/26/2022 07:19:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=17
05/26/2022 07:20:02 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
05/26/2022 07:20:05 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=17
05/26/2022 07:20:07 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=17
05/26/2022 07:20:57 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.7586512071013425 on epoch=17
05/26/2022 07:20:59 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=17
05/26/2022 07:21:02 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=18
05/26/2022 07:21:05 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
05/26/2022 07:21:07 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
05/26/2022 07:21:10 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.14 on epoch=18
05/26/2022 07:22:01 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.6702247855766124 on epoch=18
05/26/2022 07:22:04 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=18
05/26/2022 07:22:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=18
05/26/2022 07:22:09 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/26/2022 07:22:12 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
05/26/2022 07:22:14 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/26/2022 07:23:08 - INFO - __main__ - Global step 2100 Train loss 0.08 Classification-F1 0.7550255361771532 on epoch=18
05/26/2022 07:23:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.12 on epoch=18
05/26/2022 07:23:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=18
05/26/2022 07:23:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/26/2022 07:23:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=19
05/26/2022 07:23:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=19
05/26/2022 07:24:16 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.8064720268062902 on epoch=19
05/26/2022 07:24:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=19
05/26/2022 07:24:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/26/2022 07:24:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=19
05/26/2022 07:24:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/26/2022 07:24:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/26/2022 07:25:18 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.5174919012634983 on epoch=19
05/26/2022 07:25:20 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=19
05/26/2022 07:25:23 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
05/26/2022 07:25:26 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.11 on epoch=19
05/26/2022 07:25:28 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/26/2022 07:25:31 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/26/2022 07:26:23 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6274866798785135 on epoch=20
05/26/2022 07:26:25 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
05/26/2022 07:26:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
05/26/2022 07:26:30 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=20
05/26/2022 07:26:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/26/2022 07:26:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/26/2022 07:27:27 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.6746050003162851 on epoch=20
05/26/2022 07:27:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.08 on epoch=20
05/26/2022 07:27:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/26/2022 07:27:35 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.08 on epoch=20
05/26/2022 07:27:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=20
05/26/2022 07:27:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/26/2022 07:28:30 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.6445319247583604 on epoch=20
05/26/2022 07:28:32 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
05/26/2022 07:28:35 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/26/2022 07:28:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=21
05/26/2022 07:28:40 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.13 on epoch=21
05/26/2022 07:28:43 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
05/26/2022 07:29:33 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5799929286231571 on epoch=21
05/26/2022 07:29:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=21
05/26/2022 07:29:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/26/2022 07:29:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/26/2022 07:29:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.09 on epoch=21
05/26/2022 07:29:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
05/26/2022 07:30:37 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7989550804904199 on epoch=21
05/26/2022 07:30:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=21
05/26/2022 07:30:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/26/2022 07:30:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/26/2022 07:30:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
05/26/2022 07:30:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.11 on epoch=22
05/26/2022 07:31:40 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.49292611662081687 on epoch=22
05/26/2022 07:31:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=22
05/26/2022 07:31:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=22
05/26/2022 07:31:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=22
05/26/2022 07:31:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=22
05/26/2022 07:31:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.09 on epoch=22
05/26/2022 07:32:46 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7177744148788904 on epoch=22
05/26/2022 07:32:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.16 on epoch=22
05/26/2022 07:32:52 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/26/2022 07:32:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/26/2022 07:32:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/26/2022 07:32:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
05/26/2022 07:33:51 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.5500905529898675 on epoch=23
05/26/2022 07:33:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=23
05/26/2022 07:33:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 07:33:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=23
05/26/2022 07:34:01 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
05/26/2022 07:34:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=23
05/26/2022 07:34:52 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6228261239321199 on epoch=23
05/26/2022 07:34:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/26/2022 07:34:57 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=23
05/26/2022 07:35:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=23
05/26/2022 07:35:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/26/2022 07:35:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/26/2022 07:35:55 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6872286746657068 on epoch=24
05/26/2022 07:35:58 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=24
05/26/2022 07:36:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.07 on epoch=24
05/26/2022 07:36:03 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/26/2022 07:36:06 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=24
05/26/2022 07:36:08 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
05/26/2022 07:37:00 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8111130455954761 on epoch=24
05/26/2022 07:37:02 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=24
05/26/2022 07:37:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.08 on epoch=24
05/26/2022 07:37:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.09 on epoch=24
05/26/2022 07:37:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.12 on epoch=24
05/26/2022 07:37:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 07:38:02 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.8104465679969929 on epoch=24
05/26/2022 07:38:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=25
05/26/2022 07:38:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
05/26/2022 07:38:10 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.09 on epoch=25
05/26/2022 07:38:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=25
05/26/2022 07:38:15 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
05/26/2022 07:39:04 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7220306641305868 on epoch=25
05/26/2022 07:39:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.10 on epoch=25
05/26/2022 07:39:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=25
05/26/2022 07:39:12 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=25
05/26/2022 07:39:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=25
05/26/2022 07:39:17 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
05/26/2022 07:40:05 - INFO - __main__ - Global step 2900 Train loss 0.08 Classification-F1 0.7618111409592818 on epoch=25
05/26/2022 07:40:07 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/26/2022 07:40:10 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/26/2022 07:40:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/26/2022 07:40:15 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.11 on epoch=26
05/26/2022 07:40:18 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=26
05/26/2022 07:41:06 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.8584737640163935 on epoch=26
05/26/2022 07:41:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/26/2022 07:41:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 07:41:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=26
05/26/2022 07:41:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=26
05/26/2022 07:41:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/26/2022 07:41:20 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 07:41:20 - INFO - __main__ - Printing 3 examples
05/26/2022 07:41:20 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 07:41:20 - INFO - __main__ - ['Animal']
05/26/2022 07:41:20 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 07:41:20 - INFO - __main__ - ['Animal']
05/26/2022 07:41:20 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 07:41:20 - INFO - __main__ - ['Animal']
05/26/2022 07:41:20 - INFO - __main__ - Tokenizing Input ...
05/26/2022 07:41:21 - INFO - __main__ - Tokenizing Output ...
05/26/2022 07:41:23 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 07:41:23 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 07:41:23 - INFO - __main__ - Printing 3 examples
05/26/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 07:41:23 - INFO - __main__ - ['Animal']
05/26/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 07:41:23 - INFO - __main__ - ['Animal']
05/26/2022 07:41:23 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 07:41:23 - INFO - __main__ - ['Animal']
05/26/2022 07:41:23 - INFO - __main__ - Tokenizing Input ...
05/26/2022 07:41:24 - INFO - __main__ - Tokenizing Output ...
05/26/2022 07:41:25 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 07:41:41 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 07:41:41 - INFO - __main__ - task name: dbpedia_14
05/26/2022 07:41:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 07:41:42 - INFO - __main__ - Starting training!
05/26/2022 07:42:10 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7600963613083004 on epoch=26
05/26/2022 07:42:10 - INFO - __main__ - save last model!
05/26/2022 07:42:10 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 07:42:10 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 07:42:10 - INFO - __main__ - Printing 3 examples
05/26/2022 07:42:10 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 07:42:10 - INFO - __main__ - ['Animal']
05/26/2022 07:42:10 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 07:42:10 - INFO - __main__ - ['Animal']
05/26/2022 07:42:10 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 07:42:10 - INFO - __main__ - ['Village']
05/26/2022 07:42:10 - INFO - __main__ - Tokenizing Input ...
05/26/2022 07:42:12 - INFO - __main__ - Tokenizing Output ...
05/26/2022 07:42:15 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 07:44:28 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.3_8_predictions.txt
05/26/2022 07:44:29 - INFO - __main__ - Classification-F1 on test data: 0.6484
05/26/2022 07:44:29 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.3, bsz=8, dev_performance=0.8988540444720515, test_performance=0.6484252688143566
05/26/2022 07:44:29 - INFO - __main__ - Running ... prefix=dbpedia_14_128_13, lr=0.2, bsz=8 ...
05/26/2022 07:44:30 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 07:44:30 - INFO - __main__ - Printing 3 examples
05/26/2022 07:44:30 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/26/2022 07:44:30 - INFO - __main__ - ['Animal']
05/26/2022 07:44:30 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/26/2022 07:44:30 - INFO - __main__ - ['Animal']
05/26/2022 07:44:30 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/26/2022 07:44:30 - INFO - __main__ - ['Animal']
05/26/2022 07:44:30 - INFO - __main__ - Tokenizing Input ...
05/26/2022 07:44:31 - INFO - __main__ - Tokenizing Output ...
05/26/2022 07:44:33 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 07:44:33 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 07:44:33 - INFO - __main__ - Printing 3 examples
05/26/2022 07:44:33 - INFO - __main__ -  [dbpedia_14] The Andaman Treepie (Dendrocitta bayleyi) is a species of bird in the Corvidae family.It is endemic to the Andaman Islands of India.Its natural habitat is subtropical or tropical moist lowland forests. It is threatened by habitat loss.The scientific name commemorates the Anglo-Indian statesman Edward Clive Bayley.
05/26/2022 07:44:33 - INFO - __main__ - ['Animal']
05/26/2022 07:44:33 - INFO - __main__ -  [dbpedia_14] Ethmia tyranthes is a moth in the Ethmiidae family. It is found in the Democratic Republic of Congo.
05/26/2022 07:44:33 - INFO - __main__ - ['Animal']
05/26/2022 07:44:33 - INFO - __main__ -  [dbpedia_14] Van Son’s Brown (Stygionympha vansoni) is a butterfly of the Nymphalidae family. It is found in South Africa in the northern Cape from the Kamiesberg to the Springbok area.The wingspan is 36–38 mm for males and 38–40 mm for females. Adults are on wing from August to October. There is one generation per year.The larvae probably feed on Poaceae grasses.
05/26/2022 07:44:33 - INFO - __main__ - ['Animal']
05/26/2022 07:44:33 - INFO - __main__ - Tokenizing Input ...
05/26/2022 07:44:34 - INFO - __main__ - Tokenizing Output ...
05/26/2022 07:44:35 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 07:44:54 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 07:44:54 - INFO - __main__ - task name: dbpedia_14
05/26/2022 07:44:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 07:44:55 - INFO - __main__ - Starting training!
05/26/2022 07:44:58 - INFO - __main__ - Step 10 Global step 10 Train loss 6.95 on epoch=0
05/26/2022 07:45:00 - INFO - __main__ - Step 20 Global step 20 Train loss 6.18 on epoch=0
05/26/2022 07:45:03 - INFO - __main__ - Step 30 Global step 30 Train loss 5.45 on epoch=0
05/26/2022 07:45:06 - INFO - __main__ - Step 40 Global step 40 Train loss 4.78 on epoch=0
05/26/2022 07:45:08 - INFO - __main__ - Step 50 Global step 50 Train loss 3.85 on epoch=0
05/26/2022 07:53:21 - INFO - __main__ - Global step 50 Train loss 5.44 Classification-F1 0.0009530273170653754 on epoch=0
05/26/2022 07:53:21 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0009530273170653754 on epoch=0, global_step=50
05/26/2022 07:53:24 - INFO - __main__ - Step 60 Global step 60 Train loss 3.16 on epoch=0
05/26/2022 07:53:26 - INFO - __main__ - Step 70 Global step 70 Train loss 2.67 on epoch=0
05/26/2022 07:53:29 - INFO - __main__ - Step 80 Global step 80 Train loss 2.55 on epoch=0
05/26/2022 07:53:32 - INFO - __main__ - Step 90 Global step 90 Train loss 2.31 on epoch=0
05/26/2022 07:53:34 - INFO - __main__ - Step 100 Global step 100 Train loss 1.95 on epoch=0
05/26/2022 07:54:32 - INFO - __main__ - Global step 100 Train loss 2.53 Classification-F1 0.14660093831591806 on epoch=0
05/26/2022 07:54:32 - INFO - __main__ - Saving model with best Classification-F1: 0.0009530273170653754 -> 0.14660093831591806 on epoch=0, global_step=100
05/26/2022 07:54:35 - INFO - __main__ - Step 110 Global step 110 Train loss 1.91 on epoch=0
05/26/2022 07:54:37 - INFO - __main__ - Step 120 Global step 120 Train loss 1.58 on epoch=1
05/26/2022 07:54:40 - INFO - __main__ - Step 130 Global step 130 Train loss 1.45 on epoch=1
05/26/2022 07:54:43 - INFO - __main__ - Step 140 Global step 140 Train loss 1.49 on epoch=1
05/26/2022 07:54:45 - INFO - __main__ - Step 150 Global step 150 Train loss 1.43 on epoch=1
05/26/2022 07:55:50 - INFO - __main__ - Global step 150 Train loss 1.57 Classification-F1 0.23696591969543068 on epoch=1
05/26/2022 07:55:50 - INFO - __main__ - Saving model with best Classification-F1: 0.14660093831591806 -> 0.23696591969543068 on epoch=1, global_step=150
05/26/2022 07:55:53 - INFO - __main__ - Step 160 Global step 160 Train loss 1.28 on epoch=1
05/26/2022 07:55:55 - INFO - __main__ - Step 170 Global step 170 Train loss 1.12 on epoch=1
05/26/2022 07:55:58 - INFO - __main__ - Step 180 Global step 180 Train loss 1.10 on epoch=1
05/26/2022 07:56:01 - INFO - __main__ - Step 190 Global step 190 Train loss 1.08 on epoch=1
05/26/2022 07:56:03 - INFO - __main__ - Step 200 Global step 200 Train loss 1.04 on epoch=1
05/26/2022 07:57:03 - INFO - __main__ - Global step 200 Train loss 1.13 Classification-F1 0.2815454146375412 on epoch=1
05/26/2022 07:57:03 - INFO - __main__ - Saving model with best Classification-F1: 0.23696591969543068 -> 0.2815454146375412 on epoch=1, global_step=200
05/26/2022 07:57:05 - INFO - __main__ - Step 210 Global step 210 Train loss 1.01 on epoch=1
05/26/2022 07:57:08 - INFO - __main__ - Step 220 Global step 220 Train loss 1.04 on epoch=1
05/26/2022 07:57:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.97 on epoch=2
05/26/2022 07:57:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=2
05/26/2022 07:57:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=2
05/26/2022 07:58:18 - INFO - __main__ - Global step 250 Train loss 0.91 Classification-F1 0.32044555456760515 on epoch=2
05/26/2022 07:58:18 - INFO - __main__ - Saving model with best Classification-F1: 0.2815454146375412 -> 0.32044555456760515 on epoch=2, global_step=250
05/26/2022 07:58:20 - INFO - __main__ - Step 260 Global step 260 Train loss 1.03 on epoch=2
05/26/2022 07:58:23 - INFO - __main__ - Step 270 Global step 270 Train loss 0.87 on epoch=2
05/26/2022 07:58:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.86 on epoch=2
05/26/2022 07:58:28 - INFO - __main__ - Step 290 Global step 290 Train loss 0.83 on epoch=2
05/26/2022 07:58:31 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=2
05/26/2022 07:59:32 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.3509912482205268 on epoch=2
05/26/2022 07:59:32 - INFO - __main__ - Saving model with best Classification-F1: 0.32044555456760515 -> 0.3509912482205268 on epoch=2, global_step=300
05/26/2022 07:59:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.73 on epoch=2
05/26/2022 07:59:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.81 on epoch=2
05/26/2022 07:59:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.76 on epoch=2
05/26/2022 07:59:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.68 on epoch=3
05/26/2022 07:59:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.67 on epoch=3
05/26/2022 08:00:49 - INFO - __main__ - Global step 350 Train loss 0.73 Classification-F1 0.3892186699172924 on epoch=3
05/26/2022 08:00:49 - INFO - __main__ - Saving model with best Classification-F1: 0.3509912482205268 -> 0.3892186699172924 on epoch=3, global_step=350
05/26/2022 08:00:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=3
05/26/2022 08:00:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.74 on epoch=3
05/26/2022 08:00:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.71 on epoch=3
05/26/2022 08:01:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.69 on epoch=3
05/26/2022 08:01:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=3
05/26/2022 08:02:06 - INFO - __main__ - Global step 400 Train loss 0.66 Classification-F1 0.5365554942563477 on epoch=3
05/26/2022 08:02:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3892186699172924 -> 0.5365554942563477 on epoch=3, global_step=400
05/26/2022 08:02:08 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=3
05/26/2022 08:02:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.57 on epoch=3
05/26/2022 08:02:13 - INFO - __main__ - Step 430 Global step 430 Train loss 0.78 on epoch=3
05/26/2022 08:02:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.55 on epoch=3
05/26/2022 08:02:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=4
05/26/2022 08:03:15 - INFO - __main__ - Global step 450 Train loss 0.62 Classification-F1 0.5976554138516883 on epoch=4
05/26/2022 08:03:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5365554942563477 -> 0.5976554138516883 on epoch=4, global_step=450
05/26/2022 08:03:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=4
05/26/2022 08:03:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=4
05/26/2022 08:03:23 - INFO - __main__ - Step 480 Global step 480 Train loss 0.59 on epoch=4
05/26/2022 08:03:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.47 on epoch=4
05/26/2022 08:03:28 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=4
05/26/2022 08:04:30 - INFO - __main__ - Global step 500 Train loss 0.52 Classification-F1 0.5715112604180798 on epoch=4
05/26/2022 08:04:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.47 on epoch=4
05/26/2022 08:04:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.53 on epoch=4
05/26/2022 08:04:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=4
05/26/2022 08:04:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=4
05/26/2022 08:04:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=4
05/26/2022 08:05:39 - INFO - __main__ - Global step 550 Train loss 0.46 Classification-F1 0.5601655683419287 on epoch=4
05/26/2022 08:05:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.37 on epoch=4
05/26/2022 08:05:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=5
05/26/2022 08:05:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.42 on epoch=5
05/26/2022 08:05:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=5
05/26/2022 08:05:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=5
05/26/2022 08:06:49 - INFO - __main__ - Global step 600 Train loss 0.40 Classification-F1 0.4867384048933026 on epoch=5
05/26/2022 08:06:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.39 on epoch=5
05/26/2022 08:06:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=5
05/26/2022 08:06:57 - INFO - __main__ - Step 630 Global step 630 Train loss 0.48 on epoch=5
05/26/2022 08:06:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.39 on epoch=5
05/26/2022 08:07:02 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=5
05/26/2022 08:08:00 - INFO - __main__ - Global step 650 Train loss 0.42 Classification-F1 0.5764729809660354 on epoch=5
05/26/2022 08:08:03 - INFO - __main__ - Step 660 Global step 660 Train loss 0.31 on epoch=5
05/26/2022 08:08:06 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=5
05/26/2022 08:08:08 - INFO - __main__ - Step 680 Global step 680 Train loss 0.39 on epoch=6
05/26/2022 08:08:11 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=6
05/26/2022 08:08:14 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=6
05/26/2022 08:09:08 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.4788013771555127 on epoch=6
05/26/2022 08:09:11 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=6
05/26/2022 08:09:13 - INFO - __main__ - Step 720 Global step 720 Train loss 0.38 on epoch=6
05/26/2022 08:09:16 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=6
05/26/2022 08:09:19 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=6
05/26/2022 08:09:21 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=6
05/26/2022 08:10:15 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.6483245574822568 on epoch=6
05/26/2022 08:10:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5976554138516883 -> 0.6483245574822568 on epoch=6, global_step=750
05/26/2022 08:10:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=6
05/26/2022 08:10:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=6
05/26/2022 08:10:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.36 on epoch=6
05/26/2022 08:10:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.26 on epoch=7
05/26/2022 08:10:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.22 on epoch=7
05/26/2022 08:11:24 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.5058442064621326 on epoch=7
05/26/2022 08:11:26 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=7
05/26/2022 08:11:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=7
05/26/2022 08:11:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=7
05/26/2022 08:11:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=7
05/26/2022 08:11:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=7
05/26/2022 08:12:31 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.6110326351758987 on epoch=7
05/26/2022 08:12:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=7
05/26/2022 08:12:36 - INFO - __main__ - Step 870 Global step 870 Train loss 0.27 on epoch=7
05/26/2022 08:12:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=7
05/26/2022 08:12:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=7
05/26/2022 08:12:44 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=8
05/26/2022 08:13:41 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.5234436406843709 on epoch=8
05/26/2022 08:13:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=8
05/26/2022 08:13:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=8
05/26/2022 08:13:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=8
05/26/2022 08:13:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=8
05/26/2022 08:13:54 - INFO - __main__ - Step 950 Global step 950 Train loss 0.29 on epoch=8
05/26/2022 08:14:45 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.5115397826713467 on epoch=8
05/26/2022 08:14:47 - INFO - __main__ - Step 960 Global step 960 Train loss 0.23 on epoch=8
05/26/2022 08:14:50 - INFO - __main__ - Step 970 Global step 970 Train loss 0.25 on epoch=8
05/26/2022 08:14:52 - INFO - __main__ - Step 980 Global step 980 Train loss 0.18 on epoch=8
05/26/2022 08:14:55 - INFO - __main__ - Step 990 Global step 990 Train loss 0.34 on epoch=8
05/26/2022 08:14:58 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=8
05/26/2022 08:15:48 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.5302715932089953 on epoch=8
05/26/2022 08:15:50 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=9
05/26/2022 08:15:53 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=9
05/26/2022 08:15:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.20 on epoch=9
05/26/2022 08:15:58 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.29 on epoch=9
05/26/2022 08:16:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=9
05/26/2022 08:16:53 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.5035047749116023 on epoch=9
05/26/2022 08:16:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=9
05/26/2022 08:16:58 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=9
05/26/2022 08:17:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=9
05/26/2022 08:17:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=9
05/26/2022 08:17:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=9
05/26/2022 08:17:58 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.6073772775653637 on epoch=9
05/26/2022 08:18:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=9
05/26/2022 08:18:03 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.22 on epoch=9
05/26/2022 08:18:06 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.18 on epoch=10
05/26/2022 08:18:08 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=10
05/26/2022 08:18:11 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.25 on epoch=10
05/26/2022 08:19:01 - INFO - __main__ - Global step 1150 Train loss 0.20 Classification-F1 0.5222526477322249 on epoch=10
05/26/2022 08:19:04 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=10
05/26/2022 08:19:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=10
05/26/2022 08:19:09 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=10
05/26/2022 08:19:12 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
05/26/2022 08:19:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=10
05/26/2022 08:20:04 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.547154639324215 on epoch=10
05/26/2022 08:20:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=10
05/26/2022 08:20:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=10
05/26/2022 08:20:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=10
05/26/2022 08:20:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=11
05/26/2022 08:20:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=11
05/26/2022 08:21:11 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.7068395492524419 on epoch=11
05/26/2022 08:21:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6483245574822568 -> 0.7068395492524419 on epoch=11, global_step=1250
05/26/2022 08:21:13 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=11
05/26/2022 08:21:16 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=11
05/26/2022 08:21:18 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=11
05/26/2022 08:21:21 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=11
05/26/2022 08:21:24 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=11
05/26/2022 08:22:14 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.48979077496449785 on epoch=11
05/26/2022 08:22:17 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.15 on epoch=11
05/26/2022 08:22:19 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=11
05/26/2022 08:22:22 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.20 on epoch=11
05/26/2022 08:22:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.24 on epoch=11
05/26/2022 08:22:27 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/26/2022 08:23:19 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6577117306647928 on epoch=12
05/26/2022 08:23:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=12
05/26/2022 08:23:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.26 on epoch=12
05/26/2022 08:23:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.21 on epoch=12
05/26/2022 08:23:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=12
05/26/2022 08:23:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=12
05/26/2022 08:24:25 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.4492895706196368 on epoch=12
05/26/2022 08:24:28 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=12
05/26/2022 08:24:30 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=12
05/26/2022 08:24:33 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=12
05/26/2022 08:24:35 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.28 on epoch=12
05/26/2022 08:24:38 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=12
05/26/2022 08:25:28 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.675280456545984 on epoch=12
05/26/2022 08:25:30 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/26/2022 08:25:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=13
05/26/2022 08:25:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=13
05/26/2022 08:25:38 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=13
05/26/2022 08:25:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=13
05/26/2022 08:26:33 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.802690642367719 on epoch=13
05/26/2022 08:26:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7068395492524419 -> 0.802690642367719 on epoch=13, global_step=1500
05/26/2022 08:26:36 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.22 on epoch=13
05/26/2022 08:26:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=13
05/26/2022 08:26:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=13
05/26/2022 08:26:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=13
05/26/2022 08:26:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=13
05/26/2022 08:27:38 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.655176060870231 on epoch=13
05/26/2022 08:27:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.18 on epoch=13
05/26/2022 08:27:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=14
05/26/2022 08:27:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=14
05/26/2022 08:27:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.21 on epoch=14
05/26/2022 08:27:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.23 on epoch=14
05/26/2022 08:28:40 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.5447493962394293 on epoch=14
05/26/2022 08:28:42 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=14
05/26/2022 08:28:45 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=14
05/26/2022 08:28:47 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=14
05/26/2022 08:28:50 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
05/26/2022 08:28:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=14
05/26/2022 08:29:42 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6129992321485809 on epoch=14
05/26/2022 08:29:45 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=14
05/26/2022 08:29:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/26/2022 08:29:50 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=14
05/26/2022 08:29:53 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=15
05/26/2022 08:29:55 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
05/26/2022 08:30:46 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6976873112167421 on epoch=15
05/26/2022 08:30:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=15
05/26/2022 08:30:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=15
05/26/2022 08:30:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=15
05/26/2022 08:30:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.16 on epoch=15
05/26/2022 08:30:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=15
05/26/2022 08:31:49 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.6524824300455025 on epoch=15
05/26/2022 08:31:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/26/2022 08:31:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=15
05/26/2022 08:31:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.17 on epoch=15
05/26/2022 08:31:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=15
05/26/2022 08:32:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=16
05/26/2022 08:32:55 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.679947659220087 on epoch=16
05/26/2022 08:32:58 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
05/26/2022 08:33:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.15 on epoch=16
05/26/2022 08:33:03 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=16
05/26/2022 08:33:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=16
05/26/2022 08:33:08 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=16
05/26/2022 08:34:00 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.7023655975489791 on epoch=16
05/26/2022 08:34:02 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
05/26/2022 08:34:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=16
05/26/2022 08:34:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.11 on epoch=16
05/26/2022 08:34:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=16
05/26/2022 08:34:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=16
05/26/2022 08:35:04 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.6732873664895213 on epoch=16
05/26/2022 08:35:06 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=17
05/26/2022 08:35:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
05/26/2022 08:35:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.15 on epoch=17
05/26/2022 08:35:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.11 on epoch=17
05/26/2022 08:35:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
05/26/2022 08:36:07 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6929904606098664 on epoch=17
05/26/2022 08:36:10 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=17
05/26/2022 08:36:12 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=17
05/26/2022 08:36:15 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
05/26/2022 08:36:17 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=17
05/26/2022 08:36:20 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.17 on epoch=17
05/26/2022 08:37:12 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.7883782281392234 on epoch=17
05/26/2022 08:37:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=17
05/26/2022 08:37:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/26/2022 08:37:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=18
05/26/2022 08:37:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=18
05/26/2022 08:37:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.15 on epoch=18
05/26/2022 08:38:14 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.5056225260425264 on epoch=18
05/26/2022 08:38:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
05/26/2022 08:38:19 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.12 on epoch=18
05/26/2022 08:38:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/26/2022 08:38:24 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/26/2022 08:38:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=18
05/26/2022 08:39:18 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.5926047455416277 on epoch=18
05/26/2022 08:39:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.19 on epoch=18
05/26/2022 08:39:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=18
05/26/2022 08:39:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/26/2022 08:39:29 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=19
05/26/2022 08:39:32 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=19
05/26/2022 08:40:23 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6391111961720997 on epoch=19
05/26/2022 08:40:26 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=19
05/26/2022 08:40:28 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=19
05/26/2022 08:40:31 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.12 on epoch=19
05/26/2022 08:40:33 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/26/2022 08:40:36 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/26/2022 08:41:27 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.8684974404216822 on epoch=19
05/26/2022 08:41:27 - INFO - __main__ - Saving model with best Classification-F1: 0.802690642367719 -> 0.8684974404216822 on epoch=19, global_step=2200
05/26/2022 08:41:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/26/2022 08:41:32 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=19
05/26/2022 08:41:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.14 on epoch=19
05/26/2022 08:41:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=19
05/26/2022 08:41:40 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/26/2022 08:42:34 - INFO - __main__ - Global step 2250 Train loss 0.09 Classification-F1 0.6492145624506663 on epoch=20
05/26/2022 08:42:36 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=20
05/26/2022 08:42:39 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=20
05/26/2022 08:42:42 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=20
05/26/2022 08:42:44 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/26/2022 08:42:47 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.17 on epoch=20
05/26/2022 08:43:36 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.6311248783646961 on epoch=20
05/26/2022 08:43:38 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/26/2022 08:43:41 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=20
05/26/2022 08:43:43 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.10 on epoch=20
05/26/2022 08:43:46 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=20
05/26/2022 08:43:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.11 on epoch=20
05/26/2022 08:44:38 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.6340164617795783 on epoch=20
05/26/2022 08:44:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/26/2022 08:44:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=21
05/26/2022 08:44:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=21
05/26/2022 08:44:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=21
05/26/2022 08:44:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
05/26/2022 08:45:40 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.6267655184182277 on epoch=21
05/26/2022 08:45:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
05/26/2022 08:45:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/26/2022 08:45:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=21
05/26/2022 08:45:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.12 on epoch=21
05/26/2022 08:45:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.14 on epoch=21
05/26/2022 08:46:40 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.550942180545151 on epoch=21
05/26/2022 08:46:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=21
05/26/2022 08:46:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.08 on epoch=22
05/26/2022 08:46:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/26/2022 08:46:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
05/26/2022 08:46:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.12 on epoch=22
05/26/2022 08:47:39 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.5914498822063651 on epoch=22
05/26/2022 08:47:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/26/2022 08:47:44 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=22
05/26/2022 08:47:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=22
05/26/2022 08:47:49 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.10 on epoch=22
05/26/2022 08:47:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/26/2022 08:48:41 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.7576177123601153 on epoch=22
05/26/2022 08:48:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.13 on epoch=22
05/26/2022 08:48:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/26/2022 08:48:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=23
05/26/2022 08:48:52 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
05/26/2022 08:48:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/26/2022 08:49:43 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7157649491321814 on epoch=23
05/26/2022 08:49:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.14 on epoch=23
05/26/2022 08:49:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/26/2022 08:49:51 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.14 on epoch=23
05/26/2022 08:49:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=23
05/26/2022 08:49:56 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=23
05/26/2022 08:50:43 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.701108379961288 on epoch=23
05/26/2022 08:50:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.09 on epoch=23
05/26/2022 08:50:48 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.25 on epoch=23
05/26/2022 08:50:51 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=23
05/26/2022 08:50:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=24
05/26/2022 08:50:56 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=24
05/26/2022 08:51:45 - INFO - __main__ - Global step 2700 Train loss 0.10 Classification-F1 0.6693874612206705 on epoch=24
05/26/2022 08:51:47 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/26/2022 08:51:50 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.14 on epoch=24
05/26/2022 08:51:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 08:51:55 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=24
05/26/2022 08:51:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
05/26/2022 08:52:44 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.7417294977739582 on epoch=24
05/26/2022 08:52:47 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/26/2022 08:52:49 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=24
05/26/2022 08:52:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/26/2022 08:52:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
05/26/2022 08:52:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=24
05/26/2022 08:53:46 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.6760265598754733 on epoch=24
05/26/2022 08:53:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/26/2022 08:53:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=25
05/26/2022 08:53:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=25
05/26/2022 08:53:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/26/2022 08:53:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=25
05/26/2022 08:54:46 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.6322948788943096 on epoch=25
05/26/2022 08:54:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.16 on epoch=25
05/26/2022 08:54:51 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/26/2022 08:54:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/26/2022 08:54:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.14 on epoch=25
05/26/2022 08:54:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.09 on epoch=25
05/26/2022 08:55:47 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.7044625017205749 on epoch=25
05/26/2022 08:55:50 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=25
05/26/2022 08:55:52 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.06 on epoch=26
05/26/2022 08:55:55 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=26
05/26/2022 08:55:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.15 on epoch=26
05/26/2022 08:56:00 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=26
05/26/2022 08:56:46 - INFO - __main__ - Global step 2950 Train loss 0.08 Classification-F1 0.7384467325988161 on epoch=26
05/26/2022 08:56:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
05/26/2022 08:56:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=26
05/26/2022 08:56:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=26
05/26/2022 08:56:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=26
05/26/2022 08:56:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=26
05/26/2022 08:57:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 08:57:01 - INFO - __main__ - Printing 3 examples
05/26/2022 08:57:01 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 08:57:01 - INFO - __main__ - ['Plant']
05/26/2022 08:57:01 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 08:57:01 - INFO - __main__ - ['Plant']
05/26/2022 08:57:01 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 08:57:01 - INFO - __main__ - ['Plant']
05/26/2022 08:57:01 - INFO - __main__ - Tokenizing Input ...
05/26/2022 08:57:02 - INFO - __main__ - Tokenizing Output ...
05/26/2022 08:57:04 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 08:57:04 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 08:57:04 - INFO - __main__ - Printing 3 examples
05/26/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 08:57:04 - INFO - __main__ - ['Plant']
05/26/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 08:57:04 - INFO - __main__ - ['Plant']
05/26/2022 08:57:04 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 08:57:04 - INFO - __main__ - ['Plant']
05/26/2022 08:57:04 - INFO - __main__ - Tokenizing Input ...
05/26/2022 08:57:04 - INFO - __main__ - Tokenizing Output ...
05/26/2022 08:57:06 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 08:57:25 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 08:57:25 - INFO - __main__ - task name: dbpedia_14
05/26/2022 08:57:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 08:57:25 - INFO - __main__ - Starting training!
05/26/2022 08:57:48 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.747532519617648 on epoch=26
05/26/2022 08:57:48 - INFO - __main__ - save last model!
05/26/2022 08:57:48 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 08:57:48 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 08:57:48 - INFO - __main__ - Printing 3 examples
05/26/2022 08:57:48 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 08:57:48 - INFO - __main__ - ['Animal']
05/26/2022 08:57:48 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 08:57:48 - INFO - __main__ - ['Animal']
05/26/2022 08:57:48 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 08:57:48 - INFO - __main__ - ['Village']
05/26/2022 08:57:48 - INFO - __main__ - Tokenizing Input ...
05/26/2022 08:57:50 - INFO - __main__ - Tokenizing Output ...
05/26/2022 08:57:54 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 08:59:58 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_13_0.2_8_predictions.txt
05/26/2022 08:59:58 - INFO - __main__ - Classification-F1 on test data: 0.6021
05/26/2022 08:59:59 - INFO - __main__ - prefix=dbpedia_14_128_13, lr=0.2, bsz=8, dev_performance=0.8684974404216822, test_performance=0.6021299287146809
05/26/2022 08:59:59 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.5, bsz=8 ...
05/26/2022 09:00:00 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 09:00:00 - INFO - __main__ - Printing 3 examples
05/26/2022 09:00:00 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 09:00:00 - INFO - __main__ - ['Plant']
05/26/2022 09:00:00 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 09:00:00 - INFO - __main__ - ['Plant']
05/26/2022 09:00:00 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 09:00:00 - INFO - __main__ - ['Plant']
05/26/2022 09:00:00 - INFO - __main__ - Tokenizing Input ...
05/26/2022 09:00:01 - INFO - __main__ - Tokenizing Output ...
05/26/2022 09:00:03 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 09:00:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 09:00:03 - INFO - __main__ - Printing 3 examples
05/26/2022 09:00:03 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 09:00:03 - INFO - __main__ - ['Plant']
05/26/2022 09:00:03 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 09:00:03 - INFO - __main__ - ['Plant']
05/26/2022 09:00:03 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 09:00:03 - INFO - __main__ - ['Plant']
05/26/2022 09:00:03 - INFO - __main__ - Tokenizing Input ...
05/26/2022 09:00:04 - INFO - __main__ - Tokenizing Output ...
05/26/2022 09:00:05 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 09:00:24 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 09:00:24 - INFO - __main__ - task name: dbpedia_14
05/26/2022 09:00:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 09:00:25 - INFO - __main__ - Starting training!
05/26/2022 09:00:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.77 on epoch=0
05/26/2022 09:00:31 - INFO - __main__ - Step 20 Global step 20 Train loss 5.00 on epoch=0
05/26/2022 09:00:34 - INFO - __main__ - Step 30 Global step 30 Train loss 3.43 on epoch=0
05/26/2022 09:00:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.53 on epoch=0
05/26/2022 09:00:39 - INFO - __main__ - Step 50 Global step 50 Train loss 2.11 on epoch=0
05/26/2022 09:01:52 - INFO - __main__ - Global step 50 Train loss 3.97 Classification-F1 0.09041493389123625 on epoch=0
05/26/2022 09:01:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09041493389123625 on epoch=0, global_step=50
05/26/2022 09:01:55 - INFO - __main__ - Step 60 Global step 60 Train loss 1.49 on epoch=0
05/26/2022 09:01:58 - INFO - __main__ - Step 70 Global step 70 Train loss 1.44 on epoch=0
05/26/2022 09:02:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.19 on epoch=0
05/26/2022 09:02:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.10 on epoch=0
05/26/2022 09:02:06 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=0
05/26/2022 09:03:17 - INFO - __main__ - Global step 100 Train loss 1.22 Classification-F1 0.14848290552091226 on epoch=0
05/26/2022 09:03:18 - INFO - __main__ - Saving model with best Classification-F1: 0.09041493389123625 -> 0.14848290552091226 on epoch=0, global_step=100
05/26/2022 09:03:20 - INFO - __main__ - Step 110 Global step 110 Train loss 1.03 on epoch=0
05/26/2022 09:03:23 - INFO - __main__ - Step 120 Global step 120 Train loss 0.84 on epoch=1
05/26/2022 09:03:25 - INFO - __main__ - Step 130 Global step 130 Train loss 0.77 on epoch=1
05/26/2022 09:03:28 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=1
05/26/2022 09:03:31 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=1
05/26/2022 09:04:35 - INFO - __main__ - Global step 150 Train loss 0.81 Classification-F1 0.302883480916715 on epoch=1
05/26/2022 09:04:35 - INFO - __main__ - Saving model with best Classification-F1: 0.14848290552091226 -> 0.302883480916715 on epoch=1, global_step=150
05/26/2022 09:04:38 - INFO - __main__ - Step 160 Global step 160 Train loss 0.66 on epoch=1
05/26/2022 09:04:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.66 on epoch=1
05/26/2022 09:04:43 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=1
05/26/2022 09:04:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.58 on epoch=1
05/26/2022 09:04:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=1
05/26/2022 09:05:40 - INFO - __main__ - Global step 200 Train loss 0.63 Classification-F1 0.45499054985538484 on epoch=1
05/26/2022 09:05:40 - INFO - __main__ - Saving model with best Classification-F1: 0.302883480916715 -> 0.45499054985538484 on epoch=1, global_step=200
05/26/2022 09:05:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=1
05/26/2022 09:05:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.70 on epoch=1
05/26/2022 09:05:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=2
05/26/2022 09:05:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=2
05/26/2022 09:05:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=2
05/26/2022 09:06:55 - INFO - __main__ - Global step 250 Train loss 0.53 Classification-F1 0.5414612246395182 on epoch=2
05/26/2022 09:06:55 - INFO - __main__ - Saving model with best Classification-F1: 0.45499054985538484 -> 0.5414612246395182 on epoch=2, global_step=250
05/26/2022 09:06:58 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=2
05/26/2022 09:07:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=2
05/26/2022 09:07:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=2
05/26/2022 09:07:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.37 on epoch=2
05/26/2022 09:07:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=2
05/26/2022 09:08:06 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.5124449742057404 on epoch=2
05/26/2022 09:08:09 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=2
05/26/2022 09:08:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=2
05/26/2022 09:08:14 - INFO - __main__ - Step 330 Global step 330 Train loss 0.41 on epoch=2
05/26/2022 09:08:17 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=3
05/26/2022 09:08:19 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=3
05/26/2022 09:09:21 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.5435286477541703 on epoch=3
05/26/2022 09:09:21 - INFO - __main__ - Saving model with best Classification-F1: 0.5414612246395182 -> 0.5435286477541703 on epoch=3, global_step=350
05/26/2022 09:09:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=3
05/26/2022 09:09:26 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=3
05/26/2022 09:09:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=3
05/26/2022 09:09:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=3
05/26/2022 09:09:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=3
05/26/2022 09:10:27 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.5648577524142572 on epoch=3
05/26/2022 09:10:27 - INFO - __main__ - Saving model with best Classification-F1: 0.5435286477541703 -> 0.5648577524142572 on epoch=3, global_step=400
05/26/2022 09:10:30 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=3
05/26/2022 09:10:33 - INFO - __main__ - Step 420 Global step 420 Train loss 0.32 on epoch=3
05/26/2022 09:10:35 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=3
05/26/2022 09:10:38 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=3
05/26/2022 09:10:40 - INFO - __main__ - Step 450 Global step 450 Train loss 0.40 on epoch=4
05/26/2022 09:11:32 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.6159235582194348 on epoch=4
05/26/2022 09:11:32 - INFO - __main__ - Saving model with best Classification-F1: 0.5648577524142572 -> 0.6159235582194348 on epoch=4, global_step=450
05/26/2022 09:11:35 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=4
05/26/2022 09:11:37 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=4
05/26/2022 09:11:40 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=4
05/26/2022 09:11:43 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=4
05/26/2022 09:11:45 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=4
05/26/2022 09:12:35 - INFO - __main__ - Global step 500 Train loss 0.26 Classification-F1 0.4555953405645595 on epoch=4
05/26/2022 09:12:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=4
05/26/2022 09:12:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.19 on epoch=4
05/26/2022 09:12:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=4
05/26/2022 09:12:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.26 on epoch=4
05/26/2022 09:12:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=4
05/26/2022 09:13:38 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6556914317179231 on epoch=4
05/26/2022 09:13:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6159235582194348 -> 0.6556914317179231 on epoch=4, global_step=550
05/26/2022 09:13:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.33 on epoch=4
05/26/2022 09:13:43 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=5
05/26/2022 09:13:46 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=5
05/26/2022 09:13:48 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
05/26/2022 09:13:51 - INFO - __main__ - Step 600 Global step 600 Train loss 0.18 on epoch=5
05/26/2022 09:14:43 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.7404231270179805 on epoch=5
05/26/2022 09:14:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6556914317179231 -> 0.7404231270179805 on epoch=5, global_step=600
05/26/2022 09:14:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=5
05/26/2022 09:14:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=5
05/26/2022 09:14:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=5
05/26/2022 09:14:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
05/26/2022 09:14:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.19 on epoch=5
05/26/2022 09:15:47 - INFO - __main__ - Global step 650 Train loss 0.21 Classification-F1 0.7333083740633994 on epoch=5
05/26/2022 09:15:50 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=5
05/26/2022 09:15:52 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=5
05/26/2022 09:15:55 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=6
05/26/2022 09:15:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=6
05/26/2022 09:16:00 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=6
05/26/2022 09:16:48 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.49121061438327335 on epoch=6
05/26/2022 09:16:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=6
05/26/2022 09:16:53 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=6
05/26/2022 09:16:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=6
05/26/2022 09:16:58 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=6
05/26/2022 09:17:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=6
05/26/2022 09:17:53 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7032423651204198 on epoch=6
05/26/2022 09:17:55 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=6
05/26/2022 09:17:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=6
05/26/2022 09:18:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/26/2022 09:18:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=7
05/26/2022 09:18:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/26/2022 09:18:57 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.687075138162513 on epoch=7
05/26/2022 09:19:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.20 on epoch=7
05/26/2022 09:19:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=7
05/26/2022 09:19:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=7
05/26/2022 09:19:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=7
05/26/2022 09:19:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
05/26/2022 09:19:59 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6856705419386364 on epoch=7
05/26/2022 09:20:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=7
05/26/2022 09:20:05 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=7
05/26/2022 09:20:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=7
05/26/2022 09:20:10 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=7
05/26/2022 09:20:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=8
05/26/2022 09:21:01 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.720468326859049 on epoch=8
05/26/2022 09:21:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=8
05/26/2022 09:21:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.04 on epoch=8
05/26/2022 09:21:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=8
05/26/2022 09:21:12 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=8
05/26/2022 09:21:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=8
05/26/2022 09:22:03 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.698415707968661 on epoch=8
05/26/2022 09:22:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
05/26/2022 09:22:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
05/26/2022 09:22:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=8
05/26/2022 09:22:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=8
05/26/2022 09:22:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=8
05/26/2022 09:23:02 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6886857910398189 on epoch=8
05/26/2022 09:23:05 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=9
05/26/2022 09:23:07 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.05 on epoch=9
05/26/2022 09:23:10 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
05/26/2022 09:23:13 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.04 on epoch=9
05/26/2022 09:23:15 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
05/26/2022 09:23:59 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6498713256867104 on epoch=9
05/26/2022 09:24:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=9
05/26/2022 09:24:05 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=9
05/26/2022 09:24:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=9
05/26/2022 09:24:10 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.07 on epoch=9
05/26/2022 09:24:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=9
05/26/2022 09:25:00 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7066508322876244 on epoch=9
05/26/2022 09:25:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=9
05/26/2022 09:25:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=9
05/26/2022 09:25:08 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=10
05/26/2022 09:25:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/26/2022 09:25:13 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.10 on epoch=10
05/26/2022 09:25:58 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.584654628480756 on epoch=10
05/26/2022 09:26:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
05/26/2022 09:26:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=10
05/26/2022 09:26:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=10
05/26/2022 09:26:09 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=10
05/26/2022 09:26:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/26/2022 09:26:58 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6184740064411911 on epoch=10
05/26/2022 09:27:01 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=10
05/26/2022 09:27:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=10
05/26/2022 09:27:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
05/26/2022 09:27:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.08 on epoch=11
05/26/2022 09:27:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=11
05/26/2022 09:27:58 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6778799143461294 on epoch=11
05/26/2022 09:28:01 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=11
05/26/2022 09:28:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
05/26/2022 09:28:06 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=11
05/26/2022 09:28:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
05/26/2022 09:28:11 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=11
05/26/2022 09:28:58 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.6657833488224946 on epoch=11
05/26/2022 09:29:01 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/26/2022 09:29:03 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/26/2022 09:29:06 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=11
05/26/2022 09:29:08 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=11
05/26/2022 09:29:11 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
05/26/2022 09:29:58 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.6794660578013001 on epoch=12
05/26/2022 09:30:01 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=12
05/26/2022 09:30:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=12
05/26/2022 09:30:06 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=12
05/26/2022 09:30:09 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=12
05/26/2022 09:30:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=12
05/26/2022 09:30:56 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5532169748582223 on epoch=12
05/26/2022 09:30:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=12
05/26/2022 09:31:01 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=12
05/26/2022 09:31:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=12
05/26/2022 09:31:06 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
05/26/2022 09:31:09 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=12
05/26/2022 09:31:55 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6704411792770217 on epoch=12
05/26/2022 09:31:58 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/26/2022 09:32:01 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=13
05/26/2022 09:32:03 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=13
05/26/2022 09:32:06 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=13
05/26/2022 09:32:09 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
05/26/2022 09:32:55 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6879824538623714 on epoch=13
05/26/2022 09:32:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=13
05/26/2022 09:33:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
05/26/2022 09:33:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=13
05/26/2022 09:33:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
05/26/2022 09:33:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=13
05/26/2022 09:33:54 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6434066426037999 on epoch=13
05/26/2022 09:33:56 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=13
05/26/2022 09:33:59 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=14
05/26/2022 09:34:02 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=14
05/26/2022 09:34:04 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
05/26/2022 09:34:07 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=14
05/26/2022 09:34:53 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6804036392532965 on epoch=14
05/26/2022 09:34:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/26/2022 09:34:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/26/2022 09:35:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/26/2022 09:35:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/26/2022 09:35:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
05/26/2022 09:35:52 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7108725297993461 on epoch=14
05/26/2022 09:35:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=14
05/26/2022 09:35:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/26/2022 09:35:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=14
05/26/2022 09:36:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
05/26/2022 09:36:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=15
05/26/2022 09:36:51 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.809682623405308 on epoch=15
05/26/2022 09:36:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7404231270179805 -> 0.809682623405308 on epoch=15, global_step=1700
05/26/2022 09:36:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=15
05/26/2022 09:36:56 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
05/26/2022 09:36:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=15
05/26/2022 09:37:01 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/26/2022 09:37:04 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=15
05/26/2022 09:37:49 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.6280439409675111 on epoch=15
05/26/2022 09:37:52 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/26/2022 09:37:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=15
05/26/2022 09:37:57 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=15
05/26/2022 09:38:00 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
05/26/2022 09:38:02 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=16
05/26/2022 09:38:48 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7985406490339697 on epoch=16
05/26/2022 09:38:51 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
05/26/2022 09:38:53 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=16
05/26/2022 09:38:56 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 09:38:59 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/26/2022 09:39:01 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
05/26/2022 09:39:50 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.570325011668678 on epoch=16
05/26/2022 09:39:53 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/26/2022 09:39:56 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=16
05/26/2022 09:39:58 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=16
05/26/2022 09:40:01 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
05/26/2022 09:40:03 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=16
05/26/2022 09:40:49 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6899862239390074 on epoch=16
05/26/2022 09:40:52 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
05/26/2022 09:40:54 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
05/26/2022 09:40:57 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
05/26/2022 09:40:59 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 09:41:02 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
05/26/2022 09:41:46 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.42765532036312576 on epoch=17
05/26/2022 09:41:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/26/2022 09:41:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=17
05/26/2022 09:41:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=17
05/26/2022 09:41:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=17
05/26/2022 09:41:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=17
05/26/2022 09:42:46 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.46634682537542327 on epoch=17
05/26/2022 09:42:49 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=17
05/26/2022 09:42:51 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=18
05/26/2022 09:42:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=18
05/26/2022 09:42:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
05/26/2022 09:42:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=18
05/26/2022 09:43:46 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6280452933429992 on epoch=18
05/26/2022 09:43:49 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
05/26/2022 09:43:51 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 09:43:54 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/26/2022 09:43:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
05/26/2022 09:43:59 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 09:44:44 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.6246385324802335 on epoch=18
05/26/2022 09:44:47 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=18
05/26/2022 09:44:49 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/26/2022 09:44:52 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=19
05/26/2022 09:44:55 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
05/26/2022 09:44:57 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=19
05/26/2022 09:45:43 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.6760385245104112 on epoch=19
05/26/2022 09:45:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=19
05/26/2022 09:45:49 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 09:45:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
05/26/2022 09:45:54 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
05/26/2022 09:45:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/26/2022 09:46:42 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.610655439841589 on epoch=19
05/26/2022 09:46:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/26/2022 09:46:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 09:46:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=19
05/26/2022 09:46:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/26/2022 09:46:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=20
05/26/2022 09:47:41 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7158651385939255 on epoch=20
05/26/2022 09:47:44 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=20
05/26/2022 09:47:46 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=20
05/26/2022 09:47:49 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
05/26/2022 09:47:51 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=20
05/26/2022 09:47:54 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
05/26/2022 09:48:39 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.680796492141526 on epoch=20
05/26/2022 09:48:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/26/2022 09:48:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 09:48:47 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
05/26/2022 09:48:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=20
05/26/2022 09:48:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/26/2022 09:49:39 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7211406152837477 on epoch=20
05/26/2022 09:49:42 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/26/2022 09:49:44 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
05/26/2022 09:49:47 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
05/26/2022 09:49:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/26/2022 09:49:52 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=21
05/26/2022 09:50:38 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7448338315936497 on epoch=21
05/26/2022 09:50:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
05/26/2022 09:50:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=21
05/26/2022 09:50:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=21
05/26/2022 09:50:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/26/2022 09:50:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/26/2022 09:51:37 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.720115281839724 on epoch=21
05/26/2022 09:51:40 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=21
05/26/2022 09:51:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
05/26/2022 09:51:45 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
05/26/2022 09:51:48 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
05/26/2022 09:51:50 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=22
05/26/2022 09:52:36 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6791518914524157 on epoch=22
05/26/2022 09:52:39 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/26/2022 09:52:42 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
05/26/2022 09:52:44 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=22
05/26/2022 09:52:47 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/26/2022 09:52:50 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/26/2022 09:53:38 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6513230358890242 on epoch=22
05/26/2022 09:53:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
05/26/2022 09:53:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/26/2022 09:53:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
05/26/2022 09:53:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/26/2022 09:53:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/26/2022 09:54:40 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6169923085821435 on epoch=23
05/26/2022 09:54:43 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=23
05/26/2022 09:54:46 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 09:54:48 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/26/2022 09:54:51 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 09:54:54 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=23
05/26/2022 09:55:42 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6391072803085964 on epoch=23
05/26/2022 09:55:45 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=23
05/26/2022 09:55:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
05/26/2022 09:55:50 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/26/2022 09:55:53 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/26/2022 09:55:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/26/2022 09:56:43 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.5638610573935893 on epoch=24
05/26/2022 09:56:46 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/26/2022 09:56:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=24
05/26/2022 09:56:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/26/2022 09:56:54 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=24
05/26/2022 09:56:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=24
05/26/2022 09:57:43 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.5070930675054308 on epoch=24
05/26/2022 09:57:46 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 09:57:48 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/26/2022 09:57:51 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=24
05/26/2022 09:57:54 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=24
05/26/2022 09:57:56 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=24
05/26/2022 09:58:43 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.6097659923541204 on epoch=24
05/26/2022 09:58:46 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/26/2022 09:58:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=25
05/26/2022 09:58:51 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/26/2022 09:58:54 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 09:58:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/26/2022 09:59:42 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6236102781538576 on epoch=25
05/26/2022 09:59:45 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/26/2022 09:59:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/26/2022 09:59:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/26/2022 09:59:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=25
05/26/2022 09:59:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=25
05/26/2022 10:00:44 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6092022877369451 on epoch=25
05/26/2022 10:00:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
05/26/2022 10:00:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/26/2022 10:00:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/26/2022 10:00:55 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 10:00:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/26/2022 10:01:45 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7084029731741939 on epoch=26
05/26/2022 10:01:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
05/26/2022 10:01:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.09 on epoch=26
05/26/2022 10:01:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=26
05/26/2022 10:01:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/26/2022 10:01:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/26/2022 10:02:00 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 10:02:00 - INFO - __main__ - Printing 3 examples
05/26/2022 10:02:00 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 10:02:00 - INFO - __main__ - ['Plant']
05/26/2022 10:02:00 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 10:02:00 - INFO - __main__ - ['Plant']
05/26/2022 10:02:00 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 10:02:00 - INFO - __main__ - ['Plant']
05/26/2022 10:02:00 - INFO - __main__ - Tokenizing Input ...
05/26/2022 10:02:01 - INFO - __main__ - Tokenizing Output ...
05/26/2022 10:02:02 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 10:02:02 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 10:02:02 - INFO - __main__ - Printing 3 examples
05/26/2022 10:02:02 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 10:02:02 - INFO - __main__ - ['Plant']
05/26/2022 10:02:02 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 10:02:02 - INFO - __main__ - ['Plant']
05/26/2022 10:02:02 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 10:02:02 - INFO - __main__ - ['Plant']
05/26/2022 10:02:02 - INFO - __main__ - Tokenizing Input ...
05/26/2022 10:02:03 - INFO - __main__ - Tokenizing Output ...
05/26/2022 10:02:05 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 10:02:21 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 10:02:21 - INFO - __main__ - task name: dbpedia_14
05/26/2022 10:02:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 10:02:22 - INFO - __main__ - Starting training!
05/26/2022 10:02:45 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5766529498841861 on epoch=26
05/26/2022 10:02:45 - INFO - __main__ - save last model!
05/26/2022 10:02:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 10:02:46 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 10:02:46 - INFO - __main__ - Printing 3 examples
05/26/2022 10:02:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 10:02:46 - INFO - __main__ - ['Animal']
05/26/2022 10:02:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 10:02:46 - INFO - __main__ - ['Animal']
05/26/2022 10:02:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 10:02:46 - INFO - __main__ - ['Village']
05/26/2022 10:02:46 - INFO - __main__ - Tokenizing Input ...
05/26/2022 10:02:48 - INFO - __main__ - Tokenizing Output ...
05/26/2022 10:02:51 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 10:04:55 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.5_8_predictions.txt
05/26/2022 10:04:55 - INFO - __main__ - Classification-F1 on test data: 0.5525
05/26/2022 10:04:56 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.5, bsz=8, dev_performance=0.809682623405308, test_performance=0.5525085560603542
05/26/2022 10:04:56 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.4, bsz=8 ...
05/26/2022 10:04:57 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 10:04:57 - INFO - __main__ - Printing 3 examples
05/26/2022 10:04:57 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 10:04:57 - INFO - __main__ - ['Plant']
05/26/2022 10:04:57 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 10:04:57 - INFO - __main__ - ['Plant']
05/26/2022 10:04:57 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 10:04:57 - INFO - __main__ - ['Plant']
05/26/2022 10:04:57 - INFO - __main__ - Tokenizing Input ...
05/26/2022 10:04:58 - INFO - __main__ - Tokenizing Output ...
05/26/2022 10:04:59 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 10:04:59 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 10:04:59 - INFO - __main__ - Printing 3 examples
05/26/2022 10:04:59 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 10:04:59 - INFO - __main__ - ['Plant']
05/26/2022 10:04:59 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 10:04:59 - INFO - __main__ - ['Plant']
05/26/2022 10:04:59 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 10:04:59 - INFO - __main__ - ['Plant']
05/26/2022 10:04:59 - INFO - __main__ - Tokenizing Input ...
05/26/2022 10:05:00 - INFO - __main__ - Tokenizing Output ...
05/26/2022 10:05:02 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 10:05:18 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 10:05:18 - INFO - __main__ - task name: dbpedia_14
05/26/2022 10:05:19 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 10:05:19 - INFO - __main__ - Starting training!
05/26/2022 10:05:22 - INFO - __main__ - Step 10 Global step 10 Train loss 7.00 on epoch=0
05/26/2022 10:05:25 - INFO - __main__ - Step 20 Global step 20 Train loss 5.54 on epoch=0
05/26/2022 10:05:27 - INFO - __main__ - Step 30 Global step 30 Train loss 3.68 on epoch=0
05/26/2022 10:05:30 - INFO - __main__ - Step 40 Global step 40 Train loss 2.69 on epoch=0
05/26/2022 10:05:33 - INFO - __main__ - Step 50 Global step 50 Train loss 2.43 on epoch=0
05/26/2022 10:07:02 - INFO - __main__ - Global step 50 Train loss 4.27 Classification-F1 0.08412473839994306 on epoch=0
05/26/2022 10:07:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.08412473839994306 on epoch=0, global_step=50
05/26/2022 10:07:05 - INFO - __main__ - Step 60 Global step 60 Train loss 1.92 on epoch=0
05/26/2022 10:07:08 - INFO - __main__ - Step 70 Global step 70 Train loss 1.66 on epoch=0
05/26/2022 10:07:11 - INFO - __main__ - Step 80 Global step 80 Train loss 1.47 on epoch=0
05/26/2022 10:07:13 - INFO - __main__ - Step 90 Global step 90 Train loss 1.30 on epoch=0
05/26/2022 10:07:16 - INFO - __main__ - Step 100 Global step 100 Train loss 1.06 on epoch=0
05/26/2022 10:08:52 - INFO - __main__ - Global step 100 Train loss 1.48 Classification-F1 0.15098556944272354 on epoch=0
05/26/2022 10:08:52 - INFO - __main__ - Saving model with best Classification-F1: 0.08412473839994306 -> 0.15098556944272354 on epoch=0, global_step=100
05/26/2022 10:08:54 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=0
05/26/2022 10:08:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=1
05/26/2022 10:09:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.78 on epoch=1
05/26/2022 10:09:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.85 on epoch=1
05/26/2022 10:09:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.72 on epoch=1
05/26/2022 10:10:09 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.2820037752613453 on epoch=1
05/26/2022 10:10:09 - INFO - __main__ - Saving model with best Classification-F1: 0.15098556944272354 -> 0.2820037752613453 on epoch=1, global_step=150
05/26/2022 10:10:11 - INFO - __main__ - Step 160 Global step 160 Train loss 0.78 on epoch=1
05/26/2022 10:10:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.73 on epoch=1
05/26/2022 10:10:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=1
05/26/2022 10:10:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.65 on epoch=1
05/26/2022 10:10:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=1
05/26/2022 10:11:30 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.4547732527573918 on epoch=1
05/26/2022 10:11:30 - INFO - __main__ - Saving model with best Classification-F1: 0.2820037752613453 -> 0.4547732527573918 on epoch=1, global_step=200
05/26/2022 10:11:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.57 on epoch=1
05/26/2022 10:11:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=1
05/26/2022 10:11:38 - INFO - __main__ - Step 230 Global step 230 Train loss 0.49 on epoch=2
05/26/2022 10:11:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.45 on epoch=2
05/26/2022 10:11:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=2
05/26/2022 10:13:03 - INFO - __main__ - Global step 250 Train loss 0.52 Classification-F1 0.39060375800929364 on epoch=2
05/26/2022 10:13:06 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=2
05/26/2022 10:13:09 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=2
05/26/2022 10:13:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=2
05/26/2022 10:13:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=2
05/26/2022 10:13:17 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=2
05/26/2022 10:14:30 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.4074040763512888 on epoch=2
05/26/2022 10:14:33 - INFO - __main__ - Step 310 Global step 310 Train loss 0.51 on epoch=2
05/26/2022 10:14:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=2
05/26/2022 10:14:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.44 on epoch=2
05/26/2022 10:14:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=3
05/26/2022 10:14:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.29 on epoch=3
05/26/2022 10:15:55 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.4624845061503946 on epoch=3
05/26/2022 10:15:55 - INFO - __main__ - Saving model with best Classification-F1: 0.4547732527573918 -> 0.4624845061503946 on epoch=3, global_step=350
05/26/2022 10:15:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.35 on epoch=3
05/26/2022 10:16:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=3
05/26/2022 10:16:03 - INFO - __main__ - Step 380 Global step 380 Train loss 0.39 on epoch=3
05/26/2022 10:16:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=3
05/26/2022 10:16:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.27 on epoch=3
05/26/2022 10:17:09 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.49754096431679573 on epoch=3
05/26/2022 10:17:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4624845061503946 -> 0.49754096431679573 on epoch=3, global_step=400
05/26/2022 10:17:11 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=3
05/26/2022 10:17:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=3
05/26/2022 10:17:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=3
05/26/2022 10:17:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=3
05/26/2022 10:17:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=4
05/26/2022 10:18:37 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.4849689879094606 on epoch=4
05/26/2022 10:18:40 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=4
05/26/2022 10:18:43 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=4
05/26/2022 10:18:45 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=4
05/26/2022 10:18:48 - INFO - __main__ - Step 490 Global step 490 Train loss 0.32 on epoch=4
05/26/2022 10:18:51 - INFO - __main__ - Step 500 Global step 500 Train loss 0.33 on epoch=4
05/26/2022 10:20:20 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.4682867526101811 on epoch=4
05/26/2022 10:20:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=4
05/26/2022 10:20:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
05/26/2022 10:20:28 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=4
05/26/2022 10:20:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=4
05/26/2022 10:20:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.25 on epoch=4
05/26/2022 10:21:44 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.4673686587071694 on epoch=4
05/26/2022 10:21:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=4
05/26/2022 10:21:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=5
05/26/2022 10:21:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=5
05/26/2022 10:21:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=5
05/26/2022 10:21:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.12 on epoch=5
05/26/2022 10:22:58 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.5931319817002427 on epoch=5
05/26/2022 10:22:58 - INFO - __main__ - Saving model with best Classification-F1: 0.49754096431679573 -> 0.5931319817002427 on epoch=5, global_step=600
05/26/2022 10:23:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=5
05/26/2022 10:23:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=5
05/26/2022 10:23:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=5
05/26/2022 10:23:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=5
05/26/2022 10:23:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=5
05/26/2022 10:24:07 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.6900581614248675 on epoch=5
05/26/2022 10:24:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5931319817002427 -> 0.6900581614248675 on epoch=5, global_step=650
05/26/2022 10:24:10 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=5
05/26/2022 10:24:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=5
05/26/2022 10:24:15 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=6
05/26/2022 10:24:18 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=6
05/26/2022 10:24:20 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=6
05/26/2022 10:25:28 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.5045822376311958 on epoch=6
05/26/2022 10:25:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.21 on epoch=6
05/26/2022 10:25:33 - INFO - __main__ - Step 720 Global step 720 Train loss 0.14 on epoch=6
05/26/2022 10:25:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=6
05/26/2022 10:25:38 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=6
05/26/2022 10:25:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=6
05/26/2022 10:26:35 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.5149622211287671 on epoch=6
05/26/2022 10:26:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=6
05/26/2022 10:26:40 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=6
05/26/2022 10:26:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=6
05/26/2022 10:26:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=7
05/26/2022 10:26:48 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=7
05/26/2022 10:27:54 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7355636603693544 on epoch=7
05/26/2022 10:27:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6900581614248675 -> 0.7355636603693544 on epoch=7, global_step=800
05/26/2022 10:27:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=7
05/26/2022 10:27:59 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=7
05/26/2022 10:28:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=7
05/26/2022 10:28:04 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=7
05/26/2022 10:28:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
05/26/2022 10:29:10 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6420305312636936 on epoch=7
05/26/2022 10:29:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=7
05/26/2022 10:29:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=7
05/26/2022 10:29:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=7
05/26/2022 10:29:20 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=7
05/26/2022 10:29:23 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=8
05/26/2022 10:30:14 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.5789075079772247 on epoch=8
05/26/2022 10:30:17 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=8
05/26/2022 10:30:20 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=8
05/26/2022 10:30:22 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=8
05/26/2022 10:30:25 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=8
05/26/2022 10:30:27 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=8
05/26/2022 10:31:16 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.4902380392815636 on epoch=8
05/26/2022 10:31:19 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=8
05/26/2022 10:31:22 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=8
05/26/2022 10:31:24 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=8
05/26/2022 10:31:27 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/26/2022 10:31:30 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=8
05/26/2022 10:32:23 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.511782475377536 on epoch=8
05/26/2022 10:32:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.16 on epoch=9
05/26/2022 10:32:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=9
05/26/2022 10:32:31 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=9
05/26/2022 10:32:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=9
05/26/2022 10:32:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
05/26/2022 10:33:28 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.5866478041960207 on epoch=9
05/26/2022 10:33:30 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
05/26/2022 10:33:33 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=9
05/26/2022 10:33:36 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
05/26/2022 10:33:38 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=9
05/26/2022 10:33:41 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=9
05/26/2022 10:34:38 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6408189011299429 on epoch=9
05/26/2022 10:34:40 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=9
05/26/2022 10:34:43 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=9
05/26/2022 10:34:46 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=10
05/26/2022 10:34:48 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/26/2022 10:34:51 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
05/26/2022 10:35:41 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.6270992538380168 on epoch=10
05/26/2022 10:35:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
05/26/2022 10:35:46 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=10
05/26/2022 10:35:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=10
05/26/2022 10:35:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=10
05/26/2022 10:35:54 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
05/26/2022 10:36:43 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5738544098277976 on epoch=10
05/26/2022 10:36:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=10
05/26/2022 10:36:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=10
05/26/2022 10:36:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=10
05/26/2022 10:36:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=11
05/26/2022 10:36:57 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=11
05/26/2022 10:37:49 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.5244691317122551 on epoch=11
05/26/2022 10:37:52 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=11
05/26/2022 10:37:55 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=11
05/26/2022 10:37:57 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
05/26/2022 10:38:00 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=11
05/26/2022 10:38:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
05/26/2022 10:38:52 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.5625973859735154 on epoch=11
05/26/2022 10:38:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=11
05/26/2022 10:38:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=11
05/26/2022 10:39:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=11
05/26/2022 10:39:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=11
05/26/2022 10:39:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=12
05/26/2022 10:39:55 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6343963983538022 on epoch=12
05/26/2022 10:39:58 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
05/26/2022 10:40:01 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=12
05/26/2022 10:40:03 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=12
05/26/2022 10:40:06 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=12
05/26/2022 10:40:09 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=12
05/26/2022 10:40:57 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7124817308923033 on epoch=12
05/26/2022 10:41:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=12
05/26/2022 10:41:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
05/26/2022 10:41:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=12
05/26/2022 10:41:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=12
05/26/2022 10:41:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=12
05/26/2022 10:41:59 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.6864141277886006 on epoch=12
05/26/2022 10:42:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/26/2022 10:42:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=13
05/26/2022 10:42:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=13
05/26/2022 10:42:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/26/2022 10:42:12 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=13
05/26/2022 10:43:07 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8026899919054126 on epoch=13
05/26/2022 10:43:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7355636603693544 -> 0.8026899919054126 on epoch=13, global_step=1500
05/26/2022 10:43:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=13
05/26/2022 10:43:12 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=13
05/26/2022 10:43:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
05/26/2022 10:43:17 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/26/2022 10:43:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=13
05/26/2022 10:44:11 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7361240952062302 on epoch=13
05/26/2022 10:44:13 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=13
05/26/2022 10:44:16 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=14
05/26/2022 10:44:18 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
05/26/2022 10:44:21 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
05/26/2022 10:44:24 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/26/2022 10:45:13 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.5386246020921944 on epoch=14
05/26/2022 10:45:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=14
05/26/2022 10:45:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=14
05/26/2022 10:45:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=14
05/26/2022 10:45:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=14
05/26/2022 10:45:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/26/2022 10:46:15 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.5746402397611615 on epoch=14
05/26/2022 10:46:17 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=14
05/26/2022 10:46:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/26/2022 10:46:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=14
05/26/2022 10:46:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
05/26/2022 10:46:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=15
05/26/2022 10:47:17 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.5889029743999582 on epoch=15
05/26/2022 10:47:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=15
05/26/2022 10:47:22 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.07 on epoch=15
05/26/2022 10:47:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=15
05/26/2022 10:47:27 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/26/2022 10:47:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
05/26/2022 10:48:17 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.5814133193708513 on epoch=15
05/26/2022 10:48:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=15
05/26/2022 10:48:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
05/26/2022 10:48:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=15
05/26/2022 10:48:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=15
05/26/2022 10:48:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
05/26/2022 10:49:15 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.4576523952707212 on epoch=16
05/26/2022 10:49:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
05/26/2022 10:49:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
05/26/2022 10:49:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 10:49:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=16
05/26/2022 10:49:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
05/26/2022 10:50:17 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5331174644807988 on epoch=16
05/26/2022 10:50:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
05/26/2022 10:50:23 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=16
05/26/2022 10:50:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=16
05/26/2022 10:50:28 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=16
05/26/2022 10:50:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=16
05/26/2022 10:51:18 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.4324063243053683 on epoch=16
05/26/2022 10:51:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=17
05/26/2022 10:51:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
05/26/2022 10:51:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
05/26/2022 10:51:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
05/26/2022 10:51:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
05/26/2022 10:52:17 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.6094152715883326 on epoch=17
05/26/2022 10:52:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=17
05/26/2022 10:52:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
05/26/2022 10:52:25 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=17
05/26/2022 10:52:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/26/2022 10:52:30 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=17
05/26/2022 10:53:19 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7328416954683559 on epoch=17
05/26/2022 10:53:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=17
05/26/2022 10:53:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/26/2022 10:53:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=18
05/26/2022 10:53:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
05/26/2022 10:53:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/26/2022 10:54:22 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6756638222525584 on epoch=18
05/26/2022 10:54:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
05/26/2022 10:54:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 10:54:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=18
05/26/2022 10:54:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 10:54:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/26/2022 10:55:25 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7235081782697571 on epoch=18
05/26/2022 10:55:28 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=18
05/26/2022 10:55:31 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=18
05/26/2022 10:55:33 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/26/2022 10:55:36 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/26/2022 10:55:39 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/26/2022 10:56:30 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7001488182760447 on epoch=19
05/26/2022 10:56:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/26/2022 10:56:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 10:56:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
05/26/2022 10:56:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=19
05/26/2022 10:56:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
05/26/2022 10:57:34 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7729091140984586 on epoch=19
05/26/2022 10:57:36 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 10:57:39 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 10:57:41 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/26/2022 10:57:44 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=19
05/26/2022 10:57:47 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=20
05/26/2022 10:58:37 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6674226480866411 on epoch=20
05/26/2022 10:58:40 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=20
05/26/2022 10:58:42 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=20
05/26/2022 10:58:45 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
05/26/2022 10:58:48 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/26/2022 10:58:50 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
05/26/2022 10:59:40 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.510603939286839 on epoch=20
05/26/2022 10:59:42 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=20
05/26/2022 10:59:45 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/26/2022 10:59:48 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=20
05/26/2022 10:59:50 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
05/26/2022 10:59:53 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=20
05/26/2022 11:00:42 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.5551783013753191 on epoch=20
05/26/2022 11:00:45 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=21
05/26/2022 11:00:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/26/2022 11:00:51 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/26/2022 11:00:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/26/2022 11:00:56 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=21
05/26/2022 11:01:44 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.5852074697271749 on epoch=21
05/26/2022 11:01:46 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=21
05/26/2022 11:01:49 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/26/2022 11:01:52 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/26/2022 11:01:55 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/26/2022 11:01:57 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=21
05/26/2022 11:02:44 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.596507697307072 on epoch=21
05/26/2022 11:02:46 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/26/2022 11:02:49 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
05/26/2022 11:02:52 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=22
05/26/2022 11:02:54 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=22
05/26/2022 11:02:57 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/26/2022 11:03:44 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.673289614673639 on epoch=22
05/26/2022 11:03:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
05/26/2022 11:03:49 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=22
05/26/2022 11:03:52 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/26/2022 11:03:55 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/26/2022 11:03:57 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/26/2022 11:04:46 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.6444010772041575 on epoch=22
05/26/2022 11:04:49 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=22
05/26/2022 11:04:51 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/26/2022 11:04:54 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=23
05/26/2022 11:04:57 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/26/2022 11:04:59 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/26/2022 11:05:49 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.6239619561375721 on epoch=23
05/26/2022 11:05:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=23
05/26/2022 11:05:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=23
05/26/2022 11:05:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=23
05/26/2022 11:05:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=23
05/26/2022 11:06:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
05/26/2022 11:06:51 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.5203048735277194 on epoch=23
05/26/2022 11:06:54 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=23
05/26/2022 11:06:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
05/26/2022 11:06:59 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
05/26/2022 11:07:02 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=24
05/26/2022 11:07:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/26/2022 11:07:52 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6006194086867048 on epoch=24
05/26/2022 11:07:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/26/2022 11:07:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/26/2022 11:08:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/26/2022 11:08:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/26/2022 11:08:06 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
05/26/2022 11:08:55 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.5014477733027781 on epoch=24
05/26/2022 11:08:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
05/26/2022 11:09:00 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 11:09:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=24
05/26/2022 11:09:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=24
05/26/2022 11:09:08 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=24
05/26/2022 11:09:58 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.5746250679541356 on epoch=24
05/26/2022 11:10:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/26/2022 11:10:03 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=25
05/26/2022 11:10:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=25
05/26/2022 11:10:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 11:10:11 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/26/2022 11:10:59 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.5169319098610711 on epoch=25
05/26/2022 11:11:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 11:11:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=25
05/26/2022 11:11:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/26/2022 11:11:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/26/2022 11:11:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
05/26/2022 11:12:01 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.5692758274270917 on epoch=25
05/26/2022 11:12:03 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/26/2022 11:12:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/26/2022 11:12:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 11:12:12 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 11:12:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
05/26/2022 11:13:03 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.636351532731185 on epoch=26
05/26/2022 11:13:06 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
05/26/2022 11:13:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/26/2022 11:13:11 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=26
05/26/2022 11:13:14 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/26/2022 11:13:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=26
05/26/2022 11:13:18 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 11:13:18 - INFO - __main__ - Printing 3 examples
05/26/2022 11:13:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 11:13:18 - INFO - __main__ - ['Plant']
05/26/2022 11:13:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 11:13:18 - INFO - __main__ - ['Plant']
05/26/2022 11:13:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 11:13:18 - INFO - __main__ - ['Plant']
05/26/2022 11:13:18 - INFO - __main__ - Tokenizing Input ...
05/26/2022 11:13:19 - INFO - __main__ - Tokenizing Output ...
05/26/2022 11:13:21 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 11:13:21 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 11:13:21 - INFO - __main__ - Printing 3 examples
05/26/2022 11:13:21 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 11:13:21 - INFO - __main__ - ['Plant']
05/26/2022 11:13:21 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 11:13:21 - INFO - __main__ - ['Plant']
05/26/2022 11:13:21 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 11:13:21 - INFO - __main__ - ['Plant']
05/26/2022 11:13:21 - INFO - __main__ - Tokenizing Input ...
05/26/2022 11:13:22 - INFO - __main__ - Tokenizing Output ...
05/26/2022 11:13:23 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 11:13:42 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 11:13:42 - INFO - __main__ - task name: dbpedia_14
05/26/2022 11:13:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 11:13:43 - INFO - __main__ - Starting training!
05/26/2022 11:14:05 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.6148930491206065 on epoch=26
05/26/2022 11:14:05 - INFO - __main__ - save last model!
05/26/2022 11:14:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 11:14:05 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 11:14:05 - INFO - __main__ - Printing 3 examples
05/26/2022 11:14:05 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 11:14:05 - INFO - __main__ - ['Animal']
05/26/2022 11:14:05 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 11:14:05 - INFO - __main__ - ['Animal']
05/26/2022 11:14:05 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 11:14:05 - INFO - __main__ - ['Village']
05/26/2022 11:14:05 - INFO - __main__ - Tokenizing Input ...
05/26/2022 11:14:07 - INFO - __main__ - Tokenizing Output ...
05/26/2022 11:14:10 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 11:16:16 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.4_8_predictions.txt
05/26/2022 11:16:16 - INFO - __main__ - Classification-F1 on test data: 0.5411
05/26/2022 11:16:17 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.4, bsz=8, dev_performance=0.8026899919054126, test_performance=0.5411439595979859
05/26/2022 11:16:17 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.3, bsz=8 ...
05/26/2022 11:16:18 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 11:16:18 - INFO - __main__ - Printing 3 examples
05/26/2022 11:16:18 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 11:16:18 - INFO - __main__ - ['Plant']
05/26/2022 11:16:18 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 11:16:18 - INFO - __main__ - ['Plant']
05/26/2022 11:16:18 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 11:16:18 - INFO - __main__ - ['Plant']
05/26/2022 11:16:18 - INFO - __main__ - Tokenizing Input ...
05/26/2022 11:16:19 - INFO - __main__ - Tokenizing Output ...
05/26/2022 11:16:21 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 11:16:21 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 11:16:21 - INFO - __main__ - Printing 3 examples
05/26/2022 11:16:21 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 11:16:21 - INFO - __main__ - ['Plant']
05/26/2022 11:16:21 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 11:16:21 - INFO - __main__ - ['Plant']
05/26/2022 11:16:21 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 11:16:21 - INFO - __main__ - ['Plant']
05/26/2022 11:16:21 - INFO - __main__ - Tokenizing Input ...
05/26/2022 11:16:22 - INFO - __main__ - Tokenizing Output ...
05/26/2022 11:16:23 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 11:16:39 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 11:16:39 - INFO - __main__ - task name: dbpedia_14
05/26/2022 11:16:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 11:16:40 - INFO - __main__ - Starting training!
05/26/2022 11:16:43 - INFO - __main__ - Step 10 Global step 10 Train loss 7.18 on epoch=0
05/26/2022 11:16:46 - INFO - __main__ - Step 20 Global step 20 Train loss 6.56 on epoch=0
05/26/2022 11:16:49 - INFO - __main__ - Step 30 Global step 30 Train loss 5.50 on epoch=0
05/26/2022 11:16:51 - INFO - __main__ - Step 40 Global step 40 Train loss 4.34 on epoch=0
05/26/2022 11:16:54 - INFO - __main__ - Step 50 Global step 50 Train loss 3.42 on epoch=0
05/26/2022 11:19:30 - INFO - __main__ - Global step 50 Train loss 5.40 Classification-F1 0.036877342617617714 on epoch=0
05/26/2022 11:19:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.036877342617617714 on epoch=0, global_step=50
05/26/2022 11:19:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.74 on epoch=0
05/26/2022 11:19:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.27 on epoch=0
05/26/2022 11:19:38 - INFO - __main__ - Step 80 Global step 80 Train loss 1.92 on epoch=0
05/26/2022 11:19:41 - INFO - __main__ - Step 90 Global step 90 Train loss 1.94 on epoch=0
05/26/2022 11:19:43 - INFO - __main__ - Step 100 Global step 100 Train loss 1.50 on epoch=0
05/26/2022 11:20:45 - INFO - __main__ - Global step 100 Train loss 2.07 Classification-F1 0.1503763713165418 on epoch=0
05/26/2022 11:20:45 - INFO - __main__ - Saving model with best Classification-F1: 0.036877342617617714 -> 0.1503763713165418 on epoch=0, global_step=100
05/26/2022 11:20:48 - INFO - __main__ - Step 110 Global step 110 Train loss 1.24 on epoch=0
05/26/2022 11:20:50 - INFO - __main__ - Step 120 Global step 120 Train loss 1.21 on epoch=1
05/26/2022 11:20:53 - INFO - __main__ - Step 130 Global step 130 Train loss 1.23 on epoch=1
05/26/2022 11:20:56 - INFO - __main__ - Step 140 Global step 140 Train loss 1.06 on epoch=1
05/26/2022 11:20:58 - INFO - __main__ - Step 150 Global step 150 Train loss 1.01 on epoch=1
05/26/2022 11:21:58 - INFO - __main__ - Global step 150 Train loss 1.15 Classification-F1 0.27381192234660695 on epoch=1
05/26/2022 11:21:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1503763713165418 -> 0.27381192234660695 on epoch=1, global_step=150
05/26/2022 11:22:00 - INFO - __main__ - Step 160 Global step 160 Train loss 0.92 on epoch=1
05/26/2022 11:22:03 - INFO - __main__ - Step 170 Global step 170 Train loss 0.96 on epoch=1
05/26/2022 11:22:05 - INFO - __main__ - Step 180 Global step 180 Train loss 0.80 on epoch=1
05/26/2022 11:22:08 - INFO - __main__ - Step 190 Global step 190 Train loss 0.80 on epoch=1
05/26/2022 11:22:11 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=1
05/26/2022 11:23:05 - INFO - __main__ - Global step 200 Train loss 0.87 Classification-F1 0.43019283492008376 on epoch=1
05/26/2022 11:23:05 - INFO - __main__ - Saving model with best Classification-F1: 0.27381192234660695 -> 0.43019283492008376 on epoch=1, global_step=200
05/26/2022 11:23:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=1
05/26/2022 11:23:10 - INFO - __main__ - Step 220 Global step 220 Train loss 0.71 on epoch=1
05/26/2022 11:23:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.64 on epoch=2
05/26/2022 11:23:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=2
05/26/2022 11:23:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=2
05/26/2022 11:24:12 - INFO - __main__ - Global step 250 Train loss 0.65 Classification-F1 0.3937400761673721 on epoch=2
05/26/2022 11:24:14 - INFO - __main__ - Step 260 Global step 260 Train loss 0.55 on epoch=2
05/26/2022 11:24:17 - INFO - __main__ - Step 270 Global step 270 Train loss 0.51 on epoch=2
05/26/2022 11:24:20 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=2
05/26/2022 11:24:22 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=2
05/26/2022 11:24:25 - INFO - __main__ - Step 300 Global step 300 Train loss 0.51 on epoch=2
05/26/2022 11:25:22 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.5427782829490334 on epoch=2
05/26/2022 11:25:23 - INFO - __main__ - Saving model with best Classification-F1: 0.43019283492008376 -> 0.5427782829490334 on epoch=2, global_step=300
05/26/2022 11:25:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=2
05/26/2022 11:25:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=2
05/26/2022 11:25:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=2
05/26/2022 11:25:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.43 on epoch=3
05/26/2022 11:25:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=3
05/26/2022 11:26:31 - INFO - __main__ - Global step 350 Train loss 0.47 Classification-F1 0.5429198373489668 on epoch=3
05/26/2022 11:26:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5427782829490334 -> 0.5429198373489668 on epoch=3, global_step=350
05/26/2022 11:26:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=3
05/26/2022 11:26:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=3
05/26/2022 11:26:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=3
05/26/2022 11:26:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=3
05/26/2022 11:26:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.37 on epoch=3
05/26/2022 11:27:42 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.6548766053102097 on epoch=3
05/26/2022 11:27:42 - INFO - __main__ - Saving model with best Classification-F1: 0.5429198373489668 -> 0.6548766053102097 on epoch=3, global_step=400
05/26/2022 11:27:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=3
05/26/2022 11:27:47 - INFO - __main__ - Step 420 Global step 420 Train loss 0.28 on epoch=3
05/26/2022 11:27:50 - INFO - __main__ - Step 430 Global step 430 Train loss 0.26 on epoch=3
05/26/2022 11:27:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=3
05/26/2022 11:27:55 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=4
05/26/2022 11:28:50 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6285453183915011 on epoch=4
05/26/2022 11:28:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=4
05/26/2022 11:28:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=4
05/26/2022 11:28:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=4
05/26/2022 11:29:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=4
05/26/2022 11:29:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
05/26/2022 11:30:01 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.5916097727498224 on epoch=4
05/26/2022 11:30:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
05/26/2022 11:30:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
05/26/2022 11:30:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=4
05/26/2022 11:30:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=4
05/26/2022 11:30:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.19 on epoch=4
05/26/2022 11:31:12 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.695464350999399 on epoch=4
05/26/2022 11:31:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6548766053102097 -> 0.695464350999399 on epoch=4, global_step=550
05/26/2022 11:31:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=4
05/26/2022 11:31:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
05/26/2022 11:31:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=5
05/26/2022 11:31:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.20 on epoch=5
05/26/2022 11:31:25 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
05/26/2022 11:32:20 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.577591991148789 on epoch=5
05/26/2022 11:32:23 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=5
05/26/2022 11:32:26 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=5
05/26/2022 11:32:28 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=5
05/26/2022 11:32:31 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=5
05/26/2022 11:32:34 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=5
05/26/2022 11:33:29 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5887745187877451 on epoch=5
05/26/2022 11:33:32 - INFO - __main__ - Step 660 Global step 660 Train loss 0.12 on epoch=5
05/26/2022 11:33:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=5
05/26/2022 11:33:37 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=6
05/26/2022 11:33:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.19 on epoch=6
05/26/2022 11:33:42 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
05/26/2022 11:34:39 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.5902773939125732 on epoch=6
05/26/2022 11:34:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=6
05/26/2022 11:34:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=6
05/26/2022 11:34:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=6
05/26/2022 11:34:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=6
05/26/2022 11:34:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=6
05/26/2022 11:35:46 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.6754236429832137 on epoch=6
05/26/2022 11:35:48 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=6
05/26/2022 11:35:51 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=6
05/26/2022 11:35:53 - INFO - __main__ - Step 780 Global step 780 Train loss 0.20 on epoch=6
05/26/2022 11:35:56 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=7
05/26/2022 11:35:59 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/26/2022 11:36:51 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.7100067791329157 on epoch=7
05/26/2022 11:36:51 - INFO - __main__ - Saving model with best Classification-F1: 0.695464350999399 -> 0.7100067791329157 on epoch=7, global_step=800
05/26/2022 11:36:54 - INFO - __main__ - Step 810 Global step 810 Train loss 0.10 on epoch=7
05/26/2022 11:36:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=7
05/26/2022 11:36:59 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=7
05/26/2022 11:37:02 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=7
05/26/2022 11:37:04 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
05/26/2022 11:37:58 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7288737229251359 on epoch=7
05/26/2022 11:37:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7100067791329157 -> 0.7288737229251359 on epoch=7, global_step=850
05/26/2022 11:38:01 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=7
05/26/2022 11:38:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=7
05/26/2022 11:38:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=7
05/26/2022 11:38:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=7
05/26/2022 11:38:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.12 on epoch=8
05/26/2022 11:39:04 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.7585939722960965 on epoch=8
05/26/2022 11:39:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7288737229251359 -> 0.7585939722960965 on epoch=8, global_step=900
05/26/2022 11:39:06 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
05/26/2022 11:39:09 - INFO - __main__ - Step 920 Global step 920 Train loss 0.10 on epoch=8
05/26/2022 11:39:12 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=8
05/26/2022 11:39:14 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=8
05/26/2022 11:39:17 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=8
05/26/2022 11:40:08 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.8382262642163202 on epoch=8
05/26/2022 11:40:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7585939722960965 -> 0.8382262642163202 on epoch=8, global_step=950
05/26/2022 11:40:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.20 on epoch=8
05/26/2022 11:40:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=8
05/26/2022 11:40:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=8
05/26/2022 11:40:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.15 on epoch=8
05/26/2022 11:40:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=8
05/26/2022 11:41:17 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.8072060299093288 on epoch=8
05/26/2022 11:41:20 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=9
05/26/2022 11:41:23 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=9
05/26/2022 11:41:25 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=9
05/26/2022 11:41:28 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=9
05/26/2022 11:41:30 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
05/26/2022 11:42:25 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.8058278425254313 on epoch=9
05/26/2022 11:42:28 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=9
05/26/2022 11:42:30 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=9
05/26/2022 11:42:33 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=9
05/26/2022 11:42:36 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=9
05/26/2022 11:42:38 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=9
05/26/2022 11:43:28 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7785086118404667 on epoch=9
05/26/2022 11:43:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=9
05/26/2022 11:43:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=9
05/26/2022 11:43:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/26/2022 11:43:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=10
05/26/2022 11:43:41 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
05/26/2022 11:44:28 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.6372683676586471 on epoch=10
05/26/2022 11:44:31 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=10
05/26/2022 11:44:34 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=10
05/26/2022 11:44:36 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=10
05/26/2022 11:44:39 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=10
05/26/2022 11:44:42 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=10
05/26/2022 11:45:30 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.6294483078713365 on epoch=10
05/26/2022 11:45:32 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=10
05/26/2022 11:45:35 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=10
05/26/2022 11:45:37 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=10
05/26/2022 11:45:40 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=11
05/26/2022 11:45:43 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/26/2022 11:46:33 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.8555748391814854 on epoch=11
05/26/2022 11:46:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8382262642163202 -> 0.8555748391814854 on epoch=11, global_step=1250
05/26/2022 11:46:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=11
05/26/2022 11:46:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=11
05/26/2022 11:46:41 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=11
05/26/2022 11:46:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=11
05/26/2022 11:46:46 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=11
05/26/2022 11:47:34 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.6301300290603794 on epoch=11
05/26/2022 11:47:37 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/26/2022 11:47:39 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
05/26/2022 11:47:42 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=11
05/26/2022 11:47:45 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=11
05/26/2022 11:47:47 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=12
05/26/2022 11:48:36 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.693682629371339 on epoch=12
05/26/2022 11:48:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
05/26/2022 11:48:42 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
05/26/2022 11:48:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=12
05/26/2022 11:48:47 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=12
05/26/2022 11:48:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=12
05/26/2022 11:49:41 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6789009617159462 on epoch=12
05/26/2022 11:49:44 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=12
05/26/2022 11:49:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
05/26/2022 11:49:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=12
05/26/2022 11:49:52 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=12
05/26/2022 11:49:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=12
05/26/2022 11:50:45 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7412337322190239 on epoch=12
05/26/2022 11:50:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=13
05/26/2022 11:50:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=13
05/26/2022 11:50:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
05/26/2022 11:50:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/26/2022 11:50:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=13
05/26/2022 11:51:49 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.5644949999539725 on epoch=13
05/26/2022 11:51:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
05/26/2022 11:51:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=13
05/26/2022 11:51:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
05/26/2022 11:52:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=13
05/26/2022 11:52:03 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=13
05/26/2022 11:52:50 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.6615888335493577 on epoch=13
05/26/2022 11:52:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=13
05/26/2022 11:52:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
05/26/2022 11:52:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=14
05/26/2022 11:53:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=14
05/26/2022 11:53:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/26/2022 11:53:54 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7579961630708583 on epoch=14
05/26/2022 11:53:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=14
05/26/2022 11:53:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=14
05/26/2022 11:54:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=14
05/26/2022 11:54:05 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/26/2022 11:54:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=14
05/26/2022 11:55:02 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7558378513301154 on epoch=14
05/26/2022 11:55:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=14
05/26/2022 11:55:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/26/2022 11:55:10 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=14
05/26/2022 11:55:13 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/26/2022 11:55:15 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=15
05/26/2022 11:56:05 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5891901428023417 on epoch=15
05/26/2022 11:56:07 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
05/26/2022 11:56:10 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=15
05/26/2022 11:56:13 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=15
05/26/2022 11:56:15 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/26/2022 11:56:18 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
05/26/2022 11:57:11 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.9159306435861271 on epoch=15
05/26/2022 11:57:11 - INFO - __main__ - Saving model with best Classification-F1: 0.8555748391814854 -> 0.9159306435861271 on epoch=15, global_step=1750
05/26/2022 11:57:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/26/2022 11:57:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
05/26/2022 11:57:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/26/2022 11:57:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=15
05/26/2022 11:57:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/26/2022 11:58:16 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8551582874814079 on epoch=16
05/26/2022 11:58:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
05/26/2022 11:58:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
05/26/2022 11:58:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
05/26/2022 11:58:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=16
05/26/2022 11:58:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/26/2022 11:59:21 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8086193721914663 on epoch=16
05/26/2022 11:59:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
05/26/2022 11:59:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=16
05/26/2022 11:59:29 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=16
05/26/2022 11:59:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
05/26/2022 11:59:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
05/26/2022 12:00:26 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.9081811264367317 on epoch=16
05/26/2022 12:00:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=17
05/26/2022 12:00:32 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/26/2022 12:00:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
05/26/2022 12:00:37 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=17
05/26/2022 12:00:40 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/26/2022 12:01:29 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.6467237893493264 on epoch=17
05/26/2022 12:01:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
05/26/2022 12:01:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
05/26/2022 12:01:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=17
05/26/2022 12:01:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/26/2022 12:01:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=17
05/26/2022 12:02:31 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7154047779665391 on epoch=17
05/26/2022 12:02:33 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/26/2022 12:02:36 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=18
05/26/2022 12:02:39 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
05/26/2022 12:02:41 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=18
05/26/2022 12:02:44 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=18
05/26/2022 12:03:35 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7644848237778293 on epoch=18
05/26/2022 12:03:38 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=18
05/26/2022 12:03:41 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/26/2022 12:03:43 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
05/26/2022 12:03:46 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 12:03:49 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 12:04:40 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.761219254730568 on epoch=18
05/26/2022 12:04:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=18
05/26/2022 12:04:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.14 on epoch=18
05/26/2022 12:04:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
05/26/2022 12:04:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=19
05/26/2022 12:04:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/26/2022 12:05:45 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8097288226672964 on epoch=19
05/26/2022 12:05:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=19
05/26/2022 12:05:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 12:05:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=19
05/26/2022 12:05:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=19
05/26/2022 12:05:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=19
05/26/2022 12:06:46 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7234160008804499 on epoch=19
05/26/2022 12:06:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 12:06:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=19
05/26/2022 12:06:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/26/2022 12:06:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
05/26/2022 12:06:59 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/26/2022 12:07:48 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8083413290543958 on epoch=20
05/26/2022 12:07:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=20
05/26/2022 12:07:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/26/2022 12:07:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=20
05/26/2022 12:07:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.10 on epoch=20
05/26/2022 12:08:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/26/2022 12:08:52 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8055238786915055 on epoch=20
05/26/2022 12:08:54 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/26/2022 12:08:57 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 12:09:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/26/2022 12:09:02 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/26/2022 12:09:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
05/26/2022 12:09:57 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.7165220689047122 on epoch=20
05/26/2022 12:10:00 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=21
05/26/2022 12:10:03 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/26/2022 12:10:05 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
05/26/2022 12:10:08 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/26/2022 12:10:10 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
05/26/2022 12:11:01 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6884161041543407 on epoch=21
05/26/2022 12:11:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/26/2022 12:11:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=21
05/26/2022 12:11:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/26/2022 12:11:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
05/26/2022 12:11:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=21
05/26/2022 12:12:04 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8050059112853849 on epoch=21
05/26/2022 12:12:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=21
05/26/2022 12:12:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=22
05/26/2022 12:12:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/26/2022 12:12:15 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
05/26/2022 12:12:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/26/2022 12:13:08 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.8078463749321283 on epoch=22
05/26/2022 12:13:10 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
05/26/2022 12:13:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=22
05/26/2022 12:13:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=22
05/26/2022 12:13:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/26/2022 12:13:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/26/2022 12:14:13 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7228499520976518 on epoch=22
05/26/2022 12:14:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
05/26/2022 12:14:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
05/26/2022 12:14:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=23
05/26/2022 12:14:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=23
05/26/2022 12:14:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
05/26/2022 12:15:17 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8106333603293614 on epoch=23
05/26/2022 12:15:19 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/26/2022 12:15:22 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 12:15:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=23
05/26/2022 12:15:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 12:15:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
05/26/2022 12:16:20 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.918022391319182 on epoch=23
05/26/2022 12:16:20 - INFO - __main__ - Saving model with best Classification-F1: 0.9159306435861271 -> 0.918022391319182 on epoch=23, global_step=2650
05/26/2022 12:16:22 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/26/2022 12:16:25 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/26/2022 12:16:28 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
05/26/2022 12:16:30 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/26/2022 12:16:33 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/26/2022 12:17:26 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8589216805688062 on epoch=24
05/26/2022 12:17:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/26/2022 12:17:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
05/26/2022 12:17:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=24
05/26/2022 12:17:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=24
05/26/2022 12:17:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.07 on epoch=24
05/26/2022 12:18:28 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7588486107357757 on epoch=24
05/26/2022 12:18:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/26/2022 12:18:33 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 12:18:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=24
05/26/2022 12:18:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/26/2022 12:18:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 12:19:31 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9190405082420418 on epoch=24
05/26/2022 12:19:31 - INFO - __main__ - Saving model with best Classification-F1: 0.918022391319182 -> 0.9190405082420418 on epoch=24, global_step=2800
05/26/2022 12:19:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=25
05/26/2022 12:19:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/26/2022 12:19:39 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/26/2022 12:19:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 12:19:44 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
05/26/2022 12:20:34 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7212064173547192 on epoch=25
05/26/2022 12:20:36 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 12:20:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/26/2022 12:20:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.10 on epoch=25
05/26/2022 12:20:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/26/2022 12:20:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=25
05/26/2022 12:21:36 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7675722993887126 on epoch=25
05/26/2022 12:21:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
05/26/2022 12:21:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/26/2022 12:21:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 12:21:47 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 12:21:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/26/2022 12:22:39 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8630525059740913 on epoch=26
05/26/2022 12:22:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
05/26/2022 12:22:44 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=26
05/26/2022 12:22:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/26/2022 12:22:49 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/26/2022 12:22:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/26/2022 12:22:53 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 12:22:53 - INFO - __main__ - Printing 3 examples
05/26/2022 12:22:53 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 12:22:53 - INFO - __main__ - ['Plant']
05/26/2022 12:22:53 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 12:22:53 - INFO - __main__ - ['Plant']
05/26/2022 12:22:53 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 12:22:53 - INFO - __main__ - ['Plant']
05/26/2022 12:22:53 - INFO - __main__ - Tokenizing Input ...
05/26/2022 12:22:54 - INFO - __main__ - Tokenizing Output ...
05/26/2022 12:22:56 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 12:22:56 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 12:22:56 - INFO - __main__ - Printing 3 examples
05/26/2022 12:22:56 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 12:22:56 - INFO - __main__ - ['Plant']
05/26/2022 12:22:56 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 12:22:56 - INFO - __main__ - ['Plant']
05/26/2022 12:22:56 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 12:22:56 - INFO - __main__ - ['Plant']
05/26/2022 12:22:56 - INFO - __main__ - Tokenizing Input ...
05/26/2022 12:22:57 - INFO - __main__ - Tokenizing Output ...
05/26/2022 12:22:58 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 12:23:14 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 12:23:14 - INFO - __main__ - task name: dbpedia_14
05/26/2022 12:23:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 12:23:15 - INFO - __main__ - Starting training!
05/26/2022 12:23:40 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9182517973459768 on epoch=26
05/26/2022 12:23:40 - INFO - __main__ - save last model!
05/26/2022 12:23:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 12:23:41 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 12:23:41 - INFO - __main__ - Printing 3 examples
05/26/2022 12:23:41 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 12:23:41 - INFO - __main__ - ['Animal']
05/26/2022 12:23:41 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 12:23:41 - INFO - __main__ - ['Animal']
05/26/2022 12:23:41 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 12:23:41 - INFO - __main__ - ['Village']
05/26/2022 12:23:41 - INFO - __main__ - Tokenizing Input ...
05/26/2022 12:23:42 - INFO - __main__ - Tokenizing Output ...
05/26/2022 12:23:46 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 12:25:57 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.3_8_predictions.txt
05/26/2022 12:25:57 - INFO - __main__ - Classification-F1 on test data: 0.8095
05/26/2022 12:25:57 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.3, bsz=8, dev_performance=0.9190405082420418, test_performance=0.8094505239031006
05/26/2022 12:25:57 - INFO - __main__ - Running ... prefix=dbpedia_14_128_21, lr=0.2, bsz=8 ...
05/26/2022 12:25:58 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 12:25:58 - INFO - __main__ - Printing 3 examples
05/26/2022 12:25:58 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/26/2022 12:25:58 - INFO - __main__ - ['Plant']
05/26/2022 12:25:58 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/26/2022 12:25:58 - INFO - __main__ - ['Plant']
05/26/2022 12:25:58 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/26/2022 12:25:58 - INFO - __main__ - ['Plant']
05/26/2022 12:25:58 - INFO - __main__ - Tokenizing Input ...
05/26/2022 12:25:59 - INFO - __main__ - Tokenizing Output ...
05/26/2022 12:26:01 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 12:26:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 12:26:01 - INFO - __main__ - Printing 3 examples
05/26/2022 12:26:01 - INFO - __main__ -  [dbpedia_14] Sabal pumos is a species of flowering plant in the palm tree family Arecaceae. It is native to the dry forests along the Balsas River in central Mexico (Guanajuato Guerrero Jalisco Michoacán Morelos Zacatecas and the State of México). It is threatened by habitat loss.
05/26/2022 12:26:01 - INFO - __main__ - ['Plant']
05/26/2022 12:26:01 - INFO - __main__ -  [dbpedia_14] Bulbophyllum intricatum is a species of orchid in the genus Bulbophyllum.
05/26/2022 12:26:01 - INFO - __main__ - ['Plant']
05/26/2022 12:26:01 - INFO - __main__ -  [dbpedia_14] Gentiana parryi (Parry's Gentian) is a species of the genus Gentiana.
05/26/2022 12:26:01 - INFO - __main__ - ['Plant']
05/26/2022 12:26:01 - INFO - __main__ - Tokenizing Input ...
05/26/2022 12:26:02 - INFO - __main__ - Tokenizing Output ...
05/26/2022 12:26:04 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 12:26:19 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 12:26:19 - INFO - __main__ - task name: dbpedia_14
05/26/2022 12:26:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 12:26:20 - INFO - __main__ - Starting training!
05/26/2022 12:26:23 - INFO - __main__ - Step 10 Global step 10 Train loss 7.09 on epoch=0
05/26/2022 12:26:26 - INFO - __main__ - Step 20 Global step 20 Train loss 6.31 on epoch=0
05/26/2022 12:26:29 - INFO - __main__ - Step 30 Global step 30 Train loss 5.33 on epoch=0
05/26/2022 12:26:31 - INFO - __main__ - Step 40 Global step 40 Train loss 4.25 on epoch=0
05/26/2022 12:26:34 - INFO - __main__ - Step 50 Global step 50 Train loss 3.75 on epoch=0
05/26/2022 12:37:29 - INFO - __main__ - Global step 50 Train loss 5.35 Classification-F1 0.001817899234305575 on epoch=0
05/26/2022 12:37:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.001817899234305575 on epoch=0, global_step=50
05/26/2022 12:37:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.06 on epoch=0
05/26/2022 12:37:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.79 on epoch=0
05/26/2022 12:37:38 - INFO - __main__ - Step 80 Global step 80 Train loss 2.37 on epoch=0
05/26/2022 12:37:40 - INFO - __main__ - Step 90 Global step 90 Train loss 2.13 on epoch=0
05/26/2022 12:37:43 - INFO - __main__ - Step 100 Global step 100 Train loss 1.88 on epoch=0
05/26/2022 12:39:12 - INFO - __main__ - Global step 100 Train loss 2.45 Classification-F1 0.0868322326869529 on epoch=0
05/26/2022 12:39:12 - INFO - __main__ - Saving model with best Classification-F1: 0.001817899234305575 -> 0.0868322326869529 on epoch=0, global_step=100
05/26/2022 12:39:15 - INFO - __main__ - Step 110 Global step 110 Train loss 1.59 on epoch=0
05/26/2022 12:39:17 - INFO - __main__ - Step 120 Global step 120 Train loss 1.60 on epoch=1
05/26/2022 12:39:20 - INFO - __main__ - Step 130 Global step 130 Train loss 1.44 on epoch=1
05/26/2022 12:39:23 - INFO - __main__ - Step 140 Global step 140 Train loss 1.32 on epoch=1
05/26/2022 12:39:25 - INFO - __main__ - Step 150 Global step 150 Train loss 1.13 on epoch=1
05/26/2022 12:40:36 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.19301084517542197 on epoch=1
05/26/2022 12:40:36 - INFO - __main__ - Saving model with best Classification-F1: 0.0868322326869529 -> 0.19301084517542197 on epoch=1, global_step=150
05/26/2022 12:40:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.15 on epoch=1
05/26/2022 12:40:41 - INFO - __main__ - Step 170 Global step 170 Train loss 1.17 on epoch=1
05/26/2022 12:40:43 - INFO - __main__ - Step 180 Global step 180 Train loss 1.07 on epoch=1
05/26/2022 12:40:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.97 on epoch=1
05/26/2022 12:40:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.91 on epoch=1
05/26/2022 12:42:00 - INFO - __main__ - Global step 200 Train loss 1.05 Classification-F1 0.22061206023970542 on epoch=1
05/26/2022 12:42:00 - INFO - __main__ - Saving model with best Classification-F1: 0.19301084517542197 -> 0.22061206023970542 on epoch=1, global_step=200
05/26/2022 12:42:02 - INFO - __main__ - Step 210 Global step 210 Train loss 0.96 on epoch=1
05/26/2022 12:42:05 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=1
05/26/2022 12:42:08 - INFO - __main__ - Step 230 Global step 230 Train loss 0.70 on epoch=2
05/26/2022 12:42:11 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=2
05/26/2022 12:42:13 - INFO - __main__ - Step 250 Global step 250 Train loss 0.80 on epoch=2
05/26/2022 12:43:18 - INFO - __main__ - Global step 250 Train loss 0.82 Classification-F1 0.2777839904917132 on epoch=2
05/26/2022 12:43:18 - INFO - __main__ - Saving model with best Classification-F1: 0.22061206023970542 -> 0.2777839904917132 on epoch=2, global_step=250
05/26/2022 12:43:21 - INFO - __main__ - Step 260 Global step 260 Train loss 0.73 on epoch=2
05/26/2022 12:43:24 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=2
05/26/2022 12:43:26 - INFO - __main__ - Step 280 Global step 280 Train loss 0.82 on epoch=2
05/26/2022 12:43:29 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=2
05/26/2022 12:43:32 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=2
05/26/2022 12:44:36 - INFO - __main__ - Global step 300 Train loss 0.74 Classification-F1 0.25693428263004614 on epoch=2
05/26/2022 12:44:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=2
05/26/2022 12:44:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.63 on epoch=2
05/26/2022 12:44:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.68 on epoch=2
05/26/2022 12:44:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/26/2022 12:44:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.55 on epoch=3
05/26/2022 12:45:52 - INFO - __main__ - Global step 350 Train loss 0.63 Classification-F1 0.32646352381946925 on epoch=3
05/26/2022 12:45:52 - INFO - __main__ - Saving model with best Classification-F1: 0.2777839904917132 -> 0.32646352381946925 on epoch=3, global_step=350
05/26/2022 12:45:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=3
05/26/2022 12:45:57 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=3
05/26/2022 12:46:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=3
05/26/2022 12:46:02 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=3
05/26/2022 12:46:05 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=3
05/26/2022 12:47:03 - INFO - __main__ - Global step 400 Train loss 0.60 Classification-F1 0.4064268546653074 on epoch=3
05/26/2022 12:47:03 - INFO - __main__ - Saving model with best Classification-F1: 0.32646352381946925 -> 0.4064268546653074 on epoch=3, global_step=400
05/26/2022 12:47:06 - INFO - __main__ - Step 410 Global step 410 Train loss 0.64 on epoch=3
05/26/2022 12:47:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=3
05/26/2022 12:47:11 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=3
05/26/2022 12:47:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=3
05/26/2022 12:47:16 - INFO - __main__ - Step 450 Global step 450 Train loss 0.53 on epoch=4
05/26/2022 12:48:10 - INFO - __main__ - Global step 450 Train loss 0.55 Classification-F1 0.3350406814932952 on epoch=4
05/26/2022 12:48:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=4
05/26/2022 12:48:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.50 on epoch=4
05/26/2022 12:48:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=4
05/26/2022 12:48:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.44 on epoch=4
05/26/2022 12:48:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=4
05/26/2022 12:49:17 - INFO - __main__ - Global step 500 Train loss 0.44 Classification-F1 0.2787219916487469 on epoch=4
05/26/2022 12:49:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.51 on epoch=4
05/26/2022 12:49:23 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=4
05/26/2022 12:49:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.37 on epoch=4
05/26/2022 12:49:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=4
05/26/2022 12:49:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.30 on epoch=4
05/26/2022 12:50:33 - INFO - __main__ - Global step 550 Train loss 0.42 Classification-F1 0.3956454590797841 on epoch=4
05/26/2022 12:50:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.45 on epoch=4
05/26/2022 12:50:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.40 on epoch=5
05/26/2022 12:50:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=5
05/26/2022 12:50:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.39 on epoch=5
05/26/2022 12:50:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=5
05/26/2022 12:51:44 - INFO - __main__ - Global step 600 Train loss 0.37 Classification-F1 0.34039428644726216 on epoch=5
05/26/2022 12:51:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.36 on epoch=5
05/26/2022 12:51:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.30 on epoch=5
05/26/2022 12:51:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=5
05/26/2022 12:51:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.40 on epoch=5
05/26/2022 12:51:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=5
05/26/2022 12:52:51 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.44378167506715377 on epoch=5
05/26/2022 12:52:51 - INFO - __main__ - Saving model with best Classification-F1: 0.4064268546653074 -> 0.44378167506715377 on epoch=5, global_step=650
05/26/2022 12:52:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=5
05/26/2022 12:52:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.27 on epoch=5
05/26/2022 12:52:59 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=6
05/26/2022 12:53:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=6
05/26/2022 12:53:04 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=6
05/26/2022 12:53:58 - INFO - __main__ - Global step 700 Train loss 0.31 Classification-F1 0.4241280823558639 on epoch=6
05/26/2022 12:54:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.28 on epoch=6
05/26/2022 12:54:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=6
05/26/2022 12:54:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=6
05/26/2022 12:54:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=6
05/26/2022 12:54:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=6
05/26/2022 12:55:07 - INFO - __main__ - Global step 750 Train loss 0.28 Classification-F1 0.5390038803820425 on epoch=6
05/26/2022 12:55:07 - INFO - __main__ - Saving model with best Classification-F1: 0.44378167506715377 -> 0.5390038803820425 on epoch=6, global_step=750
05/26/2022 12:55:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.30 on epoch=6
05/26/2022 12:55:12 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=6
05/26/2022 12:55:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=6
05/26/2022 12:55:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.28 on epoch=7
05/26/2022 12:55:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=7
05/26/2022 12:56:11 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.431732417738399 on epoch=7
05/26/2022 12:56:14 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=7
05/26/2022 12:56:16 - INFO - __main__ - Step 820 Global step 820 Train loss 0.26 on epoch=7
05/26/2022 12:56:19 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=7
05/26/2022 12:56:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.27 on epoch=7
05/26/2022 12:56:24 - INFO - __main__ - Step 850 Global step 850 Train loss 0.17 on epoch=7
05/26/2022 12:57:16 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.45494045553536167 on epoch=7
05/26/2022 12:57:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=7
05/26/2022 12:57:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=7
05/26/2022 12:57:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=7
05/26/2022 12:57:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.18 on epoch=7
05/26/2022 12:57:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.29 on epoch=8
05/26/2022 12:58:23 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.6798854616679422 on epoch=8
05/26/2022 12:58:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5390038803820425 -> 0.6798854616679422 on epoch=8, global_step=900
05/26/2022 12:58:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=8
05/26/2022 12:58:28 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=8
05/26/2022 12:58:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=8
05/26/2022 12:58:33 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=8
05/26/2022 12:58:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=8
05/26/2022 12:59:27 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.5179005687565491 on epoch=8
05/26/2022 12:59:30 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
05/26/2022 12:59:33 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
05/26/2022 12:59:35 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=8
05/26/2022 12:59:38 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/26/2022 12:59:40 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=8
05/26/2022 13:00:32 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5236764451671777 on epoch=8
05/26/2022 13:00:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=9
05/26/2022 13:00:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=9
05/26/2022 13:00:40 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=9
05/26/2022 13:00:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=9
05/26/2022 13:00:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.22 on epoch=9
05/26/2022 13:01:44 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7100383199839344 on epoch=9
05/26/2022 13:01:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6798854616679422 -> 0.7100383199839344 on epoch=9, global_step=1050
05/26/2022 13:01:47 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
05/26/2022 13:01:49 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.14 on epoch=9
05/26/2022 13:01:52 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=9
05/26/2022 13:01:55 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=9
05/26/2022 13:01:57 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=9
05/26/2022 13:02:53 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.7775508383195391 on epoch=9
05/26/2022 13:02:53 - INFO - __main__ - Saving model with best Classification-F1: 0.7100383199839344 -> 0.7775508383195391 on epoch=9, global_step=1100
05/26/2022 13:02:56 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=9
05/26/2022 13:02:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=9
05/26/2022 13:03:01 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/26/2022 13:03:04 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=10
05/26/2022 13:03:07 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/26/2022 13:04:02 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6246788642557001 on epoch=10
05/26/2022 13:04:05 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=10
05/26/2022 13:04:07 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=10
05/26/2022 13:04:10 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=10
05/26/2022 13:04:13 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=10
05/26/2022 13:04:15 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=10
05/26/2022 13:05:09 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.716963808174244 on epoch=10
05/26/2022 13:05:12 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.18 on epoch=10
05/26/2022 13:05:14 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.13 on epoch=10
05/26/2022 13:05:17 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=10
05/26/2022 13:05:19 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=11
05/26/2022 13:05:22 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=11
05/26/2022 13:06:14 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.7722651927981495 on epoch=11
05/26/2022 13:06:16 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=11
05/26/2022 13:06:19 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=11
05/26/2022 13:06:21 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=11
05/26/2022 13:06:24 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.12 on epoch=11
05/26/2022 13:06:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/26/2022 13:07:18 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.711071509046696 on epoch=11
05/26/2022 13:07:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=11
05/26/2022 13:07:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=11
05/26/2022 13:07:26 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.07 on epoch=11
05/26/2022 13:07:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
05/26/2022 13:07:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=12
05/26/2022 13:08:23 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.9109201836308413 on epoch=12
05/26/2022 13:08:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7775508383195391 -> 0.9109201836308413 on epoch=12, global_step=1350
05/26/2022 13:08:26 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=12
05/26/2022 13:08:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
05/26/2022 13:08:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=12
05/26/2022 13:08:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=12
05/26/2022 13:08:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=12
05/26/2022 13:09:27 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.7451479212328356 on epoch=12
05/26/2022 13:09:30 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=12
05/26/2022 13:09:33 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=12
05/26/2022 13:09:35 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=12
05/26/2022 13:09:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=12
05/26/2022 13:09:40 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=12
05/26/2022 13:10:31 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.7333050723898911 on epoch=12
05/26/2022 13:10:33 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=13
05/26/2022 13:10:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=13
05/26/2022 13:10:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=13
05/26/2022 13:10:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/26/2022 13:10:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=13
05/26/2022 13:11:34 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7492880938879958 on epoch=13
05/26/2022 13:11:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=13
05/26/2022 13:11:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/26/2022 13:11:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=13
05/26/2022 13:11:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
05/26/2022 13:11:47 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=13
05/26/2022 13:12:38 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6799959723248029 on epoch=13
05/26/2022 13:12:40 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
05/26/2022 13:12:43 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.12 on epoch=14
05/26/2022 13:12:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=14
05/26/2022 13:12:48 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
05/26/2022 13:12:51 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
05/26/2022 13:13:41 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.674607228336909 on epoch=14
05/26/2022 13:13:44 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=14
05/26/2022 13:13:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
05/26/2022 13:13:49 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=14
05/26/2022 13:13:52 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
05/26/2022 13:13:54 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
05/26/2022 13:14:43 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6947636839092829 on epoch=14
05/26/2022 13:14:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
05/26/2022 13:14:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/26/2022 13:14:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=14
05/26/2022 13:14:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=15
05/26/2022 13:14:57 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=15
05/26/2022 13:15:47 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.6111231497759135 on epoch=15
05/26/2022 13:15:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=15
05/26/2022 13:15:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
05/26/2022 13:15:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=15
05/26/2022 13:15:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/26/2022 13:16:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=15
05/26/2022 13:16:51 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6726238313831563 on epoch=15
05/26/2022 13:16:53 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=15
05/26/2022 13:16:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=15
05/26/2022 13:16:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/26/2022 13:17:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
05/26/2022 13:17:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/26/2022 13:17:53 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.5867199772488965 on epoch=16
05/26/2022 13:17:56 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=16
05/26/2022 13:17:59 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=16
05/26/2022 13:18:01 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=16
05/26/2022 13:18:04 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=16
05/26/2022 13:18:07 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/26/2022 13:18:55 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.5861914278949452 on epoch=16
05/26/2022 13:18:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/26/2022 13:19:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=16
05/26/2022 13:19:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=16
05/26/2022 13:19:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
05/26/2022 13:19:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=16
05/26/2022 13:19:56 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6122120143754433 on epoch=16
05/26/2022 13:19:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=17
05/26/2022 13:20:02 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=17
05/26/2022 13:20:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
05/26/2022 13:20:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 13:20:10 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.13 on epoch=17
05/26/2022 13:20:58 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.6270566958036184 on epoch=17
05/26/2022 13:21:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=17
05/26/2022 13:21:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=17
05/26/2022 13:21:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=17
05/26/2022 13:21:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=17
05/26/2022 13:21:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
05/26/2022 13:21:58 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7056751945861278 on epoch=17
05/26/2022 13:22:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.10 on epoch=17
05/26/2022 13:22:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=18
05/26/2022 13:22:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/26/2022 13:22:09 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=18
05/26/2022 13:22:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=18
05/26/2022 13:22:59 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.6434192681240706 on epoch=18
05/26/2022 13:23:01 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=18
05/26/2022 13:23:04 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
05/26/2022 13:23:07 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/26/2022 13:23:10 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=18
05/26/2022 13:23:12 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=18
05/26/2022 13:24:00 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7510183841092242 on epoch=18
05/26/2022 13:24:03 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=18
05/26/2022 13:24:05 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
05/26/2022 13:24:08 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=19
05/26/2022 13:24:11 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=19
05/26/2022 13:24:13 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=19
05/26/2022 13:25:01 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7095780828463542 on epoch=19
05/26/2022 13:25:03 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/26/2022 13:25:06 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 13:25:09 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 13:25:11 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/26/2022 13:25:14 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=19
05/26/2022 13:25:59 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7097017766832913 on epoch=19
05/26/2022 13:26:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=19
05/26/2022 13:26:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 13:26:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/26/2022 13:26:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/26/2022 13:26:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/26/2022 13:27:00 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8603256306017586 on epoch=20
05/26/2022 13:27:03 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=20
05/26/2022 13:27:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=20
05/26/2022 13:27:08 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
05/26/2022 13:27:11 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=20
05/26/2022 13:27:13 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=20
05/26/2022 13:27:59 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7434803586569201 on epoch=20
05/26/2022 13:28:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=20
05/26/2022 13:28:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 13:28:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/26/2022 13:28:10 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=20
05/26/2022 13:28:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
05/26/2022 13:28:58 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.6180256178093958 on epoch=20
05/26/2022 13:29:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/26/2022 13:29:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/26/2022 13:29:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=21
05/26/2022 13:29:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=21
05/26/2022 13:29:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=21
05/26/2022 13:30:02 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.722634245313008 on epoch=21
05/26/2022 13:30:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=21
05/26/2022 13:30:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=21
05/26/2022 13:30:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=21
05/26/2022 13:30:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
05/26/2022 13:30:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/26/2022 13:31:01 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7388995451878948 on epoch=21
05/26/2022 13:31:04 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
05/26/2022 13:31:06 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/26/2022 13:31:09 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=22
05/26/2022 13:31:12 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
05/26/2022 13:31:14 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/26/2022 13:32:02 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7239162941734544 on epoch=22
05/26/2022 13:32:05 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=22
05/26/2022 13:32:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
05/26/2022 13:32:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=22
05/26/2022 13:32:13 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/26/2022 13:32:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/26/2022 13:33:03 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8120001349271231 on epoch=22
05/26/2022 13:33:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=22
05/26/2022 13:33:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/26/2022 13:33:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
05/26/2022 13:33:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=23
05/26/2022 13:33:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/26/2022 13:34:04 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7242473443853112 on epoch=23
05/26/2022 13:34:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=23
05/26/2022 13:34:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=23
05/26/2022 13:34:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/26/2022 13:34:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
05/26/2022 13:34:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/26/2022 13:35:03 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.752554399944279 on epoch=23
05/26/2022 13:35:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/26/2022 13:35:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
05/26/2022 13:35:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
05/26/2022 13:35:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=24
05/26/2022 13:35:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=24
05/26/2022 13:36:03 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.6855168628521143 on epoch=24
05/26/2022 13:36:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=24
05/26/2022 13:36:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
05/26/2022 13:36:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 13:36:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/26/2022 13:36:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=24
05/26/2022 13:37:03 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.76125053669677 on epoch=24
05/26/2022 13:37:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=24
05/26/2022 13:37:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 13:37:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=24
05/26/2022 13:37:14 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/26/2022 13:37:16 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=24
05/26/2022 13:38:05 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8117804527698042 on epoch=24
05/26/2022 13:38:08 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/26/2022 13:38:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/26/2022 13:38:13 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/26/2022 13:38:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 13:38:18 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/26/2022 13:39:06 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8089274033824614 on epoch=25
05/26/2022 13:39:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=25
05/26/2022 13:39:11 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=25
05/26/2022 13:39:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/26/2022 13:39:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/26/2022 13:39:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/26/2022 13:40:05 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6806388762721004 on epoch=25
05/26/2022 13:40:08 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
05/26/2022 13:40:11 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/26/2022 13:40:13 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=26
05/26/2022 13:40:16 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 13:40:19 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/26/2022 13:41:06 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7605312722852134 on epoch=26
05/26/2022 13:41:09 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/26/2022 13:41:11 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 13:41:14 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=26
05/26/2022 13:41:17 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/26/2022 13:41:19 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/26/2022 13:41:21 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 13:41:21 - INFO - __main__ - Printing 3 examples
05/26/2022 13:41:21 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 13:41:21 - INFO - __main__ - ['Company']
05/26/2022 13:41:21 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 13:41:21 - INFO - __main__ - ['Company']
05/26/2022 13:41:21 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 13:41:21 - INFO - __main__ - ['Company']
05/26/2022 13:41:21 - INFO - __main__ - Tokenizing Input ...
05/26/2022 13:41:22 - INFO - __main__ - Tokenizing Output ...
05/26/2022 13:41:23 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 13:41:23 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 13:41:23 - INFO - __main__ - Printing 3 examples
05/26/2022 13:41:23 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 13:41:23 - INFO - __main__ - ['Company']
05/26/2022 13:41:23 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 13:41:23 - INFO - __main__ - ['Company']
05/26/2022 13:41:23 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 13:41:23 - INFO - __main__ - ['Company']
05/26/2022 13:41:23 - INFO - __main__ - Tokenizing Input ...
05/26/2022 13:41:24 - INFO - __main__ - Tokenizing Output ...
05/26/2022 13:41:26 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 13:41:42 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 13:41:42 - INFO - __main__ - task name: dbpedia_14
05/26/2022 13:41:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 13:41:43 - INFO - __main__ - Starting training!
05/26/2022 13:42:06 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7473523563769506 on epoch=26
05/26/2022 13:42:06 - INFO - __main__ - save last model!
05/26/2022 13:42:06 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 13:42:06 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 13:42:06 - INFO - __main__ - Printing 3 examples
05/26/2022 13:42:06 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 13:42:06 - INFO - __main__ - ['Animal']
05/26/2022 13:42:06 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 13:42:06 - INFO - __main__ - ['Animal']
05/26/2022 13:42:06 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 13:42:06 - INFO - __main__ - ['Village']
05/26/2022 13:42:06 - INFO - __main__ - Tokenizing Input ...
05/26/2022 13:42:08 - INFO - __main__ - Tokenizing Output ...
05/26/2022 13:42:11 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 13:44:15 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_21_0.2_8_predictions.txt
05/26/2022 13:44:15 - INFO - __main__ - Classification-F1 on test data: 0.6131
05/26/2022 13:44:15 - INFO - __main__ - prefix=dbpedia_14_128_21, lr=0.2, bsz=8, dev_performance=0.9109201836308413, test_performance=0.6131007591516352
05/26/2022 13:44:15 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.5, bsz=8 ...
05/26/2022 13:44:16 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 13:44:16 - INFO - __main__ - Printing 3 examples
05/26/2022 13:44:16 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 13:44:16 - INFO - __main__ - ['Company']
05/26/2022 13:44:16 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 13:44:16 - INFO - __main__ - ['Company']
05/26/2022 13:44:16 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 13:44:16 - INFO - __main__ - ['Company']
05/26/2022 13:44:16 - INFO - __main__ - Tokenizing Input ...
05/26/2022 13:44:17 - INFO - __main__ - Tokenizing Output ...
05/26/2022 13:44:19 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 13:44:19 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 13:44:19 - INFO - __main__ - Printing 3 examples
05/26/2022 13:44:19 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 13:44:19 - INFO - __main__ - ['Company']
05/26/2022 13:44:19 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 13:44:19 - INFO - __main__ - ['Company']
05/26/2022 13:44:19 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 13:44:19 - INFO - __main__ - ['Company']
05/26/2022 13:44:19 - INFO - __main__ - Tokenizing Input ...
05/26/2022 13:44:20 - INFO - __main__ - Tokenizing Output ...
05/26/2022 13:44:21 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 13:44:37 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 13:44:37 - INFO - __main__ - task name: dbpedia_14
05/26/2022 13:44:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 13:44:38 - INFO - __main__ - Starting training!
05/26/2022 13:44:41 - INFO - __main__ - Step 10 Global step 10 Train loss 6.63 on epoch=0
05/26/2022 13:44:44 - INFO - __main__ - Step 20 Global step 20 Train loss 4.91 on epoch=0
05/26/2022 13:44:46 - INFO - __main__ - Step 30 Global step 30 Train loss 3.28 on epoch=0
05/26/2022 13:44:49 - INFO - __main__ - Step 40 Global step 40 Train loss 2.34 on epoch=0
05/26/2022 13:44:52 - INFO - __main__ - Step 50 Global step 50 Train loss 1.91 on epoch=0
05/26/2022 13:45:49 - INFO - __main__ - Global step 50 Train loss 3.81 Classification-F1 0.10533259761620989 on epoch=0
05/26/2022 13:45:49 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.10533259761620989 on epoch=0, global_step=50
05/26/2022 13:45:51 - INFO - __main__ - Step 60 Global step 60 Train loss 1.44 on epoch=0
05/26/2022 13:45:54 - INFO - __main__ - Step 70 Global step 70 Train loss 1.36 on epoch=0
05/26/2022 13:45:57 - INFO - __main__ - Step 80 Global step 80 Train loss 1.15 on epoch=0
05/26/2022 13:45:59 - INFO - __main__ - Step 90 Global step 90 Train loss 1.04 on epoch=0
05/26/2022 13:46:02 - INFO - __main__ - Step 100 Global step 100 Train loss 0.87 on epoch=0
05/26/2022 13:47:01 - INFO - __main__ - Global step 100 Train loss 1.17 Classification-F1 0.295644294251262 on epoch=0
05/26/2022 13:47:01 - INFO - __main__ - Saving model with best Classification-F1: 0.10533259761620989 -> 0.295644294251262 on epoch=0, global_step=100
05/26/2022 13:47:04 - INFO - __main__ - Step 110 Global step 110 Train loss 0.98 on epoch=0
05/26/2022 13:47:07 - INFO - __main__ - Step 120 Global step 120 Train loss 0.86 on epoch=1
05/26/2022 13:47:09 - INFO - __main__ - Step 130 Global step 130 Train loss 0.86 on epoch=1
05/26/2022 13:47:12 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=1
05/26/2022 13:47:15 - INFO - __main__ - Step 150 Global step 150 Train loss 0.73 on epoch=1
05/26/2022 13:48:12 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.39422393322044047 on epoch=1
05/26/2022 13:48:13 - INFO - __main__ - Saving model with best Classification-F1: 0.295644294251262 -> 0.39422393322044047 on epoch=1, global_step=150
05/26/2022 13:48:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.73 on epoch=1
05/26/2022 13:48:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.62 on epoch=1
05/26/2022 13:48:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=1
05/26/2022 13:48:23 - INFO - __main__ - Step 190 Global step 190 Train loss 0.70 on epoch=1
05/26/2022 13:48:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=1
05/26/2022 13:49:21 - INFO - __main__ - Global step 200 Train loss 0.69 Classification-F1 0.45996523162918085 on epoch=1
05/26/2022 13:49:21 - INFO - __main__ - Saving model with best Classification-F1: 0.39422393322044047 -> 0.45996523162918085 on epoch=1, global_step=200
05/26/2022 13:49:23 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=1
05/26/2022 13:49:26 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=1
05/26/2022 13:49:29 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=2
05/26/2022 13:49:31 - INFO - __main__ - Step 240 Global step 240 Train loss 0.58 on epoch=2
05/26/2022 13:49:34 - INFO - __main__ - Step 250 Global step 250 Train loss 0.54 on epoch=2
05/26/2022 13:50:28 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.3206161543951738 on epoch=2
05/26/2022 13:50:31 - INFO - __main__ - Step 260 Global step 260 Train loss 0.52 on epoch=2
05/26/2022 13:50:33 - INFO - __main__ - Step 270 Global step 270 Train loss 0.64 on epoch=2
05/26/2022 13:50:36 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=2
05/26/2022 13:50:39 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=2
05/26/2022 13:50:41 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=2
05/26/2022 13:51:37 - INFO - __main__ - Global step 300 Train loss 0.50 Classification-F1 0.41801614868603415 on epoch=2
05/26/2022 13:51:40 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=2
05/26/2022 13:51:43 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=2
05/26/2022 13:51:45 - INFO - __main__ - Step 330 Global step 330 Train loss 0.43 on epoch=2
05/26/2022 13:51:48 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=3
05/26/2022 13:51:51 - INFO - __main__ - Step 350 Global step 350 Train loss 0.46 on epoch=3
05/26/2022 13:52:54 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.4328738485287134 on epoch=3
05/26/2022 13:52:57 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=3
05/26/2022 13:53:00 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=3
05/26/2022 13:53:02 - INFO - __main__ - Step 380 Global step 380 Train loss 0.49 on epoch=3
05/26/2022 13:53:05 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=3
05/26/2022 13:53:08 - INFO - __main__ - Step 400 Global step 400 Train loss 0.36 on epoch=3
05/26/2022 13:54:10 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.37458623626137455 on epoch=3
05/26/2022 13:54:13 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=3
05/26/2022 13:54:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.37 on epoch=3
05/26/2022 13:54:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=3
05/26/2022 13:54:21 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=3
05/26/2022 13:54:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=4
05/26/2022 13:55:21 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.6115396574676457 on epoch=4
05/26/2022 13:55:21 - INFO - __main__ - Saving model with best Classification-F1: 0.45996523162918085 -> 0.6115396574676457 on epoch=4, global_step=450
05/26/2022 13:55:24 - INFO - __main__ - Step 460 Global step 460 Train loss 0.36 on epoch=4
05/26/2022 13:55:27 - INFO - __main__ - Step 470 Global step 470 Train loss 0.37 on epoch=4
05/26/2022 13:55:29 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=4
05/26/2022 13:55:32 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=4
05/26/2022 13:55:35 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=4
05/26/2022 13:56:29 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.36388164719911165 on epoch=4
05/26/2022 13:56:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=4
05/26/2022 13:56:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=4
05/26/2022 13:56:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=4
05/26/2022 13:56:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.34 on epoch=4
05/26/2022 13:56:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=4
05/26/2022 13:57:40 - INFO - __main__ - Global step 550 Train loss 0.26 Classification-F1 0.6214993480979129 on epoch=4
05/26/2022 13:57:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6115396574676457 -> 0.6214993480979129 on epoch=4, global_step=550
05/26/2022 13:57:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=4
05/26/2022 13:57:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.17 on epoch=5
05/26/2022 13:57:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=5
05/26/2022 13:57:50 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=5
05/26/2022 13:57:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=5
05/26/2022 13:58:48 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.41019600194196265 on epoch=5
05/26/2022 13:58:51 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=5
05/26/2022 13:58:54 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=5
05/26/2022 13:58:56 - INFO - __main__ - Step 630 Global step 630 Train loss 0.18 on epoch=5
05/26/2022 13:58:59 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=5
05/26/2022 13:59:01 - INFO - __main__ - Step 650 Global step 650 Train loss 0.14 on epoch=5
05/26/2022 13:59:53 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6686440071418062 on epoch=5
05/26/2022 13:59:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6214993480979129 -> 0.6686440071418062 on epoch=5, global_step=650
05/26/2022 13:59:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=5
05/26/2022 13:59:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.11 on epoch=5
05/26/2022 14:00:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=6
05/26/2022 14:00:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=6
05/26/2022 14:00:06 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=6
05/26/2022 14:00:58 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.5353166101487884 on epoch=6
05/26/2022 14:01:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=6
05/26/2022 14:01:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=6
05/26/2022 14:01:05 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=6
05/26/2022 14:01:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=6
05/26/2022 14:01:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.13 on epoch=6
05/26/2022 14:02:02 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.5051715181485271 on epoch=6
05/26/2022 14:02:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=6
05/26/2022 14:02:07 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=6
05/26/2022 14:02:10 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=6
05/26/2022 14:02:12 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=7
05/26/2022 14:02:15 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=7
05/26/2022 14:03:12 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.5990187830823401 on epoch=7
05/26/2022 14:03:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=7
05/26/2022 14:03:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=7
05/26/2022 14:03:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.17 on epoch=7
05/26/2022 14:03:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=7
05/26/2022 14:03:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=7
05/26/2022 14:04:14 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.6936094803645275 on epoch=7
05/26/2022 14:04:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6686440071418062 -> 0.6936094803645275 on epoch=7, global_step=850
05/26/2022 14:04:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=7
05/26/2022 14:04:19 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=7
05/26/2022 14:04:22 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=7
05/26/2022 14:04:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=7
05/26/2022 14:04:27 - INFO - __main__ - Step 900 Global step 900 Train loss 0.06 on epoch=8
05/26/2022 14:05:16 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.614458293220496 on epoch=8
05/26/2022 14:05:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=8
05/26/2022 14:05:21 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=8
05/26/2022 14:05:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=8
05/26/2022 14:05:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=8
05/26/2022 14:05:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=8
05/26/2022 14:06:18 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.5010662211183667 on epoch=8
05/26/2022 14:06:21 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=8
05/26/2022 14:06:23 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=8
05/26/2022 14:06:26 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=8
05/26/2022 14:06:28 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=8
05/26/2022 14:06:31 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=8
05/26/2022 14:07:19 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.7336862434904474 on epoch=8
05/26/2022 14:07:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6936094803645275 -> 0.7336862434904474 on epoch=8, global_step=1000
05/26/2022 14:07:22 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=9
05/26/2022 14:07:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=9
05/26/2022 14:07:27 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=9
05/26/2022 14:07:30 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=9
05/26/2022 14:07:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=9
05/26/2022 14:08:31 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6908617774887827 on epoch=9
05/26/2022 14:08:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=9
05/26/2022 14:08:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=9
05/26/2022 14:08:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.06 on epoch=9
05/26/2022 14:08:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=9
05/26/2022 14:08:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=9
05/26/2022 14:09:31 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7992049086062996 on epoch=9
05/26/2022 14:09:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7336862434904474 -> 0.7992049086062996 on epoch=9, global_step=1100
05/26/2022 14:09:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.05 on epoch=9
05/26/2022 14:09:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=9
05/26/2022 14:09:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=10
05/26/2022 14:09:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=10
05/26/2022 14:09:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
05/26/2022 14:10:39 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7273146975452709 on epoch=10
05/26/2022 14:10:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=10
05/26/2022 14:10:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=10
05/26/2022 14:10:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.02 on epoch=10
05/26/2022 14:10:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.05 on epoch=10
05/26/2022 14:10:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=10
05/26/2022 14:11:38 - INFO - __main__ - Global step 1200 Train loss 0.05 Classification-F1 0.7458247351449617 on epoch=10
05/26/2022 14:11:40 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=10
05/26/2022 14:11:43 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=10
05/26/2022 14:11:45 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=10
05/26/2022 14:11:48 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
05/26/2022 14:11:51 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=11
05/26/2022 14:12:39 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.7234387102453367 on epoch=11
05/26/2022 14:12:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=11
05/26/2022 14:12:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.06 on epoch=11
05/26/2022 14:12:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=11
05/26/2022 14:12:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=11
05/26/2022 14:12:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/26/2022 14:13:40 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.6143950985315441 on epoch=11
05/26/2022 14:13:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=11
05/26/2022 14:13:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=11
05/26/2022 14:13:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=11
05/26/2022 14:13:51 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.03 on epoch=11
05/26/2022 14:13:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/26/2022 14:14:40 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7948685463300754 on epoch=12
05/26/2022 14:14:42 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=12
05/26/2022 14:14:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=12
05/26/2022 14:14:48 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
05/26/2022 14:14:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=12
05/26/2022 14:14:53 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=12
05/26/2022 14:15:39 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.5835541049256648 on epoch=12
05/26/2022 14:15:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=12
05/26/2022 14:15:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=12
05/26/2022 14:15:47 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=12
05/26/2022 14:15:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=12
05/26/2022 14:15:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=12
05/26/2022 14:16:38 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6574742739195278 on epoch=12
05/26/2022 14:16:41 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=13
05/26/2022 14:16:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=13
05/26/2022 14:16:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=13
05/26/2022 14:16:49 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=13
05/26/2022 14:16:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.08 on epoch=13
05/26/2022 14:17:36 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6945408808021704 on epoch=13
05/26/2022 14:17:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
05/26/2022 14:17:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=13
05/26/2022 14:17:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=13
05/26/2022 14:17:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=13
05/26/2022 14:17:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=13
05/26/2022 14:18:35 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7167377868670456 on epoch=13
05/26/2022 14:18:38 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=13
05/26/2022 14:18:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=14
05/26/2022 14:18:43 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=14
05/26/2022 14:18:46 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=14
05/26/2022 14:18:48 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=14
05/26/2022 14:19:35 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6559372509303515 on epoch=14
05/26/2022 14:19:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=14
05/26/2022 14:19:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=14
05/26/2022 14:19:43 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=14
05/26/2022 14:19:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=14
05/26/2022 14:19:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=14
05/26/2022 14:20:33 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.84585843578697 on epoch=14
05/26/2022 14:20:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7992049086062996 -> 0.84585843578697 on epoch=14, global_step=1650
05/26/2022 14:20:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
05/26/2022 14:20:38 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.06 on epoch=14
05/26/2022 14:20:41 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=14
05/26/2022 14:20:43 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=15
05/26/2022 14:20:46 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=15
05/26/2022 14:21:32 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.673379595199507 on epoch=15
05/26/2022 14:21:35 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=15
05/26/2022 14:21:37 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
05/26/2022 14:21:40 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
05/26/2022 14:21:43 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=15
05/26/2022 14:21:45 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=15
05/26/2022 14:22:31 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7124432991106779 on epoch=15
05/26/2022 14:22:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=15
05/26/2022 14:22:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
05/26/2022 14:22:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=15
05/26/2022 14:22:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=15
05/26/2022 14:22:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=16
05/26/2022 14:23:39 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7000484991790227 on epoch=16
05/26/2022 14:23:41 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=16
05/26/2022 14:23:44 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.01 on epoch=16
05/26/2022 14:23:47 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 14:23:49 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=16
05/26/2022 14:23:52 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=16
05/26/2022 14:24:40 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7480118316031409 on epoch=16
05/26/2022 14:24:43 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
05/26/2022 14:24:45 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=16
05/26/2022 14:24:48 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=16
05/26/2022 14:24:51 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/26/2022 14:24:53 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=16
05/26/2022 14:25:40 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6957150038997315 on epoch=16
05/26/2022 14:25:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/26/2022 14:25:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=17
05/26/2022 14:25:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=17
05/26/2022 14:25:51 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=17
05/26/2022 14:25:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=17
05/26/2022 14:26:38 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6881773298075394 on epoch=17
05/26/2022 14:26:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=17
05/26/2022 14:26:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=17
05/26/2022 14:26:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
05/26/2022 14:26:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=17
05/26/2022 14:26:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=17
05/26/2022 14:27:37 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7408334166002413 on epoch=17
05/26/2022 14:27:39 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
05/26/2022 14:27:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=18
05/26/2022 14:27:44 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=18
05/26/2022 14:27:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=18
05/26/2022 14:27:50 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=18
05/26/2022 14:28:34 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8427650788645736 on epoch=18
05/26/2022 14:28:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/26/2022 14:28:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 14:28:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=18
05/26/2022 14:28:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=18
05/26/2022 14:28:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=18
05/26/2022 14:29:33 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.778507326918618 on epoch=18
05/26/2022 14:29:35 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=18
05/26/2022 14:29:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=18
05/26/2022 14:29:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=19
05/26/2022 14:29:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=19
05/26/2022 14:29:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/26/2022 14:30:30 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7941143244393081 on epoch=19
05/26/2022 14:30:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=19
05/26/2022 14:30:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=19
05/26/2022 14:30:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=19
05/26/2022 14:30:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/26/2022 14:30:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=19
05/26/2022 14:31:28 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7188660698201461 on epoch=19
05/26/2022 14:31:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 14:31:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 14:31:36 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=19
05/26/2022 14:31:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=19
05/26/2022 14:31:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=20
05/26/2022 14:32:26 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.759757644835374 on epoch=20
05/26/2022 14:32:29 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=20
05/26/2022 14:32:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
05/26/2022 14:32:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=20
05/26/2022 14:32:37 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=20
05/26/2022 14:32:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/26/2022 14:33:25 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8068901549950869 on epoch=20
05/26/2022 14:33:28 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=20
05/26/2022 14:33:30 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=20
05/26/2022 14:33:33 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=20
05/26/2022 14:33:35 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=20
05/26/2022 14:33:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
05/26/2022 14:34:24 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8060972494485459 on epoch=20
05/26/2022 14:34:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=21
05/26/2022 14:34:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/26/2022 14:34:31 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=21
05/26/2022 14:34:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 14:34:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=21
05/26/2022 14:35:21 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6550286879728306 on epoch=21
05/26/2022 14:35:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=21
05/26/2022 14:35:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=21
05/26/2022 14:35:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/26/2022 14:35:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/26/2022 14:35:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/26/2022 14:36:19 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.638279058461172 on epoch=21
05/26/2022 14:36:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=21
05/26/2022 14:36:24 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=22
05/26/2022 14:36:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/26/2022 14:36:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=22
05/26/2022 14:36:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/26/2022 14:37:16 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7603519319194966 on epoch=22
05/26/2022 14:37:19 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=22
05/26/2022 14:37:21 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=22
05/26/2022 14:37:24 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/26/2022 14:37:26 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=22
05/26/2022 14:37:29 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=22
05/26/2022 14:38:13 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8079152462743695 on epoch=22
05/26/2022 14:38:16 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=22
05/26/2022 14:38:19 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=22
05/26/2022 14:38:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=23
05/26/2022 14:38:24 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
05/26/2022 14:38:27 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/26/2022 14:39:11 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.8579310298674272 on epoch=23
05/26/2022 14:39:11 - INFO - __main__ - Saving model with best Classification-F1: 0.84585843578697 -> 0.8579310298674272 on epoch=23, global_step=2600
05/26/2022 14:39:14 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=23
05/26/2022 14:39:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=23
05/26/2022 14:39:19 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=23
05/26/2022 14:39:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=23
05/26/2022 14:39:24 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
05/26/2022 14:40:09 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9110383267144498 on epoch=23
05/26/2022 14:40:09 - INFO - __main__ - Saving model with best Classification-F1: 0.8579310298674272 -> 0.9110383267144498 on epoch=23, global_step=2650
05/26/2022 14:40:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=23
05/26/2022 14:40:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/26/2022 14:40:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
05/26/2022 14:40:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=24
05/26/2022 14:40:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.11 on epoch=24
05/26/2022 14:41:07 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8570027743723103 on epoch=24
05/26/2022 14:41:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/26/2022 14:41:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
05/26/2022 14:41:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=24
05/26/2022 14:41:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
05/26/2022 14:41:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=24
05/26/2022 14:42:05 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.76316587363335 on epoch=24
05/26/2022 14:42:08 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=24
05/26/2022 14:42:10 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 14:42:13 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=24
05/26/2022 14:42:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/26/2022 14:42:18 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=24
05/26/2022 14:43:03 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.9153224216305439 on epoch=24
05/26/2022 14:43:03 - INFO - __main__ - Saving model with best Classification-F1: 0.9110383267144498 -> 0.9153224216305439 on epoch=24, global_step=2800
05/26/2022 14:43:05 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/26/2022 14:43:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=25
05/26/2022 14:43:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
05/26/2022 14:43:13 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 14:43:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=25
05/26/2022 14:44:00 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7534959267515716 on epoch=25
05/26/2022 14:44:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/26/2022 14:44:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/26/2022 14:44:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=25
05/26/2022 14:44:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=25
05/26/2022 14:44:13 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/26/2022 14:44:56 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7526230200722598 on epoch=25
05/26/2022 14:44:59 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=25
05/26/2022 14:45:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/26/2022 14:45:04 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=26
05/26/2022 14:45:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=26
05/26/2022 14:45:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=26
05/26/2022 14:45:53 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7693179281243083 on epoch=26
05/26/2022 14:45:55 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=26
05/26/2022 14:45:58 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 14:46:01 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.09 on epoch=26
05/26/2022 14:46:03 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/26/2022 14:46:06 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/26/2022 14:46:07 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 14:46:07 - INFO - __main__ - Printing 3 examples
05/26/2022 14:46:07 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 14:46:07 - INFO - __main__ - ['Company']
05/26/2022 14:46:07 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 14:46:07 - INFO - __main__ - ['Company']
05/26/2022 14:46:07 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 14:46:07 - INFO - __main__ - ['Company']
05/26/2022 14:46:07 - INFO - __main__ - Tokenizing Input ...
05/26/2022 14:46:08 - INFO - __main__ - Tokenizing Output ...
05/26/2022 14:46:10 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 14:46:10 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 14:46:10 - INFO - __main__ - Printing 3 examples
05/26/2022 14:46:10 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 14:46:10 - INFO - __main__ - ['Company']
05/26/2022 14:46:10 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 14:46:10 - INFO - __main__ - ['Company']
05/26/2022 14:46:10 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 14:46:10 - INFO - __main__ - ['Company']
05/26/2022 14:46:10 - INFO - __main__ - Tokenizing Input ...
05/26/2022 14:46:11 - INFO - __main__ - Tokenizing Output ...
05/26/2022 14:46:13 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 14:46:28 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 14:46:28 - INFO - __main__ - task name: dbpedia_14
05/26/2022 14:46:29 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 14:46:29 - INFO - __main__ - Starting training!
05/26/2022 14:46:51 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8027426742231771 on epoch=26
05/26/2022 14:46:51 - INFO - __main__ - save last model!
05/26/2022 14:46:52 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 14:46:52 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 14:46:52 - INFO - __main__ - Printing 3 examples
05/26/2022 14:46:52 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 14:46:52 - INFO - __main__ - ['Animal']
05/26/2022 14:46:52 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 14:46:52 - INFO - __main__ - ['Animal']
05/26/2022 14:46:52 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 14:46:52 - INFO - __main__ - ['Village']
05/26/2022 14:46:52 - INFO - __main__ - Tokenizing Input ...
05/26/2022 14:46:53 - INFO - __main__ - Tokenizing Output ...
05/26/2022 14:46:57 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 14:49:02 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.5_8_predictions.txt
05/26/2022 14:49:02 - INFO - __main__ - Classification-F1 on test data: 0.7590
05/26/2022 14:49:02 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.5, bsz=8, dev_performance=0.9153224216305439, test_performance=0.759002765454295
05/26/2022 14:49:02 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.4, bsz=8 ...
05/26/2022 14:49:03 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 14:49:03 - INFO - __main__ - Printing 3 examples
05/26/2022 14:49:03 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 14:49:03 - INFO - __main__ - ['Company']
05/26/2022 14:49:03 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 14:49:03 - INFO - __main__ - ['Company']
05/26/2022 14:49:03 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 14:49:03 - INFO - __main__ - ['Company']
05/26/2022 14:49:03 - INFO - __main__ - Tokenizing Input ...
05/26/2022 14:49:04 - INFO - __main__ - Tokenizing Output ...
05/26/2022 14:49:06 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 14:49:06 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 14:49:06 - INFO - __main__ - Printing 3 examples
05/26/2022 14:49:06 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 14:49:06 - INFO - __main__ - ['Company']
05/26/2022 14:49:06 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 14:49:06 - INFO - __main__ - ['Company']
05/26/2022 14:49:06 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 14:49:06 - INFO - __main__ - ['Company']
05/26/2022 14:49:06 - INFO - __main__ - Tokenizing Input ...
05/26/2022 14:49:07 - INFO - __main__ - Tokenizing Output ...
05/26/2022 14:49:09 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 14:49:24 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 14:49:24 - INFO - __main__ - task name: dbpedia_14
05/26/2022 14:49:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 14:49:25 - INFO - __main__ - Starting training!
05/26/2022 14:49:28 - INFO - __main__ - Step 10 Global step 10 Train loss 6.91 on epoch=0
05/26/2022 14:49:31 - INFO - __main__ - Step 20 Global step 20 Train loss 4.93 on epoch=0
05/26/2022 14:49:33 - INFO - __main__ - Step 30 Global step 30 Train loss 3.61 on epoch=0
05/26/2022 14:49:36 - INFO - __main__ - Step 40 Global step 40 Train loss 2.87 on epoch=0
05/26/2022 14:49:39 - INFO - __main__ - Step 50 Global step 50 Train loss 2.44 on epoch=0
05/26/2022 14:50:39 - INFO - __main__ - Global step 50 Train loss 4.15 Classification-F1 0.0894309965324492 on epoch=0
05/26/2022 14:50:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0894309965324492 on epoch=0, global_step=50
05/26/2022 14:50:42 - INFO - __main__ - Step 60 Global step 60 Train loss 2.12 on epoch=0
05/26/2022 14:50:45 - INFO - __main__ - Step 70 Global step 70 Train loss 1.80 on epoch=0
05/26/2022 14:50:47 - INFO - __main__ - Step 80 Global step 80 Train loss 1.54 on epoch=0
05/26/2022 14:50:50 - INFO - __main__ - Step 90 Global step 90 Train loss 1.35 on epoch=0
05/26/2022 14:50:53 - INFO - __main__ - Step 100 Global step 100 Train loss 1.28 on epoch=0
05/26/2022 14:51:46 - INFO - __main__ - Global step 100 Train loss 1.62 Classification-F1 0.2487919453083887 on epoch=0
05/26/2022 14:51:46 - INFO - __main__ - Saving model with best Classification-F1: 0.0894309965324492 -> 0.2487919453083887 on epoch=0, global_step=100
05/26/2022 14:51:48 - INFO - __main__ - Step 110 Global step 110 Train loss 1.23 on epoch=0
05/26/2022 14:51:51 - INFO - __main__ - Step 120 Global step 120 Train loss 1.04 on epoch=1
05/26/2022 14:51:53 - INFO - __main__ - Step 130 Global step 130 Train loss 0.95 on epoch=1
05/26/2022 14:51:56 - INFO - __main__ - Step 140 Global step 140 Train loss 0.90 on epoch=1
05/26/2022 14:51:58 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=1
05/26/2022 14:52:48 - INFO - __main__ - Global step 150 Train loss 1.01 Classification-F1 0.19041126952573015 on epoch=1
05/26/2022 14:52:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.87 on epoch=1
05/26/2022 14:52:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=1
05/26/2022 14:52:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=1
05/26/2022 14:52:59 - INFO - __main__ - Step 190 Global step 190 Train loss 0.77 on epoch=1
05/26/2022 14:53:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.70 on epoch=1
05/26/2022 14:53:53 - INFO - __main__ - Global step 200 Train loss 0.77 Classification-F1 0.31454414883660464 on epoch=1
05/26/2022 14:53:53 - INFO - __main__ - Saving model with best Classification-F1: 0.2487919453083887 -> 0.31454414883660464 on epoch=1, global_step=200
05/26/2022 14:53:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.68 on epoch=1
05/26/2022 14:53:58 - INFO - __main__ - Step 220 Global step 220 Train loss 0.62 on epoch=1
05/26/2022 14:54:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=2
05/26/2022 14:54:03 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=2
05/26/2022 14:54:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.58 on epoch=2
05/26/2022 14:55:03 - INFO - __main__ - Global step 250 Train loss 0.62 Classification-F1 0.24226019675711585 on epoch=2
05/26/2022 14:55:05 - INFO - __main__ - Step 260 Global step 260 Train loss 0.63 on epoch=2
05/26/2022 14:55:08 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=2
05/26/2022 14:55:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=2
05/26/2022 14:55:13 - INFO - __main__ - Step 290 Global step 290 Train loss 0.51 on epoch=2
05/26/2022 14:55:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=2
05/26/2022 14:56:08 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.3282680611273768 on epoch=2
05/26/2022 14:56:08 - INFO - __main__ - Saving model with best Classification-F1: 0.31454414883660464 -> 0.3282680611273768 on epoch=2, global_step=300
05/26/2022 14:56:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=2
05/26/2022 14:56:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.57 on epoch=2
05/26/2022 14:56:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=2
05/26/2022 14:56:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=3
05/26/2022 14:56:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.59 on epoch=3
05/26/2022 14:57:15 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.4137624030598161 on epoch=3
05/26/2022 14:57:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3282680611273768 -> 0.4137624030598161 on epoch=3, global_step=350
05/26/2022 14:57:18 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=3
05/26/2022 14:57:20 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=3
05/26/2022 14:57:23 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=3
05/26/2022 14:57:26 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=3
05/26/2022 14:57:28 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=3
05/26/2022 14:58:19 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.6012408087213041 on epoch=3
05/26/2022 14:58:19 - INFO - __main__ - Saving model with best Classification-F1: 0.4137624030598161 -> 0.6012408087213041 on epoch=3, global_step=400
05/26/2022 14:58:22 - INFO - __main__ - Step 410 Global step 410 Train loss 0.40 on epoch=3
05/26/2022 14:58:24 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=3
05/26/2022 14:58:27 - INFO - __main__ - Step 430 Global step 430 Train loss 0.39 on epoch=3
05/26/2022 14:58:30 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=3
05/26/2022 14:58:32 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=4
05/26/2022 14:59:27 - INFO - __main__ - Global step 450 Train loss 0.36 Classification-F1 0.44178680312066604 on epoch=4
05/26/2022 14:59:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.45 on epoch=4
05/26/2022 14:59:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.42 on epoch=4
05/26/2022 14:59:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.33 on epoch=4
05/26/2022 14:59:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=4
05/26/2022 14:59:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=4
05/26/2022 15:00:29 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.5546195494464066 on epoch=4
05/26/2022 15:00:32 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=4
05/26/2022 15:00:35 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=4
05/26/2022 15:00:37 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=4
05/26/2022 15:00:40 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=4
05/26/2022 15:00:42 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=4
05/26/2022 15:01:39 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.5567956086833384 on epoch=4
05/26/2022 15:01:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=4
05/26/2022 15:01:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=5
05/26/2022 15:01:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=5
05/26/2022 15:01:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=5
05/26/2022 15:01:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=5
05/26/2022 15:02:46 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.48666435391316226 on epoch=5
05/26/2022 15:02:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=5
05/26/2022 15:02:51 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=5
05/26/2022 15:02:54 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=5
05/26/2022 15:02:56 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=5
05/26/2022 15:02:59 - INFO - __main__ - Step 650 Global step 650 Train loss 0.32 on epoch=5
05/26/2022 15:03:49 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.47641821228148 on epoch=5
05/26/2022 15:03:52 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=5
05/26/2022 15:03:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=5
05/26/2022 15:03:57 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=6
05/26/2022 15:04:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=6
05/26/2022 15:04:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=6
05/26/2022 15:04:54 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6175933373312196 on epoch=6
05/26/2022 15:04:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6012408087213041 -> 0.6175933373312196 on epoch=6, global_step=700
05/26/2022 15:04:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=6
05/26/2022 15:04:59 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=6
05/26/2022 15:05:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=6
05/26/2022 15:05:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=6
05/26/2022 15:05:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=6
05/26/2022 15:06:01 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.50074055523329 on epoch=6
05/26/2022 15:06:04 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=6
05/26/2022 15:06:06 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=6
05/26/2022 15:06:09 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/26/2022 15:06:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=7
05/26/2022 15:06:14 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=7
05/26/2022 15:07:05 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6426562617849305 on epoch=7
05/26/2022 15:07:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6175933373312196 -> 0.6426562617849305 on epoch=7, global_step=800
05/26/2022 15:07:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=7
05/26/2022 15:07:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=7
05/26/2022 15:07:13 - INFO - __main__ - Step 830 Global step 830 Train loss 0.20 on epoch=7
05/26/2022 15:07:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=7
05/26/2022 15:07:18 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=7
05/26/2022 15:08:12 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6016478051174929 on epoch=7
05/26/2022 15:08:15 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=7
05/26/2022 15:08:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=7
05/26/2022 15:08:20 - INFO - __main__ - Step 880 Global step 880 Train loss 0.21 on epoch=7
05/26/2022 15:08:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=7
05/26/2022 15:08:25 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=8
05/26/2022 15:09:17 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.551143437329071 on epoch=8
05/26/2022 15:09:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=8
05/26/2022 15:09:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=8
05/26/2022 15:09:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=8
05/26/2022 15:09:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=8
05/26/2022 15:09:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=8
05/26/2022 15:10:26 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.6053727811920947 on epoch=8
05/26/2022 15:10:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=8
05/26/2022 15:10:32 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=8
05/26/2022 15:10:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.10 on epoch=8
05/26/2022 15:10:37 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=8
05/26/2022 15:10:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=8
05/26/2022 15:11:31 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5959962095625968 on epoch=8
05/26/2022 15:11:33 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
05/26/2022 15:11:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.26 on epoch=9
05/26/2022 15:11:38 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=9
05/26/2022 15:11:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=9
05/26/2022 15:11:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=9
05/26/2022 15:12:31 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.5820252008271242 on epoch=9
05/26/2022 15:12:34 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=9
05/26/2022 15:12:37 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=9
05/26/2022 15:12:39 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=9
05/26/2022 15:12:42 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=9
05/26/2022 15:12:44 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
05/26/2022 15:13:36 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6160961362627502 on epoch=9
05/26/2022 15:13:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=9
05/26/2022 15:13:42 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
05/26/2022 15:13:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
05/26/2022 15:13:47 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=10
05/26/2022 15:13:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=10
05/26/2022 15:14:40 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.4816015212915483 on epoch=10
05/26/2022 15:14:43 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=10
05/26/2022 15:14:45 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
05/26/2022 15:14:48 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=10
05/26/2022 15:14:51 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=10
05/26/2022 15:14:53 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=10
05/26/2022 15:15:43 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.5577333449782285 on epoch=10
05/26/2022 15:15:46 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
05/26/2022 15:15:49 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=10
05/26/2022 15:15:51 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=10
05/26/2022 15:15:54 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=11
05/26/2022 15:15:56 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=11
05/26/2022 15:16:46 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.48732689695403564 on epoch=11
05/26/2022 15:16:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=11
05/26/2022 15:16:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=11
05/26/2022 15:16:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=11
05/26/2022 15:16:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=11
05/26/2022 15:16:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=11
05/26/2022 15:17:49 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.5431233229907434 on epoch=11
05/26/2022 15:17:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 15:17:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.14 on epoch=11
05/26/2022 15:17:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=11
05/26/2022 15:18:00 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=11
05/26/2022 15:18:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=12
05/26/2022 15:18:54 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.643087276502099 on epoch=12
05/26/2022 15:18:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6426562617849305 -> 0.643087276502099 on epoch=12, global_step=1350
05/26/2022 15:18:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=12
05/26/2022 15:18:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/26/2022 15:19:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=12
05/26/2022 15:19:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=12
05/26/2022 15:19:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=12
05/26/2022 15:19:57 - INFO - __main__ - Global step 1400 Train loss 0.12 Classification-F1 0.6714666155568826 on epoch=12
05/26/2022 15:19:57 - INFO - __main__ - Saving model with best Classification-F1: 0.643087276502099 -> 0.6714666155568826 on epoch=12, global_step=1400
05/26/2022 15:19:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.07 on epoch=12
05/26/2022 15:20:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=12
05/26/2022 15:20:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=12
05/26/2022 15:20:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=12
05/26/2022 15:20:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=12
05/26/2022 15:21:01 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.6694955526642475 on epoch=12
05/26/2022 15:21:04 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=13
05/26/2022 15:21:06 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=13
05/26/2022 15:21:09 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
05/26/2022 15:21:12 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=13
05/26/2022 15:21:14 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
05/26/2022 15:22:04 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.8262782738464308 on epoch=13
05/26/2022 15:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6714666155568826 -> 0.8262782738464308 on epoch=13, global_step=1500
05/26/2022 15:22:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=13
05/26/2022 15:22:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=13
05/26/2022 15:22:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=13
05/26/2022 15:22:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
05/26/2022 15:22:17 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=13
05/26/2022 15:23:07 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.6985188722522755 on epoch=13
05/26/2022 15:23:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
05/26/2022 15:23:13 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.05 on epoch=14
05/26/2022 15:23:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=14
05/26/2022 15:23:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=14
05/26/2022 15:23:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/26/2022 15:24:12 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.709414141922472 on epoch=14
05/26/2022 15:24:15 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/26/2022 15:24:18 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=14
05/26/2022 15:24:20 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/26/2022 15:24:23 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=14
05/26/2022 15:24:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=14
05/26/2022 15:25:17 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.64057997298145 on epoch=14
05/26/2022 15:25:20 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=14
05/26/2022 15:25:22 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=14
05/26/2022 15:25:25 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=14
05/26/2022 15:25:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=15
05/26/2022 15:25:30 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/26/2022 15:26:24 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.9066730329243192 on epoch=15
05/26/2022 15:26:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8262782738464308 -> 0.9066730329243192 on epoch=15, global_step=1700
05/26/2022 15:26:27 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=15
05/26/2022 15:26:29 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=15
05/26/2022 15:26:32 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=15
05/26/2022 15:26:35 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=15
05/26/2022 15:26:37 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=15
05/26/2022 15:27:25 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5461523100194617 on epoch=15
05/26/2022 15:27:28 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=15
05/26/2022 15:27:30 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=15
05/26/2022 15:27:33 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
05/26/2022 15:27:36 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=15
05/26/2022 15:27:38 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
05/26/2022 15:28:30 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7095396647919243 on epoch=16
05/26/2022 15:28:32 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=16
05/26/2022 15:28:35 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
05/26/2022 15:28:38 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 15:28:40 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/26/2022 15:28:43 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
05/26/2022 15:29:31 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.7579575449251552 on epoch=16
05/26/2022 15:29:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=16
05/26/2022 15:29:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/26/2022 15:29:39 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.10 on epoch=16
05/26/2022 15:29:42 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=16
05/26/2022 15:29:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=16
05/26/2022 15:30:34 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8570820008156318 on epoch=16
05/26/2022 15:30:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=17
05/26/2022 15:30:39 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=17
05/26/2022 15:30:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=17
05/26/2022 15:30:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 15:30:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/26/2022 15:31:33 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.715683404216596 on epoch=17
05/26/2022 15:31:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=17
05/26/2022 15:31:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=17
05/26/2022 15:31:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=17
05/26/2022 15:31:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/26/2022 15:31:46 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=17
05/26/2022 15:32:32 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6803347209003323 on epoch=17
05/26/2022 15:32:35 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=17
05/26/2022 15:32:38 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/26/2022 15:32:40 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=18
05/26/2022 15:32:43 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=18
05/26/2022 15:32:46 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/26/2022 15:33:32 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.8016007109642607 on epoch=18
05/26/2022 15:33:35 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=18
05/26/2022 15:33:37 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=18
05/26/2022 15:33:40 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=18
05/26/2022 15:33:42 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
05/26/2022 15:33:45 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 15:34:31 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7972260443717993 on epoch=18
05/26/2022 15:34:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=18
05/26/2022 15:34:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/26/2022 15:34:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=19
05/26/2022 15:34:42 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.09 on epoch=19
05/26/2022 15:34:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/26/2022 15:35:30 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7447425261972732 on epoch=19
05/26/2022 15:35:32 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=19
05/26/2022 15:35:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=19
05/26/2022 15:35:37 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=19
05/26/2022 15:35:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/26/2022 15:35:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=19
05/26/2022 15:36:29 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8497741023121195 on epoch=19
05/26/2022 15:36:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=19
05/26/2022 15:36:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=19
05/26/2022 15:36:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.07 on epoch=19
05/26/2022 15:36:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
05/26/2022 15:36:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/26/2022 15:37:32 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8024145865568021 on epoch=20
05/26/2022 15:37:35 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.08 on epoch=20
05/26/2022 15:37:38 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/26/2022 15:37:40 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/26/2022 15:37:43 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
05/26/2022 15:37:46 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/26/2022 15:38:34 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.8514497338053127 on epoch=20
05/26/2022 15:38:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/26/2022 15:38:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=20
05/26/2022 15:38:42 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=20
05/26/2022 15:38:45 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
05/26/2022 15:38:47 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=20
05/26/2022 15:39:35 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8536971377410706 on epoch=20
05/26/2022 15:39:37 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=21
05/26/2022 15:39:40 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.10 on epoch=21
05/26/2022 15:39:43 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/26/2022 15:39:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
05/26/2022 15:39:48 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=21
05/26/2022 15:40:38 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.600819953268614 on epoch=21
05/26/2022 15:40:40 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
05/26/2022 15:40:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=21
05/26/2022 15:40:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/26/2022 15:40:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/26/2022 15:40:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=21
05/26/2022 15:41:41 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8038367348947566 on epoch=21
05/26/2022 15:41:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
05/26/2022 15:41:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=22
05/26/2022 15:41:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=22
05/26/2022 15:41:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
05/26/2022 15:41:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/26/2022 15:42:42 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.8511819341438748 on epoch=22
05/26/2022 15:42:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/26/2022 15:42:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
05/26/2022 15:42:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=22
05/26/2022 15:42:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/26/2022 15:42:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/26/2022 15:43:44 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7577254870306671 on epoch=22
05/26/2022 15:43:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=22
05/26/2022 15:43:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=22
05/26/2022 15:43:52 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/26/2022 15:43:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=23
05/26/2022 15:43:57 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=23
05/26/2022 15:44:48 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6123613646146068 on epoch=23
05/26/2022 15:44:51 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/26/2022 15:44:53 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=23
05/26/2022 15:44:56 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/26/2022 15:44:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 15:45:01 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/26/2022 15:45:50 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.740405058430794 on epoch=23
05/26/2022 15:45:53 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=23
05/26/2022 15:45:56 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=23
05/26/2022 15:45:58 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/26/2022 15:46:01 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/26/2022 15:46:04 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=24
05/26/2022 15:46:51 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7377108335621222 on epoch=24
05/26/2022 15:46:53 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/26/2022 15:46:56 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/26/2022 15:46:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 15:47:01 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
05/26/2022 15:47:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=24
05/26/2022 15:47:52 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7056394645466836 on epoch=24
05/26/2022 15:47:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 15:47:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/26/2022 15:48:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=24
05/26/2022 15:48:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=24
05/26/2022 15:48:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=24
05/26/2022 15:48:53 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7415001765349246 on epoch=24
05/26/2022 15:48:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
05/26/2022 15:48:59 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=25
05/26/2022 15:49:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=25
05/26/2022 15:49:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 15:49:07 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=25
05/26/2022 15:49:55 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7580419608751638 on epoch=25
05/26/2022 15:49:58 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 15:50:01 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/26/2022 15:50:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=25
05/26/2022 15:50:06 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=25
05/26/2022 15:50:09 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=25
05/26/2022 15:50:58 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7551884171453804 on epoch=25
05/26/2022 15:51:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=25
05/26/2022 15:51:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=26
05/26/2022 15:51:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=26
05/26/2022 15:51:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 15:51:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/26/2022 15:51:59 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.753118413976833 on epoch=26
05/26/2022 15:52:02 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=26
05/26/2022 15:52:05 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=26
05/26/2022 15:52:08 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/26/2022 15:52:10 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/26/2022 15:52:13 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=26
05/26/2022 15:52:14 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 15:52:14 - INFO - __main__ - Printing 3 examples
05/26/2022 15:52:14 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 15:52:14 - INFO - __main__ - ['Company']
05/26/2022 15:52:14 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 15:52:14 - INFO - __main__ - ['Company']
05/26/2022 15:52:14 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 15:52:14 - INFO - __main__ - ['Company']
05/26/2022 15:52:14 - INFO - __main__ - Tokenizing Input ...
05/26/2022 15:52:15 - INFO - __main__ - Tokenizing Output ...
05/26/2022 15:52:17 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 15:52:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 15:52:17 - INFO - __main__ - Printing 3 examples
05/26/2022 15:52:17 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 15:52:17 - INFO - __main__ - ['Company']
05/26/2022 15:52:17 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 15:52:17 - INFO - __main__ - ['Company']
05/26/2022 15:52:17 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 15:52:17 - INFO - __main__ - ['Company']
05/26/2022 15:52:17 - INFO - __main__ - Tokenizing Input ...
05/26/2022 15:52:18 - INFO - __main__ - Tokenizing Output ...
05/26/2022 15:52:20 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 15:52:38 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 15:52:38 - INFO - __main__ - task name: dbpedia_14
05/26/2022 15:52:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 15:52:39 - INFO - __main__ - Starting training!
05/26/2022 15:53:02 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7521041797997712 on epoch=26
05/26/2022 15:53:02 - INFO - __main__ - save last model!
05/26/2022 15:53:02 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 15:53:02 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 15:53:02 - INFO - __main__ - Printing 3 examples
05/26/2022 15:53:02 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 15:53:02 - INFO - __main__ - ['Animal']
05/26/2022 15:53:02 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 15:53:02 - INFO - __main__ - ['Animal']
05/26/2022 15:53:02 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 15:53:02 - INFO - __main__ - ['Village']
05/26/2022 15:53:02 - INFO - __main__ - Tokenizing Input ...
05/26/2022 15:53:04 - INFO - __main__ - Tokenizing Output ...
05/26/2022 15:53:07 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 15:55:13 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.4_8_predictions.txt
05/26/2022 15:55:13 - INFO - __main__ - Classification-F1 on test data: 0.5157
05/26/2022 15:55:14 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.4, bsz=8, dev_performance=0.9066730329243192, test_performance=0.5157005923151841
05/26/2022 15:55:14 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.3, bsz=8 ...
05/26/2022 15:55:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 15:55:15 - INFO - __main__ - Printing 3 examples
05/26/2022 15:55:15 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 15:55:15 - INFO - __main__ - ['Company']
05/26/2022 15:55:15 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 15:55:15 - INFO - __main__ - ['Company']
05/26/2022 15:55:15 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 15:55:15 - INFO - __main__ - ['Company']
05/26/2022 15:55:15 - INFO - __main__ - Tokenizing Input ...
05/26/2022 15:55:16 - INFO - __main__ - Tokenizing Output ...
05/26/2022 15:55:17 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 15:55:17 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 15:55:17 - INFO - __main__ - Printing 3 examples
05/26/2022 15:55:17 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 15:55:17 - INFO - __main__ - ['Company']
05/26/2022 15:55:17 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 15:55:17 - INFO - __main__ - ['Company']
05/26/2022 15:55:17 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 15:55:17 - INFO - __main__ - ['Company']
05/26/2022 15:55:17 - INFO - __main__ - Tokenizing Input ...
05/26/2022 15:55:18 - INFO - __main__ - Tokenizing Output ...
05/26/2022 15:55:20 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 15:55:39 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 15:55:39 - INFO - __main__ - task name: dbpedia_14
05/26/2022 15:55:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 15:55:40 - INFO - __main__ - Starting training!
05/26/2022 15:55:43 - INFO - __main__ - Step 10 Global step 10 Train loss 7.02 on epoch=0
05/26/2022 15:55:46 - INFO - __main__ - Step 20 Global step 20 Train loss 5.81 on epoch=0
05/26/2022 15:55:48 - INFO - __main__ - Step 30 Global step 30 Train loss 4.39 on epoch=0
05/26/2022 15:55:51 - INFO - __main__ - Step 40 Global step 40 Train loss 3.39 on epoch=0
05/26/2022 15:55:53 - INFO - __main__ - Step 50 Global step 50 Train loss 2.70 on epoch=0
05/26/2022 15:57:10 - INFO - __main__ - Global step 50 Train loss 4.66 Classification-F1 0.06472442025762298 on epoch=0
05/26/2022 15:57:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.06472442025762298 on epoch=0, global_step=50
05/26/2022 15:57:13 - INFO - __main__ - Step 60 Global step 60 Train loss 2.28 on epoch=0
05/26/2022 15:57:16 - INFO - __main__ - Step 70 Global step 70 Train loss 2.02 on epoch=0
05/26/2022 15:57:18 - INFO - __main__ - Step 80 Global step 80 Train loss 1.62 on epoch=0
05/26/2022 15:57:21 - INFO - __main__ - Step 90 Global step 90 Train loss 1.63 on epoch=0
05/26/2022 15:57:24 - INFO - __main__ - Step 100 Global step 100 Train loss 1.34 on epoch=0
05/26/2022 15:58:24 - INFO - __main__ - Global step 100 Train loss 1.78 Classification-F1 0.19567792475980972 on epoch=0
05/26/2022 15:58:24 - INFO - __main__ - Saving model with best Classification-F1: 0.06472442025762298 -> 0.19567792475980972 on epoch=0, global_step=100
05/26/2022 15:58:26 - INFO - __main__ - Step 110 Global step 110 Train loss 1.29 on epoch=0
05/26/2022 15:58:29 - INFO - __main__ - Step 120 Global step 120 Train loss 1.23 on epoch=1
05/26/2022 15:58:31 - INFO - __main__ - Step 130 Global step 130 Train loss 1.07 on epoch=1
05/26/2022 15:58:34 - INFO - __main__ - Step 140 Global step 140 Train loss 0.96 on epoch=1
05/26/2022 15:58:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.89 on epoch=1
05/26/2022 15:59:32 - INFO - __main__ - Global step 150 Train loss 1.09 Classification-F1 0.15377799389764174 on epoch=1
05/26/2022 15:59:35 - INFO - __main__ - Step 160 Global step 160 Train loss 0.95 on epoch=1
05/26/2022 15:59:37 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=1
05/26/2022 15:59:40 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=1
05/26/2022 15:59:42 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=1
05/26/2022 15:59:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.77 on epoch=1
05/26/2022 16:00:40 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.23607661881482123 on epoch=1
05/26/2022 16:00:40 - INFO - __main__ - Saving model with best Classification-F1: 0.19567792475980972 -> 0.23607661881482123 on epoch=1, global_step=200
05/26/2022 16:00:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.75 on epoch=1
05/26/2022 16:00:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=1
05/26/2022 16:00:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=2
05/26/2022 16:00:51 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=2
05/26/2022 16:00:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=2
05/26/2022 16:01:51 - INFO - __main__ - Global step 250 Train loss 0.68 Classification-F1 0.29584943180363 on epoch=2
05/26/2022 16:01:51 - INFO - __main__ - Saving model with best Classification-F1: 0.23607661881482123 -> 0.29584943180363 on epoch=2, global_step=250
05/26/2022 16:01:54 - INFO - __main__ - Step 260 Global step 260 Train loss 0.68 on epoch=2
05/26/2022 16:01:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.73 on epoch=2
05/26/2022 16:01:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=2
05/26/2022 16:02:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.60 on epoch=2
05/26/2022 16:02:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.57 on epoch=2
05/26/2022 16:03:01 - INFO - __main__ - Global step 300 Train loss 0.62 Classification-F1 0.21060354376413445 on epoch=2
05/26/2022 16:03:04 - INFO - __main__ - Step 310 Global step 310 Train loss 0.55 on epoch=2
05/26/2022 16:03:07 - INFO - __main__ - Step 320 Global step 320 Train loss 0.47 on epoch=2
05/26/2022 16:03:09 - INFO - __main__ - Step 330 Global step 330 Train loss 0.52 on epoch=2
05/26/2022 16:03:12 - INFO - __main__ - Step 340 Global step 340 Train loss 0.50 on epoch=3
05/26/2022 16:03:14 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=3
05/26/2022 16:04:14 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.2401312452984172 on epoch=3
05/26/2022 16:04:17 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=3
05/26/2022 16:04:19 - INFO - __main__ - Step 370 Global step 370 Train loss 0.51 on epoch=3
05/26/2022 16:04:22 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=3
05/26/2022 16:04:25 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=3
05/26/2022 16:04:27 - INFO - __main__ - Step 400 Global step 400 Train loss 0.43 on epoch=3
05/26/2022 16:05:21 - INFO - __main__ - Global step 400 Train loss 0.49 Classification-F1 0.2722056134908549 on epoch=3
05/26/2022 16:05:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=3
05/26/2022 16:05:26 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=3
05/26/2022 16:05:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.46 on epoch=3
05/26/2022 16:05:32 - INFO - __main__ - Step 440 Global step 440 Train loss 0.47 on epoch=3
05/26/2022 16:05:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=4
05/26/2022 16:06:29 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.3862702687747317 on epoch=4
05/26/2022 16:06:30 - INFO - __main__ - Saving model with best Classification-F1: 0.29584943180363 -> 0.3862702687747317 on epoch=4, global_step=450
05/26/2022 16:06:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=4
05/26/2022 16:06:35 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=4
05/26/2022 16:06:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.43 on epoch=4
05/26/2022 16:06:40 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=4
05/26/2022 16:06:43 - INFO - __main__ - Step 500 Global step 500 Train loss 0.39 on epoch=4
05/26/2022 16:07:36 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.4517451233630092 on epoch=4
05/26/2022 16:07:36 - INFO - __main__ - Saving model with best Classification-F1: 0.3862702687747317 -> 0.4517451233630092 on epoch=4, global_step=500
05/26/2022 16:07:39 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=4
05/26/2022 16:07:42 - INFO - __main__ - Step 520 Global step 520 Train loss 0.35 on epoch=4
05/26/2022 16:07:44 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=4
05/26/2022 16:07:47 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=4
05/26/2022 16:07:49 - INFO - __main__ - Step 550 Global step 550 Train loss 0.42 on epoch=4
05/26/2022 16:08:44 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.5440396621267947 on epoch=4
05/26/2022 16:08:44 - INFO - __main__ - Saving model with best Classification-F1: 0.4517451233630092 -> 0.5440396621267947 on epoch=4, global_step=550
05/26/2022 16:08:47 - INFO - __main__ - Step 560 Global step 560 Train loss 0.31 on epoch=4
05/26/2022 16:08:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=5
05/26/2022 16:08:52 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=5
05/26/2022 16:08:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.30 on epoch=5
05/26/2022 16:08:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=5
05/26/2022 16:09:51 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.5905312183735587 on epoch=5
05/26/2022 16:09:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5440396621267947 -> 0.5905312183735587 on epoch=5, global_step=600
05/26/2022 16:09:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.40 on epoch=5
05/26/2022 16:09:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=5
05/26/2022 16:09:59 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=5
05/26/2022 16:10:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
05/26/2022 16:10:04 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=5
05/26/2022 16:10:57 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.6682412246553487 on epoch=5
05/26/2022 16:10:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5905312183735587 -> 0.6682412246553487 on epoch=5, global_step=650
05/26/2022 16:11:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=5
05/26/2022 16:11:02 - INFO - __main__ - Step 670 Global step 670 Train loss 0.26 on epoch=5
05/26/2022 16:11:05 - INFO - __main__ - Step 680 Global step 680 Train loss 0.29 on epoch=6
05/26/2022 16:11:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=6
05/26/2022 16:11:10 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=6
05/26/2022 16:12:01 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.39754706389741484 on epoch=6
05/26/2022 16:12:04 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=6
05/26/2022 16:12:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.29 on epoch=6
05/26/2022 16:12:09 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=6
05/26/2022 16:12:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=6
05/26/2022 16:12:14 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=6
05/26/2022 16:13:08 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.38657222223868726 on epoch=6
05/26/2022 16:13:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.28 on epoch=6
05/26/2022 16:13:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=6
05/26/2022 16:13:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=6
05/26/2022 16:13:19 - INFO - __main__ - Step 790 Global step 790 Train loss 0.24 on epoch=7
05/26/2022 16:13:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=7
05/26/2022 16:14:19 - INFO - __main__ - Global step 800 Train loss 0.25 Classification-F1 0.4347024258541629 on epoch=7
05/26/2022 16:14:21 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=7
05/26/2022 16:14:24 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=7
05/26/2022 16:14:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=7
05/26/2022 16:14:29 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=7
05/26/2022 16:14:32 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=7
05/26/2022 16:15:26 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.589629644155422 on epoch=7
05/26/2022 16:15:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=7
05/26/2022 16:15:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=7
05/26/2022 16:15:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=7
05/26/2022 16:15:37 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=7
05/26/2022 16:15:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=8
05/26/2022 16:16:33 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.4588778578803336 on epoch=8
05/26/2022 16:16:36 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=8
05/26/2022 16:16:38 - INFO - __main__ - Step 920 Global step 920 Train loss 0.17 on epoch=8
05/26/2022 16:16:41 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=8
05/26/2022 16:16:43 - INFO - __main__ - Step 940 Global step 940 Train loss 0.14 on epoch=8
05/26/2022 16:16:46 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=8
05/26/2022 16:17:39 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.43001075815407147 on epoch=8
05/26/2022 16:17:42 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=8
05/26/2022 16:17:44 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=8
05/26/2022 16:17:47 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=8
05/26/2022 16:17:49 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=8
05/26/2022 16:17:52 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=8
05/26/2022 16:18:45 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.46365793384726206 on epoch=8
05/26/2022 16:18:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.10 on epoch=9
05/26/2022 16:18:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=9
05/26/2022 16:18:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=9
05/26/2022 16:18:56 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=9
05/26/2022 16:18:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=9
05/26/2022 16:19:51 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6123043489787349 on epoch=9
05/26/2022 16:19:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
05/26/2022 16:19:56 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=9
05/26/2022 16:19:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=9
05/26/2022 16:20:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=9
05/26/2022 16:20:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=9
05/26/2022 16:20:59 - INFO - __main__ - Global step 1100 Train loss 0.12 Classification-F1 0.5149236301976883 on epoch=9
05/26/2022 16:21:01 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.19 on epoch=9
05/26/2022 16:21:04 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.08 on epoch=9
05/26/2022 16:21:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=10
05/26/2022 16:21:09 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=10
05/26/2022 16:21:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
05/26/2022 16:22:06 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7072170612087042 on epoch=10
05/26/2022 16:22:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6682412246553487 -> 0.7072170612087042 on epoch=10, global_step=1150
05/26/2022 16:22:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=10
05/26/2022 16:22:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=10
05/26/2022 16:22:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=10
05/26/2022 16:22:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
05/26/2022 16:22:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=10
05/26/2022 16:23:18 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.8000417537012502 on epoch=10
05/26/2022 16:23:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7072170612087042 -> 0.8000417537012502 on epoch=10, global_step=1200
05/26/2022 16:23:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
05/26/2022 16:23:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
05/26/2022 16:23:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=10
05/26/2022 16:23:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=11
05/26/2022 16:23:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=11
05/26/2022 16:24:27 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5093706473844661 on epoch=11
05/26/2022 16:24:30 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/26/2022 16:24:33 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=11
05/26/2022 16:24:35 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=11
05/26/2022 16:24:38 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
05/26/2022 16:24:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=11
05/26/2022 16:25:36 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6030735569040796 on epoch=11
05/26/2022 16:25:39 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=11
05/26/2022 16:25:41 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=11
05/26/2022 16:25:44 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=11
05/26/2022 16:25:47 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=11
05/26/2022 16:25:50 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=12
05/26/2022 16:26:46 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.915833419347079 on epoch=12
05/26/2022 16:26:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8000417537012502 -> 0.915833419347079 on epoch=12, global_step=1350
05/26/2022 16:26:48 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=12
05/26/2022 16:26:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=12
05/26/2022 16:26:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=12
05/26/2022 16:26:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=12
05/26/2022 16:26:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=12
05/26/2022 16:27:56 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.6751364989688523 on epoch=12
05/26/2022 16:27:59 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=12
05/26/2022 16:28:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=12
05/26/2022 16:28:04 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=12
05/26/2022 16:28:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=12
05/26/2022 16:28:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=12
05/26/2022 16:29:05 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.8001112065161897 on epoch=12
05/26/2022 16:29:07 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=13
05/26/2022 16:29:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.11 on epoch=13
05/26/2022 16:29:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=13
05/26/2022 16:29:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=13
05/26/2022 16:29:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=13
05/26/2022 16:30:13 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7292668563046609 on epoch=13
05/26/2022 16:30:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=13
05/26/2022 16:30:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=13
05/26/2022 16:30:21 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/26/2022 16:30:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=13
05/26/2022 16:30:26 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.18 on epoch=13
05/26/2022 16:31:22 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8491484505236854 on epoch=13
05/26/2022 16:31:25 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
05/26/2022 16:31:28 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=14
05/26/2022 16:31:30 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.12 on epoch=14
05/26/2022 16:31:33 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=14
05/26/2022 16:31:36 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=14
05/26/2022 16:32:34 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7533240219986828 on epoch=14
05/26/2022 16:32:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=14
05/26/2022 16:32:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=14
05/26/2022 16:32:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/26/2022 16:32:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=14
05/26/2022 16:32:48 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=14
05/26/2022 16:33:45 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8521879861714137 on epoch=14
05/26/2022 16:33:47 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.07 on epoch=14
05/26/2022 16:33:50 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=14
05/26/2022 16:33:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=14
05/26/2022 16:33:55 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=15
05/26/2022 16:33:58 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=15
05/26/2022 16:34:58 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7728227526508297 on epoch=15
05/26/2022 16:35:00 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=15
05/26/2022 16:35:03 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=15
05/26/2022 16:35:06 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=15
05/26/2022 16:35:08 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=15
05/26/2022 16:35:11 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=15
05/26/2022 16:36:12 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.756026181786887 on epoch=15
05/26/2022 16:36:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
05/26/2022 16:36:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
05/26/2022 16:36:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=15
05/26/2022 16:36:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=15
05/26/2022 16:36:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
05/26/2022 16:37:22 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8566223362642309 on epoch=16
05/26/2022 16:37:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=16
05/26/2022 16:37:28 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=16
05/26/2022 16:37:31 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=16
05/26/2022 16:37:33 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=16
05/26/2022 16:37:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=16
05/26/2022 16:38:30 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6851216652189211 on epoch=16
05/26/2022 16:38:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=16
05/26/2022 16:38:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/26/2022 16:38:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=16
05/26/2022 16:38:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
05/26/2022 16:38:44 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=16
05/26/2022 16:39:38 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.8071154869680023 on epoch=16
05/26/2022 16:39:41 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=17
05/26/2022 16:39:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=17
05/26/2022 16:39:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=17
05/26/2022 16:39:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 16:39:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=17
05/26/2022 16:40:46 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9169460314532818 on epoch=17
05/26/2022 16:40:46 - INFO - __main__ - Saving model with best Classification-F1: 0.915833419347079 -> 0.9169460314532818 on epoch=17, global_step=1950
05/26/2022 16:40:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/26/2022 16:40:52 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=17
05/26/2022 16:40:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=17
05/26/2022 16:40:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/26/2022 16:41:00 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
05/26/2022 16:41:51 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.8095014062491184 on epoch=17
05/26/2022 16:41:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=17
05/26/2022 16:41:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=18
05/26/2022 16:41:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=18
05/26/2022 16:42:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/26/2022 16:42:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=18
05/26/2022 16:42:57 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.9849067934813064 on epoch=18
05/26/2022 16:42:57 - INFO - __main__ - Saving model with best Classification-F1: 0.9169460314532818 -> 0.9849067934813064 on epoch=18, global_step=2050
05/26/2022 16:42:59 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=18
05/26/2022 16:43:02 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 16:43:05 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=18
05/26/2022 16:43:07 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=18
05/26/2022 16:43:10 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 16:44:01 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7995077497778338 on epoch=18
05/26/2022 16:44:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=18
05/26/2022 16:44:06 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=18
05/26/2022 16:44:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=19
05/26/2022 16:44:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=19
05/26/2022 16:44:14 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=19
05/26/2022 16:45:04 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.718218765354612 on epoch=19
05/26/2022 16:45:07 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=19
05/26/2022 16:45:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 16:45:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 16:45:15 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=19
05/26/2022 16:45:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=19
05/26/2022 16:46:07 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7232222589360245 on epoch=19
05/26/2022 16:46:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=19
05/26/2022 16:46:12 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 16:46:15 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/26/2022 16:46:17 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/26/2022 16:46:20 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/26/2022 16:47:14 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7566742821940396 on epoch=20
05/26/2022 16:47:16 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=20
05/26/2022 16:47:19 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=20
05/26/2022 16:47:21 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=20
05/26/2022 16:47:24 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
05/26/2022 16:47:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=20
05/26/2022 16:48:15 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.591591546524693 on epoch=20
05/26/2022 16:48:18 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/26/2022 16:48:21 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/26/2022 16:48:23 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=20
05/26/2022 16:48:26 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=20
05/26/2022 16:48:29 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=20
05/26/2022 16:49:19 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8615565919896844 on epoch=20
05/26/2022 16:49:22 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
05/26/2022 16:49:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=21
05/26/2022 16:49:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=21
05/26/2022 16:49:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 16:49:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=21
05/26/2022 16:50:20 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7613920066497126 on epoch=21
05/26/2022 16:50:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/26/2022 16:50:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=21
05/26/2022 16:50:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/26/2022 16:50:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=21
05/26/2022 16:50:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/26/2022 16:51:24 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8078979853294187 on epoch=21
05/26/2022 16:51:26 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=21
05/26/2022 16:51:29 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=22
05/26/2022 16:51:32 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=22
05/26/2022 16:51:34 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=22
05/26/2022 16:51:37 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=22
05/26/2022 16:52:26 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.9184643543600755 on epoch=22
05/26/2022 16:52:29 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=22
05/26/2022 16:52:31 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
05/26/2022 16:52:34 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/26/2022 16:52:36 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/26/2022 16:52:39 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/26/2022 16:53:29 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8567994091988951 on epoch=22
05/26/2022 16:53:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=22
05/26/2022 16:53:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.05 on epoch=22
05/26/2022 16:53:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=23
05/26/2022 16:53:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=23
05/26/2022 16:53:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=23
05/26/2022 16:54:32 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.920058629217883 on epoch=23
05/26/2022 16:54:34 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=23
05/26/2022 16:54:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/26/2022 16:54:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/26/2022 16:54:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 16:54:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=23
05/26/2022 16:55:34 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.8073959582083357 on epoch=23
05/26/2022 16:55:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/26/2022 16:55:39 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=23
05/26/2022 16:55:42 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/26/2022 16:55:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=24
05/26/2022 16:55:47 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.10 on epoch=24
05/26/2022 16:56:37 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7622405088626528 on epoch=24
05/26/2022 16:56:40 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/26/2022 16:56:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=24
05/26/2022 16:56:45 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=24
05/26/2022 16:56:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=24
05/26/2022 16:56:50 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
05/26/2022 16:57:39 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.624104261639598 on epoch=24
05/26/2022 16:57:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 16:57:44 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=24
05/26/2022 16:57:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=24
05/26/2022 16:57:49 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.11 on epoch=24
05/26/2022 16:57:52 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=24
05/26/2022 16:58:39 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.760787266784546 on epoch=24
05/26/2022 16:58:42 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=25
05/26/2022 16:58:45 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.08 on epoch=25
05/26/2022 16:58:47 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=25
05/26/2022 16:58:50 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 16:58:52 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
05/26/2022 16:59:42 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.8073027212162867 on epoch=25
05/26/2022 16:59:44 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=25
05/26/2022 16:59:47 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=25
05/26/2022 16:59:49 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=25
05/26/2022 16:59:52 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=25
05/26/2022 16:59:55 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=25
05/26/2022 17:00:43 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7579873801368562 on epoch=25
05/26/2022 17:00:46 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=25
05/26/2022 17:00:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=26
05/26/2022 17:00:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=26
05/26/2022 17:00:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=26
05/26/2022 17:00:57 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=26
05/26/2022 17:01:47 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.8083294577830183 on epoch=26
05/26/2022 17:01:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=26
05/26/2022 17:01:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 17:01:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.08 on epoch=26
05/26/2022 17:01:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=26
05/26/2022 17:02:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
05/26/2022 17:02:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 17:02:01 - INFO - __main__ - Printing 3 examples
05/26/2022 17:02:01 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 17:02:01 - INFO - __main__ - ['Company']
05/26/2022 17:02:01 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 17:02:01 - INFO - __main__ - ['Company']
05/26/2022 17:02:01 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 17:02:01 - INFO - __main__ - ['Company']
05/26/2022 17:02:01 - INFO - __main__ - Tokenizing Input ...
05/26/2022 17:02:02 - INFO - __main__ - Tokenizing Output ...
05/26/2022 17:02:04 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 17:02:04 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 17:02:04 - INFO - __main__ - Printing 3 examples
05/26/2022 17:02:04 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 17:02:04 - INFO - __main__ - ['Company']
05/26/2022 17:02:04 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 17:02:04 - INFO - __main__ - ['Company']
05/26/2022 17:02:04 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 17:02:04 - INFO - __main__ - ['Company']
05/26/2022 17:02:04 - INFO - __main__ - Tokenizing Input ...
05/26/2022 17:02:05 - INFO - __main__ - Tokenizing Output ...
05/26/2022 17:02:07 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 17:02:23 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 17:02:23 - INFO - __main__ - task name: dbpedia_14
05/26/2022 17:02:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 17:02:24 - INFO - __main__ - Starting training!
05/26/2022 17:02:50 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.913544513122283 on epoch=26
05/26/2022 17:02:50 - INFO - __main__ - save last model!
05/26/2022 17:02:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 17:02:50 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 17:02:50 - INFO - __main__ - Printing 3 examples
05/26/2022 17:02:50 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 17:02:50 - INFO - __main__ - ['Animal']
05/26/2022 17:02:50 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 17:02:50 - INFO - __main__ - ['Animal']
05/26/2022 17:02:50 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 17:02:50 - INFO - __main__ - ['Village']
05/26/2022 17:02:50 - INFO - __main__ - Tokenizing Input ...
05/26/2022 17:02:52 - INFO - __main__ - Tokenizing Output ...
05/26/2022 17:02:55 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 17:05:09 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.3_8_predictions.txt
05/26/2022 17:05:09 - INFO - __main__ - Classification-F1 on test data: 0.7633
05/26/2022 17:05:09 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.3, bsz=8, dev_performance=0.9849067934813064, test_performance=0.7633174253712139
05/26/2022 17:05:09 - INFO - __main__ - Running ... prefix=dbpedia_14_128_42, lr=0.2, bsz=8 ...
05/26/2022 17:05:10 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 17:05:10 - INFO - __main__ - Printing 3 examples
05/26/2022 17:05:10 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/26/2022 17:05:10 - INFO - __main__ - ['Company']
05/26/2022 17:05:10 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/26/2022 17:05:10 - INFO - __main__ - ['Company']
05/26/2022 17:05:10 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/26/2022 17:05:10 - INFO - __main__ - ['Company']
05/26/2022 17:05:10 - INFO - __main__ - Tokenizing Input ...
05/26/2022 17:05:11 - INFO - __main__ - Tokenizing Output ...
05/26/2022 17:05:13 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 17:05:13 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 17:05:13 - INFO - __main__ - Printing 3 examples
05/26/2022 17:05:13 - INFO - __main__ -  [dbpedia_14] The Aya Group of Companies commonly referred to as the Aya Group is a business conglomerate based in Uganda.
05/26/2022 17:05:13 - INFO - __main__ - ['Company']
05/26/2022 17:05:13 - INFO - __main__ -  [dbpedia_14] Casengo (founded in 2011) is a Dutch company that provides customer service tools for website and webshop owners available as a SaaS. The Amsterdam-based company was founded by Floris and Thijs van der Veen. Both brothers started off with software named Livecom used mainly by large companies such as Philips and DSM. When they decided to develop customer service software for small businesses Casengo was born.
05/26/2022 17:05:13 - INFO - __main__ - ['Company']
05/26/2022 17:05:13 - INFO - __main__ -  [dbpedia_14] KeySpan Corporation now part of National Grid USA was the fifth largest distributor of natural gas in the United States. KeySpan was formed in 1998 as result of the merger of Brooklyn Union Gas Company (founded 1895 by merging several smaller companies) and Long Island Lighting Company (LILCO).
05/26/2022 17:05:13 - INFO - __main__ - ['Company']
05/26/2022 17:05:13 - INFO - __main__ - Tokenizing Input ...
05/26/2022 17:05:14 - INFO - __main__ - Tokenizing Output ...
05/26/2022 17:05:16 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 17:05:32 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 17:05:32 - INFO - __main__ - task name: dbpedia_14
05/26/2022 17:05:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 17:05:32 - INFO - __main__ - Starting training!
05/26/2022 17:05:36 - INFO - __main__ - Step 10 Global step 10 Train loss 6.98 on epoch=0
05/26/2022 17:05:38 - INFO - __main__ - Step 20 Global step 20 Train loss 6.25 on epoch=0
05/26/2022 17:05:41 - INFO - __main__ - Step 30 Global step 30 Train loss 5.36 on epoch=0
05/26/2022 17:05:44 - INFO - __main__ - Step 40 Global step 40 Train loss 4.43 on epoch=0
05/26/2022 17:05:46 - INFO - __main__ - Step 50 Global step 50 Train loss 3.81 on epoch=0
05/26/2022 17:07:42 - INFO - __main__ - Global step 50 Train loss 5.37 Classification-F1 0.016955862793846557 on epoch=0
05/26/2022 17:07:42 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016955862793846557 on epoch=0, global_step=50
05/26/2022 17:07:45 - INFO - __main__ - Step 60 Global step 60 Train loss 3.26 on epoch=0
05/26/2022 17:07:47 - INFO - __main__ - Step 70 Global step 70 Train loss 2.74 on epoch=0
05/26/2022 17:07:50 - INFO - __main__ - Step 80 Global step 80 Train loss 2.46 on epoch=0
05/26/2022 17:07:53 - INFO - __main__ - Step 90 Global step 90 Train loss 2.28 on epoch=0
05/26/2022 17:07:55 - INFO - __main__ - Step 100 Global step 100 Train loss 2.05 on epoch=0
05/26/2022 17:08:34 - INFO - __main__ - Global step 100 Train loss 2.56 Classification-F1 0.1432031683720682 on epoch=0
05/26/2022 17:08:34 - INFO - __main__ - Saving model with best Classification-F1: 0.016955862793846557 -> 0.1432031683720682 on epoch=0, global_step=100
05/26/2022 17:08:36 - INFO - __main__ - Step 110 Global step 110 Train loss 1.96 on epoch=0
05/26/2022 17:08:39 - INFO - __main__ - Step 120 Global step 120 Train loss 1.64 on epoch=1
05/26/2022 17:08:42 - INFO - __main__ - Step 130 Global step 130 Train loss 1.53 on epoch=1
05/26/2022 17:08:44 - INFO - __main__ - Step 140 Global step 140 Train loss 1.43 on epoch=1
05/26/2022 17:08:47 - INFO - __main__ - Step 150 Global step 150 Train loss 1.32 on epoch=1
05/26/2022 17:09:36 - INFO - __main__ - Global step 150 Train loss 1.57 Classification-F1 0.2125844927466873 on epoch=1
05/26/2022 17:09:36 - INFO - __main__ - Saving model with best Classification-F1: 0.1432031683720682 -> 0.2125844927466873 on epoch=1, global_step=150
05/26/2022 17:09:38 - INFO - __main__ - Step 160 Global step 160 Train loss 1.39 on epoch=1
05/26/2022 17:09:41 - INFO - __main__ - Step 170 Global step 170 Train loss 1.24 on epoch=1
05/26/2022 17:09:43 - INFO - __main__ - Step 180 Global step 180 Train loss 1.05 on epoch=1
05/26/2022 17:09:46 - INFO - __main__ - Step 190 Global step 190 Train loss 1.16 on epoch=1
05/26/2022 17:09:49 - INFO - __main__ - Step 200 Global step 200 Train loss 1.01 on epoch=1
05/26/2022 17:10:39 - INFO - __main__ - Global step 200 Train loss 1.17 Classification-F1 0.45212511345254497 on epoch=1
05/26/2022 17:10:39 - INFO - __main__ - Saving model with best Classification-F1: 0.2125844927466873 -> 0.45212511345254497 on epoch=1, global_step=200
05/26/2022 17:10:42 - INFO - __main__ - Step 210 Global step 210 Train loss 1.09 on epoch=1
05/26/2022 17:10:44 - INFO - __main__ - Step 220 Global step 220 Train loss 1.04 on epoch=1
05/26/2022 17:10:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.91 on epoch=2
05/26/2022 17:10:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.80 on epoch=2
05/26/2022 17:10:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=2
05/26/2022 17:11:42 - INFO - __main__ - Global step 250 Train loss 0.92 Classification-F1 0.29910027809686446 on epoch=2
05/26/2022 17:11:45 - INFO - __main__ - Step 260 Global step 260 Train loss 0.85 on epoch=2
05/26/2022 17:11:48 - INFO - __main__ - Step 270 Global step 270 Train loss 0.87 on epoch=2
05/26/2022 17:11:50 - INFO - __main__ - Step 280 Global step 280 Train loss 0.80 on epoch=2
05/26/2022 17:11:53 - INFO - __main__ - Step 290 Global step 290 Train loss 0.75 on epoch=2
05/26/2022 17:11:56 - INFO - __main__ - Step 300 Global step 300 Train loss 0.75 on epoch=2
05/26/2022 17:12:46 - INFO - __main__ - Global step 300 Train loss 0.80 Classification-F1 0.28413410034956915 on epoch=2
05/26/2022 17:12:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.84 on epoch=2
05/26/2022 17:12:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.86 on epoch=2
05/26/2022 17:12:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.74 on epoch=2
05/26/2022 17:12:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=3
05/26/2022 17:12:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.62 on epoch=3
05/26/2022 17:13:52 - INFO - __main__ - Global step 350 Train loss 0.74 Classification-F1 0.2582756636693015 on epoch=3
05/26/2022 17:13:55 - INFO - __main__ - Step 360 Global step 360 Train loss 0.53 on epoch=3
05/26/2022 17:13:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.64 on epoch=3
05/26/2022 17:14:00 - INFO - __main__ - Step 380 Global step 380 Train loss 0.64 on epoch=3
05/26/2022 17:14:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.66 on epoch=3
05/26/2022 17:14:06 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=3
05/26/2022 17:14:56 - INFO - __main__ - Global step 400 Train loss 0.62 Classification-F1 0.35929964762972416 on epoch=3
05/26/2022 17:14:58 - INFO - __main__ - Step 410 Global step 410 Train loss 0.66 on epoch=3
05/26/2022 17:15:01 - INFO - __main__ - Step 420 Global step 420 Train loss 0.53 on epoch=3
05/26/2022 17:15:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.66 on epoch=3
05/26/2022 17:15:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.49 on epoch=3
05/26/2022 17:15:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.55 on epoch=4
05/26/2022 17:16:04 - INFO - __main__ - Global step 450 Train loss 0.58 Classification-F1 0.39402566403720474 on epoch=4
05/26/2022 17:16:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=4
05/26/2022 17:16:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.51 on epoch=4
05/26/2022 17:16:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.56 on epoch=4
05/26/2022 17:16:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.49 on epoch=4
05/26/2022 17:16:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.56 on epoch=4
05/26/2022 17:17:07 - INFO - __main__ - Global step 500 Train loss 0.53 Classification-F1 0.4107719093836992 on epoch=4
05/26/2022 17:17:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=4
05/26/2022 17:17:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.52 on epoch=4
05/26/2022 17:17:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.46 on epoch=4
05/26/2022 17:17:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=4
05/26/2022 17:17:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.47 on epoch=4
05/26/2022 17:18:14 - INFO - __main__ - Global step 550 Train loss 0.49 Classification-F1 0.5023469446967407 on epoch=4
05/26/2022 17:18:14 - INFO - __main__ - Saving model with best Classification-F1: 0.45212511345254497 -> 0.5023469446967407 on epoch=4, global_step=550
05/26/2022 17:18:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.35 on epoch=4
05/26/2022 17:18:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.41 on epoch=5
05/26/2022 17:18:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.46 on epoch=5
05/26/2022 17:18:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.48 on epoch=5
05/26/2022 17:18:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=5
05/26/2022 17:19:19 - INFO - __main__ - Global step 600 Train loss 0.42 Classification-F1 0.4847858686444581 on epoch=5
05/26/2022 17:19:21 - INFO - __main__ - Step 610 Global step 610 Train loss 0.53 on epoch=5
05/26/2022 17:19:24 - INFO - __main__ - Step 620 Global step 620 Train loss 0.36 on epoch=5
05/26/2022 17:19:27 - INFO - __main__ - Step 630 Global step 630 Train loss 0.41 on epoch=5
05/26/2022 17:19:29 - INFO - __main__ - Step 640 Global step 640 Train loss 0.38 on epoch=5
05/26/2022 17:19:32 - INFO - __main__ - Step 650 Global step 650 Train loss 0.39 on epoch=5
05/26/2022 17:20:25 - INFO - __main__ - Global step 650 Train loss 0.42 Classification-F1 0.5608831024008598 on epoch=5
05/26/2022 17:20:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5023469446967407 -> 0.5608831024008598 on epoch=5, global_step=650
05/26/2022 17:20:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.47 on epoch=5
05/26/2022 17:20:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.30 on epoch=5
05/26/2022 17:20:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=6
05/26/2022 17:20:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.35 on epoch=6
05/26/2022 17:20:39 - INFO - __main__ - Step 700 Global step 700 Train loss 0.38 on epoch=6
05/26/2022 17:21:31 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.5346464434318124 on epoch=6
05/26/2022 17:21:34 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=6
05/26/2022 17:21:37 - INFO - __main__ - Step 720 Global step 720 Train loss 0.37 on epoch=6
05/26/2022 17:21:39 - INFO - __main__ - Step 730 Global step 730 Train loss 0.38 on epoch=6
05/26/2022 17:21:42 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=6
05/26/2022 17:21:44 - INFO - __main__ - Step 750 Global step 750 Train loss 0.32 on epoch=6
05/26/2022 17:22:35 - INFO - __main__ - Global step 750 Train loss 0.36 Classification-F1 0.45356446219503205 on epoch=6
05/26/2022 17:22:38 - INFO - __main__ - Step 760 Global step 760 Train loss 0.36 on epoch=6
05/26/2022 17:22:41 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=6
05/26/2022 17:22:43 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=6
05/26/2022 17:22:46 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=7
05/26/2022 17:22:49 - INFO - __main__ - Step 800 Global step 800 Train loss 0.44 on epoch=7
05/26/2022 17:23:41 - INFO - __main__ - Global step 800 Train loss 0.38 Classification-F1 0.4461902222911513 on epoch=7
05/26/2022 17:23:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.34 on epoch=7
05/26/2022 17:23:47 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=7
05/26/2022 17:23:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.39 on epoch=7
05/26/2022 17:23:52 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=7
05/26/2022 17:23:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.28 on epoch=7
05/26/2022 17:24:44 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.4575007608381244 on epoch=7
05/26/2022 17:24:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.26 on epoch=7
05/26/2022 17:24:49 - INFO - __main__ - Step 870 Global step 870 Train loss 0.26 on epoch=7
05/26/2022 17:24:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.33 on epoch=7
05/26/2022 17:24:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=7
05/26/2022 17:24:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.31 on epoch=8
05/26/2022 17:25:47 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.5576474844061947 on epoch=8
05/26/2022 17:25:50 - INFO - __main__ - Step 910 Global step 910 Train loss 0.32 on epoch=8
05/26/2022 17:25:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=8
05/26/2022 17:25:55 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=8
05/26/2022 17:25:58 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=8
05/26/2022 17:26:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.31 on epoch=8
05/26/2022 17:26:52 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.6751962305120143 on epoch=8
05/26/2022 17:26:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5608831024008598 -> 0.6751962305120143 on epoch=8, global_step=950
05/26/2022 17:26:54 - INFO - __main__ - Step 960 Global step 960 Train loss 0.28 on epoch=8
05/26/2022 17:26:57 - INFO - __main__ - Step 970 Global step 970 Train loss 0.33 on epoch=8
05/26/2022 17:27:00 - INFO - __main__ - Step 980 Global step 980 Train loss 0.30 on epoch=8
05/26/2022 17:27:02 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=8
05/26/2022 17:27:05 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=8
05/26/2022 17:27:56 - INFO - __main__ - Global step 1000 Train loss 0.30 Classification-F1 0.5045838954649934 on epoch=8
05/26/2022 17:27:59 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=9
05/26/2022 17:28:01 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.28 on epoch=9
05/26/2022 17:28:04 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=9
05/26/2022 17:28:07 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=9
05/26/2022 17:28:09 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.30 on epoch=9
05/26/2022 17:28:59 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.5700861339301013 on epoch=9
05/26/2022 17:29:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.37 on epoch=9
05/26/2022 17:29:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=9
05/26/2022 17:29:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=9
05/26/2022 17:29:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=9
05/26/2022 17:29:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=9
05/26/2022 17:30:03 - INFO - __main__ - Global step 1100 Train loss 0.28 Classification-F1 0.5800823890466346 on epoch=9
05/26/2022 17:30:05 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.23 on epoch=9
05/26/2022 17:30:08 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=9
05/26/2022 17:30:11 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=10
05/26/2022 17:30:13 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=10
05/26/2022 17:30:16 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.24 on epoch=10
05/26/2022 17:31:07 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.5102074509119064 on epoch=10
05/26/2022 17:31:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.26 on epoch=10
05/26/2022 17:31:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.36 on epoch=10
05/26/2022 17:31:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.21 on epoch=10
05/26/2022 17:31:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=10
05/26/2022 17:31:20 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=10
05/26/2022 17:32:17 - INFO - __main__ - Global step 1200 Train loss 0.25 Classification-F1 0.564546727537025 on epoch=10
05/26/2022 17:32:20 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=10
05/26/2022 17:32:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.28 on epoch=10
05/26/2022 17:32:25 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=10
05/26/2022 17:32:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=11
05/26/2022 17:32:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.29 on epoch=11
05/26/2022 17:33:21 - INFO - __main__ - Global step 1250 Train loss 0.23 Classification-F1 0.5003330351294403 on epoch=11
05/26/2022 17:33:23 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.23 on epoch=11
05/26/2022 17:33:26 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=11
05/26/2022 17:33:29 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.21 on epoch=11
05/26/2022 17:33:31 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.23 on epoch=11
05/26/2022 17:33:34 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.26 on epoch=11
05/26/2022 17:34:30 - INFO - __main__ - Global step 1300 Train loss 0.23 Classification-F1 0.6855461844781574 on epoch=11
05/26/2022 17:34:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6751962305120143 -> 0.6855461844781574 on epoch=11, global_step=1300
05/26/2022 17:34:33 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=11
05/26/2022 17:34:36 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.21 on epoch=11
05/26/2022 17:34:38 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=11
05/26/2022 17:34:41 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.16 on epoch=11
05/26/2022 17:34:44 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=12
05/26/2022 17:35:36 - INFO - __main__ - Global step 1350 Train loss 0.21 Classification-F1 0.45354808025083304 on epoch=12
05/26/2022 17:35:39 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.27 on epoch=12
05/26/2022 17:35:41 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.23 on epoch=12
05/26/2022 17:35:44 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=12
05/26/2022 17:35:46 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=12
05/26/2022 17:35:49 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.23 on epoch=12
05/26/2022 17:36:43 - INFO - __main__ - Global step 1400 Train loss 0.21 Classification-F1 0.47506796100914606 on epoch=12
05/26/2022 17:36:45 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=12
05/26/2022 17:36:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=12
05/26/2022 17:36:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=12
05/26/2022 17:36:53 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.21 on epoch=12
05/26/2022 17:36:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=12
05/26/2022 17:37:48 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.3907414484103749 on epoch=12
05/26/2022 17:37:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=13
05/26/2022 17:37:53 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.18 on epoch=13
05/26/2022 17:37:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=13
05/26/2022 17:37:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=13
05/26/2022 17:38:01 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=13
05/26/2022 17:38:55 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.4921698004707368 on epoch=13
05/26/2022 17:38:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=13
05/26/2022 17:39:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=13
05/26/2022 17:39:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=13
05/26/2022 17:39:06 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=13
05/26/2022 17:39:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.20 on epoch=13
05/26/2022 17:40:00 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.3535264230693751 on epoch=13
05/26/2022 17:40:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=13
05/26/2022 17:40:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.13 on epoch=14
05/26/2022 17:40:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.21 on epoch=14
05/26/2022 17:40:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.20 on epoch=14
05/26/2022 17:40:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=14
05/26/2022 17:41:06 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.45960115353971825 on epoch=14
05/26/2022 17:41:09 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=14
05/26/2022 17:41:12 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=14
05/26/2022 17:41:14 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=14
05/26/2022 17:41:17 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.20 on epoch=14
05/26/2022 17:41:20 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.15 on epoch=14
05/26/2022 17:42:10 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.414706242545523 on epoch=14
05/26/2022 17:42:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=14
05/26/2022 17:42:15 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.20 on epoch=14
05/26/2022 17:42:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=14
05/26/2022 17:42:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=15
05/26/2022 17:42:23 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.23 on epoch=15
05/26/2022 17:43:12 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.4228101982380667 on epoch=15
05/26/2022 17:43:15 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.12 on epoch=15
05/26/2022 17:43:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=15
05/26/2022 17:43:20 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=15
05/26/2022 17:43:23 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.18 on epoch=15
05/26/2022 17:43:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=15
05/26/2022 17:44:15 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.4304532413722689 on epoch=15
05/26/2022 17:44:18 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=15
05/26/2022 17:44:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=15
05/26/2022 17:44:23 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=15
05/26/2022 17:44:26 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=15
05/26/2022 17:44:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.13 on epoch=16
05/26/2022 17:45:20 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.5362365026803388 on epoch=16
05/26/2022 17:45:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.18 on epoch=16
05/26/2022 17:45:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.11 on epoch=16
05/26/2022 17:45:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=16
05/26/2022 17:45:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/26/2022 17:45:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=16
05/26/2022 17:46:28 - INFO - __main__ - Global step 1850 Train loss 0.11 Classification-F1 0.53516355456052 on epoch=16
05/26/2022 17:46:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.15 on epoch=16
05/26/2022 17:46:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=16
05/26/2022 17:46:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.17 on epoch=16
05/26/2022 17:46:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=16
05/26/2022 17:46:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.10 on epoch=16
05/26/2022 17:47:33 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.3738819198702244 on epoch=16
05/26/2022 17:47:36 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.12 on epoch=17
05/26/2022 17:47:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=17
05/26/2022 17:47:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=17
05/26/2022 17:47:44 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=17
05/26/2022 17:47:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=17
05/26/2022 17:48:38 - INFO - __main__ - Global step 1950 Train loss 0.11 Classification-F1 0.5258949943485359 on epoch=17
05/26/2022 17:48:41 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=17
05/26/2022 17:48:44 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=17
05/26/2022 17:48:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
05/26/2022 17:48:49 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=17
05/26/2022 17:48:52 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.17 on epoch=17
05/26/2022 17:49:44 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.41494996983698146 on epoch=17
05/26/2022 17:49:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=17
05/26/2022 17:49:49 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=18
05/26/2022 17:49:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.18 on epoch=18
05/26/2022 17:49:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=18
05/26/2022 17:49:57 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.15 on epoch=18
05/26/2022 17:50:51 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.5270022770499482 on epoch=18
05/26/2022 17:50:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.15 on epoch=18
05/26/2022 17:50:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=18
05/26/2022 17:50:59 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=18
05/26/2022 17:51:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=18
05/26/2022 17:51:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=18
05/26/2022 17:52:01 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.4952404204096247 on epoch=18
05/26/2022 17:52:04 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.16 on epoch=18
05/26/2022 17:52:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=18
05/26/2022 17:52:09 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=19
05/26/2022 17:52:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=19
05/26/2022 17:52:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
05/26/2022 17:53:10 - INFO - __main__ - Global step 2150 Train loss 0.11 Classification-F1 0.6498419029504656 on epoch=19
05/26/2022 17:53:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=19
05/26/2022 17:53:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=19
05/26/2022 17:53:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=19
05/26/2022 17:53:21 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.14 on epoch=19
05/26/2022 17:53:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=19
05/26/2022 17:54:13 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.38091071827053796 on epoch=19
05/26/2022 17:54:16 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.10 on epoch=19
05/26/2022 17:54:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=19
05/26/2022 17:54:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.13 on epoch=19
05/26/2022 17:54:24 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
05/26/2022 17:54:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=20
05/26/2022 17:55:21 - INFO - __main__ - Global step 2250 Train loss 0.10 Classification-F1 0.5861236757694533 on epoch=20
05/26/2022 17:55:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.12 on epoch=20
05/26/2022 17:55:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=20
05/26/2022 17:55:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=20
05/26/2022 17:55:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
05/26/2022 17:55:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.14 on epoch=20
05/26/2022 17:56:26 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.4521812533891295 on epoch=20
05/26/2022 17:56:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=20
05/26/2022 17:56:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=20
05/26/2022 17:56:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.15 on epoch=20
05/26/2022 17:56:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=20
05/26/2022 17:56:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
05/26/2022 17:57:34 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.410906448764285 on epoch=20
05/26/2022 17:57:36 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=21
05/26/2022 17:57:39 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.24 on epoch=21
05/26/2022 17:57:42 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=21
05/26/2022 17:57:44 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=21
05/26/2022 17:57:47 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=21
05/26/2022 17:58:38 - INFO - __main__ - Global step 2400 Train loss 0.10 Classification-F1 0.45436074182466246 on epoch=21
05/26/2022 17:58:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.09 on epoch=21
05/26/2022 17:58:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=21
05/26/2022 17:58:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=21
05/26/2022 17:58:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=21
05/26/2022 17:58:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=21
05/26/2022 17:59:42 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.48933453124530196 on epoch=21
05/26/2022 17:59:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=21
05/26/2022 17:59:47 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=22
05/26/2022 17:59:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.17 on epoch=22
05/26/2022 17:59:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.14 on epoch=22
05/26/2022 17:59:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/26/2022 18:00:51 - INFO - __main__ - Global step 2500 Train loss 0.11 Classification-F1 0.5078953381523037 on epoch=22
05/26/2022 18:00:53 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/26/2022 18:00:56 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=22
05/26/2022 18:00:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=22
05/26/2022 18:01:01 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=22
05/26/2022 18:01:04 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/26/2022 18:01:59 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.471439466233372 on epoch=22
05/26/2022 18:02:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=22
05/26/2022 18:02:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=22
05/26/2022 18:02:07 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=23
05/26/2022 18:02:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.25 on epoch=23
05/26/2022 18:02:12 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=23
05/26/2022 18:03:05 - INFO - __main__ - Global step 2600 Train loss 0.10 Classification-F1 0.5132412188901282 on epoch=23
05/26/2022 18:03:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=23
05/26/2022 18:03:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/26/2022 18:03:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/26/2022 18:03:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=23
05/26/2022 18:03:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=23
05/26/2022 18:04:10 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.5398597254570535 on epoch=23
05/26/2022 18:04:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=23
05/26/2022 18:04:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=23
05/26/2022 18:04:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=23
05/26/2022 18:04:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
05/26/2022 18:04:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.11 on epoch=24
05/26/2022 18:05:17 - INFO - __main__ - Global step 2700 Train loss 0.08 Classification-F1 0.4398592940044779 on epoch=24
05/26/2022 18:05:19 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=24
05/26/2022 18:05:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=24
05/26/2022 18:05:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 18:05:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=24
05/26/2022 18:05:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=24
05/26/2022 18:06:23 - INFO - __main__ - Global step 2750 Train loss 0.07 Classification-F1 0.47108060213056524 on epoch=24
05/26/2022 18:06:26 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=24
05/26/2022 18:06:28 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=24
05/26/2022 18:06:31 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.10 on epoch=24
05/26/2022 18:06:34 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.09 on epoch=24
05/26/2022 18:06:36 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/26/2022 18:07:32 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.40489078598662925 on epoch=24
05/26/2022 18:07:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=25
05/26/2022 18:07:37 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=25
05/26/2022 18:07:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
05/26/2022 18:07:42 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=25
05/26/2022 18:07:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.09 on epoch=25
05/26/2022 18:08:36 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.6131612395647301 on epoch=25
05/26/2022 18:08:38 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=25
05/26/2022 18:08:41 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=25
05/26/2022 18:08:44 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=25
05/26/2022 18:08:46 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=25
05/26/2022 18:08:49 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=25
05/26/2022 18:09:42 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.45790983585627776 on epoch=25
05/26/2022 18:09:44 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/26/2022 18:09:47 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.07 on epoch=26
05/26/2022 18:09:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=26
05/26/2022 18:09:52 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=26
05/26/2022 18:09:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=26
05/26/2022 18:10:50 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.5617484723910763 on epoch=26
05/26/2022 18:10:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
05/26/2022 18:10:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=26
05/26/2022 18:10:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=26
05/26/2022 18:11:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=26
05/26/2022 18:11:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=26
05/26/2022 18:11:04 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 18:11:04 - INFO - __main__ - Printing 3 examples
05/26/2022 18:11:04 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 18:11:04 - INFO - __main__ - ['Film']
05/26/2022 18:11:04 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 18:11:04 - INFO - __main__ - ['Film']
05/26/2022 18:11:04 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 18:11:04 - INFO - __main__ - ['Film']
05/26/2022 18:11:04 - INFO - __main__ - Tokenizing Input ...
05/26/2022 18:11:05 - INFO - __main__ - Tokenizing Output ...
05/26/2022 18:11:07 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 18:11:07 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 18:11:07 - INFO - __main__ - Printing 3 examples
05/26/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 18:11:07 - INFO - __main__ - ['Film']
05/26/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 18:11:07 - INFO - __main__ - ['Film']
05/26/2022 18:11:07 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 18:11:07 - INFO - __main__ - ['Film']
05/26/2022 18:11:07 - INFO - __main__ - Tokenizing Input ...
05/26/2022 18:11:08 - INFO - __main__ - Tokenizing Output ...
05/26/2022 18:11:10 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 18:11:25 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 18:11:25 - INFO - __main__ - task name: dbpedia_14
05/26/2022 18:11:26 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 18:11:26 - INFO - __main__ - Starting training!
05/26/2022 18:11:57 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.38002705188743363 on epoch=26
05/26/2022 18:11:57 - INFO - __main__ - save last model!
05/26/2022 18:11:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 18:11:57 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 18:11:57 - INFO - __main__ - Printing 3 examples
05/26/2022 18:11:57 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 18:11:57 - INFO - __main__ - ['Animal']
05/26/2022 18:11:57 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 18:11:57 - INFO - __main__ - ['Animal']
05/26/2022 18:11:57 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 18:11:57 - INFO - __main__ - ['Village']
05/26/2022 18:11:57 - INFO - __main__ - Tokenizing Input ...
05/26/2022 18:11:59 - INFO - __main__ - Tokenizing Output ...
05/26/2022 18:12:02 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 18:14:11 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_42_0.2_8_predictions.txt
05/26/2022 18:14:11 - INFO - __main__ - Classification-F1 on test data: 0.3615
05/26/2022 18:14:12 - INFO - __main__ - prefix=dbpedia_14_128_42, lr=0.2, bsz=8, dev_performance=0.6855461844781574, test_performance=0.36152787169437156
05/26/2022 18:14:12 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.5, bsz=8 ...
05/26/2022 18:14:12 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 18:14:12 - INFO - __main__ - Printing 3 examples
05/26/2022 18:14:12 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 18:14:12 - INFO - __main__ - ['Film']
05/26/2022 18:14:12 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 18:14:12 - INFO - __main__ - ['Film']
05/26/2022 18:14:12 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 18:14:12 - INFO - __main__ - ['Film']
05/26/2022 18:14:12 - INFO - __main__ - Tokenizing Input ...
05/26/2022 18:14:13 - INFO - __main__ - Tokenizing Output ...
05/26/2022 18:14:15 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 18:14:15 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 18:14:15 - INFO - __main__ - Printing 3 examples
05/26/2022 18:14:15 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 18:14:15 - INFO - __main__ - ['Film']
05/26/2022 18:14:15 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 18:14:15 - INFO - __main__ - ['Film']
05/26/2022 18:14:15 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 18:14:15 - INFO - __main__ - ['Film']
05/26/2022 18:14:15 - INFO - __main__ - Tokenizing Input ...
05/26/2022 18:14:16 - INFO - __main__ - Tokenizing Output ...
05/26/2022 18:14:18 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 18:14:34 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 18:14:34 - INFO - __main__ - task name: dbpedia_14
05/26/2022 18:14:34 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 18:14:34 - INFO - __main__ - Starting training!
05/26/2022 18:14:37 - INFO - __main__ - Step 10 Global step 10 Train loss 6.51 on epoch=0
05/26/2022 18:14:40 - INFO - __main__ - Step 20 Global step 20 Train loss 4.93 on epoch=0
05/26/2022 18:14:43 - INFO - __main__ - Step 30 Global step 30 Train loss 3.22 on epoch=0
05/26/2022 18:14:45 - INFO - __main__ - Step 40 Global step 40 Train loss 2.36 on epoch=0
05/26/2022 18:14:48 - INFO - __main__ - Step 50 Global step 50 Train loss 2.23 on epoch=0
05/26/2022 18:15:44 - INFO - __main__ - Global step 50 Train loss 3.85 Classification-F1 0.13552660047914353 on epoch=0
05/26/2022 18:15:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.13552660047914353 on epoch=0, global_step=50
05/26/2022 18:15:47 - INFO - __main__ - Step 60 Global step 60 Train loss 1.71 on epoch=0
05/26/2022 18:15:49 - INFO - __main__ - Step 70 Global step 70 Train loss 1.43 on epoch=0
05/26/2022 18:15:52 - INFO - __main__ - Step 80 Global step 80 Train loss 1.29 on epoch=0
05/26/2022 18:15:54 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=0
05/26/2022 18:15:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.94 on epoch=0
05/26/2022 18:16:59 - INFO - __main__ - Global step 100 Train loss 1.30 Classification-F1 0.19057811563001179 on epoch=0
05/26/2022 18:16:59 - INFO - __main__ - Saving model with best Classification-F1: 0.13552660047914353 -> 0.19057811563001179 on epoch=0, global_step=100
05/26/2022 18:17:01 - INFO - __main__ - Step 110 Global step 110 Train loss 1.01 on epoch=0
05/26/2022 18:17:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.88 on epoch=1
05/26/2022 18:17:07 - INFO - __main__ - Step 130 Global step 130 Train loss 0.89 on epoch=1
05/26/2022 18:17:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.75 on epoch=1
05/26/2022 18:17:12 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=1
05/26/2022 18:18:09 - INFO - __main__ - Global step 150 Train loss 0.87 Classification-F1 0.3085841100702399 on epoch=1
05/26/2022 18:18:09 - INFO - __main__ - Saving model with best Classification-F1: 0.19057811563001179 -> 0.3085841100702399 on epoch=1, global_step=150
05/26/2022 18:18:12 - INFO - __main__ - Step 160 Global step 160 Train loss 0.67 on epoch=1
05/26/2022 18:18:14 - INFO - __main__ - Step 170 Global step 170 Train loss 0.68 on epoch=1
05/26/2022 18:18:17 - INFO - __main__ - Step 180 Global step 180 Train loss 0.64 on epoch=1
05/26/2022 18:18:19 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=1
05/26/2022 18:18:22 - INFO - __main__ - Step 200 Global step 200 Train loss 0.67 on epoch=1
05/26/2022 18:19:12 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.41270440573973133 on epoch=1
05/26/2022 18:19:12 - INFO - __main__ - Saving model with best Classification-F1: 0.3085841100702399 -> 0.41270440573973133 on epoch=1, global_step=200
05/26/2022 18:19:15 - INFO - __main__ - Step 210 Global step 210 Train loss 0.63 on epoch=1
05/26/2022 18:19:18 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=1
05/26/2022 18:19:20 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=2
05/26/2022 18:19:23 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=2
05/26/2022 18:19:26 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=2
05/26/2022 18:20:21 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.36580528049344996 on epoch=2
05/26/2022 18:20:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.51 on epoch=2
05/26/2022 18:20:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.41 on epoch=2
05/26/2022 18:20:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=2
05/26/2022 18:20:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.54 on epoch=2
05/26/2022 18:20:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.53 on epoch=2
05/26/2022 18:21:27 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.33230673570410807 on epoch=2
05/26/2022 18:21:29 - INFO - __main__ - Step 310 Global step 310 Train loss 0.43 on epoch=2
05/26/2022 18:21:32 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=2
05/26/2022 18:21:35 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=2
05/26/2022 18:21:37 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=3
05/26/2022 18:21:40 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=3
05/26/2022 18:22:32 - INFO - __main__ - Global step 350 Train loss 0.41 Classification-F1 0.3699562704384676 on epoch=3
05/26/2022 18:22:35 - INFO - __main__ - Step 360 Global step 360 Train loss 0.38 on epoch=3
05/26/2022 18:22:38 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=3
05/26/2022 18:22:40 - INFO - __main__ - Step 380 Global step 380 Train loss 0.40 on epoch=3
05/26/2022 18:22:43 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=3
05/26/2022 18:22:45 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=3
05/26/2022 18:23:37 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.35879912537819947 on epoch=3
05/26/2022 18:23:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.41 on epoch=3
05/26/2022 18:23:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.39 on epoch=3
05/26/2022 18:23:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.35 on epoch=3
05/26/2022 18:23:48 - INFO - __main__ - Step 440 Global step 440 Train loss 0.29 on epoch=3
05/26/2022 18:23:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=4
05/26/2022 18:24:52 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.3984510988895034 on epoch=4
05/26/2022 18:24:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=4
05/26/2022 18:24:57 - INFO - __main__ - Step 470 Global step 470 Train loss 0.34 on epoch=4
05/26/2022 18:24:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.73 on epoch=4
05/26/2022 18:25:02 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=4
05/26/2022 18:25:05 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=4
05/26/2022 18:25:55 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.6778717353677814 on epoch=4
05/26/2022 18:25:56 - INFO - __main__ - Saving model with best Classification-F1: 0.41270440573973133 -> 0.6778717353677814 on epoch=4, global_step=500
05/26/2022 18:25:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=4
05/26/2022 18:26:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.26 on epoch=4
05/26/2022 18:26:03 - INFO - __main__ - Step 530 Global step 530 Train loss 0.25 on epoch=4
05/26/2022 18:26:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=4
05/26/2022 18:26:08 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=4
05/26/2022 18:26:59 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.7409717831752188 on epoch=4
05/26/2022 18:26:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6778717353677814 -> 0.7409717831752188 on epoch=4, global_step=550
05/26/2022 18:27:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=4
05/26/2022 18:27:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=5
05/26/2022 18:27:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.21 on epoch=5
05/26/2022 18:27:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=5
05/26/2022 18:27:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=5
05/26/2022 18:28:04 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.6569086895178055 on epoch=5
05/26/2022 18:28:07 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=5
05/26/2022 18:28:09 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=5
05/26/2022 18:28:12 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=5
05/26/2022 18:28:14 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=5
05/26/2022 18:28:17 - INFO - __main__ - Step 650 Global step 650 Train loss 0.16 on epoch=5
05/26/2022 18:29:13 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.5946670370639572 on epoch=5
05/26/2022 18:29:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=5
05/26/2022 18:29:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=5
05/26/2022 18:29:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.16 on epoch=6
05/26/2022 18:29:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.18 on epoch=6
05/26/2022 18:29:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=6
05/26/2022 18:30:18 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.4647838150324245 on epoch=6
05/26/2022 18:30:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.16 on epoch=6
05/26/2022 18:30:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=6
05/26/2022 18:30:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=6
05/26/2022 18:30:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=6
05/26/2022 18:30:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=6
05/26/2022 18:31:18 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.6082170349985376 on epoch=6
05/26/2022 18:31:20 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=6
05/26/2022 18:31:23 - INFO - __main__ - Step 770 Global step 770 Train loss 0.16 on epoch=6
05/26/2022 18:31:25 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/26/2022 18:31:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=7
05/26/2022 18:31:30 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=7
05/26/2022 18:32:28 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5900668874951408 on epoch=7
05/26/2022 18:32:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=7
05/26/2022 18:32:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.15 on epoch=7
05/26/2022 18:32:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=7
05/26/2022 18:32:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=7
05/26/2022 18:32:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.11 on epoch=7
05/26/2022 18:33:36 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.5813639406947997 on epoch=7
05/26/2022 18:33:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=7
05/26/2022 18:33:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=7
05/26/2022 18:33:44 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=7
05/26/2022 18:33:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
05/26/2022 18:33:49 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=8
05/26/2022 18:34:39 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.49202532035682034 on epoch=8
05/26/2022 18:34:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=8
05/26/2022 18:34:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=8
05/26/2022 18:34:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=8
05/26/2022 18:34:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=8
05/26/2022 18:34:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.06 on epoch=8
05/26/2022 18:35:44 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.4180890351293309 on epoch=8
05/26/2022 18:35:46 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=8
05/26/2022 18:35:49 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=8
05/26/2022 18:35:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=8
05/26/2022 18:35:54 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=8
05/26/2022 18:35:57 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=8
05/26/2022 18:36:52 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.5095339119961888 on epoch=8
05/26/2022 18:36:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=9
05/26/2022 18:36:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=9
05/26/2022 18:37:00 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=9
05/26/2022 18:37:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=9
05/26/2022 18:37:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=9
05/26/2022 18:38:00 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.47713859278037085 on epoch=9
05/26/2022 18:38:03 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=9
05/26/2022 18:38:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=9
05/26/2022 18:38:08 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=9
05/26/2022 18:38:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.11 on epoch=9
05/26/2022 18:38:13 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=9
05/26/2022 18:39:08 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.670829494759631 on epoch=9
05/26/2022 18:39:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.04 on epoch=9
05/26/2022 18:39:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=9
05/26/2022 18:39:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=10
05/26/2022 18:39:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=10
05/26/2022 18:39:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=10
05/26/2022 18:40:15 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7996500057629473 on epoch=10
05/26/2022 18:40:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7409717831752188 -> 0.7996500057629473 on epoch=10, global_step=1150
05/26/2022 18:40:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=10
05/26/2022 18:40:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=10
05/26/2022 18:40:23 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=10
05/26/2022 18:40:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=10
05/26/2022 18:40:28 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=10
05/26/2022 18:41:16 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.5831455448066454 on epoch=10
05/26/2022 18:41:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=10
05/26/2022 18:41:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=10
05/26/2022 18:41:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=10
05/26/2022 18:41:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
05/26/2022 18:41:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=11
05/26/2022 18:42:19 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6435680759432791 on epoch=11
05/26/2022 18:42:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=11
05/26/2022 18:42:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=11
05/26/2022 18:42:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.07 on epoch=11
05/26/2022 18:42:29 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=11
05/26/2022 18:42:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=11
05/26/2022 18:43:21 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8039875976988273 on epoch=11
05/26/2022 18:43:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7996500057629473 -> 0.8039875976988273 on epoch=11, global_step=1300
05/26/2022 18:43:23 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 18:43:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=11
05/26/2022 18:43:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.02 on epoch=11
05/26/2022 18:43:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=11
05/26/2022 18:43:34 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=12
05/26/2022 18:44:26 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7572501990644633 on epoch=12
05/26/2022 18:44:28 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=12
05/26/2022 18:44:31 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=12
05/26/2022 18:44:34 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=12
05/26/2022 18:44:36 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=12
05/26/2022 18:44:39 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=12
05/26/2022 18:45:31 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6676668585291069 on epoch=12
05/26/2022 18:45:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=12
05/26/2022 18:45:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=12
05/26/2022 18:45:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=12
05/26/2022 18:45:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=12
05/26/2022 18:45:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=12
05/26/2022 18:46:33 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6750489409828484 on epoch=12
05/26/2022 18:46:36 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=13
05/26/2022 18:46:39 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=13
05/26/2022 18:46:41 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=13
05/26/2022 18:46:44 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
05/26/2022 18:46:46 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=13
05/26/2022 18:47:37 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6115590196822338 on epoch=13
05/26/2022 18:47:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=13
05/26/2022 18:47:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/26/2022 18:47:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=13
05/26/2022 18:47:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=13
05/26/2022 18:47:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=13
05/26/2022 18:48:39 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.622192075268154 on epoch=13
05/26/2022 18:48:41 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=13
05/26/2022 18:48:44 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=14
05/26/2022 18:48:46 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=14
05/26/2022 18:48:49 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=14
05/26/2022 18:48:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=14
05/26/2022 18:49:44 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7160360851671973 on epoch=14
05/26/2022 18:49:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=14
05/26/2022 18:49:49 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=14
05/26/2022 18:49:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=14
05/26/2022 18:49:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=14
05/26/2022 18:49:57 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=14
05/26/2022 18:50:46 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6153037978839284 on epoch=14
05/26/2022 18:50:48 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
05/26/2022 18:50:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=14
05/26/2022 18:50:53 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=14
05/26/2022 18:50:56 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=15
05/26/2022 18:50:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=15
05/26/2022 18:51:49 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.7163714641039428 on epoch=15
05/26/2022 18:51:52 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
05/26/2022 18:51:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=15
05/26/2022 18:51:57 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=15
05/26/2022 18:52:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/26/2022 18:52:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=15
05/26/2022 18:52:51 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7002645290942903 on epoch=15
05/26/2022 18:52:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=15
05/26/2022 18:52:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=15
05/26/2022 18:52:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=15
05/26/2022 18:53:02 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
05/26/2022 18:53:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=16
05/26/2022 18:53:51 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5386653108735198 on epoch=16
05/26/2022 18:53:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=16
05/26/2022 18:53:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/26/2022 18:53:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=16
05/26/2022 18:54:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=16
05/26/2022 18:54:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=16
05/26/2022 18:54:56 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7448486285216346 on epoch=16
05/26/2022 18:54:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.14 on epoch=16
05/26/2022 18:55:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=16
05/26/2022 18:55:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=16
05/26/2022 18:55:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=16
05/26/2022 18:55:09 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
05/26/2022 18:55:56 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.6516466445575902 on epoch=16
05/26/2022 18:55:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/26/2022 18:56:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=17
05/26/2022 18:56:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=17
05/26/2022 18:56:07 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 18:56:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/26/2022 18:56:58 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.9141968935054567 on epoch=17
05/26/2022 18:56:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8039875976988273 -> 0.9141968935054567 on epoch=17, global_step=1950
05/26/2022 18:57:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=17
05/26/2022 18:57:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=17
05/26/2022 18:57:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=17
05/26/2022 18:57:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=17
05/26/2022 18:57:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
05/26/2022 18:58:00 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.858123711075053 on epoch=17
05/26/2022 18:58:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=17
05/26/2022 18:58:06 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=18
05/26/2022 18:58:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=18
05/26/2022 18:58:11 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/26/2022 18:58:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=18
05/26/2022 18:59:06 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8084913180721978 on epoch=18
05/26/2022 18:59:08 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
05/26/2022 18:59:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=18
05/26/2022 18:59:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=18
05/26/2022 18:59:16 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=18
05/26/2022 18:59:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=18
05/26/2022 19:00:04 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.6131451406329428 on epoch=18
05/26/2022 19:00:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=18
05/26/2022 19:00:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=18
05/26/2022 19:00:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=19
05/26/2022 19:00:15 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=19
05/26/2022 19:00:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=19
05/26/2022 19:01:05 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8686759233541799 on epoch=19
05/26/2022 19:01:08 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=19
05/26/2022 19:01:11 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 19:01:13 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 19:01:16 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=19
05/26/2022 19:01:19 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=19
05/26/2022 19:02:08 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7885051816997348 on epoch=19
05/26/2022 19:02:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=19
05/26/2022 19:02:13 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=19
05/26/2022 19:02:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/26/2022 19:02:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=19
05/26/2022 19:02:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/26/2022 19:03:08 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6471995367317501 on epoch=20
05/26/2022 19:03:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=20
05/26/2022 19:03:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/26/2022 19:03:16 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=20
05/26/2022 19:03:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=20
05/26/2022 19:03:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=20
05/26/2022 19:04:10 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7986398918006358 on epoch=20
05/26/2022 19:04:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/26/2022 19:04:15 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=20
05/26/2022 19:04:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=20
05/26/2022 19:04:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=20
05/26/2022 19:04:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=20
05/26/2022 19:05:15 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.753975432086873 on epoch=20
05/26/2022 19:05:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=21
05/26/2022 19:05:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
05/26/2022 19:05:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=21
05/26/2022 19:05:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 19:05:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=21
05/26/2022 19:06:17 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6738181656694171 on epoch=21
05/26/2022 19:06:19 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/26/2022 19:06:22 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
05/26/2022 19:06:25 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=21
05/26/2022 19:06:27 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=21
05/26/2022 19:06:30 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=21
05/26/2022 19:07:16 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7567862759321269 on epoch=21
05/26/2022 19:07:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=21
05/26/2022 19:07:22 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=22
05/26/2022 19:07:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/26/2022 19:07:27 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
05/26/2022 19:07:30 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/26/2022 19:08:17 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.722579889319663 on epoch=22
05/26/2022 19:08:20 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=22
05/26/2022 19:08:23 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=22
05/26/2022 19:08:25 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=22
05/26/2022 19:08:28 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=22
05/26/2022 19:08:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=22
05/26/2022 19:09:20 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7176479198097423 on epoch=22
05/26/2022 19:09:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=22
05/26/2022 19:09:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=22
05/26/2022 19:09:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/26/2022 19:09:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/26/2022 19:09:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=23
05/26/2022 19:10:20 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.6371771798520006 on epoch=23
05/26/2022 19:10:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/26/2022 19:10:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=23
05/26/2022 19:10:28 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=23
05/26/2022 19:10:31 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 19:10:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=23
05/26/2022 19:11:21 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.6390181898339046 on epoch=23
05/26/2022 19:11:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=23
05/26/2022 19:11:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
05/26/2022 19:11:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=23
05/26/2022 19:11:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=24
05/26/2022 19:11:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
05/26/2022 19:12:22 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.8450346749187123 on epoch=24
05/26/2022 19:12:25 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/26/2022 19:12:27 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=24
05/26/2022 19:12:30 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=24
05/26/2022 19:12:33 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
05/26/2022 19:12:35 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=24
05/26/2022 19:13:22 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9226292017727108 on epoch=24
05/26/2022 19:13:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9141968935054567 -> 0.9226292017727108 on epoch=24, global_step=2750
05/26/2022 19:13:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 19:13:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=24
05/26/2022 19:13:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=24
05/26/2022 19:13:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=24
05/26/2022 19:13:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/26/2022 19:14:21 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8122247677488259 on epoch=24
05/26/2022 19:14:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/26/2022 19:14:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=25
05/26/2022 19:14:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=25
05/26/2022 19:14:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=25
05/26/2022 19:14:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/26/2022 19:15:21 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7623160367773184 on epoch=25
05/26/2022 19:15:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/26/2022 19:15:26 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=25
05/26/2022 19:15:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=25
05/26/2022 19:15:31 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=25
05/26/2022 19:15:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=25
05/26/2022 19:16:24 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7630662920775543 on epoch=25
05/26/2022 19:16:26 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=25
05/26/2022 19:16:29 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=26
05/26/2022 19:16:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 19:16:34 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
05/26/2022 19:16:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/26/2022 19:17:30 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7668571852924451 on epoch=26
05/26/2022 19:17:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=26
05/26/2022 19:17:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/26/2022 19:17:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/26/2022 19:17:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=26
05/26/2022 19:17:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=26
05/26/2022 19:17:44 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 19:17:44 - INFO - __main__ - Printing 3 examples
05/26/2022 19:17:44 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 19:17:44 - INFO - __main__ - ['Film']
05/26/2022 19:17:44 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 19:17:44 - INFO - __main__ - ['Film']
05/26/2022 19:17:44 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 19:17:44 - INFO - __main__ - ['Film']
05/26/2022 19:17:44 - INFO - __main__ - Tokenizing Input ...
05/26/2022 19:17:45 - INFO - __main__ - Tokenizing Output ...
05/26/2022 19:17:47 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 19:17:47 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 19:17:47 - INFO - __main__ - Printing 3 examples
05/26/2022 19:17:47 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 19:17:47 - INFO - __main__ - ['Film']
05/26/2022 19:17:47 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 19:17:47 - INFO - __main__ - ['Film']
05/26/2022 19:17:47 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 19:17:47 - INFO - __main__ - ['Film']
05/26/2022 19:17:47 - INFO - __main__ - Tokenizing Input ...
05/26/2022 19:17:48 - INFO - __main__ - Tokenizing Output ...
05/26/2022 19:17:49 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 19:18:08 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 19:18:08 - INFO - __main__ - task name: dbpedia_14
05/26/2022 19:18:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 19:18:09 - INFO - __main__ - Starting training!
05/26/2022 19:18:33 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8105097303070771 on epoch=26
05/26/2022 19:18:33 - INFO - __main__ - save last model!
05/26/2022 19:18:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 19:18:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 19:18:33 - INFO - __main__ - Printing 3 examples
05/26/2022 19:18:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 19:18:33 - INFO - __main__ - ['Animal']
05/26/2022 19:18:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 19:18:33 - INFO - __main__ - ['Animal']
05/26/2022 19:18:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 19:18:33 - INFO - __main__ - ['Village']
05/26/2022 19:18:33 - INFO - __main__ - Tokenizing Input ...
05/26/2022 19:18:35 - INFO - __main__ - Tokenizing Output ...
05/26/2022 19:18:39 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 19:20:50 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.5_8_predictions.txt
05/26/2022 19:20:50 - INFO - __main__ - Classification-F1 on test data: 0.6501
05/26/2022 19:20:51 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.5, bsz=8, dev_performance=0.9226292017727108, test_performance=0.6500502353654927
05/26/2022 19:20:51 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.4, bsz=8 ...
05/26/2022 19:20:51 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 19:20:51 - INFO - __main__ - Printing 3 examples
05/26/2022 19:20:51 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 19:20:51 - INFO - __main__ - ['Film']
05/26/2022 19:20:51 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 19:20:51 - INFO - __main__ - ['Film']
05/26/2022 19:20:51 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 19:20:51 - INFO - __main__ - ['Film']
05/26/2022 19:20:51 - INFO - __main__ - Tokenizing Input ...
05/26/2022 19:20:52 - INFO - __main__ - Tokenizing Output ...
05/26/2022 19:20:54 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 19:20:54 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 19:20:54 - INFO - __main__ - Printing 3 examples
05/26/2022 19:20:54 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 19:20:54 - INFO - __main__ - ['Film']
05/26/2022 19:20:54 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 19:20:54 - INFO - __main__ - ['Film']
05/26/2022 19:20:54 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 19:20:54 - INFO - __main__ - ['Film']
05/26/2022 19:20:54 - INFO - __main__ - Tokenizing Input ...
05/26/2022 19:20:55 - INFO - __main__ - Tokenizing Output ...
05/26/2022 19:20:57 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 19:21:16 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 19:21:16 - INFO - __main__ - task name: dbpedia_14
05/26/2022 19:21:17 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 19:21:17 - INFO - __main__ - Starting training!
05/26/2022 19:21:20 - INFO - __main__ - Step 10 Global step 10 Train loss 6.47 on epoch=0
05/26/2022 19:21:23 - INFO - __main__ - Step 20 Global step 20 Train loss 5.18 on epoch=0
05/26/2022 19:21:25 - INFO - __main__ - Step 30 Global step 30 Train loss 3.83 on epoch=0
05/26/2022 19:21:28 - INFO - __main__ - Step 40 Global step 40 Train loss 2.95 on epoch=0
05/26/2022 19:21:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.53 on epoch=0
05/26/2022 19:22:13 - INFO - __main__ - Global step 50 Train loss 4.19 Classification-F1 0.12916000917238216 on epoch=0
05/26/2022 19:22:13 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.12916000917238216 on epoch=0, global_step=50
05/26/2022 19:22:15 - INFO - __main__ - Step 60 Global step 60 Train loss 2.04 on epoch=0
05/26/2022 19:22:18 - INFO - __main__ - Step 70 Global step 70 Train loss 1.80 on epoch=0
05/26/2022 19:22:21 - INFO - __main__ - Step 80 Global step 80 Train loss 1.51 on epoch=0
05/26/2022 19:22:23 - INFO - __main__ - Step 90 Global step 90 Train loss 1.46 on epoch=0
05/26/2022 19:22:26 - INFO - __main__ - Step 100 Global step 100 Train loss 1.27 on epoch=0
05/26/2022 19:23:08 - INFO - __main__ - Global step 100 Train loss 1.62 Classification-F1 0.34882849734321264 on epoch=0
05/26/2022 19:23:09 - INFO - __main__ - Saving model with best Classification-F1: 0.12916000917238216 -> 0.34882849734321264 on epoch=0, global_step=100
05/26/2022 19:23:11 - INFO - __main__ - Step 110 Global step 110 Train loss 1.27 on epoch=0
05/26/2022 19:23:14 - INFO - __main__ - Step 120 Global step 120 Train loss 1.02 on epoch=1
05/26/2022 19:23:16 - INFO - __main__ - Step 130 Global step 130 Train loss 1.00 on epoch=1
05/26/2022 19:23:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.92 on epoch=1
05/26/2022 19:23:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=1
05/26/2022 19:24:13 - INFO - __main__ - Global step 150 Train loss 1.02 Classification-F1 0.32441096081833853 on epoch=1
05/26/2022 19:24:16 - INFO - __main__ - Step 160 Global step 160 Train loss 0.96 on epoch=1
05/26/2022 19:24:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.88 on epoch=1
05/26/2022 19:24:21 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=1
05/26/2022 19:24:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.74 on epoch=1
05/26/2022 19:24:26 - INFO - __main__ - Step 200 Global step 200 Train loss 0.74 on epoch=1
05/26/2022 19:25:19 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.41538491651480064 on epoch=1
05/26/2022 19:25:19 - INFO - __main__ - Saving model with best Classification-F1: 0.34882849734321264 -> 0.41538491651480064 on epoch=1, global_step=200
05/26/2022 19:25:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.64 on epoch=1
05/26/2022 19:25:24 - INFO - __main__ - Step 220 Global step 220 Train loss 0.67 on epoch=1
05/26/2022 19:25:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.54 on epoch=2
05/26/2022 19:25:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.50 on epoch=2
05/26/2022 19:25:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=2
05/26/2022 19:26:30 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.26879731896401315 on epoch=2
05/26/2022 19:26:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.61 on epoch=2
05/26/2022 19:26:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=2
05/26/2022 19:26:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=2
05/26/2022 19:26:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.41 on epoch=2
05/26/2022 19:26:43 - INFO - __main__ - Step 300 Global step 300 Train loss 0.58 on epoch=2
05/26/2022 19:27:30 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.31969717229615746 on epoch=2
05/26/2022 19:27:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.57 on epoch=2
05/26/2022 19:27:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=2
05/26/2022 19:27:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=2
05/26/2022 19:27:40 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=3
05/26/2022 19:27:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=3
05/26/2022 19:28:37 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.5511351313795725 on epoch=3
05/26/2022 19:28:37 - INFO - __main__ - Saving model with best Classification-F1: 0.41538491651480064 -> 0.5511351313795725 on epoch=3, global_step=350
05/26/2022 19:28:40 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=3
05/26/2022 19:28:42 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=3
05/26/2022 19:28:45 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=3
05/26/2022 19:28:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.41 on epoch=3
05/26/2022 19:28:50 - INFO - __main__ - Step 400 Global step 400 Train loss 0.38 on epoch=3
05/26/2022 19:29:44 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.5166341136482339 on epoch=3
05/26/2022 19:29:46 - INFO - __main__ - Step 410 Global step 410 Train loss 0.37 on epoch=3
05/26/2022 19:29:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=3
05/26/2022 19:29:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=3
05/26/2022 19:29:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.39 on epoch=3
05/26/2022 19:29:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=4
05/26/2022 19:30:51 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.44518606201599403 on epoch=4
05/26/2022 19:30:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=4
05/26/2022 19:30:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=4
05/26/2022 19:30:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=4
05/26/2022 19:31:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.21 on epoch=4
05/26/2022 19:31:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.19 on epoch=4
05/26/2022 19:31:53 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.4724851650833534 on epoch=4
05/26/2022 19:31:55 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=4
05/26/2022 19:31:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=4
05/26/2022 19:32:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=4
05/26/2022 19:32:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.29 on epoch=4
05/26/2022 19:32:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.21 on epoch=4
05/26/2022 19:32:55 - INFO - __main__ - Global step 550 Train loss 0.28 Classification-F1 0.5924269286599546 on epoch=4
05/26/2022 19:32:55 - INFO - __main__ - Saving model with best Classification-F1: 0.5511351313795725 -> 0.5924269286599546 on epoch=4, global_step=550
05/26/2022 19:32:57 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=4
05/26/2022 19:33:00 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=5
05/26/2022 19:33:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=5
05/26/2022 19:33:05 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=5
05/26/2022 19:33:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.24 on epoch=5
05/26/2022 19:34:01 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.4727665174105705 on epoch=5
05/26/2022 19:34:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=5
05/26/2022 19:34:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=5
05/26/2022 19:34:09 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=5
05/26/2022 19:34:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=5
05/26/2022 19:34:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=5
05/26/2022 19:35:05 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.5258854751815426 on epoch=5
05/26/2022 19:35:08 - INFO - __main__ - Step 660 Global step 660 Train loss 0.18 on epoch=5
05/26/2022 19:35:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=5
05/26/2022 19:35:13 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=6
05/26/2022 19:35:15 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=6
05/26/2022 19:35:18 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=6
05/26/2022 19:36:10 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.6014412168569504 on epoch=6
05/26/2022 19:36:10 - INFO - __main__ - Saving model with best Classification-F1: 0.5924269286599546 -> 0.6014412168569504 on epoch=6, global_step=700
05/26/2022 19:36:13 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=6
05/26/2022 19:36:15 - INFO - __main__ - Step 720 Global step 720 Train loss 0.21 on epoch=6
05/26/2022 19:36:18 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=6
05/26/2022 19:36:20 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=6
05/26/2022 19:36:23 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=6
05/26/2022 19:37:13 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.4722865994472878 on epoch=6
05/26/2022 19:37:15 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=6
05/26/2022 19:37:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=6
05/26/2022 19:37:20 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=6
05/26/2022 19:37:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=7
05/26/2022 19:37:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=7
05/26/2022 19:38:18 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.49910598473131595 on epoch=7
05/26/2022 19:38:20 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=7
05/26/2022 19:38:23 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=7
05/26/2022 19:38:26 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=7
05/26/2022 19:38:28 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=7
05/26/2022 19:38:31 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=7
05/26/2022 19:39:25 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.5559992676981179 on epoch=7
05/26/2022 19:39:27 - INFO - __main__ - Step 860 Global step 860 Train loss 0.17 on epoch=7
05/26/2022 19:39:30 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=7
05/26/2022 19:39:32 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=7
05/26/2022 19:39:35 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=7
05/26/2022 19:39:38 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=8
05/26/2022 19:40:31 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6181510985599317 on epoch=8
05/26/2022 19:40:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6014412168569504 -> 0.6181510985599317 on epoch=8, global_step=900
05/26/2022 19:40:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=8
05/26/2022 19:40:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=8
05/26/2022 19:40:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=8
05/26/2022 19:40:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=8
05/26/2022 19:40:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=8
05/26/2022 19:41:41 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.5002004568115761 on epoch=8
05/26/2022 19:41:44 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=8
05/26/2022 19:41:47 - INFO - __main__ - Step 970 Global step 970 Train loss 0.13 on epoch=8
05/26/2022 19:41:49 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=8
05/26/2022 19:41:52 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=8
05/26/2022 19:41:54 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=8
05/26/2022 19:42:48 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.5846484988432913 on epoch=8
05/26/2022 19:42:51 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=9
05/26/2022 19:42:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=9
05/26/2022 19:42:56 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=9
05/26/2022 19:42:59 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=9
05/26/2022 19:43:01 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=9
05/26/2022 19:43:53 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.6842500511986073 on epoch=9
05/26/2022 19:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6181510985599317 -> 0.6842500511986073 on epoch=9, global_step=1050
05/26/2022 19:43:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.14 on epoch=9
05/26/2022 19:43:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=9
05/26/2022 19:44:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.17 on epoch=9
05/26/2022 19:44:04 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=9
05/26/2022 19:44:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=9
05/26/2022 19:44:59 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.4627521483990999 on epoch=9
05/26/2022 19:45:02 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=9
05/26/2022 19:45:05 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=9
05/26/2022 19:45:07 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=10
05/26/2022 19:45:10 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=10
05/26/2022 19:45:12 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=10
05/26/2022 19:46:04 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.4982278511722548 on epoch=10
05/26/2022 19:46:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=10
05/26/2022 19:46:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=10
05/26/2022 19:46:11 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=10
05/26/2022 19:46:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=10
05/26/2022 19:46:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=10
05/26/2022 19:47:12 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6240965676161939 on epoch=10
05/26/2022 19:47:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=10
05/26/2022 19:47:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=10
05/26/2022 19:47:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=10
05/26/2022 19:47:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/26/2022 19:47:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=11
05/26/2022 19:48:19 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6616574049337285 on epoch=11
05/26/2022 19:48:22 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=11
05/26/2022 19:48:24 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=11
05/26/2022 19:48:27 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.18 on epoch=11
05/26/2022 19:48:30 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=11
05/26/2022 19:48:32 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=11
05/26/2022 19:49:24 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.4418479722800979 on epoch=11
05/26/2022 19:49:27 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=11
05/26/2022 19:49:30 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=11
05/26/2022 19:49:32 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=11
05/26/2022 19:49:35 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=11
05/26/2022 19:49:37 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=12
05/26/2022 19:50:32 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.5920816161470251 on epoch=12
05/26/2022 19:50:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=12
05/26/2022 19:50:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=12
05/26/2022 19:50:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=12
05/26/2022 19:50:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=12
05/26/2022 19:50:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=12
05/26/2022 19:51:39 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.6933674463163267 on epoch=12
05/26/2022 19:51:39 - INFO - __main__ - Saving model with best Classification-F1: 0.6842500511986073 -> 0.6933674463163267 on epoch=12, global_step=1400
05/26/2022 19:51:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=12
05/26/2022 19:51:44 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=12
05/26/2022 19:51:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=12
05/26/2022 19:51:49 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=12
05/26/2022 19:51:52 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=12
05/26/2022 19:52:40 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.540213736369547 on epoch=12
05/26/2022 19:52:42 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=13
05/26/2022 19:52:45 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=13
05/26/2022 19:52:47 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=13
05/26/2022 19:52:50 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=13
05/26/2022 19:52:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=13
05/26/2022 19:53:49 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6040657731279818 on epoch=13
05/26/2022 19:53:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=13
05/26/2022 19:53:54 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=13
05/26/2022 19:53:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=13
05/26/2022 19:53:59 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=13
05/26/2022 19:54:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.06 on epoch=13
05/26/2022 19:54:55 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5914763954328335 on epoch=13
05/26/2022 19:54:57 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=13
05/26/2022 19:55:00 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=14
05/26/2022 19:55:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=14
05/26/2022 19:55:05 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=14
05/26/2022 19:55:08 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=14
05/26/2022 19:55:59 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7850698131016198 on epoch=14
05/26/2022 19:55:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6933674463163267 -> 0.7850698131016198 on epoch=14, global_step=1600
05/26/2022 19:56:02 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=14
05/26/2022 19:56:04 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=14
05/26/2022 19:56:07 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=14
05/26/2022 19:56:09 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=14
05/26/2022 19:56:12 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=14
05/26/2022 19:56:59 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6692164415818318 on epoch=14
05/26/2022 19:57:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=14
05/26/2022 19:57:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/26/2022 19:57:07 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=14
05/26/2022 19:57:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=15
05/26/2022 19:57:12 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=15
05/26/2022 19:58:00 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7702327914566574 on epoch=15
05/26/2022 19:58:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=15
05/26/2022 19:58:05 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=15
05/26/2022 19:58:08 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.14 on epoch=15
05/26/2022 19:58:10 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=15
05/26/2022 19:58:13 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=15
05/26/2022 19:59:04 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7435591341117443 on epoch=15
05/26/2022 19:59:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=15
05/26/2022 19:59:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=15
05/26/2022 19:59:12 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=15
05/26/2022 19:59:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=15
05/26/2022 19:59:17 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=16
05/26/2022 20:00:05 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6152781314513087 on epoch=16
05/26/2022 20:00:07 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=16
05/26/2022 20:00:10 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=16
05/26/2022 20:00:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=16
05/26/2022 20:00:15 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.08 on epoch=16
05/26/2022 20:00:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=16
05/26/2022 20:01:08 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5383271593206778 on epoch=16
05/26/2022 20:01:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=16
05/26/2022 20:01:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=16
05/26/2022 20:01:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=16
05/26/2022 20:01:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=16
05/26/2022 20:01:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=16
05/26/2022 20:02:09 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.74846087984016 on epoch=16
05/26/2022 20:02:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=17
05/26/2022 20:02:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=17
05/26/2022 20:02:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=17
05/26/2022 20:02:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=17
05/26/2022 20:02:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=17
05/26/2022 20:03:10 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.7112407106855702 on epoch=17
05/26/2022 20:03:13 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=17
05/26/2022 20:03:16 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=17
05/26/2022 20:03:18 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/26/2022 20:03:21 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=17
05/26/2022 20:03:23 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=17
05/26/2022 20:04:12 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7191480785338441 on epoch=17
05/26/2022 20:04:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=17
05/26/2022 20:04:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=18
05/26/2022 20:04:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=18
05/26/2022 20:04:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=18
05/26/2022 20:04:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=18
05/26/2022 20:05:15 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6336989083528519 on epoch=18
05/26/2022 20:05:18 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=18
05/26/2022 20:05:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/26/2022 20:05:23 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.16 on epoch=18
05/26/2022 20:05:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 20:05:28 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=18
05/26/2022 20:06:18 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6816399039735946 on epoch=18
05/26/2022 20:06:20 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=18
05/26/2022 20:06:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=18
05/26/2022 20:06:25 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=19
05/26/2022 20:06:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=19
05/26/2022 20:06:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=19
05/26/2022 20:07:18 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7097741946383381 on epoch=19
05/26/2022 20:07:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/26/2022 20:07:23 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=19
05/26/2022 20:07:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=19
05/26/2022 20:07:29 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.14 on epoch=19
05/26/2022 20:07:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=19
05/26/2022 20:08:20 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7052025065627717 on epoch=19
05/26/2022 20:08:22 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=19
05/26/2022 20:08:25 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=19
05/26/2022 20:08:28 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=19
05/26/2022 20:08:30 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=19
05/26/2022 20:08:33 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=20
05/26/2022 20:09:21 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7142645673119109 on epoch=20
05/26/2022 20:09:23 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.09 on epoch=20
05/26/2022 20:09:26 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=20
05/26/2022 20:09:29 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=20
05/26/2022 20:09:31 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=20
05/26/2022 20:09:34 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=20
05/26/2022 20:10:29 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7622820099338447 on epoch=20
05/26/2022 20:10:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=20
05/26/2022 20:10:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/26/2022 20:10:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
05/26/2022 20:10:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=20
05/26/2022 20:10:42 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=20
05/26/2022 20:11:36 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.8115459614982545 on epoch=20
05/26/2022 20:11:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7850698131016198 -> 0.8115459614982545 on epoch=20, global_step=2350
05/26/2022 20:11:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=21
05/26/2022 20:11:42 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=21
05/26/2022 20:11:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=21
05/26/2022 20:11:47 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=21
05/26/2022 20:11:50 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.07 on epoch=21
05/26/2022 20:12:40 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8069745705209975 on epoch=21
05/26/2022 20:12:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=21
05/26/2022 20:12:45 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=21
05/26/2022 20:12:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.12 on epoch=21
05/26/2022 20:12:50 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=21
05/26/2022 20:12:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=21
05/26/2022 20:13:42 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8103438774261309 on epoch=21
05/26/2022 20:13:45 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=21
05/26/2022 20:13:48 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=22
05/26/2022 20:13:50 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
05/26/2022 20:13:53 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=22
05/26/2022 20:13:55 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=22
05/26/2022 20:14:43 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7254921861075188 on epoch=22
05/26/2022 20:14:46 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=22
05/26/2022 20:14:48 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=22
05/26/2022 20:14:51 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=22
05/26/2022 20:14:53 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=22
05/26/2022 20:14:56 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=22
05/26/2022 20:15:43 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.857274276355952 on epoch=22
05/26/2022 20:15:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8115459614982545 -> 0.857274276355952 on epoch=22, global_step=2550
05/26/2022 20:15:45 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=22
05/26/2022 20:15:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=22
05/26/2022 20:15:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=23
05/26/2022 20:15:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=23
05/26/2022 20:15:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=23
05/26/2022 20:16:47 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8617848356354252 on epoch=23
05/26/2022 20:16:47 - INFO - __main__ - Saving model with best Classification-F1: 0.857274276355952 -> 0.8617848356354252 on epoch=23, global_step=2600
05/26/2022 20:16:49 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=23
05/26/2022 20:16:52 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=23
05/26/2022 20:16:54 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=23
05/26/2022 20:16:57 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=23
05/26/2022 20:17:00 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=23
05/26/2022 20:17:46 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.8108335081246766 on epoch=23
05/26/2022 20:17:49 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/26/2022 20:17:51 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=23
05/26/2022 20:17:54 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=23
05/26/2022 20:17:57 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=24
05/26/2022 20:17:59 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=24
05/26/2022 20:18:46 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8627647806731001 on epoch=24
05/26/2022 20:18:46 - INFO - __main__ - Saving model with best Classification-F1: 0.8617848356354252 -> 0.8627647806731001 on epoch=24, global_step=2700
05/26/2022 20:18:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=24
05/26/2022 20:18:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=24
05/26/2022 20:18:54 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 20:18:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=24
05/26/2022 20:18:59 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=24
05/26/2022 20:19:48 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6777342829370157 on epoch=24
05/26/2022 20:19:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=24
05/26/2022 20:19:53 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/26/2022 20:19:56 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=24
05/26/2022 20:19:58 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=24
05/26/2022 20:20:01 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=24
05/26/2022 20:20:46 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8126923110187879 on epoch=24
05/26/2022 20:20:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=25
05/26/2022 20:20:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=25
05/26/2022 20:20:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=25
05/26/2022 20:20:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=25
05/26/2022 20:20:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=25
05/26/2022 20:21:45 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7230279884699913 on epoch=25
05/26/2022 20:21:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/26/2022 20:21:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=25
05/26/2022 20:21:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/26/2022 20:21:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/26/2022 20:21:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
05/26/2022 20:22:45 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.811998503345363 on epoch=25
05/26/2022 20:22:48 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=25
05/26/2022 20:22:51 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=26
05/26/2022 20:22:53 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 20:22:56 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=26
05/26/2022 20:22:58 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=26
05/26/2022 20:23:47 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7671046633903766 on epoch=26
05/26/2022 20:23:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=26
05/26/2022 20:23:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=26
05/26/2022 20:23:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/26/2022 20:23:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.10 on epoch=26
05/26/2022 20:24:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=26
05/26/2022 20:24:01 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 20:24:01 - INFO - __main__ - Printing 3 examples
05/26/2022 20:24:01 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 20:24:01 - INFO - __main__ - ['Film']
05/26/2022 20:24:01 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 20:24:01 - INFO - __main__ - ['Film']
05/26/2022 20:24:01 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 20:24:01 - INFO - __main__ - ['Film']
05/26/2022 20:24:01 - INFO - __main__ - Tokenizing Input ...
05/26/2022 20:24:02 - INFO - __main__ - Tokenizing Output ...
05/26/2022 20:24:04 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 20:24:04 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 20:24:04 - INFO - __main__ - Printing 3 examples
05/26/2022 20:24:04 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 20:24:04 - INFO - __main__ - ['Film']
05/26/2022 20:24:04 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 20:24:04 - INFO - __main__ - ['Film']
05/26/2022 20:24:04 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 20:24:04 - INFO - __main__ - ['Film']
05/26/2022 20:24:04 - INFO - __main__ - Tokenizing Input ...
05/26/2022 20:24:05 - INFO - __main__ - Tokenizing Output ...
05/26/2022 20:24:06 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 20:24:25 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 20:24:25 - INFO - __main__ - task name: dbpedia_14
05/26/2022 20:24:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 20:24:25 - INFO - __main__ - Starting training!
05/26/2022 20:24:46 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.5810439028846262 on epoch=26
05/26/2022 20:24:46 - INFO - __main__ - save last model!
05/26/2022 20:24:46 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 20:24:46 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 20:24:46 - INFO - __main__ - Printing 3 examples
05/26/2022 20:24:46 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 20:24:46 - INFO - __main__ - ['Animal']
05/26/2022 20:24:46 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 20:24:46 - INFO - __main__ - ['Animal']
05/26/2022 20:24:46 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 20:24:46 - INFO - __main__ - ['Village']
05/26/2022 20:24:46 - INFO - __main__ - Tokenizing Input ...
05/26/2022 20:24:48 - INFO - __main__ - Tokenizing Output ...
05/26/2022 20:24:51 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 20:26:54 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.4_8_predictions.txt
05/26/2022 20:26:54 - INFO - __main__ - Classification-F1 on test data: 0.4950
05/26/2022 20:26:55 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.4, bsz=8, dev_performance=0.8627647806731001, test_performance=0.4950302871981261
05/26/2022 20:26:55 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.3, bsz=8 ...
05/26/2022 20:26:56 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 20:26:56 - INFO - __main__ - Printing 3 examples
05/26/2022 20:26:56 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 20:26:56 - INFO - __main__ - ['Film']
05/26/2022 20:26:56 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 20:26:56 - INFO - __main__ - ['Film']
05/26/2022 20:26:56 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 20:26:56 - INFO - __main__ - ['Film']
05/26/2022 20:26:56 - INFO - __main__ - Tokenizing Input ...
05/26/2022 20:26:57 - INFO - __main__ - Tokenizing Output ...
05/26/2022 20:26:59 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 20:26:59 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 20:26:59 - INFO - __main__ - Printing 3 examples
05/26/2022 20:26:59 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 20:26:59 - INFO - __main__ - ['Film']
05/26/2022 20:26:59 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 20:26:59 - INFO - __main__ - ['Film']
05/26/2022 20:26:59 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 20:26:59 - INFO - __main__ - ['Film']
05/26/2022 20:26:59 - INFO - __main__ - Tokenizing Input ...
05/26/2022 20:26:59 - INFO - __main__ - Tokenizing Output ...
05/26/2022 20:27:01 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 20:27:17 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 20:27:17 - INFO - __main__ - task name: dbpedia_14
05/26/2022 20:27:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 20:27:18 - INFO - __main__ - Starting training!
05/26/2022 20:27:21 - INFO - __main__ - Step 10 Global step 10 Train loss 6.61 on epoch=0
05/26/2022 20:27:24 - INFO - __main__ - Step 20 Global step 20 Train loss 5.87 on epoch=0
05/26/2022 20:27:26 - INFO - __main__ - Step 30 Global step 30 Train loss 4.45 on epoch=0
05/26/2022 20:27:29 - INFO - __main__ - Step 40 Global step 40 Train loss 3.29 on epoch=0
05/26/2022 20:27:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.77 on epoch=0
05/26/2022 20:28:37 - INFO - __main__ - Global step 50 Train loss 4.60 Classification-F1 0.04525265799162889 on epoch=0
05/26/2022 20:28:37 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.04525265799162889 on epoch=0, global_step=50
05/26/2022 20:28:40 - INFO - __main__ - Step 60 Global step 60 Train loss 2.30 on epoch=0
05/26/2022 20:28:43 - INFO - __main__ - Step 70 Global step 70 Train loss 2.03 on epoch=0
05/26/2022 20:28:45 - INFO - __main__ - Step 80 Global step 80 Train loss 1.66 on epoch=0
05/26/2022 20:28:48 - INFO - __main__ - Step 90 Global step 90 Train loss 1.57 on epoch=0
05/26/2022 20:28:50 - INFO - __main__ - Step 100 Global step 100 Train loss 1.27 on epoch=0
05/26/2022 20:30:03 - INFO - __main__ - Global step 100 Train loss 1.77 Classification-F1 0.12536533438314865 on epoch=0
05/26/2022 20:30:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04525265799162889 -> 0.12536533438314865 on epoch=0, global_step=100
05/26/2022 20:30:06 - INFO - __main__ - Step 110 Global step 110 Train loss 1.33 on epoch=0
05/26/2022 20:30:09 - INFO - __main__ - Step 120 Global step 120 Train loss 1.05 on epoch=1
05/26/2022 20:30:11 - INFO - __main__ - Step 130 Global step 130 Train loss 1.10 on epoch=1
05/26/2022 20:30:14 - INFO - __main__ - Step 140 Global step 140 Train loss 1.00 on epoch=1
05/26/2022 20:30:16 - INFO - __main__ - Step 150 Global step 150 Train loss 1.02 on epoch=1
05/26/2022 20:31:15 - INFO - __main__ - Global step 150 Train loss 1.10 Classification-F1 0.2927320242771143 on epoch=1
05/26/2022 20:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.12536533438314865 -> 0.2927320242771143 on epoch=1, global_step=150
05/26/2022 20:31:18 - INFO - __main__ - Step 160 Global step 160 Train loss 1.03 on epoch=1
05/26/2022 20:31:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=1
05/26/2022 20:31:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.76 on epoch=1
05/26/2022 20:31:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.92 on epoch=1
05/26/2022 20:31:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.83 on epoch=1
05/26/2022 20:32:37 - INFO - __main__ - Global step 200 Train loss 0.88 Classification-F1 0.2981146082228981 on epoch=1
05/26/2022 20:32:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2927320242771143 -> 0.2981146082228981 on epoch=1, global_step=200
05/26/2022 20:32:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.79 on epoch=1
05/26/2022 20:32:42 - INFO - __main__ - Step 220 Global step 220 Train loss 0.83 on epoch=1
05/26/2022 20:32:45 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=2
05/26/2022 20:32:47 - INFO - __main__ - Step 240 Global step 240 Train loss 0.68 on epoch=2
05/26/2022 20:32:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.78 on epoch=2
05/26/2022 20:33:58 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.33438242992564365 on epoch=2
05/26/2022 20:33:58 - INFO - __main__ - Saving model with best Classification-F1: 0.2981146082228981 -> 0.33438242992564365 on epoch=2, global_step=250
05/26/2022 20:34:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.77 on epoch=2
05/26/2022 20:34:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=2
05/26/2022 20:34:06 - INFO - __main__ - Step 280 Global step 280 Train loss 0.68 on epoch=2
05/26/2022 20:34:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.63 on epoch=2
05/26/2022 20:34:11 - INFO - __main__ - Step 300 Global step 300 Train loss 0.62 on epoch=2
05/26/2022 20:35:09 - INFO - __main__ - Global step 300 Train loss 0.69 Classification-F1 0.5137183468133861 on epoch=2
05/26/2022 20:35:09 - INFO - __main__ - Saving model with best Classification-F1: 0.33438242992564365 -> 0.5137183468133861 on epoch=2, global_step=300
05/26/2022 20:35:12 - INFO - __main__ - Step 310 Global step 310 Train loss 0.70 on epoch=2
05/26/2022 20:35:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=2
05/26/2022 20:35:17 - INFO - __main__ - Step 330 Global step 330 Train loss 0.65 on epoch=2
05/26/2022 20:35:20 - INFO - __main__ - Step 340 Global step 340 Train loss 0.57 on epoch=3
05/26/2022 20:35:22 - INFO - __main__ - Step 350 Global step 350 Train loss 0.54 on epoch=3
05/26/2022 20:36:26 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.42970534481902 on epoch=3
05/26/2022 20:36:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=3
05/26/2022 20:36:32 - INFO - __main__ - Step 370 Global step 370 Train loss 0.55 on epoch=3
05/26/2022 20:36:34 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=3
05/26/2022 20:36:37 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=3
05/26/2022 20:36:40 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=3
05/26/2022 20:37:46 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.434104149626733 on epoch=3
05/26/2022 20:37:49 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=3
05/26/2022 20:37:51 - INFO - __main__ - Step 420 Global step 420 Train loss 0.57 on epoch=3
05/26/2022 20:37:54 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=3
05/26/2022 20:37:57 - INFO - __main__ - Step 440 Global step 440 Train loss 0.52 on epoch=3
05/26/2022 20:37:59 - INFO - __main__ - Step 450 Global step 450 Train loss 0.52 on epoch=4
05/26/2022 20:39:03 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.4014633294238126 on epoch=4
05/26/2022 20:39:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=4
05/26/2022 20:39:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=4
05/26/2022 20:39:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=4
05/26/2022 20:39:14 - INFO - __main__ - Step 490 Global step 490 Train loss 0.45 on epoch=4
05/26/2022 20:39:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=4
05/26/2022 20:40:07 - INFO - __main__ - Global step 500 Train loss 0.42 Classification-F1 0.4206766953110703 on epoch=4
05/26/2022 20:40:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=4
05/26/2022 20:40:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.36 on epoch=4
05/26/2022 20:40:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=4
05/26/2022 20:40:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.38 on epoch=4
05/26/2022 20:40:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=4
05/26/2022 20:41:23 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.42255247480933267 on epoch=4
05/26/2022 20:41:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.28 on epoch=4
05/26/2022 20:41:28 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=5
05/26/2022 20:41:31 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=5
05/26/2022 20:41:33 - INFO - __main__ - Step 590 Global step 590 Train loss 0.29 on epoch=5
05/26/2022 20:41:36 - INFO - __main__ - Step 600 Global step 600 Train loss 0.28 on epoch=5
05/26/2022 20:42:29 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.5297024734177388 on epoch=5
05/26/2022 20:42:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5137183468133861 -> 0.5297024734177388 on epoch=5, global_step=600
05/26/2022 20:42:32 - INFO - __main__ - Step 610 Global step 610 Train loss 0.22 on epoch=5
05/26/2022 20:42:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=5
05/26/2022 20:42:37 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=5
05/26/2022 20:42:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.33 on epoch=5
05/26/2022 20:42:42 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=5
05/26/2022 20:43:37 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.5849054097467407 on epoch=5
05/26/2022 20:43:37 - INFO - __main__ - Saving model with best Classification-F1: 0.5297024734177388 -> 0.5849054097467407 on epoch=5, global_step=650
05/26/2022 20:43:40 - INFO - __main__ - Step 660 Global step 660 Train loss 0.20 on epoch=5
05/26/2022 20:43:42 - INFO - __main__ - Step 670 Global step 670 Train loss 0.29 on epoch=5
05/26/2022 20:43:45 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=6
05/26/2022 20:43:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=6
05/26/2022 20:43:50 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=6
05/26/2022 20:44:45 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.5013939878395882 on epoch=6
05/26/2022 20:44:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=6
05/26/2022 20:44:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.28 on epoch=6
05/26/2022 20:44:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.20 on epoch=6
05/26/2022 20:44:56 - INFO - __main__ - Step 740 Global step 740 Train loss 0.26 on epoch=6
05/26/2022 20:44:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=6
05/26/2022 20:45:53 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.5873622087596622 on epoch=6
05/26/2022 20:45:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5849054097467407 -> 0.5873622087596622 on epoch=6, global_step=750
05/26/2022 20:45:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.24 on epoch=6
05/26/2022 20:45:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=6
05/26/2022 20:46:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=6
05/26/2022 20:46:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=7
05/26/2022 20:46:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=7
05/26/2022 20:47:00 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.6198667624839315 on epoch=7
05/26/2022 20:47:00 - INFO - __main__ - Saving model with best Classification-F1: 0.5873622087596622 -> 0.6198667624839315 on epoch=7, global_step=800
05/26/2022 20:47:02 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=7
05/26/2022 20:47:05 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=7
05/26/2022 20:47:08 - INFO - __main__ - Step 830 Global step 830 Train loss 0.27 on epoch=7
05/26/2022 20:47:10 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=7
05/26/2022 20:47:13 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=7
05/26/2022 20:48:06 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.6565187936189836 on epoch=7
05/26/2022 20:48:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6198667624839315 -> 0.6565187936189836 on epoch=7, global_step=850
05/26/2022 20:48:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=7
05/26/2022 20:48:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=7
05/26/2022 20:48:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=7
05/26/2022 20:48:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.17 on epoch=7
05/26/2022 20:48:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=8
05/26/2022 20:49:06 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.5246093839243253 on epoch=8
05/26/2022 20:49:09 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=8
05/26/2022 20:49:12 - INFO - __main__ - Step 920 Global step 920 Train loss 0.21 on epoch=8
05/26/2022 20:49:14 - INFO - __main__ - Step 930 Global step 930 Train loss 0.19 on epoch=8
05/26/2022 20:49:17 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=8
05/26/2022 20:49:19 - INFO - __main__ - Step 950 Global step 950 Train loss 0.17 on epoch=8
05/26/2022 20:50:11 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.6330616276705306 on epoch=8
05/26/2022 20:50:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=8
05/26/2022 20:50:16 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=8
05/26/2022 20:50:19 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=8
05/26/2022 20:50:21 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=8
05/26/2022 20:50:24 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=8
05/26/2022 20:51:12 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.5875849386891878 on epoch=8
05/26/2022 20:51:15 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=9
05/26/2022 20:51:18 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.11 on epoch=9
05/26/2022 20:51:20 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.13 on epoch=9
05/26/2022 20:51:23 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=9
05/26/2022 20:51:25 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.20 on epoch=9
05/26/2022 20:52:18 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7342834921518526 on epoch=9
05/26/2022 20:52:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6565187936189836 -> 0.7342834921518526 on epoch=9, global_step=1050
05/26/2022 20:52:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=9
05/26/2022 20:52:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.19 on epoch=9
05/26/2022 20:52:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=9
05/26/2022 20:52:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=9
05/26/2022 20:52:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=9
05/26/2022 20:53:26 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.602362101626505 on epoch=9
05/26/2022 20:53:28 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=9
05/26/2022 20:53:31 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=9
05/26/2022 20:53:34 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=10
05/26/2022 20:53:36 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=10
05/26/2022 20:53:39 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=10
05/26/2022 20:54:30 - INFO - __main__ - Global step 1150 Train loss 0.15 Classification-F1 0.675225840794085 on epoch=10
05/26/2022 20:54:33 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=10
05/26/2022 20:54:36 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.19 on epoch=10
05/26/2022 20:54:38 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=10
05/26/2022 20:54:41 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.15 on epoch=10
05/26/2022 20:54:43 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=10
05/26/2022 20:55:32 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.5858796039716433 on epoch=10
05/26/2022 20:55:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.10 on epoch=10
05/26/2022 20:55:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=10
05/26/2022 20:55:40 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=10
05/26/2022 20:55:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=11
05/26/2022 20:55:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=11
05/26/2022 20:56:37 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7014235364613061 on epoch=11
05/26/2022 20:56:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.14 on epoch=11
05/26/2022 20:56:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=11
05/26/2022 20:56:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=11
05/26/2022 20:56:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=11
05/26/2022 20:56:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=11
05/26/2022 20:57:38 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.6256959894528366 on epoch=11
05/26/2022 20:57:41 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=11
05/26/2022 20:57:43 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=11
05/26/2022 20:57:46 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=11
05/26/2022 20:57:48 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=11
05/26/2022 20:57:51 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=12
05/26/2022 20:58:43 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.6659852935068007 on epoch=12
05/26/2022 20:58:45 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=12
05/26/2022 20:58:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=12
05/26/2022 20:58:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=12
05/26/2022 20:58:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=12
05/26/2022 20:58:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=12
05/26/2022 20:59:43 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.6999396386237414 on epoch=12
05/26/2022 20:59:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.08 on epoch=12
05/26/2022 20:59:48 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.15 on epoch=12
05/26/2022 20:59:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=12
05/26/2022 20:59:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=12
05/26/2022 20:59:56 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=12
05/26/2022 21:00:47 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.6374047093370887 on epoch=12
05/26/2022 21:00:50 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=13
05/26/2022 21:00:52 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=13
05/26/2022 21:00:55 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=13
05/26/2022 21:00:58 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=13
05/26/2022 21:01:00 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=13
05/26/2022 21:01:49 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.5653905899553613 on epoch=13
05/26/2022 21:01:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=13
05/26/2022 21:01:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=13
05/26/2022 21:01:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=13
05/26/2022 21:02:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=13
05/26/2022 21:02:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=13
05/26/2022 21:02:50 - INFO - __main__ - Global step 1550 Train loss 0.09 Classification-F1 0.5681222569048833 on epoch=13
05/26/2022 21:02:53 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=13
05/26/2022 21:02:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=14
05/26/2022 21:02:58 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=14
05/26/2022 21:03:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=14
05/26/2022 21:03:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=14
05/26/2022 21:03:56 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.617615777848729 on epoch=14
05/26/2022 21:03:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=14
05/26/2022 21:04:01 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
05/26/2022 21:04:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.10 on epoch=14
05/26/2022 21:04:06 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=14
05/26/2022 21:04:09 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
05/26/2022 21:04:58 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.6868420690583626 on epoch=14
05/26/2022 21:05:01 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=14
05/26/2022 21:05:04 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=14
05/26/2022 21:05:06 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=14
05/26/2022 21:05:09 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=15
05/26/2022 21:05:11 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=15
05/26/2022 21:06:01 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6635298420840481 on epoch=15
05/26/2022 21:06:03 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=15
05/26/2022 21:06:06 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.10 on epoch=15
05/26/2022 21:06:09 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=15
05/26/2022 21:06:11 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=15
05/26/2022 21:06:14 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.18 on epoch=15
05/26/2022 21:07:05 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.5306984444957835 on epoch=15
05/26/2022 21:07:07 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=15
05/26/2022 21:07:10 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=15
05/26/2022 21:07:13 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=15
05/26/2022 21:07:15 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=15
05/26/2022 21:07:18 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=16
05/26/2022 21:08:07 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.5782102775354615 on epoch=16
05/26/2022 21:08:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=16
05/26/2022 21:08:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/26/2022 21:08:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=16
05/26/2022 21:08:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=16
05/26/2022 21:08:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=16
05/26/2022 21:09:08 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.598441822106804 on epoch=16
05/26/2022 21:09:10 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=16
05/26/2022 21:09:13 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.14 on epoch=16
05/26/2022 21:09:15 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=16
05/26/2022 21:09:18 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=16
05/26/2022 21:09:21 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=16
05/26/2022 21:10:10 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.5884587228474818 on epoch=16
05/26/2022 21:10:13 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.08 on epoch=17
05/26/2022 21:10:16 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
05/26/2022 21:10:18 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=17
05/26/2022 21:10:21 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=17
05/26/2022 21:10:23 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=17
05/26/2022 21:11:13 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.5805033053531141 on epoch=17
05/26/2022 21:11:15 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=17
05/26/2022 21:11:18 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=17
05/26/2022 21:11:20 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/26/2022 21:11:23 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=17
05/26/2022 21:11:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=17
05/26/2022 21:12:15 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.5270800919762823 on epoch=17
05/26/2022 21:12:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=17
05/26/2022 21:12:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=18
05/26/2022 21:12:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=18
05/26/2022 21:12:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=18
05/26/2022 21:12:29 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=18
05/26/2022 21:13:18 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5742722783522353 on epoch=18
05/26/2022 21:13:21 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=18
05/26/2022 21:13:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=18
05/26/2022 21:13:26 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=18
05/26/2022 21:13:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=18
05/26/2022 21:13:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=18
05/26/2022 21:14:18 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.5936251696370879 on epoch=18
05/26/2022 21:14:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=18
05/26/2022 21:14:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=18
05/26/2022 21:14:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/26/2022 21:14:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=19
05/26/2022 21:14:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=19
05/26/2022 21:15:20 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7018416440557892 on epoch=19
05/26/2022 21:15:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=19
05/26/2022 21:15:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.09 on epoch=19
05/26/2022 21:15:28 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.06 on epoch=19
05/26/2022 21:15:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=19
05/26/2022 21:15:33 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/26/2022 21:16:22 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.6243912790831357 on epoch=19
05/26/2022 21:16:24 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=19
05/26/2022 21:16:27 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=19
05/26/2022 21:16:30 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=19
05/26/2022 21:16:32 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=19
05/26/2022 21:16:35 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=20
05/26/2022 21:17:23 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6498963764855621 on epoch=20
05/26/2022 21:17:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=20
05/26/2022 21:17:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=20
05/26/2022 21:17:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=20
05/26/2022 21:17:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=20
05/26/2022 21:17:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=20
05/26/2022 21:18:23 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.5738914714142752 on epoch=20
05/26/2022 21:18:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=20
05/26/2022 21:18:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=20
05/26/2022 21:18:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=20
05/26/2022 21:18:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=20
05/26/2022 21:18:36 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/26/2022 21:19:24 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6744271976369065 on epoch=20
05/26/2022 21:19:26 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=21
05/26/2022 21:19:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=21
05/26/2022 21:19:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=21
05/26/2022 21:19:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=21
05/26/2022 21:19:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=21
05/26/2022 21:20:26 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7437572191239477 on epoch=21
05/26/2022 21:20:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7342834921518526 -> 0.7437572191239477 on epoch=21, global_step=2400
05/26/2022 21:20:29 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=21
05/26/2022 21:20:31 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=21
05/26/2022 21:20:34 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/26/2022 21:20:36 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=21
05/26/2022 21:20:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=21
05/26/2022 21:21:27 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6487486416347388 on epoch=21
05/26/2022 21:21:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.12 on epoch=21
05/26/2022 21:21:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.05 on epoch=22
05/26/2022 21:21:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=22
05/26/2022 21:21:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=22
05/26/2022 21:21:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=22
05/26/2022 21:22:28 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.43352188693470545 on epoch=22
05/26/2022 21:22:31 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=22
05/26/2022 21:22:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=22
05/26/2022 21:22:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=22
05/26/2022 21:22:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=22
05/26/2022 21:22:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=22
05/26/2022 21:23:29 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.5353549212375482 on epoch=22
05/26/2022 21:23:31 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
05/26/2022 21:23:34 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=22
05/26/2022 21:23:36 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=23
05/26/2022 21:23:39 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=23
05/26/2022 21:23:42 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=23
05/26/2022 21:24:28 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.5854115225633099 on epoch=23
05/26/2022 21:24:31 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=23
05/26/2022 21:24:33 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=23
05/26/2022 21:24:36 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=23
05/26/2022 21:24:39 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=23
05/26/2022 21:24:41 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=23
05/26/2022 21:25:27 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.5971976195938818 on epoch=23
05/26/2022 21:25:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=23
05/26/2022 21:25:33 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=23
05/26/2022 21:25:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
05/26/2022 21:25:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
05/26/2022 21:25:41 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=24
05/26/2022 21:26:26 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.5887194458961177 on epoch=24
05/26/2022 21:26:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=24
05/26/2022 21:26:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.08 on epoch=24
05/26/2022 21:26:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=24
05/26/2022 21:26:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=24
05/26/2022 21:26:40 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=24
05/26/2022 21:27:27 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.6270248944757603 on epoch=24
05/26/2022 21:27:30 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=24
05/26/2022 21:27:32 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=24
05/26/2022 21:27:35 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=24
05/26/2022 21:27:38 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=24
05/26/2022 21:27:40 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=24
05/26/2022 21:28:27 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.5729948608419057 on epoch=24
05/26/2022 21:28:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=25
05/26/2022 21:28:32 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=25
05/26/2022 21:28:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=25
05/26/2022 21:28:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=25
05/26/2022 21:28:40 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=25
05/26/2022 21:29:26 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.6061960064080729 on epoch=25
05/26/2022 21:29:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=25
05/26/2022 21:29:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=25
05/26/2022 21:29:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=25
05/26/2022 21:29:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=25
05/26/2022 21:29:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=25
05/26/2022 21:30:25 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.49533503053807987 on epoch=25
05/26/2022 21:30:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=25
05/26/2022 21:30:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.11 on epoch=26
05/26/2022 21:30:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=26
05/26/2022 21:30:36 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=26
05/26/2022 21:30:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=26
05/26/2022 21:31:25 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.5401759230119911 on epoch=26
05/26/2022 21:31:28 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.08 on epoch=26
05/26/2022 21:31:31 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 21:31:33 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=26
05/26/2022 21:31:36 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=26
05/26/2022 21:31:39 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=26
05/26/2022 21:31:40 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 21:31:40 - INFO - __main__ - Printing 3 examples
05/26/2022 21:31:40 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 21:31:40 - INFO - __main__ - ['Film']
05/26/2022 21:31:40 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 21:31:40 - INFO - __main__ - ['Film']
05/26/2022 21:31:40 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 21:31:40 - INFO - __main__ - ['Film']
05/26/2022 21:31:40 - INFO - __main__ - Tokenizing Input ...
05/26/2022 21:31:41 - INFO - __main__ - Tokenizing Output ...
05/26/2022 21:31:43 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 21:31:43 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 21:31:43 - INFO - __main__ - Printing 3 examples
05/26/2022 21:31:43 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 21:31:43 - INFO - __main__ - ['Film']
05/26/2022 21:31:43 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 21:31:43 - INFO - __main__ - ['Film']
05/26/2022 21:31:43 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 21:31:43 - INFO - __main__ - ['Film']
05/26/2022 21:31:43 - INFO - __main__ - Tokenizing Input ...
05/26/2022 21:31:43 - INFO - __main__ - Tokenizing Output ...
05/26/2022 21:31:45 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 21:32:02 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 21:32:02 - INFO - __main__ - task name: dbpedia_14
05/26/2022 21:32:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 21:32:03 - INFO - __main__ - Starting training!
05/26/2022 21:32:26 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.5627497513020401 on epoch=26
05/26/2022 21:32:26 - INFO - __main__ - save last model!
05/26/2022 21:32:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 21:32:26 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 21:32:26 - INFO - __main__ - Printing 3 examples
05/26/2022 21:32:26 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 21:32:26 - INFO - __main__ - ['Animal']
05/26/2022 21:32:26 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 21:32:26 - INFO - __main__ - ['Animal']
05/26/2022 21:32:26 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 21:32:26 - INFO - __main__ - ['Village']
05/26/2022 21:32:26 - INFO - __main__ - Tokenizing Input ...
05/26/2022 21:32:28 - INFO - __main__ - Tokenizing Output ...
05/26/2022 21:32:31 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 21:34:27 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.3_8_predictions.txt
05/26/2022 21:34:27 - INFO - __main__ - Classification-F1 on test data: 0.5385
05/26/2022 21:34:28 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.3, bsz=8, dev_performance=0.7437572191239477, test_performance=0.5384642091144732
05/26/2022 21:34:28 - INFO - __main__ - Running ... prefix=dbpedia_14_128_87, lr=0.2, bsz=8 ...
05/26/2022 21:34:29 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 21:34:29 - INFO - __main__ - Printing 3 examples
05/26/2022 21:34:29 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/26/2022 21:34:29 - INFO - __main__ - ['Film']
05/26/2022 21:34:29 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/26/2022 21:34:29 - INFO - __main__ - ['Film']
05/26/2022 21:34:29 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/26/2022 21:34:29 - INFO - __main__ - ['Film']
05/26/2022 21:34:29 - INFO - __main__ - Tokenizing Input ...
05/26/2022 21:34:30 - INFO - __main__ - Tokenizing Output ...
05/26/2022 21:34:31 - INFO - __main__ - Loaded 1792 examples from train data
05/26/2022 21:34:31 - INFO - __main__ - Start tokenizing ... 1792 instances
05/26/2022 21:34:31 - INFO - __main__ - Printing 3 examples
05/26/2022 21:34:31 - INFO - __main__ -  [dbpedia_14] The Debt is a 2011 American/British drama-thriller film directed by John Madden from a screenplay by Matthew Vaughn Jane Goldman and Peter Straughan. It stars Helen Mirren Sam Worthington Jessica Chastain Ciarán Hinds Tom Wilkinson Marton Csokas and Jesper Christensen. It's a remake of the 2007 Israeli film Ha-Hov directed by Assaf BernsteinOriginally scheduled for a December 2010 release the film was released in the United States on August 31 2011.
05/26/2022 21:34:31 - INFO - __main__ - ['Film']
05/26/2022 21:34:31 - INFO - __main__ -  [dbpedia_14] Naga Bonar Jadi 2 (Naga Bonar Becomes 2) is 2007 comedy film directed by Deddy Mizwar. It is starring Deddy Mizwar Tora Sudiro Lukman Sardi Darius Sinathrya and Michael Muliardo. It is a sequel to the Indonesian film Nagabonar (1987).
05/26/2022 21:34:31 - INFO - __main__ - ['Film']
05/26/2022 21:34:31 - INFO - __main__ -  [dbpedia_14] La Garce is a 1984 French thriller film directed by Christine Pascal and starring Isabelle Huppert.
05/26/2022 21:34:31 - INFO - __main__ - ['Film']
05/26/2022 21:34:31 - INFO - __main__ - Tokenizing Input ...
05/26/2022 21:34:32 - INFO - __main__ - Tokenizing Output ...
05/26/2022 21:34:34 - INFO - __main__ - Loaded 1792 examples from dev data
05/26/2022 21:34:49 - INFO - __main__ - try to initialize prompt embeddings
05/26/2022 21:34:49 - INFO - __main__ - task name: dbpedia_14
05/26/2022 21:34:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/26/2022 21:34:50 - INFO - __main__ - Starting training!
05/26/2022 21:34:53 - INFO - __main__ - Step 10 Global step 10 Train loss 6.75 on epoch=0
05/26/2022 21:34:56 - INFO - __main__ - Step 20 Global step 20 Train loss 6.43 on epoch=0
05/26/2022 21:34:58 - INFO - __main__ - Step 30 Global step 30 Train loss 5.73 on epoch=0
05/26/2022 21:35:01 - INFO - __main__ - Step 40 Global step 40 Train loss 4.97 on epoch=0
05/26/2022 21:35:04 - INFO - __main__ - Step 50 Global step 50 Train loss 4.42 on epoch=0
05/26/2022 21:41:03 - INFO - __main__ - Global step 50 Train loss 5.66 Classification-F1 0.00010984717470153771 on epoch=0
05/26/2022 21:41:03 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.00010984717470153771 on epoch=0, global_step=50
05/26/2022 21:41:06 - INFO - __main__ - Step 60 Global step 60 Train loss 3.68 on epoch=0
05/26/2022 21:41:08 - INFO - __main__ - Step 70 Global step 70 Train loss 3.15 on epoch=0
05/26/2022 21:41:11 - INFO - __main__ - Step 80 Global step 80 Train loss 2.77 on epoch=0
05/26/2022 21:41:13 - INFO - __main__ - Step 90 Global step 90 Train loss 2.28 on epoch=0
05/26/2022 21:41:16 - INFO - __main__ - Step 100 Global step 100 Train loss 2.09 on epoch=0
05/26/2022 21:42:11 - INFO - __main__ - Global step 100 Train loss 2.79 Classification-F1 0.08830286413575396 on epoch=0
05/26/2022 21:42:11 - INFO - __main__ - Saving model with best Classification-F1: 0.00010984717470153771 -> 0.08830286413575396 on epoch=0, global_step=100
05/26/2022 21:42:14 - INFO - __main__ - Step 110 Global step 110 Train loss 1.88 on epoch=0
05/26/2022 21:42:16 - INFO - __main__ - Step 120 Global step 120 Train loss 1.60 on epoch=1
05/26/2022 21:42:19 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=1
05/26/2022 21:42:21 - INFO - __main__ - Step 140 Global step 140 Train loss 1.46 on epoch=1
05/26/2022 21:42:24 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=1
05/26/2022 21:43:18 - INFO - __main__ - Global step 150 Train loss 1.58 Classification-F1 0.19205482908173938 on epoch=1
05/26/2022 21:43:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08830286413575396 -> 0.19205482908173938 on epoch=1, global_step=150
05/26/2022 21:43:21 - INFO - __main__ - Step 160 Global step 160 Train loss 1.44 on epoch=1
05/26/2022 21:43:23 - INFO - __main__ - Step 170 Global step 170 Train loss 1.23 on epoch=1
05/26/2022 21:43:26 - INFO - __main__ - Step 180 Global step 180 Train loss 1.21 on epoch=1
05/26/2022 21:43:29 - INFO - __main__ - Step 190 Global step 190 Train loss 1.12 on epoch=1
05/26/2022 21:43:31 - INFO - __main__ - Step 200 Global step 200 Train loss 1.11 on epoch=1
05/26/2022 21:44:23 - INFO - __main__ - Global step 200 Train loss 1.22 Classification-F1 0.2177655874222914 on epoch=1
05/26/2022 21:44:23 - INFO - __main__ - Saving model with best Classification-F1: 0.19205482908173938 -> 0.2177655874222914 on epoch=1, global_step=200
05/26/2022 21:44:26 - INFO - __main__ - Step 210 Global step 210 Train loss 1.03 on epoch=1
05/26/2022 21:44:29 - INFO - __main__ - Step 220 Global step 220 Train loss 1.03 on epoch=1
05/26/2022 21:44:31 - INFO - __main__ - Step 230 Global step 230 Train loss 0.95 on epoch=2
05/26/2022 21:44:34 - INFO - __main__ - Step 240 Global step 240 Train loss 0.79 on epoch=2
05/26/2022 21:44:36 - INFO - __main__ - Step 250 Global step 250 Train loss 0.87 on epoch=2
05/26/2022 21:45:26 - INFO - __main__ - Global step 250 Train loss 0.93 Classification-F1 0.23320097667622605 on epoch=2
05/26/2022 21:45:26 - INFO - __main__ - Saving model with best Classification-F1: 0.2177655874222914 -> 0.23320097667622605 on epoch=2, global_step=250
05/26/2022 21:45:28 - INFO - __main__ - Step 260 Global step 260 Train loss 1.00 on epoch=2
05/26/2022 21:45:31 - INFO - __main__ - Step 270 Global step 270 Train loss 0.88 on epoch=2
05/26/2022 21:45:33 - INFO - __main__ - Step 280 Global step 280 Train loss 0.81 on epoch=2
05/26/2022 21:45:36 - INFO - __main__ - Step 290 Global step 290 Train loss 0.74 on epoch=2
05/26/2022 21:45:39 - INFO - __main__ - Step 300 Global step 300 Train loss 0.83 on epoch=2
05/26/2022 21:46:32 - INFO - __main__ - Global step 300 Train loss 0.85 Classification-F1 0.29227355913526865 on epoch=2
05/26/2022 21:46:32 - INFO - __main__ - Saving model with best Classification-F1: 0.23320097667622605 -> 0.29227355913526865 on epoch=2, global_step=300
05/26/2022 21:46:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.87 on epoch=2
05/26/2022 21:46:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.74 on epoch=2
05/26/2022 21:46:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.75 on epoch=2
05/26/2022 21:46:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.78 on epoch=3
05/26/2022 21:46:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.66 on epoch=3
05/26/2022 21:47:41 - INFO - __main__ - Global step 350 Train loss 0.76 Classification-F1 0.3602103855995491 on epoch=3
05/26/2022 21:47:41 - INFO - __main__ - Saving model with best Classification-F1: 0.29227355913526865 -> 0.3602103855995491 on epoch=3, global_step=350
05/26/2022 21:47:44 - INFO - __main__ - Step 360 Global step 360 Train loss 0.70 on epoch=3
05/26/2022 21:47:47 - INFO - __main__ - Step 370 Global step 370 Train loss 0.70 on epoch=3
05/26/2022 21:47:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.71 on epoch=3
05/26/2022 21:47:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.72 on epoch=3
05/26/2022 21:47:54 - INFO - __main__ - Step 400 Global step 400 Train loss 0.64 on epoch=3
05/26/2022 21:48:51 - INFO - __main__ - Global step 400 Train loss 0.69 Classification-F1 0.4469453956487845 on epoch=3
05/26/2022 21:48:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3602103855995491 -> 0.4469453956487845 on epoch=3, global_step=400
05/26/2022 21:48:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.59 on epoch=3
05/26/2022 21:48:56 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=3
05/26/2022 21:48:59 - INFO - __main__ - Step 430 Global step 430 Train loss 0.64 on epoch=3
05/26/2022 21:49:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.63 on epoch=3
05/26/2022 21:49:04 - INFO - __main__ - Step 450 Global step 450 Train loss 0.64 on epoch=4
05/26/2022 21:49:56 - INFO - __main__ - Global step 450 Train loss 0.62 Classification-F1 0.4340839164013179 on epoch=4
05/26/2022 21:49:59 - INFO - __main__ - Step 460 Global step 460 Train loss 0.55 on epoch=4
05/26/2022 21:50:02 - INFO - __main__ - Step 470 Global step 470 Train loss 0.56 on epoch=4
05/26/2022 21:50:04 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=4
05/26/2022 21:50:07 - INFO - __main__ - Step 490 Global step 490 Train loss 0.52 on epoch=4
05/26/2022 21:50:09 - INFO - __main__ - Step 500 Global step 500 Train loss 0.58 on epoch=4
05/26/2022 21:50:59 - INFO - __main__ - Global step 500 Train loss 0.55 Classification-F1 0.4907532006214128 on epoch=4
05/26/2022 21:50:59 - INFO - __main__ - Saving model with best Classification-F1: 0.4469453956487845 -> 0.4907532006214128 on epoch=4, global_step=500
05/26/2022 21:51:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.52 on epoch=4
05/26/2022 21:51:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=4
05/26/2022 21:51:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=4
05/26/2022 21:51:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=4
05/26/2022 21:51:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=4
05/26/2022 21:52:05 - INFO - __main__ - Global step 550 Train loss 0.52 Classification-F1 0.5032621640506572 on epoch=4
05/26/2022 21:52:05 - INFO - __main__ - Saving model with best Classification-F1: 0.4907532006214128 -> 0.5032621640506572 on epoch=4, global_step=550
05/26/2022 21:52:07 - INFO - __main__ - Step 560 Global step 560 Train loss 0.58 on epoch=4
05/26/2022 21:52:10 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=5
05/26/2022 21:52:12 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=5
05/26/2022 21:52:15 - INFO - __main__ - Step 590 Global step 590 Train loss 0.49 on epoch=5
05/26/2022 21:52:18 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=5
05/26/2022 21:53:12 - INFO - __main__ - Global step 600 Train loss 0.45 Classification-F1 0.3336145609834217 on epoch=5
05/26/2022 21:53:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.48 on epoch=5
05/26/2022 21:53:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.46 on epoch=5
05/26/2022 21:53:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.46 on epoch=5
05/26/2022 21:53:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.49 on epoch=5
05/26/2022 21:53:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.42 on epoch=5
05/26/2022 21:54:20 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.34100243618081605 on epoch=5
05/26/2022 21:54:23 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=5
05/26/2022 21:54:25 - INFO - __main__ - Step 670 Global step 670 Train loss 0.47 on epoch=5
05/26/2022 21:54:28 - INFO - __main__ - Step 680 Global step 680 Train loss 0.48 on epoch=6
05/26/2022 21:54:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=6
05/26/2022 21:54:33 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=6
05/26/2022 21:55:26 - INFO - __main__ - Global step 700 Train loss 0.45 Classification-F1 0.44345588806561154 on epoch=6
05/26/2022 21:55:28 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=6
05/26/2022 21:55:31 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=6
05/26/2022 21:55:33 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=6
05/26/2022 21:55:36 - INFO - __main__ - Step 740 Global step 740 Train loss 0.35 on epoch=6
05/26/2022 21:55:38 - INFO - __main__ - Step 750 Global step 750 Train loss 0.43 on epoch=6
05/26/2022 21:56:32 - INFO - __main__ - Global step 750 Train loss 0.36 Classification-F1 0.3408891387913822 on epoch=6
05/26/2022 21:56:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.32 on epoch=6
05/26/2022 21:56:38 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=6
05/26/2022 21:56:40 - INFO - __main__ - Step 780 Global step 780 Train loss 0.37 on epoch=6
05/26/2022 21:56:43 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=7
05/26/2022 21:56:45 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=7
05/26/2022 21:57:43 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.4369758655377497 on epoch=7
05/26/2022 21:57:45 - INFO - __main__ - Step 810 Global step 810 Train loss 0.37 on epoch=7
05/26/2022 21:57:48 - INFO - __main__ - Step 820 Global step 820 Train loss 0.35 on epoch=7
05/26/2022 21:57:50 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=7
05/26/2022 21:57:53 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=7
05/26/2022 21:57:56 - INFO - __main__ - Step 850 Global step 850 Train loss 0.25 on epoch=7
05/26/2022 21:58:52 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.5032414280493316 on epoch=7
05/26/2022 21:58:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=7
05/26/2022 21:58:57 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=7
05/26/2022 21:59:00 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=7
05/26/2022 21:59:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=7
05/26/2022 21:59:05 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=8
05/26/2022 22:00:01 - INFO - __main__ - Global step 900 Train loss 0.28 Classification-F1 0.40073183843330573 on epoch=8
05/26/2022 22:00:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=8
05/26/2022 22:00:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=8
05/26/2022 22:00:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=8
05/26/2022 22:00:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=8
05/26/2022 22:00:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.19 on epoch=8
05/26/2022 22:01:08 - INFO - __main__ - Global step 950 Train loss 0.23 Classification-F1 0.5040675693138014 on epoch=8
05/26/2022 22:01:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5032621640506572 -> 0.5040675693138014 on epoch=8, global_step=950
05/26/2022 22:01:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.32 on epoch=8
05/26/2022 22:01:13 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=8
05/26/2022 22:01:16 - INFO - __main__ - Step 980 Global step 980 Train loss 0.20 on epoch=8
05/26/2022 22:01:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=8
05/26/2022 22:01:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.16 on epoch=8
05/26/2022 22:02:13 - INFO - __main__ - Global step 1000 Train loss 0.23 Classification-F1 0.6297389070995907 on epoch=8
05/26/2022 22:02:13 - INFO - __main__ - Saving model with best Classification-F1: 0.5040675693138014 -> 0.6297389070995907 on epoch=8, global_step=1000
05/26/2022 22:02:16 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.30 on epoch=9
05/26/2022 22:02:19 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=9
05/26/2022 22:02:21 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.22 on epoch=9
05/26/2022 22:02:24 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.22 on epoch=9
05/26/2022 22:02:26 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=9
05/26/2022 22:03:21 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.6588534201672844 on epoch=9
05/26/2022 22:03:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6297389070995907 -> 0.6588534201672844 on epoch=9, global_step=1050
05/26/2022 22:03:23 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=9
05/26/2022 22:03:26 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=9
05/26/2022 22:03:28 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=9
05/26/2022 22:03:31 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.24 on epoch=9
05/26/2022 22:03:33 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=9
05/26/2022 22:04:29 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7522753770588412 on epoch=9
05/26/2022 22:04:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6588534201672844 -> 0.7522753770588412 on epoch=9, global_step=1100
05/26/2022 22:04:32 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=9
05/26/2022 22:04:34 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.21 on epoch=9
05/26/2022 22:04:37 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=10
05/26/2022 22:04:40 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=10
05/26/2022 22:04:42 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=10
05/26/2022 22:05:34 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.6976415169016734 on epoch=10
05/26/2022 22:05:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.21 on epoch=10
05/26/2022 22:05:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=10
05/26/2022 22:05:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=10
05/26/2022 22:05:45 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=10
05/26/2022 22:05:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=10
05/26/2022 22:06:39 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.659362781840916 on epoch=10
05/26/2022 22:06:41 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=10
05/26/2022 22:06:44 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.18 on epoch=10
05/26/2022 22:06:46 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=10
05/26/2022 22:06:49 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=11
05/26/2022 22:06:52 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=11
05/26/2022 22:07:46 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.7107951178809253 on epoch=11
05/26/2022 22:07:49 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=11
05/26/2022 22:07:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=11
05/26/2022 22:07:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.16 on epoch=11
05/26/2022 22:07:57 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.17 on epoch=11
05/26/2022 22:07:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=11
05/26/2022 22:08:51 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.7972507336194734 on epoch=11
05/26/2022 22:08:51 - INFO - __main__ - Saving model with best Classification-F1: 0.7522753770588412 -> 0.7972507336194734 on epoch=11, global_step=1300
05/26/2022 22:08:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.18 on epoch=11
05/26/2022 22:08:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=11
05/26/2022 22:08:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=11
05/26/2022 22:09:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=11
05/26/2022 22:09:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.10 on epoch=12
05/26/2022 22:09:58 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.5853510797486967 on epoch=12
05/26/2022 22:10:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=12
05/26/2022 22:10:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=12
05/26/2022 22:10:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=12
05/26/2022 22:10:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.20 on epoch=12
05/26/2022 22:10:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=12
05/26/2022 22:11:04 - INFO - __main__ - Global step 1400 Train loss 0.13 Classification-F1 0.6414180896306493 on epoch=12
05/26/2022 22:11:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.17 on epoch=12
05/26/2022 22:11:09 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=12
05/26/2022 22:11:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.15 on epoch=12
05/26/2022 22:11:14 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.10 on epoch=12
05/26/2022 22:11:17 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.16 on epoch=12
05/26/2022 22:12:09 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.7560559284240853 on epoch=12
05/26/2022 22:12:11 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=13
05/26/2022 22:12:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=13
05/26/2022 22:12:16 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.22 on epoch=13
05/26/2022 22:12:19 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.19 on epoch=13
05/26/2022 22:12:21 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=13
05/26/2022 22:13:14 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.7578185018565496 on epoch=13
05/26/2022 22:13:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=13
05/26/2022 22:13:20 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.13 on epoch=13
05/26/2022 22:13:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=13
05/26/2022 22:13:25 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=13
05/26/2022 22:13:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=13
05/26/2022 22:14:20 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.7037000648259714 on epoch=13
05/26/2022 22:14:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=13
05/26/2022 22:14:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.14 on epoch=14
05/26/2022 22:14:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.10 on epoch=14
05/26/2022 22:14:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=14
05/26/2022 22:14:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=14
05/26/2022 22:15:24 - INFO - __main__ - Global step 1600 Train loss 0.13 Classification-F1 0.8568395076753128 on epoch=14
05/26/2022 22:15:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7972507336194734 -> 0.8568395076753128 on epoch=14, global_step=1600
05/26/2022 22:15:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=14
05/26/2022 22:15:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=14
05/26/2022 22:15:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.09 on epoch=14
05/26/2022 22:15:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=14
05/26/2022 22:15:37 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=14
05/26/2022 22:16:28 - INFO - __main__ - Global step 1650 Train loss 0.11 Classification-F1 0.7445925991822224 on epoch=14
05/26/2022 22:16:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=14
05/26/2022 22:16:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.12 on epoch=14
05/26/2022 22:16:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=14
05/26/2022 22:16:39 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=15
05/26/2022 22:16:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=15
05/26/2022 22:17:30 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.753041292196481 on epoch=15
05/26/2022 22:17:33 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=15
05/26/2022 22:17:36 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=15
05/26/2022 22:17:38 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=15
05/26/2022 22:17:41 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=15
05/26/2022 22:17:43 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.09 on epoch=15
05/26/2022 22:18:32 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7476237755832592 on epoch=15
05/26/2022 22:18:34 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=15
05/26/2022 22:18:37 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.07 on epoch=15
05/26/2022 22:18:39 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=15
05/26/2022 22:18:42 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.17 on epoch=15
05/26/2022 22:18:45 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=16
05/26/2022 22:19:34 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.9102147549694419 on epoch=16
05/26/2022 22:19:34 - INFO - __main__ - Saving model with best Classification-F1: 0.8568395076753128 -> 0.9102147549694419 on epoch=16, global_step=1800
05/26/2022 22:19:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=16
05/26/2022 22:19:40 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=16
05/26/2022 22:19:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=16
05/26/2022 22:19:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.12 on epoch=16
05/26/2022 22:19:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=16
05/26/2022 22:20:37 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8416927981677158 on epoch=16
05/26/2022 22:20:40 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=16
05/26/2022 22:20:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=16
05/26/2022 22:20:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=16
05/26/2022 22:20:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=16
05/26/2022 22:20:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=16
05/26/2022 22:21:40 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.8598930635772547 on epoch=16
05/26/2022 22:21:43 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=17
05/26/2022 22:21:45 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=17
05/26/2022 22:21:48 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=17
05/26/2022 22:21:50 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=17
05/26/2022 22:21:53 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.14 on epoch=17
05/26/2022 22:22:42 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.8441605643700139 on epoch=17
05/26/2022 22:22:45 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=17
05/26/2022 22:22:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=17
05/26/2022 22:22:50 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=17
05/26/2022 22:22:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=17
05/26/2022 22:22:55 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=17
05/26/2022 22:23:45 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.897070046613133 on epoch=17
05/26/2022 22:23:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=17
05/26/2022 22:23:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.08 on epoch=18
05/26/2022 22:23:52 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=18
05/26/2022 22:23:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=18
05/26/2022 22:23:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.14 on epoch=18
05/26/2022 22:24:47 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.9044369127744691 on epoch=18
05/26/2022 22:24:50 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=18
05/26/2022 22:24:52 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=18
05/26/2022 22:24:55 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=18
05/26/2022 22:24:57 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=18
05/26/2022 22:25:00 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=18
05/26/2022 22:25:49 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.7885372532914925 on epoch=18
05/26/2022 22:25:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.13 on epoch=18
05/26/2022 22:25:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=18
05/26/2022 22:25:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=19
05/26/2022 22:25:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=19
05/26/2022 22:26:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=19
05/26/2022 22:26:50 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7999327089557472 on epoch=19
05/26/2022 22:26:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=19
05/26/2022 22:26:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=19
05/26/2022 22:26:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=19
05/26/2022 22:27:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=19
05/26/2022 22:27:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=19
05/26/2022 22:27:55 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.8020690790840751 on epoch=19
05/26/2022 22:27:58 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=19
05/26/2022 22:28:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=19
05/26/2022 22:28:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=19
05/26/2022 22:28:06 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=19
05/26/2022 22:28:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=20
05/26/2022 22:28:59 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7631275025223192 on epoch=20
05/26/2022 22:29:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=20
05/26/2022 22:29:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=20
05/26/2022 22:29:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=20
05/26/2022 22:29:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=20
05/26/2022 22:29:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=20
05/26/2022 22:30:01 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7485509711677117 on epoch=20
05/26/2022 22:30:03 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=20
05/26/2022 22:30:06 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.13 on epoch=20
05/26/2022 22:30:09 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=20
05/26/2022 22:30:11 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=20
05/26/2022 22:30:14 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=20
05/26/2022 22:31:03 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.8599524123631002 on epoch=20
05/26/2022 22:31:06 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=21
05/26/2022 22:31:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=21
05/26/2022 22:31:11 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.16 on epoch=21
05/26/2022 22:31:14 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=21
05/26/2022 22:31:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.13 on epoch=21
05/26/2022 22:32:06 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.9070350314153599 on epoch=21
05/26/2022 22:32:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=21
05/26/2022 22:32:11 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=21
05/26/2022 22:32:14 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=21
05/26/2022 22:32:16 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=21
05/26/2022 22:32:19 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=21
05/26/2022 22:33:07 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8562279013881418 on epoch=21
05/26/2022 22:33:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=21
05/26/2022 22:33:13 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=22
05/26/2022 22:33:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=22
05/26/2022 22:33:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.06 on epoch=22
05/26/2022 22:33:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=22
05/26/2022 22:34:09 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.9122476411661563 on epoch=22
05/26/2022 22:34:09 - INFO - __main__ - Saving model with best Classification-F1: 0.9102147549694419 -> 0.9122476411661563 on epoch=22, global_step=2500
05/26/2022 22:34:12 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.11 on epoch=22
05/26/2022 22:34:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=22
05/26/2022 22:34:17 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=22
05/26/2022 22:34:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=22
05/26/2022 22:34:22 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=22
05/26/2022 22:35:11 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.9143480822502869 on epoch=22
05/26/2022 22:35:11 - INFO - __main__ - Saving model with best Classification-F1: 0.9122476411661563 -> 0.9143480822502869 on epoch=22, global_step=2550
05/26/2022 22:35:14 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=22
05/26/2022 22:35:16 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.14 on epoch=22
05/26/2022 22:35:19 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.10 on epoch=23
05/26/2022 22:35:22 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=23
05/26/2022 22:35:24 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=23
05/26/2022 22:36:14 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.7581532654451035 on epoch=23
05/26/2022 22:36:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=23
05/26/2022 22:36:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=23
05/26/2022 22:36:22 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=23
05/26/2022 22:36:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=23
05/26/2022 22:36:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=23
05/26/2022 22:37:16 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.8002612384893067 on epoch=23
05/26/2022 22:37:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=23
05/26/2022 22:37:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=23
05/26/2022 22:37:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=23
05/26/2022 22:37:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=24
05/26/2022 22:37:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=24
05/26/2022 22:38:19 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.804307484917037 on epoch=24
05/26/2022 22:38:22 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=24
05/26/2022 22:38:24 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=24
05/26/2022 22:38:27 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=24
05/26/2022 22:38:30 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=24
05/26/2022 22:38:32 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=24
05/26/2022 22:39:21 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.848516615679225 on epoch=24
05/26/2022 22:39:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=24
05/26/2022 22:39:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=24
05/26/2022 22:39:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=24
05/26/2022 22:39:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=24
05/26/2022 22:39:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=24
05/26/2022 22:40:23 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9186512510960761 on epoch=24
05/26/2022 22:40:23 - INFO - __main__ - Saving model with best Classification-F1: 0.9143480822502869 -> 0.9186512510960761 on epoch=24, global_step=2800
05/26/2022 22:40:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=25
05/26/2022 22:40:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=25
05/26/2022 22:40:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=25
05/26/2022 22:40:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.07 on epoch=25
05/26/2022 22:40:36 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=25
05/26/2022 22:41:27 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.8082687848034901 on epoch=25
05/26/2022 22:41:29 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=25
05/26/2022 22:41:32 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=25
05/26/2022 22:41:34 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=25
05/26/2022 22:41:37 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=25
05/26/2022 22:41:40 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=25
05/26/2022 22:42:29 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.8033382556219375 on epoch=25
05/26/2022 22:42:32 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.11 on epoch=25
05/26/2022 22:42:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=26
05/26/2022 22:42:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=26
05/26/2022 22:42:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=26
05/26/2022 22:42:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=26
05/26/2022 22:43:32 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.9167398568047066 on epoch=26
05/26/2022 22:43:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=26
05/26/2022 22:43:37 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=26
05/26/2022 22:43:39 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=26
05/26/2022 22:43:42 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=26
05/26/2022 22:43:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.07 on epoch=26
05/26/2022 22:44:33 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.8544041297813194 on epoch=26
05/26/2022 22:44:33 - INFO - __main__ - save last model!
05/26/2022 22:44:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/26/2022 22:44:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/26/2022 22:44:33 - INFO - __main__ - Printing 3 examples
05/26/2022 22:44:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/26/2022 22:44:33 - INFO - __main__ - ['Animal']
05/26/2022 22:44:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/26/2022 22:44:33 - INFO - __main__ - ['Animal']
05/26/2022 22:44:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/26/2022 22:44:33 - INFO - __main__ - ['Village']
05/26/2022 22:44:33 - INFO - __main__ - Tokenizing Input ...
05/26/2022 22:44:35 - INFO - __main__ - Tokenizing Output ...
05/26/2022 22:44:38 - INFO - __main__ - Loaded 3500 examples from test data
05/26/2022 22:46:48 - INFO - __main__ - Saved prediction in models/T5-large-cls2cls-down128shot/singletask-dbpedia_14/dbpedia_14_128_87_0.2_8_predictions.txt
05/26/2022 22:46:48 - INFO - __main__ - Classification-F1 on test data: 0.7165
05/26/2022 22:46:49 - INFO - __main__ - prefix=dbpedia_14_128_87, lr=0.2, bsz=8, dev_performance=0.9186512510960761, test_performance=0.7164602751612508
