05/22/2022 17:39:54 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/22/2022 17:39:54 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo
05/22/2022 17:39:54 - INFO - __main__ - Namespace(task_dir='data_32/emo/', task_name='emo', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/22/2022 17:39:54 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo
05/22/2022 17:39:55 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/22/2022 17:39:55 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/22/2022 17:39:55 - INFO - __main__ - args.device: cuda:0
05/22/2022 17:39:55 - INFO - __main__ - Using 2 gpus
05/22/2022 17:39:55 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/22/2022 17:39:55 - INFO - __main__ - args.device: cuda:1
05/22/2022 17:39:55 - INFO - __main__ - Using 2 gpus
05/22/2022 17:39:55 - INFO - __main__ - Fine-tuning the following samples: ['emo_32_100', 'emo_32_13', 'emo_32_21', 'emo_32_42', 'emo_32_87']
05/22/2022 17:40:00 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.5, bsz=8 ...
05/22/2022 17:40:01 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:40:01 - INFO - __main__ - Printing 3 examples
05/22/2022 17:40:01 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:40:01 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:40:01 - INFO - __main__ - Printing 3 examples
05/22/2022 17:40:01 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:40:01 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 17:40:01 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:40:01 - INFO - __main__ - Printing 3 examples
05/22/2022 17:40:01 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:40:01 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 17:40:01 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:40:01 - INFO - __main__ - Printing 3 examples
05/22/2022 17:40:01 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 17:40:01 - INFO - __main__ - ['others']
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:40:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:40:01 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 17:40:01 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 17:40:19 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 17:40:19 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 17:40:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:40:20 - INFO - __main__ - Starting training!
05/22/2022 17:40:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:40:24 - INFO - __main__ - Starting training!
05/22/2022 17:40:28 - INFO - __main__ - Step 10 Global step 10 Train loss 4.13 on epoch=1
05/22/2022 17:40:30 - INFO - __main__ - Step 20 Global step 20 Train loss 2.79 on epoch=2
05/22/2022 17:40:33 - INFO - __main__ - Step 30 Global step 30 Train loss 2.21 on epoch=3
05/22/2022 17:40:35 - INFO - __main__ - Step 40 Global step 40 Train loss 1.81 on epoch=4
05/22/2022 17:40:37 - INFO - __main__ - Step 50 Global step 50 Train loss 1.49 on epoch=6
05/22/2022 17:40:39 - INFO - __main__ - Global step 50 Train loss 2.49 Classification-F1 0.2630862793689214 on epoch=6
05/22/2022 17:40:39 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.2630862793689214 on epoch=6, global_step=50
05/22/2022 17:40:42 - INFO - __main__ - Step 60 Global step 60 Train loss 1.08 on epoch=7
05/22/2022 17:40:44 - INFO - __main__ - Step 70 Global step 70 Train loss 0.96 on epoch=8
05/22/2022 17:40:46 - INFO - __main__ - Step 80 Global step 80 Train loss 0.95 on epoch=9
05/22/2022 17:40:49 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=11
05/22/2022 17:40:51 - INFO - __main__ - Step 100 Global step 100 Train loss 0.76 on epoch=12
05/22/2022 17:40:53 - INFO - __main__ - Global step 100 Train loss 0.91 Classification-F1 0.5663925992939883 on epoch=12
05/22/2022 17:40:53 - INFO - __main__ - Saving model with best Classification-F1: 0.2630862793689214 -> 0.5663925992939883 on epoch=12, global_step=100
05/22/2022 17:40:55 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=13
05/22/2022 17:40:57 - INFO - __main__ - Step 120 Global step 120 Train loss 0.72 on epoch=14
05/22/2022 17:41:00 - INFO - __main__ - Step 130 Global step 130 Train loss 0.72 on epoch=16
05/22/2022 17:41:02 - INFO - __main__ - Step 140 Global step 140 Train loss 0.60 on epoch=17
05/22/2022 17:41:05 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=18
05/22/2022 17:41:06 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.6033718513083883 on epoch=18
05/22/2022 17:41:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5663925992939883 -> 0.6033718513083883 on epoch=18, global_step=150
05/22/2022 17:41:09 - INFO - __main__ - Step 160 Global step 160 Train loss 0.69 on epoch=19
05/22/2022 17:41:11 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=21
05/22/2022 17:41:13 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=22
05/22/2022 17:41:16 - INFO - __main__ - Step 190 Global step 190 Train loss 0.64 on epoch=23
05/22/2022 17:41:18 - INFO - __main__ - Step 200 Global step 200 Train loss 0.55 on epoch=24
05/22/2022 17:41:20 - INFO - __main__ - Global step 200 Train loss 0.62 Classification-F1 0.6460255107358766 on epoch=24
05/22/2022 17:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6033718513083883 -> 0.6460255107358766 on epoch=24, global_step=200
05/22/2022 17:41:22 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=26
05/22/2022 17:41:25 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=27
05/22/2022 17:41:27 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=28
05/22/2022 17:41:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=29
05/22/2022 17:41:32 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=31
05/22/2022 17:41:33 - INFO - __main__ - Global step 250 Train loss 0.57 Classification-F1 0.6998115247796912 on epoch=31
05/22/2022 17:41:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6460255107358766 -> 0.6998115247796912 on epoch=31, global_step=250
05/22/2022 17:41:36 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=32
05/22/2022 17:41:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.57 on epoch=33
05/22/2022 17:41:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=34
05/22/2022 17:41:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=36
05/22/2022 17:41:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.37 on epoch=37
05/22/2022 17:41:47 - INFO - __main__ - Global step 300 Train loss 0.48 Classification-F1 0.7317800994563874 on epoch=37
05/22/2022 17:41:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6998115247796912 -> 0.7317800994563874 on epoch=37, global_step=300
05/22/2022 17:41:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=38
05/22/2022 17:41:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=39
05/22/2022 17:41:54 - INFO - __main__ - Step 330 Global step 330 Train loss 0.50 on epoch=41
05/22/2022 17:41:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=42
05/22/2022 17:41:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=43
05/22/2022 17:42:00 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.7649581485973318 on epoch=43
05/22/2022 17:42:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7317800994563874 -> 0.7649581485973318 on epoch=43, global_step=350
05/22/2022 17:42:03 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=44
05/22/2022 17:42:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=46
05/22/2022 17:42:08 - INFO - __main__ - Step 380 Global step 380 Train loss 0.28 on epoch=47
05/22/2022 17:42:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.40 on epoch=48
05/22/2022 17:42:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=49
05/22/2022 17:42:14 - INFO - __main__ - Global step 400 Train loss 0.36 Classification-F1 0.7860265700483091 on epoch=49
05/22/2022 17:42:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7649581485973318 -> 0.7860265700483091 on epoch=49, global_step=400
05/22/2022 17:42:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.42 on epoch=51
05/22/2022 17:42:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=52
05/22/2022 17:42:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=53
05/22/2022 17:42:23 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=54
05/22/2022 17:42:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=56
05/22/2022 17:42:28 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.8219077915379018 on epoch=56
05/22/2022 17:42:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7860265700483091 -> 0.8219077915379018 on epoch=56, global_step=450
05/22/2022 17:42:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=57
05/22/2022 17:42:32 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=58
05/22/2022 17:42:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=59
05/22/2022 17:42:37 - INFO - __main__ - Step 490 Global step 490 Train loss 0.33 on epoch=61
05/22/2022 17:42:39 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=62
05/22/2022 17:42:41 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.7933224502487563 on epoch=62
05/22/2022 17:42:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.39 on epoch=63
05/22/2022 17:42:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=64
05/22/2022 17:42:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=66
05/22/2022 17:42:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=67
05/22/2022 17:42:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=68
05/22/2022 17:42:55 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.8271567711840437 on epoch=68
05/22/2022 17:42:56 - INFO - __main__ - Saving model with best Classification-F1: 0.8219077915379018 -> 0.8271567711840437 on epoch=68, global_step=550
05/22/2022 17:42:58 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=69
05/22/2022 17:43:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.24 on epoch=71
05/22/2022 17:43:03 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=72
05/22/2022 17:43:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=73
05/22/2022 17:43:08 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=74
05/22/2022 17:43:10 - INFO - __main__ - Global step 600 Train loss 0.26 Classification-F1 0.8044493441881503 on epoch=74
05/22/2022 17:43:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.31 on epoch=76
05/22/2022 17:43:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=77
05/22/2022 17:43:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=78
05/22/2022 17:43:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=79
05/22/2022 17:43:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=81
05/22/2022 17:43:24 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.8363900886288946 on epoch=81
05/22/2022 17:43:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8271567711840437 -> 0.8363900886288946 on epoch=81, global_step=650
05/22/2022 17:43:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.29 on epoch=82
05/22/2022 17:43:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=83
05/22/2022 17:43:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=84
05/22/2022 17:43:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=86
05/22/2022 17:43:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.19 on epoch=87
05/22/2022 17:43:39 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.8086409843178578 on epoch=87
05/22/2022 17:43:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=88
05/22/2022 17:43:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.18 on epoch=89
05/22/2022 17:43:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=91
05/22/2022 17:43:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.16 on epoch=92
05/22/2022 17:43:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=93
05/22/2022 17:43:53 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.8719050610055936 on epoch=93
05/22/2022 17:43:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8363900886288946 -> 0.8719050610055936 on epoch=93, global_step=750
05/22/2022 17:43:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.18 on epoch=94
05/22/2022 17:43:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=96
05/22/2022 17:44:01 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=97
05/22/2022 17:44:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=98
05/22/2022 17:44:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=99
05/22/2022 17:44:08 - INFO - __main__ - Global step 800 Train loss 0.17 Classification-F1 0.8572184224643531 on epoch=99
05/22/2022 17:44:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=101
05/22/2022 17:44:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=102
05/22/2022 17:44:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=103
05/22/2022 17:44:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.17 on epoch=104
05/22/2022 17:44:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=106
05/22/2022 17:44:22 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.8553556751919774 on epoch=106
05/22/2022 17:44:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=107
05/22/2022 17:44:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.21 on epoch=108
05/22/2022 17:44:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=109
05/22/2022 17:44:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=111
05/22/2022 17:44:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.17 on epoch=112
05/22/2022 17:44:37 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.8439453527700885 on epoch=112
05/22/2022 17:44:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=113
05/22/2022 17:44:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=114
05/22/2022 17:44:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=116
05/22/2022 17:44:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=117
05/22/2022 17:44:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=118
05/22/2022 17:44:51 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.8240677451203767 on epoch=118
05/22/2022 17:44:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=119
05/22/2022 17:44:56 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=121
05/22/2022 17:44:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.08 on epoch=122
05/22/2022 17:45:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=123
05/22/2022 17:45:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=124
05/22/2022 17:45:05 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.8334334726576106 on epoch=124
05/22/2022 17:45:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=126
05/22/2022 17:45:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=127
05/22/2022 17:45:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=128
05/22/2022 17:45:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=129
05/22/2022 17:45:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.12 on epoch=131
05/22/2022 17:45:18 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.8259361871650007 on epoch=131
05/22/2022 17:45:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=132
05/22/2022 17:45:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=133
05/22/2022 17:45:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=134
05/22/2022 17:45:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=136
05/22/2022 17:45:30 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=137
05/22/2022 17:45:32 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.8334334726576106 on epoch=137
05/22/2022 17:45:34 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=138
05/22/2022 17:45:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=139
05/22/2022 17:45:39 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=141
05/22/2022 17:45:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=142
05/22/2022 17:45:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=143
05/22/2022 17:45:46 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.8349981985227887 on epoch=143
05/22/2022 17:45:48 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=144
05/22/2022 17:45:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
05/22/2022 17:45:53 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.03 on epoch=147
05/22/2022 17:45:55 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=148
05/22/2022 17:45:58 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=149
05/22/2022 17:45:59 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.8351798624125515 on epoch=149
05/22/2022 17:46:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=151
05/22/2022 17:46:04 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=152
05/22/2022 17:46:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=153
05/22/2022 17:46:09 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.02 on epoch=154
05/22/2022 17:46:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=156
05/22/2022 17:46:13 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.8240105030403537 on epoch=156
05/22/2022 17:46:15 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=157
05/22/2022 17:46:18 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=158
05/22/2022 17:46:20 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
05/22/2022 17:46:22 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=161
05/22/2022 17:46:25 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=162
05/22/2022 17:46:27 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.790818858560794 on epoch=162
05/22/2022 17:46:29 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=163
05/22/2022 17:46:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=164
05/22/2022 17:46:34 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=166
05/22/2022 17:46:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=167
05/22/2022 17:46:39 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=168
05/22/2022 17:46:40 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.8243328832257645 on epoch=168
05/22/2022 17:46:43 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.01 on epoch=169
05/22/2022 17:46:45 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=171
05/22/2022 17:46:47 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=172
05/22/2022 17:46:50 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=173
05/22/2022 17:46:52 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
05/22/2022 17:46:54 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.8169945064681907 on epoch=174
05/22/2022 17:46:56 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
05/22/2022 17:46:59 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=177
05/22/2022 17:47:01 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=178
05/22/2022 17:47:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.01 on epoch=179
05/22/2022 17:47:06 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.01 on epoch=181
05/22/2022 17:47:08 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8148660904822878 on epoch=181
05/22/2022 17:47:10 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=182
05/22/2022 17:47:12 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=183
05/22/2022 17:47:15 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
05/22/2022 17:47:17 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=186
05/22/2022 17:47:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
05/22/2022 17:47:21 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8049913527332881 on epoch=187
05/22/2022 17:47:24 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
05/22/2022 17:47:26 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=189
05/22/2022 17:47:29 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
05/22/2022 17:47:31 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.03 on epoch=192
05/22/2022 17:47:33 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
05/22/2022 17:47:35 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8362183077079728 on epoch=193
05/22/2022 17:47:37 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=194
05/22/2022 17:47:40 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=196
05/22/2022 17:47:42 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=197
05/22/2022 17:47:45 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
05/22/2022 17:47:47 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=199
05/22/2022 17:47:49 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8259410857883529 on epoch=199
05/22/2022 17:47:51 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
05/22/2022 17:47:53 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=202
05/22/2022 17:47:56 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
05/22/2022 17:47:58 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=204
05/22/2022 17:48:00 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.03 on epoch=206
05/22/2022 17:48:02 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.8262025499855116 on epoch=206
05/22/2022 17:48:05 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=207
05/22/2022 17:48:07 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
05/22/2022 17:48:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
05/22/2022 17:48:12 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=211
05/22/2022 17:48:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
05/22/2022 17:48:16 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.8173453435025279 on epoch=212
05/22/2022 17:48:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=213
05/22/2022 17:48:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=214
05/22/2022 17:48:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=216
05/22/2022 17:48:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
05/22/2022 17:48:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=218
05/22/2022 17:48:29 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.8258008476976344 on epoch=218
05/22/2022 17:48:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=219
05/22/2022 17:48:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.08 on epoch=221
05/22/2022 17:48:36 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=222
05/22/2022 17:48:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
05/22/2022 17:48:41 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
05/22/2022 17:48:43 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8324737423991155 on epoch=224
05/22/2022 17:48:45 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
05/22/2022 17:48:48 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
05/22/2022 17:48:50 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
05/22/2022 17:48:52 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=229
05/22/2022 17:48:55 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=231
05/22/2022 17:48:56 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.8338673096737612 on epoch=231
05/22/2022 17:48:59 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=232
05/22/2022 17:49:01 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
05/22/2022 17:49:04 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
05/22/2022 17:49:06 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=236
05/22/2022 17:49:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=237
05/22/2022 17:49:10 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8483825885833194 on epoch=237
05/22/2022 17:49:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=238
05/22/2022 17:49:15 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
05/22/2022 17:49:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=241
05/22/2022 17:49:20 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=242
05/22/2022 17:49:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=243
05/22/2022 17:49:24 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8483074910343044 on epoch=243
05/22/2022 17:49:26 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
05/22/2022 17:49:29 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=246
05/22/2022 17:49:31 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
05/22/2022 17:49:33 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
05/22/2022 17:49:36 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.07 on epoch=249
05/22/2022 17:49:37 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.8419624091755239 on epoch=249
05/22/2022 17:49:40 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=251
05/22/2022 17:49:42 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=252
05/22/2022 17:49:45 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
05/22/2022 17:49:47 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
05/22/2022 17:49:49 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=256
05/22/2022 17:49:51 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8419624091755239 on epoch=256
05/22/2022 17:49:54 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=257
05/22/2022 17:49:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
05/22/2022 17:49:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
05/22/2022 17:50:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
05/22/2022 17:50:03 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
05/22/2022 17:50:05 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.831533157339609 on epoch=262
05/22/2022 17:50:07 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
05/22/2022 17:50:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
05/22/2022 17:50:12 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.00 on epoch=266
05/22/2022 17:50:14 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
05/22/2022 17:50:17 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.00 on epoch=268
05/22/2022 17:50:19 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.8243989549999271 on epoch=268
05/22/2022 17:50:21 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
05/22/2022 17:50:24 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
05/22/2022 17:50:26 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=272
05/22/2022 17:50:28 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=273
05/22/2022 17:50:31 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
05/22/2022 17:50:32 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.8240829667644185 on epoch=274
05/22/2022 17:50:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 17:50:37 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=277
05/22/2022 17:50:39 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
05/22/2022 17:50:42 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
05/22/2022 17:50:44 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.15 on epoch=281
05/22/2022 17:50:46 - INFO - __main__ - Global step 2250 Train loss 0.06 Classification-F1 0.8403879724186087 on epoch=281
05/22/2022 17:50:49 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=282
05/22/2022 17:50:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
05/22/2022 17:50:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
05/22/2022 17:50:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=286
05/22/2022 17:50:58 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
05/22/2022 17:51:00 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.831533157339609 on epoch=287
05/22/2022 17:51:02 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
05/22/2022 17:51:05 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
05/22/2022 17:51:07 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
05/22/2022 17:51:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
05/22/2022 17:51:12 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
05/22/2022 17:51:14 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8464491531379577 on epoch=293
05/22/2022 17:51:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
05/22/2022 17:51:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=296
05/22/2022 17:51:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
05/22/2022 17:51:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.01 on epoch=298
05/22/2022 17:51:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
05/22/2022 17:51:28 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.824642952587562 on epoch=299
05/22/2022 17:51:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
05/22/2022 17:51:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
05/22/2022 17:51:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
05/22/2022 17:51:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
05/22/2022 17:51:39 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
05/22/2022 17:51:41 - INFO - __main__ - Global step 2450 Train loss 0.00 Classification-F1 0.834068603419876 on epoch=306
05/22/2022 17:51:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
05/22/2022 17:51:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
05/22/2022 17:51:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
05/22/2022 17:51:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=311
05/22/2022 17:51:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
05/22/2022 17:51:55 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8324737423991155 on epoch=312
05/22/2022 17:51:57 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=313
05/22/2022 17:52:00 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.00 on epoch=314
05/22/2022 17:52:02 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
05/22/2022 17:52:05 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=317
05/22/2022 17:52:07 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
05/22/2022 17:52:09 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8263031824965603 on epoch=318
05/22/2022 17:52:11 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
05/22/2022 17:52:14 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
05/22/2022 17:52:16 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
05/22/2022 17:52:18 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
05/22/2022 17:52:21 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
05/22/2022 17:52:22 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.8183987469605459 on epoch=324
05/22/2022 17:52:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
05/22/2022 17:52:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
05/22/2022 17:52:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
05/22/2022 17:52:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=329
05/22/2022 17:52:34 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
05/22/2022 17:52:36 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8262397589839178 on epoch=331
05/22/2022 17:52:38 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
05/22/2022 17:52:41 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 17:52:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
05/22/2022 17:52:46 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
05/22/2022 17:52:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 17:52:50 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8322837543425778 on epoch=337
05/22/2022 17:52:52 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 17:52:55 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
05/22/2022 17:52:57 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
05/22/2022 17:52:59 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
05/22/2022 17:53:02 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 17:53:04 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8344148634517876 on epoch=343
05/22/2022 17:53:06 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 17:53:08 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=346
05/22/2022 17:53:11 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
05/22/2022 17:53:13 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
05/22/2022 17:53:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
05/22/2022 17:53:17 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8257505752858405 on epoch=349
05/22/2022 17:53:20 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
05/22/2022 17:53:22 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
05/22/2022 17:53:24 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=353
05/22/2022 17:53:27 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
05/22/2022 17:53:29 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
05/22/2022 17:53:31 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.8258770761940045 on epoch=356
05/22/2022 17:53:33 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
05/22/2022 17:53:36 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
05/22/2022 17:53:38 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 17:53:40 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
05/22/2022 17:53:43 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
05/22/2022 17:53:45 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.8178712919594067 on epoch=362
05/22/2022 17:53:47 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=363
05/22/2022 17:53:49 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
05/22/2022 17:53:52 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=366
05/22/2022 17:53:54 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
05/22/2022 17:53:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
05/22/2022 17:53:58 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.8099228896103895 on epoch=368
05/22/2022 17:54:01 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 17:54:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 17:54:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 17:54:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
05/22/2022 17:54:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
05/22/2022 17:54:11 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:54:11 - INFO - __main__ - Printing 3 examples
05/22/2022 17:54:11 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 17:54:11 - INFO - __main__ - ['others']
05/22/2022 17:54:11 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 17:54:11 - INFO - __main__ - ['others']
05/22/2022 17:54:11 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 17:54:11 - INFO - __main__ - ['others']
05/22/2022 17:54:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:54:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:54:12 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 17:54:12 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:54:12 - INFO - __main__ - Printing 3 examples
05/22/2022 17:54:12 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:54:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:54:12 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 17:54:12 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8342763892095744 on epoch=374
05/22/2022 17:54:12 - INFO - __main__ - save last model!
05/22/2022 17:54:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 17:54:12 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 17:54:12 - INFO - __main__ - Printing 3 examples
05/22/2022 17:54:12 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 17:54:12 - INFO - __main__ - ['others']
05/22/2022 17:54:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:54:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:54:20 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 17:54:30 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 17:54:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:54:31 - INFO - __main__ - Starting training!
05/22/2022 17:55:41 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_100_0.5_8_predictions.txt
05/22/2022 17:55:41 - INFO - __main__ - Classification-F1 on test data: 0.4118
05/22/2022 17:55:41 - INFO - __main__ - prefix=emo_32_100, lr=0.5, bsz=8, dev_performance=0.8719050610055936, test_performance=0.4117666533922296
05/22/2022 17:55:41 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.4, bsz=8 ...
05/22/2022 17:55:42 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:55:42 - INFO - __main__ - Printing 3 examples
05/22/2022 17:55:42 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:55:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:55:42 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 17:55:42 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 17:55:42 - INFO - __main__ - Printing 3 examples
05/22/2022 17:55:42 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 17:55:42 - INFO - __main__ - ['others']
05/22/2022 17:55:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 17:55:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 17:55:42 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 17:55:57 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 17:55:58 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 17:55:58 - INFO - __main__ - Starting training!
05/22/2022 17:56:01 - INFO - __main__ - Step 10 Global step 10 Train loss 4.19 on epoch=1
05/22/2022 17:56:03 - INFO - __main__ - Step 20 Global step 20 Train loss 2.94 on epoch=2
05/22/2022 17:56:06 - INFO - __main__ - Step 30 Global step 30 Train loss 2.46 on epoch=3
05/22/2022 17:56:08 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=4
05/22/2022 17:56:10 - INFO - __main__ - Step 50 Global step 50 Train loss 1.79 on epoch=6
05/22/2022 17:56:12 - INFO - __main__ - Global step 50 Train loss 2.67 Classification-F1 0.1384474940812969 on epoch=6
05/22/2022 17:56:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1384474940812969 on epoch=6, global_step=50
05/22/2022 17:56:15 - INFO - __main__ - Step 60 Global step 60 Train loss 1.26 on epoch=7
05/22/2022 17:56:17 - INFO - __main__ - Step 70 Global step 70 Train loss 1.21 on epoch=8
05/22/2022 17:56:20 - INFO - __main__ - Step 80 Global step 80 Train loss 1.05 on epoch=9
05/22/2022 17:56:22 - INFO - __main__ - Step 90 Global step 90 Train loss 0.98 on epoch=11
05/22/2022 17:56:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.72 on epoch=12
05/22/2022 17:56:26 - INFO - __main__ - Global step 100 Train loss 1.04 Classification-F1 0.5411763822619652 on epoch=12
05/22/2022 17:56:26 - INFO - __main__ - Saving model with best Classification-F1: 0.1384474940812969 -> 0.5411763822619652 on epoch=12, global_step=100
05/22/2022 17:56:28 - INFO - __main__ - Step 110 Global step 110 Train loss 0.88 on epoch=13
05/22/2022 17:56:31 - INFO - __main__ - Step 120 Global step 120 Train loss 0.71 on epoch=14
05/22/2022 17:56:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=16
05/22/2022 17:56:36 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=17
05/22/2022 17:56:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.82 on epoch=18
05/22/2022 17:56:40 - INFO - __main__ - Global step 150 Train loss 0.74 Classification-F1 0.6119976747251142 on epoch=18
05/22/2022 17:56:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5411763822619652 -> 0.6119976747251142 on epoch=18, global_step=150
05/22/2022 17:56:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.70 on epoch=19
05/22/2022 17:56:45 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=21
05/22/2022 17:56:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.70 on epoch=22
05/22/2022 17:56:50 - INFO - __main__ - Step 190 Global step 190 Train loss 0.60 on epoch=23
05/22/2022 17:56:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=24
05/22/2022 17:56:54 - INFO - __main__ - Global step 200 Train loss 0.64 Classification-F1 0.6094171997157072 on epoch=24
05/22/2022 17:56:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.78 on epoch=26
05/22/2022 17:56:59 - INFO - __main__ - Step 220 Global step 220 Train loss 0.54 on epoch=27
05/22/2022 17:57:01 - INFO - __main__ - Step 230 Global step 230 Train loss 0.53 on epoch=28
05/22/2022 17:57:04 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=29
05/22/2022 17:57:06 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=31
05/22/2022 17:57:08 - INFO - __main__ - Global step 250 Train loss 0.61 Classification-F1 0.7093269258191124 on epoch=31
05/22/2022 17:57:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6119976747251142 -> 0.7093269258191124 on epoch=31, global_step=250
05/22/2022 17:57:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.46 on epoch=32
05/22/2022 17:57:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=33
05/22/2022 17:57:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.49 on epoch=34
05/22/2022 17:57:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=36
05/22/2022 17:57:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=37
05/22/2022 17:57:22 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.7103672340581749 on epoch=37
05/22/2022 17:57:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7093269258191124 -> 0.7103672340581749 on epoch=37, global_step=300
05/22/2022 17:57:24 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=38
05/22/2022 17:57:27 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=39
05/22/2022 17:57:29 - INFO - __main__ - Step 330 Global step 330 Train loss 0.57 on epoch=41
05/22/2022 17:57:32 - INFO - __main__ - Step 340 Global step 340 Train loss 0.47 on epoch=42
05/22/2022 17:57:34 - INFO - __main__ - Step 350 Global step 350 Train loss 0.49 on epoch=43
05/22/2022 17:57:36 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.7202195393286563 on epoch=43
05/22/2022 17:57:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7103672340581749 -> 0.7202195393286563 on epoch=43, global_step=350
05/22/2022 17:57:38 - INFO - __main__ - Step 360 Global step 360 Train loss 0.46 on epoch=44
05/22/2022 17:57:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.50 on epoch=46
05/22/2022 17:57:43 - INFO - __main__ - Step 380 Global step 380 Train loss 0.44 on epoch=47
05/22/2022 17:57:45 - INFO - __main__ - Step 390 Global step 390 Train loss 0.46 on epoch=48
05/22/2022 17:57:48 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=49
05/22/2022 17:57:50 - INFO - __main__ - Global step 400 Train loss 0.47 Classification-F1 0.7415568806193806 on epoch=49
05/22/2022 17:57:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7202195393286563 -> 0.7415568806193806 on epoch=49, global_step=400
05/22/2022 17:57:52 - INFO - __main__ - Step 410 Global step 410 Train loss 0.45 on epoch=51
05/22/2022 17:57:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.43 on epoch=52
05/22/2022 17:57:57 - INFO - __main__ - Step 430 Global step 430 Train loss 0.51 on epoch=53
05/22/2022 17:58:00 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=54
05/22/2022 17:58:02 - INFO - __main__ - Step 450 Global step 450 Train loss 0.41 on epoch=56
05/22/2022 17:58:04 - INFO - __main__ - Global step 450 Train loss 0.44 Classification-F1 0.7313600718901493 on epoch=56
05/22/2022 17:58:06 - INFO - __main__ - Step 460 Global step 460 Train loss 0.32 on epoch=57
05/22/2022 17:58:08 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=58
05/22/2022 17:58:11 - INFO - __main__ - Step 480 Global step 480 Train loss 0.32 on epoch=59
05/22/2022 17:58:13 - INFO - __main__ - Step 490 Global step 490 Train loss 0.43 on epoch=61
05/22/2022 17:58:16 - INFO - __main__ - Step 500 Global step 500 Train loss 0.26 on epoch=62
05/22/2022 17:58:17 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.7941058245334027 on epoch=62
05/22/2022 17:58:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7415568806193806 -> 0.7941058245334027 on epoch=62, global_step=500
05/22/2022 17:58:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=63
05/22/2022 17:58:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=64
05/22/2022 17:58:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.27 on epoch=66
05/22/2022 17:58:27 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=67
05/22/2022 17:58:30 - INFO - __main__ - Step 550 Global step 550 Train loss 0.37 on epoch=68
05/22/2022 17:58:31 - INFO - __main__ - Global step 550 Train loss 0.36 Classification-F1 0.8013682396035338 on epoch=68
05/22/2022 17:58:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7941058245334027 -> 0.8013682396035338 on epoch=68, global_step=550
05/22/2022 17:58:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=69
05/22/2022 17:58:36 - INFO - __main__ - Step 570 Global step 570 Train loss 0.31 on epoch=71
05/22/2022 17:58:39 - INFO - __main__ - Step 580 Global step 580 Train loss 0.32 on epoch=72
05/22/2022 17:58:41 - INFO - __main__ - Step 590 Global step 590 Train loss 0.37 on epoch=73
05/22/2022 17:58:44 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=74
05/22/2022 17:58:45 - INFO - __main__ - Global step 600 Train loss 0.32 Classification-F1 0.7604745254745255 on epoch=74
05/22/2022 17:58:48 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=76
05/22/2022 17:58:50 - INFO - __main__ - Step 620 Global step 620 Train loss 0.27 on epoch=77
05/22/2022 17:58:53 - INFO - __main__ - Step 630 Global step 630 Train loss 0.38 on epoch=78
05/22/2022 17:58:55 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=79
05/22/2022 17:58:58 - INFO - __main__ - Step 650 Global step 650 Train loss 0.27 on epoch=81
05/22/2022 17:58:59 - INFO - __main__ - Global step 650 Train loss 0.30 Classification-F1 0.7862107078746992 on epoch=81
05/22/2022 17:59:02 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=82
05/22/2022 17:59:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=83
05/22/2022 17:59:07 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=84
05/22/2022 17:59:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=86
05/22/2022 17:59:12 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=87
05/22/2022 17:59:13 - INFO - __main__ - Global step 700 Train loss 0.26 Classification-F1 0.7886151482925677 on epoch=87
05/22/2022 17:59:16 - INFO - __main__ - Step 710 Global step 710 Train loss 0.23 on epoch=88
05/22/2022 17:59:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=89
05/22/2022 17:59:21 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=91
05/22/2022 17:59:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=92
05/22/2022 17:59:26 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=93
05/22/2022 17:59:27 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.8110275807474744 on epoch=93
05/22/2022 17:59:27 - INFO - __main__ - Saving model with best Classification-F1: 0.8013682396035338 -> 0.8110275807474744 on epoch=93, global_step=750
05/22/2022 17:59:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=94
05/22/2022 17:59:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=96
05/22/2022 17:59:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=97
05/22/2022 17:59:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.30 on epoch=98
05/22/2022 17:59:40 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=99
05/22/2022 17:59:41 - INFO - __main__ - Global step 800 Train loss 0.24 Classification-F1 0.7962317002272608 on epoch=99
05/22/2022 17:59:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=101
05/22/2022 17:59:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=102
05/22/2022 17:59:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.35 on epoch=103
05/22/2022 17:59:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.20 on epoch=104
05/22/2022 17:59:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=106
05/22/2022 17:59:55 - INFO - __main__ - Global step 850 Train loss 0.24 Classification-F1 0.7938432129608599 on epoch=106
05/22/2022 17:59:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=107
05/22/2022 18:00:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.24 on epoch=108
05/22/2022 18:00:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=109
05/22/2022 18:00:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.27 on epoch=111
05/22/2022 18:00:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=112
05/22/2022 18:00:10 - INFO - __main__ - Global step 900 Train loss 0.22 Classification-F1 0.7940910059676044 on epoch=112
05/22/2022 18:00:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.18 on epoch=113
05/22/2022 18:00:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=114
05/22/2022 18:00:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=116
05/22/2022 18:00:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=117
05/22/2022 18:00:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.20 on epoch=118
05/22/2022 18:00:24 - INFO - __main__ - Global step 950 Train loss 0.18 Classification-F1 0.8394979203802734 on epoch=118
05/22/2022 18:00:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8110275807474744 -> 0.8394979203802734 on epoch=118, global_step=950
05/22/2022 18:00:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
05/22/2022 18:00:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=121
05/22/2022 18:00:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.16 on epoch=122
05/22/2022 18:00:33 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=123
05/22/2022 18:00:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.13 on epoch=124
05/22/2022 18:00:38 - INFO - __main__ - Global step 1000 Train loss 0.17 Classification-F1 0.8022991225475697 on epoch=124
05/22/2022 18:00:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=126
05/22/2022 18:00:42 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=127
05/22/2022 18:00:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
05/22/2022 18:00:47 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=129
05/22/2022 18:00:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=131
05/22/2022 18:00:52 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.8203730618399019 on epoch=131
05/22/2022 18:00:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.13 on epoch=132
05/22/2022 18:00:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=133
05/22/2022 18:00:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.20 on epoch=134
05/22/2022 18:01:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=136
05/22/2022 18:01:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=137
05/22/2022 18:01:06 - INFO - __main__ - Global step 1100 Train loss 0.17 Classification-F1 0.8114365716315732 on epoch=137
05/22/2022 18:01:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=138
05/22/2022 18:01:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=139
05/22/2022 18:01:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.12 on epoch=141
05/22/2022 18:01:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=142
05/22/2022 18:01:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.20 on epoch=143
05/22/2022 18:01:20 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.8043650793650794 on epoch=143
05/22/2022 18:01:22 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=144
05/22/2022 18:01:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.15 on epoch=146
05/22/2022 18:01:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=147
05/22/2022 18:01:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=148
05/22/2022 18:01:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=149
05/22/2022 18:01:34 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.8267622012979705 on epoch=149
05/22/2022 18:01:36 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=151
05/22/2022 18:01:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=152
05/22/2022 18:01:41 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.08 on epoch=153
05/22/2022 18:01:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.13 on epoch=154
05/22/2022 18:01:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.12 on epoch=156
05/22/2022 18:01:48 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.822651047899598 on epoch=156
05/22/2022 18:01:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=157
05/22/2022 18:01:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=158
05/22/2022 18:01:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=159
05/22/2022 18:01:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=161
05/22/2022 18:02:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=162
05/22/2022 18:02:02 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.83017394200749 on epoch=162
05/22/2022 18:02:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=163
05/22/2022 18:02:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.08 on epoch=164
05/22/2022 18:02:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=166
05/22/2022 18:02:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=167
05/22/2022 18:02:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=168
05/22/2022 18:02:16 - INFO - __main__ - Global step 1350 Train loss 0.11 Classification-F1 0.8150073211734565 on epoch=168
05/22/2022 18:02:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
05/22/2022 18:02:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=171
05/22/2022 18:02:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=172
05/22/2022 18:02:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=173
05/22/2022 18:02:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=174
05/22/2022 18:02:30 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.8248640035724435 on epoch=174
05/22/2022 18:02:33 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=176
05/22/2022 18:02:35 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=177
05/22/2022 18:02:38 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=178
05/22/2022 18:02:40 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=179
05/22/2022 18:02:43 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=181
05/22/2022 18:02:44 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.8190363969625557 on epoch=181
05/22/2022 18:02:47 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.13 on epoch=182
05/22/2022 18:02:49 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=183
05/22/2022 18:02:52 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=184
05/22/2022 18:02:54 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
05/22/2022 18:02:57 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=187
05/22/2022 18:02:58 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.7932214927121548 on epoch=187
05/22/2022 18:03:01 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
05/22/2022 18:03:03 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=189
05/22/2022 18:03:06 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=191
05/22/2022 18:03:08 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
05/22/2022 18:03:11 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=193
05/22/2022 18:03:12 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.8160037314046635 on epoch=193
05/22/2022 18:03:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=194
05/22/2022 18:03:17 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=196
05/22/2022 18:03:20 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=197
05/22/2022 18:03:22 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=198
05/22/2022 18:03:25 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=199
05/22/2022 18:03:26 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8259585814303475 on epoch=199
05/22/2022 18:03:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=201
05/22/2022 18:03:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.08 on epoch=202
05/22/2022 18:03:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=203
05/22/2022 18:03:36 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
05/22/2022 18:03:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
05/22/2022 18:03:41 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.8263581400774856 on epoch=206
05/22/2022 18:03:43 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=207
05/22/2022 18:03:45 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
05/22/2022 18:03:48 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=209
05/22/2022 18:03:50 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
05/22/2022 18:03:53 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
05/22/2022 18:03:55 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.8112526990774064 on epoch=212
05/22/2022 18:03:57 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
05/22/2022 18:03:59 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
05/22/2022 18:04:02 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=216
05/22/2022 18:04:04 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
05/22/2022 18:04:07 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.01 on epoch=218
05/22/2022 18:04:09 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8265654447837625 on epoch=218
05/22/2022 18:04:11 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=219
05/22/2022 18:04:13 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=221
05/22/2022 18:04:16 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
05/22/2022 18:04:18 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
05/22/2022 18:04:21 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
05/22/2022 18:04:22 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8114449404180363 on epoch=224
05/22/2022 18:04:25 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.03 on epoch=226
05/22/2022 18:04:27 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
05/22/2022 18:04:30 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
05/22/2022 18:04:32 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=229
05/22/2022 18:04:35 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
05/22/2022 18:04:37 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.809574554459465 on epoch=231
05/22/2022 18:04:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
05/22/2022 18:04:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=233
05/22/2022 18:04:44 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=234
05/22/2022 18:04:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=236
05/22/2022 18:04:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=237
05/22/2022 18:04:51 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.8168917318171051 on epoch=237
05/22/2022 18:04:53 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=238
05/22/2022 18:04:56 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
05/22/2022 18:04:58 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
05/22/2022 18:05:01 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
05/22/2022 18:05:03 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
05/22/2022 18:05:05 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8266765243222168 on epoch=243
05/22/2022 18:05:08 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.11 on epoch=244
05/22/2022 18:05:10 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=246
05/22/2022 18:05:13 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
05/22/2022 18:05:15 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
05/22/2022 18:05:18 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=249
05/22/2022 18:05:20 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.8185472118096593 on epoch=249
05/22/2022 18:05:22 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
05/22/2022 18:05:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
05/22/2022 18:05:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
05/22/2022 18:05:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
05/22/2022 18:05:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=256
05/22/2022 18:05:34 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8110662864842 on epoch=256
05/22/2022 18:05:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=257
05/22/2022 18:05:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=258
05/22/2022 18:05:41 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=259
05/22/2022 18:05:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
05/22/2022 18:05:46 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
05/22/2022 18:05:48 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8188100166752919 on epoch=262
05/22/2022 18:05:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=263
05/22/2022 18:05:53 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
05/22/2022 18:05:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.06 on epoch=266
05/22/2022 18:05:58 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.13 on epoch=267
05/22/2022 18:06:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=268
05/22/2022 18:06:02 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.8005106160786386 on epoch=268
05/22/2022 18:06:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
05/22/2022 18:06:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.00 on epoch=271
05/22/2022 18:06:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
05/22/2022 18:06:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
05/22/2022 18:06:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
05/22/2022 18:06:16 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7965340321332204 on epoch=274
05/22/2022 18:06:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=276
05/22/2022 18:06:21 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=277
05/22/2022 18:06:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
05/22/2022 18:06:26 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=279
05/22/2022 18:06:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
05/22/2022 18:06:31 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.8119928323666145 on epoch=281
05/22/2022 18:06:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
05/22/2022 18:06:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
05/22/2022 18:06:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 18:06:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
05/22/2022 18:06:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
05/22/2022 18:06:45 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.811414873676963 on epoch=287
05/22/2022 18:06:48 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
05/22/2022 18:06:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
05/22/2022 18:06:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
05/22/2022 18:06:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
05/22/2022 18:06:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
05/22/2022 18:06:59 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7967922054446257 on epoch=293
05/22/2022 18:07:02 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
05/22/2022 18:07:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
05/22/2022 18:07:07 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
05/22/2022 18:07:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
05/22/2022 18:07:12 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.12 on epoch=299
05/22/2022 18:07:14 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.8020531022040945 on epoch=299
05/22/2022 18:07:16 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
05/22/2022 18:07:19 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
05/22/2022 18:07:21 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.13 on epoch=303
05/22/2022 18:07:24 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=304
05/22/2022 18:07:26 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
05/22/2022 18:07:28 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.8186612504885573 on epoch=306
05/22/2022 18:07:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
05/22/2022 18:07:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
05/22/2022 18:07:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=309
05/22/2022 18:07:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=311
05/22/2022 18:07:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
05/22/2022 18:07:42 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8109786657957934 on epoch=312
05/22/2022 18:07:45 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=313
05/22/2022 18:07:47 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
05/22/2022 18:07:50 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=316
05/22/2022 18:07:52 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
05/22/2022 18:07:55 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
05/22/2022 18:07:57 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.8177871148459385 on epoch=318
05/22/2022 18:07:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
05/22/2022 18:08:01 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=321
05/22/2022 18:08:04 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
05/22/2022 18:08:06 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
05/22/2022 18:08:09 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
05/22/2022 18:08:11 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.8191176470588236 on epoch=324
05/22/2022 18:08:13 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 18:08:16 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.14 on epoch=327
05/22/2022 18:08:18 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=328
05/22/2022 18:08:21 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 18:08:23 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
05/22/2022 18:08:25 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.8179054959395062 on epoch=331
05/22/2022 18:08:27 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
05/22/2022 18:08:30 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
05/22/2022 18:08:32 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
05/22/2022 18:08:35 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
05/22/2022 18:08:37 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 18:08:39 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.8193216655392278 on epoch=337
05/22/2022 18:08:41 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
05/22/2022 18:08:44 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 18:08:46 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
05/22/2022 18:08:49 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
05/22/2022 18:08:51 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 18:08:53 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.806249229251449 on epoch=343
05/22/2022 18:08:56 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=344
05/22/2022 18:08:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
05/22/2022 18:09:01 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
05/22/2022 18:09:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=348
05/22/2022 18:09:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
05/22/2022 18:09:07 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8255328999548406 on epoch=349
05/22/2022 18:09:10 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
05/22/2022 18:09:12 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 18:09:15 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
05/22/2022 18:09:17 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
05/22/2022 18:09:20 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 18:09:22 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.6511867384144973 on epoch=356
05/22/2022 18:09:24 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=357
05/22/2022 18:09:27 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=358
05/22/2022 18:09:29 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
05/22/2022 18:09:32 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=361
05/22/2022 18:09:34 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
05/22/2022 18:09:36 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8322408871321915 on epoch=362
05/22/2022 18:09:39 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=363
05/22/2022 18:09:41 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
05/22/2022 18:09:44 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 18:09:46 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=367
05/22/2022 18:09:49 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
05/22/2022 18:09:50 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.799755291005291 on epoch=368
05/22/2022 18:09:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=369
05/22/2022 18:09:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 18:09:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 18:10:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=373
05/22/2022 18:10:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
05/22/2022 18:10:04 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:10:04 - INFO - __main__ - Printing 3 examples
05/22/2022 18:10:04 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:10:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:10:04 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:10:04 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:10:04 - INFO - __main__ - Printing 3 examples
05/22/2022 18:10:04 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 18:10:04 - INFO - __main__ - ['others']
05/22/2022 18:10:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:10:04 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:10:04 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:10:05 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8195675924328677 on epoch=374
05/22/2022 18:10:05 - INFO - __main__ - save last model!
05/22/2022 18:10:05 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:10:05 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 18:10:05 - INFO - __main__ - Printing 3 examples
05/22/2022 18:10:05 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 18:10:05 - INFO - __main__ - ['others']
05/22/2022 18:10:05 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 18:10:05 - INFO - __main__ - ['others']
05/22/2022 18:10:05 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 18:10:05 - INFO - __main__ - ['others']
05/22/2022 18:10:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:10:07 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:10:12 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 18:10:23 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:10:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:10:24 - INFO - __main__ - Starting training!
05/22/2022 18:11:30 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_100_0.4_8_predictions.txt
05/22/2022 18:11:30 - INFO - __main__ - Classification-F1 on test data: 0.2852
05/22/2022 18:11:30 - INFO - __main__ - prefix=emo_32_100, lr=0.4, bsz=8, dev_performance=0.8394979203802734, test_performance=0.2851633302370403
05/22/2022 18:11:30 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.3, bsz=8 ...
05/22/2022 18:11:31 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:11:31 - INFO - __main__ - Printing 3 examples
05/22/2022 18:11:31 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:11:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:11:31 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:11:31 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:11:31 - INFO - __main__ - Printing 3 examples
05/22/2022 18:11:31 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 18:11:31 - INFO - __main__ - ['others']
05/22/2022 18:11:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:11:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:11:32 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:11:46 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:11:47 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:11:47 - INFO - __main__ - Starting training!
05/22/2022 18:11:50 - INFO - __main__ - Step 10 Global step 10 Train loss 3.96 on epoch=1
05/22/2022 18:11:53 - INFO - __main__ - Step 20 Global step 20 Train loss 2.72 on epoch=2
05/22/2022 18:11:55 - INFO - __main__ - Step 30 Global step 30 Train loss 2.50 on epoch=3
05/22/2022 18:11:58 - INFO - __main__ - Step 40 Global step 40 Train loss 2.18 on epoch=4
05/22/2022 18:12:00 - INFO - __main__ - Step 50 Global step 50 Train loss 2.00 on epoch=6
05/22/2022 18:12:02 - INFO - __main__ - Global step 50 Train loss 2.67 Classification-F1 0.1127946127946128 on epoch=6
05/22/2022 18:12:02 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.1127946127946128 on epoch=6, global_step=50
05/22/2022 18:12:04 - INFO - __main__ - Step 60 Global step 60 Train loss 1.56 on epoch=7
05/22/2022 18:12:07 - INFO - __main__ - Step 70 Global step 70 Train loss 1.44 on epoch=8
05/22/2022 18:12:09 - INFO - __main__ - Step 80 Global step 80 Train loss 1.19 on epoch=9
05/22/2022 18:12:12 - INFO - __main__ - Step 90 Global step 90 Train loss 1.15 on epoch=11
05/22/2022 18:12:14 - INFO - __main__ - Step 100 Global step 100 Train loss 0.88 on epoch=12
05/22/2022 18:12:16 - INFO - __main__ - Global step 100 Train loss 1.24 Classification-F1 0.5342493892960248 on epoch=12
05/22/2022 18:12:16 - INFO - __main__ - Saving model with best Classification-F1: 0.1127946127946128 -> 0.5342493892960248 on epoch=12, global_step=100
05/22/2022 18:12:19 - INFO - __main__ - Step 110 Global step 110 Train loss 0.91 on epoch=13
05/22/2022 18:12:21 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=14
05/22/2022 18:12:24 - INFO - __main__ - Step 130 Global step 130 Train loss 0.88 on epoch=16
05/22/2022 18:12:26 - INFO - __main__ - Step 140 Global step 140 Train loss 0.76 on epoch=17
05/22/2022 18:12:29 - INFO - __main__ - Step 150 Global step 150 Train loss 0.74 on epoch=18
05/22/2022 18:12:30 - INFO - __main__ - Global step 150 Train loss 0.82 Classification-F1 0.5678643238045284 on epoch=18
05/22/2022 18:12:30 - INFO - __main__ - Saving model with best Classification-F1: 0.5342493892960248 -> 0.5678643238045284 on epoch=18, global_step=150
05/22/2022 18:12:33 - INFO - __main__ - Step 160 Global step 160 Train loss 0.80 on epoch=19
05/22/2022 18:12:35 - INFO - __main__ - Step 170 Global step 170 Train loss 0.67 on epoch=21
05/22/2022 18:12:38 - INFO - __main__ - Step 180 Global step 180 Train loss 0.60 on epoch=22
05/22/2022 18:12:40 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=23
05/22/2022 18:12:42 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=24
05/22/2022 18:12:44 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5858770059477051 on epoch=24
05/22/2022 18:12:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5678643238045284 -> 0.5858770059477051 on epoch=24, global_step=200
05/22/2022 18:12:47 - INFO - __main__ - Step 210 Global step 210 Train loss 0.70 on epoch=26
05/22/2022 18:12:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=27
05/22/2022 18:12:52 - INFO - __main__ - Step 230 Global step 230 Train loss 0.73 on epoch=28
05/22/2022 18:12:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=29
05/22/2022 18:12:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.75 on epoch=31
05/22/2022 18:12:58 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.6210745660887089 on epoch=31
05/22/2022 18:12:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5858770059477051 -> 0.6210745660887089 on epoch=31, global_step=250
05/22/2022 18:13:01 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=32
05/22/2022 18:13:03 - INFO - __main__ - Step 270 Global step 270 Train loss 0.69 on epoch=33
05/22/2022 18:13:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.56 on epoch=34
05/22/2022 18:13:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.57 on epoch=36
05/22/2022 18:13:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.60 on epoch=37
05/22/2022 18:13:12 - INFO - __main__ - Global step 300 Train loss 0.60 Classification-F1 0.6349891726270701 on epoch=37
05/22/2022 18:13:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6210745660887089 -> 0.6349891726270701 on epoch=37, global_step=300
05/22/2022 18:13:15 - INFO - __main__ - Step 310 Global step 310 Train loss 0.67 on epoch=38
05/22/2022 18:13:17 - INFO - __main__ - Step 320 Global step 320 Train loss 0.65 on epoch=39
05/22/2022 18:13:19 - INFO - __main__ - Step 330 Global step 330 Train loss 0.55 on epoch=41
05/22/2022 18:13:22 - INFO - __main__ - Step 340 Global step 340 Train loss 0.60 on epoch=42
05/22/2022 18:13:24 - INFO - __main__ - Step 350 Global step 350 Train loss 0.61 on epoch=43
05/22/2022 18:13:26 - INFO - __main__ - Global step 350 Train loss 0.62 Classification-F1 0.6807845463536842 on epoch=43
05/22/2022 18:13:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6349891726270701 -> 0.6807845463536842 on epoch=43, global_step=350
05/22/2022 18:13:29 - INFO - __main__ - Step 360 Global step 360 Train loss 0.54 on epoch=44
05/22/2022 18:13:31 - INFO - __main__ - Step 370 Global step 370 Train loss 0.58 on epoch=46
05/22/2022 18:13:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.54 on epoch=47
05/22/2022 18:13:36 - INFO - __main__ - Step 390 Global step 390 Train loss 0.61 on epoch=48
05/22/2022 18:13:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.55 on epoch=49
05/22/2022 18:13:40 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.6997059199590845 on epoch=49
05/22/2022 18:13:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6807845463536842 -> 0.6997059199590845 on epoch=49, global_step=400
05/22/2022 18:13:42 - INFO - __main__ - Step 410 Global step 410 Train loss 0.52 on epoch=51
05/22/2022 18:13:45 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=52
05/22/2022 18:13:47 - INFO - __main__ - Step 430 Global step 430 Train loss 0.52 on epoch=53
05/22/2022 18:13:50 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=54
05/22/2022 18:13:52 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=56
05/22/2022 18:13:54 - INFO - __main__ - Global step 450 Train loss 0.48 Classification-F1 0.7064688213941945 on epoch=56
05/22/2022 18:13:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6997059199590845 -> 0.7064688213941945 on epoch=56, global_step=450
05/22/2022 18:13:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.47 on epoch=57
05/22/2022 18:13:59 - INFO - __main__ - Step 470 Global step 470 Train loss 0.45 on epoch=58
05/22/2022 18:14:01 - INFO - __main__ - Step 480 Global step 480 Train loss 0.40 on epoch=59
05/22/2022 18:14:04 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=61
05/22/2022 18:14:06 - INFO - __main__ - Step 500 Global step 500 Train loss 0.44 on epoch=62
05/22/2022 18:14:08 - INFO - __main__ - Global step 500 Train loss 0.43 Classification-F1 0.723965744400527 on epoch=62
05/22/2022 18:14:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7064688213941945 -> 0.723965744400527 on epoch=62, global_step=500
05/22/2022 18:14:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.47 on epoch=63
05/22/2022 18:14:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.42 on epoch=64
05/22/2022 18:14:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.38 on epoch=66
05/22/2022 18:14:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.37 on epoch=67
05/22/2022 18:14:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.54 on epoch=68
05/22/2022 18:14:22 - INFO - __main__ - Global step 550 Train loss 0.44 Classification-F1 0.7349756872791101 on epoch=68
05/22/2022 18:14:22 - INFO - __main__ - Saving model with best Classification-F1: 0.723965744400527 -> 0.7349756872791101 on epoch=68, global_step=550
05/22/2022 18:14:25 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=69
05/22/2022 18:14:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.49 on epoch=71
05/22/2022 18:14:30 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=72
05/22/2022 18:14:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=73
05/22/2022 18:14:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.33 on epoch=74
05/22/2022 18:14:36 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.7388611388611388 on epoch=74
05/22/2022 18:14:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7349756872791101 -> 0.7388611388611388 on epoch=74, global_step=600
05/22/2022 18:14:39 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=76
05/22/2022 18:14:41 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=77
05/22/2022 18:14:43 - INFO - __main__ - Step 630 Global step 630 Train loss 0.35 on epoch=78
05/22/2022 18:14:46 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=79
05/22/2022 18:14:48 - INFO - __main__ - Step 650 Global step 650 Train loss 0.35 on epoch=81
05/22/2022 18:14:50 - INFO - __main__ - Global step 650 Train loss 0.35 Classification-F1 0.719967320261438 on epoch=81
05/22/2022 18:14:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=82
05/22/2022 18:14:55 - INFO - __main__ - Step 670 Global step 670 Train loss 0.42 on epoch=83
05/22/2022 18:14:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=84
05/22/2022 18:15:00 - INFO - __main__ - Step 690 Global step 690 Train loss 0.40 on epoch=86
05/22/2022 18:15:02 - INFO - __main__ - Step 700 Global step 700 Train loss 0.33 on epoch=87
05/22/2022 18:15:04 - INFO - __main__ - Global step 700 Train loss 0.36 Classification-F1 0.7303422007406549 on epoch=87
05/22/2022 18:15:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.38 on epoch=88
05/22/2022 18:15:09 - INFO - __main__ - Step 720 Global step 720 Train loss 0.31 on epoch=89
05/22/2022 18:15:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=91
05/22/2022 18:15:14 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=92
05/22/2022 18:15:17 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=93
05/22/2022 18:15:19 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.8089987037610277 on epoch=93
05/22/2022 18:15:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7388611388611388 -> 0.8089987037610277 on epoch=93, global_step=750
05/22/2022 18:15:21 - INFO - __main__ - Step 760 Global step 760 Train loss 0.33 on epoch=94
05/22/2022 18:15:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.35 on epoch=96
05/22/2022 18:15:26 - INFO - __main__ - Step 780 Global step 780 Train loss 0.24 on epoch=97
05/22/2022 18:15:28 - INFO - __main__ - Step 790 Global step 790 Train loss 0.37 on epoch=98
05/22/2022 18:15:31 - INFO - __main__ - Step 800 Global step 800 Train loss 0.26 on epoch=99
05/22/2022 18:15:33 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.7791726743251431 on epoch=99
05/22/2022 18:15:35 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=101
05/22/2022 18:15:38 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=102
05/22/2022 18:15:40 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=103
05/22/2022 18:15:43 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=104
05/22/2022 18:15:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=106
05/22/2022 18:15:47 - INFO - __main__ - Global step 850 Train loss 0.26 Classification-F1 0.7907033395340597 on epoch=106
05/22/2022 18:15:49 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=107
05/22/2022 18:15:52 - INFO - __main__ - Step 870 Global step 870 Train loss 0.23 on epoch=108
05/22/2022 18:15:54 - INFO - __main__ - Step 880 Global step 880 Train loss 0.26 on epoch=109
05/22/2022 18:15:56 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=111
05/22/2022 18:15:59 - INFO - __main__ - Step 900 Global step 900 Train loss 0.25 on epoch=112
05/22/2022 18:16:01 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.7948254730087028 on epoch=112
05/22/2022 18:16:03 - INFO - __main__ - Step 910 Global step 910 Train loss 0.45 on epoch=113
05/22/2022 18:16:06 - INFO - __main__ - Step 920 Global step 920 Train loss 0.28 on epoch=114
05/22/2022 18:16:08 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=116
05/22/2022 18:16:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=117
05/22/2022 18:16:13 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=118
05/22/2022 18:16:15 - INFO - __main__ - Global step 950 Train loss 0.29 Classification-F1 0.826867265267689 on epoch=118
05/22/2022 18:16:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8089987037610277 -> 0.826867265267689 on epoch=118, global_step=950
05/22/2022 18:16:17 - INFO - __main__ - Step 960 Global step 960 Train loss 0.26 on epoch=119
05/22/2022 18:16:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.28 on epoch=121
05/22/2022 18:16:22 - INFO - __main__ - Step 980 Global step 980 Train loss 0.22 on epoch=122
05/22/2022 18:16:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.25 on epoch=123
05/22/2022 18:16:27 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=124
05/22/2022 18:16:29 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.8087912087912088 on epoch=124
05/22/2022 18:16:31 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
05/22/2022 18:16:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=127
05/22/2022 18:16:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=128
05/22/2022 18:16:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=129
05/22/2022 18:16:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=131
05/22/2022 18:16:43 - INFO - __main__ - Global step 1050 Train loss 0.20 Classification-F1 0.8148375768217735 on epoch=131
05/22/2022 18:16:46 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.20 on epoch=132
05/22/2022 18:16:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.29 on epoch=133
05/22/2022 18:16:51 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=134
05/22/2022 18:16:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.21 on epoch=136
05/22/2022 18:16:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=137
05/22/2022 18:16:57 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.8053848405033656 on epoch=137
05/22/2022 18:17:00 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=138
05/22/2022 18:17:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.23 on epoch=139
05/22/2022 18:17:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=141
05/22/2022 18:17:07 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
05/22/2022 18:17:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=143
05/22/2022 18:17:11 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.8405635482938115 on epoch=143
05/22/2022 18:17:11 - INFO - __main__ - Saving model with best Classification-F1: 0.826867265267689 -> 0.8405635482938115 on epoch=143, global_step=1150
05/22/2022 18:17:14 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=144
05/22/2022 18:17:16 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=146
05/22/2022 18:17:19 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=147
05/22/2022 18:17:21 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.23 on epoch=148
05/22/2022 18:17:23 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=149
05/22/2022 18:17:25 - INFO - __main__ - Global step 1200 Train loss 0.23 Classification-F1 0.8260283777525158 on epoch=149
05/22/2022 18:17:28 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=151
05/22/2022 18:17:30 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=152
05/22/2022 18:17:33 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.20 on epoch=153
05/22/2022 18:17:35 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=154
05/22/2022 18:17:38 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.23 on epoch=156
05/22/2022 18:17:39 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.8468474659512396 on epoch=156
05/22/2022 18:17:39 - INFO - __main__ - Saving model with best Classification-F1: 0.8405635482938115 -> 0.8468474659512396 on epoch=156, global_step=1250
05/22/2022 18:17:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=157
05/22/2022 18:17:44 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.20 on epoch=158
05/22/2022 18:17:47 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=159
05/22/2022 18:17:49 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.23 on epoch=161
05/22/2022 18:17:52 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=162
05/22/2022 18:17:53 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.8557955906705117 on epoch=162
05/22/2022 18:17:53 - INFO - __main__ - Saving model with best Classification-F1: 0.8468474659512396 -> 0.8557955906705117 on epoch=162, global_step=1300
05/22/2022 18:17:56 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=163
05/22/2022 18:17:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.23 on epoch=164
05/22/2022 18:18:01 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=166
05/22/2022 18:18:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=167
05/22/2022 18:18:06 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=168
05/22/2022 18:18:08 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.8333971995825716 on epoch=168
05/22/2022 18:18:10 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.12 on epoch=169
05/22/2022 18:18:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.24 on epoch=171
05/22/2022 18:18:15 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.08 on epoch=172
05/22/2022 18:18:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.18 on epoch=173
05/22/2022 18:18:20 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.14 on epoch=174
05/22/2022 18:18:22 - INFO - __main__ - Global step 1400 Train loss 0.15 Classification-F1 0.840975151416829 on epoch=174
05/22/2022 18:18:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=176
05/22/2022 18:18:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=177
05/22/2022 18:18:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=178
05/22/2022 18:18:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.07 on epoch=179
05/22/2022 18:18:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=181
05/22/2022 18:18:36 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.8409606527491678 on epoch=181
05/22/2022 18:18:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
05/22/2022 18:18:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=183
05/22/2022 18:18:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=184
05/22/2022 18:18:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
05/22/2022 18:18:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=187
05/22/2022 18:18:50 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.8406435763941659 on epoch=187
05/22/2022 18:18:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.16 on epoch=188
05/22/2022 18:18:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=189
05/22/2022 18:18:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.17 on epoch=191
05/22/2022 18:19:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=192
05/22/2022 18:19:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=193
05/22/2022 18:19:04 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.8408464174827591 on epoch=193
05/22/2022 18:19:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.13 on epoch=194
05/22/2022 18:19:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=196
05/22/2022 18:19:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=197
05/22/2022 18:19:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
05/22/2022 18:19:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.16 on epoch=199
05/22/2022 18:19:18 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.8334979661820036 on epoch=199
05/22/2022 18:19:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.16 on epoch=201
05/22/2022 18:19:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=202
05/22/2022 18:19:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.18 on epoch=203
05/22/2022 18:19:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
05/22/2022 18:19:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=206
05/22/2022 18:19:32 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.8341573252122076 on epoch=206
05/22/2022 18:19:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=207
05/22/2022 18:19:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.08 on epoch=208
05/22/2022 18:19:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.14 on epoch=209
05/22/2022 18:19:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=211
05/22/2022 18:19:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
05/22/2022 18:19:46 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.8336330994889616 on epoch=212
05/22/2022 18:19:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=213
05/22/2022 18:19:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=214
05/22/2022 18:19:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=216
05/22/2022 18:19:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
05/22/2022 18:19:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
05/22/2022 18:20:01 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8324223462550326 on epoch=218
05/22/2022 18:20:03 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=219
05/22/2022 18:20:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=221
05/22/2022 18:20:08 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=222
05/22/2022 18:20:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
05/22/2022 18:20:13 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=224
05/22/2022 18:20:15 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.8496069436367943 on epoch=224
05/22/2022 18:20:17 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=226
05/22/2022 18:20:20 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=227
05/22/2022 18:20:22 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=228
05/22/2022 18:20:25 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
05/22/2022 18:20:27 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.11 on epoch=231
05/22/2022 18:20:29 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.8568979155875184 on epoch=231
05/22/2022 18:20:29 - INFO - __main__ - Saving model with best Classification-F1: 0.8557955906705117 -> 0.8568979155875184 on epoch=231, global_step=1850
05/22/2022 18:20:31 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=232
05/22/2022 18:20:34 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.10 on epoch=233
05/22/2022 18:20:36 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
05/22/2022 18:20:39 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=236
05/22/2022 18:20:41 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.09 on epoch=237
05/22/2022 18:20:43 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.8345716080769119 on epoch=237
05/22/2022 18:20:46 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=238
05/22/2022 18:20:48 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=239
05/22/2022 18:20:51 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
05/22/2022 18:20:53 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.06 on epoch=242
05/22/2022 18:20:56 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=243
05/22/2022 18:20:58 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.8554248480817012 on epoch=243
05/22/2022 18:21:00 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
05/22/2022 18:21:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=246
05/22/2022 18:21:05 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
05/22/2022 18:21:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.11 on epoch=248
05/22/2022 18:21:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
05/22/2022 18:21:12 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.8467197579627235 on epoch=249
05/22/2022 18:21:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
05/22/2022 18:21:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
05/22/2022 18:21:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
05/22/2022 18:21:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=254
05/22/2022 18:21:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
05/22/2022 18:21:26 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.8467197579627235 on epoch=256
05/22/2022 18:21:29 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=257
05/22/2022 18:21:31 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=258
05/22/2022 18:21:34 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.11 on epoch=259
05/22/2022 18:21:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=261
05/22/2022 18:21:39 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=262
05/22/2022 18:21:40 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.8481993586592297 on epoch=262
05/22/2022 18:21:43 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
05/22/2022 18:21:45 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.09 on epoch=264
05/22/2022 18:21:48 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
05/22/2022 18:21:50 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=267
05/22/2022 18:21:53 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=268
05/22/2022 18:21:55 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.8390915299804639 on epoch=268
05/22/2022 18:21:57 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.15 on epoch=269
05/22/2022 18:22:00 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
05/22/2022 18:22:02 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.07 on epoch=272
05/22/2022 18:22:05 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
05/22/2022 18:22:07 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.12 on epoch=274
05/22/2022 18:22:09 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.8554248480817012 on epoch=274
05/22/2022 18:22:11 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=276
05/22/2022 18:22:14 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
05/22/2022 18:22:16 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
05/22/2022 18:22:19 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=279
05/22/2022 18:22:21 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=281
05/22/2022 18:22:23 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.8313060897435898 on epoch=281
05/22/2022 18:22:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
05/22/2022 18:22:28 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.11 on epoch=283
05/22/2022 18:22:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=284
05/22/2022 18:22:33 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=286
05/22/2022 18:22:35 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=287
05/22/2022 18:22:37 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.8371262279712983 on epoch=287
05/22/2022 18:22:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=288
05/22/2022 18:22:42 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
05/22/2022 18:22:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
05/22/2022 18:22:47 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=292
05/22/2022 18:22:49 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=293
05/22/2022 18:22:51 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.8296772645521857 on epoch=293
05/22/2022 18:22:54 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
05/22/2022 18:22:56 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
05/22/2022 18:22:59 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
05/22/2022 18:23:01 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
05/22/2022 18:23:04 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
05/22/2022 18:23:05 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.8641485534289132 on epoch=299
05/22/2022 18:23:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8568979155875184 -> 0.8641485534289132 on epoch=299, global_step=2400
05/22/2022 18:23:08 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=301
05/22/2022 18:23:10 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=302
05/22/2022 18:23:13 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
05/22/2022 18:23:15 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=304
05/22/2022 18:23:18 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 18:23:20 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.8554947976000608 on epoch=306
05/22/2022 18:23:22 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=307
05/22/2022 18:23:25 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=308
05/22/2022 18:23:27 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
05/22/2022 18:23:30 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=311
05/22/2022 18:23:32 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=312
05/22/2022 18:23:34 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.8554248480817012 on epoch=312
05/22/2022 18:23:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=313
05/22/2022 18:23:39 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=314
05/22/2022 18:23:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=316
05/22/2022 18:23:44 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.07 on epoch=317
05/22/2022 18:23:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=318
05/22/2022 18:23:48 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.8478506589857728 on epoch=318
05/22/2022 18:23:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
05/22/2022 18:23:53 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.13 on epoch=321
05/22/2022 18:23:56 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
05/22/2022 18:23:58 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
05/22/2022 18:24:01 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=324
05/22/2022 18:24:02 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.8492532753208837 on epoch=324
05/22/2022 18:24:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 18:24:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=327
05/22/2022 18:24:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
05/22/2022 18:24:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.07 on epoch=329
05/22/2022 18:24:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
05/22/2022 18:24:16 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8570044662945946 on epoch=331
05/22/2022 18:24:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=332
05/22/2022 18:24:21 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=333
05/22/2022 18:24:24 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=334
05/22/2022 18:24:26 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
05/22/2022 18:24:29 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
05/22/2022 18:24:31 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8482413576260239 on epoch=337
05/22/2022 18:24:33 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 18:24:36 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 18:24:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
05/22/2022 18:24:41 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
05/22/2022 18:24:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 18:24:45 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8493088555401616 on epoch=343
05/22/2022 18:24:48 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
05/22/2022 18:24:50 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=346
05/22/2022 18:24:52 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
05/22/2022 18:24:55 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
05/22/2022 18:24:57 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=349
05/22/2022 18:24:59 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8492532753208837 on epoch=349
05/22/2022 18:25:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=351
05/22/2022 18:25:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 18:25:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
05/22/2022 18:25:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=354
05/22/2022 18:25:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 18:25:14 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.8568979155875184 on epoch=356
05/22/2022 18:25:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=357
05/22/2022 18:25:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=358
05/22/2022 18:25:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
05/22/2022 18:25:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 18:25:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=362
05/22/2022 18:25:28 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.8418831168831169 on epoch=362
05/22/2022 18:25:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 18:25:33 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
05/22/2022 18:25:35 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 18:25:38 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
05/22/2022 18:25:40 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
05/22/2022 18:25:42 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.849493872628201 on epoch=368
05/22/2022 18:25:45 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
05/22/2022 18:25:47 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 18:25:50 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 18:25:52 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
05/22/2022 18:25:55 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
05/22/2022 18:25:56 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:25:56 - INFO - __main__ - Printing 3 examples
05/22/2022 18:25:56 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:25:56 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:25:56 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:25:56 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:25:56 - INFO - __main__ - Printing 3 examples
05/22/2022 18:25:56 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 18:25:56 - INFO - __main__ - ['others']
05/22/2022 18:25:56 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:25:56 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:25:56 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:25:57 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8554248480817012 on epoch=374
05/22/2022 18:25:57 - INFO - __main__ - save last model!
05/22/2022 18:25:57 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:25:57 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 18:25:57 - INFO - __main__ - Printing 3 examples
05/22/2022 18:25:57 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 18:25:57 - INFO - __main__ - ['others']
05/22/2022 18:25:57 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 18:25:57 - INFO - __main__ - ['others']
05/22/2022 18:25:57 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 18:25:57 - INFO - __main__ - ['others']
05/22/2022 18:25:57 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:25:59 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:26:04 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 18:26:15 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:26:15 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:26:15 - INFO - __main__ - Starting training!
05/22/2022 18:27:21 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_100_0.3_8_predictions.txt
05/22/2022 18:27:21 - INFO - __main__ - Classification-F1 on test data: 0.3875
05/22/2022 18:27:22 - INFO - __main__ - prefix=emo_32_100, lr=0.3, bsz=8, dev_performance=0.8641485534289132, test_performance=0.3874811760545804
05/22/2022 18:27:22 - INFO - __main__ - Running ... prefix=emo_32_100, lr=0.2, bsz=8 ...
05/22/2022 18:27:22 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:27:22 - INFO - __main__ - Printing 3 examples
05/22/2022 18:27:22 - INFO - __main__ -  [emo] how cause yes am listening
05/22/2022 18:27:22 - INFO - __main__ - ['others']
05/22/2022 18:27:22 - INFO - __main__ -  [emo] ok that way i like living wwrong
05/22/2022 18:27:22 - INFO - __main__ - ['others']
05/22/2022 18:27:22 - INFO - __main__ -  [emo] as u feel to on ur mind depends whose mind your mindn
05/22/2022 18:27:22 - INFO - __main__ - ['others']
05/22/2022 18:27:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:27:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:27:23 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:27:23 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:27:23 - INFO - __main__ - Printing 3 examples
05/22/2022 18:27:23 - INFO - __main__ -  [emo] do you like chicken who calls it soya chicken anyways  what i'm asking
05/22/2022 18:27:23 - INFO - __main__ - ['others']
05/22/2022 18:27:23 - INFO - __main__ -  [emo] i will i don't want to lose my bestie because i did not ask u wgere u r from
05/22/2022 18:27:23 - INFO - __main__ - ['others']
05/22/2022 18:27:23 - INFO - __main__ -  [emo] author name like that give me a description or summary hey that is author name yar
05/22/2022 18:27:23 - INFO - __main__ - ['others']
05/22/2022 18:27:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:27:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:27:23 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:27:38 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:27:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:27:39 - INFO - __main__ - Starting training!
05/22/2022 18:27:42 - INFO - __main__ - Step 10 Global step 10 Train loss 4.61 on epoch=1
05/22/2022 18:27:44 - INFO - __main__ - Step 20 Global step 20 Train loss 3.55 on epoch=2
05/22/2022 18:27:47 - INFO - __main__ - Step 30 Global step 30 Train loss 2.96 on epoch=3
05/22/2022 18:27:49 - INFO - __main__ - Step 40 Global step 40 Train loss 2.65 on epoch=4
05/22/2022 18:27:51 - INFO - __main__ - Step 50 Global step 50 Train loss 2.57 on epoch=6
05/22/2022 18:27:53 - INFO - __main__ - Global step 50 Train loss 3.27 Classification-F1 0.03674242424242424 on epoch=6
05/22/2022 18:27:54 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03674242424242424 on epoch=6, global_step=50
05/22/2022 18:27:56 - INFO - __main__ - Step 60 Global step 60 Train loss 2.18 on epoch=7
05/22/2022 18:27:58 - INFO - __main__ - Step 70 Global step 70 Train loss 2.09 on epoch=8
05/22/2022 18:28:01 - INFO - __main__ - Step 80 Global step 80 Train loss 1.91 on epoch=9
05/22/2022 18:28:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.81 on epoch=11
05/22/2022 18:28:06 - INFO - __main__ - Step 100 Global step 100 Train loss 1.54 on epoch=12
05/22/2022 18:28:08 - INFO - __main__ - Global step 100 Train loss 1.91 Classification-F1 0.16786470222037767 on epoch=12
05/22/2022 18:28:08 - INFO - __main__ - Saving model with best Classification-F1: 0.03674242424242424 -> 0.16786470222037767 on epoch=12, global_step=100
05/22/2022 18:28:10 - INFO - __main__ - Step 110 Global step 110 Train loss 1.48 on epoch=13
05/22/2022 18:28:12 - INFO - __main__ - Step 120 Global step 120 Train loss 1.31 on epoch=14
05/22/2022 18:28:15 - INFO - __main__ - Step 130 Global step 130 Train loss 1.34 on epoch=16
05/22/2022 18:28:17 - INFO - __main__ - Step 140 Global step 140 Train loss 1.06 on epoch=17
05/22/2022 18:28:20 - INFO - __main__ - Step 150 Global step 150 Train loss 1.08 on epoch=18
05/22/2022 18:28:21 - INFO - __main__ - Global step 150 Train loss 1.25 Classification-F1 0.5049189814814814 on epoch=18
05/22/2022 18:28:22 - INFO - __main__ - Saving model with best Classification-F1: 0.16786470222037767 -> 0.5049189814814814 on epoch=18, global_step=150
05/22/2022 18:28:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.98 on epoch=19
05/22/2022 18:28:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=21
05/22/2022 18:28:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.90 on epoch=22
05/22/2022 18:28:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.91 on epoch=23
05/22/2022 18:28:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=24
05/22/2022 18:28:35 - INFO - __main__ - Global step 200 Train loss 0.89 Classification-F1 0.5595226615236258 on epoch=24
05/22/2022 18:28:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5049189814814814 -> 0.5595226615236258 on epoch=24, global_step=200
05/22/2022 18:28:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=26
05/22/2022 18:28:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.89 on epoch=27
05/22/2022 18:28:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.85 on epoch=28
05/22/2022 18:28:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.63 on epoch=29
05/22/2022 18:28:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.87 on epoch=31
05/22/2022 18:28:49 - INFO - __main__ - Global step 250 Train loss 0.82 Classification-F1 0.5741452991452991 on epoch=31
05/22/2022 18:28:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5595226615236258 -> 0.5741452991452991 on epoch=31, global_step=250
05/22/2022 18:28:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.74 on epoch=32
05/22/2022 18:28:54 - INFO - __main__ - Step 270 Global step 270 Train loss 0.81 on epoch=33
05/22/2022 18:28:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.85 on epoch=34
05/22/2022 18:28:59 - INFO - __main__ - Step 290 Global step 290 Train loss 0.65 on epoch=36
05/22/2022 18:29:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=37
05/22/2022 18:29:04 - INFO - __main__ - Global step 300 Train loss 0.74 Classification-F1 0.6000288291954958 on epoch=37
05/22/2022 18:29:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5741452991452991 -> 0.6000288291954958 on epoch=37, global_step=300
05/22/2022 18:29:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=38
05/22/2022 18:29:08 - INFO - __main__ - Step 320 Global step 320 Train loss 0.74 on epoch=39
05/22/2022 18:29:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.67 on epoch=41
05/22/2022 18:29:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.64 on epoch=42
05/22/2022 18:29:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.73 on epoch=43
05/22/2022 18:29:17 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.6084529505582137 on epoch=43
05/22/2022 18:29:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6000288291954958 -> 0.6084529505582137 on epoch=43, global_step=350
05/22/2022 18:29:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=44
05/22/2022 18:29:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.63 on epoch=46
05/22/2022 18:29:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.65 on epoch=47
05/22/2022 18:29:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.68 on epoch=48
05/22/2022 18:29:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.61 on epoch=49
05/22/2022 18:29:31 - INFO - __main__ - Global step 400 Train loss 0.61 Classification-F1 0.5996095084375214 on epoch=49
05/22/2022 18:29:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.73 on epoch=51
05/22/2022 18:29:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=52
05/22/2022 18:29:39 - INFO - __main__ - Step 430 Global step 430 Train loss 0.57 on epoch=53
05/22/2022 18:29:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.59 on epoch=54
05/22/2022 18:29:44 - INFO - __main__ - Step 450 Global step 450 Train loss 0.67 on epoch=56
05/22/2022 18:29:45 - INFO - __main__ - Global step 450 Train loss 0.61 Classification-F1 0.649547580707001 on epoch=56
05/22/2022 18:29:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6084529505582137 -> 0.649547580707001 on epoch=56, global_step=450
05/22/2022 18:29:48 - INFO - __main__ - Step 460 Global step 460 Train loss 0.60 on epoch=57
05/22/2022 18:29:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.67 on epoch=58
05/22/2022 18:29:53 - INFO - __main__ - Step 480 Global step 480 Train loss 0.63 on epoch=59
05/22/2022 18:29:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.53 on epoch=61
05/22/2022 18:29:58 - INFO - __main__ - Step 500 Global step 500 Train loss 0.55 on epoch=62
05/22/2022 18:29:59 - INFO - __main__ - Global step 500 Train loss 0.60 Classification-F1 0.6978414279784142 on epoch=62
05/22/2022 18:29:59 - INFO - __main__ - Saving model with best Classification-F1: 0.649547580707001 -> 0.6978414279784142 on epoch=62, global_step=500
05/22/2022 18:30:02 - INFO - __main__ - Step 510 Global step 510 Train loss 0.63 on epoch=63
05/22/2022 18:30:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.63 on epoch=64
05/22/2022 18:30:07 - INFO - __main__ - Step 530 Global step 530 Train loss 0.55 on epoch=66
05/22/2022 18:30:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.43 on epoch=67
05/22/2022 18:30:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.62 on epoch=68
05/22/2022 18:30:13 - INFO - __main__ - Global step 550 Train loss 0.57 Classification-F1 0.6873963522208385 on epoch=68
05/22/2022 18:30:16 - INFO - __main__ - Step 560 Global step 560 Train loss 0.48 on epoch=69
05/22/2022 18:30:18 - INFO - __main__ - Step 570 Global step 570 Train loss 0.66 on epoch=71
05/22/2022 18:30:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.48 on epoch=72
05/22/2022 18:30:23 - INFO - __main__ - Step 590 Global step 590 Train loss 0.53 on epoch=73
05/22/2022 18:30:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.58 on epoch=74
05/22/2022 18:30:27 - INFO - __main__ - Global step 600 Train loss 0.55 Classification-F1 0.682599826237154 on epoch=74
05/22/2022 18:30:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.56 on epoch=76
05/22/2022 18:30:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=77
05/22/2022 18:30:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.57 on epoch=78
05/22/2022 18:30:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.46 on epoch=79
05/22/2022 18:30:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.51 on epoch=81
05/22/2022 18:30:41 - INFO - __main__ - Global step 650 Train loss 0.51 Classification-F1 0.7141034763781443 on epoch=81
05/22/2022 18:30:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6978414279784142 -> 0.7141034763781443 on epoch=81, global_step=650
05/22/2022 18:30:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.49 on epoch=82
05/22/2022 18:30:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.50 on epoch=83
05/22/2022 18:30:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.44 on epoch=84
05/22/2022 18:30:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.52 on epoch=86
05/22/2022 18:30:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.44 on epoch=87
05/22/2022 18:30:55 - INFO - __main__ - Global step 700 Train loss 0.48 Classification-F1 0.6991467469728339 on epoch=87
05/22/2022 18:30:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=88
05/22/2022 18:31:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.51 on epoch=89
05/22/2022 18:31:03 - INFO - __main__ - Step 730 Global step 730 Train loss 0.45 on epoch=91
05/22/2022 18:31:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=92
05/22/2022 18:31:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.45 on epoch=93
05/22/2022 18:31:10 - INFO - __main__ - Global step 750 Train loss 0.44 Classification-F1 0.7279282987894535 on epoch=93
05/22/2022 18:31:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7141034763781443 -> 0.7279282987894535 on epoch=93, global_step=750
05/22/2022 18:31:12 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=94
05/22/2022 18:31:15 - INFO - __main__ - Step 770 Global step 770 Train loss 0.38 on epoch=96
05/22/2022 18:31:17 - INFO - __main__ - Step 780 Global step 780 Train loss 0.42 on epoch=97
05/22/2022 18:31:20 - INFO - __main__ - Step 790 Global step 790 Train loss 0.45 on epoch=98
05/22/2022 18:31:22 - INFO - __main__ - Step 800 Global step 800 Train loss 0.46 on epoch=99
05/22/2022 18:31:24 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.7453927627161323 on epoch=99
05/22/2022 18:31:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7279282987894535 -> 0.7453927627161323 on epoch=99, global_step=800
05/22/2022 18:31:27 - INFO - __main__ - Step 810 Global step 810 Train loss 0.46 on epoch=101
05/22/2022 18:31:29 - INFO - __main__ - Step 820 Global step 820 Train loss 0.37 on epoch=102
05/22/2022 18:31:32 - INFO - __main__ - Step 830 Global step 830 Train loss 0.46 on epoch=103
05/22/2022 18:31:34 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=104
05/22/2022 18:31:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.39 on epoch=106
05/22/2022 18:31:38 - INFO - __main__ - Global step 850 Train loss 0.41 Classification-F1 0.770955710955711 on epoch=106
05/22/2022 18:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7453927627161323 -> 0.770955710955711 on epoch=106, global_step=850
05/22/2022 18:31:41 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=107
05/22/2022 18:31:43 - INFO - __main__ - Step 870 Global step 870 Train loss 0.35 on epoch=108
05/22/2022 18:31:46 - INFO - __main__ - Step 880 Global step 880 Train loss 0.40 on epoch=109
05/22/2022 18:31:48 - INFO - __main__ - Step 890 Global step 890 Train loss 0.37 on epoch=111
05/22/2022 18:31:51 - INFO - __main__ - Step 900 Global step 900 Train loss 0.39 on epoch=112
05/22/2022 18:31:53 - INFO - __main__ - Global step 900 Train loss 0.37 Classification-F1 0.7742636373798344 on epoch=112
05/22/2022 18:31:53 - INFO - __main__ - Saving model with best Classification-F1: 0.770955710955711 -> 0.7742636373798344 on epoch=112, global_step=900
05/22/2022 18:31:55 - INFO - __main__ - Step 910 Global step 910 Train loss 0.42 on epoch=113
05/22/2022 18:31:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.33 on epoch=114
05/22/2022 18:32:00 - INFO - __main__ - Step 930 Global step 930 Train loss 0.36 on epoch=116
05/22/2022 18:32:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.39 on epoch=117
05/22/2022 18:32:05 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=118
05/22/2022 18:32:07 - INFO - __main__ - Global step 950 Train loss 0.37 Classification-F1 0.7949590615231599 on epoch=118
05/22/2022 18:32:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7742636373798344 -> 0.7949590615231599 on epoch=118, global_step=950
05/22/2022 18:32:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.31 on epoch=119
05/22/2022 18:32:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.47 on epoch=121
05/22/2022 18:32:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.33 on epoch=122
05/22/2022 18:32:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.43 on epoch=123
05/22/2022 18:32:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=124
05/22/2022 18:32:21 - INFO - __main__ - Global step 1000 Train loss 0.37 Classification-F1 0.7870532245532246 on epoch=124
05/22/2022 18:32:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.42 on epoch=126
05/22/2022 18:32:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=127
05/22/2022 18:32:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.32 on epoch=128
05/22/2022 18:32:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.33 on epoch=129
05/22/2022 18:32:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.39 on epoch=131
05/22/2022 18:32:36 - INFO - __main__ - Global step 1050 Train loss 0.36 Classification-F1 0.816066578879276 on epoch=131
05/22/2022 18:32:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7949590615231599 -> 0.816066578879276 on epoch=131, global_step=1050
05/22/2022 18:32:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.34 on epoch=132
05/22/2022 18:32:41 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.34 on epoch=133
05/22/2022 18:32:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.28 on epoch=134
05/22/2022 18:32:46 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.25 on epoch=136
05/22/2022 18:32:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
05/22/2022 18:32:50 - INFO - __main__ - Global step 1100 Train loss 0.30 Classification-F1 0.8092802971676212 on epoch=137
05/22/2022 18:32:53 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.35 on epoch=138
05/22/2022 18:32:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=139
05/22/2022 18:32:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.30 on epoch=141
05/22/2022 18:33:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.29 on epoch=142
05/22/2022 18:33:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.36 on epoch=143
05/22/2022 18:33:04 - INFO - __main__ - Global step 1150 Train loss 0.31 Classification-F1 0.8141131815044858 on epoch=143
05/22/2022 18:33:07 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.28 on epoch=144
05/22/2022 18:33:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.26 on epoch=146
05/22/2022 18:33:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.32 on epoch=147
05/22/2022 18:33:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.31 on epoch=148
05/22/2022 18:33:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.27 on epoch=149
05/22/2022 18:33:19 - INFO - __main__ - Global step 1200 Train loss 0.29 Classification-F1 0.8238860251482971 on epoch=149
05/22/2022 18:33:19 - INFO - __main__ - Saving model with best Classification-F1: 0.816066578879276 -> 0.8238860251482971 on epoch=149, global_step=1200
05/22/2022 18:33:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.28 on epoch=151
05/22/2022 18:33:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=152
05/22/2022 18:33:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.35 on epoch=153
05/22/2022 18:33:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.31 on epoch=154
05/22/2022 18:33:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.25 on epoch=156
05/22/2022 18:33:33 - INFO - __main__ - Global step 1250 Train loss 0.29 Classification-F1 0.8414617157116039 on epoch=156
05/22/2022 18:33:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8238860251482971 -> 0.8414617157116039 on epoch=156, global_step=1250
05/22/2022 18:33:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.27 on epoch=157
05/22/2022 18:33:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=158
05/22/2022 18:33:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=159
05/22/2022 18:33:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.31 on epoch=161
05/22/2022 18:33:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=162
05/22/2022 18:33:47 - INFO - __main__ - Global step 1300 Train loss 0.25 Classification-F1 0.8487080925231981 on epoch=162
05/22/2022 18:33:47 - INFO - __main__ - Saving model with best Classification-F1: 0.8414617157116039 -> 0.8487080925231981 on epoch=162, global_step=1300
05/22/2022 18:33:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.27 on epoch=163
05/22/2022 18:33:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.28 on epoch=164
05/22/2022 18:33:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.27 on epoch=166
05/22/2022 18:33:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.25 on epoch=167
05/22/2022 18:33:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.27 on epoch=168
05/22/2022 18:34:01 - INFO - __main__ - Global step 1350 Train loss 0.27 Classification-F1 0.8412519787289793 on epoch=168
05/22/2022 18:34:04 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.26 on epoch=169
05/22/2022 18:34:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.33 on epoch=171
05/22/2022 18:34:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=172
05/22/2022 18:34:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.23 on epoch=173
05/22/2022 18:34:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=174
05/22/2022 18:34:15 - INFO - __main__ - Global step 1400 Train loss 0.25 Classification-F1 0.8322104978354979 on epoch=174
05/22/2022 18:34:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=176
05/22/2022 18:34:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=177
05/22/2022 18:34:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.23 on epoch=178
05/22/2022 18:34:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.30 on epoch=179
05/22/2022 18:34:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.20 on epoch=181
05/22/2022 18:34:29 - INFO - __main__ - Global step 1450 Train loss 0.23 Classification-F1 0.8484652893668935 on epoch=181
05/22/2022 18:34:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=182
05/22/2022 18:34:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.20 on epoch=183
05/22/2022 18:34:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.23 on epoch=184
05/22/2022 18:34:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=186
05/22/2022 18:34:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=187
05/22/2022 18:34:44 - INFO - __main__ - Global step 1500 Train loss 0.19 Classification-F1 0.8409320944585127 on epoch=187
05/22/2022 18:34:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.24 on epoch=188
05/22/2022 18:34:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.27 on epoch=189
05/22/2022 18:34:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.15 on epoch=191
05/22/2022 18:34:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=192
05/22/2022 18:34:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.26 on epoch=193
05/22/2022 18:34:58 - INFO - __main__ - Global step 1550 Train loss 0.22 Classification-F1 0.8483825885833194 on epoch=193
05/22/2022 18:35:00 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=194
05/22/2022 18:35:03 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.24 on epoch=196
05/22/2022 18:35:05 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=197
05/22/2022 18:35:08 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.19 on epoch=198
05/22/2022 18:35:10 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=199
05/22/2022 18:35:12 - INFO - __main__ - Global step 1600 Train loss 0.19 Classification-F1 0.8483519404572035 on epoch=199
05/22/2022 18:35:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.20 on epoch=201
05/22/2022 18:35:17 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.13 on epoch=202
05/22/2022 18:35:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=203
05/22/2022 18:35:22 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.17 on epoch=204
05/22/2022 18:35:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.17 on epoch=206
05/22/2022 18:35:26 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.8559544693347924 on epoch=206
05/22/2022 18:35:26 - INFO - __main__ - Saving model with best Classification-F1: 0.8487080925231981 -> 0.8559544693347924 on epoch=206, global_step=1650
05/22/2022 18:35:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.20 on epoch=207
05/22/2022 18:35:31 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.26 on epoch=208
05/22/2022 18:35:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=209
05/22/2022 18:35:36 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=211
05/22/2022 18:35:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.10 on epoch=212
05/22/2022 18:35:40 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.8559544693347924 on epoch=212
05/22/2022 18:35:43 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.30 on epoch=213
05/22/2022 18:35:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.19 on epoch=214
05/22/2022 18:35:48 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.16 on epoch=216
05/22/2022 18:35:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.11 on epoch=217
05/22/2022 18:35:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.24 on epoch=218
05/22/2022 18:35:54 - INFO - __main__ - Global step 1750 Train loss 0.20 Classification-F1 0.8182476874782103 on epoch=218
05/22/2022 18:35:57 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.23 on epoch=219
05/22/2022 18:35:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=221
05/22/2022 18:36:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.22 on epoch=222
05/22/2022 18:36:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.20 on epoch=223
05/22/2022 18:36:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=224
05/22/2022 18:36:08 - INFO - __main__ - Global step 1800 Train loss 0.18 Classification-F1 0.8349172293388863 on epoch=224
05/22/2022 18:36:11 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=226
05/22/2022 18:36:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=227
05/22/2022 18:36:16 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.18 on epoch=228
05/22/2022 18:36:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.22 on epoch=229
05/22/2022 18:36:21 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.16 on epoch=231
05/22/2022 18:36:22 - INFO - __main__ - Global step 1850 Train loss 0.15 Classification-F1 0.8540626395485731 on epoch=231
05/22/2022 18:36:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=232
05/22/2022 18:36:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.17 on epoch=233
05/22/2022 18:36:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.19 on epoch=234
05/22/2022 18:36:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=236
05/22/2022 18:36:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.15 on epoch=237
05/22/2022 18:36:37 - INFO - __main__ - Global step 1900 Train loss 0.16 Classification-F1 0.8482011635027555 on epoch=237
05/22/2022 18:36:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.19 on epoch=238
05/22/2022 18:36:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=239
05/22/2022 18:36:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.19 on epoch=241
05/22/2022 18:36:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=242
05/22/2022 18:36:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.23 on epoch=243
05/22/2022 18:36:51 - INFO - __main__ - Global step 1950 Train loss 0.17 Classification-F1 0.8401933415858657 on epoch=243
05/22/2022 18:36:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=244
05/22/2022 18:36:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=246
05/22/2022 18:36:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=247
05/22/2022 18:37:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.18 on epoch=248
05/22/2022 18:37:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=249
05/22/2022 18:37:05 - INFO - __main__ - Global step 2000 Train loss 0.13 Classification-F1 0.8634139748761394 on epoch=249
05/22/2022 18:37:05 - INFO - __main__ - Saving model with best Classification-F1: 0.8559544693347924 -> 0.8634139748761394 on epoch=249, global_step=2000
05/22/2022 18:37:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.15 on epoch=251
05/22/2022 18:37:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=252
05/22/2022 18:37:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=253
05/22/2022 18:37:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.18 on epoch=254
05/22/2022 18:37:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.11 on epoch=256
05/22/2022 18:37:19 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.8392725920741841 on epoch=256
05/22/2022 18:37:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.16 on epoch=257
05/22/2022 18:37:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.12 on epoch=258
05/22/2022 18:37:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.13 on epoch=259
05/22/2022 18:37:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.16 on epoch=261
05/22/2022 18:37:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.08 on epoch=262
05/22/2022 18:37:33 - INFO - __main__ - Global step 2100 Train loss 0.13 Classification-F1 0.8545772854596384 on epoch=262
05/22/2022 18:37:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.17 on epoch=263
05/22/2022 18:37:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=264
05/22/2022 18:37:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=266
05/22/2022 18:37:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.08 on epoch=267
05/22/2022 18:37:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.13 on epoch=268
05/22/2022 18:37:48 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.8634139748761394 on epoch=268
05/22/2022 18:37:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.14 on epoch=269
05/22/2022 18:37:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=271
05/22/2022 18:37:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.13 on epoch=272
05/22/2022 18:37:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.15 on epoch=273
05/22/2022 18:38:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=274
05/22/2022 18:38:02 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.8541727214601255 on epoch=274
05/22/2022 18:38:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=276
05/22/2022 18:38:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.13 on epoch=277
05/22/2022 18:38:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.14 on epoch=278
05/22/2022 18:38:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.17 on epoch=279
05/22/2022 18:38:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.15 on epoch=281
05/22/2022 18:38:16 - INFO - __main__ - Global step 2250 Train loss 0.13 Classification-F1 0.8392584722676255 on epoch=281
05/22/2022 18:38:19 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=282
05/22/2022 18:38:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.13 on epoch=283
05/22/2022 18:38:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=284
05/22/2022 18:38:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.17 on epoch=286
05/22/2022 18:38:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=287
05/22/2022 18:38:30 - INFO - __main__ - Global step 2300 Train loss 0.13 Classification-F1 0.8302107429737163 on epoch=287
05/22/2022 18:38:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.13 on epoch=288
05/22/2022 18:38:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=289
05/22/2022 18:38:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.13 on epoch=291
05/22/2022 18:38:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=292
05/22/2022 18:38:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=293
05/22/2022 18:38:44 - INFO - __main__ - Global step 2350 Train loss 0.11 Classification-F1 0.8378219343292873 on epoch=293
05/22/2022 18:38:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.11 on epoch=294
05/22/2022 18:38:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=296
05/22/2022 18:38:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.13 on epoch=297
05/22/2022 18:38:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=298
05/22/2022 18:38:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.13 on epoch=299
05/22/2022 18:38:59 - INFO - __main__ - Global step 2400 Train loss 0.11 Classification-F1 0.8318988885876931 on epoch=299
05/22/2022 18:39:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.10 on epoch=301
05/22/2022 18:39:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.17 on epoch=302
05/22/2022 18:39:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=303
05/22/2022 18:39:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.10 on epoch=304
05/22/2022 18:39:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=306
05/22/2022 18:39:13 - INFO - __main__ - Global step 2450 Train loss 0.11 Classification-F1 0.8319438548783813 on epoch=306
05/22/2022 18:39:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=307
05/22/2022 18:39:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=308
05/22/2022 18:39:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=309
05/22/2022 18:39:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.09 on epoch=311
05/22/2022 18:39:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.13 on epoch=312
05/22/2022 18:39:27 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.839160488879984 on epoch=312
05/22/2022 18:39:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=313
05/22/2022 18:39:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=314
05/22/2022 18:39:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=316
05/22/2022 18:39:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=317
05/22/2022 18:39:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.12 on epoch=318
05/22/2022 18:39:41 - INFO - __main__ - Global step 2550 Train loss 0.11 Classification-F1 0.8246715981496029 on epoch=318
05/22/2022 18:39:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=319
05/22/2022 18:39:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.07 on epoch=321
05/22/2022 18:39:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=322
05/22/2022 18:39:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=323
05/22/2022 18:39:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.12 on epoch=324
05/22/2022 18:39:56 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.8022610357633879 on epoch=324
05/22/2022 18:39:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=326
05/22/2022 18:40:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=327
05/22/2022 18:40:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=328
05/22/2022 18:40:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.09 on epoch=329
05/22/2022 18:40:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.08 on epoch=331
05/22/2022 18:40:10 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.8170581082833885 on epoch=331
05/22/2022 18:40:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=332
05/22/2022 18:40:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=333
05/22/2022 18:40:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.13 on epoch=334
05/22/2022 18:40:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.11 on epoch=336
05/22/2022 18:40:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=337
05/22/2022 18:40:24 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.8081086855663808 on epoch=337
05/22/2022 18:40:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=338
05/22/2022 18:40:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=339
05/22/2022 18:40:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.09 on epoch=341
05/22/2022 18:40:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=342
05/22/2022 18:40:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=343
05/22/2022 18:40:38 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.8107308493850361 on epoch=343
05/22/2022 18:40:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=344
05/22/2022 18:40:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=346
05/22/2022 18:40:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
05/22/2022 18:40:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.15 on epoch=348
05/22/2022 18:40:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.07 on epoch=349
05/22/2022 18:40:53 - INFO - __main__ - Global step 2800 Train loss 0.08 Classification-F1 0.8333115226068181 on epoch=349
05/22/2022 18:40:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.08 on epoch=351
05/22/2022 18:40:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=352
05/22/2022 18:41:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=353
05/22/2022 18:41:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=354
05/22/2022 18:41:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.13 on epoch=356
05/22/2022 18:41:07 - INFO - __main__ - Global step 2850 Train loss 0.09 Classification-F1 0.8251933999659719 on epoch=356
05/22/2022 18:41:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=357
05/22/2022 18:41:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=358
05/22/2022 18:41:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=359
05/22/2022 18:41:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.12 on epoch=361
05/22/2022 18:41:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
05/22/2022 18:41:21 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.8179239789396873 on epoch=362
05/22/2022 18:41:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.08 on epoch=363
05/22/2022 18:41:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=364
05/22/2022 18:41:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
05/22/2022 18:41:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
05/22/2022 18:41:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=368
05/22/2022 18:41:35 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.816899531824905 on epoch=368
05/22/2022 18:41:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=369
05/22/2022 18:41:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=371
05/22/2022 18:41:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=372
05/22/2022 18:41:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=373
05/22/2022 18:41:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
05/22/2022 18:41:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:41:49 - INFO - __main__ - Printing 3 examples
05/22/2022 18:41:49 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:41:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:41:49 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:41:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:41:49 - INFO - __main__ - Printing 3 examples
05/22/2022 18:41:49 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 18:41:49 - INFO - __main__ - ['others']
05/22/2022 18:41:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:41:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:41:49 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:41:49 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.8178765696593207 on epoch=374
05/22/2022 18:41:49 - INFO - __main__ - save last model!
05/22/2022 18:41:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:41:50 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 18:41:50 - INFO - __main__ - Printing 3 examples
05/22/2022 18:41:50 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 18:41:50 - INFO - __main__ - ['others']
05/22/2022 18:41:50 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 18:41:50 - INFO - __main__ - ['others']
05/22/2022 18:41:50 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 18:41:50 - INFO - __main__ - ['others']
05/22/2022 18:41:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:41:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:41:57 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 18:42:08 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:42:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:42:08 - INFO - __main__ - Starting training!
05/22/2022 18:43:16 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_100_0.2_8_predictions.txt
05/22/2022 18:43:16 - INFO - __main__ - Classification-F1 on test data: 0.3172
05/22/2022 18:43:16 - INFO - __main__ - prefix=emo_32_100, lr=0.2, bsz=8, dev_performance=0.8634139748761394, test_performance=0.3172199739535098
05/22/2022 18:43:16 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.5, bsz=8 ...
05/22/2022 18:43:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:43:17 - INFO - __main__ - Printing 3 examples
05/22/2022 18:43:17 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:43:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:43:17 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:43:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:43:17 - INFO - __main__ - Printing 3 examples
05/22/2022 18:43:17 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 18:43:17 - INFO - __main__ - ['others']
05/22/2022 18:43:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:43:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:43:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:43:36 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:43:37 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:43:37 - INFO - __main__ - Starting training!
05/22/2022 18:43:41 - INFO - __main__ - Step 10 Global step 10 Train loss 4.04 on epoch=1
05/22/2022 18:43:43 - INFO - __main__ - Step 20 Global step 20 Train loss 2.59 on epoch=2
05/22/2022 18:43:46 - INFO - __main__ - Step 30 Global step 30 Train loss 2.05 on epoch=3
05/22/2022 18:43:48 - INFO - __main__ - Step 40 Global step 40 Train loss 1.72 on epoch=4
05/22/2022 18:43:51 - INFO - __main__ - Step 50 Global step 50 Train loss 1.21 on epoch=6
05/22/2022 18:43:53 - INFO - __main__ - Global step 50 Train loss 2.32 Classification-F1 0.20654771634547636 on epoch=6
05/22/2022 18:43:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.20654771634547636 on epoch=6, global_step=50
05/22/2022 18:43:55 - INFO - __main__ - Step 60 Global step 60 Train loss 1.03 on epoch=7
05/22/2022 18:43:58 - INFO - __main__ - Step 70 Global step 70 Train loss 0.93 on epoch=8
05/22/2022 18:44:00 - INFO - __main__ - Step 80 Global step 80 Train loss 0.80 on epoch=9
05/22/2022 18:44:03 - INFO - __main__ - Step 90 Global step 90 Train loss 0.81 on epoch=11
05/22/2022 18:44:05 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=12
05/22/2022 18:44:07 - INFO - __main__ - Global step 100 Train loss 0.84 Classification-F1 0.4057562088139425 on epoch=12
05/22/2022 18:44:07 - INFO - __main__ - Saving model with best Classification-F1: 0.20654771634547636 -> 0.4057562088139425 on epoch=12, global_step=100
05/22/2022 18:44:10 - INFO - __main__ - Step 110 Global step 110 Train loss 0.75 on epoch=13
05/22/2022 18:44:12 - INFO - __main__ - Step 120 Global step 120 Train loss 0.58 on epoch=14
05/22/2022 18:44:15 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=16
05/22/2022 18:44:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.50 on epoch=17
05/22/2022 18:44:20 - INFO - __main__ - Step 150 Global step 150 Train loss 0.65 on epoch=18
05/22/2022 18:44:22 - INFO - __main__ - Global step 150 Train loss 0.62 Classification-F1 0.4502659283645289 on epoch=18
05/22/2022 18:44:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4057562088139425 -> 0.4502659283645289 on epoch=18, global_step=150
05/22/2022 18:44:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.55 on epoch=19
05/22/2022 18:44:27 - INFO - __main__ - Step 170 Global step 170 Train loss 0.44 on epoch=21
05/22/2022 18:44:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.51 on epoch=22
05/22/2022 18:44:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.50 on epoch=23
05/22/2022 18:44:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.45 on epoch=24
05/22/2022 18:44:36 - INFO - __main__ - Global step 200 Train loss 0.49 Classification-F1 0.5929338138417423 on epoch=24
05/22/2022 18:44:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4502659283645289 -> 0.5929338138417423 on epoch=24, global_step=200
05/22/2022 18:44:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.43 on epoch=26
05/22/2022 18:44:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.44 on epoch=27
05/22/2022 18:44:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.39 on epoch=28
05/22/2022 18:44:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.46 on epoch=29
05/22/2022 18:44:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.43 on epoch=31
05/22/2022 18:44:50 - INFO - __main__ - Global step 250 Train loss 0.43 Classification-F1 0.5156236559139785 on epoch=31
05/22/2022 18:44:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=32
05/22/2022 18:44:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.40 on epoch=33
05/22/2022 18:44:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=34
05/22/2022 18:45:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.36 on epoch=36
05/22/2022 18:45:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.33 on epoch=37
05/22/2022 18:45:04 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.6414549484338078 on epoch=37
05/22/2022 18:45:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5929338138417423 -> 0.6414549484338078 on epoch=37, global_step=300
05/22/2022 18:45:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=38
05/22/2022 18:45:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.27 on epoch=39
05/22/2022 18:45:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=41
05/22/2022 18:45:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.32 on epoch=42
05/22/2022 18:45:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=43
05/22/2022 18:45:18 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6771016617790812 on epoch=43
05/22/2022 18:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6414549484338078 -> 0.6771016617790812 on epoch=43, global_step=350
05/22/2022 18:45:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=44
05/22/2022 18:45:23 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=46
05/22/2022 18:45:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=47
05/22/2022 18:45:28 - INFO - __main__ - Step 390 Global step 390 Train loss 0.37 on epoch=48
05/22/2022 18:45:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=49
05/22/2022 18:45:32 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.6752292471042471 on epoch=49
05/22/2022 18:45:35 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=51
05/22/2022 18:45:37 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=52
05/22/2022 18:45:40 - INFO - __main__ - Step 430 Global step 430 Train loss 0.33 on epoch=53
05/22/2022 18:45:42 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=54
05/22/2022 18:45:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=56
05/22/2022 18:45:46 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6809182288926425 on epoch=56
05/22/2022 18:45:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6771016617790812 -> 0.6809182288926425 on epoch=56, global_step=450
05/22/2022 18:45:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=57
05/22/2022 18:45:51 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=58
05/22/2022 18:45:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=59
05/22/2022 18:45:56 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=61
05/22/2022 18:45:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.24 on epoch=62
05/22/2022 18:46:00 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.7044871794871795 on epoch=62
05/22/2022 18:46:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6809182288926425 -> 0.7044871794871795 on epoch=62, global_step=500
05/22/2022 18:46:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=63
05/22/2022 18:46:05 - INFO - __main__ - Step 520 Global step 520 Train loss 0.21 on epoch=64
05/22/2022 18:46:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.21 on epoch=66
05/22/2022 18:46:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=67
05/22/2022 18:46:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=68
05/22/2022 18:46:15 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.5757981458607284 on epoch=68
05/22/2022 18:46:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.16 on epoch=69
05/22/2022 18:46:20 - INFO - __main__ - Step 570 Global step 570 Train loss 0.18 on epoch=71
05/22/2022 18:46:22 - INFO - __main__ - Step 580 Global step 580 Train loss 0.16 on epoch=72
05/22/2022 18:46:25 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=73
05/22/2022 18:46:27 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=74
05/22/2022 18:46:29 - INFO - __main__ - Global step 600 Train loss 0.17 Classification-F1 0.5496022972556276 on epoch=74
05/22/2022 18:46:31 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=76
05/22/2022 18:46:34 - INFO - __main__ - Step 620 Global step 620 Train loss 0.21 on epoch=77
05/22/2022 18:46:36 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=78
05/22/2022 18:46:39 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=79
05/22/2022 18:46:41 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=81
05/22/2022 18:46:43 - INFO - __main__ - Global step 650 Train loss 0.17 Classification-F1 0.5955617758299266 on epoch=81
05/22/2022 18:46:45 - INFO - __main__ - Step 660 Global step 660 Train loss 0.14 on epoch=82
05/22/2022 18:46:48 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=83
05/22/2022 18:46:50 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=84
05/22/2022 18:46:53 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=86
05/22/2022 18:46:55 - INFO - __main__ - Step 700 Global step 700 Train loss 0.13 on epoch=87
05/22/2022 18:46:57 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.5923290879812619 on epoch=87
05/22/2022 18:46:59 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=88
05/22/2022 18:47:02 - INFO - __main__ - Step 720 Global step 720 Train loss 0.06 on epoch=89
05/22/2022 18:47:04 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=91
05/22/2022 18:47:07 - INFO - __main__ - Step 740 Global step 740 Train loss 0.09 on epoch=92
05/22/2022 18:47:09 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=93
05/22/2022 18:47:11 - INFO - __main__ - Global step 750 Train loss 0.09 Classification-F1 0.5737297861241523 on epoch=93
05/22/2022 18:47:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=94
05/22/2022 18:47:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=96
05/22/2022 18:47:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=97
05/22/2022 18:47:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=98
05/22/2022 18:47:23 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=99
05/22/2022 18:47:25 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.5877462707571066 on epoch=99
05/22/2022 18:47:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=101
05/22/2022 18:47:30 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=102
05/22/2022 18:47:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=103
05/22/2022 18:47:35 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=104
05/22/2022 18:47:37 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=106
05/22/2022 18:47:39 - INFO - __main__ - Global step 850 Train loss 0.09 Classification-F1 0.5899985095987665 on epoch=106
05/22/2022 18:47:42 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=107
05/22/2022 18:47:44 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=108
05/22/2022 18:47:47 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=109
05/22/2022 18:47:49 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=111
05/22/2022 18:47:52 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=112
05/22/2022 18:47:53 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.5722112428634167 on epoch=112
05/22/2022 18:47:56 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=113
05/22/2022 18:47:58 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=114
05/22/2022 18:48:01 - INFO - __main__ - Step 930 Global step 930 Train loss 0.04 on epoch=116
05/22/2022 18:48:03 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=117
05/22/2022 18:48:06 - INFO - __main__ - Step 950 Global step 950 Train loss 0.05 on epoch=118
05/22/2022 18:48:07 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.6081408158768759 on epoch=118
05/22/2022 18:48:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=119
05/22/2022 18:48:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=121
05/22/2022 18:48:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.05 on epoch=122
05/22/2022 18:48:17 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=123
05/22/2022 18:48:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.04 on epoch=124
05/22/2022 18:48:21 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.5701190476190476 on epoch=124
05/22/2022 18:48:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=126
05/22/2022 18:48:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=127
05/22/2022 18:48:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.02 on epoch=128
05/22/2022 18:48:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=129
05/22/2022 18:48:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.03 on epoch=131
05/22/2022 18:48:36 - INFO - __main__ - Global step 1050 Train loss 0.05 Classification-F1 0.583489010989011 on epoch=131
05/22/2022 18:48:38 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=132
05/22/2022 18:48:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.04 on epoch=133
05/22/2022 18:48:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=134
05/22/2022 18:48:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=136
05/22/2022 18:48:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.02 on epoch=137
05/22/2022 18:48:50 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.5676958897600379 on epoch=137
05/22/2022 18:48:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.14 on epoch=138
05/22/2022 18:48:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=139
05/22/2022 18:48:57 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
05/22/2022 18:49:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.02 on epoch=142
05/22/2022 18:49:02 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.03 on epoch=143
05/22/2022 18:49:04 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.5775483169856572 on epoch=143
05/22/2022 18:49:06 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=144
05/22/2022 18:49:09 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=146
05/22/2022 18:49:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.01 on epoch=147
05/22/2022 18:49:14 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.03 on epoch=148
05/22/2022 18:49:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=149
05/22/2022 18:49:18 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.586861098836353 on epoch=149
05/22/2022 18:49:21 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=151
05/22/2022 18:49:23 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=152
05/22/2022 18:49:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=153
05/22/2022 18:49:28 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=154
05/22/2022 18:49:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.02 on epoch=156
05/22/2022 18:49:32 - INFO - __main__ - Global step 1250 Train loss 0.03 Classification-F1 0.6004726265832498 on epoch=156
05/22/2022 18:49:35 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=157
05/22/2022 18:49:37 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=158
05/22/2022 18:49:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=159
05/22/2022 18:49:42 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=161
05/22/2022 18:49:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=162
05/22/2022 18:49:46 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.5992951871406413 on epoch=162
05/22/2022 18:49:49 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.03 on epoch=163
05/22/2022 18:49:51 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=164
05/22/2022 18:49:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=166
05/22/2022 18:49:56 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.04 on epoch=167
05/22/2022 18:49:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
05/22/2022 18:50:00 - INFO - __main__ - Global step 1350 Train loss 0.04 Classification-F1 0.7096708846708847 on epoch=168
05/22/2022 18:50:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7044871794871795 -> 0.7096708846708847 on epoch=168, global_step=1350
05/22/2022 18:50:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=169
05/22/2022 18:50:05 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=171
05/22/2022 18:50:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=172
05/22/2022 18:50:10 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.06 on epoch=173
05/22/2022 18:50:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
05/22/2022 18:50:14 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.5848964894199081 on epoch=174
05/22/2022 18:50:17 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.01 on epoch=176
05/22/2022 18:50:19 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=177
05/22/2022 18:50:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=178
05/22/2022 18:50:24 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=179
05/22/2022 18:50:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=181
05/22/2022 18:50:29 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.589977442513377 on epoch=181
05/22/2022 18:50:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=182
05/22/2022 18:50:33 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=183
05/22/2022 18:50:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=184
05/22/2022 18:50:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=186
05/22/2022 18:50:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
05/22/2022 18:50:43 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5870783342256167 on epoch=187
05/22/2022 18:50:45 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=188
05/22/2022 18:50:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.02 on epoch=189
05/22/2022 18:50:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.01 on epoch=191
05/22/2022 18:50:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
05/22/2022 18:50:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
05/22/2022 18:50:57 - INFO - __main__ - Global step 1550 Train loss 0.02 Classification-F1 0.5696393802276155 on epoch=193
05/22/2022 18:50:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.00 on epoch=194
05/22/2022 18:51:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=196
05/22/2022 18:51:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=197
05/22/2022 18:51:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
05/22/2022 18:51:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.01 on epoch=199
05/22/2022 18:51:11 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.6067144449753146 on epoch=199
05/22/2022 18:51:13 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=201
05/22/2022 18:51:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=202
05/22/2022 18:51:18 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=203
05/22/2022 18:51:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.03 on epoch=204
05/22/2022 18:51:23 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
05/22/2022 18:51:25 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.5994283976892673 on epoch=206
05/22/2022 18:51:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
05/22/2022 18:51:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.00 on epoch=208
05/22/2022 18:51:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
05/22/2022 18:51:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.00 on epoch=211
05/22/2022 18:51:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.13 on epoch=212
05/22/2022 18:51:39 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.5729921599035065 on epoch=212
05/22/2022 18:51:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
05/22/2022 18:51:44 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=214
05/22/2022 18:51:46 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=216
05/22/2022 18:51:49 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
05/22/2022 18:51:51 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.00 on epoch=218
05/22/2022 18:51:53 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.5788547253196609 on epoch=218
05/22/2022 18:51:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.00 on epoch=219
05/22/2022 18:51:58 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
05/22/2022 18:52:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
05/22/2022 18:52:03 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=223
05/22/2022 18:52:05 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.00 on epoch=224
05/22/2022 18:52:07 - INFO - __main__ - Global step 1800 Train loss 0.01 Classification-F1 0.6232538917206227 on epoch=224
05/22/2022 18:52:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
05/22/2022 18:52:12 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
05/22/2022 18:52:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.00 on epoch=228
05/22/2022 18:52:17 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=229
05/22/2022 18:52:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
05/22/2022 18:52:21 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.6031602049365691 on epoch=231
05/22/2022 18:52:24 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 18:52:26 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=233
05/22/2022 18:52:28 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
05/22/2022 18:52:31 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=236
05/22/2022 18:52:33 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.00 on epoch=237
05/22/2022 18:52:35 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.6122649618248209 on epoch=237
05/22/2022 18:52:37 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
05/22/2022 18:52:40 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
05/22/2022 18:52:42 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
05/22/2022 18:52:45 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
05/22/2022 18:52:47 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=243
05/22/2022 18:52:49 - INFO - __main__ - Global step 1950 Train loss 0.01 Classification-F1 0.5877389277389277 on epoch=243
05/22/2022 18:52:51 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=244
05/22/2022 18:52:54 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
05/22/2022 18:52:56 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
05/22/2022 18:52:59 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
05/22/2022 18:53:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
05/22/2022 18:53:03 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.6119169452795441 on epoch=249
05/22/2022 18:53:05 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.00 on epoch=251
05/22/2022 18:53:08 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
05/22/2022 18:53:10 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=253
05/22/2022 18:53:13 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=254
05/22/2022 18:53:15 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
05/22/2022 18:53:17 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.5886203585147247 on epoch=256
05/22/2022 18:53:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
05/22/2022 18:53:22 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.00 on epoch=258
05/22/2022 18:53:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
05/22/2022 18:53:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.00 on epoch=261
05/22/2022 18:53:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.00 on epoch=262
05/22/2022 18:53:31 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.5801470588235293 on epoch=262
05/22/2022 18:53:33 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
05/22/2022 18:53:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
05/22/2022 18:53:38 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=266
05/22/2022 18:53:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
05/22/2022 18:53:43 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=268
05/22/2022 18:53:45 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.5878321678321679 on epoch=268
05/22/2022 18:53:47 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
05/22/2022 18:53:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
05/22/2022 18:53:52 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.00 on epoch=272
05/22/2022 18:53:55 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=273
05/22/2022 18:53:57 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
05/22/2022 18:53:59 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.5870281956849122 on epoch=274
05/22/2022 18:54:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 18:54:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
05/22/2022 18:54:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
05/22/2022 18:54:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
05/22/2022 18:54:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=281
05/22/2022 18:54:13 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.5884349350224363 on epoch=281
05/22/2022 18:54:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
05/22/2022 18:54:18 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=283
05/22/2022 18:54:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
05/22/2022 18:54:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=286
05/22/2022 18:54:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
05/22/2022 18:54:27 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.5770035193564605 on epoch=287
05/22/2022 18:54:30 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
05/22/2022 18:54:32 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
05/22/2022 18:54:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
05/22/2022 18:54:37 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
05/22/2022 18:54:39 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
05/22/2022 18:54:41 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.580303985290715 on epoch=293
05/22/2022 18:54:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
05/22/2022 18:54:46 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
05/22/2022 18:54:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
05/22/2022 18:54:51 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=298
05/22/2022 18:54:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=299
05/22/2022 18:54:55 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5774478680361034 on epoch=299
05/22/2022 18:54:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
05/22/2022 18:55:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
05/22/2022 18:55:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=303
05/22/2022 18:55:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
05/22/2022 18:55:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 18:55:09 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.5828292499765324 on epoch=306
05/22/2022 18:55:11 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
05/22/2022 18:55:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
05/22/2022 18:55:16 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
05/22/2022 18:55:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
05/22/2022 18:55:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
05/22/2022 18:55:23 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.5791040258298861 on epoch=312
05/22/2022 18:55:25 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
05/22/2022 18:55:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 18:55:30 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
05/22/2022 18:55:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
05/22/2022 18:55:35 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
05/22/2022 18:55:37 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5774358974358974 on epoch=318
05/22/2022 18:55:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
05/22/2022 18:55:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
05/22/2022 18:55:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
05/22/2022 18:55:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
05/22/2022 18:55:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
05/22/2022 18:55:51 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5689012614606141 on epoch=324
05/22/2022 18:55:53 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
05/22/2022 18:55:56 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
05/22/2022 18:55:58 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
05/22/2022 18:56:00 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 18:56:03 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
05/22/2022 18:56:05 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7210017969451932 on epoch=331
05/22/2022 18:56:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7096708846708847 -> 0.7210017969451932 on epoch=331, global_step=2650
05/22/2022 18:56:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
05/22/2022 18:56:10 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 18:56:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
05/22/2022 18:56:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
05/22/2022 18:56:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 18:56:19 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5666798402354425 on epoch=337
05/22/2022 18:56:21 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
05/22/2022 18:56:23 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
05/22/2022 18:56:26 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
05/22/2022 18:56:28 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 18:56:31 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
05/22/2022 18:56:33 - INFO - __main__ - Global step 2750 Train loss 0.00 Classification-F1 0.5814168440255397 on epoch=343
05/22/2022 18:56:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
05/22/2022 18:56:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 18:56:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
05/22/2022 18:56:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
05/22/2022 18:56:45 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 18:56:47 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.586711229946524 on epoch=349
05/22/2022 18:56:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
05/22/2022 18:56:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
05/22/2022 18:56:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
05/22/2022 18:56:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
05/22/2022 18:56:59 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 18:57:01 - INFO - __main__ - Global step 2850 Train loss 0.00 Classification-F1 0.5750911769390029 on epoch=356
05/22/2022 18:57:03 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
05/22/2022 18:57:06 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
05/22/2022 18:57:09 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=359
05/22/2022 18:57:11 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 18:57:14 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.18 on epoch=362
05/22/2022 18:57:15 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7010324107098301 on epoch=362
05/22/2022 18:57:18 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
05/22/2022 18:57:20 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=364
05/22/2022 18:57:23 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 18:57:25 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
05/22/2022 18:57:28 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
05/22/2022 18:57:30 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5804158693710932 on epoch=368
05/22/2022 18:57:32 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 18:57:35 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 18:57:37 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
05/22/2022 18:57:40 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
05/22/2022 18:57:42 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
05/22/2022 18:57:44 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:57:44 - INFO - __main__ - Printing 3 examples
05/22/2022 18:57:44 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:57:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:57:44 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:57:44 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:57:44 - INFO - __main__ - Printing 3 examples
05/22/2022 18:57:44 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:57:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:57:44 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5605278478850023 on epoch=374
05/22/2022 18:57:44 - INFO - __main__ - save last model!
05/22/2022 18:57:44 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 18:57:44 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 18:57:44 - INFO - __main__ - Printing 3 examples
05/22/2022 18:57:44 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 18:57:44 - INFO - __main__ - ['others']
05/22/2022 18:57:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:57:44 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:57:46 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:57:51 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 18:58:02 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:58:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:58:03 - INFO - __main__ - Starting training!
05/22/2022 18:59:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_13_0.5_8_predictions.txt
05/22/2022 18:59:04 - INFO - __main__ - Classification-F1 on test data: 0.3311
05/22/2022 18:59:04 - INFO - __main__ - prefix=emo_32_13, lr=0.5, bsz=8, dev_performance=0.7210017969451932, test_performance=0.3311278083256701
05/22/2022 18:59:04 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.4, bsz=8 ...
05/22/2022 18:59:05 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:59:05 - INFO - __main__ - Printing 3 examples
05/22/2022 18:59:05 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:59:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:59:05 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 18:59:05 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 18:59:05 - INFO - __main__ - Printing 3 examples
05/22/2022 18:59:05 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 18:59:05 - INFO - __main__ - ['others']
05/22/2022 18:59:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 18:59:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 18:59:05 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 18:59:21 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 18:59:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 18:59:21 - INFO - __main__ - Starting training!
05/22/2022 18:59:25 - INFO - __main__ - Step 10 Global step 10 Train loss 4.12 on epoch=1
05/22/2022 18:59:27 - INFO - __main__ - Step 20 Global step 20 Train loss 2.76 on epoch=2
05/22/2022 18:59:30 - INFO - __main__ - Step 30 Global step 30 Train loss 2.48 on epoch=3
05/22/2022 18:59:32 - INFO - __main__ - Step 40 Global step 40 Train loss 1.94 on epoch=4
05/22/2022 18:59:35 - INFO - __main__ - Step 50 Global step 50 Train loss 1.76 on epoch=6
05/22/2022 18:59:36 - INFO - __main__ - Global step 50 Train loss 2.61 Classification-F1 0.11238146358919304 on epoch=6
05/22/2022 18:59:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.11238146358919304 on epoch=6, global_step=50
05/22/2022 18:59:39 - INFO - __main__ - Step 60 Global step 60 Train loss 1.28 on epoch=7
05/22/2022 18:59:41 - INFO - __main__ - Step 70 Global step 70 Train loss 1.30 on epoch=8
05/22/2022 18:59:44 - INFO - __main__ - Step 80 Global step 80 Train loss 0.90 on epoch=9
05/22/2022 18:59:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.82 on epoch=11
05/22/2022 18:59:49 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=12
05/22/2022 18:59:50 - INFO - __main__ - Global step 100 Train loss 1.02 Classification-F1 0.40379620379620385 on epoch=12
05/22/2022 18:59:51 - INFO - __main__ - Saving model with best Classification-F1: 0.11238146358919304 -> 0.40379620379620385 on epoch=12, global_step=100
05/22/2022 18:59:53 - INFO - __main__ - Step 110 Global step 110 Train loss 0.72 on epoch=13
05/22/2022 18:59:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.68 on epoch=14
05/22/2022 18:59:58 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=16
05/22/2022 19:00:00 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=17
05/22/2022 19:00:03 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=18
05/22/2022 19:00:05 - INFO - __main__ - Global step 150 Train loss 0.66 Classification-F1 0.43337645611251013 on epoch=18
05/22/2022 19:00:05 - INFO - __main__ - Saving model with best Classification-F1: 0.40379620379620385 -> 0.43337645611251013 on epoch=18, global_step=150
05/22/2022 19:00:07 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=19
05/22/2022 19:00:10 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=21
05/22/2022 19:00:12 - INFO - __main__ - Step 180 Global step 180 Train loss 0.57 on epoch=22
05/22/2022 19:00:15 - INFO - __main__ - Step 190 Global step 190 Train loss 0.48 on epoch=23
05/22/2022 19:00:17 - INFO - __main__ - Step 200 Global step 200 Train loss 0.50 on epoch=24
05/22/2022 19:00:19 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.5212224660065244 on epoch=24
05/22/2022 19:00:19 - INFO - __main__ - Saving model with best Classification-F1: 0.43337645611251013 -> 0.5212224660065244 on epoch=24, global_step=200
05/22/2022 19:00:21 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=26
05/22/2022 19:00:24 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=27
05/22/2022 19:00:26 - INFO - __main__ - Step 230 Global step 230 Train loss 0.48 on epoch=28
05/22/2022 19:00:29 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=29
05/22/2022 19:00:31 - INFO - __main__ - Step 250 Global step 250 Train loss 0.45 on epoch=31
05/22/2022 19:00:33 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.6125694005200646 on epoch=31
05/22/2022 19:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5212224660065244 -> 0.6125694005200646 on epoch=31, global_step=250
05/22/2022 19:00:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.41 on epoch=32
05/22/2022 19:00:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.39 on epoch=33
05/22/2022 19:00:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.41 on epoch=34
05/22/2022 19:00:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.44 on epoch=36
05/22/2022 19:00:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.44 on epoch=37
05/22/2022 19:00:47 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.6413769095148208 on epoch=37
05/22/2022 19:00:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6125694005200646 -> 0.6413769095148208 on epoch=37, global_step=300
05/22/2022 19:00:50 - INFO - __main__ - Step 310 Global step 310 Train loss 0.40 on epoch=38
05/22/2022 19:00:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=39
05/22/2022 19:00:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=41
05/22/2022 19:00:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=42
05/22/2022 19:00:59 - INFO - __main__ - Step 350 Global step 350 Train loss 0.36 on epoch=43
05/22/2022 19:01:01 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.6568244715487879 on epoch=43
05/22/2022 19:01:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6413769095148208 -> 0.6568244715487879 on epoch=43, global_step=350
05/22/2022 19:01:04 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=44
05/22/2022 19:01:06 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=46
05/22/2022 19:01:09 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=47
05/22/2022 19:01:11 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=48
05/22/2022 19:01:14 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=49
05/22/2022 19:01:15 - INFO - __main__ - Global step 400 Train loss 0.34 Classification-F1 0.7103036661961933 on epoch=49
05/22/2022 19:01:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6568244715487879 -> 0.7103036661961933 on epoch=49, global_step=400
05/22/2022 19:01:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=51
05/22/2022 19:01:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=52
05/22/2022 19:01:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=53
05/22/2022 19:01:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=54
05/22/2022 19:01:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.28 on epoch=56
05/22/2022 19:01:29 - INFO - __main__ - Global step 450 Train loss 0.33 Classification-F1 0.7277248560035445 on epoch=56
05/22/2022 19:01:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7103036661961933 -> 0.7277248560035445 on epoch=56, global_step=450
05/22/2022 19:01:32 - INFO - __main__ - Step 460 Global step 460 Train loss 0.31 on epoch=57
05/22/2022 19:01:34 - INFO - __main__ - Step 470 Global step 470 Train loss 0.44 on epoch=58
05/22/2022 19:01:37 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=59
05/22/2022 19:01:39 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=61
05/22/2022 19:01:42 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=62
05/22/2022 19:01:43 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.7005850727387729 on epoch=62
05/22/2022 19:01:46 - INFO - __main__ - Step 510 Global step 510 Train loss 0.32 on epoch=63
05/22/2022 19:01:48 - INFO - __main__ - Step 520 Global step 520 Train loss 0.28 on epoch=64
05/22/2022 19:01:51 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=66
05/22/2022 19:01:53 - INFO - __main__ - Step 540 Global step 540 Train loss 0.24 on epoch=67
05/22/2022 19:01:56 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=68
05/22/2022 19:01:58 - INFO - __main__ - Global step 550 Train loss 0.27 Classification-F1 0.7068131008271853 on epoch=68
05/22/2022 19:02:00 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=69
05/22/2022 19:02:03 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=71
05/22/2022 19:02:05 - INFO - __main__ - Step 580 Global step 580 Train loss 0.23 on epoch=72
05/22/2022 19:02:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=73
05/22/2022 19:02:10 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=74
05/22/2022 19:02:12 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.6896539281613908 on epoch=74
05/22/2022 19:02:14 - INFO - __main__ - Step 610 Global step 610 Train loss 0.24 on epoch=76
05/22/2022 19:02:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.20 on epoch=77
05/22/2022 19:02:19 - INFO - __main__ - Step 630 Global step 630 Train loss 0.23 on epoch=78
05/22/2022 19:02:22 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=79
05/22/2022 19:02:24 - INFO - __main__ - Step 650 Global step 650 Train loss 0.18 on epoch=81
05/22/2022 19:02:26 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7110353473581212 on epoch=81
05/22/2022 19:02:28 - INFO - __main__ - Step 660 Global step 660 Train loss 0.22 on epoch=82
05/22/2022 19:02:31 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=83
05/22/2022 19:02:33 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=84
05/22/2022 19:02:36 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=86
05/22/2022 19:02:38 - INFO - __main__ - Step 700 Global step 700 Train loss 0.22 on epoch=87
05/22/2022 19:02:40 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.7188034188034188 on epoch=87
05/22/2022 19:02:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=88
05/22/2022 19:02:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.11 on epoch=89
05/22/2022 19:02:47 - INFO - __main__ - Step 730 Global step 730 Train loss 0.23 on epoch=91
05/22/2022 19:02:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.15 on epoch=92
05/22/2022 19:02:52 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=93
05/22/2022 19:02:54 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6942873936550242 on epoch=93
05/22/2022 19:02:57 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=94
05/22/2022 19:02:59 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=96
05/22/2022 19:03:02 - INFO - __main__ - Step 780 Global step 780 Train loss 0.12 on epoch=97
05/22/2022 19:03:04 - INFO - __main__ - Step 790 Global step 790 Train loss 0.15 on epoch=98
05/22/2022 19:03:06 - INFO - __main__ - Step 800 Global step 800 Train loss 0.13 on epoch=99
05/22/2022 19:03:08 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6848874051405697 on epoch=99
05/22/2022 19:03:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=101
05/22/2022 19:03:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=102
05/22/2022 19:03:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=103
05/22/2022 19:03:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=104
05/22/2022 19:03:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=106
05/22/2022 19:03:22 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.6981948009561865 on epoch=106
05/22/2022 19:03:25 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=107
05/22/2022 19:03:27 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=108
05/22/2022 19:03:30 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=109
05/22/2022 19:03:32 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=111
05/22/2022 19:03:35 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=112
05/22/2022 19:03:36 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.7046091416514988 on epoch=112
05/22/2022 19:03:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=113
05/22/2022 19:03:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=114
05/22/2022 19:03:44 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=116
05/22/2022 19:03:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=117
05/22/2022 19:03:49 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=118
05/22/2022 19:03:50 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.6989172295646084 on epoch=118
05/22/2022 19:03:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.16 on epoch=119
05/22/2022 19:03:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=121
05/22/2022 19:03:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=122
05/22/2022 19:04:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.08 on epoch=123
05/22/2022 19:04:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=124
05/22/2022 19:04:05 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.6872837022132797 on epoch=124
05/22/2022 19:04:07 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=126
05/22/2022 19:04:10 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=127
05/22/2022 19:04:12 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=128
05/22/2022 19:04:15 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=129
05/22/2022 19:04:17 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=131
05/22/2022 19:04:19 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.722815304676429 on epoch=131
05/22/2022 19:04:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=132
05/22/2022 19:04:24 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=133
05/22/2022 19:04:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=134
05/22/2022 19:04:29 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=136
05/22/2022 19:04:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=137
05/22/2022 19:04:33 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7308677202224173 on epoch=137
05/22/2022 19:04:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7277248560035445 -> 0.7308677202224173 on epoch=137, global_step=1100
05/22/2022 19:04:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=138
05/22/2022 19:04:38 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=139
05/22/2022 19:04:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=141
05/22/2022 19:04:43 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=142
05/22/2022 19:04:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=143
05/22/2022 19:04:47 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7394471811713191 on epoch=143
05/22/2022 19:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.7308677202224173 -> 0.7394471811713191 on epoch=143, global_step=1150
05/22/2022 19:04:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=144
05/22/2022 19:04:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=146
05/22/2022 19:04:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=147
05/22/2022 19:04:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=148
05/22/2022 19:04:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=149
05/22/2022 19:05:01 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.5808288655272446 on epoch=149
05/22/2022 19:05:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=151
05/22/2022 19:05:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=152
05/22/2022 19:05:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=153
05/22/2022 19:05:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=154
05/22/2022 19:05:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
05/22/2022 19:05:15 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7487142220399551 on epoch=156
05/22/2022 19:05:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7394471811713191 -> 0.7487142220399551 on epoch=156, global_step=1250
05/22/2022 19:05:17 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=157
05/22/2022 19:05:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=158
05/22/2022 19:05:22 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
05/22/2022 19:05:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=161
05/22/2022 19:05:27 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=162
05/22/2022 19:05:29 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.6918192918192918 on epoch=162
05/22/2022 19:05:31 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=163
05/22/2022 19:05:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=164
05/22/2022 19:05:36 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=166
05/22/2022 19:05:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
05/22/2022 19:05:41 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=168
05/22/2022 19:05:43 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7218714629315223 on epoch=168
05/22/2022 19:05:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=169
05/22/2022 19:05:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=171
05/22/2022 19:05:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.04 on epoch=172
05/22/2022 19:05:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=173
05/22/2022 19:05:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=174
05/22/2022 19:05:57 - INFO - __main__ - Global step 1400 Train loss 0.04 Classification-F1 0.719149476689244 on epoch=174
05/22/2022 19:06:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=176
05/22/2022 19:06:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=177
05/22/2022 19:06:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=178
05/22/2022 19:06:07 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=179
05/22/2022 19:06:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
05/22/2022 19:06:11 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.6978533344673694 on epoch=181
05/22/2022 19:06:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=182
05/22/2022 19:06:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=183
05/22/2022 19:06:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=184
05/22/2022 19:06:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=186
05/22/2022 19:06:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=187
05/22/2022 19:06:26 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6968814968814968 on epoch=187
05/22/2022 19:06:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=188
05/22/2022 19:06:30 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
05/22/2022 19:06:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=191
05/22/2022 19:06:35 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
05/22/2022 19:06:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=193
05/22/2022 19:06:40 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7034446581678254 on epoch=193
05/22/2022 19:06:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=194
05/22/2022 19:06:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=196
05/22/2022 19:06:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=197
05/22/2022 19:06:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=198
05/22/2022 19:06:52 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=199
05/22/2022 19:06:54 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7069377990430622 on epoch=199
05/22/2022 19:06:56 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
05/22/2022 19:06:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
05/22/2022 19:07:01 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=203
05/22/2022 19:07:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=204
05/22/2022 19:07:06 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
05/22/2022 19:07:08 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7146236559139785 on epoch=206
05/22/2022 19:07:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
05/22/2022 19:07:13 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=208
05/22/2022 19:07:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
05/22/2022 19:07:18 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=211
05/22/2022 19:07:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=212
05/22/2022 19:07:22 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7460060832354294 on epoch=212
05/22/2022 19:07:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=213
05/22/2022 19:07:27 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.01 on epoch=214
05/22/2022 19:07:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=216
05/22/2022 19:07:32 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
05/22/2022 19:07:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=218
05/22/2022 19:07:37 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7400880702250565 on epoch=218
05/22/2022 19:07:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
05/22/2022 19:07:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=221
05/22/2022 19:07:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=222
05/22/2022 19:07:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
05/22/2022 19:07:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.04 on epoch=224
05/22/2022 19:07:51 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7214884696016772 on epoch=224
05/22/2022 19:07:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
05/22/2022 19:07:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
05/22/2022 19:07:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=228
05/22/2022 19:08:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
05/22/2022 19:08:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.08 on epoch=231
05/22/2022 19:08:05 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7221259074126225 on epoch=231
05/22/2022 19:08:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 19:08:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
05/22/2022 19:08:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
05/22/2022 19:08:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.00 on epoch=236
05/22/2022 19:08:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
05/22/2022 19:08:20 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7431454082136577 on epoch=237
05/22/2022 19:08:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
05/22/2022 19:08:25 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
05/22/2022 19:08:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
05/22/2022 19:08:30 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.00 on epoch=242
05/22/2022 19:08:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
05/22/2022 19:08:34 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7258930331838873 on epoch=243
05/22/2022 19:08:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=244
05/22/2022 19:08:39 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
05/22/2022 19:08:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
05/22/2022 19:08:44 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
05/22/2022 19:08:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
05/22/2022 19:08:49 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7437838554176951 on epoch=249
05/22/2022 19:08:51 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
05/22/2022 19:08:54 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=252
05/22/2022 19:08:56 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=253
05/22/2022 19:08:59 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
05/22/2022 19:09:01 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
05/22/2022 19:09:03 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7321217522600314 on epoch=256
05/22/2022 19:09:05 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
05/22/2022 19:09:08 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
05/22/2022 19:09:10 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
05/22/2022 19:09:13 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
05/22/2022 19:09:15 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
05/22/2022 19:09:17 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7431643625192013 on epoch=262
05/22/2022 19:09:19 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
05/22/2022 19:09:22 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
05/22/2022 19:09:24 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=266
05/22/2022 19:09:27 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=267
05/22/2022 19:09:29 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
05/22/2022 19:09:31 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7533831763930869 on epoch=268
05/22/2022 19:09:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7487142220399551 -> 0.7533831763930869 on epoch=268, global_step=2150
05/22/2022 19:09:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
05/22/2022 19:09:36 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
05/22/2022 19:09:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=272
05/22/2022 19:09:41 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 19:09:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
05/22/2022 19:09:45 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7533831763930869 on epoch=274
05/22/2022 19:09:48 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 19:09:50 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
05/22/2022 19:09:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
05/22/2022 19:09:55 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
05/22/2022 19:09:57 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
05/22/2022 19:09:59 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.7395074859981448 on epoch=281
05/22/2022 19:10:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=282
05/22/2022 19:10:04 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=283
05/22/2022 19:10:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=284
05/22/2022 19:10:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
05/22/2022 19:10:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
05/22/2022 19:10:13 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7285365624706656 on epoch=287
05/22/2022 19:10:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
05/22/2022 19:10:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
05/22/2022 19:10:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=291
05/22/2022 19:10:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
05/22/2022 19:10:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=293
05/22/2022 19:10:27 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7505343687199276 on epoch=293
05/22/2022 19:10:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.00 on epoch=294
05/22/2022 19:10:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
05/22/2022 19:10:35 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
05/22/2022 19:10:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 19:10:40 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
05/22/2022 19:10:42 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.744260060673723 on epoch=299
05/22/2022 19:10:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
05/22/2022 19:10:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
05/22/2022 19:10:49 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=303
05/22/2022 19:10:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
05/22/2022 19:10:54 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.00 on epoch=306
05/22/2022 19:10:56 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7394072940947941 on epoch=306
05/22/2022 19:10:58 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
05/22/2022 19:11:01 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
05/22/2022 19:11:03 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
05/22/2022 19:11:06 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
05/22/2022 19:11:08 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
05/22/2022 19:11:10 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7464750464750465 on epoch=312
05/22/2022 19:11:13 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=313
05/22/2022 19:11:15 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
05/22/2022 19:11:18 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=316
05/22/2022 19:11:20 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
05/22/2022 19:11:23 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
05/22/2022 19:11:24 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7452166222179168 on epoch=318
05/22/2022 19:11:27 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=319
05/22/2022 19:11:29 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 19:11:32 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.00 on epoch=322
05/22/2022 19:11:34 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
05/22/2022 19:11:37 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
05/22/2022 19:11:39 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.744836875314332 on epoch=324
05/22/2022 19:11:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
05/22/2022 19:11:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
05/22/2022 19:11:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
05/22/2022 19:11:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
05/22/2022 19:11:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=331
05/22/2022 19:11:53 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7373253983867795 on epoch=331
05/22/2022 19:11:55 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
05/22/2022 19:11:58 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
05/22/2022 19:12:00 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
05/22/2022 19:12:03 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=336
05/22/2022 19:12:05 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 19:12:07 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7431643625192013 on epoch=337
05/22/2022 19:12:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 19:12:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 19:12:14 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
05/22/2022 19:12:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
05/22/2022 19:12:19 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 19:12:21 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.744338768115942 on epoch=343
05/22/2022 19:12:23 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=344
05/22/2022 19:12:26 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=346
05/22/2022 19:12:28 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
05/22/2022 19:12:31 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
05/22/2022 19:12:33 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
05/22/2022 19:12:35 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7275666883875839 on epoch=349
05/22/2022 19:12:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.12 on epoch=351
05/22/2022 19:12:40 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
05/22/2022 19:12:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
05/22/2022 19:12:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=354
05/22/2022 19:12:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
05/22/2022 19:12:49 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.728221104694877 on epoch=356
05/22/2022 19:12:52 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=357
05/22/2022 19:12:54 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
05/22/2022 19:12:57 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 19:12:59 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
05/22/2022 19:13:02 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
05/22/2022 19:13:03 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7276056877777254 on epoch=362
05/22/2022 19:13:06 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 19:13:08 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
05/22/2022 19:13:11 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 19:13:13 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
05/22/2022 19:13:16 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
05/22/2022 19:13:17 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.743040293040293 on epoch=368
05/22/2022 19:13:20 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 19:13:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.13 on epoch=371
05/22/2022 19:13:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 19:13:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
05/22/2022 19:13:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
05/22/2022 19:13:31 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:13:31 - INFO - __main__ - Printing 3 examples
05/22/2022 19:13:31 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:13:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:13:31 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:13:31 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:13:31 - INFO - __main__ - Printing 3 examples
05/22/2022 19:13:31 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 19:13:31 - INFO - __main__ - ['others']
05/22/2022 19:13:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:13:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:13:31 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7453624139517903 on epoch=374
05/22/2022 19:13:31 - INFO - __main__ - save last model!
05/22/2022 19:13:32 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 19:13:32 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 19:13:32 - INFO - __main__ - Printing 3 examples
05/22/2022 19:13:32 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 19:13:32 - INFO - __main__ - ['others']
05/22/2022 19:13:32 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 19:13:32 - INFO - __main__ - ['others']
05/22/2022 19:13:32 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 19:13:32 - INFO - __main__ - ['others']
05/22/2022 19:13:32 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:13:32 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:13:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:13:39 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 19:13:50 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:13:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:13:51 - INFO - __main__ - Starting training!
05/22/2022 19:14:53 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_13_0.4_8_predictions.txt
05/22/2022 19:14:53 - INFO - __main__ - Classification-F1 on test data: 0.3681
05/22/2022 19:14:53 - INFO - __main__ - prefix=emo_32_13, lr=0.4, bsz=8, dev_performance=0.7533831763930869, test_performance=0.36809620019334666
05/22/2022 19:14:53 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.3, bsz=8 ...
05/22/2022 19:14:54 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:14:54 - INFO - __main__ - Printing 3 examples
05/22/2022 19:14:54 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:14:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:14:54 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:14:54 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:14:54 - INFO - __main__ - Printing 3 examples
05/22/2022 19:14:54 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 19:14:54 - INFO - __main__ - ['others']
05/22/2022 19:14:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:14:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:14:54 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:15:09 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:15:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:15:10 - INFO - __main__ - Starting training!
05/22/2022 19:15:14 - INFO - __main__ - Step 10 Global step 10 Train loss 4.18 on epoch=1
05/22/2022 19:15:16 - INFO - __main__ - Step 20 Global step 20 Train loss 2.93 on epoch=2
05/22/2022 19:15:19 - INFO - __main__ - Step 30 Global step 30 Train loss 2.80 on epoch=3
05/22/2022 19:15:21 - INFO - __main__ - Step 40 Global step 40 Train loss 2.27 on epoch=4
05/22/2022 19:15:24 - INFO - __main__ - Step 50 Global step 50 Train loss 1.97 on epoch=6
05/22/2022 19:15:25 - INFO - __main__ - Global step 50 Train loss 2.83 Classification-F1 0.006349206349206349 on epoch=6
05/22/2022 19:15:25 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.006349206349206349 on epoch=6, global_step=50
05/22/2022 19:15:28 - INFO - __main__ - Step 60 Global step 60 Train loss 1.72 on epoch=7
05/22/2022 19:15:30 - INFO - __main__ - Step 70 Global step 70 Train loss 1.52 on epoch=8
05/22/2022 19:15:33 - INFO - __main__ - Step 80 Global step 80 Train loss 1.26 on epoch=9
05/22/2022 19:15:35 - INFO - __main__ - Step 90 Global step 90 Train loss 1.08 on epoch=11
05/22/2022 19:15:38 - INFO - __main__ - Step 100 Global step 100 Train loss 0.90 on epoch=12
05/22/2022 19:15:39 - INFO - __main__ - Global step 100 Train loss 1.30 Classification-F1 0.30541243819932345 on epoch=12
05/22/2022 19:15:39 - INFO - __main__ - Saving model with best Classification-F1: 0.006349206349206349 -> 0.30541243819932345 on epoch=12, global_step=100
05/22/2022 19:15:42 - INFO - __main__ - Step 110 Global step 110 Train loss 1.02 on epoch=13
05/22/2022 19:15:44 - INFO - __main__ - Step 120 Global step 120 Train loss 0.89 on epoch=14
05/22/2022 19:15:47 - INFO - __main__ - Step 130 Global step 130 Train loss 0.74 on epoch=16
05/22/2022 19:15:49 - INFO - __main__ - Step 140 Global step 140 Train loss 0.71 on epoch=17
05/22/2022 19:15:52 - INFO - __main__ - Step 150 Global step 150 Train loss 0.88 on epoch=18
05/22/2022 19:15:54 - INFO - __main__ - Global step 150 Train loss 0.85 Classification-F1 0.3791575091575092 on epoch=18
05/22/2022 19:15:54 - INFO - __main__ - Saving model with best Classification-F1: 0.30541243819932345 -> 0.3791575091575092 on epoch=18, global_step=150
05/22/2022 19:15:56 - INFO - __main__ - Step 160 Global step 160 Train loss 0.70 on epoch=19
05/22/2022 19:15:59 - INFO - __main__ - Step 170 Global step 170 Train loss 0.61 on epoch=21
05/22/2022 19:16:01 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
05/22/2022 19:16:04 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=23
05/22/2022 19:16:06 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=24
05/22/2022 19:16:08 - INFO - __main__ - Global step 200 Train loss 0.65 Classification-F1 0.4337316204921839 on epoch=24
05/22/2022 19:16:08 - INFO - __main__ - Saving model with best Classification-F1: 0.3791575091575092 -> 0.4337316204921839 on epoch=24, global_step=200
05/22/2022 19:16:10 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=26
05/22/2022 19:16:13 - INFO - __main__ - Step 220 Global step 220 Train loss 0.53 on epoch=27
05/22/2022 19:16:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=28
05/22/2022 19:16:18 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=29
05/22/2022 19:16:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.52 on epoch=31
05/22/2022 19:16:22 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.4831881898097151 on epoch=31
05/22/2022 19:16:22 - INFO - __main__ - Saving model with best Classification-F1: 0.4337316204921839 -> 0.4831881898097151 on epoch=31, global_step=250
05/22/2022 19:16:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.66 on epoch=32
05/22/2022 19:16:27 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=33
05/22/2022 19:16:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=34
05/22/2022 19:16:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=36
05/22/2022 19:16:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.65 on epoch=37
05/22/2022 19:16:36 - INFO - __main__ - Global step 300 Train loss 0.55 Classification-F1 0.5932527657187092 on epoch=37
05/22/2022 19:16:36 - INFO - __main__ - Saving model with best Classification-F1: 0.4831881898097151 -> 0.5932527657187092 on epoch=37, global_step=300
05/22/2022 19:16:39 - INFO - __main__ - Step 310 Global step 310 Train loss 0.47 on epoch=38
05/22/2022 19:16:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.56 on epoch=39
05/22/2022 19:16:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.51 on epoch=41
05/22/2022 19:16:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.59 on epoch=42
05/22/2022 19:16:48 - INFO - __main__ - Step 350 Global step 350 Train loss 0.44 on epoch=43
05/22/2022 19:16:50 - INFO - __main__ - Global step 350 Train loss 0.51 Classification-F1 0.49243510113075323 on epoch=43
05/22/2022 19:16:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.48 on epoch=44
05/22/2022 19:16:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=46
05/22/2022 19:16:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=47
05/22/2022 19:17:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.57 on epoch=48
05/22/2022 19:17:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=49
05/22/2022 19:17:04 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.6411508366437944 on epoch=49
05/22/2022 19:17:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5932527657187092 -> 0.6411508366437944 on epoch=49, global_step=400
05/22/2022 19:17:07 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=51
05/22/2022 19:17:09 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=52
05/22/2022 19:17:12 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=53
05/22/2022 19:17:14 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=54
05/22/2022 19:17:17 - INFO - __main__ - Step 450 Global step 450 Train loss 0.33 on epoch=56
05/22/2022 19:17:18 - INFO - __main__ - Global step 450 Train loss 0.38 Classification-F1 0.6486395544504722 on epoch=56
05/22/2022 19:17:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6411508366437944 -> 0.6486395544504722 on epoch=56, global_step=450
05/22/2022 19:17:21 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=57
05/22/2022 19:17:23 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=58
05/22/2022 19:17:26 - INFO - __main__ - Step 480 Global step 480 Train loss 0.38 on epoch=59
05/22/2022 19:17:28 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=61
05/22/2022 19:17:31 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=62
05/22/2022 19:17:32 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.6552848193473193 on epoch=62
05/22/2022 19:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6486395544504722 -> 0.6552848193473193 on epoch=62, global_step=500
05/22/2022 19:17:35 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=63
05/22/2022 19:17:37 - INFO - __main__ - Step 520 Global step 520 Train loss 0.34 on epoch=64
05/22/2022 19:17:40 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=66
05/22/2022 19:17:42 - INFO - __main__ - Step 540 Global step 540 Train loss 0.45 on epoch=67
05/22/2022 19:17:45 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=68
05/22/2022 19:17:46 - INFO - __main__ - Global step 550 Train loss 0.38 Classification-F1 0.6556286196911197 on epoch=68
05/22/2022 19:17:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6552848193473193 -> 0.6556286196911197 on epoch=68, global_step=550
05/22/2022 19:17:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=69
05/22/2022 19:17:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=71
05/22/2022 19:17:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=72
05/22/2022 19:17:56 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=73
05/22/2022 19:17:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=74
05/22/2022 19:18:01 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6652846144326275 on epoch=74
05/22/2022 19:18:01 - INFO - __main__ - Saving model with best Classification-F1: 0.6556286196911197 -> 0.6652846144326275 on epoch=74, global_step=600
05/22/2022 19:18:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.27 on epoch=76
05/22/2022 19:18:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=77
05/22/2022 19:18:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=78
05/22/2022 19:18:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=79
05/22/2022 19:18:13 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=81
05/22/2022 19:18:15 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.6754758164066884 on epoch=81
05/22/2022 19:18:15 - INFO - __main__ - Saving model with best Classification-F1: 0.6652846144326275 -> 0.6754758164066884 on epoch=81, global_step=650
05/22/2022 19:18:17 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=82
05/22/2022 19:18:20 - INFO - __main__ - Step 670 Global step 670 Train loss 0.36 on epoch=83
05/22/2022 19:18:22 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=84
05/22/2022 19:18:25 - INFO - __main__ - Step 690 Global step 690 Train loss 0.25 on epoch=86
05/22/2022 19:18:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=87
05/22/2022 19:18:29 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.6740811965811966 on epoch=87
05/22/2022 19:18:31 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=88
05/22/2022 19:18:34 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=89
05/22/2022 19:18:36 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=91
05/22/2022 19:18:39 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=92
05/22/2022 19:18:41 - INFO - __main__ - Step 750 Global step 750 Train loss 0.24 on epoch=93
05/22/2022 19:18:43 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.707710781831457 on epoch=93
05/22/2022 19:18:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6754758164066884 -> 0.707710781831457 on epoch=93, global_step=750
05/22/2022 19:18:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.22 on epoch=94
05/22/2022 19:18:48 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=96
05/22/2022 19:18:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=97
05/22/2022 19:18:53 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=98
05/22/2022 19:18:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=99
05/22/2022 19:18:57 - INFO - __main__ - Global step 800 Train loss 0.28 Classification-F1 0.7257585022290904 on epoch=99
05/22/2022 19:18:57 - INFO - __main__ - Saving model with best Classification-F1: 0.707710781831457 -> 0.7257585022290904 on epoch=99, global_step=800
05/22/2022 19:19:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=101
05/22/2022 19:19:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=102
05/22/2022 19:19:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=103
05/22/2022 19:19:07 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=104
05/22/2022 19:19:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.23 on epoch=106
05/22/2022 19:19:12 - INFO - __main__ - Global step 850 Train loss 0.23 Classification-F1 0.7161984427609427 on epoch=106
05/22/2022 19:19:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=107
05/22/2022 19:19:17 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=108
05/22/2022 19:19:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=109
05/22/2022 19:19:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.21 on epoch=111
05/22/2022 19:19:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=112
05/22/2022 19:19:26 - INFO - __main__ - Global step 900 Train loss 0.24 Classification-F1 0.7320524961149962 on epoch=112
05/22/2022 19:19:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7257585022290904 -> 0.7320524961149962 on epoch=112, global_step=900
05/22/2022 19:19:29 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=113
05/22/2022 19:19:31 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=114
05/22/2022 19:19:34 - INFO - __main__ - Step 930 Global step 930 Train loss 0.11 on epoch=116
05/22/2022 19:19:36 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=117
05/22/2022 19:19:39 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=118
05/22/2022 19:19:40 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.7156926406926407 on epoch=118
05/22/2022 19:19:43 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=119
05/22/2022 19:19:45 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=121
05/22/2022 19:19:48 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=122
05/22/2022 19:19:50 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=123
05/22/2022 19:19:53 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=124
05/22/2022 19:19:55 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7389779812082894 on epoch=124
05/22/2022 19:19:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7320524961149962 -> 0.7389779812082894 on epoch=124, global_step=1000
05/22/2022 19:19:57 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=126
05/22/2022 19:20:00 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=127
05/22/2022 19:20:02 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=128
05/22/2022 19:20:05 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.17 on epoch=129
05/22/2022 19:20:07 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.21 on epoch=131
05/22/2022 19:20:09 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.7139484467314656 on epoch=131
05/22/2022 19:20:12 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=132
05/22/2022 19:20:14 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.22 on epoch=133
05/22/2022 19:20:17 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=134
05/22/2022 19:20:19 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.15 on epoch=136
05/22/2022 19:20:22 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=137
05/22/2022 19:20:23 - INFO - __main__ - Global step 1100 Train loss 0.16 Classification-F1 0.7313803704856787 on epoch=137
05/22/2022 19:20:26 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.15 on epoch=138
05/22/2022 19:20:28 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.15 on epoch=139
05/22/2022 19:20:31 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=141
05/22/2022 19:20:34 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=142
05/22/2022 19:20:36 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=143
05/22/2022 19:20:38 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7151655601537678 on epoch=143
05/22/2022 19:20:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=144
05/22/2022 19:20:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=146
05/22/2022 19:20:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=147
05/22/2022 19:20:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=148
05/22/2022 19:20:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=149
05/22/2022 19:20:52 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.7128280791061364 on epoch=149
05/22/2022 19:20:55 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.09 on epoch=151
05/22/2022 19:20:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=152
05/22/2022 19:21:00 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=153
05/22/2022 19:21:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=154
05/22/2022 19:21:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=156
05/22/2022 19:21:06 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.72520711143695 on epoch=156
05/22/2022 19:21:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.08 on epoch=157
05/22/2022 19:21:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.12 on epoch=158
05/22/2022 19:21:14 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
05/22/2022 19:21:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.16 on epoch=161
05/22/2022 19:21:19 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=162
05/22/2022 19:21:21 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.7218830128205128 on epoch=162
05/22/2022 19:21:23 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=163
05/22/2022 19:21:26 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=164
05/22/2022 19:21:28 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=166
05/22/2022 19:21:31 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=167
05/22/2022 19:21:33 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.15 on epoch=168
05/22/2022 19:21:35 - INFO - __main__ - Global step 1350 Train loss 0.10 Classification-F1 0.7140945311997944 on epoch=168
05/22/2022 19:21:38 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.09 on epoch=169
05/22/2022 19:21:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=171
05/22/2022 19:21:43 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=172
05/22/2022 19:21:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=173
05/22/2022 19:21:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=174
05/22/2022 19:21:49 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.723054244767135 on epoch=174
05/22/2022 19:21:52 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=176
05/22/2022 19:21:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=177
05/22/2022 19:21:57 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=178
05/22/2022 19:21:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=179
05/22/2022 19:22:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
05/22/2022 19:22:04 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.5945902736420734 on epoch=181
05/22/2022 19:22:06 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.04 on epoch=182
05/22/2022 19:22:09 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=183
05/22/2022 19:22:11 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=184
05/22/2022 19:22:14 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=186
05/22/2022 19:22:16 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=187
05/22/2022 19:22:18 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7282726181979913 on epoch=187
05/22/2022 19:22:21 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.12 on epoch=188
05/22/2022 19:22:23 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
05/22/2022 19:22:26 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
05/22/2022 19:22:28 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=192
05/22/2022 19:22:31 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
05/22/2022 19:22:32 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7121358503711445 on epoch=193
05/22/2022 19:22:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=194
05/22/2022 19:22:37 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.06 on epoch=196
05/22/2022 19:22:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=197
05/22/2022 19:22:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
05/22/2022 19:22:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=199
05/22/2022 19:22:47 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.7187280040221217 on epoch=199
05/22/2022 19:22:49 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=201
05/22/2022 19:22:52 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
05/22/2022 19:22:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
05/22/2022 19:22:57 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=204
05/22/2022 19:22:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
05/22/2022 19:23:01 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.7296355551659313 on epoch=206
05/22/2022 19:23:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=207
05/22/2022 19:23:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
05/22/2022 19:23:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
05/22/2022 19:23:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=211
05/22/2022 19:23:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
05/22/2022 19:23:15 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7392862645622233 on epoch=212
05/22/2022 19:23:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7389779812082894 -> 0.7392862645622233 on epoch=212, global_step=1700
05/22/2022 19:23:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=213
05/22/2022 19:23:20 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
05/22/2022 19:23:22 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=216
05/22/2022 19:23:25 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
05/22/2022 19:23:28 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=218
05/22/2022 19:23:29 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7390615326574834 on epoch=218
05/22/2022 19:23:32 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
05/22/2022 19:23:34 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=221
05/22/2022 19:23:37 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
05/22/2022 19:23:39 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
05/22/2022 19:23:42 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=224
05/22/2022 19:23:44 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7279735089795859 on epoch=224
05/22/2022 19:23:46 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=226
05/22/2022 19:23:49 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
05/22/2022 19:23:51 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
05/22/2022 19:23:54 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=229
05/22/2022 19:23:56 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.02 on epoch=231
05/22/2022 19:23:58 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7367330016583747 on epoch=231
05/22/2022 19:24:00 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=232
05/22/2022 19:24:03 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
05/22/2022 19:24:05 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
05/22/2022 19:24:08 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
05/22/2022 19:24:11 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=237
05/22/2022 19:24:12 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7526087907633845 on epoch=237
05/22/2022 19:24:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7392862645622233 -> 0.7526087907633845 on epoch=237, global_step=1900
05/22/2022 19:24:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=238
05/22/2022 19:24:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=239
05/22/2022 19:24:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=241
05/22/2022 19:24:22 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=242
05/22/2022 19:24:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=243
05/22/2022 19:24:26 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.7465911659460046 on epoch=243
05/22/2022 19:24:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
05/22/2022 19:24:32 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=246
05/22/2022 19:24:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
05/22/2022 19:24:37 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=248
05/22/2022 19:24:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=249
05/22/2022 19:24:41 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7460168104340086 on epoch=249
05/22/2022 19:24:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=251
05/22/2022 19:24:46 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
05/22/2022 19:24:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=253
05/22/2022 19:24:51 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
05/22/2022 19:24:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=256
05/22/2022 19:24:56 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7460168104340086 on epoch=256
05/22/2022 19:24:58 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=257
05/22/2022 19:25:01 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.10 on epoch=258
05/22/2022 19:25:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
05/22/2022 19:25:06 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
05/22/2022 19:25:09 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
05/22/2022 19:25:10 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7258099052388475 on epoch=262
05/22/2022 19:25:13 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=263
05/22/2022 19:25:16 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=264
05/22/2022 19:25:18 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=266
05/22/2022 19:25:21 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
05/22/2022 19:25:23 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
05/22/2022 19:25:25 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7472740555360419 on epoch=268
05/22/2022 19:25:28 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=269
05/22/2022 19:25:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=271
05/22/2022 19:25:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=272
05/22/2022 19:25:36 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 19:25:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=274
05/22/2022 19:25:40 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7211709162200134 on epoch=274
05/22/2022 19:25:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.09 on epoch=276
05/22/2022 19:25:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
05/22/2022 19:25:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
05/22/2022 19:25:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
05/22/2022 19:25:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
05/22/2022 19:25:54 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7468969948769455 on epoch=281
05/22/2022 19:25:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.11 on epoch=282
05/22/2022 19:26:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
05/22/2022 19:26:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 19:26:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=286
05/22/2022 19:26:07 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=287
05/22/2022 19:26:09 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7397945804195805 on epoch=287
05/22/2022 19:26:12 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
05/22/2022 19:26:14 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
05/22/2022 19:26:17 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=291
05/22/2022 19:26:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
05/22/2022 19:26:22 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
05/22/2022 19:26:24 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7531164487686226 on epoch=293
05/22/2022 19:26:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7526087907633845 -> 0.7531164487686226 on epoch=293, global_step=2350
05/22/2022 19:26:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
05/22/2022 19:26:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
05/22/2022 19:26:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
05/22/2022 19:26:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=298
05/22/2022 19:26:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=299
05/22/2022 19:26:38 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7159565580618212 on epoch=299
05/22/2022 19:26:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
05/22/2022 19:26:43 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
05/22/2022 19:26:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=303
05/22/2022 19:26:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
05/22/2022 19:26:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 19:26:53 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7278213087036616 on epoch=306
05/22/2022 19:26:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
05/22/2022 19:26:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
05/22/2022 19:27:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
05/22/2022 19:27:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
05/22/2022 19:27:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
05/22/2022 19:27:07 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.586090653242429 on epoch=312
05/22/2022 19:27:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
05/22/2022 19:27:12 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 19:27:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
05/22/2022 19:27:17 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
05/22/2022 19:27:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
05/22/2022 19:27:21 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.591501230516817 on epoch=318
05/22/2022 19:27:24 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
05/22/2022 19:27:26 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=321
05/22/2022 19:27:29 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
05/22/2022 19:27:31 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
05/22/2022 19:27:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
05/22/2022 19:27:36 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.744759705779045 on epoch=324
05/22/2022 19:27:38 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 19:27:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
05/22/2022 19:27:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
05/22/2022 19:27:45 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 19:27:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
05/22/2022 19:27:50 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.6047771238417 on epoch=331
05/22/2022 19:27:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
05/22/2022 19:27:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
05/22/2022 19:27:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
05/22/2022 19:28:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
05/22/2022 19:28:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
05/22/2022 19:28:04 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7528254738412214 on epoch=337
05/22/2022 19:28:07 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=338
05/22/2022 19:28:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
05/22/2022 19:28:12 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
05/22/2022 19:28:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 19:28:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=343
05/22/2022 19:28:18 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7522799492047042 on epoch=343
05/22/2022 19:28:21 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
05/22/2022 19:28:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 19:28:26 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
05/22/2022 19:28:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
05/22/2022 19:28:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 19:28:33 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7234018980726619 on epoch=349
05/22/2022 19:28:35 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
05/22/2022 19:28:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
05/22/2022 19:28:40 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
05/22/2022 19:28:43 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
05/22/2022 19:28:45 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=356
05/22/2022 19:28:47 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7438402124908259 on epoch=356
05/22/2022 19:28:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
05/22/2022 19:28:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=358
05/22/2022 19:28:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 19:28:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.07 on epoch=361
05/22/2022 19:28:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=362
05/22/2022 19:29:01 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.5980549389567147 on epoch=362
05/22/2022 19:29:04 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
05/22/2022 19:29:06 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
05/22/2022 19:29:09 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 19:29:11 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
05/22/2022 19:29:14 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
05/22/2022 19:29:15 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5980549389567147 on epoch=368
05/22/2022 19:29:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
05/22/2022 19:29:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 19:29:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
05/22/2022 19:29:25 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
05/22/2022 19:29:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
05/22/2022 19:29:29 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:29:29 - INFO - __main__ - Printing 3 examples
05/22/2022 19:29:29 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 19:29:29 - INFO - __main__ - ['others']
05/22/2022 19:29:29 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 19:29:29 - INFO - __main__ - ['others']
05/22/2022 19:29:29 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 19:29:29 - INFO - __main__ - ['others']
05/22/2022 19:29:29 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:29:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:29:30 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7131592039800995 on epoch=374
05/22/2022 19:29:30 - INFO - __main__ - save last model!
05/22/2022 19:29:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 19:29:30 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:29:30 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:29:30 - INFO - __main__ - Printing 3 examples
05/22/2022 19:29:30 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:29:30 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 19:29:30 - INFO - __main__ - Printing 3 examples
05/22/2022 19:29:30 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 19:29:30 - INFO - __main__ - ['others']
05/22/2022 19:29:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:29:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:29:30 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:29:32 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:29:37 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 19:29:46 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:29:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:29:46 - INFO - __main__ - Starting training!
05/22/2022 19:30:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_13_0.3_8_predictions.txt
05/22/2022 19:30:50 - INFO - __main__ - Classification-F1 on test data: 0.3604
05/22/2022 19:30:51 - INFO - __main__ - prefix=emo_32_13, lr=0.3, bsz=8, dev_performance=0.7531164487686226, test_performance=0.36035136982511007
05/22/2022 19:30:51 - INFO - __main__ - Running ... prefix=emo_32_13, lr=0.2, bsz=8 ...
05/22/2022 19:30:52 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:30:52 - INFO - __main__ - Printing 3 examples
05/22/2022 19:30:52 - INFO - __main__ -  [emo] you picture you sent one to my phone you sent one to my phone
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ -  [emo] it's boring without you is not boring on a date no not on date
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ -  [emo] really  hmph yes i just didn't bother to find out before how can you call me without having my number
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:30:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:30:52 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:30:52 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:30:52 - INFO - __main__ - Printing 3 examples
05/22/2022 19:30:52 - INFO - __main__ -  [emo] please be my other half your who sorry don't be like that okkkk then my gi
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ -  [emo] i'll catch you after a short  what if you don't can i
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ -  [emo] u oly first  no you no u
05/22/2022 19:30:52 - INFO - __main__ - ['others']
05/22/2022 19:30:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:30:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:30:52 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:31:07 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:31:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:31:08 - INFO - __main__ - Starting training!
05/22/2022 19:31:11 - INFO - __main__ - Step 10 Global step 10 Train loss 4.52 on epoch=1
05/22/2022 19:31:14 - INFO - __main__ - Step 20 Global step 20 Train loss 3.52 on epoch=2
05/22/2022 19:31:16 - INFO - __main__ - Step 30 Global step 30 Train loss 2.89 on epoch=3
05/22/2022 19:31:19 - INFO - __main__ - Step 40 Global step 40 Train loss 2.79 on epoch=4
05/22/2022 19:31:21 - INFO - __main__ - Step 50 Global step 50 Train loss 2.58 on epoch=6
05/22/2022 19:31:23 - INFO - __main__ - Global step 50 Train loss 3.26 Classification-F1 0.009856809856809857 on epoch=6
05/22/2022 19:31:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.009856809856809857 on epoch=6, global_step=50
05/22/2022 19:31:26 - INFO - __main__ - Step 60 Global step 60 Train loss 2.12 on epoch=7
05/22/2022 19:31:28 - INFO - __main__ - Step 70 Global step 70 Train loss 2.09 on epoch=8
05/22/2022 19:31:31 - INFO - __main__ - Step 80 Global step 80 Train loss 1.90 on epoch=9
05/22/2022 19:31:33 - INFO - __main__ - Step 90 Global step 90 Train loss 1.71 on epoch=11
05/22/2022 19:31:36 - INFO - __main__ - Step 100 Global step 100 Train loss 1.55 on epoch=12
05/22/2022 19:31:38 - INFO - __main__ - Global step 100 Train loss 1.87 Classification-F1 0.14554376657824936 on epoch=12
05/22/2022 19:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.009856809856809857 -> 0.14554376657824936 on epoch=12, global_step=100
05/22/2022 19:31:40 - INFO - __main__ - Step 110 Global step 110 Train loss 1.34 on epoch=13
05/22/2022 19:31:42 - INFO - __main__ - Step 120 Global step 120 Train loss 1.32 on epoch=14
05/22/2022 19:31:45 - INFO - __main__ - Step 130 Global step 130 Train loss 1.17 on epoch=16
05/22/2022 19:31:48 - INFO - __main__ - Step 140 Global step 140 Train loss 0.97 on epoch=17
05/22/2022 19:31:50 - INFO - __main__ - Step 150 Global step 150 Train loss 0.94 on epoch=18
05/22/2022 19:31:52 - INFO - __main__ - Global step 150 Train loss 1.15 Classification-F1 0.3790017268705793 on epoch=18
05/22/2022 19:31:52 - INFO - __main__ - Saving model with best Classification-F1: 0.14554376657824936 -> 0.3790017268705793 on epoch=18, global_step=150
05/22/2022 19:31:54 - INFO - __main__ - Step 160 Global step 160 Train loss 0.93 on epoch=19
05/22/2022 19:31:57 - INFO - __main__ - Step 170 Global step 170 Train loss 0.85 on epoch=21
05/22/2022 19:31:59 - INFO - __main__ - Step 180 Global step 180 Train loss 0.83 on epoch=22
05/22/2022 19:32:02 - INFO - __main__ - Step 190 Global step 190 Train loss 0.93 on epoch=23
05/22/2022 19:32:04 - INFO - __main__ - Step 200 Global step 200 Train loss 0.78 on epoch=24
05/22/2022 19:32:06 - INFO - __main__ - Global step 200 Train loss 0.86 Classification-F1 0.40340591308333246 on epoch=24
05/22/2022 19:32:06 - INFO - __main__ - Saving model with best Classification-F1: 0.3790017268705793 -> 0.40340591308333246 on epoch=24, global_step=200
05/22/2022 19:32:08 - INFO - __main__ - Step 210 Global step 210 Train loss 0.87 on epoch=26
05/22/2022 19:32:11 - INFO - __main__ - Step 220 Global step 220 Train loss 0.61 on epoch=27
05/22/2022 19:32:13 - INFO - __main__ - Step 230 Global step 230 Train loss 0.76 on epoch=28
05/22/2022 19:32:16 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=29
05/22/2022 19:32:18 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=31
05/22/2022 19:32:20 - INFO - __main__ - Global step 250 Train loss 0.70 Classification-F1 0.4012840957737838 on epoch=31
05/22/2022 19:32:23 - INFO - __main__ - Step 260 Global step 260 Train loss 0.66 on epoch=32
05/22/2022 19:32:25 - INFO - __main__ - Step 270 Global step 270 Train loss 0.71 on epoch=33
05/22/2022 19:32:28 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=34
05/22/2022 19:32:30 - INFO - __main__ - Step 290 Global step 290 Train loss 0.56 on epoch=36
05/22/2022 19:32:33 - INFO - __main__ - Step 300 Global step 300 Train loss 0.64 on epoch=37
05/22/2022 19:32:34 - INFO - __main__ - Global step 300 Train loss 0.63 Classification-F1 0.4546973772797191 on epoch=37
05/22/2022 19:32:34 - INFO - __main__ - Saving model with best Classification-F1: 0.40340591308333246 -> 0.4546973772797191 on epoch=37, global_step=300
05/22/2022 19:32:37 - INFO - __main__ - Step 310 Global step 310 Train loss 0.53 on epoch=38
05/22/2022 19:32:39 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=39
05/22/2022 19:32:42 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=41
05/22/2022 19:32:44 - INFO - __main__ - Step 340 Global step 340 Train loss 0.54 on epoch=42
05/22/2022 19:32:47 - INFO - __main__ - Step 350 Global step 350 Train loss 0.68 on epoch=43
05/22/2022 19:32:48 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.43353047297827285 on epoch=43
05/22/2022 19:32:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=44
05/22/2022 19:32:53 - INFO - __main__ - Step 370 Global step 370 Train loss 0.54 on epoch=46
05/22/2022 19:32:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.56 on epoch=47
05/22/2022 19:32:58 - INFO - __main__ - Step 390 Global step 390 Train loss 0.58 on epoch=48
05/22/2022 19:33:01 - INFO - __main__ - Step 400 Global step 400 Train loss 0.54 on epoch=49
05/22/2022 19:33:03 - INFO - __main__ - Global step 400 Train loss 0.57 Classification-F1 0.4823831375904176 on epoch=49
05/22/2022 19:33:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4546973772797191 -> 0.4823831375904176 on epoch=49, global_step=400
05/22/2022 19:33:05 - INFO - __main__ - Step 410 Global step 410 Train loss 0.44 on epoch=51
05/22/2022 19:33:08 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=52
05/22/2022 19:33:10 - INFO - __main__ - Step 430 Global step 430 Train loss 0.53 on epoch=53
05/22/2022 19:33:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.58 on epoch=54
05/22/2022 19:33:15 - INFO - __main__ - Step 450 Global step 450 Train loss 0.47 on epoch=56
05/22/2022 19:33:17 - INFO - __main__ - Global step 450 Train loss 0.50 Classification-F1 0.49591913720559067 on epoch=56
05/22/2022 19:33:17 - INFO - __main__ - Saving model with best Classification-F1: 0.4823831375904176 -> 0.49591913720559067 on epoch=56, global_step=450
05/22/2022 19:33:19 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=57
05/22/2022 19:33:22 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=58
05/22/2022 19:33:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.44 on epoch=59
05/22/2022 19:33:27 - INFO - __main__ - Step 490 Global step 490 Train loss 0.39 on epoch=61
05/22/2022 19:33:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.43 on epoch=62
05/22/2022 19:33:31 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.4922251590362219 on epoch=62
05/22/2022 19:33:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.48 on epoch=63
05/22/2022 19:33:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.45 on epoch=64
05/22/2022 19:33:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.44 on epoch=66
05/22/2022 19:33:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.47 on epoch=67
05/22/2022 19:33:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.39 on epoch=68
05/22/2022 19:33:45 - INFO - __main__ - Global step 550 Train loss 0.45 Classification-F1 0.6140847451431913 on epoch=68
05/22/2022 19:33:45 - INFO - __main__ - Saving model with best Classification-F1: 0.49591913720559067 -> 0.6140847451431913 on epoch=68, global_step=550
05/22/2022 19:33:48 - INFO - __main__ - Step 560 Global step 560 Train loss 0.36 on epoch=69
05/22/2022 19:33:50 - INFO - __main__ - Step 570 Global step 570 Train loss 0.35 on epoch=71
05/22/2022 19:33:53 - INFO - __main__ - Step 580 Global step 580 Train loss 0.50 on epoch=72
05/22/2022 19:33:55 - INFO - __main__ - Step 590 Global step 590 Train loss 0.47 on epoch=73
05/22/2022 19:33:58 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=74
05/22/2022 19:33:59 - INFO - __main__ - Global step 600 Train loss 0.41 Classification-F1 0.6230641516532343 on epoch=74
05/22/2022 19:33:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6140847451431913 -> 0.6230641516532343 on epoch=74, global_step=600
05/22/2022 19:34:02 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=76
05/22/2022 19:34:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=77
05/22/2022 19:34:07 - INFO - __main__ - Step 630 Global step 630 Train loss 0.37 on epoch=78
05/22/2022 19:34:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=79
05/22/2022 19:34:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.40 on epoch=81
05/22/2022 19:34:13 - INFO - __main__ - Global step 650 Train loss 0.37 Classification-F1 0.6148776969175966 on epoch=81
05/22/2022 19:34:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=82
05/22/2022 19:34:18 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=83
05/22/2022 19:34:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=84
05/22/2022 19:34:23 - INFO - __main__ - Step 690 Global step 690 Train loss 0.34 on epoch=86
05/22/2022 19:34:26 - INFO - __main__ - Step 700 Global step 700 Train loss 0.31 on epoch=87
05/22/2022 19:34:27 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.6597753314456587 on epoch=87
05/22/2022 19:34:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6230641516532343 -> 0.6597753314456587 on epoch=87, global_step=700
05/22/2022 19:34:30 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=88
05/22/2022 19:34:32 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=89
05/22/2022 19:34:35 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=91
05/22/2022 19:34:37 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=92
05/22/2022 19:34:40 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=93
05/22/2022 19:34:41 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.6718677973472494 on epoch=93
05/22/2022 19:34:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6597753314456587 -> 0.6718677973472494 on epoch=93, global_step=750
05/22/2022 19:34:44 - INFO - __main__ - Step 760 Global step 760 Train loss 0.29 on epoch=94
05/22/2022 19:34:46 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=96
05/22/2022 19:34:49 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=97
05/22/2022 19:34:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=98
05/22/2022 19:34:54 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=99
05/22/2022 19:34:55 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.6792713123981987 on epoch=99
05/22/2022 19:34:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6718677973472494 -> 0.6792713123981987 on epoch=99, global_step=800
05/22/2022 19:34:58 - INFO - __main__ - Step 810 Global step 810 Train loss 0.33 on epoch=101
05/22/2022 19:35:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=102
05/22/2022 19:35:03 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=103
05/22/2022 19:35:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.35 on epoch=104
05/22/2022 19:35:08 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=106
05/22/2022 19:35:10 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.7007002352600917 on epoch=106
05/22/2022 19:35:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6792713123981987 -> 0.7007002352600917 on epoch=106, global_step=850
05/22/2022 19:35:12 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=107
05/22/2022 19:35:15 - INFO - __main__ - Step 870 Global step 870 Train loss 0.33 on epoch=108
05/22/2022 19:35:17 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=109
05/22/2022 19:35:19 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=111
05/22/2022 19:35:22 - INFO - __main__ - Step 900 Global step 900 Train loss 0.32 on epoch=112
05/22/2022 19:35:24 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.6829385029738526 on epoch=112
05/22/2022 19:35:26 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=113
05/22/2022 19:35:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=114
05/22/2022 19:35:31 - INFO - __main__ - Step 930 Global step 930 Train loss 0.25 on epoch=116
05/22/2022 19:35:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.26 on epoch=117
05/22/2022 19:35:36 - INFO - __main__ - Step 950 Global step 950 Train loss 0.34 on epoch=118
05/22/2022 19:35:38 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.6990541087761976 on epoch=118
05/22/2022 19:35:40 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=119
05/22/2022 19:35:43 - INFO - __main__ - Step 970 Global step 970 Train loss 0.22 on epoch=121
05/22/2022 19:35:45 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=122
05/22/2022 19:35:48 - INFO - __main__ - Step 990 Global step 990 Train loss 0.31 on epoch=123
05/22/2022 19:35:50 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.18 on epoch=124
05/22/2022 19:35:52 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.6819234154929578 on epoch=124
05/22/2022 19:35:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
05/22/2022 19:35:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.31 on epoch=127
05/22/2022 19:35:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.25 on epoch=128
05/22/2022 19:36:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.27 on epoch=129
05/22/2022 19:36:04 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=131
05/22/2022 19:36:06 - INFO - __main__ - Global step 1050 Train loss 0.25 Classification-F1 0.7100015794045644 on epoch=131
05/22/2022 19:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7007002352600917 -> 0.7100015794045644 on epoch=131, global_step=1050
05/22/2022 19:36:08 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.27 on epoch=132
05/22/2022 19:36:11 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.27 on epoch=133
05/22/2022 19:36:13 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=134
05/22/2022 19:36:16 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.28 on epoch=136
05/22/2022 19:36:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=137
05/22/2022 19:36:20 - INFO - __main__ - Global step 1100 Train loss 0.26 Classification-F1 0.7056997884770347 on epoch=137
05/22/2022 19:36:22 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=138
05/22/2022 19:36:25 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.20 on epoch=139
05/22/2022 19:36:27 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.23 on epoch=141
05/22/2022 19:36:30 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.25 on epoch=142
05/22/2022 19:36:32 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.27 on epoch=143
05/22/2022 19:36:34 - INFO - __main__ - Global step 1150 Train loss 0.23 Classification-F1 0.6909220278938588 on epoch=143
05/22/2022 19:36:36 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=144
05/22/2022 19:36:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.16 on epoch=146
05/22/2022 19:36:41 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=147
05/22/2022 19:36:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=148
05/22/2022 19:36:46 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.25 on epoch=149
05/22/2022 19:36:48 - INFO - __main__ - Global step 1200 Train loss 0.20 Classification-F1 0.7252800446830298 on epoch=149
05/22/2022 19:36:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7100015794045644 -> 0.7252800446830298 on epoch=149, global_step=1200
05/22/2022 19:36:50 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=151
05/22/2022 19:36:53 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=152
05/22/2022 19:36:56 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.24 on epoch=153
05/22/2022 19:36:58 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
05/22/2022 19:37:01 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.19 on epoch=156
05/22/2022 19:37:02 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.7067765567765568 on epoch=156
05/22/2022 19:37:05 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.24 on epoch=157
05/22/2022 19:37:07 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.25 on epoch=158
05/22/2022 19:37:10 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.22 on epoch=159
05/22/2022 19:37:12 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=161
05/22/2022 19:37:15 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=162
05/22/2022 19:37:16 - INFO - __main__ - Global step 1300 Train loss 0.22 Classification-F1 0.700868541861189 on epoch=162
05/22/2022 19:37:19 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.20 on epoch=163
05/22/2022 19:37:21 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=164
05/22/2022 19:37:24 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=166
05/22/2022 19:37:26 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=167
05/22/2022 19:37:29 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.24 on epoch=168
05/22/2022 19:37:30 - INFO - __main__ - Global step 1350 Train loss 0.20 Classification-F1 0.7222363328495405 on epoch=168
05/22/2022 19:37:33 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.20 on epoch=169
05/22/2022 19:37:35 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.16 on epoch=171
05/22/2022 19:37:38 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=172
05/22/2022 19:37:40 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=173
05/22/2022 19:37:43 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=174
05/22/2022 19:37:45 - INFO - __main__ - Global step 1400 Train loss 0.18 Classification-F1 0.707435712761417 on epoch=174
05/22/2022 19:37:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=176
05/22/2022 19:37:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.18 on epoch=177
05/22/2022 19:37:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=178
05/22/2022 19:37:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=179
05/22/2022 19:37:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=181
05/22/2022 19:37:59 - INFO - __main__ - Global step 1450 Train loss 0.17 Classification-F1 0.7167804621848739 on epoch=181
05/22/2022 19:38:01 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.21 on epoch=182
05/22/2022 19:38:04 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.24 on epoch=183
05/22/2022 19:38:06 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.16 on epoch=184
05/22/2022 19:38:09 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.15 on epoch=186
05/22/2022 19:38:11 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=187
05/22/2022 19:38:13 - INFO - __main__ - Global step 1500 Train loss 0.18 Classification-F1 0.7213213553720629 on epoch=187
05/22/2022 19:38:15 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=188
05/22/2022 19:38:18 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.18 on epoch=189
05/22/2022 19:38:20 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=191
05/22/2022 19:38:23 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=192
05/22/2022 19:38:25 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.17 on epoch=193
05/22/2022 19:38:27 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.7089525058275058 on epoch=193
05/22/2022 19:38:29 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=194
05/22/2022 19:38:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.17 on epoch=196
05/22/2022 19:38:34 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.19 on epoch=197
05/22/2022 19:38:37 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.24 on epoch=198
05/22/2022 19:38:39 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.14 on epoch=199
05/22/2022 19:38:41 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.7556755470406786 on epoch=199
05/22/2022 19:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7252800446830298 -> 0.7556755470406786 on epoch=199, global_step=1600
05/22/2022 19:38:43 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.12 on epoch=201
05/22/2022 19:38:46 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=202
05/22/2022 19:38:48 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.14 on epoch=203
05/22/2022 19:38:51 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=204
05/22/2022 19:38:53 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=206
05/22/2022 19:38:55 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7310747166879243 on epoch=206
05/22/2022 19:38:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=207
05/22/2022 19:39:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=208
05/22/2022 19:39:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=209
05/22/2022 19:39:05 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
05/22/2022 19:39:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=212
05/22/2022 19:39:09 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.7067520986153062 on epoch=212
05/22/2022 19:39:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.19 on epoch=213
05/22/2022 19:39:14 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
05/22/2022 19:39:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.10 on epoch=216
05/22/2022 19:39:19 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=217
05/22/2022 19:39:22 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=218
05/22/2022 19:39:23 - INFO - __main__ - Global step 1750 Train loss 0.12 Classification-F1 0.7228911713286714 on epoch=218
05/22/2022 19:39:26 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.11 on epoch=219
05/22/2022 19:39:28 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=221
05/22/2022 19:39:31 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
05/22/2022 19:39:33 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.15 on epoch=223
05/22/2022 19:39:36 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=224
05/22/2022 19:39:38 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.7077161308293385 on epoch=224
05/22/2022 19:39:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.14 on epoch=226
05/22/2022 19:39:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=227
05/22/2022 19:39:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.13 on epoch=228
05/22/2022 19:39:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=229
05/22/2022 19:39:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=231
05/22/2022 19:39:52 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.7245971541344078 on epoch=231
05/22/2022 19:39:54 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=232
05/22/2022 19:39:57 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
05/22/2022 19:39:59 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
05/22/2022 19:40:02 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=236
05/22/2022 19:40:04 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
05/22/2022 19:40:06 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7259368352505491 on epoch=237
05/22/2022 19:40:08 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.16 on epoch=238
05/22/2022 19:40:11 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=239
05/22/2022 19:40:13 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.10 on epoch=241
05/22/2022 19:40:16 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=242
05/22/2022 19:40:18 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=243
05/22/2022 19:40:20 - INFO - __main__ - Global step 1950 Train loss 0.12 Classification-F1 0.7148940384234502 on epoch=243
05/22/2022 19:40:23 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.14 on epoch=244
05/22/2022 19:40:25 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.08 on epoch=246
05/22/2022 19:40:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.09 on epoch=247
05/22/2022 19:40:30 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.10 on epoch=248
05/22/2022 19:40:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=249
05/22/2022 19:40:34 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.7393510099055873 on epoch=249
05/22/2022 19:40:37 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=251
05/22/2022 19:40:39 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=252
05/22/2022 19:40:42 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=253
05/22/2022 19:40:44 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.06 on epoch=254
05/22/2022 19:40:47 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=256
05/22/2022 19:40:48 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.7397945804195805 on epoch=256
05/22/2022 19:40:51 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=257
05/22/2022 19:40:53 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=258
05/22/2022 19:40:56 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=259
05/22/2022 19:40:58 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.07 on epoch=261
05/22/2022 19:41:01 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.14 on epoch=262
05/22/2022 19:41:02 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.7213213553720629 on epoch=262
05/22/2022 19:41:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
05/22/2022 19:41:07 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=264
05/22/2022 19:41:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=266
05/22/2022 19:41:12 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.07 on epoch=267
05/22/2022 19:41:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=268
05/22/2022 19:41:16 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7560920231972863 on epoch=268
05/22/2022 19:41:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7556755470406786 -> 0.7560920231972863 on epoch=268, global_step=2150
05/22/2022 19:41:19 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=269
05/22/2022 19:41:21 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=271
05/22/2022 19:41:24 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=272
05/22/2022 19:41:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=273
05/22/2022 19:41:29 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
05/22/2022 19:41:31 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7399064637721625 on epoch=274
05/22/2022 19:41:33 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=276
05/22/2022 19:41:36 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
05/22/2022 19:41:38 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
05/22/2022 19:41:41 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=279
05/22/2022 19:41:43 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=281
05/22/2022 19:41:45 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.7544300086831076 on epoch=281
05/22/2022 19:41:47 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=282
05/22/2022 19:41:50 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=283
05/22/2022 19:41:52 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=284
05/22/2022 19:41:55 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
05/22/2022 19:41:57 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=287
05/22/2022 19:41:59 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.7404712057038659 on epoch=287
05/22/2022 19:42:01 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.11 on epoch=288
05/22/2022 19:42:04 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=289
05/22/2022 19:42:06 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=291
05/22/2022 19:42:09 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=292
05/22/2022 19:42:11 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=293
05/22/2022 19:42:13 - INFO - __main__ - Global step 2350 Train loss 0.08 Classification-F1 0.7295834247118803 on epoch=293
05/22/2022 19:42:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.05 on epoch=294
05/22/2022 19:42:18 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=296
05/22/2022 19:42:21 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=297
05/22/2022 19:42:23 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.12 on epoch=298
05/22/2022 19:42:26 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
05/22/2022 19:42:27 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7375036284470247 on epoch=299
05/22/2022 19:42:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
05/22/2022 19:42:32 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=302
05/22/2022 19:42:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=303
05/22/2022 19:42:37 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=304
05/22/2022 19:42:40 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=306
05/22/2022 19:42:41 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7285496794871795 on epoch=306
05/22/2022 19:42:44 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
05/22/2022 19:42:46 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
05/22/2022 19:42:49 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
05/22/2022 19:42:52 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=311
05/22/2022 19:42:54 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=312
05/22/2022 19:42:56 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.7375722103982973 on epoch=312
05/22/2022 19:42:58 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=313
05/22/2022 19:43:01 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
05/22/2022 19:43:03 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=316
05/22/2022 19:43:06 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.12 on epoch=317
05/22/2022 19:43:08 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=318
05/22/2022 19:43:10 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.746401392248245 on epoch=318
05/22/2022 19:43:12 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=319
05/22/2022 19:43:15 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=321
05/22/2022 19:43:17 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=322
05/22/2022 19:43:20 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
05/22/2022 19:43:22 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
05/22/2022 19:43:24 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7281446540880503 on epoch=324
05/22/2022 19:43:26 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=326
05/22/2022 19:43:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=327
05/22/2022 19:43:31 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=328
05/22/2022 19:43:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.12 on epoch=329
05/22/2022 19:43:36 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
05/22/2022 19:43:38 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7360028131619051 on epoch=331
05/22/2022 19:43:40 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
05/22/2022 19:43:43 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=333
05/22/2022 19:43:45 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=334
05/22/2022 19:43:48 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
05/22/2022 19:43:50 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=337
05/22/2022 19:43:52 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7311642870372608 on epoch=337
05/22/2022 19:43:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
05/22/2022 19:43:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 19:44:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=341
05/22/2022 19:44:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
05/22/2022 19:44:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.08 on epoch=343
05/22/2022 19:44:06 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7479579780949644 on epoch=343
05/22/2022 19:44:09 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
05/22/2022 19:44:11 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 19:44:14 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=347
05/22/2022 19:44:16 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
05/22/2022 19:44:19 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
05/22/2022 19:44:20 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7109915329768272 on epoch=349
05/22/2022 19:44:23 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
05/22/2022 19:44:25 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=352
05/22/2022 19:44:28 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
05/22/2022 19:44:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=354
05/22/2022 19:44:33 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=356
05/22/2022 19:44:34 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7558299339549339 on epoch=356
05/22/2022 19:44:37 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
05/22/2022 19:44:39 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=358
05/22/2022 19:44:42 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=359
05/22/2022 19:44:44 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=361
05/22/2022 19:44:47 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=362
05/22/2022 19:44:49 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7550437564522071 on epoch=362
05/22/2022 19:44:51 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=363
05/22/2022 19:44:53 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
05/22/2022 19:44:56 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.08 on epoch=366
05/22/2022 19:44:58 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.07 on epoch=367
05/22/2022 19:45:01 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=368
05/22/2022 19:45:03 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7397911947207723 on epoch=368
05/22/2022 19:45:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.05 on epoch=369
05/22/2022 19:45:08 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=371
05/22/2022 19:45:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
05/22/2022 19:45:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=373
05/22/2022 19:45:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
05/22/2022 19:45:16 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:45:16 - INFO - __main__ - Printing 3 examples
05/22/2022 19:45:16 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 19:45:16 - INFO - __main__ - ['sad']
05/22/2022 19:45:16 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 19:45:16 - INFO - __main__ - ['sad']
05/22/2022 19:45:16 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 19:45:16 - INFO - __main__ - ['sad']
05/22/2022 19:45:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:45:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:45:17 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:45:17 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:45:17 - INFO - __main__ - Printing 3 examples
05/22/2022 19:45:17 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 19:45:17 - INFO - __main__ - ['sad']
05/22/2022 19:45:17 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 19:45:17 - INFO - __main__ - ['sad']
05/22/2022 19:45:17 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 19:45:17 - INFO - __main__ - ['sad']
05/22/2022 19:45:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:45:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:45:17 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7407136980666392 on epoch=374
05/22/2022 19:45:17 - INFO - __main__ - save last model!
05/22/2022 19:45:17 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 19:45:17 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 19:45:17 - INFO - __main__ - Printing 3 examples
05/22/2022 19:45:17 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 19:45:17 - INFO - __main__ - ['others']
05/22/2022 19:45:17 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 19:45:17 - INFO - __main__ - ['others']
05/22/2022 19:45:17 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 19:45:17 - INFO - __main__ - ['others']
05/22/2022 19:45:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:45:17 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:45:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:45:24 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 19:45:35 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:45:36 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:45:36 - INFO - __main__ - Starting training!
05/22/2022 19:46:38 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_13_0.2_8_predictions.txt
05/22/2022 19:46:38 - INFO - __main__ - Classification-F1 on test data: 0.3709
05/22/2022 19:46:38 - INFO - __main__ - prefix=emo_32_13, lr=0.2, bsz=8, dev_performance=0.7560920231972863, test_performance=0.37093357072501376
05/22/2022 19:46:38 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.5, bsz=8 ...
05/22/2022 19:46:39 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:46:39 - INFO - __main__ - Printing 3 examples
05/22/2022 19:46:39 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:46:39 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:46:39 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 19:46:39 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 19:46:39 - INFO - __main__ - Printing 3 examples
05/22/2022 19:46:39 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 19:46:39 - INFO - __main__ - ['sad']
05/22/2022 19:46:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 19:46:39 - INFO - __main__ - Tokenizing Output ...
05/22/2022 19:46:39 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 19:46:54 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 19:46:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 19:46:55 - INFO - __main__ - Starting training!
05/22/2022 19:46:58 - INFO - __main__ - Step 10 Global step 10 Train loss 3.74 on epoch=1
05/22/2022 19:47:00 - INFO - __main__ - Step 20 Global step 20 Train loss 2.63 on epoch=2
05/22/2022 19:47:03 - INFO - __main__ - Step 30 Global step 30 Train loss 1.90 on epoch=3
05/22/2022 19:47:05 - INFO - __main__ - Step 40 Global step 40 Train loss 1.63 on epoch=4
05/22/2022 19:47:08 - INFO - __main__ - Step 50 Global step 50 Train loss 1.17 on epoch=6
05/22/2022 19:47:09 - INFO - __main__ - Global step 50 Train loss 2.21 Classification-F1 0.23128205128205132 on epoch=6
05/22/2022 19:47:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.23128205128205132 on epoch=6, global_step=50
05/22/2022 19:47:12 - INFO - __main__ - Step 60 Global step 60 Train loss 1.20 on epoch=7
05/22/2022 19:47:14 - INFO - __main__ - Step 70 Global step 70 Train loss 0.84 on epoch=8
05/22/2022 19:47:17 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
05/22/2022 19:47:19 - INFO - __main__ - Step 90 Global step 90 Train loss 0.73 on epoch=11
05/22/2022 19:47:22 - INFO - __main__ - Step 100 Global step 100 Train loss 0.76 on epoch=12
05/22/2022 19:47:23 - INFO - __main__ - Global step 100 Train loss 0.89 Classification-F1 0.49383691810383107 on epoch=12
05/22/2022 19:47:23 - INFO - __main__ - Saving model with best Classification-F1: 0.23128205128205132 -> 0.49383691810383107 on epoch=12, global_step=100
05/22/2022 19:47:26 - INFO - __main__ - Step 110 Global step 110 Train loss 0.76 on epoch=13
05/22/2022 19:47:28 - INFO - __main__ - Step 120 Global step 120 Train loss 0.64 on epoch=14
05/22/2022 19:47:30 - INFO - __main__ - Step 130 Global step 130 Train loss 0.53 on epoch=16
05/22/2022 19:47:33 - INFO - __main__ - Step 140 Global step 140 Train loss 0.61 on epoch=17
05/22/2022 19:47:35 - INFO - __main__ - Step 150 Global step 150 Train loss 0.64 on epoch=18
05/22/2022 19:47:37 - INFO - __main__ - Global step 150 Train loss 0.63 Classification-F1 0.5581587704618463 on epoch=18
05/22/2022 19:47:37 - INFO - __main__ - Saving model with best Classification-F1: 0.49383691810383107 -> 0.5581587704618463 on epoch=18, global_step=150
05/22/2022 19:47:39 - INFO - __main__ - Step 160 Global step 160 Train loss 0.57 on epoch=19
05/22/2022 19:47:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.64 on epoch=21
05/22/2022 19:47:44 - INFO - __main__ - Step 180 Global step 180 Train loss 0.56 on epoch=22
05/22/2022 19:47:46 - INFO - __main__ - Step 190 Global step 190 Train loss 0.56 on epoch=23
05/22/2022 19:47:49 - INFO - __main__ - Step 200 Global step 200 Train loss 0.47 on epoch=24
05/22/2022 19:47:50 - INFO - __main__ - Global step 200 Train loss 0.56 Classification-F1 0.6799866050559853 on epoch=24
05/22/2022 19:47:51 - INFO - __main__ - Saving model with best Classification-F1: 0.5581587704618463 -> 0.6799866050559853 on epoch=24, global_step=200
05/22/2022 19:47:53 - INFO - __main__ - Step 210 Global step 210 Train loss 0.54 on epoch=26
05/22/2022 19:47:55 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=27
05/22/2022 19:47:58 - INFO - __main__ - Step 230 Global step 230 Train loss 0.56 on epoch=28
05/22/2022 19:48:00 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=29
05/22/2022 19:48:03 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=31
05/22/2022 19:48:04 - INFO - __main__ - Global step 250 Train loss 0.54 Classification-F1 0.6981280193236715 on epoch=31
05/22/2022 19:48:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6799866050559853 -> 0.6981280193236715 on epoch=31, global_step=250
05/22/2022 19:48:07 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=32
05/22/2022 19:48:09 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=33
05/22/2022 19:48:11 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=34
05/22/2022 19:48:14 - INFO - __main__ - Step 290 Global step 290 Train loss 0.39 on epoch=36
05/22/2022 19:48:16 - INFO - __main__ - Step 300 Global step 300 Train loss 0.59 on epoch=37
05/22/2022 19:48:18 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.7050503821472348 on epoch=37
05/22/2022 19:48:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6981280193236715 -> 0.7050503821472348 on epoch=37, global_step=300
05/22/2022 19:48:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.41 on epoch=38
05/22/2022 19:48:23 - INFO - __main__ - Step 320 Global step 320 Train loss 0.34 on epoch=39
05/22/2022 19:48:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=41
05/22/2022 19:48:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=42
05/22/2022 19:48:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=43
05/22/2022 19:48:31 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.7054389541252521 on epoch=43
05/22/2022 19:48:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7050503821472348 -> 0.7054389541252521 on epoch=43, global_step=350
05/22/2022 19:48:34 - INFO - __main__ - Step 360 Global step 360 Train loss 0.40 on epoch=44
05/22/2022 19:48:36 - INFO - __main__ - Step 370 Global step 370 Train loss 0.39 on epoch=46
05/22/2022 19:48:39 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=47
05/22/2022 19:48:41 - INFO - __main__ - Step 390 Global step 390 Train loss 0.44 on epoch=48
05/22/2022 19:48:44 - INFO - __main__ - Step 400 Global step 400 Train loss 0.33 on epoch=49
05/22/2022 19:48:45 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.7097956165120345 on epoch=49
05/22/2022 19:48:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7054389541252521 -> 0.7097956165120345 on epoch=49, global_step=400
05/22/2022 19:48:48 - INFO - __main__ - Step 410 Global step 410 Train loss 0.34 on epoch=51
05/22/2022 19:48:50 - INFO - __main__ - Step 420 Global step 420 Train loss 0.48 on epoch=52
05/22/2022 19:48:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.41 on epoch=53
05/22/2022 19:48:55 - INFO - __main__ - Step 440 Global step 440 Train loss 0.28 on epoch=54
05/22/2022 19:48:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=56
05/22/2022 19:48:59 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.6837474120082816 on epoch=56
05/22/2022 19:49:01 - INFO - __main__ - Step 460 Global step 460 Train loss 0.35 on epoch=57
05/22/2022 19:49:04 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=58
05/22/2022 19:49:06 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=59
05/22/2022 19:49:08 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=61
05/22/2022 19:49:11 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=62
05/22/2022 19:49:12 - INFO - __main__ - Global step 500 Train loss 0.32 Classification-F1 0.6725351963586325 on epoch=62
05/22/2022 19:49:15 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=63
05/22/2022 19:49:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=64
05/22/2022 19:49:20 - INFO - __main__ - Step 530 Global step 530 Train loss 0.28 on epoch=66
05/22/2022 19:49:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.28 on epoch=67
05/22/2022 19:49:24 - INFO - __main__ - Step 550 Global step 550 Train loss 0.29 on epoch=68
05/22/2022 19:49:26 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.667143438286548 on epoch=68
05/22/2022 19:49:28 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=69
05/22/2022 19:49:31 - INFO - __main__ - Step 570 Global step 570 Train loss 0.28 on epoch=71
05/22/2022 19:49:33 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=72
05/22/2022 19:49:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=73
05/22/2022 19:49:38 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=74
05/22/2022 19:49:40 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.6964094728800612 on epoch=74
05/22/2022 19:49:42 - INFO - __main__ - Step 610 Global step 610 Train loss 0.28 on epoch=76
05/22/2022 19:49:44 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=77
05/22/2022 19:49:47 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=78
05/22/2022 19:49:49 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=79
05/22/2022 19:49:51 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=81
05/22/2022 19:49:53 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.7011702568351286 on epoch=81
05/22/2022 19:49:56 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=82
05/22/2022 19:49:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=83
05/22/2022 19:50:01 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=84
05/22/2022 19:50:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=86
05/22/2022 19:50:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.30 on epoch=87
05/22/2022 19:50:07 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.7129655186589187 on epoch=87
05/22/2022 19:50:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7097956165120345 -> 0.7129655186589187 on epoch=87, global_step=700
05/22/2022 19:50:10 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=88
05/22/2022 19:50:12 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=89
05/22/2022 19:50:14 - INFO - __main__ - Step 730 Global step 730 Train loss 0.18 on epoch=91
05/22/2022 19:50:17 - INFO - __main__ - Step 740 Global step 740 Train loss 0.30 on epoch=92
05/22/2022 19:50:19 - INFO - __main__ - Step 750 Global step 750 Train loss 0.16 on epoch=93
05/22/2022 19:50:21 - INFO - __main__ - Global step 750 Train loss 0.21 Classification-F1 0.7283677433677433 on epoch=93
05/22/2022 19:50:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7129655186589187 -> 0.7283677433677433 on epoch=93, global_step=750
05/22/2022 19:50:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=94
05/22/2022 19:50:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=96
05/22/2022 19:50:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=97
05/22/2022 19:50:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.12 on epoch=98
05/22/2022 19:50:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.16 on epoch=99
05/22/2022 19:50:34 - INFO - __main__ - Global step 800 Train loss 0.16 Classification-F1 0.673634984296749 on epoch=99
05/22/2022 19:50:37 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=101
05/22/2022 19:50:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.16 on epoch=102
05/22/2022 19:50:42 - INFO - __main__ - Step 830 Global step 830 Train loss 0.19 on epoch=103
05/22/2022 19:50:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.12 on epoch=104
05/22/2022 19:50:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=106
05/22/2022 19:50:48 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.7374153439792559 on epoch=106
05/22/2022 19:50:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7283677433677433 -> 0.7374153439792559 on epoch=106, global_step=850
05/22/2022 19:50:50 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=107
05/22/2022 19:50:53 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=108
05/22/2022 19:50:55 - INFO - __main__ - Step 880 Global step 880 Train loss 0.13 on epoch=109
05/22/2022 19:50:58 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=111
05/22/2022 19:51:00 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=112
05/22/2022 19:51:02 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.7179924755826084 on epoch=112
05/22/2022 19:51:04 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=113
05/22/2022 19:51:07 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=114
05/22/2022 19:51:09 - INFO - __main__ - Step 930 Global step 930 Train loss 0.06 on epoch=116
05/22/2022 19:51:11 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=117
05/22/2022 19:51:14 - INFO - __main__ - Step 950 Global step 950 Train loss 0.09 on epoch=118
05/22/2022 19:51:16 - INFO - __main__ - Global step 950 Train loss 0.12 Classification-F1 0.7448061831623476 on epoch=118
05/22/2022 19:51:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7374153439792559 -> 0.7448061831623476 on epoch=118, global_step=950
05/22/2022 19:51:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=119
05/22/2022 19:51:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=121
05/22/2022 19:51:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=122
05/22/2022 19:51:25 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=123
05/22/2022 19:51:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=124
05/22/2022 19:51:29 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.7407389191552327 on epoch=124
05/22/2022 19:51:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=126
05/22/2022 19:51:34 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=127
05/22/2022 19:51:36 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=128
05/22/2022 19:51:39 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.06 on epoch=129
05/22/2022 19:51:41 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=131
05/22/2022 19:51:43 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7210028773780713 on epoch=131
05/22/2022 19:51:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=132
05/22/2022 19:51:48 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=133
05/22/2022 19:51:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=134
05/22/2022 19:51:53 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=136
05/22/2022 19:51:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=137
05/22/2022 19:51:57 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.7294258373205741 on epoch=137
05/22/2022 19:51:59 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=138
05/22/2022 19:52:02 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=139
05/22/2022 19:52:04 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=141
05/22/2022 19:52:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=142
05/22/2022 19:52:09 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=143
05/22/2022 19:52:10 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.7193443265102307 on epoch=143
05/22/2022 19:52:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=144
05/22/2022 19:52:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=146
05/22/2022 19:52:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.06 on epoch=147
05/22/2022 19:52:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=148
05/22/2022 19:52:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=149
05/22/2022 19:52:24 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7779890248640249 on epoch=149
05/22/2022 19:52:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7448061831623476 -> 0.7779890248640249 on epoch=149, global_step=1200
05/22/2022 19:52:26 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=151
05/22/2022 19:52:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=152
05/22/2022 19:52:31 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.02 on epoch=153
05/22/2022 19:52:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=154
05/22/2022 19:52:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
05/22/2022 19:52:38 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7270591812523572 on epoch=156
05/22/2022 19:52:40 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=157
05/22/2022 19:52:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=158
05/22/2022 19:52:45 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=159
05/22/2022 19:52:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=161
05/22/2022 19:52:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=162
05/22/2022 19:52:52 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7713128411755661 on epoch=162
05/22/2022 19:52:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=163
05/22/2022 19:52:56 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.04 on epoch=164
05/22/2022 19:52:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=166
05/22/2022 19:53:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=167
05/22/2022 19:53:04 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=168
05/22/2022 19:53:05 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7267596782302664 on epoch=168
05/22/2022 19:53:08 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=169
05/22/2022 19:53:10 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=171
05/22/2022 19:53:12 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.01 on epoch=172
05/22/2022 19:53:15 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=173
05/22/2022 19:53:17 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.03 on epoch=174
05/22/2022 19:53:19 - INFO - __main__ - Global step 1400 Train loss 0.02 Classification-F1 0.7533422459893048 on epoch=174
05/22/2022 19:53:21 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=176
05/22/2022 19:53:24 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=177
05/22/2022 19:53:26 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.04 on epoch=178
05/22/2022 19:53:29 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=179
05/22/2022 19:53:31 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=181
05/22/2022 19:53:33 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7441130915897758 on epoch=181
05/22/2022 19:53:35 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=182
05/22/2022 19:53:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.01 on epoch=183
05/22/2022 19:53:40 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
05/22/2022 19:53:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=186
05/22/2022 19:53:45 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
05/22/2022 19:53:46 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7349693265102308 on epoch=187
05/22/2022 19:53:49 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=188
05/22/2022 19:53:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=189
05/22/2022 19:53:54 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=191
05/22/2022 19:53:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
05/22/2022 19:53:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
05/22/2022 19:54:00 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7172365745273781 on epoch=193
05/22/2022 19:54:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=194
05/22/2022 19:54:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=196
05/22/2022 19:54:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=197
05/22/2022 19:54:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=198
05/22/2022 19:54:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=199
05/22/2022 19:54:14 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.7113572434936666 on epoch=199
05/22/2022 19:54:16 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=201
05/22/2022 19:54:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=202
05/22/2022 19:54:21 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=203
05/22/2022 19:54:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
05/22/2022 19:54:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=206
05/22/2022 19:54:28 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7709609845509297 on epoch=206
05/22/2022 19:54:30 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
05/22/2022 19:54:32 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
05/22/2022 19:54:35 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.07 on epoch=209
05/22/2022 19:54:37 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=211
05/22/2022 19:54:40 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=212
05/22/2022 19:54:41 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7305248624833578 on epoch=212
05/22/2022 19:54:44 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=213
05/22/2022 19:54:46 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=214
05/22/2022 19:54:49 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.00 on epoch=216
05/22/2022 19:54:51 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=217
05/22/2022 19:54:54 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=218
05/22/2022 19:54:55 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.6958290568697524 on epoch=218
05/22/2022 19:54:58 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
05/22/2022 19:55:00 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=221
05/22/2022 19:55:03 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=222
05/22/2022 19:55:05 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
05/22/2022 19:55:08 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=224
05/22/2022 19:55:09 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6983115306066126 on epoch=224
05/22/2022 19:55:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=226
05/22/2022 19:55:14 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=227
05/22/2022 19:55:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=228
05/22/2022 19:55:19 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=229
05/22/2022 19:55:22 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
05/22/2022 19:55:24 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7260780687651055 on epoch=231
05/22/2022 19:55:26 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 19:55:28 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=233
05/22/2022 19:55:31 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=234
05/22/2022 19:55:33 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=236
05/22/2022 19:55:36 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=237
05/22/2022 19:55:37 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.746474358974359 on epoch=237
05/22/2022 19:55:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
05/22/2022 19:55:42 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
05/22/2022 19:55:45 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
05/22/2022 19:55:47 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
05/22/2022 19:55:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
05/22/2022 19:55:51 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.7407286580640162 on epoch=243
05/22/2022 19:55:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=244
05/22/2022 19:55:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
05/22/2022 19:55:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.01 on epoch=247
05/22/2022 19:56:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=248
05/22/2022 19:56:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.00 on epoch=249
05/22/2022 19:56:05 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6952509503557648 on epoch=249
05/22/2022 19:56:08 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.01 on epoch=251
05/22/2022 19:56:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=252
05/22/2022 19:56:13 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.00 on epoch=253
05/22/2022 19:56:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
05/22/2022 19:56:18 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
05/22/2022 19:56:19 - INFO - __main__ - Global step 2050 Train loss 0.01 Classification-F1 0.7634387620379001 on epoch=256
05/22/2022 19:56:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=257
05/22/2022 19:56:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
05/22/2022 19:56:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=259
05/22/2022 19:56:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
05/22/2022 19:56:31 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=262
05/22/2022 19:56:33 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7551629205749907 on epoch=262
05/22/2022 19:56:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
05/22/2022 19:56:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.00 on epoch=264
05/22/2022 19:56:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
05/22/2022 19:56:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
05/22/2022 19:56:45 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
05/22/2022 19:56:47 - INFO - __main__ - Global step 2150 Train loss 0.01 Classification-F1 0.7214395773717808 on epoch=268
05/22/2022 19:56:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=269
05/22/2022 19:56:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
05/22/2022 19:56:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
05/22/2022 19:56:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 19:56:59 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=274
05/22/2022 19:57:01 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.7491169561750226 on epoch=274
05/22/2022 19:57:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=276
05/22/2022 19:57:06 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
05/22/2022 19:57:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.03 on epoch=278
05/22/2022 19:57:11 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
05/22/2022 19:57:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=281
05/22/2022 19:57:15 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7565855745132061 on epoch=281
05/22/2022 19:57:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=282
05/22/2022 19:57:20 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=283
05/22/2022 19:57:23 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 19:57:25 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=286
05/22/2022 19:57:27 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
05/22/2022 19:57:29 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.7488445446914036 on epoch=287
05/22/2022 19:57:32 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=288
05/22/2022 19:57:34 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=289
05/22/2022 19:57:37 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=291
05/22/2022 19:57:39 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
05/22/2022 19:57:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
05/22/2022 19:57:43 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.715449822258682 on epoch=293
05/22/2022 19:57:46 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
05/22/2022 19:57:48 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=296
05/22/2022 19:57:50 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=297
05/22/2022 19:57:53 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 19:57:55 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
05/22/2022 19:57:57 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7064014142567224 on epoch=299
05/22/2022 19:58:00 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
05/22/2022 19:58:02 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=302
05/22/2022 19:58:05 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
05/22/2022 19:58:07 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
05/22/2022 19:58:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=306
05/22/2022 19:58:11 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7082544191919192 on epoch=306
05/22/2022 19:58:14 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
05/22/2022 19:58:16 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
05/22/2022 19:58:18 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
05/22/2022 19:58:21 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.07 on epoch=311
05/22/2022 19:58:23 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
05/22/2022 19:58:25 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7372712978845055 on epoch=312
05/22/2022 19:58:28 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=313
05/22/2022 19:58:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 19:58:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
05/22/2022 19:58:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.00 on epoch=317
05/22/2022 19:58:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
05/22/2022 19:58:39 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.7464108031272211 on epoch=318
05/22/2022 19:58:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.00 on epoch=319
05/22/2022 19:58:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 19:58:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
05/22/2022 19:58:49 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
05/22/2022 19:58:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.00 on epoch=324
05/22/2022 19:58:53 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.7144623316498316 on epoch=324
05/22/2022 19:58:56 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 19:58:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
05/22/2022 19:59:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
05/22/2022 19:59:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=329
05/22/2022 19:59:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
05/22/2022 19:59:07 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.724391433587119 on epoch=331
05/22/2022 19:59:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=332
05/22/2022 19:59:12 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.00 on epoch=333
05/22/2022 19:59:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
05/22/2022 19:59:17 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=336
05/22/2022 19:59:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.00 on epoch=337
05/22/2022 19:59:21 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7339672819274337 on epoch=337
05/22/2022 19:59:24 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 19:59:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 19:59:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
05/22/2022 19:59:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 19:59:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
05/22/2022 19:59:35 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.6976590875836363 on epoch=343
05/22/2022 19:59:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=344
05/22/2022 19:59:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 19:59:42 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
05/22/2022 19:59:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
05/22/2022 19:59:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=349
05/22/2022 19:59:49 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.7559849076242517 on epoch=349
05/22/2022 19:59:51 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=351
05/22/2022 19:59:54 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 19:59:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
05/22/2022 19:59:59 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
05/22/2022 20:00:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=356
05/22/2022 20:00:03 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7305085663294619 on epoch=356
05/22/2022 20:00:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=357
05/22/2022 20:00:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
05/22/2022 20:00:10 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=359
05/22/2022 20:00:13 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.00 on epoch=361
05/22/2022 20:00:15 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
05/22/2022 20:00:17 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6883751883751883 on epoch=362
05/22/2022 20:00:20 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 20:00:22 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
05/22/2022 20:00:24 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
05/22/2022 20:00:27 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
05/22/2022 20:00:29 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
05/22/2022 20:00:31 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7566463586360417 on epoch=368
05/22/2022 20:00:34 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 20:00:36 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 20:00:38 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 20:00:41 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
05/22/2022 20:00:43 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=374
05/22/2022 20:00:45 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:00:45 - INFO - __main__ - Printing 3 examples
05/22/2022 20:00:45 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:00:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:00:45 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:00:45 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:00:45 - INFO - __main__ - Printing 3 examples
05/22/2022 20:00:45 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:00:45 - INFO - __main__ - ['sad']
05/22/2022 20:00:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:00:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:00:45 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:00:45 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7061670238525982 on epoch=374
05/22/2022 20:00:45 - INFO - __main__ - save last model!
05/22/2022 20:00:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:00:45 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 20:00:45 - INFO - __main__ - Printing 3 examples
05/22/2022 20:00:45 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 20:00:45 - INFO - __main__ - ['others']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 20:00:45 - INFO - __main__ - ['others']
05/22/2022 20:00:45 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 20:00:45 - INFO - __main__ - ['others']
05/22/2022 20:00:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:00:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:00:53 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 20:01:03 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:01:04 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:01:04 - INFO - __main__ - Starting training!
05/22/2022 20:02:26 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_21_0.5_8_predictions.txt
05/22/2022 20:02:26 - INFO - __main__ - Classification-F1 on test data: 0.3290
05/22/2022 20:02:27 - INFO - __main__ - prefix=emo_32_21, lr=0.5, bsz=8, dev_performance=0.7779890248640249, test_performance=0.3289761826425092
05/22/2022 20:02:27 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.4, bsz=8 ...
05/22/2022 20:02:28 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:02:28 - INFO - __main__ - Printing 3 examples
05/22/2022 20:02:28 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:02:28 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:02:28 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:02:28 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:02:28 - INFO - __main__ - Printing 3 examples
05/22/2022 20:02:28 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:02:28 - INFO - __main__ - ['sad']
05/22/2022 20:02:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:02:28 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:02:28 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:02:43 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:02:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:02:44 - INFO - __main__ - Starting training!
05/22/2022 20:02:47 - INFO - __main__ - Step 10 Global step 10 Train loss 3.87 on epoch=1
05/22/2022 20:02:49 - INFO - __main__ - Step 20 Global step 20 Train loss 2.64 on epoch=2
05/22/2022 20:02:52 - INFO - __main__ - Step 30 Global step 30 Train loss 2.25 on epoch=3
05/22/2022 20:02:54 - INFO - __main__ - Step 40 Global step 40 Train loss 1.87 on epoch=4
05/22/2022 20:02:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.41 on epoch=6
05/22/2022 20:02:58 - INFO - __main__ - Global step 50 Train loss 2.41 Classification-F1 0.17751436781609195 on epoch=6
05/22/2022 20:02:58 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.17751436781609195 on epoch=6, global_step=50
05/22/2022 20:03:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.29 on epoch=7
05/22/2022 20:03:03 - INFO - __main__ - Step 70 Global step 70 Train loss 1.19 on epoch=8
05/22/2022 20:03:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.84 on epoch=9
05/22/2022 20:03:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.88 on epoch=11
05/22/2022 20:03:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.75 on epoch=12
05/22/2022 20:03:13 - INFO - __main__ - Global step 100 Train loss 0.99 Classification-F1 0.45904054691183405 on epoch=12
05/22/2022 20:03:13 - INFO - __main__ - Saving model with best Classification-F1: 0.17751436781609195 -> 0.45904054691183405 on epoch=12, global_step=100
05/22/2022 20:03:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.74 on epoch=13
05/22/2022 20:03:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.63 on epoch=14
05/22/2022 20:03:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.72 on epoch=16
05/22/2022 20:03:23 - INFO - __main__ - Step 140 Global step 140 Train loss 0.68 on epoch=17
05/22/2022 20:03:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.70 on epoch=18
05/22/2022 20:03:27 - INFO - __main__ - Global step 150 Train loss 0.69 Classification-F1 0.5422313617965792 on epoch=18
05/22/2022 20:03:27 - INFO - __main__ - Saving model with best Classification-F1: 0.45904054691183405 -> 0.5422313617965792 on epoch=18, global_step=150
05/22/2022 20:03:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.65 on epoch=19
05/22/2022 20:03:32 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=21
05/22/2022 20:03:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.58 on epoch=22
05/22/2022 20:03:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.57 on epoch=23
05/22/2022 20:03:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.56 on epoch=24
05/22/2022 20:03:41 - INFO - __main__ - Global step 200 Train loss 0.61 Classification-F1 0.6547349916397536 on epoch=24
05/22/2022 20:03:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5422313617965792 -> 0.6547349916397536 on epoch=24, global_step=200
05/22/2022 20:03:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=26
05/22/2022 20:03:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.56 on epoch=27
05/22/2022 20:03:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.47 on epoch=28
05/22/2022 20:03:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.56 on epoch=29
05/22/2022 20:03:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.49 on epoch=31
05/22/2022 20:03:54 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.7200860223830513 on epoch=31
05/22/2022 20:03:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6547349916397536 -> 0.7200860223830513 on epoch=31, global_step=250
05/22/2022 20:03:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.48 on epoch=32
05/22/2022 20:03:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=33
05/22/2022 20:04:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.45 on epoch=34
05/22/2022 20:04:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=36
05/22/2022 20:04:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=37
05/22/2022 20:04:08 - INFO - __main__ - Global step 300 Train loss 0.47 Classification-F1 0.7346266478619419 on epoch=37
05/22/2022 20:04:08 - INFO - __main__ - Saving model with best Classification-F1: 0.7200860223830513 -> 0.7346266478619419 on epoch=37, global_step=300
05/22/2022 20:04:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=38
05/22/2022 20:04:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=39
05/22/2022 20:04:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.47 on epoch=41
05/22/2022 20:04:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=42
05/22/2022 20:04:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.40 on epoch=43
05/22/2022 20:04:22 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.7006450467510947 on epoch=43
05/22/2022 20:04:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=44
05/22/2022 20:04:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.33 on epoch=46
05/22/2022 20:04:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.42 on epoch=47
05/22/2022 20:04:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=48
05/22/2022 20:04:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=49
05/22/2022 20:04:36 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.6873458140145219 on epoch=49
05/22/2022 20:04:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=51
05/22/2022 20:04:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.36 on epoch=52
05/22/2022 20:04:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.34 on epoch=53
05/22/2022 20:04:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=54
05/22/2022 20:04:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.36 on epoch=56
05/22/2022 20:04:50 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.7019042228778909 on epoch=56
05/22/2022 20:04:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=57
05/22/2022 20:04:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=58
05/22/2022 20:04:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.29 on epoch=59
05/22/2022 20:05:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.37 on epoch=61
05/22/2022 20:05:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=62
05/22/2022 20:05:04 - INFO - __main__ - Global step 500 Train loss 0.35 Classification-F1 0.7087403207121517 on epoch=62
05/22/2022 20:05:06 - INFO - __main__ - Step 510 Global step 510 Train loss 0.38 on epoch=63
05/22/2022 20:05:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=64
05/22/2022 20:05:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.33 on epoch=66
05/22/2022 20:05:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.27 on epoch=67
05/22/2022 20:05:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.38 on epoch=68
05/22/2022 20:05:18 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.6918653485817666 on epoch=68
05/22/2022 20:05:20 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=69
05/22/2022 20:05:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=71
05/22/2022 20:05:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=72
05/22/2022 20:05:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.32 on epoch=73
05/22/2022 20:05:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.29 on epoch=74
05/22/2022 20:05:32 - INFO - __main__ - Global step 600 Train loss 0.28 Classification-F1 0.7148288575241324 on epoch=74
05/22/2022 20:05:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=76
05/22/2022 20:05:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=77
05/22/2022 20:05:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.30 on epoch=78
05/22/2022 20:05:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=79
05/22/2022 20:05:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=81
05/22/2022 20:05:46 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.7248765960547168 on epoch=81
05/22/2022 20:05:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.23 on epoch=82
05/22/2022 20:05:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.28 on epoch=83
05/22/2022 20:05:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=84
05/22/2022 20:05:55 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=86
05/22/2022 20:05:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.26 on epoch=87
05/22/2022 20:06:00 - INFO - __main__ - Global step 700 Train loss 0.23 Classification-F1 0.7399596592095488 on epoch=87
05/22/2022 20:06:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7346266478619419 -> 0.7399596592095488 on epoch=87, global_step=700
05/22/2022 20:06:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=88
05/22/2022 20:06:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=89
05/22/2022 20:06:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.22 on epoch=91
05/22/2022 20:06:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.27 on epoch=92
05/22/2022 20:06:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=93
05/22/2022 20:06:14 - INFO - __main__ - Global step 750 Train loss 0.26 Classification-F1 0.7315340909090909 on epoch=93
05/22/2022 20:06:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.15 on epoch=94
05/22/2022 20:06:18 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=96
05/22/2022 20:06:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.26 on epoch=97
05/22/2022 20:06:23 - INFO - __main__ - Step 790 Global step 790 Train loss 0.21 on epoch=98
05/22/2022 20:06:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=99
05/22/2022 20:06:27 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.7024484789190671 on epoch=99
05/22/2022 20:06:30 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=101
05/22/2022 20:06:32 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=102
05/22/2022 20:06:35 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=103
05/22/2022 20:06:37 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=104
05/22/2022 20:06:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=106
05/22/2022 20:06:41 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.7002471160680116 on epoch=106
05/22/2022 20:06:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=107
05/22/2022 20:06:46 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=108
05/22/2022 20:06:49 - INFO - __main__ - Step 880 Global step 880 Train loss 0.17 on epoch=109
05/22/2022 20:06:51 - INFO - __main__ - Step 890 Global step 890 Train loss 0.19 on epoch=111
05/22/2022 20:06:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=112
05/22/2022 20:06:55 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.7274998406729972 on epoch=112
05/22/2022 20:06:58 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=113
05/22/2022 20:07:00 - INFO - __main__ - Step 920 Global step 920 Train loss 0.14 on epoch=114
05/22/2022 20:07:03 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=116
05/22/2022 20:07:05 - INFO - __main__ - Step 940 Global step 940 Train loss 0.17 on epoch=117
05/22/2022 20:07:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=118
05/22/2022 20:07:09 - INFO - __main__ - Global step 950 Train loss 0.15 Classification-F1 0.7280327367014011 on epoch=118
05/22/2022 20:07:12 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
05/22/2022 20:07:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.21 on epoch=121
05/22/2022 20:07:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=122
05/22/2022 20:07:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.17 on epoch=123
05/22/2022 20:07:21 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=124
05/22/2022 20:07:23 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7455808080808081 on epoch=124
05/22/2022 20:07:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7399596592095488 -> 0.7455808080808081 on epoch=124, global_step=1000
05/22/2022 20:07:26 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.20 on epoch=126
05/22/2022 20:07:28 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=127
05/22/2022 20:07:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=128
05/22/2022 20:07:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=129
05/22/2022 20:07:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=131
05/22/2022 20:07:37 - INFO - __main__ - Global step 1050 Train loss 0.14 Classification-F1 0.7288153773780713 on epoch=131
05/22/2022 20:07:40 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=132
05/22/2022 20:07:42 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=133
05/22/2022 20:07:44 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.09 on epoch=134
05/22/2022 20:07:47 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=136
05/22/2022 20:07:49 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=137
05/22/2022 20:07:51 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.7288153773780713 on epoch=137
05/22/2022 20:07:54 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=138
05/22/2022 20:07:56 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=139
05/22/2022 20:07:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=141
05/22/2022 20:08:01 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=142
05/22/2022 20:08:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.23 on epoch=143
05/22/2022 20:08:05 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.7073590069701617 on epoch=143
05/22/2022 20:08:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=144
05/22/2022 20:08:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=146
05/22/2022 20:08:12 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=147
05/22/2022 20:08:15 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=148
05/22/2022 20:08:17 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.10 on epoch=149
05/22/2022 20:08:19 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.7232130056323605 on epoch=149
05/22/2022 20:08:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.11 on epoch=151
05/22/2022 20:08:24 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.08 on epoch=152
05/22/2022 20:08:26 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=153
05/22/2022 20:08:29 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
05/22/2022 20:08:31 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=156
05/22/2022 20:08:33 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.7476970901076959 on epoch=156
05/22/2022 20:08:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7455808080808081 -> 0.7476970901076959 on epoch=156, global_step=1250
05/22/2022 20:08:36 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=157
05/22/2022 20:08:38 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=158
05/22/2022 20:08:40 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=159
05/22/2022 20:08:43 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=161
05/22/2022 20:08:45 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=162
05/22/2022 20:08:47 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7465659340659341 on epoch=162
05/22/2022 20:08:50 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.17 on epoch=163
05/22/2022 20:08:52 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=164
05/22/2022 20:08:54 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=166
05/22/2022 20:08:57 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
05/22/2022 20:08:59 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=168
05/22/2022 20:09:01 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.755486673414305 on epoch=168
05/22/2022 20:09:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7476970901076959 -> 0.755486673414305 on epoch=168, global_step=1350
05/22/2022 20:09:03 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=169
05/22/2022 20:09:06 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=171
05/22/2022 20:09:08 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=172
05/22/2022 20:09:11 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=173
05/22/2022 20:09:13 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=174
05/22/2022 20:09:15 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.755486673414305 on epoch=174
05/22/2022 20:09:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
05/22/2022 20:09:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=177
05/22/2022 20:09:22 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=178
05/22/2022 20:09:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=179
05/22/2022 20:09:27 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=181
05/22/2022 20:09:29 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.7291161139406003 on epoch=181
05/22/2022 20:09:32 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
05/22/2022 20:09:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
05/22/2022 20:09:37 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=184
05/22/2022 20:09:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.07 on epoch=186
05/22/2022 20:09:41 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.05 on epoch=187
05/22/2022 20:09:43 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7377387105647975 on epoch=187
05/22/2022 20:09:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=188
05/22/2022 20:09:48 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=189
05/22/2022 20:09:50 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=191
05/22/2022 20:09:53 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
05/22/2022 20:09:55 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
05/22/2022 20:09:57 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.762110861135499 on epoch=193
05/22/2022 20:09:57 - INFO - __main__ - Saving model with best Classification-F1: 0.755486673414305 -> 0.762110861135499 on epoch=193, global_step=1550
05/22/2022 20:09:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
05/22/2022 20:10:02 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=196
05/22/2022 20:10:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
05/22/2022 20:10:07 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.09 on epoch=198
05/22/2022 20:10:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=199
05/22/2022 20:10:11 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.757054927329407 on epoch=199
05/22/2022 20:10:14 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.08 on epoch=201
05/22/2022 20:10:16 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=202
05/22/2022 20:10:19 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
05/22/2022 20:10:21 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=204
05/22/2022 20:10:24 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
05/22/2022 20:10:25 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.7391599151845053 on epoch=206
05/22/2022 20:10:28 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=207
05/22/2022 20:10:30 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
05/22/2022 20:10:33 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=209
05/22/2022 20:10:35 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
05/22/2022 20:10:38 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
05/22/2022 20:10:40 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7226353297421845 on epoch=212
05/22/2022 20:10:42 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
05/22/2022 20:10:45 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=214
05/22/2022 20:10:47 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=216
05/22/2022 20:10:50 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
05/22/2022 20:10:52 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
05/22/2022 20:10:54 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7251705029838021 on epoch=218
05/22/2022 20:10:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
05/22/2022 20:10:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
05/22/2022 20:11:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
05/22/2022 20:11:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
05/22/2022 20:11:06 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
05/22/2022 20:11:08 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.7232142857142857 on epoch=224
05/22/2022 20:11:10 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
05/22/2022 20:11:13 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=227
05/22/2022 20:11:15 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
05/22/2022 20:11:18 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
05/22/2022 20:11:20 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=231
05/22/2022 20:11:22 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.7307834372392694 on epoch=231
05/22/2022 20:11:25 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 20:11:27 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=233
05/22/2022 20:11:30 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
05/22/2022 20:11:32 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
05/22/2022 20:11:35 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=237
05/22/2022 20:11:36 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7290759271891348 on epoch=237
05/22/2022 20:11:39 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=238
05/22/2022 20:11:41 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.01 on epoch=239
05/22/2022 20:11:44 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=241
05/22/2022 20:11:46 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
05/22/2022 20:11:49 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
05/22/2022 20:11:51 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7482990189886741 on epoch=243
05/22/2022 20:11:53 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
05/22/2022 20:11:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
05/22/2022 20:11:58 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
05/22/2022 20:12:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
05/22/2022 20:12:03 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
05/22/2022 20:12:05 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.7464108031272211 on epoch=249
05/22/2022 20:12:07 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=251
05/22/2022 20:12:10 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=252
05/22/2022 20:12:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
05/22/2022 20:12:15 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
05/22/2022 20:12:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=256
05/22/2022 20:12:19 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.716506993371651 on epoch=256
05/22/2022 20:12:22 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
05/22/2022 20:12:24 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
05/22/2022 20:12:27 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
05/22/2022 20:12:29 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
05/22/2022 20:12:32 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
05/22/2022 20:12:33 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7288999447208403 on epoch=262
05/22/2022 20:12:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=263
05/22/2022 20:12:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
05/22/2022 20:12:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.15 on epoch=266
05/22/2022 20:12:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
05/22/2022 20:12:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=268
05/22/2022 20:12:48 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7648745519713261 on epoch=268
05/22/2022 20:12:48 - INFO - __main__ - Saving model with best Classification-F1: 0.762110861135499 -> 0.7648745519713261 on epoch=268, global_step=2150
05/22/2022 20:12:50 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=269
05/22/2022 20:12:53 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=271
05/22/2022 20:12:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=272
05/22/2022 20:12:58 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 20:13:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
05/22/2022 20:13:02 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7558442051851909 on epoch=274
05/22/2022 20:13:04 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 20:13:07 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.00 on epoch=277
05/22/2022 20:13:09 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.00 on epoch=278
05/22/2022 20:13:12 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
05/22/2022 20:13:14 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.12 on epoch=281
05/22/2022 20:13:16 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7318075117370892 on epoch=281
05/22/2022 20:13:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
05/22/2022 20:13:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
05/22/2022 20:13:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=284
05/22/2022 20:13:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
05/22/2022 20:13:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=287
05/22/2022 20:13:30 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7565407772304324 on epoch=287
05/22/2022 20:13:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=288
05/22/2022 20:13:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
05/22/2022 20:13:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
05/22/2022 20:13:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=292
05/22/2022 20:13:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
05/22/2022 20:13:44 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.7178475935828876 on epoch=293
05/22/2022 20:13:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
05/22/2022 20:13:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
05/22/2022 20:13:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=297
05/22/2022 20:13:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 20:13:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.00 on epoch=299
05/22/2022 20:13:59 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.7307539682539683 on epoch=299
05/22/2022 20:14:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
05/22/2022 20:14:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
05/22/2022 20:14:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
05/22/2022 20:14:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
05/22/2022 20:14:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 20:14:13 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.7410906183227541 on epoch=306
05/22/2022 20:14:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.07 on epoch=307
05/22/2022 20:14:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
05/22/2022 20:14:20 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=309
05/22/2022 20:14:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
05/22/2022 20:14:25 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
05/22/2022 20:14:27 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7506088170526346 on epoch=312
05/22/2022 20:14:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
05/22/2022 20:14:32 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 20:14:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=316
05/22/2022 20:14:37 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
05/22/2022 20:14:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
05/22/2022 20:14:41 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7417976949382732 on epoch=318
05/22/2022 20:14:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
05/22/2022 20:14:47 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
05/22/2022 20:14:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
05/22/2022 20:14:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
05/22/2022 20:14:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=324
05/22/2022 20:14:56 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.746852222876813 on epoch=324
05/22/2022 20:14:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
05/22/2022 20:15:01 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=327
05/22/2022 20:15:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
05/22/2022 20:15:06 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
05/22/2022 20:15:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
05/22/2022 20:15:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7470563595522168 on epoch=331
05/22/2022 20:15:13 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
05/22/2022 20:15:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=333
05/22/2022 20:15:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
05/22/2022 20:15:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=336
05/22/2022 20:15:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 20:15:24 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7475054460197902 on epoch=337
05/22/2022 20:15:27 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 20:15:29 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=339
05/22/2022 20:15:32 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
05/22/2022 20:15:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
05/22/2022 20:15:37 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=343
05/22/2022 20:15:38 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7189841096387585 on epoch=343
05/22/2022 20:15:41 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 20:15:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 20:15:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
05/22/2022 20:15:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
05/22/2022 20:15:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 20:15:53 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7393998695368558 on epoch=349
05/22/2022 20:15:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
05/22/2022 20:15:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=352
05/22/2022 20:16:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
05/22/2022 20:16:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
05/22/2022 20:16:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 20:16:07 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.7404794746725476 on epoch=356
05/22/2022 20:16:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.00 on epoch=357
05/22/2022 20:16:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
05/22/2022 20:16:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 20:16:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=361
05/22/2022 20:16:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=362
05/22/2022 20:16:21 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7405333413566294 on epoch=362
05/22/2022 20:16:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=363
05/22/2022 20:16:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
05/22/2022 20:16:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
05/22/2022 20:16:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
05/22/2022 20:16:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=368
05/22/2022 20:16:35 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7332073724182643 on epoch=368
05/22/2022 20:16:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 20:16:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=371
05/22/2022 20:16:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
05/22/2022 20:16:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=373
05/22/2022 20:16:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=374
05/22/2022 20:16:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:16:49 - INFO - __main__ - Printing 3 examples
05/22/2022 20:16:49 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:16:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:16:49 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:16:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:16:49 - INFO - __main__ - Printing 3 examples
05/22/2022 20:16:49 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:16:49 - INFO - __main__ - ['sad']
05/22/2022 20:16:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:16:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:16:49 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:16:50 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7321432870728646 on epoch=374
05/22/2022 20:16:50 - INFO - __main__ - save last model!
05/22/2022 20:16:50 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:16:50 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 20:16:50 - INFO - __main__ - Printing 3 examples
05/22/2022 20:16:50 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 20:16:50 - INFO - __main__ - ['others']
05/22/2022 20:16:50 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 20:16:50 - INFO - __main__ - ['others']
05/22/2022 20:16:50 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 20:16:50 - INFO - __main__ - ['others']
05/22/2022 20:16:50 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:16:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:16:57 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 20:17:08 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:17:09 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:17:09 - INFO - __main__ - Starting training!
05/22/2022 20:18:25 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_21_0.4_8_predictions.txt
05/22/2022 20:18:25 - INFO - __main__ - Classification-F1 on test data: 0.3436
05/22/2022 20:18:25 - INFO - __main__ - prefix=emo_32_21, lr=0.4, bsz=8, dev_performance=0.7648745519713261, test_performance=0.34355974173480036
05/22/2022 20:18:25 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.3, bsz=8 ...
05/22/2022 20:18:26 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:18:26 - INFO - __main__ - Printing 3 examples
05/22/2022 20:18:26 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:18:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:18:26 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:18:26 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:18:26 - INFO - __main__ - Printing 3 examples
05/22/2022 20:18:26 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:18:26 - INFO - __main__ - ['sad']
05/22/2022 20:18:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:18:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:18:26 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:18:41 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:18:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:18:42 - INFO - __main__ - Starting training!
05/22/2022 20:18:45 - INFO - __main__ - Step 10 Global step 10 Train loss 3.98 on epoch=1
05/22/2022 20:18:48 - INFO - __main__ - Step 20 Global step 20 Train loss 3.24 on epoch=2
05/22/2022 20:18:50 - INFO - __main__ - Step 30 Global step 30 Train loss 2.65 on epoch=3
05/22/2022 20:18:53 - INFO - __main__ - Step 40 Global step 40 Train loss 2.31 on epoch=4
05/22/2022 20:18:55 - INFO - __main__ - Step 50 Global step 50 Train loss 2.08 on epoch=6
05/22/2022 20:18:57 - INFO - __main__ - Global step 50 Train loss 2.85 Classification-F1 0.01282051282051282 on epoch=6
05/22/2022 20:18:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01282051282051282 on epoch=6, global_step=50
05/22/2022 20:18:59 - INFO - __main__ - Step 60 Global step 60 Train loss 1.64 on epoch=7
05/22/2022 20:19:01 - INFO - __main__ - Step 70 Global step 70 Train loss 1.59 on epoch=8
05/22/2022 20:19:04 - INFO - __main__ - Step 80 Global step 80 Train loss 1.34 on epoch=9
05/22/2022 20:19:06 - INFO - __main__ - Step 90 Global step 90 Train loss 1.09 on epoch=11
05/22/2022 20:19:09 - INFO - __main__ - Step 100 Global step 100 Train loss 1.04 on epoch=12
05/22/2022 20:19:10 - INFO - __main__ - Global step 100 Train loss 1.34 Classification-F1 0.43706349206349204 on epoch=12
05/22/2022 20:19:10 - INFO - __main__ - Saving model with best Classification-F1: 0.01282051282051282 -> 0.43706349206349204 on epoch=12, global_step=100
05/22/2022 20:19:13 - INFO - __main__ - Step 110 Global step 110 Train loss 0.86 on epoch=13
05/22/2022 20:19:15 - INFO - __main__ - Step 120 Global step 120 Train loss 0.81 on epoch=14
05/22/2022 20:19:18 - INFO - __main__ - Step 130 Global step 130 Train loss 0.82 on epoch=16
05/22/2022 20:19:20 - INFO - __main__ - Step 140 Global step 140 Train loss 0.77 on epoch=17
05/22/2022 20:19:22 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=18
05/22/2022 20:19:24 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.4825866644298373 on epoch=18
05/22/2022 20:19:24 - INFO - __main__ - Saving model with best Classification-F1: 0.43706349206349204 -> 0.4825866644298373 on epoch=18, global_step=150
05/22/2022 20:19:27 - INFO - __main__ - Step 160 Global step 160 Train loss 0.70 on epoch=19
05/22/2022 20:19:29 - INFO - __main__ - Step 170 Global step 170 Train loss 0.72 on epoch=21
05/22/2022 20:19:32 - INFO - __main__ - Step 180 Global step 180 Train loss 0.75 on epoch=22
05/22/2022 20:19:34 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=23
05/22/2022 20:19:36 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=24
05/22/2022 20:19:38 - INFO - __main__ - Global step 200 Train loss 0.70 Classification-F1 0.5415321048632219 on epoch=24
05/22/2022 20:19:38 - INFO - __main__ - Saving model with best Classification-F1: 0.4825866644298373 -> 0.5415321048632219 on epoch=24, global_step=200
05/22/2022 20:19:41 - INFO - __main__ - Step 210 Global step 210 Train loss 0.69 on epoch=26
05/22/2022 20:19:43 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=27
05/22/2022 20:19:46 - INFO - __main__ - Step 230 Global step 230 Train loss 0.63 on epoch=28
05/22/2022 20:19:48 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=29
05/22/2022 20:19:50 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=31
05/22/2022 20:19:52 - INFO - __main__ - Global step 250 Train loss 0.65 Classification-F1 0.6087311649938856 on epoch=31
05/22/2022 20:19:52 - INFO - __main__ - Saving model with best Classification-F1: 0.5415321048632219 -> 0.6087311649938856 on epoch=31, global_step=250
05/22/2022 20:19:55 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=32
05/22/2022 20:19:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.63 on epoch=33
05/22/2022 20:19:59 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=34
05/22/2022 20:20:02 - INFO - __main__ - Step 290 Global step 290 Train loss 0.55 on epoch=36
05/22/2022 20:20:04 - INFO - __main__ - Step 300 Global step 300 Train loss 0.61 on epoch=37
05/22/2022 20:20:06 - INFO - __main__ - Global step 300 Train loss 0.61 Classification-F1 0.6395897314749193 on epoch=37
05/22/2022 20:20:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6087311649938856 -> 0.6395897314749193 on epoch=37, global_step=300
05/22/2022 20:20:08 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=38
05/22/2022 20:20:11 - INFO - __main__ - Step 320 Global step 320 Train loss 0.61 on epoch=39
05/22/2022 20:20:13 - INFO - __main__ - Step 330 Global step 330 Train loss 0.60 on epoch=41
05/22/2022 20:20:16 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=42
05/22/2022 20:20:18 - INFO - __main__ - Step 350 Global step 350 Train loss 0.49 on epoch=43
05/22/2022 20:20:20 - INFO - __main__ - Global step 350 Train loss 0.54 Classification-F1 0.6637913907115867 on epoch=43
05/22/2022 20:20:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6395897314749193 -> 0.6637913907115867 on epoch=43, global_step=350
05/22/2022 20:20:22 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=44
05/22/2022 20:20:25 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=46
05/22/2022 20:20:27 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=47
05/22/2022 20:20:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.52 on epoch=48
05/22/2022 20:20:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=49
05/22/2022 20:20:33 - INFO - __main__ - Global step 400 Train loss 0.50 Classification-F1 0.6883982585060194 on epoch=49
05/22/2022 20:20:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6637913907115867 -> 0.6883982585060194 on epoch=49, global_step=400
05/22/2022 20:20:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=51
05/22/2022 20:20:38 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
05/22/2022 20:20:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.56 on epoch=53
05/22/2022 20:20:43 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=54
05/22/2022 20:20:45 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=56
05/22/2022 20:20:47 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.7051810865191146 on epoch=56
05/22/2022 20:20:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6883982585060194 -> 0.7051810865191146 on epoch=56, global_step=450
05/22/2022 20:20:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.50 on epoch=57
05/22/2022 20:20:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.58 on epoch=58
05/22/2022 20:20:54 - INFO - __main__ - Step 480 Global step 480 Train loss 0.41 on epoch=59
05/22/2022 20:20:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=61
05/22/2022 20:20:59 - INFO - __main__ - Step 500 Global step 500 Train loss 0.52 on epoch=62
05/22/2022 20:21:01 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.7349744245524297 on epoch=62
05/22/2022 20:21:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7051810865191146 -> 0.7349744245524297 on epoch=62, global_step=500
05/22/2022 20:21:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.41 on epoch=63
05/22/2022 20:21:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=64
05/22/2022 20:21:08 - INFO - __main__ - Step 530 Global step 530 Train loss 0.36 on epoch=66
05/22/2022 20:21:10 - INFO - __main__ - Step 540 Global step 540 Train loss 0.41 on epoch=67
05/22/2022 20:21:13 - INFO - __main__ - Step 550 Global step 550 Train loss 0.43 on epoch=68
05/22/2022 20:21:14 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.7004692891649413 on epoch=68
05/22/2022 20:21:17 - INFO - __main__ - Step 560 Global step 560 Train loss 0.42 on epoch=69
05/22/2022 20:21:19 - INFO - __main__ - Step 570 Global step 570 Train loss 0.38 on epoch=71
05/22/2022 20:21:21 - INFO - __main__ - Step 580 Global step 580 Train loss 0.37 on epoch=72
05/22/2022 20:21:24 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=73
05/22/2022 20:21:26 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=74
05/22/2022 20:21:28 - INFO - __main__ - Global step 600 Train loss 0.39 Classification-F1 0.7451668198853356 on epoch=74
05/22/2022 20:21:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7349744245524297 -> 0.7451668198853356 on epoch=74, global_step=600
05/22/2022 20:21:30 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=76
05/22/2022 20:21:33 - INFO - __main__ - Step 620 Global step 620 Train loss 0.38 on epoch=77
05/22/2022 20:21:35 - INFO - __main__ - Step 630 Global step 630 Train loss 0.44 on epoch=78
05/22/2022 20:21:38 - INFO - __main__ - Step 640 Global step 640 Train loss 0.30 on epoch=79
05/22/2022 20:21:40 - INFO - __main__ - Step 650 Global step 650 Train loss 0.33 on epoch=81
05/22/2022 20:21:42 - INFO - __main__ - Global step 650 Train loss 0.36 Classification-F1 0.6903449863895671 on epoch=81
05/22/2022 20:21:44 - INFO - __main__ - Step 660 Global step 660 Train loss 0.36 on epoch=82
05/22/2022 20:21:46 - INFO - __main__ - Step 670 Global step 670 Train loss 0.39 on epoch=83
05/22/2022 20:21:49 - INFO - __main__ - Step 680 Global step 680 Train loss 0.38 on epoch=84
05/22/2022 20:21:51 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=86
05/22/2022 20:21:54 - INFO - __main__ - Step 700 Global step 700 Train loss 0.27 on epoch=87
05/22/2022 20:21:55 - INFO - __main__ - Global step 700 Train loss 0.34 Classification-F1 0.7354341736694677 on epoch=87
05/22/2022 20:21:58 - INFO - __main__ - Step 710 Global step 710 Train loss 0.35 on epoch=88
05/22/2022 20:22:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=89
05/22/2022 20:22:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=91
05/22/2022 20:22:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.39 on epoch=92
05/22/2022 20:22:07 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=93
05/22/2022 20:22:09 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.6649908606210524 on epoch=93
05/22/2022 20:22:11 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=94
05/22/2022 20:22:14 - INFO - __main__ - Step 770 Global step 770 Train loss 0.33 on epoch=96
05/22/2022 20:22:16 - INFO - __main__ - Step 780 Global step 780 Train loss 0.32 on epoch=97
05/22/2022 20:22:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=98
05/22/2022 20:22:21 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=99
05/22/2022 20:22:22 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.7004490851066795 on epoch=99
05/22/2022 20:22:25 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=101
05/22/2022 20:22:27 - INFO - __main__ - Step 820 Global step 820 Train loss 0.30 on epoch=102
05/22/2022 20:22:30 - INFO - __main__ - Step 830 Global step 830 Train loss 0.34 on epoch=103
05/22/2022 20:22:32 - INFO - __main__ - Step 840 Global step 840 Train loss 0.25 on epoch=104
05/22/2022 20:22:35 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=106
05/22/2022 20:22:36 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.6832321347806423 on epoch=106
05/22/2022 20:22:39 - INFO - __main__ - Step 860 Global step 860 Train loss 0.23 on epoch=107
05/22/2022 20:22:41 - INFO - __main__ - Step 870 Global step 870 Train loss 0.31 on epoch=108
05/22/2022 20:22:43 - INFO - __main__ - Step 880 Global step 880 Train loss 0.30 on epoch=109
05/22/2022 20:22:46 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=111
05/22/2022 20:22:48 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=112
05/22/2022 20:22:50 - INFO - __main__ - Global step 900 Train loss 0.25 Classification-F1 0.7162157287157288 on epoch=112
05/22/2022 20:22:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=113
05/22/2022 20:22:55 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=114
05/22/2022 20:22:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=116
05/22/2022 20:22:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=117
05/22/2022 20:23:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.32 on epoch=118
05/22/2022 20:23:03 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.6898425039872408 on epoch=118
05/22/2022 20:23:06 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=119
05/22/2022 20:23:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.31 on epoch=121
05/22/2022 20:23:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=122
05/22/2022 20:23:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.29 on epoch=123
05/22/2022 20:23:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.29 on epoch=124
05/22/2022 20:23:17 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.714502543522606 on epoch=124
05/22/2022 20:23:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.21 on epoch=126
05/22/2022 20:23:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=127
05/22/2022 20:23:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.21 on epoch=128
05/22/2022 20:23:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=129
05/22/2022 20:23:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=131
05/22/2022 20:23:31 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.7096229260935144 on epoch=131
05/22/2022 20:23:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.25 on epoch=132
05/22/2022 20:23:36 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.25 on epoch=133
05/22/2022 20:23:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=134
05/22/2022 20:23:41 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=136
05/22/2022 20:23:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.14 on epoch=137
05/22/2022 20:23:45 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.72303488514174 on epoch=137
05/22/2022 20:23:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=138
05/22/2022 20:23:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.13 on epoch=139
05/22/2022 20:23:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=141
05/22/2022 20:23:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.23 on epoch=142
05/22/2022 20:23:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.35 on epoch=143
05/22/2022 20:23:58 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.7208981918238995 on epoch=143
05/22/2022 20:24:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=144
05/22/2022 20:24:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.14 on epoch=146
05/22/2022 20:24:05 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.19 on epoch=147
05/22/2022 20:24:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=148
05/22/2022 20:24:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.18 on epoch=149
05/22/2022 20:24:12 - INFO - __main__ - Global step 1200 Train loss 0.17 Classification-F1 0.7000120250120251 on epoch=149
05/22/2022 20:24:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=151
05/22/2022 20:24:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.27 on epoch=152
05/22/2022 20:24:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.21 on epoch=153
05/22/2022 20:24:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.20 on epoch=154
05/22/2022 20:24:24 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=156
05/22/2022 20:24:26 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.7156804579755399 on epoch=156
05/22/2022 20:24:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=157
05/22/2022 20:24:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=158
05/22/2022 20:24:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=159
05/22/2022 20:24:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=161
05/22/2022 20:24:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=162
05/22/2022 20:24:39 - INFO - __main__ - Global step 1300 Train loss 0.17 Classification-F1 0.7100530969065012 on epoch=162
05/22/2022 20:24:42 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.14 on epoch=163
05/22/2022 20:24:44 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=164
05/22/2022 20:24:47 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=166
05/22/2022 20:24:49 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=167
05/22/2022 20:24:52 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=168
05/22/2022 20:24:53 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.7288153773780713 on epoch=168
05/22/2022 20:24:56 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=169
05/22/2022 20:24:58 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=171
05/22/2022 20:25:00 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=172
05/22/2022 20:25:03 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.14 on epoch=173
05/22/2022 20:25:05 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.15 on epoch=174
05/22/2022 20:25:07 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.7004911233544264 on epoch=174
05/22/2022 20:25:09 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.12 on epoch=176
05/22/2022 20:25:12 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.19 on epoch=177
05/22/2022 20:25:14 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.19 on epoch=178
05/22/2022 20:25:17 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=179
05/22/2022 20:25:19 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=181
05/22/2022 20:25:21 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.7224341778440139 on epoch=181
05/22/2022 20:25:23 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=182
05/22/2022 20:25:26 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=183
05/22/2022 20:25:28 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.09 on epoch=184
05/22/2022 20:25:30 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=186
05/22/2022 20:25:33 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=187
05/22/2022 20:25:34 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.7407480565821334 on epoch=187
05/22/2022 20:25:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
05/22/2022 20:25:39 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=189
05/22/2022 20:25:41 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.11 on epoch=191
05/22/2022 20:25:44 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=192
05/22/2022 20:25:46 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.12 on epoch=193
05/22/2022 20:25:48 - INFO - __main__ - Global step 1550 Train loss 0.11 Classification-F1 0.7247338247338247 on epoch=193
05/22/2022 20:25:51 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=194
05/22/2022 20:25:53 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
05/22/2022 20:25:55 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=197
05/22/2022 20:25:58 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=198
05/22/2022 20:26:00 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=199
05/22/2022 20:26:02 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.7465945512820512 on epoch=199
05/22/2022 20:26:02 - INFO - __main__ - Saving model with best Classification-F1: 0.7451668198853356 -> 0.7465945512820512 on epoch=199, global_step=1600
05/22/2022 20:26:04 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=201
05/22/2022 20:26:07 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=202
05/22/2022 20:26:09 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=203
05/22/2022 20:26:12 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=204
05/22/2022 20:26:14 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
05/22/2022 20:26:16 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.7226594297276554 on epoch=206
05/22/2022 20:26:18 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=207
05/22/2022 20:26:20 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=208
05/22/2022 20:26:23 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=209
05/22/2022 20:26:25 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=211
05/22/2022 20:26:28 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
05/22/2022 20:26:29 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.7174630924630925 on epoch=212
05/22/2022 20:26:32 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.16 on epoch=213
05/22/2022 20:26:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.08 on epoch=214
05/22/2022 20:26:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=216
05/22/2022 20:26:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
05/22/2022 20:26:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.08 on epoch=218
05/22/2022 20:26:43 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7282549559404027 on epoch=218
05/22/2022 20:26:45 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.07 on epoch=219
05/22/2022 20:26:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=221
05/22/2022 20:26:50 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=222
05/22/2022 20:26:53 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=223
05/22/2022 20:26:55 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=224
05/22/2022 20:26:57 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7652066520989738 on epoch=224
05/22/2022 20:26:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7465945512820512 -> 0.7652066520989738 on epoch=224, global_step=1800
05/22/2022 20:26:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=226
05/22/2022 20:27:01 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
05/22/2022 20:27:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=228
05/22/2022 20:27:06 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=229
05/22/2022 20:27:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=231
05/22/2022 20:27:10 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7569541841982235 on epoch=231
05/22/2022 20:27:13 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=232
05/22/2022 20:27:15 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.08 on epoch=233
05/22/2022 20:27:17 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=234
05/22/2022 20:27:20 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.08 on epoch=236
05/22/2022 20:27:22 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=237
05/22/2022 20:27:24 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.7488731367707001 on epoch=237
05/22/2022 20:27:26 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
05/22/2022 20:27:29 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
05/22/2022 20:27:31 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=241
05/22/2022 20:27:33 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=242
05/22/2022 20:27:36 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=243
05/22/2022 20:27:38 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7456674473067916 on epoch=243
05/22/2022 20:27:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
05/22/2022 20:27:42 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=246
05/22/2022 20:27:45 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.14 on epoch=247
05/22/2022 20:27:47 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=248
05/22/2022 20:27:50 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=249
05/22/2022 20:27:51 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7359880315762669 on epoch=249
05/22/2022 20:27:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
05/22/2022 20:27:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=252
05/22/2022 20:27:58 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=253
05/22/2022 20:28:01 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
05/22/2022 20:28:03 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
05/22/2022 20:28:05 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7049660757706487 on epoch=256
05/22/2022 20:28:07 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=257
05/22/2022 20:28:10 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=258
05/22/2022 20:28:12 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=259
05/22/2022 20:28:15 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.05 on epoch=261
05/22/2022 20:28:17 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=262
05/22/2022 20:28:19 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7370204448329448 on epoch=262
05/22/2022 20:28:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=263
05/22/2022 20:28:24 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
05/22/2022 20:28:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
05/22/2022 20:28:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
05/22/2022 20:28:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=268
05/22/2022 20:28:32 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.73566474605207 on epoch=268
05/22/2022 20:28:35 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=269
05/22/2022 20:28:37 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
05/22/2022 20:28:40 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
05/22/2022 20:28:42 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
05/22/2022 20:28:44 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=274
05/22/2022 20:28:46 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7389523925160155 on epoch=274
05/22/2022 20:28:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.06 on epoch=276
05/22/2022 20:28:51 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=277
05/22/2022 20:28:53 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
05/22/2022 20:28:56 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=279
05/22/2022 20:28:58 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
05/22/2022 20:29:00 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7433343912217152 on epoch=281
05/22/2022 20:29:02 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=282
05/22/2022 20:29:05 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.12 on epoch=283
05/22/2022 20:29:07 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=284
05/22/2022 20:29:09 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=286
05/22/2022 20:29:12 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
05/22/2022 20:29:14 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.7639177172811995 on epoch=287
05/22/2022 20:29:16 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
05/22/2022 20:29:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.08 on epoch=289
05/22/2022 20:29:21 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=291
05/22/2022 20:29:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=292
05/22/2022 20:29:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.10 on epoch=293
05/22/2022 20:29:27 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.7377660679374389 on epoch=293
05/22/2022 20:29:30 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
05/22/2022 20:29:32 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=296
05/22/2022 20:29:34 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.11 on epoch=297
05/22/2022 20:29:37 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
05/22/2022 20:29:39 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=299
05/22/2022 20:29:41 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.728467590967591 on epoch=299
05/22/2022 20:29:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=301
05/22/2022 20:29:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
05/22/2022 20:29:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
05/22/2022 20:29:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=304
05/22/2022 20:29:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=306
05/22/2022 20:29:55 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7367514812680289 on epoch=306
05/22/2022 20:29:57 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
05/22/2022 20:29:59 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
05/22/2022 20:30:02 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
05/22/2022 20:30:04 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
05/22/2022 20:30:07 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=312
05/22/2022 20:30:09 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7459251201291679 on epoch=312
05/22/2022 20:30:11 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
05/22/2022 20:30:13 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 20:30:16 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=316
05/22/2022 20:30:18 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.04 on epoch=317
05/22/2022 20:30:21 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
05/22/2022 20:30:22 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7205143490389392 on epoch=318
05/22/2022 20:30:25 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
05/22/2022 20:30:27 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 20:30:30 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=322
05/22/2022 20:30:32 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
05/22/2022 20:30:34 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
05/22/2022 20:30:36 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7465091819930529 on epoch=324
05/22/2022 20:30:39 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
05/22/2022 20:30:41 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=327
05/22/2022 20:30:43 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.11 on epoch=328
05/22/2022 20:30:46 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
05/22/2022 20:30:48 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
05/22/2022 20:30:50 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7332095461006056 on epoch=331
05/22/2022 20:30:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
05/22/2022 20:30:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=333
05/22/2022 20:30:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
05/22/2022 20:30:59 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
05/22/2022 20:31:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 20:31:04 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7093890018418321 on epoch=337
05/22/2022 20:31:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.12 on epoch=338
05/22/2022 20:31:08 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
05/22/2022 20:31:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=341
05/22/2022 20:31:13 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 20:31:16 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 20:31:17 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.7119357243516377 on epoch=343
05/22/2022 20:31:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 20:31:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 20:31:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
05/22/2022 20:31:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
05/22/2022 20:31:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=349
05/22/2022 20:31:31 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7050216450216451 on epoch=349
05/22/2022 20:31:34 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
05/22/2022 20:31:36 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
05/22/2022 20:31:38 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=353
05/22/2022 20:31:41 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
05/22/2022 20:31:43 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 20:31:45 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7222605519480519 on epoch=356
05/22/2022 20:31:47 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=357
05/22/2022 20:31:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
05/22/2022 20:31:52 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 20:31:55 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=361
05/22/2022 20:31:57 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=362
05/22/2022 20:31:59 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7404121863799282 on epoch=362
05/22/2022 20:32:01 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 20:32:04 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=364
05/22/2022 20:32:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
05/22/2022 20:32:09 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=367
05/22/2022 20:32:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
05/22/2022 20:32:13 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7357193732193732 on epoch=368
05/22/2022 20:32:15 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
05/22/2022 20:32:17 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=371
05/22/2022 20:32:20 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.12 on epoch=372
05/22/2022 20:32:22 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
05/22/2022 20:32:25 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
05/22/2022 20:32:26 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:32:26 - INFO - __main__ - Printing 3 examples
05/22/2022 20:32:26 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:32:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:32:26 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:32:26 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:32:26 - INFO - __main__ - Printing 3 examples
05/22/2022 20:32:26 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:32:26 - INFO - __main__ - ['sad']
05/22/2022 20:32:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:32:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:32:26 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:32:26 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7307061248296752 on epoch=374
05/22/2022 20:32:26 - INFO - __main__ - save last model!
05/22/2022 20:32:26 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:32:26 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 20:32:26 - INFO - __main__ - Printing 3 examples
05/22/2022 20:32:26 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 20:32:26 - INFO - __main__ - ['others']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 20:32:26 - INFO - __main__ - ['others']
05/22/2022 20:32:26 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 20:32:26 - INFO - __main__ - ['others']
05/22/2022 20:32:26 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:32:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:32:34 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 20:32:45 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:32:45 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:32:45 - INFO - __main__ - Starting training!
05/22/2022 20:33:49 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_21_0.3_8_predictions.txt
05/22/2022 20:33:49 - INFO - __main__ - Classification-F1 on test data: 0.3347
05/22/2022 20:33:50 - INFO - __main__ - prefix=emo_32_21, lr=0.3, bsz=8, dev_performance=0.7652066520989738, test_performance=0.334671695045212
05/22/2022 20:33:50 - INFO - __main__ - Running ... prefix=emo_32_21, lr=0.2, bsz=8 ...
05/22/2022 20:33:51 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:33:51 - INFO - __main__ - Printing 3 examples
05/22/2022 20:33:51 - INFO - __main__ -  [emo] yes buts its real it's me and u she cheated on me
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ -  [emo] i missed you so much i missed you so much more  don't be sad
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ -  [emo] m not okay i disagree  my promotion got hold
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:33:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:33:51 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:33:51 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:33:51 - INFO - __main__ - Printing 3 examples
05/22/2022 20:33:51 - INFO - __main__ -  [emo] i am not ok why  down with fever
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ -  [emo] i'm disappointed such people stink that's rude to generalise
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ -  [emo] o go to hell how are u  miserable
05/22/2022 20:33:51 - INFO - __main__ - ['sad']
05/22/2022 20:33:51 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:33:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:33:51 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:34:06 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:34:07 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:34:07 - INFO - __main__ - Starting training!
05/22/2022 20:34:10 - INFO - __main__ - Step 10 Global step 10 Train loss 4.51 on epoch=1
05/22/2022 20:34:12 - INFO - __main__ - Step 20 Global step 20 Train loss 3.52 on epoch=2
05/22/2022 20:34:15 - INFO - __main__ - Step 30 Global step 30 Train loss 2.93 on epoch=3
05/22/2022 20:34:17 - INFO - __main__ - Step 40 Global step 40 Train loss 2.62 on epoch=4
05/22/2022 20:34:20 - INFO - __main__ - Step 50 Global step 50 Train loss 2.36 on epoch=6
05/22/2022 20:34:21 - INFO - __main__ - Global step 50 Train loss 3.19 Classification-F1 0.005847953216374269 on epoch=6
05/22/2022 20:34:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.005847953216374269 on epoch=6, global_step=50
05/22/2022 20:34:24 - INFO - __main__ - Step 60 Global step 60 Train loss 2.20 on epoch=7
05/22/2022 20:34:26 - INFO - __main__ - Step 70 Global step 70 Train loss 2.03 on epoch=8
05/22/2022 20:34:29 - INFO - __main__ - Step 80 Global step 80 Train loss 1.93 on epoch=9
05/22/2022 20:34:31 - INFO - __main__ - Step 90 Global step 90 Train loss 1.63 on epoch=11
05/22/2022 20:34:33 - INFO - __main__ - Step 100 Global step 100 Train loss 1.57 on epoch=12
05/22/2022 20:34:35 - INFO - __main__ - Global step 100 Train loss 1.87 Classification-F1 0.15158961147661712 on epoch=12
05/22/2022 20:34:35 - INFO - __main__ - Saving model with best Classification-F1: 0.005847953216374269 -> 0.15158961147661712 on epoch=12, global_step=100
05/22/2022 20:34:38 - INFO - __main__ - Step 110 Global step 110 Train loss 1.43 on epoch=13
05/22/2022 20:34:40 - INFO - __main__ - Step 120 Global step 120 Train loss 1.37 on epoch=14
05/22/2022 20:34:42 - INFO - __main__ - Step 130 Global step 130 Train loss 1.11 on epoch=16
05/22/2022 20:34:45 - INFO - __main__ - Step 140 Global step 140 Train loss 1.04 on epoch=17
05/22/2022 20:34:47 - INFO - __main__ - Step 150 Global step 150 Train loss 1.05 on epoch=18
05/22/2022 20:34:49 - INFO - __main__ - Global step 150 Train loss 1.20 Classification-F1 0.4610110319787739 on epoch=18
05/22/2022 20:34:49 - INFO - __main__ - Saving model with best Classification-F1: 0.15158961147661712 -> 0.4610110319787739 on epoch=18, global_step=150
05/22/2022 20:34:51 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=19
05/22/2022 20:34:53 - INFO - __main__ - Step 170 Global step 170 Train loss 0.92 on epoch=21
05/22/2022 20:34:56 - INFO - __main__ - Step 180 Global step 180 Train loss 0.77 on epoch=22
05/22/2022 20:34:58 - INFO - __main__ - Step 190 Global step 190 Train loss 0.82 on epoch=23
05/22/2022 20:35:01 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=24
05/22/2022 20:35:02 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.4502509337068161 on epoch=24
05/22/2022 20:35:05 - INFO - __main__ - Step 210 Global step 210 Train loss 0.81 on epoch=26
05/22/2022 20:35:07 - INFO - __main__ - Step 220 Global step 220 Train loss 0.78 on epoch=27
05/22/2022 20:35:09 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=28
05/22/2022 20:35:12 - INFO - __main__ - Step 240 Global step 240 Train loss 0.82 on epoch=29
05/22/2022 20:35:14 - INFO - __main__ - Step 250 Global step 250 Train loss 0.60 on epoch=31
05/22/2022 20:35:16 - INFO - __main__ - Global step 250 Train loss 0.77 Classification-F1 0.47031500134585685 on epoch=31
05/22/2022 20:35:16 - INFO - __main__ - Saving model with best Classification-F1: 0.4610110319787739 -> 0.47031500134585685 on epoch=31, global_step=250
05/22/2022 20:35:18 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=32
05/22/2022 20:35:21 - INFO - __main__ - Step 270 Global step 270 Train loss 0.60 on epoch=33
05/22/2022 20:35:23 - INFO - __main__ - Step 280 Global step 280 Train loss 0.64 on epoch=34
05/22/2022 20:35:26 - INFO - __main__ - Step 290 Global step 290 Train loss 0.71 on epoch=36
05/22/2022 20:35:28 - INFO - __main__ - Step 300 Global step 300 Train loss 0.67 on epoch=37
05/22/2022 20:35:30 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.4976890756302521 on epoch=37
05/22/2022 20:35:30 - INFO - __main__ - Saving model with best Classification-F1: 0.47031500134585685 -> 0.4976890756302521 on epoch=37, global_step=300
05/22/2022 20:35:32 - INFO - __main__ - Step 310 Global step 310 Train loss 0.69 on epoch=38
05/22/2022 20:35:35 - INFO - __main__ - Step 320 Global step 320 Train loss 0.76 on epoch=39
05/22/2022 20:35:37 - INFO - __main__ - Step 330 Global step 330 Train loss 0.64 on epoch=41
05/22/2022 20:35:39 - INFO - __main__ - Step 340 Global step 340 Train loss 0.69 on epoch=42
05/22/2022 20:35:42 - INFO - __main__ - Step 350 Global step 350 Train loss 0.74 on epoch=43
05/22/2022 20:35:43 - INFO - __main__ - Global step 350 Train loss 0.70 Classification-F1 0.5003317003470096 on epoch=43
05/22/2022 20:35:43 - INFO - __main__ - Saving model with best Classification-F1: 0.4976890756302521 -> 0.5003317003470096 on epoch=43, global_step=350
05/22/2022 20:35:46 - INFO - __main__ - Step 360 Global step 360 Train loss 0.61 on epoch=44
05/22/2022 20:35:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.68 on epoch=46
05/22/2022 20:35:50 - INFO - __main__ - Step 380 Global step 380 Train loss 0.67 on epoch=47
05/22/2022 20:35:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.62 on epoch=48
05/22/2022 20:35:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.58 on epoch=49
05/22/2022 20:35:57 - INFO - __main__ - Global step 400 Train loss 0.63 Classification-F1 0.570851959875702 on epoch=49
05/22/2022 20:35:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5003317003470096 -> 0.570851959875702 on epoch=49, global_step=400
05/22/2022 20:35:59 - INFO - __main__ - Step 410 Global step 410 Train loss 0.53 on epoch=51
05/22/2022 20:36:02 - INFO - __main__ - Step 420 Global step 420 Train loss 0.58 on epoch=52
05/22/2022 20:36:04 - INFO - __main__ - Step 430 Global step 430 Train loss 0.59 on epoch=53
05/22/2022 20:36:06 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=54
05/22/2022 20:36:09 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=56
05/22/2022 20:36:10 - INFO - __main__ - Global step 450 Train loss 0.56 Classification-F1 0.617352896939225 on epoch=56
05/22/2022 20:36:10 - INFO - __main__ - Saving model with best Classification-F1: 0.570851959875702 -> 0.617352896939225 on epoch=56, global_step=450
05/22/2022 20:36:13 - INFO - __main__ - Step 460 Global step 460 Train loss 0.51 on epoch=57
05/22/2022 20:36:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.66 on epoch=58
05/22/2022 20:36:18 - INFO - __main__ - Step 480 Global step 480 Train loss 0.55 on epoch=59
05/22/2022 20:36:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.44 on epoch=61
05/22/2022 20:36:22 - INFO - __main__ - Step 500 Global step 500 Train loss 0.54 on epoch=62
05/22/2022 20:36:24 - INFO - __main__ - Global step 500 Train loss 0.54 Classification-F1 0.6298333502220872 on epoch=62
05/22/2022 20:36:24 - INFO - __main__ - Saving model with best Classification-F1: 0.617352896939225 -> 0.6298333502220872 on epoch=62, global_step=500
05/22/2022 20:36:26 - INFO - __main__ - Step 510 Global step 510 Train loss 0.57 on epoch=63
05/22/2022 20:36:29 - INFO - __main__ - Step 520 Global step 520 Train loss 0.48 on epoch=64
05/22/2022 20:36:31 - INFO - __main__ - Step 530 Global step 530 Train loss 0.49 on epoch=66
05/22/2022 20:36:34 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=67
05/22/2022 20:36:36 - INFO - __main__ - Step 550 Global step 550 Train loss 0.48 on epoch=68
05/22/2022 20:36:38 - INFO - __main__ - Global step 550 Train loss 0.51 Classification-F1 0.6702737974284413 on epoch=68
05/22/2022 20:36:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6298333502220872 -> 0.6702737974284413 on epoch=68, global_step=550
05/22/2022 20:36:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.49 on epoch=69
05/22/2022 20:36:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=71
05/22/2022 20:36:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.49 on epoch=72
05/22/2022 20:36:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=73
05/22/2022 20:36:49 - INFO - __main__ - Step 600 Global step 600 Train loss 0.48 on epoch=74
05/22/2022 20:36:51 - INFO - __main__ - Global step 600 Train loss 0.48 Classification-F1 0.7237234092072803 on epoch=74
05/22/2022 20:36:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6702737974284413 -> 0.7237234092072803 on epoch=74, global_step=600
05/22/2022 20:36:54 - INFO - __main__ - Step 610 Global step 610 Train loss 0.47 on epoch=76
05/22/2022 20:36:56 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=77
05/22/2022 20:36:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.54 on epoch=78
05/22/2022 20:37:01 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=79
05/22/2022 20:37:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=81
05/22/2022 20:37:05 - INFO - __main__ - Global step 650 Train loss 0.45 Classification-F1 0.6909287373448068 on epoch=81
05/22/2022 20:37:07 - INFO - __main__ - Step 660 Global step 660 Train loss 0.45 on epoch=82
05/22/2022 20:37:10 - INFO - __main__ - Step 670 Global step 670 Train loss 0.51 on epoch=83
05/22/2022 20:37:12 - INFO - __main__ - Step 680 Global step 680 Train loss 0.41 on epoch=84
05/22/2022 20:37:14 - INFO - __main__ - Step 690 Global step 690 Train loss 0.29 on epoch=86
05/22/2022 20:37:17 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=87
05/22/2022 20:37:18 - INFO - __main__ - Global step 700 Train loss 0.41 Classification-F1 0.7060581209584631 on epoch=87
05/22/2022 20:37:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.44 on epoch=88
05/22/2022 20:37:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.43 on epoch=89
05/22/2022 20:37:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=91
05/22/2022 20:37:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=92
05/22/2022 20:37:30 - INFO - __main__ - Step 750 Global step 750 Train loss 0.47 on epoch=93
05/22/2022 20:37:32 - INFO - __main__ - Global step 750 Train loss 0.42 Classification-F1 0.708595505544624 on epoch=93
05/22/2022 20:37:35 - INFO - __main__ - Step 760 Global step 760 Train loss 0.40 on epoch=94
05/22/2022 20:37:37 - INFO - __main__ - Step 770 Global step 770 Train loss 0.43 on epoch=96
05/22/2022 20:37:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.39 on epoch=97
05/22/2022 20:37:42 - INFO - __main__ - Step 790 Global step 790 Train loss 0.43 on epoch=98
05/22/2022 20:37:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.50 on epoch=99
05/22/2022 20:37:46 - INFO - __main__ - Global step 800 Train loss 0.43 Classification-F1 0.7009408821520948 on epoch=99
05/22/2022 20:37:48 - INFO - __main__ - Step 810 Global step 810 Train loss 0.40 on epoch=101
05/22/2022 20:37:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.41 on epoch=102
05/22/2022 20:37:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.37 on epoch=103
05/22/2022 20:37:55 - INFO - __main__ - Step 840 Global step 840 Train loss 0.42 on epoch=104
05/22/2022 20:37:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.39 on epoch=106
05/22/2022 20:37:59 - INFO - __main__ - Global step 850 Train loss 0.40 Classification-F1 0.7192632850241546 on epoch=106
05/22/2022 20:38:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.35 on epoch=107
05/22/2022 20:38:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.33 on epoch=108
05/22/2022 20:38:06 - INFO - __main__ - Step 880 Global step 880 Train loss 0.35 on epoch=109
05/22/2022 20:38:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.32 on epoch=111
05/22/2022 20:38:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=112
05/22/2022 20:38:13 - INFO - __main__ - Global step 900 Train loss 0.34 Classification-F1 0.7376826805313486 on epoch=112
05/22/2022 20:38:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7237234092072803 -> 0.7376826805313486 on epoch=112, global_step=900
05/22/2022 20:38:15 - INFO - __main__ - Step 910 Global step 910 Train loss 0.47 on epoch=113
05/22/2022 20:38:18 - INFO - __main__ - Step 920 Global step 920 Train loss 0.35 on epoch=114
05/22/2022 20:38:20 - INFO - __main__ - Step 930 Global step 930 Train loss 0.28 on epoch=116
05/22/2022 20:38:22 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=117
05/22/2022 20:38:25 - INFO - __main__ - Step 950 Global step 950 Train loss 0.39 on epoch=118
05/22/2022 20:38:26 - INFO - __main__ - Global step 950 Train loss 0.36 Classification-F1 0.6885821650527534 on epoch=118
05/22/2022 20:38:29 - INFO - __main__ - Step 960 Global step 960 Train loss 0.33 on epoch=119
05/22/2022 20:38:31 - INFO - __main__ - Step 970 Global step 970 Train loss 0.40 on epoch=121
05/22/2022 20:38:34 - INFO - __main__ - Step 980 Global step 980 Train loss 0.32 on epoch=122
05/22/2022 20:38:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.32 on epoch=123
05/22/2022 20:38:39 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=124
05/22/2022 20:38:40 - INFO - __main__ - Global step 1000 Train loss 0.34 Classification-F1 0.7007253088034716 on epoch=124
05/22/2022 20:38:43 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.34 on epoch=126
05/22/2022 20:38:45 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.35 on epoch=127
05/22/2022 20:38:47 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.34 on epoch=128
05/22/2022 20:38:50 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.25 on epoch=129
05/22/2022 20:38:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.32 on epoch=131
05/22/2022 20:38:54 - INFO - __main__ - Global step 1050 Train loss 0.32 Classification-F1 0.7005760989115182 on epoch=131
05/22/2022 20:38:56 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=132
05/22/2022 20:38:59 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.33 on epoch=133
05/22/2022 20:39:01 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.30 on epoch=134
05/22/2022 20:39:03 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.26 on epoch=136
05/22/2022 20:39:06 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.34 on epoch=137
05/22/2022 20:39:07 - INFO - __main__ - Global step 1100 Train loss 0.31 Classification-F1 0.7041666666666667 on epoch=137
05/22/2022 20:39:10 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.37 on epoch=138
05/22/2022 20:39:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.30 on epoch=139
05/22/2022 20:39:15 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.31 on epoch=141
05/22/2022 20:39:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.35 on epoch=142
05/22/2022 20:39:19 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.33 on epoch=143
05/22/2022 20:39:21 - INFO - __main__ - Global step 1150 Train loss 0.33 Classification-F1 0.6866647844908714 on epoch=143
05/22/2022 20:39:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.23 on epoch=144
05/22/2022 20:39:26 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.21 on epoch=146
05/22/2022 20:39:28 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.34 on epoch=147
05/22/2022 20:39:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=148
05/22/2022 20:39:33 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=149
05/22/2022 20:39:35 - INFO - __main__ - Global step 1200 Train loss 0.26 Classification-F1 0.7033642547928262 on epoch=149
05/22/2022 20:39:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.24 on epoch=151
05/22/2022 20:39:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=152
05/22/2022 20:39:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.26 on epoch=153
05/22/2022 20:39:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.25 on epoch=154
05/22/2022 20:39:46 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.30 on epoch=156
05/22/2022 20:39:48 - INFO - __main__ - Global step 1250 Train loss 0.26 Classification-F1 0.6667843634476597 on epoch=156
05/22/2022 20:39:50 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.34 on epoch=157
05/22/2022 20:39:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.22 on epoch=158
05/22/2022 20:39:55 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=159
05/22/2022 20:39:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.26 on epoch=161
05/22/2022 20:40:00 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.23 on epoch=162
05/22/2022 20:40:02 - INFO - __main__ - Global step 1300 Train loss 0.24 Classification-F1 0.7023915664443915 on epoch=162
05/22/2022 20:40:04 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.28 on epoch=163
05/22/2022 20:40:06 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.29 on epoch=164
05/22/2022 20:40:09 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.25 on epoch=166
05/22/2022 20:40:11 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.30 on epoch=167
05/22/2022 20:40:14 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.25 on epoch=168
05/22/2022 20:40:15 - INFO - __main__ - Global step 1350 Train loss 0.27 Classification-F1 0.7237914862914864 on epoch=168
05/22/2022 20:40:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=169
05/22/2022 20:40:20 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=171
05/22/2022 20:40:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.25 on epoch=172
05/22/2022 20:40:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.33 on epoch=173
05/22/2022 20:40:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.30 on epoch=174
05/22/2022 20:40:29 - INFO - __main__ - Global step 1400 Train loss 0.27 Classification-F1 0.7162113381291464 on epoch=174
05/22/2022 20:40:31 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.21 on epoch=176
05/22/2022 20:40:34 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.26 on epoch=177
05/22/2022 20:40:36 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.22 on epoch=178
05/22/2022 20:40:38 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.16 on epoch=179
05/22/2022 20:40:41 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.18 on epoch=181
05/22/2022 20:40:42 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.7070273398398399 on epoch=181
05/22/2022 20:40:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=182
05/22/2022 20:40:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.23 on epoch=183
05/22/2022 20:40:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.18 on epoch=184
05/22/2022 20:40:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=186
05/22/2022 20:40:54 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.23 on epoch=187
05/22/2022 20:40:56 - INFO - __main__ - Global step 1500 Train loss 0.19 Classification-F1 0.6953521624574256 on epoch=187
05/22/2022 20:40:58 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.23 on epoch=188
05/22/2022 20:41:01 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.20 on epoch=189
05/22/2022 20:41:03 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.24 on epoch=191
05/22/2022 20:41:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.21 on epoch=192
05/22/2022 20:41:08 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=193
05/22/2022 20:41:10 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.6759136812015278 on epoch=193
05/22/2022 20:41:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.15 on epoch=194
05/22/2022 20:41:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=196
05/22/2022 20:41:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=197
05/22/2022 20:41:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.25 on epoch=198
05/22/2022 20:41:21 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.20 on epoch=199
05/22/2022 20:41:23 - INFO - __main__ - Global step 1600 Train loss 0.18 Classification-F1 0.7004013104013104 on epoch=199
05/22/2022 20:41:26 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=201
05/22/2022 20:41:28 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.11 on epoch=202
05/22/2022 20:41:30 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.26 on epoch=203
05/22/2022 20:41:33 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.15 on epoch=204
05/22/2022 20:41:35 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.22 on epoch=206
05/22/2022 20:41:37 - INFO - __main__ - Global step 1650 Train loss 0.18 Classification-F1 0.7172162804515746 on epoch=206
05/22/2022 20:41:39 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.20 on epoch=207
05/22/2022 20:41:41 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.18 on epoch=208
05/22/2022 20:41:44 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=209
05/22/2022 20:41:46 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.16 on epoch=211
05/22/2022 20:41:49 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.23 on epoch=212
05/22/2022 20:41:50 - INFO - __main__ - Global step 1700 Train loss 0.18 Classification-F1 0.685822772446463 on epoch=212
05/22/2022 20:41:53 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=213
05/22/2022 20:41:55 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.16 on epoch=214
05/22/2022 20:41:58 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.18 on epoch=216
05/22/2022 20:42:00 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.24 on epoch=217
05/22/2022 20:42:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.25 on epoch=218
05/22/2022 20:42:04 - INFO - __main__ - Global step 1750 Train loss 0.19 Classification-F1 0.6722773406028791 on epoch=218
05/22/2022 20:42:06 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.16 on epoch=219
05/22/2022 20:42:09 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=221
05/22/2022 20:42:11 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.20 on epoch=222
05/22/2022 20:42:14 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.13 on epoch=223
05/22/2022 20:42:16 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.17 on epoch=224
05/22/2022 20:42:18 - INFO - __main__ - Global step 1800 Train loss 0.15 Classification-F1 0.7159844706719707 on epoch=224
05/22/2022 20:42:20 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=226
05/22/2022 20:42:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=227
05/22/2022 20:42:25 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=228
05/22/2022 20:42:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=229
05/22/2022 20:42:30 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=231
05/22/2022 20:42:31 - INFO - __main__ - Global step 1850 Train loss 0.14 Classification-F1 0.7492755262417417 on epoch=231
05/22/2022 20:42:31 - INFO - __main__ - Saving model with best Classification-F1: 0.7376826805313486 -> 0.7492755262417417 on epoch=231, global_step=1850
05/22/2022 20:42:34 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.12 on epoch=232
05/22/2022 20:42:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.15 on epoch=233
05/22/2022 20:42:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.22 on epoch=234
05/22/2022 20:42:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.13 on epoch=236
05/22/2022 20:42:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=237
05/22/2022 20:42:45 - INFO - __main__ - Global step 1900 Train loss 0.15 Classification-F1 0.764493294478302 on epoch=237
05/22/2022 20:42:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7492755262417417 -> 0.764493294478302 on epoch=237, global_step=1900
05/22/2022 20:42:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.10 on epoch=238
05/22/2022 20:42:50 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.10 on epoch=239
05/22/2022 20:42:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.16 on epoch=241
05/22/2022 20:42:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=242
05/22/2022 20:42:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.15 on epoch=243
05/22/2022 20:42:58 - INFO - __main__ - Global step 1950 Train loss 0.13 Classification-F1 0.723131555944056 on epoch=243
05/22/2022 20:43:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
05/22/2022 20:43:03 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.16 on epoch=246
05/22/2022 20:43:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.13 on epoch=247
05/22/2022 20:43:08 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.25 on epoch=248
05/22/2022 20:43:10 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.11 on epoch=249
05/22/2022 20:43:12 - INFO - __main__ - Global step 2000 Train loss 0.15 Classification-F1 0.6886756424107867 on epoch=249
05/22/2022 20:43:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.21 on epoch=251
05/22/2022 20:43:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.11 on epoch=252
05/22/2022 20:43:19 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.19 on epoch=253
05/22/2022 20:43:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.13 on epoch=254
05/22/2022 20:43:24 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=256
05/22/2022 20:43:26 - INFO - __main__ - Global step 2050 Train loss 0.14 Classification-F1 0.7410387949039264 on epoch=256
05/22/2022 20:43:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=257
05/22/2022 20:43:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.15 on epoch=258
05/22/2022 20:43:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=259
05/22/2022 20:43:35 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.11 on epoch=261
05/22/2022 20:43:37 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.20 on epoch=262
05/22/2022 20:43:39 - INFO - __main__ - Global step 2100 Train loss 0.13 Classification-F1 0.7635571772568676 on epoch=262
05/22/2022 20:43:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.11 on epoch=263
05/22/2022 20:43:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=264
05/22/2022 20:43:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.09 on epoch=266
05/22/2022 20:43:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
05/22/2022 20:43:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=268
05/22/2022 20:43:53 - INFO - __main__ - Global step 2150 Train loss 0.08 Classification-F1 0.7420242974238875 on epoch=268
05/22/2022 20:43:55 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=269
05/22/2022 20:43:57 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=271
05/22/2022 20:44:00 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.14 on epoch=272
05/22/2022 20:44:02 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.12 on epoch=273
05/22/2022 20:44:05 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=274
05/22/2022 20:44:06 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.7259808195292066 on epoch=274
05/22/2022 20:44:09 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.16 on epoch=276
05/22/2022 20:44:11 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=277
05/22/2022 20:44:13 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.10 on epoch=278
05/22/2022 20:44:16 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=279
05/22/2022 20:44:18 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.18 on epoch=281
05/22/2022 20:44:20 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.709259205143191 on epoch=281
05/22/2022 20:44:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.18 on epoch=282
05/22/2022 20:44:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=283
05/22/2022 20:44:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
05/22/2022 20:44:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=286
05/22/2022 20:44:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.16 on epoch=287
05/22/2022 20:44:34 - INFO - __main__ - Global step 2300 Train loss 0.11 Classification-F1 0.7651512207525535 on epoch=287
05/22/2022 20:44:34 - INFO - __main__ - Saving model with best Classification-F1: 0.764493294478302 -> 0.7651512207525535 on epoch=287, global_step=2300
05/22/2022 20:44:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.10 on epoch=288
05/22/2022 20:44:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.16 on epoch=289
05/22/2022 20:44:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=291
05/22/2022 20:44:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=292
05/22/2022 20:44:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=293
05/22/2022 20:44:47 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.716271924796515 on epoch=293
05/22/2022 20:44:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.12 on epoch=294
05/22/2022 20:44:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
05/22/2022 20:44:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=297
05/22/2022 20:44:57 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=298
05/22/2022 20:44:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=299
05/22/2022 20:45:01 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.731990231990232 on epoch=299
05/22/2022 20:45:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
05/22/2022 20:45:05 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.12 on epoch=302
05/22/2022 20:45:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=303
05/22/2022 20:45:10 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=304
05/22/2022 20:45:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=306
05/22/2022 20:45:14 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.7321740806520451 on epoch=306
05/22/2022 20:45:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=307
05/22/2022 20:45:19 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=308
05/22/2022 20:45:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=309
05/22/2022 20:45:24 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=311
05/22/2022 20:45:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=312
05/22/2022 20:45:28 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.7159657244164287 on epoch=312
05/22/2022 20:45:30 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.17 on epoch=313
05/22/2022 20:45:33 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=314
05/22/2022 20:45:35 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=316
05/22/2022 20:45:38 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
05/22/2022 20:45:40 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.10 on epoch=318
05/22/2022 20:45:42 - INFO - __main__ - Global step 2550 Train loss 0.10 Classification-F1 0.7333053613966957 on epoch=318
05/22/2022 20:45:44 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.15 on epoch=319
05/22/2022 20:45:46 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.13 on epoch=321
05/22/2022 20:45:49 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.14 on epoch=322
05/22/2022 20:45:51 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.12 on epoch=323
05/22/2022 20:45:54 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.08 on epoch=324
05/22/2022 20:45:55 - INFO - __main__ - Global step 2600 Train loss 0.12 Classification-F1 0.7579365079365079 on epoch=324
05/22/2022 20:45:58 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=326
05/22/2022 20:46:00 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
05/22/2022 20:46:03 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=328
05/22/2022 20:46:05 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=329
05/22/2022 20:46:08 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.09 on epoch=331
05/22/2022 20:46:09 - INFO - __main__ - Global step 2650 Train loss 0.07 Classification-F1 0.7318075117370892 on epoch=331
05/22/2022 20:46:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
05/22/2022 20:46:14 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.10 on epoch=333
05/22/2022 20:46:17 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=334
05/22/2022 20:46:19 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.15 on epoch=336
05/22/2022 20:46:22 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=337
05/22/2022 20:46:23 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.7143341065644148 on epoch=337
05/22/2022 20:46:26 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=338
05/22/2022 20:46:28 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=339
05/22/2022 20:46:31 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.11 on epoch=341
05/22/2022 20:46:34 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.10 on epoch=342
05/22/2022 20:46:36 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.05 on epoch=343
05/22/2022 20:46:38 - INFO - __main__ - Global step 2750 Train loss 0.09 Classification-F1 0.7307002856298632 on epoch=343
05/22/2022 20:46:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=344
05/22/2022 20:46:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.09 on epoch=346
05/22/2022 20:46:45 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=347
05/22/2022 20:46:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
05/22/2022 20:46:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=349
05/22/2022 20:46:52 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7415496565458324 on epoch=349
05/22/2022 20:46:55 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=351
05/22/2022 20:46:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=352
05/22/2022 20:47:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=353
05/22/2022 20:47:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.05 on epoch=354
05/22/2022 20:47:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.10 on epoch=356
05/22/2022 20:47:07 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.6973729426559615 on epoch=356
05/22/2022 20:47:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=357
05/22/2022 20:47:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
05/22/2022 20:47:14 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.06 on epoch=359
05/22/2022 20:47:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=361
05/22/2022 20:47:19 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=362
05/22/2022 20:47:21 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7421708300806662 on epoch=362
05/22/2022 20:47:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.10 on epoch=363
05/22/2022 20:47:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
05/22/2022 20:47:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=366
05/22/2022 20:47:31 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.08 on epoch=367
05/22/2022 20:47:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=368
05/22/2022 20:47:35 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7494868637110017 on epoch=368
05/22/2022 20:47:38 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.09 on epoch=369
05/22/2022 20:47:40 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 20:47:43 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
05/22/2022 20:47:45 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=373
05/22/2022 20:47:48 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=374
05/22/2022 20:47:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:47:49 - INFO - __main__ - Printing 3 examples
05/22/2022 20:47:49 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:47:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:47:49 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:47:49 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:47:49 - INFO - __main__ - Printing 3 examples
05/22/2022 20:47:49 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 20:47:49 - INFO - __main__ - ['happy']
05/22/2022 20:47:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:47:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:47:49 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.7321428571428572 on epoch=374
05/22/2022 20:47:49 - INFO - __main__ - save last model!
05/22/2022 20:47:49 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:47:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 20:47:49 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 20:47:49 - INFO - __main__ - Printing 3 examples
05/22/2022 20:47:49 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 20:47:49 - INFO - __main__ - ['others']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 20:47:49 - INFO - __main__ - ['others']
05/22/2022 20:47:49 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 20:47:49 - INFO - __main__ - ['others']
05/22/2022 20:47:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:47:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:47:57 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 20:48:05 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:48:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:48:06 - INFO - __main__ - Starting training!
05/22/2022 20:49:10 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_21_0.2_8_predictions.txt
05/22/2022 20:49:10 - INFO - __main__ - Classification-F1 on test data: 0.1913
05/22/2022 20:49:10 - INFO - __main__ - prefix=emo_32_21, lr=0.2, bsz=8, dev_performance=0.7651512207525535, test_performance=0.19127675080546544
05/22/2022 20:49:10 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.5, bsz=8 ...
05/22/2022 20:49:11 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:49:11 - INFO - __main__ - Printing 3 examples
05/22/2022 20:49:11 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:49:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:49:11 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 20:49:11 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 20:49:11 - INFO - __main__ - Printing 3 examples
05/22/2022 20:49:11 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 20:49:11 - INFO - __main__ - ['happy']
05/22/2022 20:49:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 20:49:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 20:49:11 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 20:49:30 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 20:49:31 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 20:49:31 - INFO - __main__ - Starting training!
05/22/2022 20:49:34 - INFO - __main__ - Step 10 Global step 10 Train loss 3.86 on epoch=1
05/22/2022 20:49:36 - INFO - __main__ - Step 20 Global step 20 Train loss 2.62 on epoch=2
05/22/2022 20:49:39 - INFO - __main__ - Step 30 Global step 30 Train loss 2.02 on epoch=3
05/22/2022 20:49:41 - INFO - __main__ - Step 40 Global step 40 Train loss 1.80 on epoch=4
05/22/2022 20:49:43 - INFO - __main__ - Step 50 Global step 50 Train loss 1.49 on epoch=6
05/22/2022 20:49:45 - INFO - __main__ - Global step 50 Train loss 2.36 Classification-F1 0.31002103652706064 on epoch=6
05/22/2022 20:49:45 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.31002103652706064 on epoch=6, global_step=50
05/22/2022 20:49:47 - INFO - __main__ - Step 60 Global step 60 Train loss 1.04 on epoch=7
05/22/2022 20:49:50 - INFO - __main__ - Step 70 Global step 70 Train loss 0.86 on epoch=8
05/22/2022 20:49:52 - INFO - __main__ - Step 80 Global step 80 Train loss 0.87 on epoch=9
05/22/2022 20:49:55 - INFO - __main__ - Step 90 Global step 90 Train loss 0.71 on epoch=11
05/22/2022 20:49:57 - INFO - __main__ - Step 100 Global step 100 Train loss 0.78 on epoch=12
05/22/2022 20:49:59 - INFO - __main__ - Global step 100 Train loss 0.85 Classification-F1 0.4896868157489255 on epoch=12
05/22/2022 20:49:59 - INFO - __main__ - Saving model with best Classification-F1: 0.31002103652706064 -> 0.4896868157489255 on epoch=12, global_step=100
05/22/2022 20:50:01 - INFO - __main__ - Step 110 Global step 110 Train loss 0.64 on epoch=13
05/22/2022 20:50:04 - INFO - __main__ - Step 120 Global step 120 Train loss 0.70 on epoch=14
05/22/2022 20:50:06 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=16
05/22/2022 20:50:09 - INFO - __main__ - Step 140 Global step 140 Train loss 0.64 on epoch=17
05/22/2022 20:50:11 - INFO - __main__ - Step 150 Global step 150 Train loss 0.60 on epoch=18
05/22/2022 20:50:13 - INFO - __main__ - Global step 150 Train loss 0.67 Classification-F1 0.5280955743879473 on epoch=18
05/22/2022 20:50:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4896868157489255 -> 0.5280955743879473 on epoch=18, global_step=150
05/22/2022 20:50:15 - INFO - __main__ - Step 160 Global step 160 Train loss 0.59 on epoch=19
05/22/2022 20:50:18 - INFO - __main__ - Step 170 Global step 170 Train loss 0.48 on epoch=21
05/22/2022 20:50:20 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
05/22/2022 20:50:22 - INFO - __main__ - Step 190 Global step 190 Train loss 0.55 on epoch=23
05/22/2022 20:50:25 - INFO - __main__ - Step 200 Global step 200 Train loss 0.40 on epoch=24
05/22/2022 20:50:26 - INFO - __main__ - Global step 200 Train loss 0.54 Classification-F1 0.5499056329849012 on epoch=24
05/22/2022 20:50:26 - INFO - __main__ - Saving model with best Classification-F1: 0.5280955743879473 -> 0.5499056329849012 on epoch=24, global_step=200
05/22/2022 20:50:29 - INFO - __main__ - Step 210 Global step 210 Train loss 0.49 on epoch=26
05/22/2022 20:50:31 - INFO - __main__ - Step 220 Global step 220 Train loss 0.49 on epoch=27
05/22/2022 20:50:34 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=28
05/22/2022 20:50:36 - INFO - __main__ - Step 240 Global step 240 Train loss 0.40 on epoch=29
05/22/2022 20:50:39 - INFO - __main__ - Step 250 Global step 250 Train loss 0.39 on epoch=31
05/22/2022 20:50:40 - INFO - __main__ - Global step 250 Train loss 0.44 Classification-F1 0.5847143466861777 on epoch=31
05/22/2022 20:50:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5499056329849012 -> 0.5847143466861777 on epoch=31, global_step=250
05/22/2022 20:50:43 - INFO - __main__ - Step 260 Global step 260 Train loss 0.43 on epoch=32
05/22/2022 20:50:45 - INFO - __main__ - Step 270 Global step 270 Train loss 0.37 on epoch=33
05/22/2022 20:50:48 - INFO - __main__ - Step 280 Global step 280 Train loss 0.50 on epoch=34
05/22/2022 20:50:50 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=36
05/22/2022 20:50:53 - INFO - __main__ - Step 300 Global step 300 Train loss 0.54 on epoch=37
05/22/2022 20:50:54 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.6270632480379976 on epoch=37
05/22/2022 20:50:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5847143466861777 -> 0.6270632480379976 on epoch=37, global_step=300
05/22/2022 20:50:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.34 on epoch=38
05/22/2022 20:50:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.33 on epoch=39
05/22/2022 20:51:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.30 on epoch=41
05/22/2022 20:51:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.35 on epoch=42
05/22/2022 20:51:06 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=43
05/22/2022 20:51:08 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.6597850283808537 on epoch=43
05/22/2022 20:51:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6270632480379976 -> 0.6597850283808537 on epoch=43, global_step=350
05/22/2022 20:51:10 - INFO - __main__ - Step 360 Global step 360 Train loss 0.39 on epoch=44
05/22/2022 20:51:13 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=46
05/22/2022 20:51:15 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=47
05/22/2022 20:51:18 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=48
05/22/2022 20:51:20 - INFO - __main__ - Step 400 Global step 400 Train loss 0.32 on epoch=49
05/22/2022 20:51:22 - INFO - __main__ - Global step 400 Train loss 0.35 Classification-F1 0.6225210731442037 on epoch=49
05/22/2022 20:51:24 - INFO - __main__ - Step 410 Global step 410 Train loss 0.23 on epoch=51
05/22/2022 20:51:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=52
05/22/2022 20:51:29 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=53
05/22/2022 20:51:31 - INFO - __main__ - Step 440 Global step 440 Train loss 0.23 on epoch=54
05/22/2022 20:51:34 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=56
05/22/2022 20:51:36 - INFO - __main__ - Global step 450 Train loss 0.27 Classification-F1 0.6956228999083597 on epoch=56
05/22/2022 20:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6597850283808537 -> 0.6956228999083597 on epoch=56, global_step=450
05/22/2022 20:51:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=57
05/22/2022 20:51:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=58
05/22/2022 20:51:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.17 on epoch=59
05/22/2022 20:51:45 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=61
05/22/2022 20:51:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.20 on epoch=62
05/22/2022 20:51:49 - INFO - __main__ - Global step 500 Train loss 0.22 Classification-F1 0.6680351906158359 on epoch=62
05/22/2022 20:51:52 - INFO - __main__ - Step 510 Global step 510 Train loss 0.24 on epoch=63
05/22/2022 20:51:54 - INFO - __main__ - Step 520 Global step 520 Train loss 0.22 on epoch=64
05/22/2022 20:51:57 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=66
05/22/2022 20:51:59 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=67
05/22/2022 20:52:01 - INFO - __main__ - Step 550 Global step 550 Train loss 0.17 on epoch=68
05/22/2022 20:52:03 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.7156285817205357 on epoch=68
05/22/2022 20:52:03 - INFO - __main__ - Saving model with best Classification-F1: 0.6956228999083597 -> 0.7156285817205357 on epoch=68, global_step=550
05/22/2022 20:52:05 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=69
05/22/2022 20:52:08 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=71
05/22/2022 20:52:10 - INFO - __main__ - Step 580 Global step 580 Train loss 0.25 on epoch=72
05/22/2022 20:52:13 - INFO - __main__ - Step 590 Global step 590 Train loss 0.11 on epoch=73
05/22/2022 20:52:15 - INFO - __main__ - Step 600 Global step 600 Train loss 0.20 on epoch=74
05/22/2022 20:52:17 - INFO - __main__ - Global step 600 Train loss 0.18 Classification-F1 0.7041785114934089 on epoch=74
05/22/2022 20:52:19 - INFO - __main__ - Step 610 Global step 610 Train loss 0.16 on epoch=76
05/22/2022 20:52:22 - INFO - __main__ - Step 620 Global step 620 Train loss 0.15 on epoch=77
05/22/2022 20:52:24 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=78
05/22/2022 20:52:26 - INFO - __main__ - Step 640 Global step 640 Train loss 0.10 on epoch=79
05/22/2022 20:52:29 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=81
05/22/2022 20:52:31 - INFO - __main__ - Global step 650 Train loss 0.15 Classification-F1 0.7096424268296381 on epoch=81
05/22/2022 20:52:33 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=82
05/22/2022 20:52:36 - INFO - __main__ - Step 670 Global step 670 Train loss 0.16 on epoch=83
05/22/2022 20:52:38 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=84
05/22/2022 20:52:40 - INFO - __main__ - Step 690 Global step 690 Train loss 0.11 on epoch=86
05/22/2022 20:52:43 - INFO - __main__ - Step 700 Global step 700 Train loss 0.29 on epoch=87
05/22/2022 20:52:45 - INFO - __main__ - Global step 700 Train loss 0.18 Classification-F1 0.6668275273113983 on epoch=87
05/22/2022 20:52:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=88
05/22/2022 20:52:49 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=89
05/22/2022 20:52:52 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=91
05/22/2022 20:52:54 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=92
05/22/2022 20:52:56 - INFO - __main__ - Step 750 Global step 750 Train loss 0.14 on epoch=93
05/22/2022 20:52:58 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.7314681192227881 on epoch=93
05/22/2022 20:52:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7156285817205357 -> 0.7314681192227881 on epoch=93, global_step=750
05/22/2022 20:53:01 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=94
05/22/2022 20:53:03 - INFO - __main__ - Step 770 Global step 770 Train loss 0.09 on epoch=96
05/22/2022 20:53:05 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=97
05/22/2022 20:53:08 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=98
05/22/2022 20:53:11 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=99
05/22/2022 20:53:12 - INFO - __main__ - Global step 800 Train loss 0.09 Classification-F1 0.7499400517448097 on epoch=99
05/22/2022 20:53:12 - INFO - __main__ - Saving model with best Classification-F1: 0.7314681192227881 -> 0.7499400517448097 on epoch=99, global_step=800
05/22/2022 20:53:15 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=101
05/22/2022 20:53:17 - INFO - __main__ - Step 820 Global step 820 Train loss 0.10 on epoch=102
05/22/2022 20:53:20 - INFO - __main__ - Step 830 Global step 830 Train loss 0.06 on epoch=103
05/22/2022 20:53:22 - INFO - __main__ - Step 840 Global step 840 Train loss 0.07 on epoch=104
05/22/2022 20:53:25 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=106
05/22/2022 20:53:26 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.7040844298245614 on epoch=106
05/22/2022 20:53:29 - INFO - __main__ - Step 860 Global step 860 Train loss 0.06 on epoch=107
05/22/2022 20:53:31 - INFO - __main__ - Step 870 Global step 870 Train loss 0.07 on epoch=108
05/22/2022 20:53:34 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=109
05/22/2022 20:53:36 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=111
05/22/2022 20:53:39 - INFO - __main__ - Step 900 Global step 900 Train loss 0.04 on epoch=112
05/22/2022 20:53:40 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.6743906032240986 on epoch=112
05/22/2022 20:53:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.07 on epoch=113
05/22/2022 20:53:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=114
05/22/2022 20:53:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=116
05/22/2022 20:53:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=117
05/22/2022 20:53:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=118
05/22/2022 20:53:54 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7063487159678574 on epoch=118
05/22/2022 20:53:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.08 on epoch=119
05/22/2022 20:53:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.07 on epoch=121
05/22/2022 20:54:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=122
05/22/2022 20:54:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=123
05/22/2022 20:54:06 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=124
05/22/2022 20:54:08 - INFO - __main__ - Global step 1000 Train loss 0.09 Classification-F1 0.6928102636026899 on epoch=124
05/22/2022 20:54:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=126
05/22/2022 20:54:13 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.10 on epoch=127
05/22/2022 20:54:15 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.09 on epoch=128
05/22/2022 20:54:18 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.12 on epoch=129
05/22/2022 20:54:20 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.06 on epoch=131
05/22/2022 20:54:22 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.636285404736109 on epoch=131
05/22/2022 20:54:25 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.01 on epoch=132
05/22/2022 20:54:27 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=133
05/22/2022 20:54:30 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=134
05/22/2022 20:54:32 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.03 on epoch=136
05/22/2022 20:54:35 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=137
05/22/2022 20:54:36 - INFO - __main__ - Global step 1100 Train loss 0.04 Classification-F1 0.6354177323103155 on epoch=137
05/22/2022 20:54:39 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=138
05/22/2022 20:54:41 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=139
05/22/2022 20:54:44 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=141
05/22/2022 20:54:46 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=142
05/22/2022 20:54:49 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=143
05/22/2022 20:54:50 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.6832893815380575 on epoch=143
05/22/2022 20:54:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=144
05/22/2022 20:54:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=146
05/22/2022 20:54:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=147
05/22/2022 20:55:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=148
05/22/2022 20:55:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.05 on epoch=149
05/22/2022 20:55:04 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7149457871660296 on epoch=149
05/22/2022 20:55:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=151
05/22/2022 20:55:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=152
05/22/2022 20:55:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=153
05/22/2022 20:55:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=154
05/22/2022 20:55:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=156
05/22/2022 20:55:18 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.7425067925067924 on epoch=156
05/22/2022 20:55:21 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=157
05/22/2022 20:55:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=158
05/22/2022 20:55:26 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=159
05/22/2022 20:55:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=161
05/22/2022 20:55:31 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=162
05/22/2022 20:55:32 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.7236652236652237 on epoch=162
05/22/2022 20:55:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.01 on epoch=163
05/22/2022 20:55:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=164
05/22/2022 20:55:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.01 on epoch=166
05/22/2022 20:55:42 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=167
05/22/2022 20:55:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=168
05/22/2022 20:55:46 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6857548264907136 on epoch=168
05/22/2022 20:55:49 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=169
05/22/2022 20:55:51 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=171
05/22/2022 20:55:54 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=172
05/22/2022 20:55:56 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=173
05/22/2022 20:55:59 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=174
05/22/2022 20:56:00 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7381692311031056 on epoch=174
05/22/2022 20:56:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=176
05/22/2022 20:56:05 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=177
05/22/2022 20:56:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=178
05/22/2022 20:56:10 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=179
05/22/2022 20:56:13 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=181
05/22/2022 20:56:15 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.678950020034412 on epoch=181
05/22/2022 20:56:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=182
05/22/2022 20:56:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=183
05/22/2022 20:56:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=184
05/22/2022 20:56:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.06 on epoch=186
05/22/2022 20:56:27 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=187
05/22/2022 20:56:29 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6405493075564643 on epoch=187
05/22/2022 20:56:32 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=188
05/22/2022 20:56:34 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
05/22/2022 20:56:37 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.07 on epoch=191
05/22/2022 20:56:39 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=192
05/22/2022 20:56:42 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
05/22/2022 20:56:44 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.718833715896914 on epoch=193
05/22/2022 20:56:46 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.01 on epoch=194
05/22/2022 20:56:49 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.01 on epoch=196
05/22/2022 20:56:51 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.03 on epoch=197
05/22/2022 20:56:54 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=198
05/22/2022 20:56:56 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.00 on epoch=199
05/22/2022 20:56:58 - INFO - __main__ - Global step 1600 Train loss 0.01 Classification-F1 0.7085880962930142 on epoch=199
05/22/2022 20:57:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.01 on epoch=201
05/22/2022 20:57:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=202
05/22/2022 20:57:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=203
05/22/2022 20:57:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.00 on epoch=204
05/22/2022 20:57:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.01 on epoch=206
05/22/2022 20:57:12 - INFO - __main__ - Global step 1650 Train loss 0.03 Classification-F1 0.7173769466073414 on epoch=206
05/22/2022 20:57:15 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=207
05/22/2022 20:57:17 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
05/22/2022 20:57:20 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=209
05/22/2022 20:57:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
05/22/2022 20:57:25 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=212
05/22/2022 20:57:27 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7382165751383134 on epoch=212
05/22/2022 20:57:29 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=213
05/22/2022 20:57:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=214
05/22/2022 20:57:34 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=216
05/22/2022 20:57:37 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
05/22/2022 20:57:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=218
05/22/2022 20:57:41 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.5871085644218071 on epoch=218
05/22/2022 20:57:44 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=219
05/22/2022 20:57:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=221
05/22/2022 20:57:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=222
05/22/2022 20:57:52 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
05/22/2022 20:57:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
05/22/2022 20:57:56 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7081273920174959 on epoch=224
05/22/2022 20:57:59 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=226
05/22/2022 20:58:02 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
05/22/2022 20:58:04 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=228
05/22/2022 20:58:07 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=229
05/22/2022 20:58:09 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.00 on epoch=231
05/22/2022 20:58:11 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.7294349586605098 on epoch=231
05/22/2022 20:58:14 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 20:58:16 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
05/22/2022 20:58:19 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=234
05/22/2022 20:58:22 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=236
05/22/2022 20:58:24 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=237
05/22/2022 20:58:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.7323956190823331 on epoch=237
05/22/2022 20:58:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
05/22/2022 20:58:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=239
05/22/2022 20:58:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.00 on epoch=241
05/22/2022 20:58:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
05/22/2022 20:58:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.00 on epoch=243
05/22/2022 20:58:41 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6703711447374592 on epoch=243
05/22/2022 20:58:43 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
05/22/2022 20:58:46 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.00 on epoch=246
05/22/2022 20:58:48 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=247
05/22/2022 20:58:51 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=248
05/22/2022 20:58:54 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
05/22/2022 20:58:55 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7162462796500615 on epoch=249
05/22/2022 20:58:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
05/22/2022 20:59:01 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
05/22/2022 20:59:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=253
05/22/2022 20:59:06 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
05/22/2022 20:59:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.12 on epoch=256
05/22/2022 20:59:10 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.720973754622253 on epoch=256
05/22/2022 20:59:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=257
05/22/2022 20:59:15 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
05/22/2022 20:59:18 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
05/22/2022 20:59:20 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
05/22/2022 20:59:23 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
05/22/2022 20:59:25 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.7154571867952857 on epoch=262
05/22/2022 20:59:27 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
05/22/2022 20:59:30 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
05/22/2022 20:59:32 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
05/22/2022 20:59:35 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
05/22/2022 20:59:38 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
05/22/2022 20:59:39 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7006831442315313 on epoch=268
05/22/2022 20:59:42 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
05/22/2022 20:59:45 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=271
05/22/2022 20:59:47 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=272
05/22/2022 20:59:50 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=273
05/22/2022 20:59:52 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
05/22/2022 20:59:54 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7001228639899972 on epoch=274
05/22/2022 20:59:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
05/22/2022 20:59:59 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
05/22/2022 21:00:02 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=278
05/22/2022 21:00:04 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.00 on epoch=279
05/22/2022 21:00:07 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=281
05/22/2022 21:00:09 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.6852678571428572 on epoch=281
05/22/2022 21:00:11 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
05/22/2022 21:00:14 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.00 on epoch=283
05/22/2022 21:00:17 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.00 on epoch=284
05/22/2022 21:00:19 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=286
05/22/2022 21:00:22 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=287
05/22/2022 21:00:24 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.5629943586856446 on epoch=287
05/22/2022 21:00:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
05/22/2022 21:00:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=289
05/22/2022 21:00:32 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=291
05/22/2022 21:00:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
05/22/2022 21:00:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
05/22/2022 21:00:38 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.720984349894945 on epoch=293
05/22/2022 21:00:41 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
05/22/2022 21:00:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=296
05/22/2022 21:00:46 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
05/22/2022 21:00:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 21:00:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=299
05/22/2022 21:00:52 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.5802464788732393 on epoch=299
05/22/2022 21:00:55 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.00 on epoch=301
05/22/2022 21:00:57 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
05/22/2022 21:01:00 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=303
05/22/2022 21:01:02 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.05 on epoch=304
05/22/2022 21:01:05 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.10 on epoch=306
05/22/2022 21:01:07 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.5437247049397012 on epoch=306
05/22/2022 21:01:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.00 on epoch=307
05/22/2022 21:01:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.00 on epoch=308
05/22/2022 21:01:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
05/22/2022 21:01:17 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=311
05/22/2022 21:01:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
05/22/2022 21:01:21 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.5738109980834439 on epoch=312
05/22/2022 21:01:23 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
05/22/2022 21:01:26 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=314
05/22/2022 21:01:28 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
05/22/2022 21:01:31 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
05/22/2022 21:01:33 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.00 on epoch=318
05/22/2022 21:01:35 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.5613251118507299 on epoch=318
05/22/2022 21:01:37 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=319
05/22/2022 21:01:40 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
05/22/2022 21:01:42 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=322
05/22/2022 21:01:45 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=323
05/22/2022 21:01:47 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=324
05/22/2022 21:01:49 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.5736455303108365 on epoch=324
05/22/2022 21:01:52 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=326
05/22/2022 21:01:54 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
05/22/2022 21:01:57 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
05/22/2022 21:01:59 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 21:02:02 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
05/22/2022 21:02:03 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.549520954397715 on epoch=331
05/22/2022 21:02:06 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
05/22/2022 21:02:08 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=333
05/22/2022 21:02:11 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
05/22/2022 21:02:13 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.00 on epoch=336
05/22/2022 21:02:16 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=337
05/22/2022 21:02:17 - INFO - __main__ - Global step 2700 Train loss 0.01 Classification-F1 0.5743813427010147 on epoch=337
05/22/2022 21:02:20 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=338
05/22/2022 21:02:22 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.00 on epoch=339
05/22/2022 21:02:25 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
05/22/2022 21:02:27 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
05/22/2022 21:02:30 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=343
05/22/2022 21:02:32 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6981537727505469 on epoch=343
05/22/2022 21:02:34 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 21:02:37 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
05/22/2022 21:02:39 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
05/22/2022 21:02:42 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.05 on epoch=348
05/22/2022 21:02:44 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 21:02:46 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7290419374077449 on epoch=349
05/22/2022 21:02:48 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=351
05/22/2022 21:02:51 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.00 on epoch=352
05/22/2022 21:02:53 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
05/22/2022 21:02:56 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
05/22/2022 21:02:58 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 21:03:00 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.5743638398287355 on epoch=356
05/22/2022 21:03:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
05/22/2022 21:03:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
05/22/2022 21:03:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=359
05/22/2022 21:03:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 21:03:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
05/22/2022 21:03:14 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.6983005883005884 on epoch=362
05/22/2022 21:03:17 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
05/22/2022 21:03:19 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
05/22/2022 21:03:22 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 21:03:24 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=367
05/22/2022 21:03:27 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
05/22/2022 21:03:28 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.5675676865507373 on epoch=368
05/22/2022 21:03:31 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=369
05/22/2022 21:03:33 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 21:03:36 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=372
05/22/2022 21:03:38 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
05/22/2022 21:03:41 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
05/22/2022 21:03:42 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:03:42 - INFO - __main__ - Printing 3 examples
05/22/2022 21:03:42 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:03:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:03:42 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:03:42 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:03:42 - INFO - __main__ - Printing 3 examples
05/22/2022 21:03:42 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:03:42 - INFO - __main__ - ['happy']
05/22/2022 21:03:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:03:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:03:43 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:03:43 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.5678447700652371 on epoch=374
05/22/2022 21:03:43 - INFO - __main__ - save last model!
05/22/2022 21:03:43 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 21:03:43 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 21:03:43 - INFO - __main__ - Printing 3 examples
05/22/2022 21:03:43 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 21:03:43 - INFO - __main__ - ['others']
05/22/2022 21:03:43 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 21:03:43 - INFO - __main__ - ['others']
05/22/2022 21:03:43 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 21:03:43 - INFO - __main__ - ['others']
05/22/2022 21:03:43 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:03:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:03:50 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 21:04:01 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:04:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:04:02 - INFO - __main__ - Starting training!
05/22/2022 21:05:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_42_0.5_8_predictions.txt
05/22/2022 21:05:04 - INFO - __main__ - Classification-F1 on test data: 0.4457
05/22/2022 21:05:04 - INFO - __main__ - prefix=emo_32_42, lr=0.5, bsz=8, dev_performance=0.7499400517448097, test_performance=0.44573249096702294
05/22/2022 21:05:04 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.4, bsz=8 ...
05/22/2022 21:05:05 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:05:05 - INFO - __main__ - Printing 3 examples
05/22/2022 21:05:05 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:05:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:05:05 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:05:05 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:05:05 - INFO - __main__ - Printing 3 examples
05/22/2022 21:05:05 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:05:05 - INFO - __main__ - ['happy']
05/22/2022 21:05:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:05:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:05:05 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:05:21 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:05:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:05:21 - INFO - __main__ - Starting training!
05/22/2022 21:05:24 - INFO - __main__ - Step 10 Global step 10 Train loss 4.28 on epoch=1
05/22/2022 21:05:27 - INFO - __main__ - Step 20 Global step 20 Train loss 2.88 on epoch=2
05/22/2022 21:05:29 - INFO - __main__ - Step 30 Global step 30 Train loss 2.35 on epoch=3
05/22/2022 21:05:32 - INFO - __main__ - Step 40 Global step 40 Train loss 2.01 on epoch=4
05/22/2022 21:05:34 - INFO - __main__ - Step 50 Global step 50 Train loss 1.69 on epoch=6
05/22/2022 21:05:36 - INFO - __main__ - Global step 50 Train loss 2.64 Classification-F1 0.25315939383883634 on epoch=6
05/22/2022 21:05:36 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.25315939383883634 on epoch=6, global_step=50
05/22/2022 21:05:38 - INFO - __main__ - Step 60 Global step 60 Train loss 1.37 on epoch=7
05/22/2022 21:05:41 - INFO - __main__ - Step 70 Global step 70 Train loss 0.97 on epoch=8
05/22/2022 21:05:43 - INFO - __main__ - Step 80 Global step 80 Train loss 0.93 on epoch=9
05/22/2022 21:05:46 - INFO - __main__ - Step 90 Global step 90 Train loss 0.78 on epoch=11
05/22/2022 21:05:48 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=12
05/22/2022 21:05:50 - INFO - __main__ - Global step 100 Train loss 1.01 Classification-F1 0.4723859240719024 on epoch=12
05/22/2022 21:05:50 - INFO - __main__ - Saving model with best Classification-F1: 0.25315939383883634 -> 0.4723859240719024 on epoch=12, global_step=100
05/22/2022 21:05:52 - INFO - __main__ - Step 110 Global step 110 Train loss 0.62 on epoch=13
05/22/2022 21:05:55 - INFO - __main__ - Step 120 Global step 120 Train loss 0.69 on epoch=14
05/22/2022 21:05:57 - INFO - __main__ - Step 130 Global step 130 Train loss 0.76 on epoch=16
05/22/2022 21:05:59 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=17
05/22/2022 21:06:02 - INFO - __main__ - Step 150 Global step 150 Train loss 0.69 on epoch=18
05/22/2022 21:06:03 - INFO - __main__ - Global step 150 Train loss 0.70 Classification-F1 0.5003351153894393 on epoch=18
05/22/2022 21:06:03 - INFO - __main__ - Saving model with best Classification-F1: 0.4723859240719024 -> 0.5003351153894393 on epoch=18, global_step=150
05/22/2022 21:06:06 - INFO - __main__ - Step 160 Global step 160 Train loss 0.60 on epoch=19
05/22/2022 21:06:08 - INFO - __main__ - Step 170 Global step 170 Train loss 0.58 on epoch=21
05/22/2022 21:06:11 - INFO - __main__ - Step 180 Global step 180 Train loss 0.63 on epoch=22
05/22/2022 21:06:13 - INFO - __main__ - Step 190 Global step 190 Train loss 0.62 on epoch=23
05/22/2022 21:06:16 - INFO - __main__ - Step 200 Global step 200 Train loss 0.53 on epoch=24
05/22/2022 21:06:17 - INFO - __main__ - Global step 200 Train loss 0.59 Classification-F1 0.5889662882696939 on epoch=24
05/22/2022 21:06:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5003351153894393 -> 0.5889662882696939 on epoch=24, global_step=200
05/22/2022 21:06:20 - INFO - __main__ - Step 210 Global step 210 Train loss 0.61 on epoch=26
05/22/2022 21:06:22 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=27
05/22/2022 21:06:25 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=28
05/22/2022 21:06:27 - INFO - __main__ - Step 240 Global step 240 Train loss 0.49 on epoch=29
05/22/2022 21:06:30 - INFO - __main__ - Step 250 Global step 250 Train loss 0.46 on epoch=31
05/22/2022 21:06:31 - INFO - __main__ - Global step 250 Train loss 0.55 Classification-F1 0.5783730158730158 on epoch=31
05/22/2022 21:06:34 - INFO - __main__ - Step 260 Global step 260 Train loss 0.44 on epoch=32
05/22/2022 21:06:36 - INFO - __main__ - Step 270 Global step 270 Train loss 0.48 on epoch=33
05/22/2022 21:06:39 - INFO - __main__ - Step 280 Global step 280 Train loss 0.42 on epoch=34
05/22/2022 21:06:41 - INFO - __main__ - Step 290 Global step 290 Train loss 0.45 on epoch=36
05/22/2022 21:06:44 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=37
05/22/2022 21:06:46 - INFO - __main__ - Global step 300 Train loss 0.44 Classification-F1 0.617363184079602 on epoch=37
05/22/2022 21:06:46 - INFO - __main__ - Saving model with best Classification-F1: 0.5889662882696939 -> 0.617363184079602 on epoch=37, global_step=300
05/22/2022 21:06:48 - INFO - __main__ - Step 310 Global step 310 Train loss 0.54 on epoch=38
05/22/2022 21:06:51 - INFO - __main__ - Step 320 Global step 320 Train loss 0.40 on epoch=39
05/22/2022 21:06:53 - INFO - __main__ - Step 330 Global step 330 Train loss 0.42 on epoch=41
05/22/2022 21:06:56 - INFO - __main__ - Step 340 Global step 340 Train loss 0.38 on epoch=42
05/22/2022 21:06:58 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=43
05/22/2022 21:07:00 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.5874504366126138 on epoch=43
05/22/2022 21:07:02 - INFO - __main__ - Step 360 Global step 360 Train loss 0.43 on epoch=44
05/22/2022 21:07:05 - INFO - __main__ - Step 370 Global step 370 Train loss 0.45 on epoch=46
05/22/2022 21:07:07 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=47
05/22/2022 21:07:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=48
05/22/2022 21:07:12 - INFO - __main__ - Step 400 Global step 400 Train loss 0.34 on epoch=49
05/22/2022 21:07:14 - INFO - __main__ - Global step 400 Train loss 0.38 Classification-F1 0.6224747474747474 on epoch=49
05/22/2022 21:07:14 - INFO - __main__ - Saving model with best Classification-F1: 0.617363184079602 -> 0.6224747474747474 on epoch=49, global_step=400
05/22/2022 21:07:16 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=51
05/22/2022 21:07:19 - INFO - __main__ - Step 420 Global step 420 Train loss 0.35 on epoch=52
05/22/2022 21:07:21 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=53
05/22/2022 21:07:24 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=54
05/22/2022 21:07:26 - INFO - __main__ - Step 450 Global step 450 Train loss 0.31 on epoch=56
05/22/2022 21:07:28 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.6898153492906437 on epoch=56
05/22/2022 21:07:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6224747474747474 -> 0.6898153492906437 on epoch=56, global_step=450
05/22/2022 21:07:31 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=57
05/22/2022 21:07:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=58
05/22/2022 21:07:36 - INFO - __main__ - Step 480 Global step 480 Train loss 0.26 on epoch=59
05/22/2022 21:07:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.23 on epoch=61
05/22/2022 21:07:41 - INFO - __main__ - Step 500 Global step 500 Train loss 0.27 on epoch=62
05/22/2022 21:07:42 - INFO - __main__ - Global step 500 Train loss 0.25 Classification-F1 0.6635830125575819 on epoch=62
05/22/2022 21:07:45 - INFO - __main__ - Step 510 Global step 510 Train loss 0.22 on epoch=63
05/22/2022 21:07:47 - INFO - __main__ - Step 520 Global step 520 Train loss 0.20 on epoch=64
05/22/2022 21:07:50 - INFO - __main__ - Step 530 Global step 530 Train loss 0.34 on epoch=66
05/22/2022 21:07:52 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=67
05/22/2022 21:07:55 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=68
05/22/2022 21:07:56 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.6706022766029004 on epoch=68
05/22/2022 21:07:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.18 on epoch=69
05/22/2022 21:08:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=71
05/22/2022 21:08:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=72
05/22/2022 21:08:06 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=73
05/22/2022 21:08:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.17 on epoch=74
05/22/2022 21:08:10 - INFO - __main__ - Global step 600 Train loss 0.21 Classification-F1 0.6797619047619048 on epoch=74
05/22/2022 21:08:13 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=76
05/22/2022 21:08:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=77
05/22/2022 21:08:18 - INFO - __main__ - Step 630 Global step 630 Train loss 0.17 on epoch=78
05/22/2022 21:08:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.24 on epoch=79
05/22/2022 21:08:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=81
05/22/2022 21:08:25 - INFO - __main__ - Global step 650 Train loss 0.20 Classification-F1 0.7252036808918051 on epoch=81
05/22/2022 21:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6898153492906437 -> 0.7252036808918051 on epoch=81, global_step=650
05/22/2022 21:08:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.11 on epoch=82
05/22/2022 21:08:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=83
05/22/2022 21:08:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.15 on epoch=84
05/22/2022 21:08:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.15 on epoch=86
05/22/2022 21:08:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=87
05/22/2022 21:08:39 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6924979596635866 on epoch=87
05/22/2022 21:08:41 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=88
05/22/2022 21:08:44 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=89
05/22/2022 21:08:46 - INFO - __main__ - Step 730 Global step 730 Train loss 0.11 on epoch=91
05/22/2022 21:08:49 - INFO - __main__ - Step 740 Global step 740 Train loss 0.11 on epoch=92
05/22/2022 21:08:51 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=93
05/22/2022 21:08:53 - INFO - __main__ - Global step 750 Train loss 0.15 Classification-F1 0.7197665135706024 on epoch=93
05/22/2022 21:08:56 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=94
05/22/2022 21:08:58 - INFO - __main__ - Step 770 Global step 770 Train loss 0.21 on epoch=96
05/22/2022 21:09:00 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=97
05/22/2022 21:09:03 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=98
05/22/2022 21:09:05 - INFO - __main__ - Step 800 Global step 800 Train loss 0.09 on epoch=99
05/22/2022 21:09:07 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6665945317616538 on epoch=99
05/22/2022 21:09:10 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=101
05/22/2022 21:09:12 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=102
05/22/2022 21:09:15 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=103
05/22/2022 21:09:17 - INFO - __main__ - Step 840 Global step 840 Train loss 0.06 on epoch=104
05/22/2022 21:09:20 - INFO - __main__ - Step 850 Global step 850 Train loss 0.14 on epoch=106
05/22/2022 21:09:21 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.7013943308976667 on epoch=106
05/22/2022 21:09:24 - INFO - __main__ - Step 860 Global step 860 Train loss 0.09 on epoch=107
05/22/2022 21:09:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.06 on epoch=108
05/22/2022 21:09:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.09 on epoch=109
05/22/2022 21:09:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=111
05/22/2022 21:09:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=112
05/22/2022 21:09:36 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.683139371257313 on epoch=112
05/22/2022 21:09:38 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=113
05/22/2022 21:09:41 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=114
05/22/2022 21:09:43 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=116
05/22/2022 21:09:46 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=117
05/22/2022 21:09:48 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=118
05/22/2022 21:09:50 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7190336545175255 on epoch=118
05/22/2022 21:09:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=119
05/22/2022 21:09:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=121
05/22/2022 21:09:57 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=122
05/22/2022 21:10:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=123
05/22/2022 21:10:02 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=124
05/22/2022 21:10:04 - INFO - __main__ - Global step 1000 Train loss 0.10 Classification-F1 0.69986772971652 on epoch=124
05/22/2022 21:10:06 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=126
05/22/2022 21:10:09 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=127
05/22/2022 21:10:11 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.06 on epoch=128
05/22/2022 21:10:14 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=129
05/22/2022 21:10:16 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=131
05/22/2022 21:10:18 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.7005596004267259 on epoch=131
05/22/2022 21:10:21 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=132
05/22/2022 21:10:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=133
05/22/2022 21:10:26 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=134
05/22/2022 21:10:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=136
05/22/2022 21:10:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.05 on epoch=137
05/22/2022 21:10:32 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.7019336219336219 on epoch=137
05/22/2022 21:10:35 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.06 on epoch=138
05/22/2022 21:10:37 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=139
05/22/2022 21:10:40 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.03 on epoch=141
05/22/2022 21:10:42 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.05 on epoch=142
05/22/2022 21:10:45 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=143
05/22/2022 21:10:47 - INFO - __main__ - Global step 1150 Train loss 0.05 Classification-F1 0.6699927431059506 on epoch=143
05/22/2022 21:10:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=144
05/22/2022 21:10:52 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=146
05/22/2022 21:10:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=147
05/22/2022 21:10:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.11 on epoch=148
05/22/2022 21:10:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.16 on epoch=149
05/22/2022 21:11:01 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7398172588258919 on epoch=149
05/22/2022 21:11:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7252036808918051 -> 0.7398172588258919 on epoch=149, global_step=1200
05/22/2022 21:11:03 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.12 on epoch=151
05/22/2022 21:11:06 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=152
05/22/2022 21:11:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=153
05/22/2022 21:11:11 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=154
05/22/2022 21:11:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.06 on epoch=156
05/22/2022 21:11:15 - INFO - __main__ - Global step 1250 Train loss 0.07 Classification-F1 0.719796844060078 on epoch=156
05/22/2022 21:11:18 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.03 on epoch=157
05/22/2022 21:11:20 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=158
05/22/2022 21:11:23 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=159
05/22/2022 21:11:25 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=161
05/22/2022 21:11:28 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=162
05/22/2022 21:11:29 - INFO - __main__ - Global step 1300 Train loss 0.04 Classification-F1 0.7123833966793843 on epoch=162
05/22/2022 21:11:32 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=163
05/22/2022 21:11:34 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.02 on epoch=164
05/22/2022 21:11:37 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=166
05/22/2022 21:11:39 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=167
05/22/2022 21:11:42 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=168
05/22/2022 21:11:43 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.6690616572969513 on epoch=168
05/22/2022 21:11:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.03 on epoch=169
05/22/2022 21:11:48 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.09 on epoch=171
05/22/2022 21:11:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=172
05/22/2022 21:11:53 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=173
05/22/2022 21:11:56 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=174
05/22/2022 21:11:58 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.6876778168624588 on epoch=174
05/22/2022 21:12:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.02 on epoch=176
05/22/2022 21:12:02 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=177
05/22/2022 21:12:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.02 on epoch=178
05/22/2022 21:12:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=179
05/22/2022 21:12:10 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=181
05/22/2022 21:12:12 - INFO - __main__ - Global step 1450 Train loss 0.03 Classification-F1 0.5837185833890863 on epoch=181
05/22/2022 21:12:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=182
05/22/2022 21:12:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=183
05/22/2022 21:12:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=184
05/22/2022 21:12:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=186
05/22/2022 21:12:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.02 on epoch=187
05/22/2022 21:12:26 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5752299094510469 on epoch=187
05/22/2022 21:12:28 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.01 on epoch=188
05/22/2022 21:12:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=189
05/22/2022 21:12:33 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
05/22/2022 21:12:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=192
05/22/2022 21:12:38 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=193
05/22/2022 21:12:40 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7031273920174959 on epoch=193
05/22/2022 21:12:43 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.08 on epoch=194
05/22/2022 21:12:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=196
05/22/2022 21:12:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=197
05/22/2022 21:12:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
05/22/2022 21:12:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=199
05/22/2022 21:12:54 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.5625285388127853 on epoch=199
05/22/2022 21:12:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.02 on epoch=201
05/22/2022 21:12:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=202
05/22/2022 21:13:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=203
05/22/2022 21:13:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=204
05/22/2022 21:13:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=206
05/22/2022 21:13:09 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6694542723829652 on epoch=206
05/22/2022 21:13:11 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=207
05/22/2022 21:13:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
05/22/2022 21:13:16 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=209
05/22/2022 21:13:19 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=211
05/22/2022 21:13:21 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=212
05/22/2022 21:13:23 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.6462070073931212 on epoch=212
05/22/2022 21:13:25 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
05/22/2022 21:13:28 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=214
05/22/2022 21:13:30 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=216
05/22/2022 21:13:33 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.01 on epoch=217
05/22/2022 21:13:35 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
05/22/2022 21:13:37 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.5990378437155048 on epoch=218
05/22/2022 21:13:40 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
05/22/2022 21:13:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
05/22/2022 21:13:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.06 on epoch=222
05/22/2022 21:13:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=223
05/22/2022 21:13:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.01 on epoch=224
05/22/2022 21:13:51 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7320524984187223 on epoch=224
05/22/2022 21:13:54 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
05/22/2022 21:13:56 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=227
05/22/2022 21:13:59 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=228
05/22/2022 21:14:01 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=229
05/22/2022 21:14:04 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
05/22/2022 21:14:05 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7013196480938416 on epoch=231
05/22/2022 21:14:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=232
05/22/2022 21:14:10 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=233
05/22/2022 21:14:13 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=234
05/22/2022 21:14:15 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=236
05/22/2022 21:14:18 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=237
05/22/2022 21:14:19 - INFO - __main__ - Global step 1900 Train loss 0.05 Classification-F1 0.7275008775008776 on epoch=237
05/22/2022 21:14:22 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.01 on epoch=238
05/22/2022 21:14:24 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.05 on epoch=239
05/22/2022 21:14:27 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=241
05/22/2022 21:14:29 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
05/22/2022 21:14:32 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
05/22/2022 21:14:33 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.5510470085470085 on epoch=243
05/22/2022 21:14:36 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=244
05/22/2022 21:14:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.10 on epoch=246
05/22/2022 21:14:41 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=247
05/22/2022 21:14:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
05/22/2022 21:14:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.01 on epoch=249
05/22/2022 21:14:47 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7263095182919292 on epoch=249
05/22/2022 21:14:50 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=251
05/22/2022 21:14:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.00 on epoch=252
05/22/2022 21:14:54 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=253
05/22/2022 21:14:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=254
05/22/2022 21:14:59 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
05/22/2022 21:15:01 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.7191775209602036 on epoch=256
05/22/2022 21:15:03 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
05/22/2022 21:15:06 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=258
05/22/2022 21:15:08 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
05/22/2022 21:15:11 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=261
05/22/2022 21:15:13 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
05/22/2022 21:15:15 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.7113062803586998 on epoch=262
05/22/2022 21:15:17 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
05/22/2022 21:15:20 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=264
05/22/2022 21:15:22 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
05/22/2022 21:15:25 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=267
05/22/2022 21:15:27 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
05/22/2022 21:15:29 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.7613331646850493 on epoch=268
05/22/2022 21:15:29 - INFO - __main__ - Saving model with best Classification-F1: 0.7398172588258919 -> 0.7613331646850493 on epoch=268, global_step=2150
05/22/2022 21:15:31 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
05/22/2022 21:15:34 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.06 on epoch=271
05/22/2022 21:15:36 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
05/22/2022 21:15:39 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 21:15:41 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=274
05/22/2022 21:15:43 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7538027222679787 on epoch=274
05/22/2022 21:15:45 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=276
05/22/2022 21:15:48 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=277
05/22/2022 21:15:50 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
05/22/2022 21:15:53 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=279
05/22/2022 21:15:55 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.00 on epoch=281
05/22/2022 21:15:57 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.6122793148880105 on epoch=281
05/22/2022 21:15:59 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.00 on epoch=282
05/22/2022 21:16:02 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
05/22/2022 21:16:04 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 21:16:06 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.00 on epoch=286
05/22/2022 21:16:09 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.00 on epoch=287
05/22/2022 21:16:11 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.717857142857143 on epoch=287
05/22/2022 21:16:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=288
05/22/2022 21:16:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
05/22/2022 21:16:18 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
05/22/2022 21:16:20 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
05/22/2022 21:16:23 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=293
05/22/2022 21:16:24 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6054976641974946 on epoch=293
05/22/2022 21:16:27 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
05/22/2022 21:16:29 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=296
05/22/2022 21:16:32 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=297
05/22/2022 21:16:34 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=298
05/22/2022 21:16:37 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=299
05/22/2022 21:16:39 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.755033416875522 on epoch=299
05/22/2022 21:16:41 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=301
05/22/2022 21:16:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=302
05/22/2022 21:16:46 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
05/22/2022 21:16:48 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.00 on epoch=304
05/22/2022 21:16:51 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 21:16:53 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7394013472403304 on epoch=306
05/22/2022 21:16:55 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=307
05/22/2022 21:16:57 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
05/22/2022 21:17:00 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=309
05/22/2022 21:17:02 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=311
05/22/2022 21:17:05 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=312
05/22/2022 21:17:06 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7254757259128237 on epoch=312
05/22/2022 21:17:09 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
05/22/2022 21:17:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 21:17:14 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
05/22/2022 21:17:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=317
05/22/2022 21:17:19 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=318
05/22/2022 21:17:20 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.7684177705868473 on epoch=318
05/22/2022 21:17:20 - INFO - __main__ - Saving model with best Classification-F1: 0.7613331646850493 -> 0.7684177705868473 on epoch=318, global_step=2550
05/22/2022 21:17:23 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
05/22/2022 21:17:25 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 21:17:28 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
05/22/2022 21:17:30 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
05/22/2022 21:17:32 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
05/22/2022 21:17:34 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.5998500167782786 on epoch=324
05/22/2022 21:17:37 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
05/22/2022 21:17:39 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.15 on epoch=327
05/22/2022 21:17:41 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=328
05/22/2022 21:17:44 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
05/22/2022 21:17:46 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=331
05/22/2022 21:17:48 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7088906682656682 on epoch=331
05/22/2022 21:17:51 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.00 on epoch=332
05/22/2022 21:17:53 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 21:17:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=334
05/22/2022 21:17:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=336
05/22/2022 21:18:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
05/22/2022 21:18:02 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6958204105745089 on epoch=337
05/22/2022 21:18:04 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.00 on epoch=338
05/22/2022 21:18:07 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 21:18:09 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=341
05/22/2022 21:18:12 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 21:18:14 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=343
05/22/2022 21:18:16 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7240425655679892 on epoch=343
05/22/2022 21:18:18 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 21:18:21 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=346
05/22/2022 21:18:23 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
05/22/2022 21:18:25 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
05/22/2022 21:18:28 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 21:18:30 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7474321208069088 on epoch=349
05/22/2022 21:18:32 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
05/22/2022 21:18:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=352
05/22/2022 21:18:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
05/22/2022 21:18:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=354
05/22/2022 21:18:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 21:18:43 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.6068125509977005 on epoch=356
05/22/2022 21:18:46 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
05/22/2022 21:18:48 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
05/22/2022 21:18:51 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 21:18:53 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 21:18:56 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
05/22/2022 21:18:57 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7186847326649959 on epoch=362
05/22/2022 21:19:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
05/22/2022 21:19:02 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
05/22/2022 21:19:05 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 21:19:07 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
05/22/2022 21:19:09 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=368
05/22/2022 21:19:11 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7556121565458325 on epoch=368
05/22/2022 21:19:14 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=369
05/22/2022 21:19:16 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 21:19:18 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
05/22/2022 21:19:21 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
05/22/2022 21:19:23 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
05/22/2022 21:19:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:19:25 - INFO - __main__ - Printing 3 examples
05/22/2022 21:19:25 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:19:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:19:25 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:19:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:19:25 - INFO - __main__ - Printing 3 examples
05/22/2022 21:19:25 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:19:25 - INFO - __main__ - ['happy']
05/22/2022 21:19:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:19:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:19:25 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:19:25 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7610586361579545 on epoch=374
05/22/2022 21:19:25 - INFO - __main__ - save last model!
05/22/2022 21:19:25 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 21:19:25 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 21:19:25 - INFO - __main__ - Printing 3 examples
05/22/2022 21:19:25 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 21:19:25 - INFO - __main__ - ['others']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 21:19:25 - INFO - __main__ - ['others']
05/22/2022 21:19:25 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 21:19:25 - INFO - __main__ - ['others']
05/22/2022 21:19:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:19:27 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:19:33 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 21:19:41 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:19:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:19:41 - INFO - __main__ - Starting training!
05/22/2022 21:20:50 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_42_0.4_8_predictions.txt
05/22/2022 21:20:50 - INFO - __main__ - Classification-F1 on test data: 0.3067
05/22/2022 21:20:51 - INFO - __main__ - prefix=emo_32_42, lr=0.4, bsz=8, dev_performance=0.7684177705868473, test_performance=0.30672815566859885
05/22/2022 21:20:51 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.3, bsz=8 ...
05/22/2022 21:20:52 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:20:52 - INFO - __main__ - Printing 3 examples
05/22/2022 21:20:52 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:20:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:20:52 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:20:52 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:20:52 - INFO - __main__ - Printing 3 examples
05/22/2022 21:20:52 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:20:52 - INFO - __main__ - ['happy']
05/22/2022 21:20:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:20:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:20:52 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:21:07 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:21:08 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:21:08 - INFO - __main__ - Starting training!
05/22/2022 21:21:11 - INFO - __main__ - Step 10 Global step 10 Train loss 4.37 on epoch=1
05/22/2022 21:21:13 - INFO - __main__ - Step 20 Global step 20 Train loss 3.10 on epoch=2
05/22/2022 21:21:16 - INFO - __main__ - Step 30 Global step 30 Train loss 2.45 on epoch=3
05/22/2022 21:21:18 - INFO - __main__ - Step 40 Global step 40 Train loss 2.25 on epoch=4
05/22/2022 21:21:21 - INFO - __main__ - Step 50 Global step 50 Train loss 1.96 on epoch=6
05/22/2022 21:21:23 - INFO - __main__ - Global step 50 Train loss 2.82 Classification-F1 0.09559996247302749 on epoch=6
05/22/2022 21:21:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.09559996247302749 on epoch=6, global_step=50
05/22/2022 21:21:25 - INFO - __main__ - Step 60 Global step 60 Train loss 1.80 on epoch=7
05/22/2022 21:21:27 - INFO - __main__ - Step 70 Global step 70 Train loss 1.46 on epoch=8
05/22/2022 21:21:30 - INFO - __main__ - Step 80 Global step 80 Train loss 1.43 on epoch=9
05/22/2022 21:21:32 - INFO - __main__ - Step 90 Global step 90 Train loss 1.26 on epoch=11
05/22/2022 21:21:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.02 on epoch=12
05/22/2022 21:21:36 - INFO - __main__ - Global step 100 Train loss 1.39 Classification-F1 0.4837153087679034 on epoch=12
05/22/2022 21:21:36 - INFO - __main__ - Saving model with best Classification-F1: 0.09559996247302749 -> 0.4837153087679034 on epoch=12, global_step=100
05/22/2022 21:21:39 - INFO - __main__ - Step 110 Global step 110 Train loss 0.81 on epoch=13
05/22/2022 21:21:41 - INFO - __main__ - Step 120 Global step 120 Train loss 0.93 on epoch=14
05/22/2022 21:21:43 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=16
05/22/2022 21:21:46 - INFO - __main__ - Step 140 Global step 140 Train loss 0.80 on epoch=17
05/22/2022 21:21:48 - INFO - __main__ - Step 150 Global step 150 Train loss 0.76 on epoch=18
05/22/2022 21:21:50 - INFO - __main__ - Global step 150 Train loss 0.83 Classification-F1 0.4922770323772414 on epoch=18
05/22/2022 21:21:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4837153087679034 -> 0.4922770323772414 on epoch=18, global_step=150
05/22/2022 21:21:52 - INFO - __main__ - Step 160 Global step 160 Train loss 0.82 on epoch=19
05/22/2022 21:21:55 - INFO - __main__ - Step 170 Global step 170 Train loss 0.70 on epoch=21
05/22/2022 21:21:57 - INFO - __main__ - Step 180 Global step 180 Train loss 0.69 on epoch=22
05/22/2022 21:22:00 - INFO - __main__ - Step 190 Global step 190 Train loss 0.66 on epoch=23
05/22/2022 21:22:02 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=24
05/22/2022 21:22:04 - INFO - __main__ - Global step 200 Train loss 0.71 Classification-F1 0.5550424243169869 on epoch=24
05/22/2022 21:22:04 - INFO - __main__ - Saving model with best Classification-F1: 0.4922770323772414 -> 0.5550424243169869 on epoch=24, global_step=200
05/22/2022 21:22:06 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=26
05/22/2022 21:22:09 - INFO - __main__ - Step 220 Global step 220 Train loss 0.68 on epoch=27
05/22/2022 21:22:11 - INFO - __main__ - Step 230 Global step 230 Train loss 0.60 on epoch=28
05/22/2022 21:22:13 - INFO - __main__ - Step 240 Global step 240 Train loss 0.62 on epoch=29
05/22/2022 21:22:16 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=31
05/22/2022 21:22:17 - INFO - __main__ - Global step 250 Train loss 0.64 Classification-F1 0.5592203548085901 on epoch=31
05/22/2022 21:22:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5550424243169869 -> 0.5592203548085901 on epoch=31, global_step=250
05/22/2022 21:22:20 - INFO - __main__ - Step 260 Global step 260 Train loss 0.56 on epoch=32
05/22/2022 21:22:22 - INFO - __main__ - Step 270 Global step 270 Train loss 0.47 on epoch=33
05/22/2022 21:22:25 - INFO - __main__ - Step 280 Global step 280 Train loss 0.51 on epoch=34
05/22/2022 21:22:27 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=36
05/22/2022 21:22:29 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=37
05/22/2022 21:22:31 - INFO - __main__ - Global step 300 Train loss 0.51 Classification-F1 0.5622597717831941 on epoch=37
05/22/2022 21:22:31 - INFO - __main__ - Saving model with best Classification-F1: 0.5592203548085901 -> 0.5622597717831941 on epoch=37, global_step=300
05/22/2022 21:22:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=38
05/22/2022 21:22:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.48 on epoch=39
05/22/2022 21:22:38 - INFO - __main__ - Step 330 Global step 330 Train loss 0.53 on epoch=41
05/22/2022 21:22:41 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=42
05/22/2022 21:22:43 - INFO - __main__ - Step 350 Global step 350 Train loss 0.42 on epoch=43
05/22/2022 21:22:45 - INFO - __main__ - Global step 350 Train loss 0.50 Classification-F1 0.577201262352202 on epoch=43
05/22/2022 21:22:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5622597717831941 -> 0.577201262352202 on epoch=43, global_step=350
05/22/2022 21:22:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=44
05/22/2022 21:22:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.42 on epoch=46
05/22/2022 21:22:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=47
05/22/2022 21:22:54 - INFO - __main__ - Step 390 Global step 390 Train loss 0.42 on epoch=48
05/22/2022 21:22:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=49
05/22/2022 21:22:59 - INFO - __main__ - Global step 400 Train loss 0.44 Classification-F1 0.6178550576827853 on epoch=49
05/22/2022 21:22:59 - INFO - __main__ - Saving model with best Classification-F1: 0.577201262352202 -> 0.6178550576827853 on epoch=49, global_step=400
05/22/2022 21:23:01 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=51
05/22/2022 21:23:03 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=52
05/22/2022 21:23:06 - INFO - __main__ - Step 430 Global step 430 Train loss 0.40 on epoch=53
05/22/2022 21:23:08 - INFO - __main__ - Step 440 Global step 440 Train loss 0.44 on epoch=54
05/22/2022 21:23:10 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=56
05/22/2022 21:23:12 - INFO - __main__ - Global step 450 Train loss 0.39 Classification-F1 0.6155160510390898 on epoch=56
05/22/2022 21:23:15 - INFO - __main__ - Step 460 Global step 460 Train loss 0.42 on epoch=57
05/22/2022 21:23:17 - INFO - __main__ - Step 470 Global step 470 Train loss 0.41 on epoch=58
05/22/2022 21:23:19 - INFO - __main__ - Step 480 Global step 480 Train loss 0.39 on epoch=59
05/22/2022 21:23:22 - INFO - __main__ - Step 490 Global step 490 Train loss 0.30 on epoch=61
05/22/2022 21:23:24 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=62
05/22/2022 21:23:26 - INFO - __main__ - Global step 500 Train loss 0.37 Classification-F1 0.6275710755219989 on epoch=62
05/22/2022 21:23:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6178550576827853 -> 0.6275710755219989 on epoch=62, global_step=500
05/22/2022 21:23:28 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=63
05/22/2022 21:23:31 - INFO - __main__ - Step 520 Global step 520 Train loss 0.30 on epoch=64
05/22/2022 21:23:33 - INFO - __main__ - Step 530 Global step 530 Train loss 0.29 on epoch=66
05/22/2022 21:23:35 - INFO - __main__ - Step 540 Global step 540 Train loss 0.33 on epoch=67
05/22/2022 21:23:38 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=68
05/22/2022 21:23:40 - INFO - __main__ - Global step 550 Train loss 0.30 Classification-F1 0.6456349206349207 on epoch=68
05/22/2022 21:23:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6275710755219989 -> 0.6456349206349207 on epoch=68, global_step=550
05/22/2022 21:23:42 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=69
05/22/2022 21:23:44 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=71
05/22/2022 21:23:47 - INFO - __main__ - Step 580 Global step 580 Train loss 0.30 on epoch=72
05/22/2022 21:23:49 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=73
05/22/2022 21:23:52 - INFO - __main__ - Step 600 Global step 600 Train loss 0.30 on epoch=74
05/22/2022 21:23:53 - INFO - __main__ - Global step 600 Train loss 0.30 Classification-F1 0.6980495719414526 on epoch=74
05/22/2022 21:23:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6456349206349207 -> 0.6980495719414526 on epoch=74, global_step=600
05/22/2022 21:23:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.19 on epoch=76
05/22/2022 21:23:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.24 on epoch=77
05/22/2022 21:24:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.25 on epoch=78
05/22/2022 21:24:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=79
05/22/2022 21:24:05 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=81
05/22/2022 21:24:07 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.674164296233533 on epoch=81
05/22/2022 21:24:09 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=82
05/22/2022 21:24:12 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=83
05/22/2022 21:24:14 - INFO - __main__ - Step 680 Global step 680 Train loss 0.26 on epoch=84
05/22/2022 21:24:17 - INFO - __main__ - Step 690 Global step 690 Train loss 0.32 on epoch=86
05/22/2022 21:24:19 - INFO - __main__ - Step 700 Global step 700 Train loss 0.42 on epoch=87
05/22/2022 21:24:21 - INFO - __main__ - Global step 700 Train loss 0.29 Classification-F1 0.7016177637179785 on epoch=87
05/22/2022 21:24:21 - INFO - __main__ - Saving model with best Classification-F1: 0.6980495719414526 -> 0.7016177637179785 on epoch=87, global_step=700
05/22/2022 21:24:23 - INFO - __main__ - Step 710 Global step 710 Train loss 0.30 on epoch=88
05/22/2022 21:24:26 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=89
05/22/2022 21:24:28 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=91
05/22/2022 21:24:30 - INFO - __main__ - Step 740 Global step 740 Train loss 0.24 on epoch=92
05/22/2022 21:24:33 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=93
05/22/2022 21:24:35 - INFO - __main__ - Global step 750 Train loss 0.24 Classification-F1 0.7052525252525252 on epoch=93
05/22/2022 21:24:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7016177637179785 -> 0.7052525252525252 on epoch=93, global_step=750
05/22/2022 21:24:37 - INFO - __main__ - Step 760 Global step 760 Train loss 0.27 on epoch=94
05/22/2022 21:24:39 - INFO - __main__ - Step 770 Global step 770 Train loss 0.22 on epoch=96
05/22/2022 21:24:42 - INFO - __main__ - Step 780 Global step 780 Train loss 0.21 on epoch=97
05/22/2022 21:24:44 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=98
05/22/2022 21:24:47 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=99
05/22/2022 21:24:49 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.6958844435950321 on epoch=99
05/22/2022 21:24:51 - INFO - __main__ - Step 810 Global step 810 Train loss 0.21 on epoch=101
05/22/2022 21:24:54 - INFO - __main__ - Step 820 Global step 820 Train loss 0.17 on epoch=102
05/22/2022 21:24:56 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=103
05/22/2022 21:24:58 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=104
05/22/2022 21:25:01 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=106
05/22/2022 21:25:03 - INFO - __main__ - Global step 850 Train loss 0.17 Classification-F1 0.7105392847085328 on epoch=106
05/22/2022 21:25:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7052525252525252 -> 0.7105392847085328 on epoch=106, global_step=850
05/22/2022 21:25:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=107
05/22/2022 21:25:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.13 on epoch=108
05/22/2022 21:25:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.24 on epoch=109
05/22/2022 21:25:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=111
05/22/2022 21:25:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=112
05/22/2022 21:25:17 - INFO - __main__ - Global step 900 Train loss 0.18 Classification-F1 0.6895968909577781 on epoch=112
05/22/2022 21:25:19 - INFO - __main__ - Step 910 Global step 910 Train loss 0.17 on epoch=113
05/22/2022 21:25:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.18 on epoch=114
05/22/2022 21:25:24 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=116
05/22/2022 21:25:27 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=117
05/22/2022 21:25:29 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=118
05/22/2022 21:25:31 - INFO - __main__ - Global step 950 Train loss 0.19 Classification-F1 0.6829136389160904 on epoch=118
05/22/2022 21:25:33 - INFO - __main__ - Step 960 Global step 960 Train loss 0.17 on epoch=119
05/22/2022 21:25:36 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=121
05/22/2022 21:25:38 - INFO - __main__ - Step 980 Global step 980 Train loss 0.17 on epoch=122
05/22/2022 21:25:41 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=123
05/22/2022 21:25:43 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=124
05/22/2022 21:25:45 - INFO - __main__ - Global step 1000 Train loss 0.15 Classification-F1 0.6656258054789591 on epoch=124
05/22/2022 21:25:48 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=126
05/22/2022 21:25:50 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=127
05/22/2022 21:25:53 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=128
05/22/2022 21:25:55 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=129
05/22/2022 21:25:58 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=131
05/22/2022 21:25:59 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.7087820512820513 on epoch=131
05/22/2022 21:26:02 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=132
05/22/2022 21:26:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=133
05/22/2022 21:26:07 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=134
05/22/2022 21:26:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.14 on epoch=136
05/22/2022 21:26:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.13 on epoch=137
05/22/2022 21:26:13 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6465042166495032 on epoch=137
05/22/2022 21:26:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=138
05/22/2022 21:26:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=139
05/22/2022 21:26:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=141
05/22/2022 21:26:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=142
05/22/2022 21:26:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=143
05/22/2022 21:26:28 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.6479119740278967 on epoch=143
05/22/2022 21:26:30 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.05 on epoch=144
05/22/2022 21:26:32 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.17 on epoch=146
05/22/2022 21:26:35 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=147
05/22/2022 21:26:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.12 on epoch=148
05/22/2022 21:26:40 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=149
05/22/2022 21:26:42 - INFO - __main__ - Global step 1200 Train loss 0.12 Classification-F1 0.7299615863706674 on epoch=149
05/22/2022 21:26:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7105392847085328 -> 0.7299615863706674 on epoch=149, global_step=1200
05/22/2022 21:26:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=151
05/22/2022 21:26:47 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=152
05/22/2022 21:26:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.15 on epoch=153
05/22/2022 21:26:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=154
05/22/2022 21:26:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.13 on epoch=156
05/22/2022 21:26:56 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.7131284611694938 on epoch=156
05/22/2022 21:26:58 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=157
05/22/2022 21:27:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=158
05/22/2022 21:27:03 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.11 on epoch=159
05/22/2022 21:27:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=161
05/22/2022 21:27:08 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=162
05/22/2022 21:27:10 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.7147642717159965 on epoch=162
05/22/2022 21:27:12 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=163
05/22/2022 21:27:15 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=164
05/22/2022 21:27:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=166
05/22/2022 21:27:20 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.07 on epoch=167
05/22/2022 21:27:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=168
05/22/2022 21:27:24 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7259000981226651 on epoch=168
05/22/2022 21:27:27 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=169
05/22/2022 21:27:29 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=171
05/22/2022 21:27:31 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=172
05/22/2022 21:27:34 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=173
05/22/2022 21:27:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=174
05/22/2022 21:27:38 - INFO - __main__ - Global step 1400 Train loss 0.09 Classification-F1 0.7405123665135839 on epoch=174
05/22/2022 21:27:38 - INFO - __main__ - Saving model with best Classification-F1: 0.7299615863706674 -> 0.7405123665135839 on epoch=174, global_step=1400
05/22/2022 21:27:41 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
05/22/2022 21:27:43 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=177
05/22/2022 21:27:46 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.13 on epoch=178
05/22/2022 21:27:48 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.13 on epoch=179
05/22/2022 21:27:51 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=181
05/22/2022 21:27:52 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.72495537990821 on epoch=181
05/22/2022 21:27:55 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.20 on epoch=182
05/22/2022 21:27:57 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=183
05/22/2022 21:28:00 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=184
05/22/2022 21:28:02 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=186
05/22/2022 21:28:05 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=187
05/22/2022 21:28:06 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.7432417582417583 on epoch=187
05/22/2022 21:28:06 - INFO - __main__ - Saving model with best Classification-F1: 0.7405123665135839 -> 0.7432417582417583 on epoch=187, global_step=1500
05/22/2022 21:28:09 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=188
05/22/2022 21:28:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.03 on epoch=189
05/22/2022 21:28:14 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
05/22/2022 21:28:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=192
05/22/2022 21:28:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=193
05/22/2022 21:28:21 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7352244597708307 on epoch=193
05/22/2022 21:28:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=194
05/22/2022 21:28:26 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=196
05/22/2022 21:28:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=197
05/22/2022 21:28:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
05/22/2022 21:28:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=199
05/22/2022 21:28:35 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.6703416216816529 on epoch=199
05/22/2022 21:28:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=201
05/22/2022 21:28:40 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=202
05/22/2022 21:28:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
05/22/2022 21:28:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.13 on epoch=204
05/22/2022 21:28:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=206
05/22/2022 21:28:49 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.722034148647052 on epoch=206
05/22/2022 21:28:51 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
05/22/2022 21:28:54 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
05/22/2022 21:28:56 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=209
05/22/2022 21:28:59 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.05 on epoch=211
05/22/2022 21:29:01 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
05/22/2022 21:29:03 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.7157752591272072 on epoch=212
05/22/2022 21:29:05 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
05/22/2022 21:29:08 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=214
05/22/2022 21:29:10 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=216
05/22/2022 21:29:13 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=217
05/22/2022 21:29:15 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
05/22/2022 21:29:17 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.736181433056433 on epoch=218
05/22/2022 21:29:20 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.01 on epoch=219
05/22/2022 21:29:22 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=221
05/22/2022 21:29:25 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.08 on epoch=222
05/22/2022 21:29:27 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
05/22/2022 21:29:30 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=224
05/22/2022 21:29:31 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7211064430242511 on epoch=224
05/22/2022 21:29:34 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=226
05/22/2022 21:29:36 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
05/22/2022 21:29:39 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=228
05/22/2022 21:29:41 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=229
05/22/2022 21:29:44 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=231
05/22/2022 21:29:46 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7434423434423435 on epoch=231
05/22/2022 21:29:46 - INFO - __main__ - Saving model with best Classification-F1: 0.7432417582417583 -> 0.7434423434423435 on epoch=231, global_step=1850
05/22/2022 21:29:48 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=232
05/22/2022 21:29:51 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=233
05/22/2022 21:29:53 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
05/22/2022 21:29:56 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=236
05/22/2022 21:29:58 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.04 on epoch=237
05/22/2022 21:30:00 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7382301395017199 on epoch=237
05/22/2022 21:30:02 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
05/22/2022 21:30:05 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.12 on epoch=239
05/22/2022 21:30:07 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=241
05/22/2022 21:30:10 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=242
05/22/2022 21:30:12 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=243
05/22/2022 21:30:14 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7453895160321263 on epoch=243
05/22/2022 21:30:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7434423434423435 -> 0.7453895160321263 on epoch=243, global_step=1950
05/22/2022 21:30:16 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=244
05/22/2022 21:30:19 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=246
05/22/2022 21:30:21 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=247
05/22/2022 21:30:24 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=248
05/22/2022 21:30:26 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=249
05/22/2022 21:30:28 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.7313373818636257 on epoch=249
05/22/2022 21:30:31 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
05/22/2022 21:30:33 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
05/22/2022 21:30:35 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=253
05/22/2022 21:30:38 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
05/22/2022 21:30:40 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
05/22/2022 21:30:42 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7458646616541353 on epoch=256
05/22/2022 21:30:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7453895160321263 -> 0.7458646616541353 on epoch=256, global_step=2050
05/22/2022 21:30:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.08 on epoch=257
05/22/2022 21:30:47 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
05/22/2022 21:30:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=259
05/22/2022 21:30:52 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
05/22/2022 21:30:55 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=262
05/22/2022 21:30:56 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.7436306430508036 on epoch=262
05/22/2022 21:30:59 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=263
05/22/2022 21:31:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
05/22/2022 21:31:04 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=266
05/22/2022 21:31:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=267
05/22/2022 21:31:09 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.06 on epoch=268
05/22/2022 21:31:10 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.739401897992658 on epoch=268
05/22/2022 21:31:13 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=269
05/22/2022 21:31:15 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
05/22/2022 21:31:18 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=272
05/22/2022 21:31:20 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 21:31:23 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=274
05/22/2022 21:31:24 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7294809710063948 on epoch=274
05/22/2022 21:31:27 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.05 on epoch=276
05/22/2022 21:31:29 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.05 on epoch=277
05/22/2022 21:31:32 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=278
05/22/2022 21:31:34 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=279
05/22/2022 21:31:37 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
05/22/2022 21:31:39 - INFO - __main__ - Global step 2250 Train loss 0.04 Classification-F1 0.7261986278379722 on epoch=281
05/22/2022 21:31:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
05/22/2022 21:31:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=283
05/22/2022 21:31:46 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 21:31:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
05/22/2022 21:31:51 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=287
05/22/2022 21:31:53 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7240256224271461 on epoch=287
05/22/2022 21:31:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=288
05/22/2022 21:31:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=289
05/22/2022 21:32:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
05/22/2022 21:32:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=292
05/22/2022 21:32:05 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=293
05/22/2022 21:32:07 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7442271389812374 on epoch=293
05/22/2022 21:32:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=294
05/22/2022 21:32:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=296
05/22/2022 21:32:14 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=297
05/22/2022 21:32:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=298
05/22/2022 21:32:19 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=299
05/22/2022 21:32:21 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7348095821304639 on epoch=299
05/22/2022 21:32:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
05/22/2022 21:32:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
05/22/2022 21:32:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=303
05/22/2022 21:32:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
05/22/2022 21:32:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=306
05/22/2022 21:32:35 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7375662066778373 on epoch=306
05/22/2022 21:32:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=307
05/22/2022 21:32:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
05/22/2022 21:32:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
05/22/2022 21:32:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
05/22/2022 21:32:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=312
05/22/2022 21:32:49 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.7460407829490238 on epoch=312
05/22/2022 21:32:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7458646616541353 -> 0.7460407829490238 on epoch=312, global_step=2500
05/22/2022 21:32:52 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=313
05/22/2022 21:32:54 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.11 on epoch=314
05/22/2022 21:32:57 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=316
05/22/2022 21:32:59 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
05/22/2022 21:33:02 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=318
05/22/2022 21:33:03 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.746542166345144 on epoch=318
05/22/2022 21:33:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7460407829490238 -> 0.746542166345144 on epoch=318, global_step=2550
05/22/2022 21:33:06 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=319
05/22/2022 21:33:08 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 21:33:11 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=322
05/22/2022 21:33:14 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=323
05/22/2022 21:33:16 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=324
05/22/2022 21:33:18 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7458664967934034 on epoch=324
05/22/2022 21:33:20 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=326
05/22/2022 21:33:23 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=327
05/22/2022 21:33:25 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=328
05/22/2022 21:33:28 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.00 on epoch=329
05/22/2022 21:33:30 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
05/22/2022 21:33:32 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.746902999751013 on epoch=331
05/22/2022 21:33:32 - INFO - __main__ - Saving model with best Classification-F1: 0.746542166345144 -> 0.746902999751013 on epoch=331, global_step=2650
05/22/2022 21:33:34 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
05/22/2022 21:33:37 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 21:33:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=334
05/22/2022 21:33:42 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
05/22/2022 21:33:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=337
05/22/2022 21:33:46 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7470567128203021 on epoch=337
05/22/2022 21:33:46 - INFO - __main__ - Saving model with best Classification-F1: 0.746902999751013 -> 0.7470567128203021 on epoch=337, global_step=2700
05/22/2022 21:33:49 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=338
05/22/2022 21:33:51 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 21:33:53 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
05/22/2022 21:33:56 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=342
05/22/2022 21:33:58 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 21:34:00 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.746311011532003 on epoch=343
05/22/2022 21:34:03 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=344
05/22/2022 21:34:05 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 21:34:08 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=347
05/22/2022 21:34:10 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=348
05/22/2022 21:34:13 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=349
05/22/2022 21:34:14 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.744322963434594 on epoch=349
05/22/2022 21:34:17 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
05/22/2022 21:34:19 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
05/22/2022 21:34:22 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=353
05/22/2022 21:34:24 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=354
05/22/2022 21:34:27 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
05/22/2022 21:34:29 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7453838281070213 on epoch=356
05/22/2022 21:34:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
05/22/2022 21:34:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=358
05/22/2022 21:34:36 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 21:34:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=361
05/22/2022 21:34:41 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=362
05/22/2022 21:34:43 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7527975397057804 on epoch=362
05/22/2022 21:34:43 - INFO - __main__ - Saving model with best Classification-F1: 0.7470567128203021 -> 0.7527975397057804 on epoch=362, global_step=2900
05/22/2022 21:34:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=363
05/22/2022 21:34:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=364
05/22/2022 21:34:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=366
05/22/2022 21:34:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
05/22/2022 21:34:55 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
05/22/2022 21:34:57 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7746642246642246 on epoch=368
05/22/2022 21:34:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7527975397057804 -> 0.7746642246642246 on epoch=368, global_step=2950
05/22/2022 21:35:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
05/22/2022 21:35:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 21:35:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=372
05/22/2022 21:35:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
05/22/2022 21:35:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=374
05/22/2022 21:35:11 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:35:11 - INFO - __main__ - Printing 3 examples
05/22/2022 21:35:11 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:35:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:35:11 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:35:11 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:35:11 - INFO - __main__ - Printing 3 examples
05/22/2022 21:35:11 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:35:11 - INFO - __main__ - ['happy']
05/22/2022 21:35:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:35:11 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:35:11 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:35:11 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7514724238546349 on epoch=374
05/22/2022 21:35:11 - INFO - __main__ - save last model!
05/22/2022 21:35:11 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 21:35:11 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 21:35:11 - INFO - __main__ - Printing 3 examples
05/22/2022 21:35:11 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 21:35:11 - INFO - __main__ - ['others']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 21:35:11 - INFO - __main__ - ['others']
05/22/2022 21:35:11 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 21:35:11 - INFO - __main__ - ['others']
05/22/2022 21:35:11 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:35:13 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:35:19 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 21:35:30 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:35:30 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:35:30 - INFO - __main__ - Starting training!
05/22/2022 21:36:37 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_42_0.3_8_predictions.txt
05/22/2022 21:36:37 - INFO - __main__ - Classification-F1 on test data: 0.3615
05/22/2022 21:36:37 - INFO - __main__ - prefix=emo_32_42, lr=0.3, bsz=8, dev_performance=0.7746642246642246, test_performance=0.36150610609838946
05/22/2022 21:36:37 - INFO - __main__ - Running ... prefix=emo_32_42, lr=0.2, bsz=8 ...
05/22/2022 21:36:38 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:36:38 - INFO - __main__ - Printing 3 examples
05/22/2022 21:36:38 - INFO - __main__ -  [emo] hahah i loved it yay glad you loved it x3 grinningfacewithsweat you always make us happy
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ -  [emo] your right i'm always right i am impressed
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ -  [emo] okay lol well that made me rolling on floor laughing funny
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:36:38 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:36:38 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:36:38 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:36:38 - INFO - __main__ - Printing 3 examples
05/22/2022 21:36:38 - INFO - __main__ -  [emo] can i get yes if i'm allowed to get a tiger so funny
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ -  [emo] haha facewithtearsofjoy of course i wont leave you alone what do you think of me facewithtearsofjoy are u a grl
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ -  [emo] awesome thank you but for what todays my best friend's birthday and we are enjoying the precious  day
05/22/2022 21:36:38 - INFO - __main__ - ['happy']
05/22/2022 21:36:38 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:36:38 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:36:38 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:36:53 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:36:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:36:54 - INFO - __main__ - Starting training!
05/22/2022 21:36:57 - INFO - __main__ - Step 10 Global step 10 Train loss 4.11 on epoch=1
05/22/2022 21:37:00 - INFO - __main__ - Step 20 Global step 20 Train loss 3.29 on epoch=2
05/22/2022 21:37:02 - INFO - __main__ - Step 30 Global step 30 Train loss 2.71 on epoch=3
05/22/2022 21:37:05 - INFO - __main__ - Step 40 Global step 40 Train loss 2.57 on epoch=4
05/22/2022 21:37:07 - INFO - __main__ - Step 50 Global step 50 Train loss 2.36 on epoch=6
05/22/2022 21:37:09 - INFO - __main__ - Global step 50 Train loss 3.01 Classification-F1 0.010857235456165938 on epoch=6
05/22/2022 21:37:09 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.010857235456165938 on epoch=6, global_step=50
05/22/2022 21:37:11 - INFO - __main__ - Step 60 Global step 60 Train loss 2.26 on epoch=7
05/22/2022 21:37:14 - INFO - __main__ - Step 70 Global step 70 Train loss 1.84 on epoch=8
05/22/2022 21:37:16 - INFO - __main__ - Step 80 Global step 80 Train loss 1.66 on epoch=9
05/22/2022 21:37:19 - INFO - __main__ - Step 90 Global step 90 Train loss 1.80 on epoch=11
05/22/2022 21:37:21 - INFO - __main__ - Step 100 Global step 100 Train loss 1.61 on epoch=12
05/22/2022 21:37:23 - INFO - __main__ - Global step 100 Train loss 1.83 Classification-F1 0.24571465585845687 on epoch=12
05/22/2022 21:37:23 - INFO - __main__ - Saving model with best Classification-F1: 0.010857235456165938 -> 0.24571465585845687 on epoch=12, global_step=100
05/22/2022 21:37:26 - INFO - __main__ - Step 110 Global step 110 Train loss 1.24 on epoch=13
05/22/2022 21:37:28 - INFO - __main__ - Step 120 Global step 120 Train loss 1.25 on epoch=14
05/22/2022 21:37:31 - INFO - __main__ - Step 130 Global step 130 Train loss 1.27 on epoch=16
05/22/2022 21:37:33 - INFO - __main__ - Step 140 Global step 140 Train loss 1.15 on epoch=17
05/22/2022 21:37:36 - INFO - __main__ - Step 150 Global step 150 Train loss 0.91 on epoch=18
05/22/2022 21:37:37 - INFO - __main__ - Global step 150 Train loss 1.16 Classification-F1 0.48948365231259966 on epoch=18
05/22/2022 21:37:37 - INFO - __main__ - Saving model with best Classification-F1: 0.24571465585845687 -> 0.48948365231259966 on epoch=18, global_step=150
05/22/2022 21:37:40 - INFO - __main__ - Step 160 Global step 160 Train loss 0.99 on epoch=19
05/22/2022 21:37:42 - INFO - __main__ - Step 170 Global step 170 Train loss 0.84 on epoch=21
05/22/2022 21:37:45 - INFO - __main__ - Step 180 Global step 180 Train loss 0.72 on epoch=22
05/22/2022 21:37:47 - INFO - __main__ - Step 190 Global step 190 Train loss 0.75 on epoch=23
05/22/2022 21:37:50 - INFO - __main__ - Step 200 Global step 200 Train loss 0.82 on epoch=24
05/22/2022 21:37:51 - INFO - __main__ - Global step 200 Train loss 0.82 Classification-F1 0.5058700974431313 on epoch=24
05/22/2022 21:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.48948365231259966 -> 0.5058700974431313 on epoch=24, global_step=200
05/22/2022 21:37:54 - INFO - __main__ - Step 210 Global step 210 Train loss 0.76 on epoch=26
05/22/2022 21:37:56 - INFO - __main__ - Step 220 Global step 220 Train loss 0.82 on epoch=27
05/22/2022 21:37:59 - INFO - __main__ - Step 230 Global step 230 Train loss 0.72 on epoch=28
05/22/2022 21:38:01 - INFO - __main__ - Step 240 Global step 240 Train loss 0.60 on epoch=29
05/22/2022 21:38:04 - INFO - __main__ - Step 250 Global step 250 Train loss 0.77 on epoch=31
05/22/2022 21:38:05 - INFO - __main__ - Global step 250 Train loss 0.74 Classification-F1 0.4767504376094024 on epoch=31
05/22/2022 21:38:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.71 on epoch=32
05/22/2022 21:38:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=33
05/22/2022 21:38:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.54 on epoch=34
05/22/2022 21:38:15 - INFO - __main__ - Step 290 Global step 290 Train loss 0.65 on epoch=36
05/22/2022 21:38:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.71 on epoch=37
05/22/2022 21:38:20 - INFO - __main__ - Global step 300 Train loss 0.68 Classification-F1 0.5186470497024058 on epoch=37
05/22/2022 21:38:20 - INFO - __main__ - Saving model with best Classification-F1: 0.5058700974431313 -> 0.5186470497024058 on epoch=37, global_step=300
05/22/2022 21:38:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.52 on epoch=38
05/22/2022 21:38:25 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=39
05/22/2022 21:38:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.56 on epoch=41
05/22/2022 21:38:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.66 on epoch=42
05/22/2022 21:38:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.63 on epoch=43
05/22/2022 21:38:34 - INFO - __main__ - Global step 350 Train loss 0.60 Classification-F1 0.5262778215054166 on epoch=43
05/22/2022 21:38:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5186470497024058 -> 0.5262778215054166 on epoch=43, global_step=350
05/22/2022 21:38:36 - INFO - __main__ - Step 360 Global step 360 Train loss 0.57 on epoch=44
05/22/2022 21:38:39 - INFO - __main__ - Step 370 Global step 370 Train loss 0.52 on epoch=46
05/22/2022 21:38:41 - INFO - __main__ - Step 380 Global step 380 Train loss 0.55 on epoch=47
05/22/2022 21:38:44 - INFO - __main__ - Step 390 Global step 390 Train loss 0.51 on epoch=48
05/22/2022 21:38:46 - INFO - __main__ - Step 400 Global step 400 Train loss 0.47 on epoch=49
05/22/2022 21:38:48 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.5781654666503953 on epoch=49
05/22/2022 21:38:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5262778215054166 -> 0.5781654666503953 on epoch=49, global_step=400
05/22/2022 21:38:50 - INFO - __main__ - Step 410 Global step 410 Train loss 0.51 on epoch=51
05/22/2022 21:38:53 - INFO - __main__ - Step 420 Global step 420 Train loss 0.56 on epoch=52
05/22/2022 21:38:55 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=53
05/22/2022 21:38:58 - INFO - __main__ - Step 440 Global step 440 Train loss 0.45 on epoch=54
05/22/2022 21:39:00 - INFO - __main__ - Step 450 Global step 450 Train loss 0.51 on epoch=56
05/22/2022 21:39:02 - INFO - __main__ - Global step 450 Train loss 0.49 Classification-F1 0.5676786843769766 on epoch=56
05/22/2022 21:39:05 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=57
05/22/2022 21:39:07 - INFO - __main__ - Step 470 Global step 470 Train loss 0.47 on epoch=58
05/22/2022 21:39:10 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=59
05/22/2022 21:39:12 - INFO - __main__ - Step 490 Global step 490 Train loss 0.40 on epoch=61
05/22/2022 21:39:15 - INFO - __main__ - Step 500 Global step 500 Train loss 0.46 on epoch=62
05/22/2022 21:39:16 - INFO - __main__ - Global step 500 Train loss 0.45 Classification-F1 0.6270542810016494 on epoch=62
05/22/2022 21:39:16 - INFO - __main__ - Saving model with best Classification-F1: 0.5781654666503953 -> 0.6270542810016494 on epoch=62, global_step=500
05/22/2022 21:39:19 - INFO - __main__ - Step 510 Global step 510 Train loss 0.35 on epoch=63
05/22/2022 21:39:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.43 on epoch=64
05/22/2022 21:39:24 - INFO - __main__ - Step 530 Global step 530 Train loss 0.39 on epoch=66
05/22/2022 21:39:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.44 on epoch=67
05/22/2022 21:39:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.40 on epoch=68
05/22/2022 21:39:30 - INFO - __main__ - Global step 550 Train loss 0.40 Classification-F1 0.6272963323596235 on epoch=68
05/22/2022 21:39:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6270542810016494 -> 0.6272963323596235 on epoch=68, global_step=550
05/22/2022 21:39:33 - INFO - __main__ - Step 560 Global step 560 Train loss 0.40 on epoch=69
05/22/2022 21:39:35 - INFO - __main__ - Step 570 Global step 570 Train loss 0.55 on epoch=71
05/22/2022 21:39:38 - INFO - __main__ - Step 580 Global step 580 Train loss 0.49 on epoch=72
05/22/2022 21:39:40 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=73
05/22/2022 21:39:43 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=74
05/22/2022 21:39:44 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.6623705817254204 on epoch=74
05/22/2022 21:39:44 - INFO - __main__ - Saving model with best Classification-F1: 0.6272963323596235 -> 0.6623705817254204 on epoch=74, global_step=600
05/22/2022 21:39:47 - INFO - __main__ - Step 610 Global step 610 Train loss 0.49 on epoch=76
05/22/2022 21:39:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.35 on epoch=77
05/22/2022 21:39:52 - INFO - __main__ - Step 630 Global step 630 Train loss 0.42 on epoch=78
05/22/2022 21:39:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=79
05/22/2022 21:39:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=81
05/22/2022 21:39:59 - INFO - __main__ - Global step 650 Train loss 0.40 Classification-F1 0.6682672002429608 on epoch=81
05/22/2022 21:39:59 - INFO - __main__ - Saving model with best Classification-F1: 0.6623705817254204 -> 0.6682672002429608 on epoch=81, global_step=650
05/22/2022 21:40:01 - INFO - __main__ - Step 660 Global step 660 Train loss 0.40 on epoch=82
05/22/2022 21:40:04 - INFO - __main__ - Step 670 Global step 670 Train loss 0.32 on epoch=83
05/22/2022 21:40:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.37 on epoch=84
05/22/2022 21:40:09 - INFO - __main__ - Step 690 Global step 690 Train loss 0.37 on epoch=86
05/22/2022 21:40:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=87
05/22/2022 21:40:13 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.6627508484867356 on epoch=87
05/22/2022 21:40:15 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=88
05/22/2022 21:40:18 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=89
05/22/2022 21:40:20 - INFO - __main__ - Step 730 Global step 730 Train loss 0.37 on epoch=91
05/22/2022 21:40:23 - INFO - __main__ - Step 740 Global step 740 Train loss 0.40 on epoch=92
05/22/2022 21:40:25 - INFO - __main__ - Step 750 Global step 750 Train loss 0.34 on epoch=93
05/22/2022 21:40:27 - INFO - __main__ - Global step 750 Train loss 0.37 Classification-F1 0.6729978663839965 on epoch=93
05/22/2022 21:40:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6682672002429608 -> 0.6729978663839965 on epoch=93, global_step=750
05/22/2022 21:40:30 - INFO - __main__ - Step 760 Global step 760 Train loss 0.26 on epoch=94
05/22/2022 21:40:32 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=96
05/22/2022 21:40:35 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=97
05/22/2022 21:40:37 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=98
05/22/2022 21:40:39 - INFO - __main__ - Step 800 Global step 800 Train loss 0.30 on epoch=99
05/22/2022 21:40:41 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.6867648972157169 on epoch=99
05/22/2022 21:40:41 - INFO - __main__ - Saving model with best Classification-F1: 0.6729978663839965 -> 0.6867648972157169 on epoch=99, global_step=800
05/22/2022 21:40:44 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=101
05/22/2022 21:40:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.39 on epoch=102
05/22/2022 21:40:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=103
05/22/2022 21:40:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.31 on epoch=104
05/22/2022 21:40:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.31 on epoch=106
05/22/2022 21:40:55 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.6872943957451 on epoch=106
05/22/2022 21:40:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6867648972157169 -> 0.6872943957451 on epoch=106, global_step=850
05/22/2022 21:40:58 - INFO - __main__ - Step 860 Global step 860 Train loss 0.37 on epoch=107
05/22/2022 21:41:00 - INFO - __main__ - Step 870 Global step 870 Train loss 0.30 on epoch=108
05/22/2022 21:41:03 - INFO - __main__ - Step 880 Global step 880 Train loss 0.34 on epoch=109
05/22/2022 21:41:05 - INFO - __main__ - Step 890 Global step 890 Train loss 0.28 on epoch=111
05/22/2022 21:41:08 - INFO - __main__ - Step 900 Global step 900 Train loss 0.23 on epoch=112
05/22/2022 21:41:09 - INFO - __main__ - Global step 900 Train loss 0.30 Classification-F1 0.6772175402139614 on epoch=112
05/22/2022 21:41:12 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=113
05/22/2022 21:41:14 - INFO - __main__ - Step 920 Global step 920 Train loss 0.31 on epoch=114
05/22/2022 21:41:17 - INFO - __main__ - Step 930 Global step 930 Train loss 0.21 on epoch=116
05/22/2022 21:41:19 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=117
05/22/2022 21:41:22 - INFO - __main__ - Step 950 Global step 950 Train loss 0.23 on epoch=118
05/22/2022 21:41:24 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.6971153846153846 on epoch=118
05/22/2022 21:41:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6872943957451 -> 0.6971153846153846 on epoch=118, global_step=950
05/22/2022 21:41:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.19 on epoch=119
05/22/2022 21:41:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.30 on epoch=121
05/22/2022 21:41:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.26 on epoch=122
05/22/2022 21:41:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=123
05/22/2022 21:41:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.29 on epoch=124
05/22/2022 21:41:38 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.6819185313903624 on epoch=124
05/22/2022 21:41:40 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.24 on epoch=126
05/22/2022 21:41:43 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.20 on epoch=127
05/22/2022 21:41:45 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.27 on epoch=128
05/22/2022 21:41:48 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.32 on epoch=129
05/22/2022 21:41:50 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.27 on epoch=131
05/22/2022 21:41:52 - INFO - __main__ - Global step 1050 Train loss 0.26 Classification-F1 0.6878449675324676 on epoch=131
05/22/2022 21:41:54 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.31 on epoch=132
05/22/2022 21:41:57 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=133
05/22/2022 21:41:59 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.24 on epoch=134
05/22/2022 21:42:02 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.30 on epoch=136
05/22/2022 21:42:04 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.29 on epoch=137
05/22/2022 21:42:06 - INFO - __main__ - Global step 1100 Train loss 0.27 Classification-F1 0.7047087672087672 on epoch=137
05/22/2022 21:42:06 - INFO - __main__ - Saving model with best Classification-F1: 0.6971153846153846 -> 0.7047087672087672 on epoch=137, global_step=1100
05/22/2022 21:42:08 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=138
05/22/2022 21:42:11 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.18 on epoch=139
05/22/2022 21:42:13 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.24 on epoch=141
05/22/2022 21:42:16 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=142
05/22/2022 21:42:18 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.22 on epoch=143
05/22/2022 21:42:20 - INFO - __main__ - Global step 1150 Train loss 0.21 Classification-F1 0.701836069023569 on epoch=143
05/22/2022 21:42:23 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=144
05/22/2022 21:42:25 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.18 on epoch=146
05/22/2022 21:42:27 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.28 on epoch=147
05/22/2022 21:42:30 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=148
05/22/2022 21:42:32 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=149
05/22/2022 21:42:34 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.7115694164989941 on epoch=149
05/22/2022 21:42:34 - INFO - __main__ - Saving model with best Classification-F1: 0.7047087672087672 -> 0.7115694164989941 on epoch=149, global_step=1200
05/22/2022 21:42:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=151
05/22/2022 21:42:39 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.25 on epoch=152
05/22/2022 21:42:42 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=153
05/22/2022 21:42:44 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=154
05/22/2022 21:42:47 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=156
05/22/2022 21:42:48 - INFO - __main__ - Global step 1250 Train loss 0.19 Classification-F1 0.6894136823502787 on epoch=156
05/22/2022 21:42:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=157
05/22/2022 21:42:53 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.26 on epoch=158
05/22/2022 21:42:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.19 on epoch=159
05/22/2022 21:42:58 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=161
05/22/2022 21:43:01 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=162
05/22/2022 21:43:03 - INFO - __main__ - Global step 1300 Train loss 0.18 Classification-F1 0.6859419967675845 on epoch=162
05/22/2022 21:43:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=163
05/22/2022 21:43:08 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.25 on epoch=164
05/22/2022 21:43:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.13 on epoch=166
05/22/2022 21:43:13 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=167
05/22/2022 21:43:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.13 on epoch=168
05/22/2022 21:43:17 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.6932267615254368 on epoch=168
05/22/2022 21:43:19 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=169
05/22/2022 21:43:22 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=171
05/22/2022 21:43:24 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.14 on epoch=172
05/22/2022 21:43:27 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.22 on epoch=173
05/22/2022 21:43:29 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=174
05/22/2022 21:43:31 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.6710284989651714 on epoch=174
05/22/2022 21:43:34 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=176
05/22/2022 21:43:36 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.14 on epoch=177
05/22/2022 21:43:39 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=178
05/22/2022 21:43:41 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.17 on epoch=179
05/22/2022 21:43:44 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=181
05/22/2022 21:43:45 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.6826357839563794 on epoch=181
05/22/2022 21:43:48 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=182
05/22/2022 21:43:50 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=183
05/22/2022 21:43:53 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=184
05/22/2022 21:43:55 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=186
05/22/2022 21:43:58 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=187
05/22/2022 21:44:00 - INFO - __main__ - Global step 1500 Train loss 0.13 Classification-F1 0.6897979348158868 on epoch=187
05/22/2022 21:44:02 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=188
05/22/2022 21:44:04 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=189
05/22/2022 21:44:07 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=191
05/22/2022 21:44:09 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=192
05/22/2022 21:44:12 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=193
05/22/2022 21:44:14 - INFO - __main__ - Global step 1550 Train loss 0.14 Classification-F1 0.6992260427744299 on epoch=193
05/22/2022 21:44:16 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.14 on epoch=194
05/22/2022 21:44:19 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=196
05/22/2022 21:44:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.09 on epoch=197
05/22/2022 21:44:24 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.13 on epoch=198
05/22/2022 21:44:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=199
05/22/2022 21:44:28 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.702753917836494 on epoch=199
05/22/2022 21:44:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=201
05/22/2022 21:44:33 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.17 on epoch=202
05/22/2022 21:44:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.19 on epoch=203
05/22/2022 21:44:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=204
05/22/2022 21:44:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.08 on epoch=206
05/22/2022 21:44:42 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.7141143180531976 on epoch=206
05/22/2022 21:44:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7115694164989941 -> 0.7141143180531976 on epoch=206, global_step=1650
05/22/2022 21:44:44 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=207
05/22/2022 21:44:47 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=208
05/22/2022 21:44:49 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=209
05/22/2022 21:44:52 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=211
05/22/2022 21:44:54 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=212
05/22/2022 21:44:56 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.6919394956144351 on epoch=212
05/22/2022 21:44:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.11 on epoch=213
05/22/2022 21:45:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.11 on epoch=214
05/22/2022 21:45:03 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.11 on epoch=216
05/22/2022 21:45:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=217
05/22/2022 21:45:08 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=218
05/22/2022 21:45:10 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.7394956128704009 on epoch=218
05/22/2022 21:45:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7141143180531976 -> 0.7394956128704009 on epoch=218, global_step=1750
05/22/2022 21:45:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=219
05/22/2022 21:45:15 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.16 on epoch=221
05/22/2022 21:45:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.12 on epoch=222
05/22/2022 21:45:20 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.14 on epoch=223
05/22/2022 21:45:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=224
05/22/2022 21:45:24 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.6970347431950706 on epoch=224
05/22/2022 21:45:27 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.10 on epoch=226
05/22/2022 21:45:29 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.13 on epoch=227
05/22/2022 21:45:32 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.14 on epoch=228
05/22/2022 21:45:34 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.13 on epoch=229
05/22/2022 21:45:36 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=231
05/22/2022 21:45:38 - INFO - __main__ - Global step 1850 Train loss 0.12 Classification-F1 0.6895562770562771 on epoch=231
05/22/2022 21:45:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.09 on epoch=232
05/22/2022 21:45:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.12 on epoch=233
05/22/2022 21:45:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.18 on epoch=234
05/22/2022 21:45:48 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=236
05/22/2022 21:45:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.12 on epoch=237
05/22/2022 21:45:52 - INFO - __main__ - Global step 1900 Train loss 0.11 Classification-F1 0.7318601869971733 on epoch=237
05/22/2022 21:45:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=238
05/22/2022 21:45:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=239
05/22/2022 21:46:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=241
05/22/2022 21:46:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.07 on epoch=242
05/22/2022 21:46:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=243
05/22/2022 21:46:06 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7040665183075614 on epoch=243
05/22/2022 21:46:09 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=244
05/22/2022 21:46:11 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=246
05/22/2022 21:46:14 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=247
05/22/2022 21:46:16 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=248
05/22/2022 21:46:19 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=249
05/22/2022 21:46:20 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7242048734045402 on epoch=249
05/22/2022 21:46:23 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=251
05/22/2022 21:46:25 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=252
05/22/2022 21:46:28 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
05/22/2022 21:46:30 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
05/22/2022 21:46:33 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=256
05/22/2022 21:46:34 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.7082260348222384 on epoch=256
05/22/2022 21:46:37 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=257
05/22/2022 21:46:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=258
05/22/2022 21:46:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
05/22/2022 21:46:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=261
05/22/2022 21:46:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=262
05/22/2022 21:46:49 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.6635519652761033 on epoch=262
05/22/2022 21:46:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=263
05/22/2022 21:46:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=264
05/22/2022 21:46:56 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=266
05/22/2022 21:46:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=267
05/22/2022 21:47:01 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=268
05/22/2022 21:47:03 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.686534426762447 on epoch=268
05/22/2022 21:47:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=269
05/22/2022 21:47:08 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=271
05/22/2022 21:47:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=272
05/22/2022 21:47:13 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=273
05/22/2022 21:47:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.11 on epoch=274
05/22/2022 21:47:17 - INFO - __main__ - Global step 2200 Train loss 0.07 Classification-F1 0.7066951232247285 on epoch=274
05/22/2022 21:47:19 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=276
05/22/2022 21:47:22 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.08 on epoch=277
05/22/2022 21:47:24 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=278
05/22/2022 21:47:27 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.12 on epoch=279
05/22/2022 21:47:29 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=281
05/22/2022 21:47:31 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6840345515079724 on epoch=281
05/22/2022 21:47:33 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=282
05/22/2022 21:47:36 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.09 on epoch=283
05/22/2022 21:47:38 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=284
05/22/2022 21:47:41 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=286
05/22/2022 21:47:43 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.12 on epoch=287
05/22/2022 21:47:45 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.725193814129809 on epoch=287
05/22/2022 21:47:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=288
05/22/2022 21:47:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=289
05/22/2022 21:47:52 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=291
05/22/2022 21:47:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=292
05/22/2022 21:47:57 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=293
05/22/2022 21:47:59 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.7258442159859221 on epoch=293
05/22/2022 21:48:01 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=294
05/22/2022 21:48:04 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
05/22/2022 21:48:06 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.07 on epoch=297
05/22/2022 21:48:09 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=298
05/22/2022 21:48:11 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=299
05/22/2022 21:48:13 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.7340992916105615 on epoch=299
05/22/2022 21:48:15 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=301
05/22/2022 21:48:18 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.11 on epoch=302
05/22/2022 21:48:20 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.09 on epoch=303
05/22/2022 21:48:23 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=304
05/22/2022 21:48:25 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=306
05/22/2022 21:48:27 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.7088049884189493 on epoch=306
05/22/2022 21:48:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.13 on epoch=307
05/22/2022 21:48:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
05/22/2022 21:48:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=309
05/22/2022 21:48:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=311
05/22/2022 21:48:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.10 on epoch=312
05/22/2022 21:48:41 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7176597309794032 on epoch=312
05/22/2022 21:48:43 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.06 on epoch=313
05/22/2022 21:48:46 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=314
05/22/2022 21:48:48 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
05/22/2022 21:48:51 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=317
05/22/2022 21:48:53 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=318
05/22/2022 21:48:55 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.6951772481006353 on epoch=318
05/22/2022 21:48:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=319
05/22/2022 21:49:00 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=321
05/22/2022 21:49:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
05/22/2022 21:49:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.03 on epoch=323
05/22/2022 21:49:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=324
05/22/2022 21:49:09 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7109649122807018 on epoch=324
05/22/2022 21:49:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 21:49:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=327
05/22/2022 21:49:16 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=328
05/22/2022 21:49:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 21:49:21 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=331
05/22/2022 21:49:23 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7093258228295738 on epoch=331
05/22/2022 21:49:25 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
05/22/2022 21:49:28 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.05 on epoch=333
05/22/2022 21:49:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=334
05/22/2022 21:49:33 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=336
05/22/2022 21:49:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=337
05/22/2022 21:49:37 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.6932535689889445 on epoch=337
05/22/2022 21:49:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=338
05/22/2022 21:49:42 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=339
05/22/2022 21:49:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=341
05/22/2022 21:49:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
05/22/2022 21:49:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=343
05/22/2022 21:49:51 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6950986866241102 on epoch=343
05/22/2022 21:49:53 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=344
05/22/2022 21:49:56 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=346
05/22/2022 21:49:58 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=347
05/22/2022 21:50:01 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
05/22/2022 21:50:03 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=349
05/22/2022 21:50:05 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.7092828503736104 on epoch=349
05/22/2022 21:50:07 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=351
05/22/2022 21:50:10 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 21:50:12 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
05/22/2022 21:50:15 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
05/22/2022 21:50:17 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.08 on epoch=356
05/22/2022 21:50:19 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6937901250829333 on epoch=356
05/22/2022 21:50:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=357
05/22/2022 21:50:24 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=358
05/22/2022 21:50:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
05/22/2022 21:50:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=361
05/22/2022 21:50:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=362
05/22/2022 21:50:33 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.7005802034114497 on epoch=362
05/22/2022 21:50:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=363
05/22/2022 21:50:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
05/22/2022 21:50:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=366
05/22/2022 21:50:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=367
05/22/2022 21:50:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.07 on epoch=368
05/22/2022 21:50:47 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7230975305694809 on epoch=368
05/22/2022 21:50:49 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
05/22/2022 21:50:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=371
05/22/2022 21:50:54 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.06 on epoch=372
05/22/2022 21:50:57 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=373
05/22/2022 21:50:59 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
05/22/2022 21:51:00 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:51:00 - INFO - __main__ - Printing 3 examples
05/22/2022 21:51:00 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 21:51:00 - INFO - __main__ - ['others']
05/22/2022 21:51:00 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 21:51:00 - INFO - __main__ - ['others']
05/22/2022 21:51:00 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 21:51:00 - INFO - __main__ - ['others']
05/22/2022 21:51:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:51:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:51:01 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:51:01 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:51:01 - INFO - __main__ - Printing 3 examples
05/22/2022 21:51:01 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:51:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:51:01 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:51:01 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.70931415286254 on epoch=374
05/22/2022 21:51:01 - INFO - __main__ - save last model!
05/22/2022 21:51:01 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 21:51:01 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 21:51:01 - INFO - __main__ - Printing 3 examples
05/22/2022 21:51:01 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 21:51:01 - INFO - __main__ - ['others']
05/22/2022 21:51:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:51:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:51:08 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 21:51:19 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:51:20 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:51:20 - INFO - __main__ - Starting training!
05/22/2022 21:52:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_42_0.2_8_predictions.txt
05/22/2022 21:52:23 - INFO - __main__ - Classification-F1 on test data: 0.2994
05/22/2022 21:52:24 - INFO - __main__ - prefix=emo_32_42, lr=0.2, bsz=8, dev_performance=0.7394956128704009, test_performance=0.2993803411984955
05/22/2022 21:52:24 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.5, bsz=8 ...
05/22/2022 21:52:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:52:25 - INFO - __main__ - Printing 3 examples
05/22/2022 21:52:25 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:52:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:52:25 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 21:52:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 21:52:25 - INFO - __main__ - Printing 3 examples
05/22/2022 21:52:25 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 21:52:25 - INFO - __main__ - ['others']
05/22/2022 21:52:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 21:52:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 21:52:25 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 21:52:44 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 21:52:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 21:52:44 - INFO - __main__ - Starting training!
05/22/2022 21:52:47 - INFO - __main__ - Step 10 Global step 10 Train loss 4.19 on epoch=1
05/22/2022 21:52:50 - INFO - __main__ - Step 20 Global step 20 Train loss 2.67 on epoch=2
05/22/2022 21:52:52 - INFO - __main__ - Step 30 Global step 30 Train loss 2.20 on epoch=3
05/22/2022 21:52:55 - INFO - __main__ - Step 40 Global step 40 Train loss 1.90 on epoch=4
05/22/2022 21:52:57 - INFO - __main__ - Step 50 Global step 50 Train loss 1.46 on epoch=6
05/22/2022 21:52:59 - INFO - __main__ - Global step 50 Train loss 2.48 Classification-F1 0.4091503009185936 on epoch=6
05/22/2022 21:52:59 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.4091503009185936 on epoch=6, global_step=50
05/22/2022 21:53:01 - INFO - __main__ - Step 60 Global step 60 Train loss 1.06 on epoch=7
05/22/2022 21:53:04 - INFO - __main__ - Step 70 Global step 70 Train loss 1.02 on epoch=8
05/22/2022 21:53:06 - INFO - __main__ - Step 80 Global step 80 Train loss 0.82 on epoch=9
05/22/2022 21:53:09 - INFO - __main__ - Step 90 Global step 90 Train loss 0.74 on epoch=11
05/22/2022 21:53:11 - INFO - __main__ - Step 100 Global step 100 Train loss 0.65 on epoch=12
05/22/2022 21:53:13 - INFO - __main__ - Global step 100 Train loss 0.86 Classification-F1 0.49982281972413556 on epoch=12
05/22/2022 21:53:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4091503009185936 -> 0.49982281972413556 on epoch=12, global_step=100
05/22/2022 21:53:15 - INFO - __main__ - Step 110 Global step 110 Train loss 0.53 on epoch=13
05/22/2022 21:53:18 - INFO - __main__ - Step 120 Global step 120 Train loss 0.60 on epoch=14
05/22/2022 21:53:20 - INFO - __main__ - Step 130 Global step 130 Train loss 0.61 on epoch=16
05/22/2022 21:53:22 - INFO - __main__ - Step 140 Global step 140 Train loss 0.63 on epoch=17
05/22/2022 21:53:25 - INFO - __main__ - Step 150 Global step 150 Train loss 0.54 on epoch=18
05/22/2022 21:53:27 - INFO - __main__ - Global step 150 Train loss 0.58 Classification-F1 0.5401456267309925 on epoch=18
05/22/2022 21:53:27 - INFO - __main__ - Saving model with best Classification-F1: 0.49982281972413556 -> 0.5401456267309925 on epoch=18, global_step=150
05/22/2022 21:53:29 - INFO - __main__ - Step 160 Global step 160 Train loss 0.58 on epoch=19
05/22/2022 21:53:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.57 on epoch=21
05/22/2022 21:53:34 - INFO - __main__ - Step 180 Global step 180 Train loss 0.52 on epoch=22
05/22/2022 21:53:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=23
05/22/2022 21:53:39 - INFO - __main__ - Step 200 Global step 200 Train loss 0.53 on epoch=24
05/22/2022 21:53:40 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.594302240309904 on epoch=24
05/22/2022 21:53:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5401456267309925 -> 0.594302240309904 on epoch=24, global_step=200
05/22/2022 21:53:43 - INFO - __main__ - Step 210 Global step 210 Train loss 0.55 on epoch=26
05/22/2022 21:53:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=27
05/22/2022 21:53:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=28
05/22/2022 21:53:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.42 on epoch=29
05/22/2022 21:53:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.38 on epoch=31
05/22/2022 21:53:54 - INFO - __main__ - Global step 250 Train loss 0.46 Classification-F1 0.6651720736227779 on epoch=31
05/22/2022 21:53:54 - INFO - __main__ - Saving model with best Classification-F1: 0.594302240309904 -> 0.6651720736227779 on epoch=31, global_step=250
05/22/2022 21:53:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=32
05/22/2022 21:53:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.46 on epoch=33
05/22/2022 21:54:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.48 on epoch=34
05/22/2022 21:54:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.35 on epoch=36
05/22/2022 21:54:06 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=37
05/22/2022 21:54:08 - INFO - __main__ - Global step 300 Train loss 0.43 Classification-F1 0.7014328808446455 on epoch=37
05/22/2022 21:54:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6651720736227779 -> 0.7014328808446455 on epoch=37, global_step=300
05/22/2022 21:54:10 - INFO - __main__ - Step 310 Global step 310 Train loss 0.48 on epoch=38
05/22/2022 21:54:13 - INFO - __main__ - Step 320 Global step 320 Train loss 0.37 on epoch=39
05/22/2022 21:54:15 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=41
05/22/2022 21:54:18 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=42
05/22/2022 21:54:20 - INFO - __main__ - Step 350 Global step 350 Train loss 0.34 on epoch=43
05/22/2022 21:54:22 - INFO - __main__ - Global step 350 Train loss 0.40 Classification-F1 0.6974684012351879 on epoch=43
05/22/2022 21:54:24 - INFO - __main__ - Step 360 Global step 360 Train loss 0.45 on epoch=44
05/22/2022 21:54:27 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=46
05/22/2022 21:54:29 - INFO - __main__ - Step 380 Global step 380 Train loss 0.35 on epoch=47
05/22/2022 21:54:32 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=48
05/22/2022 21:54:34 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=49
05/22/2022 21:54:36 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.7336312691991849 on epoch=49
05/22/2022 21:54:36 - INFO - __main__ - Saving model with best Classification-F1: 0.7014328808446455 -> 0.7336312691991849 on epoch=49, global_step=400
05/22/2022 21:54:39 - INFO - __main__ - Step 410 Global step 410 Train loss 0.35 on epoch=51
05/22/2022 21:54:41 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=52
05/22/2022 21:54:44 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=53
05/22/2022 21:54:46 - INFO - __main__ - Step 440 Global step 440 Train loss 0.32 on epoch=54
05/22/2022 21:54:48 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=56
05/22/2022 21:54:50 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.7346010877113505 on epoch=56
05/22/2022 21:54:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7336312691991849 -> 0.7346010877113505 on epoch=56, global_step=450
05/22/2022 21:54:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.26 on epoch=57
05/22/2022 21:54:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.25 on epoch=58
05/22/2022 21:54:58 - INFO - __main__ - Step 480 Global step 480 Train loss 0.30 on epoch=59
05/22/2022 21:55:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=61
05/22/2022 21:55:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.28 on epoch=62
05/22/2022 21:55:04 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.764073171837581 on epoch=62
05/22/2022 21:55:04 - INFO - __main__ - Saving model with best Classification-F1: 0.7346010877113505 -> 0.764073171837581 on epoch=62, global_step=500
05/22/2022 21:55:07 - INFO - __main__ - Step 510 Global step 510 Train loss 0.27 on epoch=63
05/22/2022 21:55:09 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=64
05/22/2022 21:55:11 - INFO - __main__ - Step 530 Global step 530 Train loss 0.24 on epoch=66
05/22/2022 21:55:14 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=67
05/22/2022 21:55:16 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=68
05/22/2022 21:55:18 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7758509389671362 on epoch=68
05/22/2022 21:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.764073171837581 -> 0.7758509389671362 on epoch=68, global_step=550
05/22/2022 21:55:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=69
05/22/2022 21:55:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.19 on epoch=71
05/22/2022 21:55:25 - INFO - __main__ - Step 580 Global step 580 Train loss 0.29 on epoch=72
05/22/2022 21:55:28 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=73
05/22/2022 21:55:30 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=74
05/22/2022 21:55:32 - INFO - __main__ - Global step 600 Train loss 0.24 Classification-F1 0.805123491704374 on epoch=74
05/22/2022 21:55:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7758509389671362 -> 0.805123491704374 on epoch=74, global_step=600
05/22/2022 21:55:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=76
05/22/2022 21:55:37 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=77
05/22/2022 21:55:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.27 on epoch=78
05/22/2022 21:55:42 - INFO - __main__ - Step 640 Global step 640 Train loss 0.22 on epoch=79
05/22/2022 21:55:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=81
05/22/2022 21:55:46 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.7719096647668076 on epoch=81
05/22/2022 21:55:49 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=82
05/22/2022 21:55:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.19 on epoch=83
05/22/2022 21:55:54 - INFO - __main__ - Step 680 Global step 680 Train loss 0.18 on epoch=84
05/22/2022 21:55:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=86
05/22/2022 21:55:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=87
05/22/2022 21:56:00 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.7716407529362046 on epoch=87
05/22/2022 21:56:03 - INFO - __main__ - Step 710 Global step 710 Train loss 0.17 on epoch=88
05/22/2022 21:56:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.15 on epoch=89
05/22/2022 21:56:08 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=91
05/22/2022 21:56:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=92
05/22/2022 21:56:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=93
05/22/2022 21:56:14 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.7791639236339698 on epoch=93
05/22/2022 21:56:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.14 on epoch=94
05/22/2022 21:56:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.12 on epoch=96
05/22/2022 21:56:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=97
05/22/2022 21:56:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.10 on epoch=98
05/22/2022 21:56:26 - INFO - __main__ - Step 800 Global step 800 Train loss 0.10 on epoch=99
05/22/2022 21:56:28 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7934546251373407 on epoch=99
05/22/2022 21:56:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=101
05/22/2022 21:56:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=102
05/22/2022 21:56:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=103
05/22/2022 21:56:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.14 on epoch=104
05/22/2022 21:56:40 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=106
05/22/2022 21:56:42 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.7886013202142236 on epoch=106
05/22/2022 21:56:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=107
05/22/2022 21:56:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.20 on epoch=108
05/22/2022 21:56:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=109
05/22/2022 21:56:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=111
05/22/2022 21:56:54 - INFO - __main__ - Step 900 Global step 900 Train loss 0.08 on epoch=112
05/22/2022 21:56:56 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.7887996031746032 on epoch=112
05/22/2022 21:56:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=113
05/22/2022 21:57:01 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=114
05/22/2022 21:57:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.09 on epoch=116
05/22/2022 21:57:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.16 on epoch=117
05/22/2022 21:57:08 - INFO - __main__ - Step 950 Global step 950 Train loss 0.15 on epoch=118
05/22/2022 21:57:10 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.6233722260537338 on epoch=118
05/22/2022 21:57:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=119
05/22/2022 21:57:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=121
05/22/2022 21:57:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.07 on epoch=122
05/22/2022 21:57:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.05 on epoch=123
05/22/2022 21:57:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=124
05/22/2022 21:57:24 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.6291571374118543 on epoch=124
05/22/2022 21:57:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.05 on epoch=126
05/22/2022 21:57:29 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=127
05/22/2022 21:57:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=128
05/22/2022 21:57:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=129
05/22/2022 21:57:36 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=131
05/22/2022 21:57:38 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.783336827246936 on epoch=131
05/22/2022 21:57:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.08 on epoch=132
05/22/2022 21:57:43 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=133
05/22/2022 21:57:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=134
05/22/2022 21:57:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.06 on epoch=136
05/22/2022 21:57:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=137
05/22/2022 21:57:52 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.8003266522522416 on epoch=137
05/22/2022 21:57:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=138
05/22/2022 21:57:57 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=139
05/22/2022 21:58:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.09 on epoch=141
05/22/2022 21:58:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.04 on epoch=142
05/22/2022 21:58:04 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=143
05/22/2022 21:58:06 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.8095105207892445 on epoch=143
05/22/2022 21:58:06 - INFO - __main__ - Saving model with best Classification-F1: 0.805123491704374 -> 0.8095105207892445 on epoch=143, global_step=1150
05/22/2022 21:58:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=144
05/22/2022 21:58:11 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=146
05/22/2022 21:58:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=147
05/22/2022 21:58:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=148
05/22/2022 21:58:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.02 on epoch=149
05/22/2022 21:58:20 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.784421196185902 on epoch=149
05/22/2022 21:58:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=151
05/22/2022 21:58:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.07 on epoch=152
05/22/2022 21:58:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=153
05/22/2022 21:58:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=154
05/22/2022 21:58:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=156
05/22/2022 21:58:35 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.809264891513342 on epoch=156
05/22/2022 21:58:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=157
05/22/2022 21:58:39 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=158
05/22/2022 21:58:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.03 on epoch=159
05/22/2022 21:58:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.02 on epoch=161
05/22/2022 21:58:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.05 on epoch=162
05/22/2022 21:58:49 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.8089591567852437 on epoch=162
05/22/2022 21:58:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=163
05/22/2022 21:58:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=164
05/22/2022 21:58:56 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=166
05/22/2022 21:58:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=167
05/22/2022 21:59:01 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=168
05/22/2022 21:59:03 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.7124073370695647 on epoch=168
05/22/2022 21:59:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=169
05/22/2022 21:59:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=171
05/22/2022 21:59:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=172
05/22/2022 21:59:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=173
05/22/2022 21:59:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.02 on epoch=174
05/22/2022 21:59:17 - INFO - __main__ - Global step 1400 Train loss 0.03 Classification-F1 0.7546513030888031 on epoch=174
05/22/2022 21:59:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=176
05/22/2022 21:59:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.06 on epoch=177
05/22/2022 21:59:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=178
05/22/2022 21:59:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=179
05/22/2022 21:59:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=181
05/22/2022 21:59:32 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.800697389702139 on epoch=181
05/22/2022 21:59:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=182
05/22/2022 21:59:36 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=183
05/22/2022 21:59:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=184
05/22/2022 21:59:41 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.01 on epoch=186
05/22/2022 21:59:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=187
05/22/2022 21:59:46 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.7818654311039485 on epoch=187
05/22/2022 21:59:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=188
05/22/2022 21:59:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=189
05/22/2022 21:59:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=191
05/22/2022 21:59:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=192
05/22/2022 21:59:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=193
05/22/2022 22:00:00 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.7861716899452749 on epoch=193
05/22/2022 22:00:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.03 on epoch=194
05/22/2022 22:00:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=196
05/22/2022 22:00:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=197
05/22/2022 22:00:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=198
05/22/2022 22:00:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=199
05/22/2022 22:00:14 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.774252027533565 on epoch=199
05/22/2022 22:00:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=201
05/22/2022 22:00:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=202
05/22/2022 22:00:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.01 on epoch=203
05/22/2022 22:00:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=204
05/22/2022 22:00:26 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=206
05/22/2022 22:00:28 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.79109477124183 on epoch=206
05/22/2022 22:00:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.02 on epoch=207
05/22/2022 22:00:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=208
05/22/2022 22:00:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.01 on epoch=209
05/22/2022 22:00:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.01 on epoch=211
05/22/2022 22:00:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
05/22/2022 22:00:43 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.739615921207961 on epoch=212
05/22/2022 22:00:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=213
05/22/2022 22:00:48 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.00 on epoch=214
05/22/2022 22:00:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=216
05/22/2022 22:00:53 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=217
05/22/2022 22:00:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=218
05/22/2022 22:00:57 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.8092240571113811 on epoch=218
05/22/2022 22:00:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=219
05/22/2022 22:01:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=221
05/22/2022 22:01:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=222
05/22/2022 22:01:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=223
05/22/2022 22:01:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=224
05/22/2022 22:01:11 - INFO - __main__ - Global step 1800 Train loss 0.02 Classification-F1 0.7985760301058809 on epoch=224
05/22/2022 22:01:14 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=226
05/22/2022 22:01:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=227
05/22/2022 22:01:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.04 on epoch=228
05/22/2022 22:01:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=229
05/22/2022 22:01:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=231
05/22/2022 22:01:25 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7866210032996893 on epoch=231
05/22/2022 22:01:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.01 on epoch=232
05/22/2022 22:01:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=233
05/22/2022 22:01:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
05/22/2022 22:01:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=236
05/22/2022 22:01:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=237
05/22/2022 22:01:40 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.7934252676900992 on epoch=237
05/22/2022 22:01:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=238
05/22/2022 22:01:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=239
05/22/2022 22:01:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.04 on epoch=241
05/22/2022 22:01:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.01 on epoch=242
05/22/2022 22:01:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=243
05/22/2022 22:01:54 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.8088911088911089 on epoch=243
05/22/2022 22:01:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.09 on epoch=244
05/22/2022 22:01:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=246
05/22/2022 22:02:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=247
05/22/2022 22:02:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
05/22/2022 22:02:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=249
05/22/2022 22:02:08 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7876654701278927 on epoch=249
05/22/2022 22:02:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=251
05/22/2022 22:02:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=252
05/22/2022 22:02:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
05/22/2022 22:02:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=254
05/22/2022 22:02:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.01 on epoch=256
05/22/2022 22:02:22 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.8089591567852437 on epoch=256
05/22/2022 22:02:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.00 on epoch=257
05/22/2022 22:02:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=258
05/22/2022 22:02:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=259
05/22/2022 22:02:33 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=261
05/22/2022 22:02:35 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=262
05/22/2022 22:02:37 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8018202861952861 on epoch=262
05/22/2022 22:02:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.00 on epoch=263
05/22/2022 22:02:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.11 on epoch=264
05/22/2022 22:02:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=266
05/22/2022 22:02:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=267
05/22/2022 22:02:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=268
05/22/2022 22:02:51 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.8170148155357637 on epoch=268
05/22/2022 22:02:51 - INFO - __main__ - Saving model with best Classification-F1: 0.8095105207892445 -> 0.8170148155357637 on epoch=268, global_step=2150
05/22/2022 22:02:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.00 on epoch=269
05/22/2022 22:02:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
05/22/2022 22:02:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
05/22/2022 22:03:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=273
05/22/2022 22:03:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=274
05/22/2022 22:03:05 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8005381806294125 on epoch=274
05/22/2022 22:03:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.00 on epoch=276
05/22/2022 22:03:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=277
05/22/2022 22:03:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
05/22/2022 22:03:14 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=279
05/22/2022 22:03:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=281
05/22/2022 22:03:19 - INFO - __main__ - Global step 2250 Train loss 0.01 Classification-F1 0.8174235446196689 on epoch=281
05/22/2022 22:03:19 - INFO - __main__ - Saving model with best Classification-F1: 0.8170148155357637 -> 0.8174235446196689 on epoch=281, global_step=2250
05/22/2022 22:03:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=282
05/22/2022 22:03:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=283
05/22/2022 22:03:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.03 on epoch=284
05/22/2022 22:03:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
05/22/2022 22:03:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
05/22/2022 22:03:33 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8003477878295921 on epoch=287
05/22/2022 22:03:35 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.00 on epoch=288
05/22/2022 22:03:38 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=289
05/22/2022 22:03:40 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
05/22/2022 22:03:42 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.00 on epoch=292
05/22/2022 22:03:45 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=293
05/22/2022 22:03:47 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7942663817663816 on epoch=293
05/22/2022 22:03:49 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
05/22/2022 22:03:52 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.00 on epoch=296
05/22/2022 22:03:54 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.00 on epoch=297
05/22/2022 22:03:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 22:03:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
05/22/2022 22:04:01 - INFO - __main__ - Global step 2400 Train loss 0.01 Classification-F1 0.8014189514189515 on epoch=299
05/22/2022 22:04:03 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
05/22/2022 22:04:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=302
05/22/2022 22:04:08 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
05/22/2022 22:04:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
05/22/2022 22:04:13 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 22:04:15 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.7957417582417582 on epoch=306
05/22/2022 22:04:17 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=307
05/22/2022 22:04:20 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=308
05/22/2022 22:04:22 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=309
05/22/2022 22:04:25 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.00 on epoch=311
05/22/2022 22:04:27 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=312
05/22/2022 22:04:29 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7892552482918639 on epoch=312
05/22/2022 22:04:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=313
05/22/2022 22:04:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=314
05/22/2022 22:04:36 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.06 on epoch=316
05/22/2022 22:04:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=317
05/22/2022 22:04:41 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=318
05/22/2022 22:04:43 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8033986175115208 on epoch=318
05/22/2022 22:04:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=319
05/22/2022 22:04:48 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.00 on epoch=321
05/22/2022 22:04:50 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=322
05/22/2022 22:04:53 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
05/22/2022 22:04:55 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=324
05/22/2022 22:04:58 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.817982017982018 on epoch=324
05/22/2022 22:04:58 - INFO - __main__ - Saving model with best Classification-F1: 0.8174235446196689 -> 0.817982017982018 on epoch=324, global_step=2600
05/22/2022 22:05:00 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=326
05/22/2022 22:05:03 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=327
05/22/2022 22:05:05 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=328
05/22/2022 22:05:08 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=329
05/22/2022 22:05:10 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
05/22/2022 22:05:12 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.8115911418330773 on epoch=331
05/22/2022 22:05:15 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=332
05/22/2022 22:05:17 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 22:05:20 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=334
05/22/2022 22:05:22 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.06 on epoch=336
05/22/2022 22:05:24 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=337
05/22/2022 22:05:27 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7970078200966898 on epoch=337
05/22/2022 22:05:29 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 22:05:32 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
05/22/2022 22:05:34 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=341
05/22/2022 22:05:37 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=342
05/22/2022 22:05:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=343
05/22/2022 22:05:41 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.7893859334151787 on epoch=343
05/22/2022 22:05:44 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 22:05:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=346
05/22/2022 22:05:49 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=347
05/22/2022 22:05:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=348
05/22/2022 22:05:54 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 22:05:56 - INFO - __main__ - Global step 2800 Train loss 0.00 Classification-F1 0.7961138478379857 on epoch=349
05/22/2022 22:05:58 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=351
05/22/2022 22:06:01 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=352
05/22/2022 22:06:03 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
05/22/2022 22:06:06 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=354
05/22/2022 22:06:08 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=356
05/22/2022 22:06:10 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.787057387057387 on epoch=356
05/22/2022 22:06:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
05/22/2022 22:06:15 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=358
05/22/2022 22:06:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 22:06:20 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 22:06:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.00 on epoch=362
05/22/2022 22:06:25 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.7942249456333963 on epoch=362
05/22/2022 22:06:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.00 on epoch=363
05/22/2022 22:06:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=364
05/22/2022 22:06:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.00 on epoch=366
05/22/2022 22:06:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=367
05/22/2022 22:06:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
05/22/2022 22:06:40 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.7837872839438215 on epoch=368
05/22/2022 22:06:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
05/22/2022 22:06:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.00 on epoch=371
05/22/2022 22:06:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.00 on epoch=372
05/22/2022 22:06:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=373
05/22/2022 22:06:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=374
05/22/2022 22:06:54 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:06:54 - INFO - __main__ - Printing 3 examples
05/22/2022 22:06:54 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:06:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:06:54 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:06:54 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:06:54 - INFO - __main__ - Printing 3 examples
05/22/2022 22:06:54 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:06:54 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:06:54 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:06:54 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.8074337687720969 on epoch=374
05/22/2022 22:06:54 - INFO - __main__ - save last model!
05/22/2022 22:06:54 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 22:06:54 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 22:06:54 - INFO - __main__ - Printing 3 examples
05/22/2022 22:06:54 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 22:06:54 - INFO - __main__ - ['others']
05/22/2022 22:06:54 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:06:56 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:07:02 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 22:07:12 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:07:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:07:13 - INFO - __main__ - Starting training!
05/22/2022 22:08:21 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_87_0.5_8_predictions.txt
05/22/2022 22:08:21 - INFO - __main__ - Classification-F1 on test data: 0.2907
05/22/2022 22:08:21 - INFO - __main__ - prefix=emo_32_87, lr=0.5, bsz=8, dev_performance=0.817982017982018, test_performance=0.29067143694909564
05/22/2022 22:08:21 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.4, bsz=8 ...
05/22/2022 22:08:22 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:08:22 - INFO - __main__ - Printing 3 examples
05/22/2022 22:08:22 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:08:22 - INFO - __main__ - ['others']
05/22/2022 22:08:22 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:08:22 - INFO - __main__ - ['others']
05/22/2022 22:08:22 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:08:22 - INFO - __main__ - ['others']
05/22/2022 22:08:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:08:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:08:23 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:08:23 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:08:23 - INFO - __main__ - Printing 3 examples
05/22/2022 22:08:23 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:08:23 - INFO - __main__ - ['others']
05/22/2022 22:08:23 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:08:23 - INFO - __main__ - ['others']
05/22/2022 22:08:23 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:08:23 - INFO - __main__ - ['others']
05/22/2022 22:08:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:08:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:08:23 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:08:41 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:08:42 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:08:42 - INFO - __main__ - Starting training!
05/22/2022 22:08:45 - INFO - __main__ - Step 10 Global step 10 Train loss 4.01 on epoch=1
05/22/2022 22:08:48 - INFO - __main__ - Step 20 Global step 20 Train loss 2.78 on epoch=2
05/22/2022 22:08:50 - INFO - __main__ - Step 30 Global step 30 Train loss 2.29 on epoch=3
05/22/2022 22:08:53 - INFO - __main__ - Step 40 Global step 40 Train loss 1.99 on epoch=4
05/22/2022 22:08:55 - INFO - __main__ - Step 50 Global step 50 Train loss 1.66 on epoch=6
05/22/2022 22:08:57 - INFO - __main__ - Global step 50 Train loss 2.55 Classification-F1 0.15903637711144736 on epoch=6
05/22/2022 22:08:57 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.15903637711144736 on epoch=6, global_step=50
05/22/2022 22:09:00 - INFO - __main__ - Step 60 Global step 60 Train loss 1.43 on epoch=7
05/22/2022 22:09:02 - INFO - __main__ - Step 70 Global step 70 Train loss 1.25 on epoch=8
05/22/2022 22:09:05 - INFO - __main__ - Step 80 Global step 80 Train loss 1.00 on epoch=9
05/22/2022 22:09:07 - INFO - __main__ - Step 90 Global step 90 Train loss 0.96 on epoch=11
05/22/2022 22:09:10 - INFO - __main__ - Step 100 Global step 100 Train loss 0.82 on epoch=12
05/22/2022 22:09:11 - INFO - __main__ - Global step 100 Train loss 1.09 Classification-F1 0.4119426772058351 on epoch=12
05/22/2022 22:09:11 - INFO - __main__ - Saving model with best Classification-F1: 0.15903637711144736 -> 0.4119426772058351 on epoch=12, global_step=100
05/22/2022 22:09:14 - INFO - __main__ - Step 110 Global step 110 Train loss 0.79 on epoch=13
05/22/2022 22:09:16 - INFO - __main__ - Step 120 Global step 120 Train loss 0.76 on epoch=14
05/22/2022 22:09:19 - INFO - __main__ - Step 130 Global step 130 Train loss 0.69 on epoch=16
05/22/2022 22:09:21 - INFO - __main__ - Step 140 Global step 140 Train loss 0.69 on epoch=17
05/22/2022 22:09:24 - INFO - __main__ - Step 150 Global step 150 Train loss 0.71 on epoch=18
05/22/2022 22:09:26 - INFO - __main__ - Global step 150 Train loss 0.73 Classification-F1 0.5459495751162418 on epoch=18
05/22/2022 22:09:26 - INFO - __main__ - Saving model with best Classification-F1: 0.4119426772058351 -> 0.5459495751162418 on epoch=18, global_step=150
05/22/2022 22:09:28 - INFO - __main__ - Step 160 Global step 160 Train loss 0.54 on epoch=19
05/22/2022 22:09:31 - INFO - __main__ - Step 170 Global step 170 Train loss 0.60 on epoch=21
05/22/2022 22:09:33 - INFO - __main__ - Step 180 Global step 180 Train loss 0.53 on epoch=22
05/22/2022 22:09:36 - INFO - __main__ - Step 190 Global step 190 Train loss 0.59 on epoch=23
05/22/2022 22:09:38 - INFO - __main__ - Step 200 Global step 200 Train loss 0.51 on epoch=24
05/22/2022 22:09:40 - INFO - __main__ - Global step 200 Train loss 0.55 Classification-F1 0.5498411070530328 on epoch=24
05/22/2022 22:09:40 - INFO - __main__ - Saving model with best Classification-F1: 0.5459495751162418 -> 0.5498411070530328 on epoch=24, global_step=200
05/22/2022 22:09:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.53 on epoch=26
05/22/2022 22:09:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.59 on epoch=27
05/22/2022 22:09:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.68 on epoch=28
05/22/2022 22:09:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.54 on epoch=29
05/22/2022 22:09:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.65 on epoch=31
05/22/2022 22:09:54 - INFO - __main__ - Global step 250 Train loss 0.60 Classification-F1 0.577176725051953 on epoch=31
05/22/2022 22:09:54 - INFO - __main__ - Saving model with best Classification-F1: 0.5498411070530328 -> 0.577176725051953 on epoch=31, global_step=250
05/22/2022 22:09:57 - INFO - __main__ - Step 260 Global step 260 Train loss 0.53 on epoch=32
05/22/2022 22:09:59 - INFO - __main__ - Step 270 Global step 270 Train loss 0.55 on epoch=33
05/22/2022 22:10:02 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=34
05/22/2022 22:10:04 - INFO - __main__ - Step 290 Global step 290 Train loss 0.47 on epoch=36
05/22/2022 22:10:07 - INFO - __main__ - Step 300 Global step 300 Train loss 0.46 on epoch=37
05/22/2022 22:10:09 - INFO - __main__ - Global step 300 Train loss 0.49 Classification-F1 0.5683853459972863 on epoch=37
05/22/2022 22:10:11 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=38
05/22/2022 22:10:14 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=39
05/22/2022 22:10:16 - INFO - __main__ - Step 330 Global step 330 Train loss 0.52 on epoch=41
05/22/2022 22:10:19 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=42
05/22/2022 22:10:21 - INFO - __main__ - Step 350 Global step 350 Train loss 0.48 on epoch=43
05/22/2022 22:10:23 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.650345640219953 on epoch=43
05/22/2022 22:10:23 - INFO - __main__ - Saving model with best Classification-F1: 0.577176725051953 -> 0.650345640219953 on epoch=43, global_step=350
05/22/2022 22:10:25 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=44
05/22/2022 22:10:28 - INFO - __main__ - Step 370 Global step 370 Train loss 0.38 on epoch=46
05/22/2022 22:10:30 - INFO - __main__ - Step 380 Global step 380 Train loss 0.45 on epoch=47
05/22/2022 22:10:33 - INFO - __main__ - Step 390 Global step 390 Train loss 0.36 on epoch=48
05/22/2022 22:10:35 - INFO - __main__ - Step 400 Global step 400 Train loss 0.42 on epoch=49
05/22/2022 22:10:37 - INFO - __main__ - Global step 400 Train loss 0.41 Classification-F1 0.6507222601959444 on epoch=49
05/22/2022 22:10:37 - INFO - __main__ - Saving model with best Classification-F1: 0.650345640219953 -> 0.6507222601959444 on epoch=49, global_step=400
05/22/2022 22:10:40 - INFO - __main__ - Step 410 Global step 410 Train loss 0.38 on epoch=51
05/22/2022 22:10:42 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=52
05/22/2022 22:10:45 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=53
05/22/2022 22:10:47 - INFO - __main__ - Step 440 Global step 440 Train loss 0.35 on epoch=54
05/22/2022 22:10:50 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=56
05/22/2022 22:10:51 - INFO - __main__ - Global step 450 Train loss 0.37 Classification-F1 0.6616022894503907 on epoch=56
05/22/2022 22:10:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6507222601959444 -> 0.6616022894503907 on epoch=56, global_step=450
05/22/2022 22:10:54 - INFO - __main__ - Step 460 Global step 460 Train loss 0.44 on epoch=57
05/22/2022 22:10:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=58
05/22/2022 22:10:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.31 on epoch=59
05/22/2022 22:11:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=61
05/22/2022 22:11:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=62
05/22/2022 22:11:05 - INFO - __main__ - Global step 500 Train loss 0.38 Classification-F1 0.684188648058324 on epoch=62
05/22/2022 22:11:05 - INFO - __main__ - Saving model with best Classification-F1: 0.6616022894503907 -> 0.684188648058324 on epoch=62, global_step=500
05/22/2022 22:11:08 - INFO - __main__ - Step 510 Global step 510 Train loss 0.36 on epoch=63
05/22/2022 22:11:10 - INFO - __main__ - Step 520 Global step 520 Train loss 0.32 on epoch=64
05/22/2022 22:11:13 - INFO - __main__ - Step 530 Global step 530 Train loss 0.45 on epoch=66
05/22/2022 22:11:15 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=67
05/22/2022 22:11:18 - INFO - __main__ - Step 550 Global step 550 Train loss 0.34 on epoch=68
05/22/2022 22:11:20 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.7079991087344027 on epoch=68
05/22/2022 22:11:20 - INFO - __main__ - Saving model with best Classification-F1: 0.684188648058324 -> 0.7079991087344027 on epoch=68, global_step=550
05/22/2022 22:11:22 - INFO - __main__ - Step 560 Global step 560 Train loss 0.39 on epoch=69
05/22/2022 22:11:25 - INFO - __main__ - Step 570 Global step 570 Train loss 0.27 on epoch=71
05/22/2022 22:11:27 - INFO - __main__ - Step 580 Global step 580 Train loss 0.31 on epoch=72
05/22/2022 22:11:30 - INFO - __main__ - Step 590 Global step 590 Train loss 0.26 on epoch=73
05/22/2022 22:11:32 - INFO - __main__ - Step 600 Global step 600 Train loss 0.31 on epoch=74
05/22/2022 22:11:34 - INFO - __main__ - Global step 600 Train loss 0.31 Classification-F1 0.6353070458952812 on epoch=74
05/22/2022 22:11:36 - INFO - __main__ - Step 610 Global step 610 Train loss 0.33 on epoch=76
05/22/2022 22:11:39 - INFO - __main__ - Step 620 Global step 620 Train loss 0.28 on epoch=77
05/22/2022 22:11:41 - INFO - __main__ - Step 630 Global step 630 Train loss 0.31 on epoch=78
05/22/2022 22:11:44 - INFO - __main__ - Step 640 Global step 640 Train loss 0.23 on epoch=79
05/22/2022 22:11:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=81
05/22/2022 22:11:48 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.741190149120339 on epoch=81
05/22/2022 22:11:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7079991087344027 -> 0.741190149120339 on epoch=81, global_step=650
05/22/2022 22:11:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=82
05/22/2022 22:11:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=83
05/22/2022 22:11:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.32 on epoch=84
05/22/2022 22:11:58 - INFO - __main__ - Step 690 Global step 690 Train loss 0.30 on epoch=86
05/22/2022 22:12:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=87
05/22/2022 22:12:02 - INFO - __main__ - Global step 700 Train loss 0.27 Classification-F1 0.7482411138792104 on epoch=87
05/22/2022 22:12:02 - INFO - __main__ - Saving model with best Classification-F1: 0.741190149120339 -> 0.7482411138792104 on epoch=87, global_step=700
05/22/2022 22:12:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=88
05/22/2022 22:12:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=89
05/22/2022 22:12:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.31 on epoch=91
05/22/2022 22:12:12 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=92
05/22/2022 22:12:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.19 on epoch=93
05/22/2022 22:12:17 - INFO - __main__ - Global step 750 Train loss 0.23 Classification-F1 0.7760171418119105 on epoch=93
05/22/2022 22:12:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7482411138792104 -> 0.7760171418119105 on epoch=93, global_step=750
05/22/2022 22:12:19 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=94
05/22/2022 22:12:22 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=96
05/22/2022 22:12:24 - INFO - __main__ - Step 780 Global step 780 Train loss 0.22 on epoch=97
05/22/2022 22:12:27 - INFO - __main__ - Step 790 Global step 790 Train loss 0.20 on epoch=98
05/22/2022 22:12:29 - INFO - __main__ - Step 800 Global step 800 Train loss 0.25 on epoch=99
05/22/2022 22:12:31 - INFO - __main__ - Global step 800 Train loss 0.21 Classification-F1 0.7616983413083542 on epoch=99
05/22/2022 22:12:33 - INFO - __main__ - Step 810 Global step 810 Train loss 0.23 on epoch=101
05/22/2022 22:12:36 - INFO - __main__ - Step 820 Global step 820 Train loss 0.23 on epoch=102
05/22/2022 22:12:38 - INFO - __main__ - Step 830 Global step 830 Train loss 0.22 on epoch=103
05/22/2022 22:12:41 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=104
05/22/2022 22:12:43 - INFO - __main__ - Step 850 Global step 850 Train loss 0.16 on epoch=106
05/22/2022 22:12:45 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7561395126612519 on epoch=106
05/22/2022 22:12:47 - INFO - __main__ - Step 860 Global step 860 Train loss 0.36 on epoch=107
05/22/2022 22:12:50 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=108
05/22/2022 22:12:52 - INFO - __main__ - Step 880 Global step 880 Train loss 0.14 on epoch=109
05/22/2022 22:12:55 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=111
05/22/2022 22:12:57 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=112
05/22/2022 22:12:59 - INFO - __main__ - Global step 900 Train loss 0.20 Classification-F1 0.7730477551452465 on epoch=112
05/22/2022 22:13:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.20 on epoch=113
05/22/2022 22:13:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=114
05/22/2022 22:13:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=116
05/22/2022 22:13:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=117
05/22/2022 22:13:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=118
05/22/2022 22:13:13 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.7691907311269739 on epoch=118
05/22/2022 22:13:16 - INFO - __main__ - Step 960 Global step 960 Train loss 0.14 on epoch=119
05/22/2022 22:13:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.14 on epoch=121
05/22/2022 22:13:21 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=122
05/22/2022 22:13:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.10 on epoch=123
05/22/2022 22:13:26 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=124
05/22/2022 22:13:28 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.807821707278229 on epoch=124
05/22/2022 22:13:28 - INFO - __main__ - Saving model with best Classification-F1: 0.7760171418119105 -> 0.807821707278229 on epoch=124, global_step=1000
05/22/2022 22:13:30 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=126
05/22/2022 22:13:33 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.16 on epoch=127
05/22/2022 22:13:35 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.19 on epoch=128
05/22/2022 22:13:38 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.15 on epoch=129
05/22/2022 22:13:40 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=131
05/22/2022 22:13:42 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.7862976176386047 on epoch=131
05/22/2022 22:13:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=132
05/22/2022 22:13:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.11 on epoch=133
05/22/2022 22:13:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=134
05/22/2022 22:13:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.17 on epoch=136
05/22/2022 22:13:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.12 on epoch=137
05/22/2022 22:13:56 - INFO - __main__ - Global step 1100 Train loss 0.11 Classification-F1 0.7790468006451406 on epoch=137
05/22/2022 22:13:58 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=138
05/22/2022 22:14:01 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=139
05/22/2022 22:14:03 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=141
05/22/2022 22:14:06 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.10 on epoch=142
05/22/2022 22:14:08 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=143
05/22/2022 22:14:10 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.7786454658688059 on epoch=143
05/22/2022 22:14:13 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.14 on epoch=144
05/22/2022 22:14:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=146
05/22/2022 22:14:18 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=147
05/22/2022 22:14:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=148
05/22/2022 22:14:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=149
05/22/2022 22:14:24 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7620229941291585 on epoch=149
05/22/2022 22:14:27 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=151
05/22/2022 22:14:29 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=152
05/22/2022 22:14:32 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.12 on epoch=153
05/22/2022 22:14:34 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.11 on epoch=154
05/22/2022 22:14:37 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.14 on epoch=156
05/22/2022 22:14:38 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.7745035718948762 on epoch=156
05/22/2022 22:14:41 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=157
05/22/2022 22:14:43 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=158
05/22/2022 22:14:46 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=159
05/22/2022 22:14:48 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=161
05/22/2022 22:14:51 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.10 on epoch=162
05/22/2022 22:14:53 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7791403095498923 on epoch=162
05/22/2022 22:14:55 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=163
05/22/2022 22:14:58 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=164
05/22/2022 22:15:00 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=166
05/22/2022 22:15:03 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=167
05/22/2022 22:15:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=168
05/22/2022 22:15:07 - INFO - __main__ - Global step 1350 Train loss 0.08 Classification-F1 0.7714725360018715 on epoch=168
05/22/2022 22:15:09 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=169
05/22/2022 22:15:12 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=171
05/22/2022 22:15:14 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=172
05/22/2022 22:15:17 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=173
05/22/2022 22:15:19 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=174
05/22/2022 22:15:21 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7885110663983903 on epoch=174
05/22/2022 22:15:24 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=176
05/22/2022 22:15:26 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.10 on epoch=177
05/22/2022 22:15:29 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.10 on epoch=178
05/22/2022 22:15:31 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=179
05/22/2022 22:15:34 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=181
05/22/2022 22:15:35 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.7839266113452757 on epoch=181
05/22/2022 22:15:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=182
05/22/2022 22:15:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=183
05/22/2022 22:15:43 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=184
05/22/2022 22:15:45 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.12 on epoch=186
05/22/2022 22:15:48 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.10 on epoch=187
05/22/2022 22:15:50 - INFO - __main__ - Global step 1500 Train loss 0.11 Classification-F1 0.7890629968203499 on epoch=187
05/22/2022 22:15:52 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.06 on epoch=188
05/22/2022 22:15:55 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=189
05/22/2022 22:15:57 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=191
05/22/2022 22:16:00 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=192
05/22/2022 22:16:02 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=193
05/22/2022 22:16:04 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.7694852941176471 on epoch=193
05/22/2022 22:16:06 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=194
05/22/2022 22:16:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.02 on epoch=196
05/22/2022 22:16:11 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=197
05/22/2022 22:16:14 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.07 on epoch=198
05/22/2022 22:16:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=199
05/22/2022 22:16:18 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.8053078937039415 on epoch=199
05/22/2022 22:16:21 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=201
05/22/2022 22:16:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.02 on epoch=202
05/22/2022 22:16:26 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=203
05/22/2022 22:16:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=204
05/22/2022 22:16:31 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=206
05/22/2022 22:16:33 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.7906842044402977 on epoch=206
05/22/2022 22:16:35 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=207
05/22/2022 22:16:37 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.02 on epoch=208
05/22/2022 22:16:40 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=209
05/22/2022 22:16:42 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
05/22/2022 22:16:45 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=212
05/22/2022 22:16:47 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7861554724629578 on epoch=212
05/22/2022 22:16:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=213
05/22/2022 22:16:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=214
05/22/2022 22:16:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=216
05/22/2022 22:16:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=217
05/22/2022 22:16:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=218
05/22/2022 22:17:01 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.7692763537385536 on epoch=218
05/22/2022 22:17:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=219
05/22/2022 22:17:06 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=221
05/22/2022 22:17:09 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=222
05/22/2022 22:17:11 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=223
05/22/2022 22:17:14 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=224
05/22/2022 22:17:16 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.815637303872598 on epoch=224
05/22/2022 22:17:16 - INFO - __main__ - Saving model with best Classification-F1: 0.807821707278229 -> 0.815637303872598 on epoch=224, global_step=1800
05/22/2022 22:17:18 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=226
05/22/2022 22:17:21 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=227
05/22/2022 22:17:23 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=228
05/22/2022 22:17:26 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=229
05/22/2022 22:17:28 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
05/22/2022 22:17:30 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7532485245251201 on epoch=231
05/22/2022 22:17:32 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.11 on epoch=232
05/22/2022 22:17:35 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=233
05/22/2022 22:17:37 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=234
05/22/2022 22:17:40 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=236
05/22/2022 22:17:42 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.01 on epoch=237
05/22/2022 22:17:44 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7787590187590188 on epoch=237
05/22/2022 22:17:47 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=238
05/22/2022 22:17:49 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=239
05/22/2022 22:17:52 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
05/22/2022 22:17:54 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=242
05/22/2022 22:17:57 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=243
05/22/2022 22:17:59 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.7722817197054259 on epoch=243
05/22/2022 22:18:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.08 on epoch=244
05/22/2022 22:18:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=246
05/22/2022 22:18:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=247
05/22/2022 22:18:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.01 on epoch=248
05/22/2022 22:18:11 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=249
05/22/2022 22:18:13 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.7742975264522458 on epoch=249
05/22/2022 22:18:15 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=251
05/22/2022 22:18:18 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=252
05/22/2022 22:18:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=253
05/22/2022 22:18:23 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=254
05/22/2022 22:18:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=256
05/22/2022 22:18:27 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.7531206203479203 on epoch=256
05/22/2022 22:18:30 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=257
05/22/2022 22:18:32 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=258
05/22/2022 22:18:35 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=259
05/22/2022 22:18:37 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=261
05/22/2022 22:18:40 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=262
05/22/2022 22:18:41 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.7480599165341812 on epoch=262
05/22/2022 22:18:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=263
05/22/2022 22:18:46 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=264
05/22/2022 22:18:49 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=266
05/22/2022 22:18:51 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.05 on epoch=267
05/22/2022 22:18:54 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=268
05/22/2022 22:18:56 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.7767570227730013 on epoch=268
05/22/2022 22:18:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=269
05/22/2022 22:19:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=271
05/22/2022 22:19:03 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
05/22/2022 22:19:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=273
05/22/2022 22:19:08 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=274
05/22/2022 22:19:10 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7699768204432385 on epoch=274
05/22/2022 22:19:13 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 22:19:15 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=277
05/22/2022 22:19:18 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=278
05/22/2022 22:19:20 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=279
05/22/2022 22:19:23 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.06 on epoch=281
05/22/2022 22:19:24 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7672621739785919 on epoch=281
05/22/2022 22:19:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=282
05/22/2022 22:19:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=283
05/22/2022 22:19:32 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=284
05/22/2022 22:19:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=286
05/22/2022 22:19:37 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=287
05/22/2022 22:19:39 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7529775626103228 on epoch=287
05/22/2022 22:19:41 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=288
05/22/2022 22:19:44 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=289
05/22/2022 22:19:46 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.00 on epoch=291
05/22/2022 22:19:49 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
05/22/2022 22:19:51 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=293
05/22/2022 22:19:53 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.7828835306514598 on epoch=293
05/22/2022 22:19:55 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=294
05/22/2022 22:19:58 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=296
05/22/2022 22:20:00 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.09 on epoch=297
05/22/2022 22:20:03 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.00 on epoch=298
05/22/2022 22:20:05 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=299
05/22/2022 22:20:07 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7995475113122172 on epoch=299
05/22/2022 22:20:10 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=301
05/22/2022 22:20:12 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=302
05/22/2022 22:20:15 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=303
05/22/2022 22:20:17 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=304
05/22/2022 22:20:20 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.11 on epoch=306
05/22/2022 22:20:21 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7723432043027803 on epoch=306
05/22/2022 22:20:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=307
05/22/2022 22:20:26 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=308
05/22/2022 22:20:29 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=309
05/22/2022 22:20:31 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=311
05/22/2022 22:20:34 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=312
05/22/2022 22:20:36 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7651562654047126 on epoch=312
05/22/2022 22:20:38 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=313
05/22/2022 22:20:41 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
05/22/2022 22:20:43 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=316
05/22/2022 22:20:46 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
05/22/2022 22:20:48 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=318
05/22/2022 22:20:50 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.7626437071399758 on epoch=318
05/22/2022 22:20:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=319
05/22/2022 22:20:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=321
05/22/2022 22:20:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=322
05/22/2022 22:21:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=323
05/22/2022 22:21:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
05/22/2022 22:21:04 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7753178847296494 on epoch=324
05/22/2022 22:21:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.00 on epoch=326
05/22/2022 22:21:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=327
05/22/2022 22:21:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=328
05/22/2022 22:21:14 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=329
05/22/2022 22:21:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=331
05/22/2022 22:21:19 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7828762437810945 on epoch=331
05/22/2022 22:21:21 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=332
05/22/2022 22:21:24 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=333
05/22/2022 22:21:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=334
05/22/2022 22:21:29 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.05 on epoch=336
05/22/2022 22:21:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.06 on epoch=337
05/22/2022 22:21:33 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7626437071399758 on epoch=337
05/22/2022 22:21:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 22:21:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=339
05/22/2022 22:21:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=341
05/22/2022 22:21:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=342
05/22/2022 22:21:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=343
05/22/2022 22:21:47 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.7730799706246134 on epoch=343
05/22/2022 22:21:50 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=344
05/22/2022 22:21:52 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=346
05/22/2022 22:21:55 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=347
05/22/2022 22:21:57 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=348
05/22/2022 22:22:00 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.00 on epoch=349
05/22/2022 22:22:02 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.7828762437810945 on epoch=349
05/22/2022 22:22:04 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=351
05/22/2022 22:22:07 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 22:22:09 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.00 on epoch=353
05/22/2022 22:22:12 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
05/22/2022 22:22:14 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=356
05/22/2022 22:22:16 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7829148629148628 on epoch=356
05/22/2022 22:22:19 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=357
05/22/2022 22:22:21 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=358
05/22/2022 22:22:24 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
05/22/2022 22:22:26 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=361
05/22/2022 22:22:29 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=362
05/22/2022 22:22:30 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7829148629148628 on epoch=362
05/22/2022 22:22:33 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 22:22:35 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=364
05/22/2022 22:22:38 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
05/22/2022 22:22:40 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=367
05/22/2022 22:22:43 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=368
05/22/2022 22:22:45 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7901903907496013 on epoch=368
05/22/2022 22:22:47 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=369
05/22/2022 22:22:50 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 22:22:52 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 22:22:55 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.00 on epoch=373
05/22/2022 22:22:57 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=374
05/22/2022 22:22:58 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:22:58 - INFO - __main__ - Printing 3 examples
05/22/2022 22:22:58 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:22:58 - INFO - __main__ - ['others']
05/22/2022 22:22:58 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:22:58 - INFO - __main__ - ['others']
05/22/2022 22:22:58 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:22:58 - INFO - __main__ - ['others']
05/22/2022 22:22:58 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:22:58 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:22:59 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:22:59 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:22:59 - INFO - __main__ - Printing 3 examples
05/22/2022 22:22:59 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:22:59 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:22:59 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:22:59 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7920997920997921 on epoch=374
05/22/2022 22:22:59 - INFO - __main__ - save last model!
05/22/2022 22:22:59 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 22:22:59 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 22:22:59 - INFO - __main__ - Printing 3 examples
05/22/2022 22:22:59 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 22:22:59 - INFO - __main__ - ['others']
05/22/2022 22:22:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:23:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:23:06 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 22:23:17 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:23:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:23:18 - INFO - __main__ - Starting training!
05/22/2022 22:24:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_87_0.4_8_predictions.txt
05/22/2022 22:24:23 - INFO - __main__ - Classification-F1 on test data: 0.2564
05/22/2022 22:24:24 - INFO - __main__ - prefix=emo_32_87, lr=0.4, bsz=8, dev_performance=0.815637303872598, test_performance=0.2564361171761002
05/22/2022 22:24:24 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.3, bsz=8 ...
05/22/2022 22:24:24 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:24:24 - INFO - __main__ - Printing 3 examples
05/22/2022 22:24:24 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:24:24 - INFO - __main__ - ['others']
05/22/2022 22:24:24 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:24:24 - INFO - __main__ - ['others']
05/22/2022 22:24:24 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:24:24 - INFO - __main__ - ['others']
05/22/2022 22:24:24 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:24:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:24:25 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:24:25 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:24:25 - INFO - __main__ - Printing 3 examples
05/22/2022 22:24:25 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:24:25 - INFO - __main__ - ['others']
05/22/2022 22:24:25 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:24:25 - INFO - __main__ - ['others']
05/22/2022 22:24:25 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:24:25 - INFO - __main__ - ['others']
05/22/2022 22:24:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:24:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:24:25 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:24:40 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:24:41 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:24:41 - INFO - __main__ - Starting training!
05/22/2022 22:24:44 - INFO - __main__ - Step 10 Global step 10 Train loss 4.17 on epoch=1
05/22/2022 22:24:46 - INFO - __main__ - Step 20 Global step 20 Train loss 3.06 on epoch=2
05/22/2022 22:24:49 - INFO - __main__ - Step 30 Global step 30 Train loss 2.70 on epoch=3
05/22/2022 22:24:51 - INFO - __main__ - Step 40 Global step 40 Train loss 2.21 on epoch=4
05/22/2022 22:24:54 - INFO - __main__ - Step 50 Global step 50 Train loss 1.95 on epoch=6
05/22/2022 22:24:56 - INFO - __main__ - Global step 50 Train loss 2.82 Classification-F1 0.014827418570734078 on epoch=6
05/22/2022 22:24:56 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.014827418570734078 on epoch=6, global_step=50
05/22/2022 22:24:58 - INFO - __main__ - Step 60 Global step 60 Train loss 1.77 on epoch=7
05/22/2022 22:25:00 - INFO - __main__ - Step 70 Global step 70 Train loss 1.47 on epoch=8
05/22/2022 22:25:03 - INFO - __main__ - Step 80 Global step 80 Train loss 1.41 on epoch=9
05/22/2022 22:25:05 - INFO - __main__ - Step 90 Global step 90 Train loss 1.11 on epoch=11
05/22/2022 22:25:07 - INFO - __main__ - Step 100 Global step 100 Train loss 0.98 on epoch=12
05/22/2022 22:25:09 - INFO - __main__ - Global step 100 Train loss 1.35 Classification-F1 0.4039554957237884 on epoch=12
05/22/2022 22:25:09 - INFO - __main__ - Saving model with best Classification-F1: 0.014827418570734078 -> 0.4039554957237884 on epoch=12, global_step=100
05/22/2022 22:25:12 - INFO - __main__ - Step 110 Global step 110 Train loss 0.90 on epoch=13
05/22/2022 22:25:14 - INFO - __main__ - Step 120 Global step 120 Train loss 0.91 on epoch=14
05/22/2022 22:25:16 - INFO - __main__ - Step 130 Global step 130 Train loss 0.84 on epoch=16
05/22/2022 22:25:19 - INFO - __main__ - Step 140 Global step 140 Train loss 0.74 on epoch=17
05/22/2022 22:25:21 - INFO - __main__ - Step 150 Global step 150 Train loss 0.80 on epoch=18
05/22/2022 22:25:23 - INFO - __main__ - Global step 150 Train loss 0.84 Classification-F1 0.4253910533910534 on epoch=18
05/22/2022 22:25:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4039554957237884 -> 0.4253910533910534 on epoch=18, global_step=150
05/22/2022 22:25:25 - INFO - __main__ - Step 160 Global step 160 Train loss 0.71 on epoch=19
05/22/2022 22:25:28 - INFO - __main__ - Step 170 Global step 170 Train loss 0.74 on epoch=21
05/22/2022 22:25:30 - INFO - __main__ - Step 180 Global step 180 Train loss 0.65 on epoch=22
05/22/2022 22:25:32 - INFO - __main__ - Step 190 Global step 190 Train loss 0.63 on epoch=23
05/22/2022 22:25:35 - INFO - __main__ - Step 200 Global step 200 Train loss 0.68 on epoch=24
05/22/2022 22:25:37 - INFO - __main__ - Global step 200 Train loss 0.68 Classification-F1 0.5285723878592533 on epoch=24
05/22/2022 22:25:37 - INFO - __main__ - Saving model with best Classification-F1: 0.4253910533910534 -> 0.5285723878592533 on epoch=24, global_step=200
05/22/2022 22:25:39 - INFO - __main__ - Step 210 Global step 210 Train loss 0.65 on epoch=26
05/22/2022 22:25:41 - INFO - __main__ - Step 220 Global step 220 Train loss 0.76 on epoch=27
05/22/2022 22:25:44 - INFO - __main__ - Step 230 Global step 230 Train loss 0.61 on epoch=28
05/22/2022 22:25:46 - INFO - __main__ - Step 240 Global step 240 Train loss 0.57 on epoch=29
05/22/2022 22:25:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=31
05/22/2022 22:25:50 - INFO - __main__ - Global step 250 Train loss 0.63 Classification-F1 0.5612699970940858 on epoch=31
05/22/2022 22:25:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5285723878592533 -> 0.5612699970940858 on epoch=31, global_step=250
05/22/2022 22:25:53 - INFO - __main__ - Step 260 Global step 260 Train loss 0.49 on epoch=32
05/22/2022 22:25:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.58 on epoch=33
05/22/2022 22:25:57 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=34
05/22/2022 22:26:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.53 on epoch=36
05/22/2022 22:26:02 - INFO - __main__ - Step 300 Global step 300 Train loss 0.52 on epoch=37
05/22/2022 22:26:04 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.5789907764907765 on epoch=37
05/22/2022 22:26:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5612699970940858 -> 0.5789907764907765 on epoch=37, global_step=300
05/22/2022 22:26:06 - INFO - __main__ - Step 310 Global step 310 Train loss 0.59 on epoch=38
05/22/2022 22:26:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.46 on epoch=39
05/22/2022 22:26:11 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=41
05/22/2022 22:26:13 - INFO - __main__ - Step 340 Global step 340 Train loss 0.44 on epoch=42
05/22/2022 22:26:16 - INFO - __main__ - Step 350 Global step 350 Train loss 0.49 on epoch=43
05/22/2022 22:26:18 - INFO - __main__ - Global step 350 Train loss 0.48 Classification-F1 0.6354675390716582 on epoch=43
05/22/2022 22:26:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5789907764907765 -> 0.6354675390716582 on epoch=43, global_step=350
05/22/2022 22:26:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=44
05/22/2022 22:26:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=46
05/22/2022 22:26:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.46 on epoch=47
05/22/2022 22:26:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.47 on epoch=48
05/22/2022 22:26:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=49
05/22/2022 22:26:31 - INFO - __main__ - Global step 400 Train loss 0.46 Classification-F1 0.6226329522436228 on epoch=49
05/22/2022 22:26:34 - INFO - __main__ - Step 410 Global step 410 Train loss 0.43 on epoch=51
05/22/2022 22:26:36 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=52
05/22/2022 22:26:38 - INFO - __main__ - Step 430 Global step 430 Train loss 0.49 on epoch=53
05/22/2022 22:26:41 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=54
05/22/2022 22:26:43 - INFO - __main__ - Step 450 Global step 450 Train loss 0.48 on epoch=56
05/22/2022 22:26:45 - INFO - __main__ - Global step 450 Train loss 0.45 Classification-F1 0.6743857449683017 on epoch=56
05/22/2022 22:26:45 - INFO - __main__ - Saving model with best Classification-F1: 0.6354675390716582 -> 0.6743857449683017 on epoch=56, global_step=450
05/22/2022 22:26:47 - INFO - __main__ - Step 460 Global step 460 Train loss 0.48 on epoch=57
05/22/2022 22:26:50 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=58
05/22/2022 22:26:52 - INFO - __main__ - Step 480 Global step 480 Train loss 0.42 on epoch=59
05/22/2022 22:26:55 - INFO - __main__ - Step 490 Global step 490 Train loss 0.38 on epoch=61
05/22/2022 22:26:57 - INFO - __main__ - Step 500 Global step 500 Train loss 0.30 on epoch=62
05/22/2022 22:26:59 - INFO - __main__ - Global step 500 Train loss 0.40 Classification-F1 0.6563107539226942 on epoch=62
05/22/2022 22:27:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.44 on epoch=63
05/22/2022 22:27:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.44 on epoch=64
05/22/2022 22:27:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=66
05/22/2022 22:27:08 - INFO - __main__ - Step 540 Global step 540 Train loss 0.42 on epoch=67
05/22/2022 22:27:11 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=68
05/22/2022 22:27:12 - INFO - __main__ - Global step 550 Train loss 0.41 Classification-F1 0.6759515496357602 on epoch=68
05/22/2022 22:27:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6743857449683017 -> 0.6759515496357602 on epoch=68, global_step=550
05/22/2022 22:27:15 - INFO - __main__ - Step 560 Global step 560 Train loss 0.29 on epoch=69
05/22/2022 22:27:17 - INFO - __main__ - Step 570 Global step 570 Train loss 0.29 on epoch=71
05/22/2022 22:27:20 - INFO - __main__ - Step 580 Global step 580 Train loss 0.40 on epoch=72
05/22/2022 22:27:22 - INFO - __main__ - Step 590 Global step 590 Train loss 0.34 on epoch=73
05/22/2022 22:27:24 - INFO - __main__ - Step 600 Global step 600 Train loss 0.38 on epoch=74
05/22/2022 22:27:26 - INFO - __main__ - Global step 600 Train loss 0.34 Classification-F1 0.6818773096821877 on epoch=74
05/22/2022 22:27:26 - INFO - __main__ - Saving model with best Classification-F1: 0.6759515496357602 -> 0.6818773096821877 on epoch=74, global_step=600
05/22/2022 22:27:28 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=76
05/22/2022 22:27:31 - INFO - __main__ - Step 620 Global step 620 Train loss 0.32 on epoch=77
05/22/2022 22:27:33 - INFO - __main__ - Step 630 Global step 630 Train loss 0.33 on epoch=78
05/22/2022 22:27:36 - INFO - __main__ - Step 640 Global step 640 Train loss 0.37 on epoch=79
05/22/2022 22:27:38 - INFO - __main__ - Step 650 Global step 650 Train loss 0.32 on epoch=81
05/22/2022 22:27:40 - INFO - __main__ - Global step 650 Train loss 0.34 Classification-F1 0.6975031755969369 on epoch=81
05/22/2022 22:27:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6818773096821877 -> 0.6975031755969369 on epoch=81, global_step=650
05/22/2022 22:27:42 - INFO - __main__ - Step 660 Global step 660 Train loss 0.38 on epoch=82
05/22/2022 22:27:44 - INFO - __main__ - Step 670 Global step 670 Train loss 0.36 on epoch=83
05/22/2022 22:27:47 - INFO - __main__ - Step 680 Global step 680 Train loss 0.31 on epoch=84
05/22/2022 22:27:49 - INFO - __main__ - Step 690 Global step 690 Train loss 0.31 on epoch=86
05/22/2022 22:27:52 - INFO - __main__ - Step 700 Global step 700 Train loss 0.28 on epoch=87
05/22/2022 22:27:53 - INFO - __main__ - Global step 700 Train loss 0.33 Classification-F1 0.6939256069573301 on epoch=87
05/22/2022 22:27:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=88
05/22/2022 22:27:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.26 on epoch=89
05/22/2022 22:28:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.24 on epoch=91
05/22/2022 22:28:03 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=92
05/22/2022 22:28:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.37 on epoch=93
05/22/2022 22:28:08 - INFO - __main__ - Global step 750 Train loss 0.25 Classification-F1 0.7192299709422997 on epoch=93
05/22/2022 22:28:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6975031755969369 -> 0.7192299709422997 on epoch=93, global_step=750
05/22/2022 22:28:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.38 on epoch=94
05/22/2022 22:28:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.25 on epoch=96
05/22/2022 22:28:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.35 on epoch=97
05/22/2022 22:28:17 - INFO - __main__ - Step 790 Global step 790 Train loss 0.36 on epoch=98
05/22/2022 22:28:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=99
05/22/2022 22:28:21 - INFO - __main__ - Global step 800 Train loss 0.33 Classification-F1 0.7553555705855293 on epoch=99
05/22/2022 22:28:21 - INFO - __main__ - Saving model with best Classification-F1: 0.7192299709422997 -> 0.7553555705855293 on epoch=99, global_step=800
05/22/2022 22:28:24 - INFO - __main__ - Step 810 Global step 810 Train loss 0.25 on epoch=101
05/22/2022 22:28:26 - INFO - __main__ - Step 820 Global step 820 Train loss 0.27 on epoch=102
05/22/2022 22:28:29 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=103
05/22/2022 22:28:31 - INFO - __main__ - Step 840 Global step 840 Train loss 0.35 on epoch=104
05/22/2022 22:28:33 - INFO - __main__ - Step 850 Global step 850 Train loss 0.30 on epoch=106
05/22/2022 22:28:35 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.7445306748142368 on epoch=106
05/22/2022 22:28:38 - INFO - __main__ - Step 860 Global step 860 Train loss 0.27 on epoch=107
05/22/2022 22:28:40 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=108
05/22/2022 22:28:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=109
05/22/2022 22:28:45 - INFO - __main__ - Step 890 Global step 890 Train loss 0.34 on epoch=111
05/22/2022 22:28:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.30 on epoch=112
05/22/2022 22:28:49 - INFO - __main__ - Global step 900 Train loss 0.31 Classification-F1 0.737424924924925 on epoch=112
05/22/2022 22:28:51 - INFO - __main__ - Step 910 Global step 910 Train loss 0.22 on epoch=113
05/22/2022 22:28:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.32 on epoch=114
05/22/2022 22:28:56 - INFO - __main__ - Step 930 Global step 930 Train loss 0.23 on epoch=116
05/22/2022 22:28:59 - INFO - __main__ - Step 940 Global step 940 Train loss 0.31 on epoch=117
05/22/2022 22:29:01 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=118
05/22/2022 22:29:03 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.7936794120633328 on epoch=118
05/22/2022 22:29:03 - INFO - __main__ - Saving model with best Classification-F1: 0.7553555705855293 -> 0.7936794120633328 on epoch=118, global_step=950
05/22/2022 22:29:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.31 on epoch=119
05/22/2022 22:29:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=121
05/22/2022 22:29:10 - INFO - __main__ - Step 980 Global step 980 Train loss 0.23 on epoch=122
05/22/2022 22:29:12 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=123
05/22/2022 22:29:15 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=124
05/22/2022 22:29:17 - INFO - __main__ - Global step 1000 Train loss 0.25 Classification-F1 0.7694852941176471 on epoch=124
05/22/2022 22:29:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=126
05/22/2022 22:29:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.29 on epoch=127
05/22/2022 22:29:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=128
05/22/2022 22:29:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.19 on epoch=129
05/22/2022 22:29:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=131
05/22/2022 22:29:30 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.7763440070505289 on epoch=131
05/22/2022 22:29:33 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.24 on epoch=132
05/22/2022 22:29:35 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=133
05/22/2022 22:29:38 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.25 on epoch=134
05/22/2022 22:29:40 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=136
05/22/2022 22:29:43 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.18 on epoch=137
05/22/2022 22:29:44 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.7501061740192174 on epoch=137
05/22/2022 22:29:47 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.21 on epoch=138
05/22/2022 22:29:49 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=139
05/22/2022 22:29:52 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.14 on epoch=141
05/22/2022 22:29:54 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.20 on epoch=142
05/22/2022 22:29:57 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.18 on epoch=143
05/22/2022 22:29:58 - INFO - __main__ - Global step 1150 Train loss 0.18 Classification-F1 0.8092056520417369 on epoch=143
05/22/2022 22:29:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7936794120633328 -> 0.8092056520417369 on epoch=143, global_step=1150
05/22/2022 22:30:01 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=144
05/22/2022 22:30:03 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=146
05/22/2022 22:30:06 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.13 on epoch=147
05/22/2022 22:30:08 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=148
05/22/2022 22:30:11 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.22 on epoch=149
05/22/2022 22:30:12 - INFO - __main__ - Global step 1200 Train loss 0.16 Classification-F1 0.822843822843823 on epoch=149
05/22/2022 22:30:12 - INFO - __main__ - Saving model with best Classification-F1: 0.8092056520417369 -> 0.822843822843823 on epoch=149, global_step=1200
05/22/2022 22:30:15 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=151
05/22/2022 22:30:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.14 on epoch=152
05/22/2022 22:30:20 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.22 on epoch=153
05/22/2022 22:30:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=154
05/22/2022 22:30:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=156
05/22/2022 22:30:26 - INFO - __main__ - Global step 1250 Train loss 0.17 Classification-F1 0.8161642411642412 on epoch=156
05/22/2022 22:30:29 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.12 on epoch=157
05/22/2022 22:30:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.14 on epoch=158
05/22/2022 22:30:34 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=159
05/22/2022 22:30:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.15 on epoch=161
05/22/2022 22:30:39 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=162
05/22/2022 22:30:40 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.8137682221082705 on epoch=162
05/22/2022 22:30:43 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=163
05/22/2022 22:30:45 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.18 on epoch=164
05/22/2022 22:30:48 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.16 on epoch=166
05/22/2022 22:30:50 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.22 on epoch=167
05/22/2022 22:30:53 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.12 on epoch=168
05/22/2022 22:30:55 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.8174372557934201 on epoch=168
05/22/2022 22:30:57 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.18 on epoch=169
05/22/2022 22:30:59 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=171
05/22/2022 22:31:02 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=172
05/22/2022 22:31:04 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=173
05/22/2022 22:31:07 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=174
05/22/2022 22:31:09 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.8137682221082705 on epoch=174
05/22/2022 22:31:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=176
05/22/2022 22:31:14 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=177
05/22/2022 22:31:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=178
05/22/2022 22:31:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=179
05/22/2022 22:31:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=181
05/22/2022 22:31:23 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.8137682221082705 on epoch=181
05/22/2022 22:31:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.09 on epoch=182
05/22/2022 22:31:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=183
05/22/2022 22:31:30 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.13 on epoch=184
05/22/2022 22:31:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=186
05/22/2022 22:31:35 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=187
05/22/2022 22:31:37 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.8137682221082705 on epoch=187
05/22/2022 22:31:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=188
05/22/2022 22:31:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=189
05/22/2022 22:31:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=191
05/22/2022 22:31:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=192
05/22/2022 22:31:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.07 on epoch=193
05/22/2022 22:31:52 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.8155992068727917 on epoch=193
05/22/2022 22:31:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=194
05/22/2022 22:31:56 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=196
05/22/2022 22:31:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=197
05/22/2022 22:32:01 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=198
05/22/2022 22:32:04 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=199
05/22/2022 22:32:06 - INFO - __main__ - Global step 1600 Train loss 0.09 Classification-F1 0.8180812777586971 on epoch=199
05/22/2022 22:32:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=201
05/22/2022 22:32:11 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.15 on epoch=202
05/22/2022 22:32:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=203
05/22/2022 22:32:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.09 on epoch=204
05/22/2022 22:32:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=206
05/22/2022 22:32:20 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.8174372557934201 on epoch=206
05/22/2022 22:32:23 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.10 on epoch=207
05/22/2022 22:32:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=208
05/22/2022 22:32:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.13 on epoch=209
05/22/2022 22:32:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=211
05/22/2022 22:32:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.07 on epoch=212
05/22/2022 22:32:35 - INFO - __main__ - Global step 1700 Train loss 0.09 Classification-F1 0.8174372557934201 on epoch=212
05/22/2022 22:32:37 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=213
05/22/2022 22:32:39 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
05/22/2022 22:32:42 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=216
05/22/2022 22:32:44 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=217
05/22/2022 22:32:47 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=218
05/22/2022 22:32:49 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.8093990076824584 on epoch=218
05/22/2022 22:32:51 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=219
05/22/2022 22:32:54 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=221
05/22/2022 22:32:56 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=222
05/22/2022 22:32:59 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=223
05/22/2022 22:33:01 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.09 on epoch=224
05/22/2022 22:33:03 - INFO - __main__ - Global step 1800 Train loss 0.08 Classification-F1 0.8004015092879257 on epoch=224
05/22/2022 22:33:06 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=226
05/22/2022 22:33:08 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=227
05/22/2022 22:33:11 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=228
05/22/2022 22:33:13 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=229
05/22/2022 22:33:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=231
05/22/2022 22:33:17 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.7997656416842656 on epoch=231
05/22/2022 22:33:20 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.06 on epoch=232
05/22/2022 22:33:22 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=233
05/22/2022 22:33:25 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=234
05/22/2022 22:33:27 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=236
05/22/2022 22:33:30 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=237
05/22/2022 22:33:32 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.8155679099364652 on epoch=237
05/22/2022 22:33:34 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=238
05/22/2022 22:33:37 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=239
05/22/2022 22:33:39 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=241
05/22/2022 22:33:42 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=242
05/22/2022 22:33:44 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=243
05/22/2022 22:33:46 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.793535155433609 on epoch=243
05/22/2022 22:33:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=244
05/22/2022 22:33:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=246
05/22/2022 22:33:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=247
05/22/2022 22:33:56 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=248
05/22/2022 22:33:58 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.18 on epoch=249
05/22/2022 22:34:00 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.8088942307692308 on epoch=249
05/22/2022 22:34:03 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=251
05/22/2022 22:34:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=252
05/22/2022 22:34:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=253
05/22/2022 22:34:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=254
05/22/2022 22:34:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=256
05/22/2022 22:34:15 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8084719334719336 on epoch=256
05/22/2022 22:34:17 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=257
05/22/2022 22:34:20 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=258
05/22/2022 22:34:22 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=259
05/22/2022 22:34:25 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=261
05/22/2022 22:34:27 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=262
05/22/2022 22:34:29 - INFO - __main__ - Global step 2100 Train loss 0.05 Classification-F1 0.8011879704043883 on epoch=262
05/22/2022 22:34:32 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.07 on epoch=263
05/22/2022 22:34:34 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=264
05/22/2022 22:34:36 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=266
05/22/2022 22:34:39 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=267
05/22/2022 22:34:41 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.08 on epoch=268
05/22/2022 22:34:43 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7931400688863375 on epoch=268
05/22/2022 22:34:46 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=269
05/22/2022 22:34:48 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=271
05/22/2022 22:34:51 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=272
05/22/2022 22:34:53 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.11 on epoch=273
05/22/2022 22:34:56 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.05 on epoch=274
05/22/2022 22:34:58 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.8013690647252292 on epoch=274
05/22/2022 22:35:00 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=276
05/22/2022 22:35:02 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=277
05/22/2022 22:35:05 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=278
05/22/2022 22:35:07 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=279
05/22/2022 22:35:10 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=281
05/22/2022 22:35:12 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.8018201671694318 on epoch=281
05/22/2022 22:35:14 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.05 on epoch=282
05/22/2022 22:35:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=283
05/22/2022 22:35:19 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=284
05/22/2022 22:35:22 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=286
05/22/2022 22:35:24 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=287
05/22/2022 22:35:26 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.7950126262626263 on epoch=287
05/22/2022 22:35:29 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=288
05/22/2022 22:35:31 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=289
05/22/2022 22:35:34 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=291
05/22/2022 22:35:36 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=292
05/22/2022 22:35:38 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=293
05/22/2022 22:35:40 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7913033045385987 on epoch=293
05/22/2022 22:35:43 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=294
05/22/2022 22:35:45 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=296
05/22/2022 22:35:48 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=297
05/22/2022 22:35:50 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=298
05/22/2022 22:35:53 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.10 on epoch=299
05/22/2022 22:35:55 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.8061788879529223 on epoch=299
05/22/2022 22:35:57 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=301
05/22/2022 22:36:00 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=302
05/22/2022 22:36:02 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=303
05/22/2022 22:36:05 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=304
05/22/2022 22:36:07 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=306
05/22/2022 22:36:09 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.8033413506885494 on epoch=306
05/22/2022 22:36:12 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=307
05/22/2022 22:36:14 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=308
05/22/2022 22:36:17 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=309
05/22/2022 22:36:19 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=311
05/22/2022 22:36:21 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=312
05/22/2022 22:36:23 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8011202830188681 on epoch=312
05/22/2022 22:36:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=313
05/22/2022 22:36:28 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=314
05/22/2022 22:36:31 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=316
05/22/2022 22:36:33 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.27 on epoch=317
05/22/2022 22:36:36 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=318
05/22/2022 22:36:38 - INFO - __main__ - Global step 2550 Train loss 0.09 Classification-F1 0.8087384837384838 on epoch=318
05/22/2022 22:36:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=319
05/22/2022 22:36:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=321
05/22/2022 22:36:45 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=322
05/22/2022 22:36:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=323
05/22/2022 22:36:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=324
05/22/2022 22:36:52 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.8172356204147364 on epoch=324
05/22/2022 22:36:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.06 on epoch=326
05/22/2022 22:36:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=327
05/22/2022 22:37:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=328
05/22/2022 22:37:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=329
05/22/2022 22:37:04 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=331
05/22/2022 22:37:06 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.8096217096217095 on epoch=331
05/22/2022 22:37:09 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.08 on epoch=332
05/22/2022 22:37:11 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
05/22/2022 22:37:14 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=334
05/22/2022 22:37:16 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=336
05/22/2022 22:37:19 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=337
05/22/2022 22:37:21 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.8129417033145003 on epoch=337
05/22/2022 22:37:23 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=338
05/22/2022 22:37:26 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=339
05/22/2022 22:37:28 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=341
05/22/2022 22:37:31 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=342
05/22/2022 22:37:33 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.10 on epoch=343
05/22/2022 22:37:35 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.8092548076923077 on epoch=343
05/22/2022 22:37:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=344
05/22/2022 22:37:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=346
05/22/2022 22:37:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=347
05/22/2022 22:37:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=348
05/22/2022 22:37:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.08 on epoch=349
05/22/2022 22:37:50 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.8084719334719336 on epoch=349
05/22/2022 22:37:52 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=351
05/22/2022 22:37:55 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=352
05/22/2022 22:37:57 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=353
05/22/2022 22:38:00 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=354
05/22/2022 22:38:02 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=356
05/22/2022 22:38:04 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.8096509971509971 on epoch=356
05/22/2022 22:38:07 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=357
05/22/2022 22:38:09 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=358
05/22/2022 22:38:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=359
05/22/2022 22:38:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.09 on epoch=361
05/22/2022 22:38:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=362
05/22/2022 22:38:18 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7970055970149253 on epoch=362
05/22/2022 22:38:21 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=363
05/22/2022 22:38:23 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=364
05/22/2022 22:38:26 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=366
05/22/2022 22:38:28 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
05/22/2022 22:38:31 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=368
05/22/2022 22:38:33 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.8245564246105406 on epoch=368
05/22/2022 22:38:33 - INFO - __main__ - Saving model with best Classification-F1: 0.822843822843823 -> 0.8245564246105406 on epoch=368, global_step=2950
05/22/2022 22:38:35 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=369
05/22/2022 22:38:38 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=371
05/22/2022 22:38:40 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=372
05/22/2022 22:38:43 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=373
05/22/2022 22:38:45 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.08 on epoch=374
05/22/2022 22:38:46 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:38:46 - INFO - __main__ - Printing 3 examples
05/22/2022 22:38:46 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:38:46 - INFO - __main__ - ['others']
05/22/2022 22:38:46 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:38:46 - INFO - __main__ - ['others']
05/22/2022 22:38:46 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:38:46 - INFO - __main__ - ['others']
05/22/2022 22:38:46 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:38:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:38:47 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:38:47 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:38:47 - INFO - __main__ - Printing 3 examples
05/22/2022 22:38:47 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:38:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:38:47 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:38:47 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8009632830404889 on epoch=374
05/22/2022 22:38:47 - INFO - __main__ - save last model!
05/22/2022 22:38:47 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 22:38:47 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 22:38:47 - INFO - __main__ - Printing 3 examples
05/22/2022 22:38:47 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 22:38:47 - INFO - __main__ - ['others']
05/22/2022 22:38:47 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:38:49 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:38:55 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 22:39:05 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:39:06 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:39:06 - INFO - __main__ - Starting training!
05/22/2022 22:40:17 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_87_0.3_8_predictions.txt
05/22/2022 22:40:17 - INFO - __main__ - Classification-F1 on test data: 0.3393
05/22/2022 22:40:17 - INFO - __main__ - prefix=emo_32_87, lr=0.3, bsz=8, dev_performance=0.8245564246105406, test_performance=0.33931422555051477
05/22/2022 22:40:17 - INFO - __main__ - Running ... prefix=emo_32_87, lr=0.2, bsz=8 ...
05/22/2022 22:40:18 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:40:18 - INFO - __main__ - Printing 3 examples
05/22/2022 22:40:18 - INFO - __main__ -  [emo] cool i agree cool info  whats the information u gave
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ -  [emo] will still love her will you oh btw who are you loving again grinningsquintingface my baby
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ -  [emo] nayis thenks bro what  you're doing
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:40:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:40:18 - INFO - __main__ - Loaded 128 examples from train data
05/22/2022 22:40:18 - INFO - __main__ - Start tokenizing ... 128 instances
05/22/2022 22:40:18 - INFO - __main__ - Printing 3 examples
05/22/2022 22:40:18 - INFO - __main__ -  [emo] yes i can see clearly now i am sleepy
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ -  [emo] oh what the timr don't forget the one behind the knee time
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ -  [emo] almost robots are dangerous and inhuman how exactly would robots take over the planet and you are one of them
05/22/2022 22:40:18 - INFO - __main__ - ['others']
05/22/2022 22:40:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:40:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:40:19 - INFO - __main__ - Loaded 128 examples from dev data
05/22/2022 22:40:37 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 22:40:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 22:40:38 - INFO - __main__ - Starting training!
05/22/2022 22:40:41 - INFO - __main__ - Step 10 Global step 10 Train loss 4.36 on epoch=1
05/22/2022 22:40:43 - INFO - __main__ - Step 20 Global step 20 Train loss 3.19 on epoch=2
05/22/2022 22:40:46 - INFO - __main__ - Step 30 Global step 30 Train loss 2.86 on epoch=3
05/22/2022 22:40:48 - INFO - __main__ - Step 40 Global step 40 Train loss 2.63 on epoch=4
05/22/2022 22:40:51 - INFO - __main__ - Step 50 Global step 50 Train loss 2.31 on epoch=6
05/22/2022 22:40:53 - INFO - __main__ - Global step 50 Train loss 3.07 Classification-F1 0.0 on epoch=6
05/22/2022 22:40:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0 on epoch=6, global_step=50
05/22/2022 22:40:55 - INFO - __main__ - Step 60 Global step 60 Train loss 2.16 on epoch=7
05/22/2022 22:40:58 - INFO - __main__ - Step 70 Global step 70 Train loss 2.20 on epoch=8
05/22/2022 22:41:00 - INFO - __main__ - Step 80 Global step 80 Train loss 1.77 on epoch=9
05/22/2022 22:41:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.73 on epoch=11
05/22/2022 22:41:05 - INFO - __main__ - Step 100 Global step 100 Train loss 1.50 on epoch=12
05/22/2022 22:41:07 - INFO - __main__ - Global step 100 Train loss 1.87 Classification-F1 0.2095297244594035 on epoch=12
05/22/2022 22:41:07 - INFO - __main__ - Saving model with best Classification-F1: 0.0 -> 0.2095297244594035 on epoch=12, global_step=100
05/22/2022 22:41:09 - INFO - __main__ - Step 110 Global step 110 Train loss 1.42 on epoch=13
05/22/2022 22:41:12 - INFO - __main__ - Step 120 Global step 120 Train loss 1.27 on epoch=14
05/22/2022 22:41:14 - INFO - __main__ - Step 130 Global step 130 Train loss 1.18 on epoch=16
05/22/2022 22:41:17 - INFO - __main__ - Step 140 Global step 140 Train loss 0.99 on epoch=17
05/22/2022 22:41:19 - INFO - __main__ - Step 150 Global step 150 Train loss 0.97 on epoch=18
05/22/2022 22:41:21 - INFO - __main__ - Global step 150 Train loss 1.17 Classification-F1 0.40832741056621646 on epoch=18
05/22/2022 22:41:21 - INFO - __main__ - Saving model with best Classification-F1: 0.2095297244594035 -> 0.40832741056621646 on epoch=18, global_step=150
05/22/2022 22:41:24 - INFO - __main__ - Step 160 Global step 160 Train loss 0.91 on epoch=19
05/22/2022 22:41:26 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=21
05/22/2022 22:41:29 - INFO - __main__ - Step 180 Global step 180 Train loss 0.79 on epoch=22
05/22/2022 22:41:31 - INFO - __main__ - Step 190 Global step 190 Train loss 0.86 on epoch=23
05/22/2022 22:41:34 - INFO - __main__ - Step 200 Global step 200 Train loss 0.79 on epoch=24
05/22/2022 22:41:35 - INFO - __main__ - Global step 200 Train loss 0.84 Classification-F1 0.4224386724386724 on epoch=24
05/22/2022 22:41:35 - INFO - __main__ - Saving model with best Classification-F1: 0.40832741056621646 -> 0.4224386724386724 on epoch=24, global_step=200
05/22/2022 22:41:38 - INFO - __main__ - Step 210 Global step 210 Train loss 0.73 on epoch=26
05/22/2022 22:41:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.74 on epoch=27
05/22/2022 22:41:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.69 on epoch=28
05/22/2022 22:41:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.72 on epoch=29
05/22/2022 22:41:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.69 on epoch=31
05/22/2022 22:41:50 - INFO - __main__ - Global step 250 Train loss 0.71 Classification-F1 0.5211542950513539 on epoch=31
05/22/2022 22:41:50 - INFO - __main__ - Saving model with best Classification-F1: 0.4224386724386724 -> 0.5211542950513539 on epoch=31, global_step=250
05/22/2022 22:41:52 - INFO - __main__ - Step 260 Global step 260 Train loss 0.65 on epoch=32
05/22/2022 22:41:55 - INFO - __main__ - Step 270 Global step 270 Train loss 0.74 on epoch=33
05/22/2022 22:41:58 - INFO - __main__ - Step 280 Global step 280 Train loss 0.67 on epoch=34
05/22/2022 22:42:00 - INFO - __main__ - Step 290 Global step 290 Train loss 0.61 on epoch=36
05/22/2022 22:42:03 - INFO - __main__ - Step 300 Global step 300 Train loss 0.61 on epoch=37
05/22/2022 22:42:04 - INFO - __main__ - Global step 300 Train loss 0.66 Classification-F1 0.5306111696522656 on epoch=37
05/22/2022 22:42:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5211542950513539 -> 0.5306111696522656 on epoch=37, global_step=300
05/22/2022 22:42:07 - INFO - __main__ - Step 310 Global step 310 Train loss 0.75 on epoch=38
05/22/2022 22:42:09 - INFO - __main__ - Step 320 Global step 320 Train loss 0.64 on epoch=39
05/22/2022 22:42:12 - INFO - __main__ - Step 330 Global step 330 Train loss 0.54 on epoch=41
05/22/2022 22:42:14 - INFO - __main__ - Step 340 Global step 340 Train loss 0.58 on epoch=42
05/22/2022 22:42:17 - INFO - __main__ - Step 350 Global step 350 Train loss 0.71 on epoch=43
05/22/2022 22:42:19 - INFO - __main__ - Global step 350 Train loss 0.64 Classification-F1 0.5331675554278295 on epoch=43
05/22/2022 22:42:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5306111696522656 -> 0.5331675554278295 on epoch=43, global_step=350
05/22/2022 22:42:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.55 on epoch=44
05/22/2022 22:42:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.57 on epoch=46
05/22/2022 22:42:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=47
05/22/2022 22:42:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.64 on epoch=48
05/22/2022 22:42:32 - INFO - __main__ - Step 400 Global step 400 Train loss 0.53 on epoch=49
05/22/2022 22:42:33 - INFO - __main__ - Global step 400 Train loss 0.58 Classification-F1 0.5496820349761526 on epoch=49
05/22/2022 22:42:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5331675554278295 -> 0.5496820349761526 on epoch=49, global_step=400
05/22/2022 22:42:36 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=51
05/22/2022 22:42:39 - INFO - __main__ - Step 420 Global step 420 Train loss 0.54 on epoch=52
05/22/2022 22:42:41 - INFO - __main__ - Step 430 Global step 430 Train loss 0.62 on epoch=53
05/22/2022 22:42:44 - INFO - __main__ - Step 440 Global step 440 Train loss 0.53 on epoch=54
05/22/2022 22:42:46 - INFO - __main__ - Step 450 Global step 450 Train loss 0.56 on epoch=56
05/22/2022 22:42:48 - INFO - __main__ - Global step 450 Train loss 0.56 Classification-F1 0.572092731829574 on epoch=56
05/22/2022 22:42:48 - INFO - __main__ - Saving model with best Classification-F1: 0.5496820349761526 -> 0.572092731829574 on epoch=56, global_step=450
05/22/2022 22:42:50 - INFO - __main__ - Step 460 Global step 460 Train loss 0.54 on epoch=57
05/22/2022 22:42:53 - INFO - __main__ - Step 470 Global step 470 Train loss 0.43 on epoch=58
05/22/2022 22:42:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.50 on epoch=59
05/22/2022 22:42:58 - INFO - __main__ - Step 490 Global step 490 Train loss 0.48 on epoch=61
05/22/2022 22:43:01 - INFO - __main__ - Step 500 Global step 500 Train loss 0.50 on epoch=62
05/22/2022 22:43:02 - INFO - __main__ - Global step 500 Train loss 0.49 Classification-F1 0.6096204080081026 on epoch=62
05/22/2022 22:43:02 - INFO - __main__ - Saving model with best Classification-F1: 0.572092731829574 -> 0.6096204080081026 on epoch=62, global_step=500
05/22/2022 22:43:05 - INFO - __main__ - Step 510 Global step 510 Train loss 0.43 on epoch=63
05/22/2022 22:43:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.50 on epoch=64
05/22/2022 22:43:10 - INFO - __main__ - Step 530 Global step 530 Train loss 0.47 on epoch=66
05/22/2022 22:43:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.56 on epoch=67
05/22/2022 22:43:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=68
05/22/2022 22:43:17 - INFO - __main__ - Global step 550 Train loss 0.48 Classification-F1 0.5957997471155365 on epoch=68
05/22/2022 22:43:19 - INFO - __main__ - Step 560 Global step 560 Train loss 0.49 on epoch=69
05/22/2022 22:43:22 - INFO - __main__ - Step 570 Global step 570 Train loss 0.53 on epoch=71
05/22/2022 22:43:24 - INFO - __main__ - Step 580 Global step 580 Train loss 0.51 on epoch=72
05/22/2022 22:43:27 - INFO - __main__ - Step 590 Global step 590 Train loss 0.46 on epoch=73
05/22/2022 22:43:29 - INFO - __main__ - Step 600 Global step 600 Train loss 0.44 on epoch=74
05/22/2022 22:43:31 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.6231409001956947 on epoch=74
05/22/2022 22:43:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6096204080081026 -> 0.6231409001956947 on epoch=74, global_step=600
05/22/2022 22:43:34 - INFO - __main__ - Step 610 Global step 610 Train loss 0.38 on epoch=76
05/22/2022 22:43:36 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=77
05/22/2022 22:43:39 - INFO - __main__ - Step 630 Global step 630 Train loss 0.47 on epoch=78
05/22/2022 22:43:41 - INFO - __main__ - Step 640 Global step 640 Train loss 0.43 on epoch=79
05/22/2022 22:43:44 - INFO - __main__ - Step 650 Global step 650 Train loss 0.38 on epoch=81
05/22/2022 22:43:46 - INFO - __main__ - Global step 650 Train loss 0.42 Classification-F1 0.6568467643467644 on epoch=81
05/22/2022 22:43:46 - INFO - __main__ - Saving model with best Classification-F1: 0.6231409001956947 -> 0.6568467643467644 on epoch=81, global_step=650
05/22/2022 22:43:48 - INFO - __main__ - Step 660 Global step 660 Train loss 0.50 on epoch=82
05/22/2022 22:43:51 - INFO - __main__ - Step 670 Global step 670 Train loss 0.40 on epoch=83
05/22/2022 22:43:53 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=84
05/22/2022 22:43:56 - INFO - __main__ - Step 690 Global step 690 Train loss 0.41 on epoch=86
05/22/2022 22:43:58 - INFO - __main__ - Step 700 Global step 700 Train loss 0.46 on epoch=87
05/22/2022 22:44:00 - INFO - __main__ - Global step 700 Train loss 0.44 Classification-F1 0.6501158455105823 on epoch=87
05/22/2022 22:44:02 - INFO - __main__ - Step 710 Global step 710 Train loss 0.43 on epoch=88
05/22/2022 22:44:05 - INFO - __main__ - Step 720 Global step 720 Train loss 0.40 on epoch=89
05/22/2022 22:44:07 - INFO - __main__ - Step 730 Global step 730 Train loss 0.39 on epoch=91
05/22/2022 22:44:10 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=92
05/22/2022 22:44:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.38 on epoch=93
05/22/2022 22:44:14 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.6423907143085226 on epoch=93
05/22/2022 22:44:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.45 on epoch=94
05/22/2022 22:44:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.36 on epoch=96
05/22/2022 22:44:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.41 on epoch=97
05/22/2022 22:44:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.44 on epoch=98
05/22/2022 22:44:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.44 on epoch=99
05/22/2022 22:44:28 - INFO - __main__ - Global step 800 Train loss 0.42 Classification-F1 0.6571506672547701 on epoch=99
05/22/2022 22:44:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6568467643467644 -> 0.6571506672547701 on epoch=99, global_step=800
05/22/2022 22:44:31 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=101
05/22/2022 22:44:33 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=102
05/22/2022 22:44:36 - INFO - __main__ - Step 830 Global step 830 Train loss 0.41 on epoch=103
05/22/2022 22:44:38 - INFO - __main__ - Step 840 Global step 840 Train loss 0.37 on epoch=104
05/22/2022 22:44:41 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=106
05/22/2022 22:44:42 - INFO - __main__ - Global step 850 Train loss 0.34 Classification-F1 0.6793469877649373 on epoch=106
05/22/2022 22:44:42 - INFO - __main__ - Saving model with best Classification-F1: 0.6571506672547701 -> 0.6793469877649373 on epoch=106, global_step=850
05/22/2022 22:44:45 - INFO - __main__ - Step 860 Global step 860 Train loss 0.41 on epoch=107
05/22/2022 22:44:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.43 on epoch=108
05/22/2022 22:44:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.37 on epoch=109
05/22/2022 22:44:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=111
05/22/2022 22:44:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.43 on epoch=112
05/22/2022 22:44:57 - INFO - __main__ - Global step 900 Train loss 0.40 Classification-F1 0.6867695230355739 on epoch=112
05/22/2022 22:44:57 - INFO - __main__ - Saving model with best Classification-F1: 0.6793469877649373 -> 0.6867695230355739 on epoch=112, global_step=900
05/22/2022 22:44:59 - INFO - __main__ - Step 910 Global step 910 Train loss 0.35 on epoch=113
05/22/2022 22:45:02 - INFO - __main__ - Step 920 Global step 920 Train loss 0.41 on epoch=114
05/22/2022 22:45:04 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=116
05/22/2022 22:45:06 - INFO - __main__ - Step 940 Global step 940 Train loss 0.29 on epoch=117
05/22/2022 22:45:09 - INFO - __main__ - Step 950 Global step 950 Train loss 0.31 on epoch=118
05/22/2022 22:45:11 - INFO - __main__ - Global step 950 Train loss 0.33 Classification-F1 0.7006049506049505 on epoch=118
05/22/2022 22:45:11 - INFO - __main__ - Saving model with best Classification-F1: 0.6867695230355739 -> 0.7006049506049505 on epoch=118, global_step=950
05/22/2022 22:45:13 - INFO - __main__ - Step 960 Global step 960 Train loss 0.37 on epoch=119
05/22/2022 22:45:15 - INFO - __main__ - Step 970 Global step 970 Train loss 0.29 on epoch=121
05/22/2022 22:45:18 - INFO - __main__ - Step 980 Global step 980 Train loss 0.34 on epoch=122
05/22/2022 22:45:20 - INFO - __main__ - Step 990 Global step 990 Train loss 0.33 on epoch=123
05/22/2022 22:45:23 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.34 on epoch=124
05/22/2022 22:45:25 - INFO - __main__ - Global step 1000 Train loss 0.33 Classification-F1 0.7088023123272409 on epoch=124
05/22/2022 22:45:25 - INFO - __main__ - Saving model with best Classification-F1: 0.7006049506049505 -> 0.7088023123272409 on epoch=124, global_step=1000
05/22/2022 22:45:27 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.31 on epoch=126
05/22/2022 22:45:30 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=127
05/22/2022 22:45:32 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.30 on epoch=128
05/22/2022 22:45:34 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.28 on epoch=129
05/22/2022 22:45:37 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.36 on epoch=131
05/22/2022 22:45:39 - INFO - __main__ - Global step 1050 Train loss 0.30 Classification-F1 0.6957886904761905 on epoch=131
05/22/2022 22:45:41 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.30 on epoch=132
05/22/2022 22:45:44 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.32 on epoch=133
05/22/2022 22:45:46 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.28 on epoch=134
05/22/2022 22:45:48 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.27 on epoch=136
05/22/2022 22:45:51 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.36 on epoch=137
05/22/2022 22:45:53 - INFO - __main__ - Global step 1100 Train loss 0.31 Classification-F1 0.6887298287298287 on epoch=137
05/22/2022 22:45:55 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=138
05/22/2022 22:45:58 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.30 on epoch=139
05/22/2022 22:46:00 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.28 on epoch=141
05/22/2022 22:46:02 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.30 on epoch=142
05/22/2022 22:46:05 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.34 on epoch=143
05/22/2022 22:46:07 - INFO - __main__ - Global step 1150 Train loss 0.31 Classification-F1 0.740575510453414 on epoch=143
05/22/2022 22:46:07 - INFO - __main__ - Saving model with best Classification-F1: 0.7088023123272409 -> 0.740575510453414 on epoch=143, global_step=1150
05/22/2022 22:46:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.25 on epoch=144
05/22/2022 22:46:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.25 on epoch=146
05/22/2022 22:46:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.20 on epoch=147
05/22/2022 22:46:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.36 on epoch=148
05/22/2022 22:46:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.28 on epoch=149
05/22/2022 22:46:21 - INFO - __main__ - Global step 1200 Train loss 0.27 Classification-F1 0.7763328157349896 on epoch=149
05/22/2022 22:46:21 - INFO - __main__ - Saving model with best Classification-F1: 0.740575510453414 -> 0.7763328157349896 on epoch=149, global_step=1200
05/22/2022 22:46:23 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.22 on epoch=151
05/22/2022 22:46:26 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.26 on epoch=152
05/22/2022 22:46:28 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.25 on epoch=153
05/22/2022 22:46:31 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.30 on epoch=154
05/22/2022 22:46:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.18 on epoch=156
05/22/2022 22:46:35 - INFO - __main__ - Global step 1250 Train loss 0.24 Classification-F1 0.7189611486486487 on epoch=156
05/22/2022 22:46:37 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.26 on epoch=157
05/22/2022 22:46:40 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.24 on epoch=158
05/22/2022 22:46:42 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.25 on epoch=159
05/22/2022 22:46:45 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.27 on epoch=161
05/22/2022 22:46:47 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.30 on epoch=162
05/22/2022 22:46:49 - INFO - __main__ - Global step 1300 Train loss 0.26 Classification-F1 0.7960656436487639 on epoch=162
05/22/2022 22:46:49 - INFO - __main__ - Saving model with best Classification-F1: 0.7763328157349896 -> 0.7960656436487639 on epoch=162, global_step=1300
05/22/2022 22:46:52 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.21 on epoch=163
05/22/2022 22:46:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.24 on epoch=164
05/22/2022 22:46:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.24 on epoch=166
05/22/2022 22:46:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.28 on epoch=167
05/22/2022 22:47:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.22 on epoch=168
05/22/2022 22:47:03 - INFO - __main__ - Global step 1350 Train loss 0.24 Classification-F1 0.7786766232443862 on epoch=168
05/22/2022 22:47:06 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.22 on epoch=169
05/22/2022 22:47:08 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.22 on epoch=171
05/22/2022 22:47:11 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.19 on epoch=172
05/22/2022 22:47:13 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.24 on epoch=173
05/22/2022 22:47:16 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.40 on epoch=174
05/22/2022 22:47:17 - INFO - __main__ - Global step 1400 Train loss 0.25 Classification-F1 0.7786766232443862 on epoch=174
05/22/2022 22:47:20 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=176
05/22/2022 22:47:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.23 on epoch=177
05/22/2022 22:47:25 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=178
05/22/2022 22:47:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.20 on epoch=179
05/22/2022 22:47:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.23 on epoch=181
05/22/2022 22:47:32 - INFO - __main__ - Global step 1450 Train loss 0.21 Classification-F1 0.7760853805698642 on epoch=181
05/22/2022 22:47:34 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.23 on epoch=182
05/22/2022 22:47:37 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.22 on epoch=183
05/22/2022 22:47:39 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.24 on epoch=184
05/22/2022 22:47:42 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.23 on epoch=186
05/22/2022 22:47:44 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.20 on epoch=187
05/22/2022 22:47:46 - INFO - __main__ - Global step 1500 Train loss 0.22 Classification-F1 0.7819122906079428 on epoch=187
05/22/2022 22:47:48 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.19 on epoch=188
05/22/2022 22:47:51 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.24 on epoch=189
05/22/2022 22:47:53 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.19 on epoch=191
05/22/2022 22:47:56 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.19 on epoch=192
05/22/2022 22:47:58 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.25 on epoch=193
05/22/2022 22:48:00 - INFO - __main__ - Global step 1550 Train loss 0.21 Classification-F1 0.7886082480682288 on epoch=193
05/22/2022 22:48:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=194
05/22/2022 22:48:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.18 on epoch=196
05/22/2022 22:48:07 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=197
05/22/2022 22:48:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.11 on epoch=198
05/22/2022 22:48:12 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.17 on epoch=199
05/22/2022 22:48:14 - INFO - __main__ - Global step 1600 Train loss 0.17 Classification-F1 0.7964432133997351 on epoch=199
05/22/2022 22:48:14 - INFO - __main__ - Saving model with best Classification-F1: 0.7960656436487639 -> 0.7964432133997351 on epoch=199, global_step=1600
05/22/2022 22:48:17 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.20 on epoch=201
05/22/2022 22:48:19 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.21 on epoch=202
05/22/2022 22:48:22 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=203
05/22/2022 22:48:24 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=204
05/22/2022 22:48:27 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.20 on epoch=206
05/22/2022 22:48:28 - INFO - __main__ - Global step 1650 Train loss 0.19 Classification-F1 0.7797275564162209 on epoch=206
05/22/2022 22:48:31 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=207
05/22/2022 22:48:33 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.19 on epoch=208
05/22/2022 22:48:36 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.20 on epoch=209
05/22/2022 22:48:38 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.13 on epoch=211
05/22/2022 22:48:41 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.17 on epoch=212
05/22/2022 22:48:43 - INFO - __main__ - Global step 1700 Train loss 0.16 Classification-F1 0.7724026422163068 on epoch=212
05/22/2022 22:48:45 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.15 on epoch=213
05/22/2022 22:48:47 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=214
05/22/2022 22:48:50 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.19 on epoch=216
05/22/2022 22:48:52 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.17 on epoch=217
05/22/2022 22:48:55 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.07 on epoch=218
05/22/2022 22:48:57 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.7793061573944646 on epoch=218
05/22/2022 22:48:59 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.16 on epoch=219
05/22/2022 22:49:02 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=221
05/22/2022 22:49:04 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.15 on epoch=222
05/22/2022 22:49:07 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.21 on epoch=223
05/22/2022 22:49:09 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.18 on epoch=224
05/22/2022 22:49:11 - INFO - __main__ - Global step 1800 Train loss 0.16 Classification-F1 0.7796346608818965 on epoch=224
05/22/2022 22:49:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.12 on epoch=226
05/22/2022 22:49:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.20 on epoch=227
05/22/2022 22:49:18 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=228
05/22/2022 22:49:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.18 on epoch=229
05/22/2022 22:49:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=231
05/22/2022 22:49:25 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.772306240063593 on epoch=231
05/22/2022 22:49:28 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=232
05/22/2022 22:49:30 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.19 on epoch=233
05/22/2022 22:49:33 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.18 on epoch=234
05/22/2022 22:49:35 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=236
05/22/2022 22:49:38 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=237
05/22/2022 22:49:39 - INFO - __main__ - Global step 1900 Train loss 0.15 Classification-F1 0.7816570977706151 on epoch=237
05/22/2022 22:49:42 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.14 on epoch=238
05/22/2022 22:49:44 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.16 on epoch=239
05/22/2022 22:49:47 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.15 on epoch=241
05/22/2022 22:49:49 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.15 on epoch=242
05/22/2022 22:49:52 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=243
05/22/2022 22:49:54 - INFO - __main__ - Global step 1950 Train loss 0.14 Classification-F1 0.7869785414165666 on epoch=243
05/22/2022 22:49:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=244
05/22/2022 22:49:59 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.12 on epoch=246
05/22/2022 22:50:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.14 on epoch=247
05/22/2022 22:50:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.22 on epoch=248
05/22/2022 22:50:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=249
05/22/2022 22:50:08 - INFO - __main__ - Global step 2000 Train loss 0.14 Classification-F1 0.7869785414165666 on epoch=249
05/22/2022 22:50:10 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=251
05/22/2022 22:50:13 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.13 on epoch=252
05/22/2022 22:50:15 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.12 on epoch=253
05/22/2022 22:50:18 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=254
05/22/2022 22:50:20 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=256
05/22/2022 22:50:22 - INFO - __main__ - Global step 2050 Train loss 0.11 Classification-F1 0.7801766376228416 on epoch=256
05/22/2022 22:50:25 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=257
05/22/2022 22:50:27 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.20 on epoch=258
05/22/2022 22:50:30 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=259
05/22/2022 22:50:32 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.09 on epoch=261
05/22/2022 22:50:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=262
05/22/2022 22:50:36 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.7577057427681022 on epoch=262
05/22/2022 22:50:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.15 on epoch=263
05/22/2022 22:50:41 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.07 on epoch=264
05/22/2022 22:50:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.15 on epoch=266
05/22/2022 22:50:46 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=267
05/22/2022 22:50:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.09 on epoch=268
05/22/2022 22:50:51 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.7647523613353375 on epoch=268
05/22/2022 22:50:53 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.16 on epoch=269
05/22/2022 22:50:56 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.13 on epoch=271
05/22/2022 22:50:58 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=272
05/22/2022 22:51:01 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=273
05/22/2022 22:51:03 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.13 on epoch=274
05/22/2022 22:51:05 - INFO - __main__ - Global step 2200 Train loss 0.12 Classification-F1 0.7733148101898102 on epoch=274
05/22/2022 22:51:07 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.12 on epoch=276
05/22/2022 22:51:10 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.12 on epoch=277
05/22/2022 22:51:12 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.12 on epoch=278
05/22/2022 22:51:15 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=279
05/22/2022 22:51:17 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.11 on epoch=281
05/22/2022 22:51:19 - INFO - __main__ - Global step 2250 Train loss 0.12 Classification-F1 0.7726146331738437 on epoch=281
05/22/2022 22:51:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=282
05/22/2022 22:51:24 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=283
05/22/2022 22:51:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.09 on epoch=284
05/22/2022 22:51:29 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.09 on epoch=286
05/22/2022 22:51:32 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.15 on epoch=287
05/22/2022 22:51:34 - INFO - __main__ - Global step 2300 Train loss 0.10 Classification-F1 0.7735551948051949 on epoch=287
05/22/2022 22:51:36 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=288
05/22/2022 22:51:39 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=289
05/22/2022 22:51:41 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.09 on epoch=291
05/22/2022 22:51:43 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=292
05/22/2022 22:51:46 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.12 on epoch=293
05/22/2022 22:51:48 - INFO - __main__ - Global step 2350 Train loss 0.10 Classification-F1 0.7647363433459271 on epoch=293
05/22/2022 22:51:50 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=294
05/22/2022 22:51:53 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=296
05/22/2022 22:51:55 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=297
05/22/2022 22:51:58 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=298
05/22/2022 22:52:00 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=299
05/22/2022 22:52:02 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7790629968203499 on epoch=299
05/22/2022 22:52:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=301
05/22/2022 22:52:07 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=302
05/22/2022 22:52:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=303
05/22/2022 22:52:12 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=304
05/22/2022 22:52:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=306
05/22/2022 22:52:16 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7724811796046268 on epoch=306
05/22/2022 22:52:19 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=307
05/22/2022 22:52:21 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.11 on epoch=308
05/22/2022 22:52:24 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.11 on epoch=309
05/22/2022 22:52:26 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.10 on epoch=311
05/22/2022 22:52:28 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.09 on epoch=312
05/22/2022 22:52:30 - INFO - __main__ - Global step 2500 Train loss 0.10 Classification-F1 0.7647363433459271 on epoch=312
05/22/2022 22:52:33 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=313
05/22/2022 22:52:35 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=314
05/22/2022 22:52:38 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=316
05/22/2022 22:52:41 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=317
05/22/2022 22:52:43 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.13 on epoch=318
05/22/2022 22:52:45 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.7720802238805972 on epoch=318
05/22/2022 22:52:48 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.10 on epoch=319
05/22/2022 22:52:50 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.12 on epoch=321
05/22/2022 22:52:53 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=322
05/22/2022 22:52:55 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.09 on epoch=323
05/22/2022 22:52:58 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=324
05/22/2022 22:53:00 - INFO - __main__ - Global step 2600 Train loss 0.09 Classification-F1 0.7722817197054259 on epoch=324
05/22/2022 22:53:02 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=326
05/22/2022 22:53:04 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.08 on epoch=327
05/22/2022 22:53:07 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=328
05/22/2022 22:53:09 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.05 on epoch=329
05/22/2022 22:53:12 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=331
05/22/2022 22:53:14 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.7796256002400961 on epoch=331
05/22/2022 22:53:17 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=332
05/22/2022 22:53:19 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=333
05/22/2022 22:53:21 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=334
05/22/2022 22:53:24 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=336
05/22/2022 22:53:26 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=337
05/22/2022 22:53:28 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.7722817197054259 on epoch=337
05/22/2022 22:53:31 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.09 on epoch=338
05/22/2022 22:53:33 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=339
05/22/2022 22:53:36 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=341
05/22/2022 22:53:38 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.09 on epoch=342
05/22/2022 22:53:41 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=343
05/22/2022 22:53:42 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.7716579265832998 on epoch=343
05/22/2022 22:53:45 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.11 on epoch=344
05/22/2022 22:53:47 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=346
05/22/2022 22:53:50 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=347
05/22/2022 22:53:52 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=348
05/22/2022 22:53:55 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=349
05/22/2022 22:53:57 - INFO - __main__ - Global step 2800 Train loss 0.06 Classification-F1 0.7647363433459271 on epoch=349
05/22/2022 22:53:59 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=351
05/22/2022 22:54:02 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=352
05/22/2022 22:54:04 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.05 on epoch=353
05/22/2022 22:54:07 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=354
05/22/2022 22:54:09 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=356
05/22/2022 22:54:11 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7716579265832998 on epoch=356
05/22/2022 22:54:13 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=357
05/22/2022 22:54:16 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.06 on epoch=358
05/22/2022 22:54:18 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=359
05/22/2022 22:54:21 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.08 on epoch=361
05/22/2022 22:54:23 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.10 on epoch=362
05/22/2022 22:54:25 - INFO - __main__ - Global step 2900 Train loss 0.06 Classification-F1 0.7720802238805972 on epoch=362
05/22/2022 22:54:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=363
05/22/2022 22:54:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=364
05/22/2022 22:54:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.05 on epoch=366
05/22/2022 22:54:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=367
05/22/2022 22:54:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.09 on epoch=368
05/22/2022 22:54:40 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7811013426020581 on epoch=368
05/22/2022 22:54:42 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=369
05/22/2022 22:54:45 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=371
05/22/2022 22:54:47 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=372
05/22/2022 22:54:50 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=373
05/22/2022 22:54:52 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=374
05/22/2022 22:54:55 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.78197109689647 on epoch=374
05/22/2022 22:54:55 - INFO - __main__ - save last model!
05/22/2022 22:54:55 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 22:54:55 - INFO - __main__ - Start tokenizing ... 5509 instances
05/22/2022 22:54:55 - INFO - __main__ - Printing 3 examples
05/22/2022 22:54:55 - INFO - __main__ -  [emo] hmm what does your bio mean i dont have any bio
05/22/2022 22:54:55 - INFO - __main__ - ['others']
05/22/2022 22:54:55 - INFO - __main__ -  [emo] what you like very little things ok
05/22/2022 22:54:55 - INFO - __main__ - ['others']
05/22/2022 22:54:55 - INFO - __main__ -  [emo] yes how so i want to fuck babu
05/22/2022 22:54:55 - INFO - __main__ - ['others']
05/22/2022 22:54:55 - INFO - __main__ - Tokenizing Input ...
05/22/2022 22:54:57 - INFO - __main__ - Tokenizing Output ...
05/22/2022 22:55:02 - INFO - __main__ - Loaded 5509 examples from test data
05/22/2022 22:56:26 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-emo/emo_32_87_0.2_8_predictions.txt
05/22/2022 22:56:26 - INFO - __main__ - Classification-F1 on test data: 0.3471
05/22/2022 22:56:27 - INFO - __main__ - prefix=emo_32_87, lr=0.2, bsz=8, dev_performance=0.7964432133997351, test_performance=0.3471078504485582
