05/22/2022 03:08:17 - INFO - __main__ - Namespace(task_dir='data_32/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/22/2022 03:08:17 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14
05/22/2022 03:08:17 - INFO - __main__ - Namespace(task_dir='data_32/dbpedia_14/', task_name='dbpedia_14', identifier='T5-large-multitask-cls2cls-5e-1-4-20-down32shot', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='4,5')
05/22/2022 03:08:17 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14
05/22/2022 03:08:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
05/22/2022 03:08:19 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
05/22/2022 03:08:19 - INFO - __main__ - args.device: cuda:1
05/22/2022 03:08:19 - INFO - __main__ - args.device: cuda:0
05/22/2022 03:08:19 - INFO - __main__ - Using 2 gpus
05/22/2022 03:08:19 - INFO - __main__ - Using 2 gpus
05/22/2022 03:08:19 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_32_100', 'dbpedia_14_32_13', 'dbpedia_14_32_21', 'dbpedia_14_32_42', 'dbpedia_14_32_87']
05/22/2022 03:08:19 - INFO - __main__ - Fine-tuning the following samples: ['dbpedia_14_32_100', 'dbpedia_14_32_13', 'dbpedia_14_32_21', 'dbpedia_14_32_42', 'dbpedia_14_32_87']
05/22/2022 03:08:23 - INFO - __main__ - Running ... prefix=dbpedia_14_32_100, lr=0.5, bsz=8 ...
05/22/2022 03:08:24 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:08:24 - INFO - __main__ - Printing 3 examples
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:08:24 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:08:24 - INFO - __main__ - Printing 3 examples
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 03:08:24 - INFO - __main__ - ['Animal']
05/22/2022 03:08:24 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:08:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:08:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:08:25 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 03:08:25 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:08:25 - INFO - __main__ - Printing 3 examples
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:08:25 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 03:08:25 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:08:25 - INFO - __main__ - Printing 3 examples
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 03:08:25 - INFO - __main__ - ['Animal']
05/22/2022 03:08:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:08:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:08:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:08:25 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 03:08:25 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 03:08:43 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 03:08:43 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 03:08:44 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 03:08:44 - INFO - __main__ - Starting training!
05/22/2022 03:08:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 03:08:50 - INFO - __main__ - Starting training!
05/22/2022 03:08:55 - INFO - __main__ - Step 10 Global step 10 Train loss 6.73 on epoch=0
05/22/2022 03:08:57 - INFO - __main__ - Step 20 Global step 20 Train loss 4.73 on epoch=0
05/22/2022 03:09:00 - INFO - __main__ - Step 30 Global step 30 Train loss 3.91 on epoch=1
05/22/2022 03:09:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.24 on epoch=1
05/22/2022 03:09:05 - INFO - __main__ - Step 50 Global step 50 Train loss 2.91 on epoch=1
05/22/2022 03:09:19 - INFO - __main__ - Global step 50 Train loss 4.30 Classification-F1 0.030293803204019924 on epoch=1
05/22/2022 03:09:19 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.030293803204019924 on epoch=1, global_step=50
05/22/2022 03:09:22 - INFO - __main__ - Step 60 Global step 60 Train loss 2.57 on epoch=2
05/22/2022 03:09:24 - INFO - __main__ - Step 70 Global step 70 Train loss 2.33 on epoch=2
05/22/2022 03:09:27 - INFO - __main__ - Step 80 Global step 80 Train loss 2.09 on epoch=2
05/22/2022 03:09:29 - INFO - __main__ - Step 90 Global step 90 Train loss 1.89 on epoch=3
05/22/2022 03:09:32 - INFO - __main__ - Step 100 Global step 100 Train loss 1.77 on epoch=3
05/22/2022 03:09:43 - INFO - __main__ - Global step 100 Train loss 2.13 Classification-F1 0.09745867863199953 on epoch=3
05/22/2022 03:09:43 - INFO - __main__ - Saving model with best Classification-F1: 0.030293803204019924 -> 0.09745867863199953 on epoch=3, global_step=100
05/22/2022 03:09:46 - INFO - __main__ - Step 110 Global step 110 Train loss 1.58 on epoch=3
05/22/2022 03:09:49 - INFO - __main__ - Step 120 Global step 120 Train loss 1.61 on epoch=4
05/22/2022 03:09:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.50 on epoch=4
05/22/2022 03:09:54 - INFO - __main__ - Step 140 Global step 140 Train loss 1.19 on epoch=4
05/22/2022 03:09:56 - INFO - __main__ - Step 150 Global step 150 Train loss 1.18 on epoch=5
05/22/2022 03:10:07 - INFO - __main__ - Global step 150 Train loss 1.41 Classification-F1 0.1871783378201505 on epoch=5
05/22/2022 03:10:07 - INFO - __main__ - Saving model with best Classification-F1: 0.09745867863199953 -> 0.1871783378201505 on epoch=5, global_step=150
05/22/2022 03:10:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.02 on epoch=5
05/22/2022 03:10:13 - INFO - __main__ - Step 170 Global step 170 Train loss 0.83 on epoch=6
05/22/2022 03:10:15 - INFO - __main__ - Step 180 Global step 180 Train loss 0.85 on epoch=6
05/22/2022 03:10:18 - INFO - __main__ - Step 190 Global step 190 Train loss 0.73 on epoch=6
05/22/2022 03:10:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.69 on epoch=7
05/22/2022 03:10:32 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.2654991626715997 on epoch=7
05/22/2022 03:10:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1871783378201505 -> 0.2654991626715997 on epoch=7, global_step=200
05/22/2022 03:10:35 - INFO - __main__ - Step 210 Global step 210 Train loss 0.67 on epoch=7
05/22/2022 03:10:37 - INFO - __main__ - Step 220 Global step 220 Train loss 0.58 on epoch=7
05/22/2022 03:10:40 - INFO - __main__ - Step 230 Global step 230 Train loss 0.59 on epoch=8
05/22/2022 03:10:42 - INFO - __main__ - Step 240 Global step 240 Train loss 0.55 on epoch=8
05/22/2022 03:10:45 - INFO - __main__ - Step 250 Global step 250 Train loss 0.55 on epoch=8
05/22/2022 03:10:57 - INFO - __main__ - Global step 250 Train loss 0.59 Classification-F1 0.37741854966010385 on epoch=8
05/22/2022 03:10:57 - INFO - __main__ - Saving model with best Classification-F1: 0.2654991626715997 -> 0.37741854966010385 on epoch=8, global_step=250
05/22/2022 03:11:00 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=9
05/22/2022 03:11:02 - INFO - __main__ - Step 270 Global step 270 Train loss 0.44 on epoch=9
05/22/2022 03:11:05 - INFO - __main__ - Step 280 Global step 280 Train loss 0.40 on epoch=9
05/22/2022 03:11:08 - INFO - __main__ - Step 290 Global step 290 Train loss 0.49 on epoch=10
05/22/2022 03:11:10 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=10
05/22/2022 03:11:23 - INFO - __main__ - Global step 300 Train loss 0.46 Classification-F1 0.4390306971486457 on epoch=10
05/22/2022 03:11:23 - INFO - __main__ - Saving model with best Classification-F1: 0.37741854966010385 -> 0.4390306971486457 on epoch=10, global_step=300
05/22/2022 03:11:26 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=11
05/22/2022 03:11:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.42 on epoch=11
05/22/2022 03:11:31 - INFO - __main__ - Step 330 Global step 330 Train loss 0.33 on epoch=11
05/22/2022 03:11:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.36 on epoch=12
05/22/2022 03:11:36 - INFO - __main__ - Step 350 Global step 350 Train loss 0.41 on epoch=12
05/22/2022 03:11:49 - INFO - __main__ - Global step 350 Train loss 0.38 Classification-F1 0.5068859326937106 on epoch=12
05/22/2022 03:11:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4390306971486457 -> 0.5068859326937106 on epoch=12, global_step=350
05/22/2022 03:11:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.32 on epoch=12
05/22/2022 03:11:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.34 on epoch=13
05/22/2022 03:11:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.26 on epoch=13
05/22/2022 03:11:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.23 on epoch=13
05/22/2022 03:12:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.31 on epoch=14
05/22/2022 03:12:15 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5226517986080451 on epoch=14
05/22/2022 03:12:15 - INFO - __main__ - Saving model with best Classification-F1: 0.5068859326937106 -> 0.5226517986080451 on epoch=14, global_step=400
05/22/2022 03:12:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.29 on epoch=14
05/22/2022 03:12:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=14
05/22/2022 03:12:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.27 on epoch=15
05/22/2022 03:12:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=15
05/22/2022 03:12:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=16
05/22/2022 03:12:41 - INFO - __main__ - Global step 450 Train loss 0.23 Classification-F1 0.6711101784018452 on epoch=16
05/22/2022 03:12:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5226517986080451 -> 0.6711101784018452 on epoch=16, global_step=450
05/22/2022 03:12:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=16
05/22/2022 03:12:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=16
05/22/2022 03:12:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.27 on epoch=17
05/22/2022 03:12:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=17
05/22/2022 03:12:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=17
05/22/2022 03:13:07 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6880805058062429 on epoch=17
05/22/2022 03:13:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6711101784018452 -> 0.6880805058062429 on epoch=17, global_step=500
05/22/2022 03:13:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.30 on epoch=18
05/22/2022 03:13:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.17 on epoch=18
05/22/2022 03:13:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.15 on epoch=18
05/22/2022 03:13:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=19
05/22/2022 03:13:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.22 on epoch=19
05/22/2022 03:13:32 - INFO - __main__ - Global step 550 Train loss 0.22 Classification-F1 0.7012001976718047 on epoch=19
05/22/2022 03:13:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6880805058062429 -> 0.7012001976718047 on epoch=19, global_step=550
05/22/2022 03:13:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=19
05/22/2022 03:13:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.23 on epoch=20
05/22/2022 03:13:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=20
05/22/2022 03:13:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=21
05/22/2022 03:13:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.23 on epoch=21
05/22/2022 03:13:58 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.5881844378927357 on epoch=21
05/22/2022 03:14:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.15 on epoch=21
05/22/2022 03:14:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.16 on epoch=22
05/22/2022 03:14:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=22
05/22/2022 03:14:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.15 on epoch=22
05/22/2022 03:14:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.25 on epoch=23
05/22/2022 03:14:23 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6315377992304733 on epoch=23
05/22/2022 03:14:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=23
05/22/2022 03:14:28 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=23
05/22/2022 03:14:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=24
05/22/2022 03:14:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=24
05/22/2022 03:14:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.11 on epoch=24
05/22/2022 03:14:48 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6174516653741208 on epoch=24
05/22/2022 03:14:51 - INFO - __main__ - Step 710 Global step 710 Train loss 0.24 on epoch=25
05/22/2022 03:14:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=25
05/22/2022 03:14:56 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=26
05/22/2022 03:14:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=26
05/22/2022 03:15:01 - INFO - __main__ - Step 750 Global step 750 Train loss 0.05 on epoch=26
05/22/2022 03:15:14 - INFO - __main__ - Global step 750 Train loss 0.14 Classification-F1 0.5814182238788865 on epoch=26
05/22/2022 03:15:16 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=27
05/22/2022 03:15:19 - INFO - __main__ - Step 770 Global step 770 Train loss 0.19 on epoch=27
05/22/2022 03:15:21 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=27
05/22/2022 03:15:24 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=28
05/22/2022 03:15:27 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=28
05/22/2022 03:15:39 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.661837934552138 on epoch=28
05/22/2022 03:15:42 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=28
05/22/2022 03:15:44 - INFO - __main__ - Step 820 Global step 820 Train loss 0.21 on epoch=29
05/22/2022 03:15:47 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=29
05/22/2022 03:15:49 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=29
05/22/2022 03:15:52 - INFO - __main__ - Step 850 Global step 850 Train loss 0.22 on epoch=30
05/22/2022 03:16:04 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.570502099358115 on epoch=30
05/22/2022 03:16:07 - INFO - __main__ - Step 860 Global step 860 Train loss 0.10 on epoch=30
05/22/2022 03:16:09 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=31
05/22/2022 03:16:12 - INFO - __main__ - Step 880 Global step 880 Train loss 0.15 on epoch=31
05/22/2022 03:16:15 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=31
05/22/2022 03:16:17 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=32
05/22/2022 03:16:30 - INFO - __main__ - Global step 900 Train loss 0.12 Classification-F1 0.5355283539354954 on epoch=32
05/22/2022 03:16:32 - INFO - __main__ - Step 910 Global step 910 Train loss 0.13 on epoch=32
05/22/2022 03:16:35 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=32
05/22/2022 03:16:37 - INFO - __main__ - Step 930 Global step 930 Train loss 0.12 on epoch=33
05/22/2022 03:16:40 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=33
05/22/2022 03:16:43 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=33
05/22/2022 03:16:55 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.508709049732245 on epoch=33
05/22/2022 03:16:58 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=34
05/22/2022 03:17:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=34
05/22/2022 03:17:03 - INFO - __main__ - Step 980 Global step 980 Train loss 0.04 on epoch=34
05/22/2022 03:17:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.18 on epoch=35
05/22/2022 03:17:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.07 on epoch=35
05/22/2022 03:17:21 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5658523601817713 on epoch=35
05/22/2022 03:17:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=36
05/22/2022 03:17:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=36
05/22/2022 03:17:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=36
05/22/2022 03:17:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=37
05/22/2022 03:17:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=37
05/22/2022 03:17:46 - INFO - __main__ - Global step 1050 Train loss 0.11 Classification-F1 0.622219963419338 on epoch=37
05/22/2022 03:17:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=37
05/22/2022 03:17:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=38
05/22/2022 03:17:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=38
05/22/2022 03:17:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=38
05/22/2022 03:17:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.11 on epoch=39
05/22/2022 03:18:11 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.5728032992636989 on epoch=39
05/22/2022 03:18:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=39
05/22/2022 03:18:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.05 on epoch=39
05/22/2022 03:18:19 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.17 on epoch=40
05/22/2022 03:18:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=40
05/22/2022 03:18:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=41
05/22/2022 03:18:37 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.5613602242025459 on epoch=41
05/22/2022 03:18:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.15 on epoch=41
05/22/2022 03:18:42 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.03 on epoch=41
05/22/2022 03:18:45 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=42
05/22/2022 03:18:47 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.13 on epoch=42
05/22/2022 03:18:50 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=42
05/22/2022 03:19:03 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5736398589313287 on epoch=42
05/22/2022 03:19:05 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=43
05/22/2022 03:19:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=43
05/22/2022 03:19:10 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.06 on epoch=43
05/22/2022 03:19:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=44
05/22/2022 03:19:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=44
05/22/2022 03:19:28 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.5166753360964061 on epoch=44
05/22/2022 03:19:31 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.04 on epoch=44
05/22/2022 03:19:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=45
05/22/2022 03:19:36 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=45
05/22/2022 03:19:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=46
05/22/2022 03:19:41 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.13 on epoch=46
05/22/2022 03:19:54 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.5429941810493927 on epoch=46
05/22/2022 03:19:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=46
05/22/2022 03:19:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=47
05/22/2022 03:20:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=47
05/22/2022 03:20:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=47
05/22/2022 03:20:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=48
05/22/2022 03:20:20 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.6052049233443985 on epoch=48
05/22/2022 03:20:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.08 on epoch=48
05/22/2022 03:20:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.02 on epoch=48
05/22/2022 03:20:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.13 on epoch=49
05/22/2022 03:20:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=49
05/22/2022 03:20:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=49
05/22/2022 03:20:46 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.5560701511951281 on epoch=49
05/22/2022 03:20:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.14 on epoch=50
05/22/2022 03:20:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=50
05/22/2022 03:20:53 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=51
05/22/2022 03:20:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=51
05/22/2022 03:20:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.02 on epoch=51
05/22/2022 03:21:11 - INFO - __main__ - Global step 1450 Train loss 0.09 Classification-F1 0.573820123945774 on epoch=51
05/22/2022 03:21:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=52
05/22/2022 03:21:16 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=52
05/22/2022 03:21:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.08 on epoch=52
05/22/2022 03:21:21 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=53
05/22/2022 03:21:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=53
05/22/2022 03:21:36 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.6277752179880367 on epoch=53
05/22/2022 03:21:39 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.04 on epoch=53
05/22/2022 03:21:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.11 on epoch=54
05/22/2022 03:21:44 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=54
05/22/2022 03:21:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.02 on epoch=54
05/22/2022 03:21:49 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=55
05/22/2022 03:22:01 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6106584411234467 on epoch=55
05/22/2022 03:22:04 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=55
05/22/2022 03:22:07 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=56
05/22/2022 03:22:09 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.21 on epoch=56
05/22/2022 03:22:12 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=56
05/22/2022 03:22:14 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=57
05/22/2022 03:22:27 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6308579763976433 on epoch=57
05/22/2022 03:22:30 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.11 on epoch=57
05/22/2022 03:22:32 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=57
05/22/2022 03:22:35 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=58
05/22/2022 03:22:38 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.08 on epoch=58
05/22/2022 03:22:40 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=58
05/22/2022 03:22:53 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.6704269327791305 on epoch=58
05/22/2022 03:22:55 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.14 on epoch=59
05/22/2022 03:22:58 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=59
05/22/2022 03:23:00 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=59
05/22/2022 03:23:03 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.08 on epoch=60
05/22/2022 03:23:06 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=60
05/22/2022 03:23:19 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.7262385446470145 on epoch=60
05/22/2022 03:23:19 - INFO - __main__ - Saving model with best Classification-F1: 0.7012001976718047 -> 0.7262385446470145 on epoch=60, global_step=1700
05/22/2022 03:23:21 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=61
05/22/2022 03:23:24 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.09 on epoch=61
05/22/2022 03:23:26 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.01 on epoch=61
05/22/2022 03:23:29 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.07 on epoch=62
05/22/2022 03:23:31 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=62
05/22/2022 03:23:44 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6340034057392628 on epoch=62
05/22/2022 03:23:47 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=62
05/22/2022 03:23:49 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=63
05/22/2022 03:23:52 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=63
05/22/2022 03:23:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.01 on epoch=63
05/22/2022 03:23:57 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.07 on epoch=64
05/22/2022 03:24:10 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.6131197982058953 on epoch=64
05/22/2022 03:24:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=64
05/22/2022 03:24:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=64
05/22/2022 03:24:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.09 on epoch=65
05/22/2022 03:24:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.03 on epoch=65
05/22/2022 03:24:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=66
05/22/2022 03:24:35 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.6641685019215757 on epoch=66
05/22/2022 03:24:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=66
05/22/2022 03:24:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=66
05/22/2022 03:24:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=67
05/22/2022 03:24:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=67
05/22/2022 03:24:48 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=67
05/22/2022 03:25:01 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.6550673114453852 on epoch=67
05/22/2022 03:25:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=68
05/22/2022 03:25:06 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=68
05/22/2022 03:25:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 03:25:11 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=69
05/22/2022 03:25:14 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=69
05/22/2022 03:25:26 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.650411156709638 on epoch=69
05/22/2022 03:25:29 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=69
05/22/2022 03:25:31 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=70
05/22/2022 03:25:34 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=70
05/22/2022 03:25:36 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=71
05/22/2022 03:25:39 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=71
05/22/2022 03:25:51 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6856963163034022 on epoch=71
05/22/2022 03:25:54 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=71
05/22/2022 03:25:56 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=72
05/22/2022 03:25:59 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=72
05/22/2022 03:26:02 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=72
05/22/2022 03:26:04 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=73
05/22/2022 03:26:16 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6930527682077265 on epoch=73
05/22/2022 03:26:19 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=73
05/22/2022 03:26:21 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=73
05/22/2022 03:26:24 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.09 on epoch=74
05/22/2022 03:26:27 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=74
05/22/2022 03:26:29 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=74
05/22/2022 03:26:42 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6953810205401059 on epoch=74
05/22/2022 03:26:44 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=75
05/22/2022 03:26:47 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=75
05/22/2022 03:26:50 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=76
05/22/2022 03:26:52 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=76
05/22/2022 03:26:55 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=76
05/22/2022 03:27:07 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.5971066383595532 on epoch=76
05/22/2022 03:27:10 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.02 on epoch=77
05/22/2022 03:27:12 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=77
05/22/2022 03:27:15 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=77
05/22/2022 03:27:17 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.09 on epoch=78
05/22/2022 03:27:20 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=78
05/22/2022 03:27:32 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.599666335214258 on epoch=78
05/22/2022 03:27:35 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 03:27:38 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=79
05/22/2022 03:27:40 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=79
05/22/2022 03:27:43 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=79
05/22/2022 03:27:45 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 03:27:58 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6046310881000556 on epoch=80
05/22/2022 03:28:01 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=80
05/22/2022 03:28:03 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=81
05/22/2022 03:28:06 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.06 on epoch=81
05/22/2022 03:28:08 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=81
05/22/2022 03:28:11 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=82
05/22/2022 03:28:23 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7504212793820915 on epoch=82
05/22/2022 03:28:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7262385446470145 -> 0.7504212793820915 on epoch=82, global_step=2300
05/22/2022 03:28:26 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=82
05/22/2022 03:28:29 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=82
05/22/2022 03:28:31 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=83
05/22/2022 03:28:34 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=83
05/22/2022 03:28:37 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=83
05/22/2022 03:28:49 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.7088911035611593 on epoch=83
05/22/2022 03:28:52 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=84
05/22/2022 03:28:55 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=84
05/22/2022 03:28:57 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=84
05/22/2022 03:29:00 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=85
05/22/2022 03:29:02 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 03:29:15 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7505467804461746 on epoch=85
05/22/2022 03:29:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7504212793820915 -> 0.7505467804461746 on epoch=85, global_step=2400
05/22/2022 03:29:17 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=86
05/22/2022 03:29:20 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 03:29:23 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=86
05/22/2022 03:29:25 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=87
05/22/2022 03:29:28 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=87
05/22/2022 03:29:40 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.6686049044743055 on epoch=87
05/22/2022 03:29:43 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=87
05/22/2022 03:29:45 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=88
05/22/2022 03:29:48 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=88
05/22/2022 03:29:51 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=88
05/22/2022 03:29:53 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=89
05/22/2022 03:30:06 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.6689481357667832 on epoch=89
05/22/2022 03:30:08 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=89
05/22/2022 03:30:11 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=89
05/22/2022 03:30:13 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.04 on epoch=90
05/22/2022 03:30:16 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=90
05/22/2022 03:30:18 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=91
05/22/2022 03:30:31 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.6624362760962634 on epoch=91
05/22/2022 03:30:33 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=91
05/22/2022 03:30:36 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=91
05/22/2022 03:30:39 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=92
05/22/2022 03:30:41 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=92
05/22/2022 03:30:44 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=92
05/22/2022 03:30:56 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.5609710460091927 on epoch=92
05/22/2022 03:30:59 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=93
05/22/2022 03:31:02 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 03:31:04 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=93
05/22/2022 03:31:07 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=94
05/22/2022 03:31:09 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=94
05/22/2022 03:31:22 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7062980167906264 on epoch=94
05/22/2022 03:31:24 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=94
05/22/2022 03:31:27 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=95
05/22/2022 03:31:30 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=95
05/22/2022 03:31:32 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=96
05/22/2022 03:31:35 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=96
05/22/2022 03:31:47 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.6062285886999059 on epoch=96
05/22/2022 03:31:50 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=96
05/22/2022 03:31:52 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=97
05/22/2022 03:31:55 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=97
05/22/2022 03:31:57 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=97
05/22/2022 03:32:00 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=98
05/22/2022 03:32:13 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.5981062737944264 on epoch=98
05/22/2022 03:32:15 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=98
05/22/2022 03:32:18 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=98
05/22/2022 03:32:20 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=99
05/22/2022 03:32:23 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=99
05/22/2022 03:32:25 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=99
05/22/2022 03:32:38 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6406237282566488 on epoch=99
05/22/2022 03:32:41 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=100
05/22/2022 03:32:43 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=100
05/22/2022 03:32:46 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 03:32:48 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=101
05/22/2022 03:32:51 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=101
05/22/2022 03:33:03 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7434416648484713 on epoch=101
05/22/2022 03:33:06 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=102
05/22/2022 03:33:08 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.00 on epoch=102
05/22/2022 03:33:11 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.00 on epoch=102
05/22/2022 03:33:14 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 03:33:16 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=103
05/22/2022 03:33:29 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7135085589919943 on epoch=103
05/22/2022 03:33:31 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=103
05/22/2022 03:33:34 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.10 on epoch=104
05/22/2022 03:33:37 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=104
05/22/2022 03:33:39 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=104
05/22/2022 03:33:42 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.12 on epoch=105
05/22/2022 03:33:54 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.794844179355759 on epoch=105
05/22/2022 03:33:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7505467804461746 -> 0.794844179355759 on epoch=105, global_step=2950
05/22/2022 03:33:57 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.00 on epoch=105
05/22/2022 03:34:00 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 03:34:02 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 03:34:05 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 03:34:07 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=107
05/22/2022 03:34:09 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:34:09 - INFO - __main__ - Printing 3 examples
05/22/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 03:34:09 - INFO - __main__ - ['Animal']
05/22/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 03:34:09 - INFO - __main__ - ['Animal']
05/22/2022 03:34:09 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 03:34:09 - INFO - __main__ - ['Animal']
05/22/2022 03:34:09 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:34:09 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:34:10 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 03:34:10 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:34:10 - INFO - __main__ - Printing 3 examples
05/22/2022 03:34:10 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 03:34:10 - INFO - __main__ - ['Animal']
05/22/2022 03:34:10 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 03:34:10 - INFO - __main__ - ['Animal']
05/22/2022 03:34:10 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 03:34:10 - INFO - __main__ - ['Animal']
05/22/2022 03:34:10 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:34:10 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:34:10 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 03:34:20 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7902393707029713 on epoch=107
05/22/2022 03:34:20 - INFO - __main__ - save last model!
05/22/2022 03:34:20 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 03:34:20 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 03:34:20 - INFO - __main__ - Printing 3 examples
05/22/2022 03:34:20 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 03:34:20 - INFO - __main__ - ['Animal']
05/22/2022 03:34:20 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 03:34:20 - INFO - __main__ - ['Animal']
05/22/2022 03:34:20 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 03:34:20 - INFO - __main__ - ['Village']
05/22/2022 03:34:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:34:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:34:26 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 03:34:26 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 03:34:27 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 03:34:27 - INFO - __main__ - Starting training!
05/22/2022 03:36:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_100_0.5_8_predictions.txt
05/22/2022 03:36:39 - INFO - __main__ - Classification-F1 on test data: 0.5891
05/22/2022 03:36:40 - INFO - __main__ - prefix=dbpedia_14_32_100, lr=0.5, bsz=8, dev_performance=0.794844179355759, test_performance=0.5891225906168484
05/22/2022 03:36:40 - INFO - __main__ - Running ... prefix=dbpedia_14_32_100, lr=0.4, bsz=8 ...
05/22/2022 03:36:41 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:36:41 - INFO - __main__ - Printing 3 examples
05/22/2022 03:36:41 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 03:36:41 - INFO - __main__ - ['Animal']
05/22/2022 03:36:41 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 03:36:41 - INFO - __main__ - ['Animal']
05/22/2022 03:36:41 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 03:36:41 - INFO - __main__ - ['Animal']
05/22/2022 03:36:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:36:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:36:42 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 03:36:42 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 03:36:42 - INFO - __main__ - Printing 3 examples
05/22/2022 03:36:42 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 03:36:42 - INFO - __main__ - ['Animal']
05/22/2022 03:36:42 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 03:36:42 - INFO - __main__ - ['Animal']
05/22/2022 03:36:42 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 03:36:42 - INFO - __main__ - ['Animal']
05/22/2022 03:36:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 03:36:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 03:36:42 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 03:37:01 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 03:37:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 03:37:02 - INFO - __main__ - Starting training!
05/22/2022 03:37:05 - INFO - __main__ - Step 10 Global step 10 Train loss 6.84 on epoch=0
05/22/2022 03:37:08 - INFO - __main__ - Step 20 Global step 20 Train loss 5.15 on epoch=0
05/22/2022 03:37:11 - INFO - __main__ - Step 30 Global step 30 Train loss 4.48 on epoch=1
05/22/2022 03:37:13 - INFO - __main__ - Step 40 Global step 40 Train loss 3.78 on epoch=1
05/22/2022 03:37:16 - INFO - __main__ - Step 50 Global step 50 Train loss 3.28 on epoch=1
05/22/2022 03:37:29 - INFO - __main__ - Global step 50 Train loss 4.70 Classification-F1 0.023418581527550705 on epoch=1
05/22/2022 03:37:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.023418581527550705 on epoch=1, global_step=50
05/22/2022 03:37:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.11 on epoch=2
05/22/2022 03:37:34 - INFO - __main__ - Step 70 Global step 70 Train loss 2.74 on epoch=2
05/22/2022 03:37:37 - INFO - __main__ - Step 80 Global step 80 Train loss 2.40 on epoch=2
05/22/2022 03:37:40 - INFO - __main__ - Step 90 Global step 90 Train loss 2.23 on epoch=3
05/22/2022 03:37:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.20 on epoch=3
05/22/2022 03:37:54 - INFO - __main__ - Global step 100 Train loss 2.54 Classification-F1 0.06749817637559573 on epoch=3
05/22/2022 03:37:54 - INFO - __main__ - Saving model with best Classification-F1: 0.023418581527550705 -> 0.06749817637559573 on epoch=3, global_step=100
05/22/2022 03:37:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.96 on epoch=3
05/22/2022 03:37:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.84 on epoch=4
05/22/2022 03:38:02 - INFO - __main__ - Step 130 Global step 130 Train loss 1.82 on epoch=4
05/22/2022 03:38:05 - INFO - __main__ - Step 140 Global step 140 Train loss 1.45 on epoch=4
05/22/2022 03:38:07 - INFO - __main__ - Step 150 Global step 150 Train loss 1.49 on epoch=5
05/22/2022 03:38:18 - INFO - __main__ - Global step 150 Train loss 1.71 Classification-F1 0.14150796788548595 on epoch=5
05/22/2022 03:38:18 - INFO - __main__ - Saving model with best Classification-F1: 0.06749817637559573 -> 0.14150796788548595 on epoch=5, global_step=150
05/22/2022 03:38:21 - INFO - __main__ - Step 160 Global step 160 Train loss 1.48 on epoch=5
05/22/2022 03:38:23 - INFO - __main__ - Step 170 Global step 170 Train loss 1.15 on epoch=6
05/22/2022 03:38:26 - INFO - __main__ - Step 180 Global step 180 Train loss 1.26 on epoch=6
05/22/2022 03:38:29 - INFO - __main__ - Step 190 Global step 190 Train loss 1.16 on epoch=6
05/22/2022 03:38:31 - INFO - __main__ - Step 200 Global step 200 Train loss 1.00 on epoch=7
05/22/2022 03:38:42 - INFO - __main__ - Global step 200 Train loss 1.21 Classification-F1 0.18229937241833127 on epoch=7
05/22/2022 03:38:42 - INFO - __main__ - Saving model with best Classification-F1: 0.14150796788548595 -> 0.18229937241833127 on epoch=7, global_step=200
05/22/2022 03:38:45 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=7
05/22/2022 03:38:48 - INFO - __main__ - Step 220 Global step 220 Train loss 0.79 on epoch=7
05/22/2022 03:38:50 - INFO - __main__ - Step 230 Global step 230 Train loss 0.80 on epoch=8
05/22/2022 03:38:53 - INFO - __main__ - Step 240 Global step 240 Train loss 0.78 on epoch=8
05/22/2022 03:38:55 - INFO - __main__ - Step 250 Global step 250 Train loss 0.61 on epoch=8
05/22/2022 03:39:07 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.2787049810494571 on epoch=8
05/22/2022 03:39:07 - INFO - __main__ - Saving model with best Classification-F1: 0.18229937241833127 -> 0.2787049810494571 on epoch=8, global_step=250
05/22/2022 03:39:10 - INFO - __main__ - Step 260 Global step 260 Train loss 0.69 on epoch=9
05/22/2022 03:39:13 - INFO - __main__ - Step 270 Global step 270 Train loss 0.68 on epoch=9
05/22/2022 03:39:15 - INFO - __main__ - Step 280 Global step 280 Train loss 0.61 on epoch=9
05/22/2022 03:39:18 - INFO - __main__ - Step 290 Global step 290 Train loss 0.67 on epoch=10
05/22/2022 03:39:20 - INFO - __main__ - Step 300 Global step 300 Train loss 0.55 on epoch=10
05/22/2022 03:39:33 - INFO - __main__ - Global step 300 Train loss 0.64 Classification-F1 0.3622973587907348 on epoch=10
05/22/2022 03:39:33 - INFO - __main__ - Saving model with best Classification-F1: 0.2787049810494571 -> 0.3622973587907348 on epoch=10, global_step=300
05/22/2022 03:39:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=11
05/22/2022 03:39:38 - INFO - __main__ - Step 320 Global step 320 Train loss 0.53 on epoch=11
05/22/2022 03:39:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=11
05/22/2022 03:39:43 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=12
05/22/2022 03:39:46 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=12
05/22/2022 03:39:58 - INFO - __main__ - Global step 350 Train loss 0.46 Classification-F1 0.39627076255315286 on epoch=12
05/22/2022 03:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.3622973587907348 -> 0.39627076255315286 on epoch=12, global_step=350
05/22/2022 03:40:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.44 on epoch=12
05/22/2022 03:40:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.40 on epoch=13
05/22/2022 03:40:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.38 on epoch=13
05/22/2022 03:40:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=13
05/22/2022 03:40:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.46 on epoch=14
05/22/2022 03:40:23 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.4720608426690569 on epoch=14
05/22/2022 03:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.39627076255315286 -> 0.4720608426690569 on epoch=14, global_step=400
05/22/2022 03:40:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.36 on epoch=14
05/22/2022 03:40:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.30 on epoch=14
05/22/2022 03:40:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.45 on epoch=15
05/22/2022 03:40:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.31 on epoch=15
05/22/2022 03:40:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.35 on epoch=16
05/22/2022 03:40:49 - INFO - __main__ - Global step 450 Train loss 0.35 Classification-F1 0.524491596254733 on epoch=16
05/22/2022 03:40:49 - INFO - __main__ - Saving model with best Classification-F1: 0.4720608426690569 -> 0.524491596254733 on epoch=16, global_step=450
05/22/2022 03:40:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.38 on epoch=16
05/22/2022 03:40:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.28 on epoch=16
05/22/2022 03:40:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.28 on epoch=17
05/22/2022 03:41:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=17
05/22/2022 03:41:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=17
05/22/2022 03:41:15 - INFO - __main__ - Global step 500 Train loss 0.29 Classification-F1 0.5356867869813097 on epoch=17
05/22/2022 03:41:15 - INFO - __main__ - Saving model with best Classification-F1: 0.524491596254733 -> 0.5356867869813097 on epoch=17, global_step=500
05/22/2022 03:41:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.29 on epoch=18
05/22/2022 03:41:20 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=18
05/22/2022 03:41:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.22 on epoch=18
05/22/2022 03:41:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.39 on epoch=19
05/22/2022 03:41:28 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=19
05/22/2022 03:41:41 - INFO - __main__ - Global step 550 Train loss 0.29 Classification-F1 0.6366793543948489 on epoch=19
05/22/2022 03:41:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5356867869813097 -> 0.6366793543948489 on epoch=19, global_step=550
05/22/2022 03:41:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.30 on epoch=19
05/22/2022 03:41:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.30 on epoch=20
05/22/2022 03:41:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.20 on epoch=20
05/22/2022 03:41:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.19 on epoch=21
05/22/2022 03:41:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.36 on epoch=21
05/22/2022 03:42:07 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.6020950852892403 on epoch=21
05/22/2022 03:42:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.18 on epoch=21
05/22/2022 03:42:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=22
05/22/2022 03:42:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=22
05/22/2022 03:42:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=22
05/22/2022 03:42:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=23
05/22/2022 03:42:32 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.5749336827026259 on epoch=23
05/22/2022 03:42:35 - INFO - __main__ - Step 660 Global step 660 Train loss 0.21 on epoch=23
05/22/2022 03:42:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=23
05/22/2022 03:42:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.27 on epoch=24
05/22/2022 03:42:43 - INFO - __main__ - Step 690 Global step 690 Train loss 0.17 on epoch=24
05/22/2022 03:42:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.15 on epoch=24
05/22/2022 03:42:58 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6035385726120699 on epoch=24
05/22/2022 03:43:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=25
05/22/2022 03:43:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.16 on epoch=25
05/22/2022 03:43:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=26
05/22/2022 03:43:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.33 on epoch=26
05/22/2022 03:43:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=26
05/22/2022 03:43:24 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.5951713926690784 on epoch=26
05/22/2022 03:43:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.17 on epoch=27
05/22/2022 03:43:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.23 on epoch=27
05/22/2022 03:43:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=27
05/22/2022 03:43:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.16 on epoch=28
05/22/2022 03:43:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=28
05/22/2022 03:43:49 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7043350716393734 on epoch=28
05/22/2022 03:43:49 - INFO - __main__ - Saving model with best Classification-F1: 0.6366793543948489 -> 0.7043350716393734 on epoch=28, global_step=800
05/22/2022 03:43:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=28
05/22/2022 03:43:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.20 on epoch=29
05/22/2022 03:43:57 - INFO - __main__ - Step 830 Global step 830 Train loss 0.15 on epoch=29
05/22/2022 03:44:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=29
05/22/2022 03:44:02 - INFO - __main__ - Step 850 Global step 850 Train loss 0.24 on epoch=30
05/22/2022 03:44:15 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6033219060197509 on epoch=30
05/22/2022 03:44:17 - INFO - __main__ - Step 860 Global step 860 Train loss 0.08 on epoch=30
05/22/2022 03:44:20 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=31
05/22/2022 03:44:23 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=31
05/22/2022 03:44:25 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=31
05/22/2022 03:44:28 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=32
05/22/2022 03:44:40 - INFO - __main__ - Global step 900 Train loss 0.13 Classification-F1 0.6328247544509724 on epoch=32
05/22/2022 03:44:43 - INFO - __main__ - Step 910 Global step 910 Train loss 0.21 on epoch=32
05/22/2022 03:44:45 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=32
05/22/2022 03:44:48 - INFO - __main__ - Step 930 Global step 930 Train loss 0.15 on epoch=33
05/22/2022 03:44:51 - INFO - __main__ - Step 940 Global step 940 Train loss 0.13 on epoch=33
05/22/2022 03:44:53 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=33
05/22/2022 03:45:06 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.6727366566047922 on epoch=33
05/22/2022 03:45:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.18 on epoch=34
05/22/2022 03:45:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.15 on epoch=34
05/22/2022 03:45:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=34
05/22/2022 03:45:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.28 on epoch=35
05/22/2022 03:45:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=35
05/22/2022 03:45:31 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.6338424785442609 on epoch=35
05/22/2022 03:45:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=36
05/22/2022 03:45:36 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.21 on epoch=36
05/22/2022 03:45:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=36
05/22/2022 03:45:41 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.13 on epoch=37
05/22/2022 03:45:44 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.15 on epoch=37
05/22/2022 03:45:56 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.6266471144596144 on epoch=37
05/22/2022 03:45:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.11 on epoch=37
05/22/2022 03:46:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.16 on epoch=38
05/22/2022 03:46:04 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.12 on epoch=38
05/22/2022 03:46:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=38
05/22/2022 03:46:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.19 on epoch=39
05/22/2022 03:46:21 - INFO - __main__ - Global step 1100 Train loss 0.14 Classification-F1 0.6247795139715577 on epoch=39
05/22/2022 03:46:24 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=39
05/22/2022 03:46:26 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=39
05/22/2022 03:46:29 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.26 on epoch=40
05/22/2022 03:46:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.07 on epoch=40
05/22/2022 03:46:34 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=41
05/22/2022 03:46:46 - INFO - __main__ - Global step 1150 Train loss 0.13 Classification-F1 0.621192618128446 on epoch=41
05/22/2022 03:46:49 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=41
05/22/2022 03:46:51 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=41
05/22/2022 03:46:54 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=42
05/22/2022 03:46:57 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=42
05/22/2022 03:46:59 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=42
05/22/2022 03:47:12 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.650273602783127 on epoch=42
05/22/2022 03:47:14 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=43
05/22/2022 03:47:17 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.12 on epoch=43
05/22/2022 03:47:19 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.05 on epoch=43
05/22/2022 03:47:22 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.15 on epoch=44
05/22/2022 03:47:25 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=44
05/22/2022 03:47:37 - INFO - __main__ - Global step 1250 Train loss 0.11 Classification-F1 0.5878669546872312 on epoch=44
05/22/2022 03:47:39 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=44
05/22/2022 03:47:42 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=45
05/22/2022 03:47:44 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=45
05/22/2022 03:47:47 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=46
05/22/2022 03:47:50 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.20 on epoch=46
05/22/2022 03:48:02 - INFO - __main__ - Global step 1300 Train loss 0.12 Classification-F1 0.6225020939451472 on epoch=46
05/22/2022 03:48:05 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=46
05/22/2022 03:48:07 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.10 on epoch=47
05/22/2022 03:48:10 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=47
05/22/2022 03:48:12 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=47
05/22/2022 03:48:15 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=48
05/22/2022 03:48:27 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.661577099340537 on epoch=48
05/22/2022 03:48:30 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.14 on epoch=48
05/22/2022 03:48:33 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=48
05/22/2022 03:48:35 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.12 on epoch=49
05/22/2022 03:48:38 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=49
05/22/2022 03:48:40 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=49
05/22/2022 03:48:53 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.6191775696424335 on epoch=49
05/22/2022 03:48:55 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.21 on epoch=50
05/22/2022 03:48:58 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.07 on epoch=50
05/22/2022 03:49:00 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=51
05/22/2022 03:49:03 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.18 on epoch=51
05/22/2022 03:49:05 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=51
05/22/2022 03:49:18 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.681134748984472 on epoch=51
05/22/2022 03:49:21 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=52
05/22/2022 03:49:23 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=52
05/22/2022 03:49:26 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.03 on epoch=52
05/22/2022 03:49:29 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.08 on epoch=53
05/22/2022 03:49:31 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=53
05/22/2022 03:49:44 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6674126590411726 on epoch=53
05/22/2022 03:49:46 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.03 on epoch=53
05/22/2022 03:49:49 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=54
05/22/2022 03:49:51 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=54
05/22/2022 03:49:54 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=54
05/22/2022 03:49:56 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=55
05/22/2022 03:50:09 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.6408548490711581 on epoch=55
05/22/2022 03:50:12 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=55
05/22/2022 03:50:14 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 03:50:17 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.20 on epoch=56
05/22/2022 03:50:19 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=56
05/22/2022 03:50:22 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.07 on epoch=57
05/22/2022 03:50:34 - INFO - __main__ - Global step 1600 Train loss 0.08 Classification-F1 0.6794926631610483 on epoch=57
05/22/2022 03:50:37 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=57
05/22/2022 03:50:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.04 on epoch=57
05/22/2022 03:50:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=58
05/22/2022 03:50:45 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.16 on epoch=58
05/22/2022 03:50:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=58
05/22/2022 03:51:00 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.5931136259005112 on epoch=58
05/22/2022 03:51:02 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.11 on epoch=59
05/22/2022 03:51:05 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.10 on epoch=59
05/22/2022 03:51:08 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.03 on epoch=59
05/22/2022 03:51:10 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.11 on epoch=60
05/22/2022 03:51:13 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=60
05/22/2022 03:51:26 - INFO - __main__ - Global step 1700 Train loss 0.08 Classification-F1 0.746047640630974 on epoch=60
05/22/2022 03:51:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7043350716393734 -> 0.746047640630974 on epoch=60, global_step=1700
05/22/2022 03:51:28 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=61
05/22/2022 03:51:31 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.19 on epoch=61
05/22/2022 03:51:33 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=61
05/22/2022 03:51:36 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.13 on epoch=62
05/22/2022 03:51:39 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=62
05/22/2022 03:51:51 - INFO - __main__ - Global step 1750 Train loss 0.09 Classification-F1 0.6987313676161822 on epoch=62
05/22/2022 03:51:54 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=62
05/22/2022 03:51:56 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.10 on epoch=63
05/22/2022 03:51:59 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=63
05/22/2022 03:52:01 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=63
05/22/2022 03:52:04 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=64
05/22/2022 03:52:16 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.7358974358974358 on epoch=64
05/22/2022 03:52:19 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=64
05/22/2022 03:52:22 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=64
05/22/2022 03:52:24 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=65
05/22/2022 03:52:27 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=65
05/22/2022 03:52:29 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=66
05/22/2022 03:52:42 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7942525325433097 on epoch=66
05/22/2022 03:52:42 - INFO - __main__ - Saving model with best Classification-F1: 0.746047640630974 -> 0.7942525325433097 on epoch=66, global_step=1850
05/22/2022 03:52:44 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.17 on epoch=66
05/22/2022 03:52:47 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=66
05/22/2022 03:52:50 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.07 on epoch=67
05/22/2022 03:52:52 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=67
05/22/2022 03:52:55 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=67
05/22/2022 03:53:07 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.7236909467146437 on epoch=67
05/22/2022 03:53:10 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=68
05/22/2022 03:53:12 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=68
05/22/2022 03:53:15 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 03:53:17 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.14 on epoch=69
05/22/2022 03:53:20 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=69
05/22/2022 03:53:33 - INFO - __main__ - Global step 1950 Train loss 0.07 Classification-F1 0.686031283769687 on epoch=69
05/22/2022 03:53:35 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=69
05/22/2022 03:53:38 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.13 on epoch=70
05/22/2022 03:53:40 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=70
05/22/2022 03:53:43 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=71
05/22/2022 03:53:45 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.09 on epoch=71
05/22/2022 03:53:58 - INFO - __main__ - Global step 2000 Train loss 0.07 Classification-F1 0.7900103812328045 on epoch=71
05/22/2022 03:54:01 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=71
05/22/2022 03:54:03 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.07 on epoch=72
05/22/2022 03:54:06 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=72
05/22/2022 03:54:08 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.01 on epoch=72
05/22/2022 03:54:11 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=73
05/22/2022 03:54:23 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.7081973402400494 on epoch=73
05/22/2022 03:54:26 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=73
05/22/2022 03:54:29 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=73
05/22/2022 03:54:31 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.12 on epoch=74
05/22/2022 03:54:34 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=74
05/22/2022 03:54:36 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=74
05/22/2022 03:54:49 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.7362301818127285 on epoch=74
05/22/2022 03:54:51 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=75
05/22/2022 03:54:54 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=75
05/22/2022 03:54:57 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=76
05/22/2022 03:54:59 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.14 on epoch=76
05/22/2022 03:55:02 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=76
05/22/2022 03:55:14 - INFO - __main__ - Global step 2150 Train loss 0.06 Classification-F1 0.7300969238772209 on epoch=76
05/22/2022 03:55:17 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=77
05/22/2022 03:55:19 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=77
05/22/2022 03:55:22 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=77
05/22/2022 03:55:24 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 03:55:27 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.09 on epoch=78
05/22/2022 03:55:39 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.7441772268097153 on epoch=78
05/22/2022 03:55:42 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 03:55:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=79
05/22/2022 03:55:47 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.13 on epoch=79
05/22/2022 03:55:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=79
05/22/2022 03:55:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.13 on epoch=80
05/22/2022 03:56:05 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7087848667486286 on epoch=80
05/22/2022 03:56:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 03:56:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 03:56:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.12 on epoch=81
05/22/2022 03:56:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=81
05/22/2022 03:56:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.06 on epoch=82
05/22/2022 03:56:30 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6709526722920257 on epoch=82
05/22/2022 03:56:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=82
05/22/2022 03:56:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=82
05/22/2022 03:56:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=83
05/22/2022 03:56:40 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.08 on epoch=83
05/22/2022 03:56:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=83
05/22/2022 03:56:55 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.7124295115774839 on epoch=83
05/22/2022 03:56:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=84
05/22/2022 03:57:00 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=84
05/22/2022 03:57:03 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=84
05/22/2022 03:57:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=85
05/22/2022 03:57:08 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 03:57:21 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.7171095921924676 on epoch=85
05/22/2022 03:57:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=86
05/22/2022 03:57:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 03:57:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=86
05/22/2022 03:57:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=87
05/22/2022 03:57:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=87
05/22/2022 03:57:46 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7541193906080209 on epoch=87
05/22/2022 03:57:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=87
05/22/2022 03:57:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=88
05/22/2022 03:57:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 03:57:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 03:57:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=89
05/22/2022 03:58:11 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8559666029838426 on epoch=89
05/22/2022 03:58:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7942525325433097 -> 0.8559666029838426 on epoch=89, global_step=2500
05/22/2022 03:58:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=89
05/22/2022 03:58:16 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 03:58:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.11 on epoch=90
05/22/2022 03:58:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=90
05/22/2022 03:58:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=91
05/22/2022 03:58:36 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.8077045658248804 on epoch=91
05/22/2022 03:58:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.13 on epoch=91
05/22/2022 03:58:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 03:58:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.09 on epoch=92
05/22/2022 03:58:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.06 on epoch=92
05/22/2022 03:58:50 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=92
05/22/2022 03:59:02 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.7609777378561532 on epoch=92
05/22/2022 03:59:05 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=93
05/22/2022 03:59:07 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=93
05/22/2022 03:59:10 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=93
05/22/2022 03:59:12 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.08 on epoch=94
05/22/2022 03:59:15 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=94
05/22/2022 03:59:27 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7543367737601129 on epoch=94
05/22/2022 03:59:30 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=94
05/22/2022 03:59:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=95
05/22/2022 03:59:35 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=95
05/22/2022 03:59:38 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=96
05/22/2022 03:59:40 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.07 on epoch=96
05/22/2022 03:59:52 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.7946329688954996 on epoch=96
05/22/2022 03:59:55 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=96
05/22/2022 03:59:58 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=97
05/22/2022 04:00:00 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=97
05/22/2022 04:00:03 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=97
05/22/2022 04:00:05 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=98
05/22/2022 04:00:17 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.7989995101810518 on epoch=98
05/22/2022 04:00:20 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=98
05/22/2022 04:00:23 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.03 on epoch=98
05/22/2022 04:00:25 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=99
05/22/2022 04:00:28 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=99
05/22/2022 04:00:31 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=99
05/22/2022 04:00:43 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7154955785484782 on epoch=99
05/22/2022 04:00:45 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=100
05/22/2022 04:00:48 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=100
05/22/2022 04:00:50 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.04 on epoch=101
05/22/2022 04:00:53 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.11 on epoch=101
05/22/2022 04:00:56 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=101
05/22/2022 04:01:08 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7589654732892589 on epoch=101
05/22/2022 04:01:11 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=102
05/22/2022 04:01:13 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=102
05/22/2022 04:01:16 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=102
05/22/2022 04:01:18 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=103
05/22/2022 04:01:21 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=103
05/22/2022 04:01:33 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.7166376753100877 on epoch=103
05/22/2022 04:01:35 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=103
05/22/2022 04:01:38 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=104
05/22/2022 04:01:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=104
05/22/2022 04:01:43 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=104
05/22/2022 04:01:46 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.12 on epoch=105
05/22/2022 04:01:58 - INFO - __main__ - Global step 2950 Train loss 0.03 Classification-F1 0.7566796229134821 on epoch=105
05/22/2022 04:02:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 04:02:03 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=106
05/22/2022 04:02:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.05 on epoch=106
05/22/2022 04:02:08 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=106
05/22/2022 04:02:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=107
05/22/2022 04:02:12 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:02:12 - INFO - __main__ - Printing 3 examples
05/22/2022 04:02:12 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 04:02:12 - INFO - __main__ - ['Animal']
05/22/2022 04:02:12 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 04:02:12 - INFO - __main__ - ['Animal']
05/22/2022 04:02:12 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 04:02:12 - INFO - __main__ - ['Animal']
05/22/2022 04:02:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:02:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:02:13 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 04:02:13 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:02:13 - INFO - __main__ - Printing 3 examples
05/22/2022 04:02:13 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 04:02:13 - INFO - __main__ - ['Animal']
05/22/2022 04:02:13 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 04:02:13 - INFO - __main__ - ['Animal']
05/22/2022 04:02:13 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 04:02:13 - INFO - __main__ - ['Animal']
05/22/2022 04:02:13 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:02:13 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:02:13 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 04:02:23 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.8040438230648235 on epoch=107
05/22/2022 04:02:23 - INFO - __main__ - save last model!
05/22/2022 04:02:23 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 04:02:23 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 04:02:23 - INFO - __main__ - Printing 3 examples
05/22/2022 04:02:23 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 04:02:23 - INFO - __main__ - ['Animal']
05/22/2022 04:02:23 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 04:02:23 - INFO - __main__ - ['Animal']
05/22/2022 04:02:23 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 04:02:23 - INFO - __main__ - ['Village']
05/22/2022 04:02:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:02:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:02:28 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 04:02:32 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 04:02:33 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 04:02:33 - INFO - __main__ - Starting training!
05/22/2022 04:04:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_100_0.4_8_predictions.txt
05/22/2022 04:04:34 - INFO - __main__ - Classification-F1 on test data: 0.6188
05/22/2022 04:04:35 - INFO - __main__ - prefix=dbpedia_14_32_100, lr=0.4, bsz=8, dev_performance=0.8559666029838426, test_performance=0.6188083448073552
05/22/2022 04:04:35 - INFO - __main__ - Running ... prefix=dbpedia_14_32_100, lr=0.3, bsz=8 ...
05/22/2022 04:04:36 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:04:36 - INFO - __main__ - Printing 3 examples
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:04:36 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:04:36 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 04:04:36 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:04:36 - INFO - __main__ - Printing 3 examples
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 04:04:36 - INFO - __main__ - ['Animal']
05/22/2022 04:04:36 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:04:36 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:04:37 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 04:04:55 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 04:04:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 04:04:56 - INFO - __main__ - Starting training!
05/22/2022 04:04:59 - INFO - __main__ - Step 10 Global step 10 Train loss 7.82 on epoch=0
05/22/2022 04:05:02 - INFO - __main__ - Step 20 Global step 20 Train loss 5.05 on epoch=0
05/22/2022 04:05:04 - INFO - __main__ - Step 30 Global step 30 Train loss 4.58 on epoch=1
05/22/2022 04:05:07 - INFO - __main__ - Step 40 Global step 40 Train loss 4.04 on epoch=1
05/22/2022 04:05:09 - INFO - __main__ - Step 50 Global step 50 Train loss 3.68 on epoch=1
05/22/2022 04:05:23 - INFO - __main__ - Global step 50 Train loss 5.04 Classification-F1 0.018082072054329306 on epoch=1
05/22/2022 04:05:23 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.018082072054329306 on epoch=1, global_step=50
05/22/2022 04:05:26 - INFO - __main__ - Step 60 Global step 60 Train loss 3.32 on epoch=2
05/22/2022 04:05:28 - INFO - __main__ - Step 70 Global step 70 Train loss 3.10 on epoch=2
05/22/2022 04:05:31 - INFO - __main__ - Step 80 Global step 80 Train loss 2.74 on epoch=2
05/22/2022 04:05:34 - INFO - __main__ - Step 90 Global step 90 Train loss 2.45 on epoch=3
05/22/2022 04:05:36 - INFO - __main__ - Step 100 Global step 100 Train loss 2.44 on epoch=3
05/22/2022 04:05:49 - INFO - __main__ - Global step 100 Train loss 2.81 Classification-F1 0.05048056864197712 on epoch=3
05/22/2022 04:05:49 - INFO - __main__ - Saving model with best Classification-F1: 0.018082072054329306 -> 0.05048056864197712 on epoch=3, global_step=100
05/22/2022 04:05:52 - INFO - __main__ - Step 110 Global step 110 Train loss 2.33 on epoch=3
05/22/2022 04:05:54 - INFO - __main__ - Step 120 Global step 120 Train loss 2.04 on epoch=4
05/22/2022 04:05:57 - INFO - __main__ - Step 130 Global step 130 Train loss 2.07 on epoch=4
05/22/2022 04:05:59 - INFO - __main__ - Step 140 Global step 140 Train loss 1.88 on epoch=4
05/22/2022 04:06:02 - INFO - __main__ - Step 150 Global step 150 Train loss 1.82 on epoch=5
05/22/2022 04:06:13 - INFO - __main__ - Global step 150 Train loss 2.03 Classification-F1 0.09408775225646293 on epoch=5
05/22/2022 04:06:13 - INFO - __main__ - Saving model with best Classification-F1: 0.05048056864197712 -> 0.09408775225646293 on epoch=5, global_step=150
05/22/2022 04:06:15 - INFO - __main__ - Step 160 Global step 160 Train loss 1.72 on epoch=5
05/22/2022 04:06:18 - INFO - __main__ - Step 170 Global step 170 Train loss 1.64 on epoch=6
05/22/2022 04:06:20 - INFO - __main__ - Step 180 Global step 180 Train loss 1.60 on epoch=6
05/22/2022 04:06:23 - INFO - __main__ - Step 190 Global step 190 Train loss 1.49 on epoch=6
05/22/2022 04:06:25 - INFO - __main__ - Step 200 Global step 200 Train loss 1.42 on epoch=7
05/22/2022 04:06:37 - INFO - __main__ - Global step 200 Train loss 1.57 Classification-F1 0.14161231174909272 on epoch=7
05/22/2022 04:06:37 - INFO - __main__ - Saving model with best Classification-F1: 0.09408775225646293 -> 0.14161231174909272 on epoch=7, global_step=200
05/22/2022 04:06:39 - INFO - __main__ - Step 210 Global step 210 Train loss 1.31 on epoch=7
05/22/2022 04:06:42 - INFO - __main__ - Step 220 Global step 220 Train loss 1.22 on epoch=7
05/22/2022 04:06:44 - INFO - __main__ - Step 230 Global step 230 Train loss 1.07 on epoch=8
05/22/2022 04:06:47 - INFO - __main__ - Step 240 Global step 240 Train loss 1.16 on epoch=8
05/22/2022 04:06:50 - INFO - __main__ - Step 250 Global step 250 Train loss 1.06 on epoch=8
05/22/2022 04:07:00 - INFO - __main__ - Global step 250 Train loss 1.16 Classification-F1 0.17867023492447465 on epoch=8
05/22/2022 04:07:00 - INFO - __main__ - Saving model with best Classification-F1: 0.14161231174909272 -> 0.17867023492447465 on epoch=8, global_step=250
05/22/2022 04:07:03 - INFO - __main__ - Step 260 Global step 260 Train loss 0.99 on epoch=9
05/22/2022 04:07:06 - INFO - __main__ - Step 270 Global step 270 Train loss 1.01 on epoch=9
05/22/2022 04:07:08 - INFO - __main__ - Step 280 Global step 280 Train loss 0.76 on epoch=9
05/22/2022 04:07:11 - INFO - __main__ - Step 290 Global step 290 Train loss 0.93 on epoch=10
05/22/2022 04:07:13 - INFO - __main__ - Step 300 Global step 300 Train loss 0.68 on epoch=10
05/22/2022 04:07:25 - INFO - __main__ - Global step 300 Train loss 0.88 Classification-F1 0.2782479914014583 on epoch=10
05/22/2022 04:07:25 - INFO - __main__ - Saving model with best Classification-F1: 0.17867023492447465 -> 0.2782479914014583 on epoch=10, global_step=300
05/22/2022 04:07:27 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=11
05/22/2022 04:07:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.72 on epoch=11
05/22/2022 04:07:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.66 on epoch=11
05/22/2022 04:07:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.63 on epoch=12
05/22/2022 04:07:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.58 on epoch=12
05/22/2022 04:07:50 - INFO - __main__ - Global step 350 Train loss 0.66 Classification-F1 0.3285940317091487 on epoch=12
05/22/2022 04:07:50 - INFO - __main__ - Saving model with best Classification-F1: 0.2782479914014583 -> 0.3285940317091487 on epoch=12, global_step=350
05/22/2022 04:07:52 - INFO - __main__ - Step 360 Global step 360 Train loss 0.60 on epoch=12
05/22/2022 04:07:55 - INFO - __main__ - Step 370 Global step 370 Train loss 0.66 on epoch=13
05/22/2022 04:07:57 - INFO - __main__ - Step 380 Global step 380 Train loss 0.61 on epoch=13
05/22/2022 04:08:00 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=13
05/22/2022 04:08:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.62 on epoch=14
05/22/2022 04:08:15 - INFO - __main__ - Global step 400 Train loss 0.59 Classification-F1 0.358618213997248 on epoch=14
05/22/2022 04:08:15 - INFO - __main__ - Saving model with best Classification-F1: 0.3285940317091487 -> 0.358618213997248 on epoch=14, global_step=400
05/22/2022 04:08:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.55 on epoch=14
05/22/2022 04:08:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.38 on epoch=14
05/22/2022 04:08:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.50 on epoch=15
05/22/2022 04:08:25 - INFO - __main__ - Step 440 Global step 440 Train loss 0.38 on epoch=15
05/22/2022 04:08:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=16
05/22/2022 04:08:41 - INFO - __main__ - Global step 450 Train loss 0.43 Classification-F1 0.4604280653868153 on epoch=16
05/22/2022 04:08:41 - INFO - __main__ - Saving model with best Classification-F1: 0.358618213997248 -> 0.4604280653868153 on epoch=16, global_step=450
05/22/2022 04:08:43 - INFO - __main__ - Step 460 Global step 460 Train loss 0.41 on epoch=16
05/22/2022 04:08:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.48 on epoch=16
05/22/2022 04:08:48 - INFO - __main__ - Step 480 Global step 480 Train loss 0.45 on epoch=17
05/22/2022 04:08:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=17
05/22/2022 04:08:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.35 on epoch=17
05/22/2022 04:09:07 - INFO - __main__ - Global step 500 Train loss 0.41 Classification-F1 0.44929274951412235 on epoch=17
05/22/2022 04:09:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.34 on epoch=18
05/22/2022 04:09:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=18
05/22/2022 04:09:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.32 on epoch=18
05/22/2022 04:09:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.49 on epoch=19
05/22/2022 04:09:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=19
05/22/2022 04:09:33 - INFO - __main__ - Global step 550 Train loss 0.39 Classification-F1 0.554691197121549 on epoch=19
05/22/2022 04:09:33 - INFO - __main__ - Saving model with best Classification-F1: 0.4604280653868153 -> 0.554691197121549 on epoch=19, global_step=550
05/22/2022 04:09:35 - INFO - __main__ - Step 560 Global step 560 Train loss 0.21 on epoch=19
05/22/2022 04:09:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.39 on epoch=20
05/22/2022 04:09:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=20
05/22/2022 04:09:43 - INFO - __main__ - Step 590 Global step 590 Train loss 0.28 on epoch=21
05/22/2022 04:09:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.39 on epoch=21
05/22/2022 04:09:58 - INFO - __main__ - Global step 600 Train loss 0.33 Classification-F1 0.5507535247876009 on epoch=21
05/22/2022 04:10:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=21
05/22/2022 04:10:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.31 on epoch=22
05/22/2022 04:10:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.33 on epoch=22
05/22/2022 04:10:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=22
05/22/2022 04:10:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.28 on epoch=23
05/22/2022 04:10:24 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.5710883505251763 on epoch=23
05/22/2022 04:10:24 - INFO - __main__ - Saving model with best Classification-F1: 0.554691197121549 -> 0.5710883505251763 on epoch=23, global_step=650
05/22/2022 04:10:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.27 on epoch=23
05/22/2022 04:10:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.18 on epoch=23
05/22/2022 04:10:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.33 on epoch=24
05/22/2022 04:10:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.28 on epoch=24
05/22/2022 04:10:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=24
05/22/2022 04:10:50 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.5676767143443884 on epoch=24
05/22/2022 04:10:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.29 on epoch=25
05/22/2022 04:10:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=25
05/22/2022 04:10:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=26
05/22/2022 04:11:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.25 on epoch=26
05/22/2022 04:11:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.17 on epoch=26
05/22/2022 04:11:16 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.5528469445064382 on epoch=26
05/22/2022 04:11:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=27
05/22/2022 04:11:21 - INFO - __main__ - Step 770 Global step 770 Train loss 0.24 on epoch=27
05/22/2022 04:11:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.11 on epoch=27
05/22/2022 04:11:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.22 on epoch=28
05/22/2022 04:11:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=28
05/22/2022 04:11:41 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.5724365499164824 on epoch=28
05/22/2022 04:11:41 - INFO - __main__ - Saving model with best Classification-F1: 0.5710883505251763 -> 0.5724365499164824 on epoch=28, global_step=800
05/22/2022 04:11:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=28
05/22/2022 04:11:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.31 on epoch=29
05/22/2022 04:11:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.16 on epoch=29
05/22/2022 04:11:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=29
05/22/2022 04:11:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=30
05/22/2022 04:12:06 - INFO - __main__ - Global step 850 Train loss 0.21 Classification-F1 0.5425043057741005 on epoch=30
05/22/2022 04:12:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.22 on epoch=30
05/22/2022 04:12:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.15 on epoch=31
05/22/2022 04:12:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.33 on epoch=31
05/22/2022 04:12:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.16 on epoch=31
05/22/2022 04:12:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.19 on epoch=32
05/22/2022 04:12:32 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5459348170230516 on epoch=32
05/22/2022 04:12:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.19 on epoch=32
05/22/2022 04:12:37 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=32
05/22/2022 04:12:40 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=33
05/22/2022 04:12:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.27 on epoch=33
05/22/2022 04:12:45 - INFO - __main__ - Step 950 Global step 950 Train loss 0.14 on epoch=33
05/22/2022 04:12:57 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.5811753045415633 on epoch=33
05/22/2022 04:12:57 - INFO - __main__ - Saving model with best Classification-F1: 0.5724365499164824 -> 0.5811753045415633 on epoch=33, global_step=950
05/22/2022 04:12:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.26 on epoch=34
05/22/2022 04:13:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=34
05/22/2022 04:13:05 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=34
05/22/2022 04:13:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.19 on epoch=35
05/22/2022 04:13:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=35
05/22/2022 04:13:22 - INFO - __main__ - Global step 1000 Train loss 0.18 Classification-F1 0.5226642013267567 on epoch=35
05/22/2022 04:13:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.14 on epoch=36
05/22/2022 04:13:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.27 on epoch=36
05/22/2022 04:13:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.14 on epoch=36
05/22/2022 04:13:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=37
05/22/2022 04:13:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.18 on epoch=37
05/22/2022 04:13:47 - INFO - __main__ - Global step 1050 Train loss 0.19 Classification-F1 0.5132756430399155 on epoch=37
05/22/2022 04:13:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=37
05/22/2022 04:13:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.18 on epoch=38
05/22/2022 04:13:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=38
05/22/2022 04:13:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=38
05/22/2022 04:14:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.22 on epoch=39
05/22/2022 04:14:13 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.544282002007442 on epoch=39
05/22/2022 04:14:15 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=39
05/22/2022 04:14:18 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.12 on epoch=39
05/22/2022 04:14:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.29 on epoch=40
05/22/2022 04:14:23 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.11 on epoch=40
05/22/2022 04:14:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.16 on epoch=41
05/22/2022 04:14:38 - INFO - __main__ - Global step 1150 Train loss 0.16 Classification-F1 0.5816169741078608 on epoch=41
05/22/2022 04:14:38 - INFO - __main__ - Saving model with best Classification-F1: 0.5811753045415633 -> 0.5816169741078608 on epoch=41, global_step=1150
05/22/2022 04:14:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=41
05/22/2022 04:14:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.12 on epoch=41
05/22/2022 04:14:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.12 on epoch=42
05/22/2022 04:14:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.22 on epoch=42
05/22/2022 04:14:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.09 on epoch=42
05/22/2022 04:15:03 - INFO - __main__ - Global step 1200 Train loss 0.15 Classification-F1 0.5398588162562311 on epoch=42
05/22/2022 04:15:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=43
05/22/2022 04:15:08 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=43
05/22/2022 04:15:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=43
05/22/2022 04:15:13 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.16 on epoch=44
05/22/2022 04:15:16 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=44
05/22/2022 04:15:29 - INFO - __main__ - Global step 1250 Train loss 0.14 Classification-F1 0.6102285176010345 on epoch=44
05/22/2022 04:15:29 - INFO - __main__ - Saving model with best Classification-F1: 0.5816169741078608 -> 0.6102285176010345 on epoch=44, global_step=1250
05/22/2022 04:15:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=44
05/22/2022 04:15:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=45
05/22/2022 04:15:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=45
05/22/2022 04:15:39 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.06 on epoch=46
05/22/2022 04:15:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.16 on epoch=46
05/22/2022 04:15:54 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.564778429380931 on epoch=46
05/22/2022 04:15:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=46
05/22/2022 04:15:59 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.17 on epoch=47
05/22/2022 04:16:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.17 on epoch=47
05/22/2022 04:16:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.12 on epoch=47
05/22/2022 04:16:07 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.19 on epoch=48
05/22/2022 04:16:19 - INFO - __main__ - Global step 1350 Train loss 0.14 Classification-F1 0.5759216217278289 on epoch=48
05/22/2022 04:16:22 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.11 on epoch=48
05/22/2022 04:16:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=48
05/22/2022 04:16:27 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.21 on epoch=49
05/22/2022 04:16:30 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=49
05/22/2022 04:16:32 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.05 on epoch=49
05/22/2022 04:16:45 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.5928467121916189 on epoch=49
05/22/2022 04:16:47 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.19 on epoch=50
05/22/2022 04:16:50 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=50
05/22/2022 04:16:52 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=51
05/22/2022 04:16:55 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.24 on epoch=51
05/22/2022 04:16:58 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=51
05/22/2022 04:17:10 - INFO - __main__ - Global step 1450 Train loss 0.14 Classification-F1 0.6141460987578101 on epoch=51
05/22/2022 04:17:10 - INFO - __main__ - Saving model with best Classification-F1: 0.6102285176010345 -> 0.6141460987578101 on epoch=51, global_step=1450
05/22/2022 04:17:13 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=52
05/22/2022 04:17:15 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.12 on epoch=52
05/22/2022 04:17:18 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.10 on epoch=52
05/22/2022 04:17:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.11 on epoch=53
05/22/2022 04:17:23 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.12 on epoch=53
05/22/2022 04:17:35 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.6190647083931852 on epoch=53
05/22/2022 04:17:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6141460987578101 -> 0.6190647083931852 on epoch=53, global_step=1500
05/22/2022 04:17:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=53
05/22/2022 04:17:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.16 on epoch=54
05/22/2022 04:17:43 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=54
05/22/2022 04:17:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=54
05/22/2022 04:17:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.16 on epoch=55
05/22/2022 04:18:00 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.5596009737237139 on epoch=55
05/22/2022 04:18:02 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=55
05/22/2022 04:18:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=56
05/22/2022 04:18:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.18 on epoch=56
05/22/2022 04:18:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=56
05/22/2022 04:18:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=57
05/22/2022 04:18:25 - INFO - __main__ - Global step 1600 Train loss 0.10 Classification-F1 0.48541831925532763 on epoch=57
05/22/2022 04:18:27 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=57
05/22/2022 04:18:30 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=57
05/22/2022 04:18:32 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.11 on epoch=58
05/22/2022 04:18:35 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=58
05/22/2022 04:18:38 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.07 on epoch=58
05/22/2022 04:18:50 - INFO - __main__ - Global step 1650 Train loss 0.10 Classification-F1 0.529529907718279 on epoch=58
05/22/2022 04:18:53 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.18 on epoch=59
05/22/2022 04:18:56 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=59
05/22/2022 04:18:58 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=59
05/22/2022 04:19:01 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.17 on epoch=60
05/22/2022 04:19:04 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=60
05/22/2022 04:19:16 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.5600895111999445 on epoch=60
05/22/2022 04:19:18 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=61
05/22/2022 04:19:21 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.15 on epoch=61
05/22/2022 04:19:23 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=61
05/22/2022 04:19:26 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=62
05/22/2022 04:19:29 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.12 on epoch=62
05/22/2022 04:19:41 - INFO - __main__ - Global step 1750 Train loss 0.10 Classification-F1 0.5536968575826855 on epoch=62
05/22/2022 04:19:43 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.03 on epoch=62
05/22/2022 04:19:46 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.13 on epoch=63
05/22/2022 04:19:49 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=63
05/22/2022 04:19:51 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=63
05/22/2022 04:19:54 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.14 on epoch=64
05/22/2022 04:20:06 - INFO - __main__ - Global step 1800 Train loss 0.10 Classification-F1 0.5551081837727948 on epoch=64
05/22/2022 04:20:08 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=64
05/22/2022 04:20:11 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=64
05/22/2022 04:20:13 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.17 on epoch=65
05/22/2022 04:20:16 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 04:20:18 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=66
05/22/2022 04:20:31 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.5928951312851909 on epoch=66
05/22/2022 04:20:33 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.18 on epoch=66
05/22/2022 04:20:36 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=66
05/22/2022 04:20:38 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=67
05/22/2022 04:20:41 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.11 on epoch=67
05/22/2022 04:20:43 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=67
05/22/2022 04:20:56 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.6266431925501841 on epoch=67
05/22/2022 04:20:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6190647083931852 -> 0.6266431925501841 on epoch=67, global_step=1900
05/22/2022 04:20:59 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=68
05/22/2022 04:21:01 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.08 on epoch=68
05/22/2022 04:21:04 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.08 on epoch=68
05/22/2022 04:21:06 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=69
05/22/2022 04:21:09 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=69
05/22/2022 04:21:22 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.6343079931493022 on epoch=69
05/22/2022 04:21:22 - INFO - __main__ - Saving model with best Classification-F1: 0.6266431925501841 -> 0.6343079931493022 on epoch=69, global_step=1950
05/22/2022 04:21:24 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=69
05/22/2022 04:21:27 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.20 on epoch=70
05/22/2022 04:21:29 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=70
05/22/2022 04:21:32 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=71
05/22/2022 04:21:34 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=71
05/22/2022 04:21:47 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.6354457624947603 on epoch=71
05/22/2022 04:21:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6343079931493022 -> 0.6354457624947603 on epoch=71, global_step=2000
05/22/2022 04:21:50 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=71
05/22/2022 04:21:52 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.10 on epoch=72
05/22/2022 04:21:55 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.08 on epoch=72
05/22/2022 04:21:57 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=72
05/22/2022 04:22:00 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.10 on epoch=73
05/22/2022 04:22:12 - INFO - __main__ - Global step 2050 Train loss 0.07 Classification-F1 0.571649682261513 on epoch=73
05/22/2022 04:22:15 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.06 on epoch=73
05/22/2022 04:22:18 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=73
05/22/2022 04:22:20 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.15 on epoch=74
05/22/2022 04:22:23 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=74
05/22/2022 04:22:26 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=74
05/22/2022 04:22:38 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6362806359447444 on epoch=74
05/22/2022 04:22:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6354457624947603 -> 0.6362806359447444 on epoch=74, global_step=2100
05/22/2022 04:22:41 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.22 on epoch=75
05/22/2022 04:22:44 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=75
05/22/2022 04:22:46 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=76
05/22/2022 04:22:49 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.18 on epoch=76
05/22/2022 04:22:51 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=76
05/22/2022 04:23:04 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6412336974672199 on epoch=76
05/22/2022 04:23:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6362806359447444 -> 0.6412336974672199 on epoch=76, global_step=2150
05/22/2022 04:23:06 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=77
05/22/2022 04:23:09 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=77
05/22/2022 04:23:12 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=77
05/22/2022 04:23:14 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=78
05/22/2022 04:23:17 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=78
05/22/2022 04:23:29 - INFO - __main__ - Global step 2200 Train loss 0.08 Classification-F1 0.6431435649521016 on epoch=78
05/22/2022 04:23:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6412336974672199 -> 0.6431435649521016 on epoch=78, global_step=2200
05/22/2022 04:23:32 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=78
05/22/2022 04:23:34 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.10 on epoch=79
05/22/2022 04:23:37 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=79
05/22/2022 04:23:40 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=79
05/22/2022 04:23:42 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.17 on epoch=80
05/22/2022 04:23:55 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.5839246717043735 on epoch=80
05/22/2022 04:23:57 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 04:24:00 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.05 on epoch=81
05/22/2022 04:24:02 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.16 on epoch=81
05/22/2022 04:24:05 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=81
05/22/2022 04:24:08 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.10 on epoch=82
05/22/2022 04:24:20 - INFO - __main__ - Global step 2300 Train loss 0.07 Classification-F1 0.5979706754166515 on epoch=82
05/22/2022 04:24:23 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=82
05/22/2022 04:24:25 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=82
05/22/2022 04:24:28 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=83
05/22/2022 04:24:30 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=83
05/22/2022 04:24:33 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=83
05/22/2022 04:24:46 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.5731616084711783 on epoch=83
05/22/2022 04:24:48 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.08 on epoch=84
05/22/2022 04:24:51 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=84
05/22/2022 04:24:53 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=84
05/22/2022 04:24:56 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.08 on epoch=85
05/22/2022 04:24:59 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=85
05/22/2022 04:25:11 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.5704979795872582 on epoch=85
05/22/2022 04:25:14 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=86
05/22/2022 04:25:16 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.12 on epoch=86
05/22/2022 04:25:19 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=86
05/22/2022 04:25:22 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.08 on epoch=87
05/22/2022 04:25:24 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.08 on epoch=87
05/22/2022 04:25:36 - INFO - __main__ - Global step 2450 Train loss 0.07 Classification-F1 0.6688700083933978 on epoch=87
05/22/2022 04:25:36 - INFO - __main__ - Saving model with best Classification-F1: 0.6431435649521016 -> 0.6688700083933978 on epoch=87, global_step=2450
05/22/2022 04:25:39 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=87
05/22/2022 04:25:42 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.09 on epoch=88
05/22/2022 04:25:44 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=88
05/22/2022 04:25:47 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=88
05/22/2022 04:25:49 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=89
05/22/2022 04:26:02 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.609443539010113 on epoch=89
05/22/2022 04:26:04 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=89
05/22/2022 04:26:07 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 04:26:10 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=90
05/22/2022 04:26:12 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 04:26:15 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=91
05/22/2022 04:26:27 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.6601897771477943 on epoch=91
05/22/2022 04:26:30 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.11 on epoch=91
05/22/2022 04:26:32 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 04:26:35 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.06 on epoch=92
05/22/2022 04:26:38 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=92
05/22/2022 04:26:40 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=92
05/22/2022 04:26:53 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.5971787151707507 on epoch=92
05/22/2022 04:26:55 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.08 on epoch=93
05/22/2022 04:26:58 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=93
05/22/2022 04:27:00 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.04 on epoch=93
05/22/2022 04:27:03 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.06 on epoch=94
05/22/2022 04:27:06 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=94
05/22/2022 04:27:18 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.6837605823843662 on epoch=94
05/22/2022 04:27:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6688700083933978 -> 0.6837605823843662 on epoch=94, global_step=2650
05/22/2022 04:27:20 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=94
05/22/2022 04:27:23 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=95
05/22/2022 04:27:26 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=95
05/22/2022 04:27:28 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=96
05/22/2022 04:27:31 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.11 on epoch=96
05/22/2022 04:27:43 - INFO - __main__ - Global step 2700 Train loss 0.05 Classification-F1 0.6920574081984825 on epoch=96
05/22/2022 04:27:43 - INFO - __main__ - Saving model with best Classification-F1: 0.6837605823843662 -> 0.6920574081984825 on epoch=96, global_step=2700
05/22/2022 04:27:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=96
05/22/2022 04:27:48 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=97
05/22/2022 04:27:51 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.07 on epoch=97
05/22/2022 04:27:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=97
05/22/2022 04:27:56 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=98
05/22/2022 04:28:08 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.6812221113791572 on epoch=98
05/22/2022 04:28:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=98
05/22/2022 04:28:14 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=98
05/22/2022 04:28:17 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.08 on epoch=99
05/22/2022 04:28:19 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=99
05/22/2022 04:28:22 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=99
05/22/2022 04:28:34 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.6789866047632376 on epoch=99
05/22/2022 04:28:37 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.13 on epoch=100
05/22/2022 04:28:39 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=100
05/22/2022 04:28:42 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 04:28:45 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.14 on epoch=101
05/22/2022 04:28:47 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=101
05/22/2022 04:28:59 - INFO - __main__ - Global step 2850 Train loss 0.07 Classification-F1 0.6256572471023392 on epoch=101
05/22/2022 04:29:02 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.06 on epoch=102
05/22/2022 04:29:05 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.09 on epoch=102
05/22/2022 04:29:07 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=102
05/22/2022 04:29:10 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=103
05/22/2022 04:29:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=103
05/22/2022 04:29:25 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7232698785665854 on epoch=103
05/22/2022 04:29:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6920574081984825 -> 0.7232698785665854 on epoch=103, global_step=2900
05/22/2022 04:29:28 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=103
05/22/2022 04:29:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=104
05/22/2022 04:29:33 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=104
05/22/2022 04:29:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 04:29:38 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=105
05/22/2022 04:29:51 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.7226944631080016 on epoch=105
05/22/2022 04:29:53 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 04:29:56 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=106
05/22/2022 04:29:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.13 on epoch=106
05/22/2022 04:30:01 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 04:30:04 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=107
05/22/2022 04:30:05 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:30:05 - INFO - __main__ - Printing 3 examples
05/22/2022 04:30:05 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 04:30:05 - INFO - __main__ - ['Animal']
05/22/2022 04:30:05 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 04:30:05 - INFO - __main__ - ['Animal']
05/22/2022 04:30:05 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 04:30:05 - INFO - __main__ - ['Animal']
05/22/2022 04:30:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:30:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:30:06 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 04:30:06 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:30:06 - INFO - __main__ - Printing 3 examples
05/22/2022 04:30:06 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 04:30:06 - INFO - __main__ - ['Animal']
05/22/2022 04:30:06 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 04:30:06 - INFO - __main__ - ['Animal']
05/22/2022 04:30:06 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 04:30:06 - INFO - __main__ - ['Animal']
05/22/2022 04:30:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:30:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:30:06 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 04:30:16 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7245532205569188 on epoch=107
05/22/2022 04:30:16 - INFO - __main__ - Saving model with best Classification-F1: 0.7232698785665854 -> 0.7245532205569188 on epoch=107, global_step=3000
05/22/2022 04:30:16 - INFO - __main__ - save last model!
05/22/2022 04:30:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 04:30:16 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 04:30:16 - INFO - __main__ - Printing 3 examples
05/22/2022 04:30:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 04:30:16 - INFO - __main__ - ['Animal']
05/22/2022 04:30:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 04:30:16 - INFO - __main__ - ['Animal']
05/22/2022 04:30:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 04:30:16 - INFO - __main__ - ['Village']
05/22/2022 04:30:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:30:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:30:21 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 04:30:25 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 04:30:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 04:30:25 - INFO - __main__ - Starting training!
05/22/2022 04:32:26 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_100_0.3_8_predictions.txt
05/22/2022 04:32:26 - INFO - __main__ - Classification-F1 on test data: 0.5688
05/22/2022 04:32:27 - INFO - __main__ - prefix=dbpedia_14_32_100, lr=0.3, bsz=8, dev_performance=0.7245532205569188, test_performance=0.5687862099066116
05/22/2022 04:32:27 - INFO - __main__ - Running ... prefix=dbpedia_14_32_100, lr=0.2, bsz=8 ...
05/22/2022 04:32:28 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:32:28 - INFO - __main__ - Printing 3 examples
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Linnaemyini is a tribe of flies in the family Tachinidae.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Morula ambrosia is a species of sea snail a marine gastropod mollusk in the family Muricidae the murex snails or rock snails.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Neoduma plagosus is a moth of the Arctiidae family. It was described by Rothschild in 1912. It is found in New Guinea.The length of the forewings 10 mm. The forewings are creamy white with a yellow costa. The basal half of the wings is edged with black and there are two olive-grey antemedian patches as well as one on the termen. The hindwings are buff.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:32:28 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:32:28 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 04:32:28 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:32:28 - INFO - __main__ - Printing 3 examples
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Pseudometapterus umbrosus is a species of assassin bug found in North America. It is univoltine in Illinois and overwinters as an adult. It has been reported from spider webs and plants (Heuchera parviflora) on sandstone and limestone bluffs. The vast majority of observed individuals are mictropterus but in 2000 a macropterus (full-size winged) female was observed in Little Grand Canyon Jackson County Southern Illinois.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Lymantriini (sometimes misspelled as Lymantrini) is a tribe of the family Lymantriidae comprising a group of polyphagous noctuoid (or owlet) moths that reside mostly in the tropical regions of Afro-Eurasia but also North America.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ -  [dbpedia_14] Prominea porrecta is a species of moth of the Noctuidae family. It is found on the African Indian Ocean islands of Madagascar Réunion and Mauritius.It has a winglength of approx. 16-17 mmn wingspan around 33 mm.
05/22/2022 04:32:28 - INFO - __main__ - ['Animal']
05/22/2022 04:32:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:32:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:32:29 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 04:32:45 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 04:32:46 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 04:32:46 - INFO - __main__ - Starting training!
05/22/2022 04:32:49 - INFO - __main__ - Step 10 Global step 10 Train loss 7.59 on epoch=0
05/22/2022 04:32:52 - INFO - __main__ - Step 20 Global step 20 Train loss 6.11 on epoch=0
05/22/2022 04:32:55 - INFO - __main__ - Step 30 Global step 30 Train loss 5.41 on epoch=1
05/22/2022 04:32:57 - INFO - __main__ - Step 40 Global step 40 Train loss 4.77 on epoch=1
05/22/2022 04:33:00 - INFO - __main__ - Step 50 Global step 50 Train loss 4.22 on epoch=1
05/22/2022 04:33:12 - INFO - __main__ - Global step 50 Train loss 5.62 Classification-F1 0.014866911724826222 on epoch=1
05/22/2022 04:33:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.014866911724826222 on epoch=1, global_step=50
05/22/2022 04:33:15 - INFO - __main__ - Step 60 Global step 60 Train loss 4.10 on epoch=2
05/22/2022 04:33:17 - INFO - __main__ - Step 70 Global step 70 Train loss 3.76 on epoch=2
05/22/2022 04:33:20 - INFO - __main__ - Step 80 Global step 80 Train loss 3.32 on epoch=2
05/22/2022 04:33:23 - INFO - __main__ - Step 90 Global step 90 Train loss 3.30 on epoch=3
05/22/2022 04:33:25 - INFO - __main__ - Step 100 Global step 100 Train loss 3.14 on epoch=3
05/22/2022 04:33:39 - INFO - __main__ - Global step 100 Train loss 3.52 Classification-F1 0.024589870227563284 on epoch=3
05/22/2022 04:33:39 - INFO - __main__ - Saving model with best Classification-F1: 0.014866911724826222 -> 0.024589870227563284 on epoch=3, global_step=100
05/22/2022 04:33:42 - INFO - __main__ - Step 110 Global step 110 Train loss 2.94 on epoch=3
05/22/2022 04:33:44 - INFO - __main__ - Step 120 Global step 120 Train loss 2.71 on epoch=4
05/22/2022 04:33:47 - INFO - __main__ - Step 130 Global step 130 Train loss 2.64 on epoch=4
05/22/2022 04:33:49 - INFO - __main__ - Step 140 Global step 140 Train loss 2.55 on epoch=4
05/22/2022 04:33:52 - INFO - __main__ - Step 150 Global step 150 Train loss 2.33 on epoch=5
05/22/2022 04:34:04 - INFO - __main__ - Global step 150 Train loss 2.63 Classification-F1 0.04966781985665178 on epoch=5
05/22/2022 04:34:04 - INFO - __main__ - Saving model with best Classification-F1: 0.024589870227563284 -> 0.04966781985665178 on epoch=5, global_step=150
05/22/2022 04:34:07 - INFO - __main__ - Step 160 Global step 160 Train loss 2.27 on epoch=5
05/22/2022 04:34:09 - INFO - __main__ - Step 170 Global step 170 Train loss 2.16 on epoch=6
05/22/2022 04:34:12 - INFO - __main__ - Step 180 Global step 180 Train loss 1.94 on epoch=6
05/22/2022 04:34:15 - INFO - __main__ - Step 190 Global step 190 Train loss 2.06 on epoch=6
05/22/2022 04:34:17 - INFO - __main__ - Step 200 Global step 200 Train loss 2.02 on epoch=7
05/22/2022 04:34:29 - INFO - __main__ - Global step 200 Train loss 2.09 Classification-F1 0.07197758368438109 on epoch=7
05/22/2022 04:34:29 - INFO - __main__ - Saving model with best Classification-F1: 0.04966781985665178 -> 0.07197758368438109 on epoch=7, global_step=200
05/22/2022 04:34:32 - INFO - __main__ - Step 210 Global step 210 Train loss 2.00 on epoch=7
05/22/2022 04:34:34 - INFO - __main__ - Step 220 Global step 220 Train loss 1.83 on epoch=7
05/22/2022 04:34:37 - INFO - __main__ - Step 230 Global step 230 Train loss 1.82 on epoch=8
05/22/2022 04:34:39 - INFO - __main__ - Step 240 Global step 240 Train loss 1.83 on epoch=8
05/22/2022 04:34:42 - INFO - __main__ - Step 250 Global step 250 Train loss 1.72 on epoch=8
05/22/2022 04:34:53 - INFO - __main__ - Global step 250 Train loss 1.84 Classification-F1 0.1180976776465707 on epoch=8
05/22/2022 04:34:53 - INFO - __main__ - Saving model with best Classification-F1: 0.07197758368438109 -> 0.1180976776465707 on epoch=8, global_step=250
05/22/2022 04:34:56 - INFO - __main__ - Step 260 Global step 260 Train loss 1.64 on epoch=9
05/22/2022 04:34:58 - INFO - __main__ - Step 270 Global step 270 Train loss 1.61 on epoch=9
05/22/2022 04:35:01 - INFO - __main__ - Step 280 Global step 280 Train loss 1.36 on epoch=9
05/22/2022 04:35:04 - INFO - __main__ - Step 290 Global step 290 Train loss 1.43 on epoch=10
05/22/2022 04:35:06 - INFO - __main__ - Step 300 Global step 300 Train loss 1.48 on epoch=10
05/22/2022 04:35:17 - INFO - __main__ - Global step 300 Train loss 1.50 Classification-F1 0.14201938185655166 on epoch=10
05/22/2022 04:35:17 - INFO - __main__ - Saving model with best Classification-F1: 0.1180976776465707 -> 0.14201938185655166 on epoch=10, global_step=300
05/22/2022 04:35:20 - INFO - __main__ - Step 310 Global step 310 Train loss 1.19 on epoch=11
05/22/2022 04:35:23 - INFO - __main__ - Step 320 Global step 320 Train loss 1.42 on epoch=11
05/22/2022 04:35:25 - INFO - __main__ - Step 330 Global step 330 Train loss 1.36 on epoch=11
05/22/2022 04:35:28 - INFO - __main__ - Step 340 Global step 340 Train loss 1.26 on epoch=12
05/22/2022 04:35:30 - INFO - __main__ - Step 350 Global step 350 Train loss 1.22 on epoch=12
05/22/2022 04:35:42 - INFO - __main__ - Global step 350 Train loss 1.29 Classification-F1 0.16060605559394173 on epoch=12
05/22/2022 04:35:42 - INFO - __main__ - Saving model with best Classification-F1: 0.14201938185655166 -> 0.16060605559394173 on epoch=12, global_step=350
05/22/2022 04:35:44 - INFO - __main__ - Step 360 Global step 360 Train loss 1.12 on epoch=12
05/22/2022 04:35:47 - INFO - __main__ - Step 370 Global step 370 Train loss 1.07 on epoch=13
05/22/2022 04:35:49 - INFO - __main__ - Step 380 Global step 380 Train loss 0.88 on epoch=13
05/22/2022 04:35:52 - INFO - __main__ - Step 390 Global step 390 Train loss 0.91 on epoch=13
05/22/2022 04:35:55 - INFO - __main__ - Step 400 Global step 400 Train loss 0.97 on epoch=14
05/22/2022 04:36:06 - INFO - __main__ - Global step 400 Train loss 0.99 Classification-F1 0.2064842475932653 on epoch=14
05/22/2022 04:36:06 - INFO - __main__ - Saving model with best Classification-F1: 0.16060605559394173 -> 0.2064842475932653 on epoch=14, global_step=400
05/22/2022 04:36:09 - INFO - __main__ - Step 410 Global step 410 Train loss 0.88 on epoch=14
05/22/2022 04:36:11 - INFO - __main__ - Step 420 Global step 420 Train loss 0.77 on epoch=14
05/22/2022 04:36:14 - INFO - __main__ - Step 430 Global step 430 Train loss 0.76 on epoch=15
05/22/2022 04:36:16 - INFO - __main__ - Step 440 Global step 440 Train loss 0.75 on epoch=15
05/22/2022 04:36:19 - INFO - __main__ - Step 450 Global step 450 Train loss 0.68 on epoch=16
05/22/2022 04:36:31 - INFO - __main__ - Global step 450 Train loss 0.77 Classification-F1 0.24413520641496136 on epoch=16
05/22/2022 04:36:31 - INFO - __main__ - Saving model with best Classification-F1: 0.2064842475932653 -> 0.24413520641496136 on epoch=16, global_step=450
05/22/2022 04:36:33 - INFO - __main__ - Step 460 Global step 460 Train loss 0.83 on epoch=16
05/22/2022 04:36:36 - INFO - __main__ - Step 470 Global step 470 Train loss 0.72 on epoch=16
05/22/2022 04:36:38 - INFO - __main__ - Step 480 Global step 480 Train loss 0.64 on epoch=17
05/22/2022 04:36:41 - INFO - __main__ - Step 490 Global step 490 Train loss 0.71 on epoch=17
05/22/2022 04:36:44 - INFO - __main__ - Step 500 Global step 500 Train loss 0.70 on epoch=17
05/22/2022 04:36:56 - INFO - __main__ - Global step 500 Train loss 0.72 Classification-F1 0.2948618300527992 on epoch=17
05/22/2022 04:36:56 - INFO - __main__ - Saving model with best Classification-F1: 0.24413520641496136 -> 0.2948618300527992 on epoch=17, global_step=500
05/22/2022 04:36:58 - INFO - __main__ - Step 510 Global step 510 Train loss 0.63 on epoch=18
05/22/2022 04:37:01 - INFO - __main__ - Step 520 Global step 520 Train loss 0.66 on epoch=18
05/22/2022 04:37:04 - INFO - __main__ - Step 530 Global step 530 Train loss 0.56 on epoch=18
05/22/2022 04:37:06 - INFO - __main__ - Step 540 Global step 540 Train loss 0.62 on epoch=19
05/22/2022 04:37:09 - INFO - __main__ - Step 550 Global step 550 Train loss 0.64 on epoch=19
05/22/2022 04:37:21 - INFO - __main__ - Global step 550 Train loss 0.62 Classification-F1 0.34826008850204276 on epoch=19
05/22/2022 04:37:21 - INFO - __main__ - Saving model with best Classification-F1: 0.2948618300527992 -> 0.34826008850204276 on epoch=19, global_step=550
05/22/2022 04:37:24 - INFO - __main__ - Step 560 Global step 560 Train loss 0.54 on epoch=19
05/22/2022 04:37:27 - INFO - __main__ - Step 570 Global step 570 Train loss 0.64 on epoch=20
05/22/2022 04:37:29 - INFO - __main__ - Step 580 Global step 580 Train loss 0.43 on epoch=20
05/22/2022 04:37:32 - INFO - __main__ - Step 590 Global step 590 Train loss 0.41 on epoch=21
05/22/2022 04:37:34 - INFO - __main__ - Step 600 Global step 600 Train loss 0.51 on epoch=21
05/22/2022 04:37:48 - INFO - __main__ - Global step 600 Train loss 0.50 Classification-F1 0.404069005378565 on epoch=21
05/22/2022 04:37:48 - INFO - __main__ - Saving model with best Classification-F1: 0.34826008850204276 -> 0.404069005378565 on epoch=21, global_step=600
05/22/2022 04:37:50 - INFO - __main__ - Step 610 Global step 610 Train loss 0.46 on epoch=21
05/22/2022 04:37:53 - INFO - __main__ - Step 620 Global step 620 Train loss 0.52 on epoch=22
05/22/2022 04:37:55 - INFO - __main__ - Step 630 Global step 630 Train loss 0.46 on epoch=22
05/22/2022 04:37:58 - INFO - __main__ - Step 640 Global step 640 Train loss 0.35 on epoch=22
05/22/2022 04:38:00 - INFO - __main__ - Step 650 Global step 650 Train loss 0.52 on epoch=23
05/22/2022 04:38:14 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.4819457415423573 on epoch=23
05/22/2022 04:38:14 - INFO - __main__ - Saving model with best Classification-F1: 0.404069005378565 -> 0.4819457415423573 on epoch=23, global_step=650
05/22/2022 04:38:16 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=23
05/22/2022 04:38:19 - INFO - __main__ - Step 670 Global step 670 Train loss 0.44 on epoch=23
05/22/2022 04:38:21 - INFO - __main__ - Step 680 Global step 680 Train loss 0.47 on epoch=24
05/22/2022 04:38:24 - INFO - __main__ - Step 690 Global step 690 Train loss 0.49 on epoch=24
05/22/2022 04:38:27 - INFO - __main__ - Step 700 Global step 700 Train loss 0.40 on epoch=24
05/22/2022 04:38:40 - INFO - __main__ - Global step 700 Train loss 0.45 Classification-F1 0.5043945533559724 on epoch=24
05/22/2022 04:38:40 - INFO - __main__ - Saving model with best Classification-F1: 0.4819457415423573 -> 0.5043945533559724 on epoch=24, global_step=700
05/22/2022 04:38:42 - INFO - __main__ - Step 710 Global step 710 Train loss 0.46 on epoch=25
05/22/2022 04:38:45 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=25
05/22/2022 04:38:48 - INFO - __main__ - Step 730 Global step 730 Train loss 0.35 on epoch=26
05/22/2022 04:38:50 - INFO - __main__ - Step 740 Global step 740 Train loss 0.42 on epoch=26
05/22/2022 04:38:53 - INFO - __main__ - Step 750 Global step 750 Train loss 0.38 on epoch=26
05/22/2022 04:39:06 - INFO - __main__ - Global step 750 Train loss 0.39 Classification-F1 0.48929260268357155 on epoch=26
05/22/2022 04:39:09 - INFO - __main__ - Step 760 Global step 760 Train loss 0.41 on epoch=27
05/22/2022 04:39:11 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=27
05/22/2022 04:39:14 - INFO - __main__ - Step 780 Global step 780 Train loss 0.33 on epoch=27
05/22/2022 04:39:16 - INFO - __main__ - Step 790 Global step 790 Train loss 0.39 on epoch=28
05/22/2022 04:39:19 - INFO - __main__ - Step 800 Global step 800 Train loss 0.27 on epoch=28
05/22/2022 04:39:32 - INFO - __main__ - Global step 800 Train loss 0.35 Classification-F1 0.5036656944767098 on epoch=28
05/22/2022 04:39:34 - INFO - __main__ - Step 810 Global step 810 Train loss 0.30 on epoch=28
05/22/2022 04:39:37 - INFO - __main__ - Step 820 Global step 820 Train loss 0.44 on epoch=29
05/22/2022 04:39:39 - INFO - __main__ - Step 830 Global step 830 Train loss 0.32 on epoch=29
05/22/2022 04:39:42 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=29
05/22/2022 04:39:45 - INFO - __main__ - Step 850 Global step 850 Train loss 0.45 on epoch=30
05/22/2022 04:39:58 - INFO - __main__ - Global step 850 Train loss 0.36 Classification-F1 0.5056247063413387 on epoch=30
05/22/2022 04:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.5043945533559724 -> 0.5056247063413387 on epoch=30, global_step=850
05/22/2022 04:40:00 - INFO - __main__ - Step 860 Global step 860 Train loss 0.40 on epoch=30
05/22/2022 04:40:03 - INFO - __main__ - Step 870 Global step 870 Train loss 0.29 on epoch=31
05/22/2022 04:40:05 - INFO - __main__ - Step 880 Global step 880 Train loss 0.40 on epoch=31
05/22/2022 04:40:08 - INFO - __main__ - Step 890 Global step 890 Train loss 0.29 on epoch=31
05/22/2022 04:40:11 - INFO - __main__ - Step 900 Global step 900 Train loss 0.26 on epoch=32
05/22/2022 04:40:24 - INFO - __main__ - Global step 900 Train loss 0.33 Classification-F1 0.5397990799097441 on epoch=32
05/22/2022 04:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5056247063413387 -> 0.5397990799097441 on epoch=32, global_step=900
05/22/2022 04:40:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=32
05/22/2022 04:40:29 - INFO - __main__ - Step 920 Global step 920 Train loss 0.22 on epoch=32
05/22/2022 04:40:32 - INFO - __main__ - Step 930 Global step 930 Train loss 0.32 on epoch=33
05/22/2022 04:40:34 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=33
05/22/2022 04:40:37 - INFO - __main__ - Step 950 Global step 950 Train loss 0.24 on epoch=33
05/22/2022 04:40:50 - INFO - __main__ - Global step 950 Train loss 0.27 Classification-F1 0.5721934237301818 on epoch=33
05/22/2022 04:40:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5397990799097441 -> 0.5721934237301818 on epoch=33, global_step=950
05/22/2022 04:40:52 - INFO - __main__ - Step 960 Global step 960 Train loss 0.30 on epoch=34
05/22/2022 04:40:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.24 on epoch=34
05/22/2022 04:40:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=34
05/22/2022 04:41:00 - INFO - __main__ - Step 990 Global step 990 Train loss 0.35 on epoch=35
05/22/2022 04:41:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.19 on epoch=35
05/22/2022 04:41:15 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.5668056377658252 on epoch=35
05/22/2022 04:41:18 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.19 on epoch=36
05/22/2022 04:41:21 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.33 on epoch=36
05/22/2022 04:41:23 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.22 on epoch=36
05/22/2022 04:41:26 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.35 on epoch=37
05/22/2022 04:41:28 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=37
05/22/2022 04:41:41 - INFO - __main__ - Global step 1050 Train loss 0.27 Classification-F1 0.5444881343654805 on epoch=37
05/22/2022 04:41:44 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.23 on epoch=37
05/22/2022 04:41:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=38
05/22/2022 04:41:49 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=38
05/22/2022 04:41:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.18 on epoch=38
05/22/2022 04:41:54 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.24 on epoch=39
05/22/2022 04:42:07 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.524349713031704 on epoch=39
05/22/2022 04:42:09 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.25 on epoch=39
05/22/2022 04:42:12 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.28 on epoch=39
05/22/2022 04:42:14 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.33 on epoch=40
05/22/2022 04:42:17 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=40
05/22/2022 04:42:20 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=41
05/22/2022 04:42:32 - INFO - __main__ - Global step 1150 Train loss 0.24 Classification-F1 0.5135248330588832 on epoch=41
05/22/2022 04:42:35 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.22 on epoch=41
05/22/2022 04:42:37 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.26 on epoch=41
05/22/2022 04:42:40 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.22 on epoch=42
05/22/2022 04:42:43 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=42
05/22/2022 04:42:45 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.20 on epoch=42
05/22/2022 04:42:58 - INFO - __main__ - Global step 1200 Train loss 0.22 Classification-F1 0.5460508005754467 on epoch=42
05/22/2022 04:43:00 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.20 on epoch=43
05/22/2022 04:43:03 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.26 on epoch=43
05/22/2022 04:43:06 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=43
05/22/2022 04:43:08 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.33 on epoch=44
05/22/2022 04:43:11 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=44
05/22/2022 04:43:23 - INFO - __main__ - Global step 1250 Train loss 0.22 Classification-F1 0.6095348499141949 on epoch=44
05/22/2022 04:43:23 - INFO - __main__ - Saving model with best Classification-F1: 0.5721934237301818 -> 0.6095348499141949 on epoch=44, global_step=1250
05/22/2022 04:43:26 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.17 on epoch=44
05/22/2022 04:43:29 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.23 on epoch=45
05/22/2022 04:43:31 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.15 on epoch=45
05/22/2022 04:43:34 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=46
05/22/2022 04:43:36 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.28 on epoch=46
05/22/2022 04:43:49 - INFO - __main__ - Global step 1300 Train loss 0.21 Classification-F1 0.5506970842964966 on epoch=46
05/22/2022 04:43:51 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.16 on epoch=46
05/22/2022 04:43:54 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=47
05/22/2022 04:43:57 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.19 on epoch=47
05/22/2022 04:43:59 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.20 on epoch=47
05/22/2022 04:44:02 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=48
05/22/2022 04:44:14 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.5728407177402028 on epoch=48
05/22/2022 04:44:17 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.23 on epoch=48
05/22/2022 04:44:19 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=48
05/22/2022 04:44:22 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.23 on epoch=49
05/22/2022 04:44:25 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.21 on epoch=49
05/22/2022 04:44:27 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=49
05/22/2022 04:44:40 - INFO - __main__ - Global step 1400 Train loss 0.20 Classification-F1 0.5513267446560918 on epoch=49
05/22/2022 04:44:42 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.24 on epoch=50
05/22/2022 04:44:45 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.17 on epoch=50
05/22/2022 04:44:48 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.27 on epoch=51
05/22/2022 04:44:50 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.25 on epoch=51
05/22/2022 04:44:53 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.19 on epoch=51
05/22/2022 04:45:05 - INFO - __main__ - Global step 1450 Train loss 0.22 Classification-F1 0.6007759337794351 on epoch=51
05/22/2022 04:45:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.17 on epoch=52
05/22/2022 04:45:10 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.25 on epoch=52
05/22/2022 04:45:13 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=52
05/22/2022 04:45:15 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.26 on epoch=53
05/22/2022 04:45:18 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.22 on epoch=53
05/22/2022 04:45:31 - INFO - __main__ - Global step 1500 Train loss 0.20 Classification-F1 0.577318433000564 on epoch=53
05/22/2022 04:45:33 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=53
05/22/2022 04:45:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.23 on epoch=54
05/22/2022 04:45:38 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.12 on epoch=54
05/22/2022 04:45:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.15 on epoch=54
05/22/2022 04:45:43 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.25 on epoch=55
05/22/2022 04:45:56 - INFO - __main__ - Global step 1550 Train loss 0.17 Classification-F1 0.5517221772522125 on epoch=55
05/22/2022 04:45:58 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.17 on epoch=55
05/22/2022 04:46:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=56
05/22/2022 04:46:03 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.23 on epoch=56
05/22/2022 04:46:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.10 on epoch=56
05/22/2022 04:46:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=57
05/22/2022 04:46:21 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.6049094881686228 on epoch=57
05/22/2022 04:46:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.18 on epoch=57
05/22/2022 04:46:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=57
05/22/2022 04:46:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.23 on epoch=58
05/22/2022 04:46:32 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.22 on epoch=58
05/22/2022 04:46:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.11 on epoch=58
05/22/2022 04:46:47 - INFO - __main__ - Global step 1650 Train loss 0.16 Classification-F1 0.6399823518496225 on epoch=58
05/22/2022 04:46:47 - INFO - __main__ - Saving model with best Classification-F1: 0.6095348499141949 -> 0.6399823518496225 on epoch=58, global_step=1650
05/22/2022 04:46:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.17 on epoch=59
05/22/2022 04:46:52 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.14 on epoch=59
05/22/2022 04:46:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.12 on epoch=59
05/22/2022 04:46:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.28 on epoch=60
05/22/2022 04:47:00 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=60
05/22/2022 04:47:12 - INFO - __main__ - Global step 1700 Train loss 0.17 Classification-F1 0.5831611335287054 on epoch=60
05/22/2022 04:47:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=61
05/22/2022 04:47:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.19 on epoch=61
05/22/2022 04:47:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=61
05/22/2022 04:47:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=62
05/22/2022 04:47:25 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.23 on epoch=62
05/22/2022 04:47:37 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.5799833987910026 on epoch=62
05/22/2022 04:47:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.12 on epoch=62
05/22/2022 04:47:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.15 on epoch=63
05/22/2022 04:47:45 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.16 on epoch=63
05/22/2022 04:47:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=63
05/22/2022 04:47:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.15 on epoch=64
05/22/2022 04:48:02 - INFO - __main__ - Global step 1800 Train loss 0.13 Classification-F1 0.5502033120271125 on epoch=64
05/22/2022 04:48:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.17 on epoch=64
05/22/2022 04:48:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.10 on epoch=64
05/22/2022 04:48:10 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.23 on epoch=65
05/22/2022 04:48:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.09 on epoch=65
05/22/2022 04:48:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.09 on epoch=66
05/22/2022 04:48:27 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.6119388097837001 on epoch=66
05/22/2022 04:48:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.18 on epoch=66
05/22/2022 04:48:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=66
05/22/2022 04:48:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.18 on epoch=67
05/22/2022 04:48:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.19 on epoch=67
05/22/2022 04:48:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=67
05/22/2022 04:48:53 - INFO - __main__ - Global step 1900 Train loss 0.15 Classification-F1 0.6174611641913157 on epoch=67
05/22/2022 04:48:55 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.19 on epoch=68
05/22/2022 04:48:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.14 on epoch=68
05/22/2022 04:49:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=68
05/22/2022 04:49:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.19 on epoch=69
05/22/2022 04:49:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.12 on epoch=69
05/22/2022 04:49:18 - INFO - __main__ - Global step 1950 Train loss 0.14 Classification-F1 0.579703223922221 on epoch=69
05/22/2022 04:49:20 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=69
05/22/2022 04:49:23 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.14 on epoch=70
05/22/2022 04:49:26 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=70
05/22/2022 04:49:28 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.09 on epoch=71
05/22/2022 04:49:31 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.19 on epoch=71
05/22/2022 04:49:43 - INFO - __main__ - Global step 2000 Train loss 0.11 Classification-F1 0.5689698296780519 on epoch=71
05/22/2022 04:49:45 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=71
05/22/2022 04:49:48 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.16 on epoch=72
05/22/2022 04:49:51 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.14 on epoch=72
05/22/2022 04:49:53 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.10 on epoch=72
05/22/2022 04:49:56 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.13 on epoch=73
05/22/2022 04:50:08 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.5836952919770301 on epoch=73
05/22/2022 04:50:11 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.13 on epoch=73
05/22/2022 04:50:13 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=73
05/22/2022 04:50:16 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.19 on epoch=74
05/22/2022 04:50:18 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.13 on epoch=74
05/22/2022 04:50:21 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=74
05/22/2022 04:50:33 - INFO - __main__ - Global step 2100 Train loss 0.12 Classification-F1 0.5778027327646766 on epoch=74
05/22/2022 04:50:36 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.21 on epoch=75
05/22/2022 04:50:38 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=75
05/22/2022 04:50:41 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.10 on epoch=76
05/22/2022 04:50:43 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.15 on epoch=76
05/22/2022 04:50:46 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=76
05/22/2022 04:50:58 - INFO - __main__ - Global step 2150 Train loss 0.12 Classification-F1 0.6019451155340867 on epoch=76
05/22/2022 04:51:01 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.11 on epoch=77
05/22/2022 04:51:03 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.13 on epoch=77
05/22/2022 04:51:06 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=77
05/22/2022 04:51:08 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=78
05/22/2022 04:51:11 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.15 on epoch=78
05/22/2022 04:51:23 - INFO - __main__ - Global step 2200 Train loss 0.10 Classification-F1 0.6036404632040209 on epoch=78
05/22/2022 04:51:26 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=78
05/22/2022 04:51:28 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.17 on epoch=79
05/22/2022 04:51:31 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.08 on epoch=79
05/22/2022 04:51:33 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.05 on epoch=79
05/22/2022 04:51:36 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.16 on epoch=80
05/22/2022 04:51:48 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.5887066190463864 on epoch=80
05/22/2022 04:51:50 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=80
05/22/2022 04:51:53 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=81
05/22/2022 04:51:55 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.15 on epoch=81
05/22/2022 04:51:58 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.05 on epoch=81
05/22/2022 04:52:01 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.12 on epoch=82
05/22/2022 04:52:13 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.6106824682933554 on epoch=82
05/22/2022 04:52:15 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.19 on epoch=82
05/22/2022 04:52:18 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.11 on epoch=82
05/22/2022 04:52:20 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.17 on epoch=83
05/22/2022 04:52:23 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.11 on epoch=83
05/22/2022 04:52:26 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=83
05/22/2022 04:52:38 - INFO - __main__ - Global step 2350 Train loss 0.13 Classification-F1 0.5522161075307559 on epoch=83
05/22/2022 04:52:40 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.10 on epoch=84
05/22/2022 04:52:43 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.09 on epoch=84
05/22/2022 04:52:45 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=84
05/22/2022 04:52:48 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.15 on epoch=85
05/22/2022 04:52:51 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=85
05/22/2022 04:53:03 - INFO - __main__ - Global step 2400 Train loss 0.09 Classification-F1 0.5518659468313687 on epoch=85
05/22/2022 04:53:05 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.07 on epoch=86
05/22/2022 04:53:08 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.15 on epoch=86
05/22/2022 04:53:10 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.06 on epoch=86
05/22/2022 04:53:13 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.11 on epoch=87
05/22/2022 04:53:15 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.13 on epoch=87
05/22/2022 04:53:27 - INFO - __main__ - Global step 2450 Train loss 0.10 Classification-F1 0.5551927246405989 on epoch=87
05/22/2022 04:53:30 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=87
05/22/2022 04:53:33 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.12 on epoch=88
05/22/2022 04:53:35 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.10 on epoch=88
05/22/2022 04:53:38 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=88
05/22/2022 04:53:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.13 on epoch=89
05/22/2022 04:53:52 - INFO - __main__ - Global step 2500 Train loss 0.09 Classification-F1 0.5527765693088275 on epoch=89
05/22/2022 04:53:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=89
05/22/2022 04:53:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.08 on epoch=89
05/22/2022 04:54:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.13 on epoch=90
05/22/2022 04:54:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=90
05/22/2022 04:54:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=91
05/22/2022 04:54:17 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.5403280651779848 on epoch=91
05/22/2022 04:54:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.18 on epoch=91
05/22/2022 04:54:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=91
05/22/2022 04:54:25 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.11 on epoch=92
05/22/2022 04:54:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=92
05/22/2022 04:54:30 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.13 on epoch=92
05/22/2022 04:54:42 - INFO - __main__ - Global step 2600 Train loss 0.11 Classification-F1 0.6269271294261938 on epoch=92
05/22/2022 04:54:45 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.10 on epoch=93
05/22/2022 04:54:48 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.15 on epoch=93
05/22/2022 04:54:50 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.10 on epoch=93
05/22/2022 04:54:53 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.13 on epoch=94
05/22/2022 04:54:55 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=94
05/22/2022 04:55:08 - INFO - __main__ - Global step 2650 Train loss 0.11 Classification-F1 0.6506771657222713 on epoch=94
05/22/2022 04:55:08 - INFO - __main__ - Saving model with best Classification-F1: 0.6399823518496225 -> 0.6506771657222713 on epoch=94, global_step=2650
05/22/2022 04:55:10 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.06 on epoch=94
05/22/2022 04:55:13 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.15 on epoch=95
05/22/2022 04:55:15 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=95
05/22/2022 04:55:18 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=96
05/22/2022 04:55:20 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.15 on epoch=96
05/22/2022 04:55:33 - INFO - __main__ - Global step 2700 Train loss 0.09 Classification-F1 0.5927114085793089 on epoch=96
05/22/2022 04:55:35 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=96
05/22/2022 04:55:38 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=97
05/22/2022 04:55:40 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.14 on epoch=97
05/22/2022 04:55:43 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=97
05/22/2022 04:55:45 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.13 on epoch=98
05/22/2022 04:55:58 - INFO - __main__ - Global step 2750 Train loss 0.08 Classification-F1 0.6192410882106254 on epoch=98
05/22/2022 04:56:00 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.08 on epoch=98
05/22/2022 04:56:03 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=98
05/22/2022 04:56:05 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.18 on epoch=99
05/22/2022 04:56:08 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=99
05/22/2022 04:56:10 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=99
05/22/2022 04:56:23 - INFO - __main__ - Global step 2800 Train loss 0.10 Classification-F1 0.588788338952545 on epoch=99
05/22/2022 04:56:25 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.16 on epoch=100
05/22/2022 04:56:28 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=100
05/22/2022 04:56:30 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.10 on epoch=101
05/22/2022 04:56:33 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.16 on epoch=101
05/22/2022 04:56:35 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=101
05/22/2022 04:56:47 - INFO - __main__ - Global step 2850 Train loss 0.10 Classification-F1 0.6576295540004211 on epoch=101
05/22/2022 04:56:48 - INFO - __main__ - Saving model with best Classification-F1: 0.6506771657222713 -> 0.6576295540004211 on epoch=101, global_step=2850
05/22/2022 04:56:50 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.10 on epoch=102
05/22/2022 04:56:53 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.11 on epoch=102
05/22/2022 04:56:55 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=102
05/22/2022 04:56:58 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.13 on epoch=103
05/22/2022 04:57:00 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.08 on epoch=103
05/22/2022 04:57:12 - INFO - __main__ - Global step 2900 Train loss 0.09 Classification-F1 0.6231683694907897 on epoch=103
05/22/2022 04:57:15 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=103
05/22/2022 04:57:18 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.11 on epoch=104
05/22/2022 04:57:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.09 on epoch=104
05/22/2022 04:57:23 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 04:57:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.16 on epoch=105
05/22/2022 04:57:38 - INFO - __main__ - Global step 2950 Train loss 0.09 Classification-F1 0.7019038035839111 on epoch=105
05/22/2022 04:57:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6576295540004211 -> 0.7019038035839111 on epoch=105, global_step=2950
05/22/2022 04:57:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=105
05/22/2022 04:57:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.06 on epoch=106
05/22/2022 04:57:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.13 on epoch=106
05/22/2022 04:57:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.07 on epoch=106
05/22/2022 04:57:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.09 on epoch=107
05/22/2022 04:57:52 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:57:52 - INFO - __main__ - Printing 3 examples
05/22/2022 04:57:52 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 04:57:52 - INFO - __main__ - ['Animal']
05/22/2022 04:57:52 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 04:57:52 - INFO - __main__ - ['Animal']
05/22/2022 04:57:52 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 04:57:52 - INFO - __main__ - ['Animal']
05/22/2022 04:57:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:57:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:57:53 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 04:57:53 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 04:57:53 - INFO - __main__ - Printing 3 examples
05/22/2022 04:57:53 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 04:57:53 - INFO - __main__ - ['Animal']
05/22/2022 04:57:53 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 04:57:53 - INFO - __main__ - ['Animal']
05/22/2022 04:57:53 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 04:57:53 - INFO - __main__ - ['Animal']
05/22/2022 04:57:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:57:53 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:57:53 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 04:58:03 - INFO - __main__ - Global step 3000 Train loss 0.08 Classification-F1 0.664258723967977 on epoch=107
05/22/2022 04:58:03 - INFO - __main__ - save last model!
05/22/2022 04:58:03 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 04:58:03 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 04:58:03 - INFO - __main__ - Printing 3 examples
05/22/2022 04:58:03 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 04:58:03 - INFO - __main__ - ['Animal']
05/22/2022 04:58:03 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 04:58:03 - INFO - __main__ - ['Animal']
05/22/2022 04:58:03 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 04:58:03 - INFO - __main__ - ['Village']
05/22/2022 04:58:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 04:58:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 04:58:08 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 04:58:11 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 04:58:12 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 04:58:12 - INFO - __main__ - Starting training!
05/22/2022 05:00:00 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_100_0.2_8_predictions.txt
05/22/2022 05:00:00 - INFO - __main__ - Classification-F1 on test data: 0.4687
05/22/2022 05:00:01 - INFO - __main__ - prefix=dbpedia_14_32_100, lr=0.2, bsz=8, dev_performance=0.7019038035839111, test_performance=0.46871130041103753
05/22/2022 05:00:01 - INFO - __main__ - Running ... prefix=dbpedia_14_32_13, lr=0.5, bsz=8 ...
05/22/2022 05:00:02 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:00:02 - INFO - __main__ - Printing 3 examples
05/22/2022 05:00:02 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 05:00:02 - INFO - __main__ - ['Animal']
05/22/2022 05:00:02 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 05:00:02 - INFO - __main__ - ['Animal']
05/22/2022 05:00:02 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 05:00:02 - INFO - __main__ - ['Animal']
05/22/2022 05:00:02 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:00:02 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:00:03 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 05:00:03 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:00:03 - INFO - __main__ - Printing 3 examples
05/22/2022 05:00:03 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 05:00:03 - INFO - __main__ - ['Animal']
05/22/2022 05:00:03 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 05:00:03 - INFO - __main__ - ['Animal']
05/22/2022 05:00:03 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 05:00:03 - INFO - __main__ - ['Animal']
05/22/2022 05:00:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:00:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:00:03 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 05:00:20 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 05:00:21 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 05:00:21 - INFO - __main__ - Starting training!
05/22/2022 05:00:24 - INFO - __main__ - Step 10 Global step 10 Train loss 7.06 on epoch=0
05/22/2022 05:00:27 - INFO - __main__ - Step 20 Global step 20 Train loss 4.67 on epoch=0
05/22/2022 05:00:30 - INFO - __main__ - Step 30 Global step 30 Train loss 4.04 on epoch=1
05/22/2022 05:00:32 - INFO - __main__ - Step 40 Global step 40 Train loss 3.50 on epoch=1
05/22/2022 05:00:35 - INFO - __main__ - Step 50 Global step 50 Train loss 2.81 on epoch=1
05/22/2022 05:00:47 - INFO - __main__ - Global step 50 Train loss 4.42 Classification-F1 0.03394564253828889 on epoch=1
05/22/2022 05:00:47 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03394564253828889 on epoch=1, global_step=50
05/22/2022 05:00:50 - INFO - __main__ - Step 60 Global step 60 Train loss 2.44 on epoch=2
05/22/2022 05:00:52 - INFO - __main__ - Step 70 Global step 70 Train loss 2.48 on epoch=2
05/22/2022 05:00:55 - INFO - __main__ - Step 80 Global step 80 Train loss 2.02 on epoch=2
05/22/2022 05:00:57 - INFO - __main__ - Step 90 Global step 90 Train loss 1.95 on epoch=3
05/22/2022 05:01:00 - INFO - __main__ - Step 100 Global step 100 Train loss 1.75 on epoch=3
05/22/2022 05:01:11 - INFO - __main__ - Global step 100 Train loss 2.13 Classification-F1 0.09226482611284952 on epoch=3
05/22/2022 05:01:11 - INFO - __main__ - Saving model with best Classification-F1: 0.03394564253828889 -> 0.09226482611284952 on epoch=3, global_step=100
05/22/2022 05:01:14 - INFO - __main__ - Step 110 Global step 110 Train loss 1.61 on epoch=3
05/22/2022 05:01:16 - INFO - __main__ - Step 120 Global step 120 Train loss 1.59 on epoch=4
05/22/2022 05:01:19 - INFO - __main__ - Step 130 Global step 130 Train loss 1.26 on epoch=4
05/22/2022 05:01:21 - INFO - __main__ - Step 140 Global step 140 Train loss 1.27 on epoch=4
05/22/2022 05:01:24 - INFO - __main__ - Step 150 Global step 150 Train loss 1.11 on epoch=5
05/22/2022 05:01:35 - INFO - __main__ - Global step 150 Train loss 1.37 Classification-F1 0.18973023720122817 on epoch=5
05/22/2022 05:01:35 - INFO - __main__ - Saving model with best Classification-F1: 0.09226482611284952 -> 0.18973023720122817 on epoch=5, global_step=150
05/22/2022 05:01:37 - INFO - __main__ - Step 160 Global step 160 Train loss 0.97 on epoch=5
05/22/2022 05:01:40 - INFO - __main__ - Step 170 Global step 170 Train loss 0.94 on epoch=6
05/22/2022 05:01:42 - INFO - __main__ - Step 180 Global step 180 Train loss 0.78 on epoch=6
05/22/2022 05:01:45 - INFO - __main__ - Step 190 Global step 190 Train loss 0.69 on epoch=6
05/22/2022 05:01:48 - INFO - __main__ - Step 200 Global step 200 Train loss 0.66 on epoch=7
05/22/2022 05:01:59 - INFO - __main__ - Global step 200 Train loss 0.81 Classification-F1 0.29672553885356273 on epoch=7
05/22/2022 05:01:59 - INFO - __main__ - Saving model with best Classification-F1: 0.18973023720122817 -> 0.29672553885356273 on epoch=7, global_step=200
05/22/2022 05:02:02 - INFO - __main__ - Step 210 Global step 210 Train loss 0.71 on epoch=7
05/22/2022 05:02:04 - INFO - __main__ - Step 220 Global step 220 Train loss 0.51 on epoch=7
05/22/2022 05:02:07 - INFO - __main__ - Step 230 Global step 230 Train loss 0.58 on epoch=8
05/22/2022 05:02:09 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=8
05/22/2022 05:02:12 - INFO - __main__ - Step 250 Global step 250 Train loss 0.50 on epoch=8
05/22/2022 05:02:25 - INFO - __main__ - Global step 250 Train loss 0.56 Classification-F1 0.3883878252500736 on epoch=8
05/22/2022 05:02:25 - INFO - __main__ - Saving model with best Classification-F1: 0.29672553885356273 -> 0.3883878252500736 on epoch=8, global_step=250
05/22/2022 05:02:27 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=9
05/22/2022 05:02:30 - INFO - __main__ - Step 270 Global step 270 Train loss 0.42 on epoch=9
05/22/2022 05:02:32 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=9
05/22/2022 05:02:35 - INFO - __main__ - Step 290 Global step 290 Train loss 0.38 on epoch=10
05/22/2022 05:02:37 - INFO - __main__ - Step 300 Global step 300 Train loss 0.34 on epoch=10
05/22/2022 05:02:51 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.5125794072599877 on epoch=10
05/22/2022 05:02:51 - INFO - __main__ - Saving model with best Classification-F1: 0.3883878252500736 -> 0.5125794072599877 on epoch=10, global_step=300
05/22/2022 05:02:53 - INFO - __main__ - Step 310 Global step 310 Train loss 0.36 on epoch=11
05/22/2022 05:02:56 - INFO - __main__ - Step 320 Global step 320 Train loss 0.36 on epoch=11
05/22/2022 05:02:58 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=11
05/22/2022 05:03:01 - INFO - __main__ - Step 340 Global step 340 Train loss 0.30 on epoch=12
05/22/2022 05:03:03 - INFO - __main__ - Step 350 Global step 350 Train loss 0.31 on epoch=12
05/22/2022 05:03:17 - INFO - __main__ - Global step 350 Train loss 0.35 Classification-F1 0.5175813163870585 on epoch=12
05/22/2022 05:03:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5125794072599877 -> 0.5175813163870585 on epoch=12, global_step=350
05/22/2022 05:03:20 - INFO - __main__ - Step 360 Global step 360 Train loss 0.34 on epoch=12
05/22/2022 05:03:22 - INFO - __main__ - Step 370 Global step 370 Train loss 0.26 on epoch=13
05/22/2022 05:03:25 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=13
05/22/2022 05:03:27 - INFO - __main__ - Step 390 Global step 390 Train loss 0.25 on epoch=13
05/22/2022 05:03:30 - INFO - __main__ - Step 400 Global step 400 Train loss 0.20 on epoch=14
05/22/2022 05:03:43 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.5523653465224274 on epoch=14
05/22/2022 05:03:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5175813163870585 -> 0.5523653465224274 on epoch=14, global_step=400
05/22/2022 05:03:45 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=14
05/22/2022 05:03:48 - INFO - __main__ - Step 420 Global step 420 Train loss 0.29 on epoch=14
05/22/2022 05:03:51 - INFO - __main__ - Step 430 Global step 430 Train loss 0.22 on epoch=15
05/22/2022 05:03:53 - INFO - __main__ - Step 440 Global step 440 Train loss 0.21 on epoch=15
05/22/2022 05:03:56 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=16
05/22/2022 05:04:08 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.6175713425020477 on epoch=16
05/22/2022 05:04:08 - INFO - __main__ - Saving model with best Classification-F1: 0.5523653465224274 -> 0.6175713425020477 on epoch=16, global_step=450
05/22/2022 05:04:11 - INFO - __main__ - Step 460 Global step 460 Train loss 0.17 on epoch=16
05/22/2022 05:04:13 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=16
05/22/2022 05:04:16 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=17
05/22/2022 05:04:18 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=17
05/22/2022 05:04:21 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=17
05/22/2022 05:04:33 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.6339617099077144 on epoch=17
05/22/2022 05:04:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6175713425020477 -> 0.6339617099077144 on epoch=17, global_step=500
05/22/2022 05:04:36 - INFO - __main__ - Step 510 Global step 510 Train loss 0.16 on epoch=18
05/22/2022 05:04:38 - INFO - __main__ - Step 520 Global step 520 Train loss 0.18 on epoch=18
05/22/2022 05:04:41 - INFO - __main__ - Step 530 Global step 530 Train loss 0.14 on epoch=18
05/22/2022 05:04:43 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=19
05/22/2022 05:04:46 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=19
05/22/2022 05:04:59 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.6222979295016385 on epoch=19
05/22/2022 05:05:02 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=19
05/22/2022 05:05:04 - INFO - __main__ - Step 570 Global step 570 Train loss 0.15 on epoch=20
05/22/2022 05:05:07 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=20
05/22/2022 05:05:09 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=21
05/22/2022 05:05:12 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=21
05/22/2022 05:05:24 - INFO - __main__ - Global step 600 Train loss 0.16 Classification-F1 0.685471944951454 on epoch=21
05/22/2022 05:05:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6339617099077144 -> 0.685471944951454 on epoch=21, global_step=600
05/22/2022 05:05:27 - INFO - __main__ - Step 610 Global step 610 Train loss 0.13 on epoch=21
05/22/2022 05:05:29 - INFO - __main__ - Step 620 Global step 620 Train loss 0.13 on epoch=22
05/22/2022 05:05:32 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=22
05/22/2022 05:05:35 - INFO - __main__ - Step 640 Global step 640 Train loss 0.18 on epoch=22
05/22/2022 05:05:37 - INFO - __main__ - Step 650 Global step 650 Train loss 0.12 on epoch=23
05/22/2022 05:05:51 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.6539253047698764 on epoch=23
05/22/2022 05:05:53 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=23
05/22/2022 05:05:56 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=23
05/22/2022 05:05:58 - INFO - __main__ - Step 680 Global step 680 Train loss 0.17 on epoch=24
05/22/2022 05:06:01 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=24
05/22/2022 05:06:03 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=24
05/22/2022 05:06:16 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6866333099208225 on epoch=24
05/22/2022 05:06:16 - INFO - __main__ - Saving model with best Classification-F1: 0.685471944951454 -> 0.6866333099208225 on epoch=24, global_step=700
05/22/2022 05:06:19 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=25
05/22/2022 05:06:22 - INFO - __main__ - Step 720 Global step 720 Train loss 0.13 on epoch=25
05/22/2022 05:06:24 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=26
05/22/2022 05:06:27 - INFO - __main__ - Step 740 Global step 740 Train loss 0.13 on epoch=26
05/22/2022 05:06:29 - INFO - __main__ - Step 750 Global step 750 Train loss 0.11 on epoch=26
05/22/2022 05:06:42 - INFO - __main__ - Global step 750 Train loss 0.13 Classification-F1 0.586318275518134 on epoch=26
05/22/2022 05:06:45 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=27
05/22/2022 05:06:47 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=27
05/22/2022 05:06:50 - INFO - __main__ - Step 780 Global step 780 Train loss 0.09 on epoch=27
05/22/2022 05:06:52 - INFO - __main__ - Step 790 Global step 790 Train loss 0.06 on epoch=28
05/22/2022 05:06:55 - INFO - __main__ - Step 800 Global step 800 Train loss 0.08 on epoch=28
05/22/2022 05:07:08 - INFO - __main__ - Global step 800 Train loss 0.11 Classification-F1 0.5886941602638258 on epoch=28
05/22/2022 05:07:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.07 on epoch=28
05/22/2022 05:07:13 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=29
05/22/2022 05:07:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=29
05/22/2022 05:07:18 - INFO - __main__ - Step 840 Global step 840 Train loss 0.10 on epoch=29
05/22/2022 05:07:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.09 on epoch=30
05/22/2022 05:07:34 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.6266209071834123 on epoch=30
05/22/2022 05:07:36 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=30
05/22/2022 05:07:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.10 on epoch=31
05/22/2022 05:07:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.12 on epoch=31
05/22/2022 05:07:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.09 on epoch=31
05/22/2022 05:07:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=32
05/22/2022 05:07:59 - INFO - __main__ - Global step 900 Train loss 0.10 Classification-F1 0.6278846735361897 on epoch=32
05/22/2022 05:08:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=32
05/22/2022 05:08:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=32
05/22/2022 05:08:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=33
05/22/2022 05:08:09 - INFO - __main__ - Step 940 Global step 940 Train loss 0.07 on epoch=33
05/22/2022 05:08:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.10 on epoch=33
05/22/2022 05:08:25 - INFO - __main__ - Global step 950 Train loss 0.08 Classification-F1 0.7024674520642262 on epoch=33
05/22/2022 05:08:25 - INFO - __main__ - Saving model with best Classification-F1: 0.6866333099208225 -> 0.7024674520642262 on epoch=33, global_step=950
05/22/2022 05:08:28 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=34
05/22/2022 05:08:30 - INFO - __main__ - Step 970 Global step 970 Train loss 0.06 on epoch=34
05/22/2022 05:08:33 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=34
05/22/2022 05:08:36 - INFO - __main__ - Step 990 Global step 990 Train loss 0.06 on epoch=35
05/22/2022 05:08:38 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.06 on epoch=35
05/22/2022 05:08:52 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.7199718046587529 on epoch=35
05/22/2022 05:08:52 - INFO - __main__ - Saving model with best Classification-F1: 0.7024674520642262 -> 0.7199718046587529 on epoch=35, global_step=1000
05/22/2022 05:08:54 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=36
05/22/2022 05:08:57 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.13 on epoch=36
05/22/2022 05:08:59 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=36
05/22/2022 05:09:02 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.05 on epoch=37
05/22/2022 05:09:05 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.09 on epoch=37
05/22/2022 05:09:18 - INFO - __main__ - Global step 1050 Train loss 0.10 Classification-F1 0.7288134233864494 on epoch=37
05/22/2022 05:09:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7199718046587529 -> 0.7288134233864494 on epoch=37, global_step=1050
05/22/2022 05:09:20 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=37
05/22/2022 05:09:23 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=38
05/22/2022 05:09:25 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=38
05/22/2022 05:09:28 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=38
05/22/2022 05:09:31 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=39
05/22/2022 05:09:43 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7287063325388797 on epoch=39
05/22/2022 05:09:46 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=39
05/22/2022 05:09:48 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=39
05/22/2022 05:09:51 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=40
05/22/2022 05:09:53 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.03 on epoch=40
05/22/2022 05:09:56 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=41
05/22/2022 05:10:09 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.6550638222874843 on epoch=41
05/22/2022 05:10:12 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=41
05/22/2022 05:10:15 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=41
05/22/2022 05:10:17 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.11 on epoch=42
05/22/2022 05:10:20 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=42
05/22/2022 05:10:22 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.07 on epoch=42
05/22/2022 05:10:35 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.7372137938314408 on epoch=42
05/22/2022 05:10:35 - INFO - __main__ - Saving model with best Classification-F1: 0.7288134233864494 -> 0.7372137938314408 on epoch=42, global_step=1200
05/22/2022 05:10:37 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.04 on epoch=43
05/22/2022 05:10:40 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.03 on epoch=43
05/22/2022 05:10:43 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=43
05/22/2022 05:10:45 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.03 on epoch=44
05/22/2022 05:10:48 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=44
05/22/2022 05:11:00 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.7834268442832824 on epoch=44
05/22/2022 05:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.7372137938314408 -> 0.7834268442832824 on epoch=44, global_step=1250
05/22/2022 05:11:03 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=44
05/22/2022 05:11:05 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=45
05/22/2022 05:11:08 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=45
05/22/2022 05:11:10 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=46
05/22/2022 05:11:13 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.03 on epoch=46
05/22/2022 05:11:26 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.7349189762235716 on epoch=46
05/22/2022 05:11:28 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=46
05/22/2022 05:11:31 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.03 on epoch=47
05/22/2022 05:11:33 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=47
05/22/2022 05:11:36 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=47
05/22/2022 05:11:38 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=48
05/22/2022 05:11:51 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.7354760616103784 on epoch=48
05/22/2022 05:11:54 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=48
05/22/2022 05:11:56 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.04 on epoch=48
05/22/2022 05:11:59 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=49
05/22/2022 05:12:02 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=49
05/22/2022 05:12:04 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=49
05/22/2022 05:12:17 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.7701017116846315 on epoch=49
05/22/2022 05:12:19 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=50
05/22/2022 05:12:22 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=50
05/22/2022 05:12:24 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=51
05/22/2022 05:12:27 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.04 on epoch=51
05/22/2022 05:12:30 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=51
05/22/2022 05:12:42 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.6923622559504953 on epoch=51
05/22/2022 05:12:45 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=52
05/22/2022 05:12:47 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=52
05/22/2022 05:12:50 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=52
05/22/2022 05:12:52 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=53
05/22/2022 05:12:55 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=53
05/22/2022 05:13:07 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.5686876450799899 on epoch=53
05/22/2022 05:13:10 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=53
05/22/2022 05:13:13 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=54
05/22/2022 05:13:15 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=54
05/22/2022 05:13:18 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.11 on epoch=54
05/22/2022 05:13:20 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=55
05/22/2022 05:13:32 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.633824906627574 on epoch=55
05/22/2022 05:13:35 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=55
05/22/2022 05:13:38 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.10 on epoch=56
05/22/2022 05:13:40 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=56
05/22/2022 05:13:43 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=56
05/22/2022 05:13:45 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=57
05/22/2022 05:13:57 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7858595715611331 on epoch=57
05/22/2022 05:13:57 - INFO - __main__ - Saving model with best Classification-F1: 0.7834268442832824 -> 0.7858595715611331 on epoch=57, global_step=1600
05/22/2022 05:14:00 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.04 on epoch=57
05/22/2022 05:14:03 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=57
05/22/2022 05:14:05 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.06 on epoch=58
05/22/2022 05:14:08 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.02 on epoch=58
05/22/2022 05:14:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=58
05/22/2022 05:14:22 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.8458544698043302 on epoch=58
05/22/2022 05:14:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7858595715611331 -> 0.8458544698043302 on epoch=58, global_step=1650
05/22/2022 05:14:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=59
05/22/2022 05:14:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=59
05/22/2022 05:14:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=59
05/22/2022 05:14:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=60
05/22/2022 05:14:35 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.02 on epoch=60
05/22/2022 05:14:47 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7911309486345648 on epoch=60
05/22/2022 05:14:50 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=61
05/22/2022 05:14:53 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=61
05/22/2022 05:14:55 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=61
05/22/2022 05:14:58 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=62
05/22/2022 05:15:00 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 05:15:13 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.7020391529574546 on epoch=62
05/22/2022 05:15:15 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=62
05/22/2022 05:15:18 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=63
05/22/2022 05:15:20 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=63
05/22/2022 05:15:23 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=63
05/22/2022 05:15:26 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.02 on epoch=64
05/22/2022 05:15:38 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.7507393816197255 on epoch=64
05/22/2022 05:15:40 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.01 on epoch=64
05/22/2022 05:15:43 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=64
05/22/2022 05:15:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=65
05/22/2022 05:15:48 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=65
05/22/2022 05:15:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=66
05/22/2022 05:16:03 - INFO - __main__ - Global step 1850 Train loss 0.03 Classification-F1 0.7076413932510149 on epoch=66
05/22/2022 05:16:06 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=66
05/22/2022 05:16:08 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=66
05/22/2022 05:16:11 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=67
05/22/2022 05:16:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=67
05/22/2022 05:16:16 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=67
05/22/2022 05:16:28 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6580524812132548 on epoch=67
05/22/2022 05:16:31 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=68
05/22/2022 05:16:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 05:16:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 05:16:39 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=69
05/22/2022 05:16:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=69
05/22/2022 05:16:53 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.6929242239703939 on epoch=69
05/22/2022 05:16:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.03 on epoch=69
05/22/2022 05:16:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=70
05/22/2022 05:17:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=70
05/22/2022 05:17:04 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=71
05/22/2022 05:17:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=71
05/22/2022 05:17:19 - INFO - __main__ - Global step 2000 Train loss 0.03 Classification-F1 0.6597769335112219 on epoch=71
05/22/2022 05:17:21 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=71
05/22/2022 05:17:24 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=72
05/22/2022 05:17:27 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=72
05/22/2022 05:17:29 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=72
05/22/2022 05:17:32 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=73
05/22/2022 05:17:44 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.7945872178420892 on epoch=73
05/22/2022 05:17:47 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=73
05/22/2022 05:17:49 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.01 on epoch=73
05/22/2022 05:17:52 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=74
05/22/2022 05:17:54 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=74
05/22/2022 05:17:57 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=74
05/22/2022 05:18:09 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.7428829965386787 on epoch=74
05/22/2022 05:18:12 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=75
05/22/2022 05:18:14 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=75
05/22/2022 05:18:17 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=76
05/22/2022 05:18:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.01 on epoch=76
05/22/2022 05:18:22 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=76
05/22/2022 05:18:34 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.6630890889072926 on epoch=76
05/22/2022 05:18:37 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=77
05/22/2022 05:18:40 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=77
05/22/2022 05:18:42 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=77
05/22/2022 05:18:45 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=78
05/22/2022 05:18:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=78
05/22/2022 05:19:00 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7432798273780369 on epoch=78
05/22/2022 05:19:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.01 on epoch=78
05/22/2022 05:19:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=79
05/22/2022 05:19:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=79
05/22/2022 05:19:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=79
05/22/2022 05:19:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=80
05/22/2022 05:19:25 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.6668151712019637 on epoch=80
05/22/2022 05:19:27 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 05:19:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 05:19:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=81
05/22/2022 05:19:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=81
05/22/2022 05:19:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=82
05/22/2022 05:19:50 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.7026312253095668 on epoch=82
05/22/2022 05:19:52 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=82
05/22/2022 05:19:55 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=82
05/22/2022 05:19:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=83
05/22/2022 05:20:00 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=83
05/22/2022 05:20:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.01 on epoch=83
05/22/2022 05:20:15 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6650432633307919 on epoch=83
05/22/2022 05:20:18 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=84
05/22/2022 05:20:20 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=84
05/22/2022 05:20:23 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=84
05/22/2022 05:20:25 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=85
05/22/2022 05:20:28 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=85
05/22/2022 05:20:40 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.6972671619225933 on epoch=85
05/22/2022 05:20:43 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=86
05/22/2022 05:20:46 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=86
05/22/2022 05:20:48 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=86
05/22/2022 05:20:51 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 05:20:53 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=87
05/22/2022 05:21:06 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9072848149132514 on epoch=87
05/22/2022 05:21:06 - INFO - __main__ - Saving model with best Classification-F1: 0.8458544698043302 -> 0.9072848149132514 on epoch=87, global_step=2450
05/22/2022 05:21:09 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=87
05/22/2022 05:21:11 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=88
05/22/2022 05:21:14 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 05:21:16 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=88
05/22/2022 05:21:19 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=89
05/22/2022 05:21:31 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.7932100467511671 on epoch=89
05/22/2022 05:21:34 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=89
05/22/2022 05:21:37 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.02 on epoch=89
05/22/2022 05:21:39 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=90
05/22/2022 05:21:42 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 05:21:44 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=91
05/22/2022 05:21:57 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.842464737465848 on epoch=91
05/22/2022 05:21:59 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=91
05/22/2022 05:22:02 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=91
05/22/2022 05:22:05 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=92
05/22/2022 05:22:07 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=92
05/22/2022 05:22:10 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=92
05/22/2022 05:22:22 - INFO - __main__ - Global step 2600 Train loss 0.02 Classification-F1 0.7445861560998908 on epoch=92
05/22/2022 05:22:25 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=93
05/22/2022 05:22:27 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 05:22:30 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=93
05/22/2022 05:22:32 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 05:22:35 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=94
05/22/2022 05:22:47 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7393492918005771 on epoch=94
05/22/2022 05:22:50 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=94
05/22/2022 05:22:52 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=95
05/22/2022 05:22:55 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=95
05/22/2022 05:22:58 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 05:23:00 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=96
05/22/2022 05:23:13 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7856956803535986 on epoch=96
05/22/2022 05:23:15 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=96
05/22/2022 05:23:18 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=97
05/22/2022 05:23:20 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=97
05/22/2022 05:23:23 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=97
05/22/2022 05:23:26 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=98
05/22/2022 05:23:38 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8534103360571449 on epoch=98
05/22/2022 05:23:40 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=98
05/22/2022 05:23:43 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=98
05/22/2022 05:23:46 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=99
05/22/2022 05:23:48 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=99
05/22/2022 05:23:51 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=99
05/22/2022 05:24:03 - INFO - __main__ - Global step 2800 Train loss 0.01 Classification-F1 0.7078536865888309 on epoch=99
05/22/2022 05:24:06 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=100
05/22/2022 05:24:08 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=100
05/22/2022 05:24:11 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=101
05/22/2022 05:24:14 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=101
05/22/2022 05:24:16 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=101
05/22/2022 05:24:29 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7512406926843054 on epoch=101
05/22/2022 05:24:31 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=102
05/22/2022 05:24:34 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=102
05/22/2022 05:24:37 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=102
05/22/2022 05:24:39 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 05:24:42 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 05:24:54 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7118459082474612 on epoch=103
05/22/2022 05:24:57 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=103
05/22/2022 05:24:59 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=104
05/22/2022 05:25:02 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=104
05/22/2022 05:25:05 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=104
05/22/2022 05:25:07 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=105
05/22/2022 05:25:20 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8465236002011549 on epoch=105
05/22/2022 05:25:22 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=105
05/22/2022 05:25:25 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=106
05/22/2022 05:25:27 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 05:25:30 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=106
05/22/2022 05:25:33 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=107
05/22/2022 05:25:34 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:25:34 - INFO - __main__ - Printing 3 examples
05/22/2022 05:25:34 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 05:25:34 - INFO - __main__ - ['Animal']
05/22/2022 05:25:34 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 05:25:34 - INFO - __main__ - ['Animal']
05/22/2022 05:25:34 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 05:25:34 - INFO - __main__ - ['Animal']
05/22/2022 05:25:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:25:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:25:35 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 05:25:35 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:25:35 - INFO - __main__ - Printing 3 examples
05/22/2022 05:25:35 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 05:25:35 - INFO - __main__ - ['Animal']
05/22/2022 05:25:35 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 05:25:35 - INFO - __main__ - ['Animal']
05/22/2022 05:25:35 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 05:25:35 - INFO - __main__ - ['Animal']
05/22/2022 05:25:35 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:25:35 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:25:36 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 05:25:45 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.7502855136271229 on epoch=107
05/22/2022 05:25:45 - INFO - __main__ - save last model!
05/22/2022 05:25:45 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 05:25:45 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 05:25:45 - INFO - __main__ - Printing 3 examples
05/22/2022 05:25:45 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 05:25:45 - INFO - __main__ - ['Animal']
05/22/2022 05:25:45 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 05:25:45 - INFO - __main__ - ['Animal']
05/22/2022 05:25:45 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 05:25:45 - INFO - __main__ - ['Village']
05/22/2022 05:25:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:25:47 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:25:50 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 05:25:51 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 05:25:52 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 05:25:52 - INFO - __main__ - Starting training!
05/22/2022 05:27:57 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_13_0.5_8_predictions.txt
05/22/2022 05:27:57 - INFO - __main__ - Classification-F1 on test data: 0.5443
05/22/2022 05:27:58 - INFO - __main__ - prefix=dbpedia_14_32_13, lr=0.5, bsz=8, dev_performance=0.9072848149132514, test_performance=0.5442911214382303
05/22/2022 05:27:58 - INFO - __main__ - Running ... prefix=dbpedia_14_32_13, lr=0.4, bsz=8 ...
05/22/2022 05:27:59 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:27:59 - INFO - __main__ - Printing 3 examples
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:27:59 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:27:59 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 05:27:59 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:27:59 - INFO - __main__ - Printing 3 examples
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 05:27:59 - INFO - __main__ - ['Animal']
05/22/2022 05:27:59 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:27:59 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:28:00 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 05:28:16 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 05:28:16 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 05:28:16 - INFO - __main__ - Starting training!
05/22/2022 05:28:20 - INFO - __main__ - Step 10 Global step 10 Train loss 6.49 on epoch=0
05/22/2022 05:28:23 - INFO - __main__ - Step 20 Global step 20 Train loss 4.66 on epoch=0
05/22/2022 05:28:25 - INFO - __main__ - Step 30 Global step 30 Train loss 4.21 on epoch=1
05/22/2022 05:28:28 - INFO - __main__ - Step 40 Global step 40 Train loss 3.58 on epoch=1
05/22/2022 05:28:31 - INFO - __main__ - Step 50 Global step 50 Train loss 2.94 on epoch=1
05/22/2022 05:28:44 - INFO - __main__ - Global step 50 Train loss 4.38 Classification-F1 0.02812921378088052 on epoch=1
05/22/2022 05:28:44 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02812921378088052 on epoch=1, global_step=50
05/22/2022 05:28:47 - INFO - __main__ - Step 60 Global step 60 Train loss 2.70 on epoch=2
05/22/2022 05:28:49 - INFO - __main__ - Step 70 Global step 70 Train loss 2.61 on epoch=2
05/22/2022 05:28:52 - INFO - __main__ - Step 80 Global step 80 Train loss 2.18 on epoch=2
05/22/2022 05:28:54 - INFO - __main__ - Step 90 Global step 90 Train loss 2.06 on epoch=3
05/22/2022 05:28:57 - INFO - __main__ - Step 100 Global step 100 Train loss 2.02 on epoch=3
05/22/2022 05:29:08 - INFO - __main__ - Global step 100 Train loss 2.31 Classification-F1 0.06697796110919278 on epoch=3
05/22/2022 05:29:08 - INFO - __main__ - Saving model with best Classification-F1: 0.02812921378088052 -> 0.06697796110919278 on epoch=3, global_step=100
05/22/2022 05:29:11 - INFO - __main__ - Step 110 Global step 110 Train loss 1.73 on epoch=3
05/22/2022 05:29:14 - INFO - __main__ - Step 120 Global step 120 Train loss 1.77 on epoch=4
05/22/2022 05:29:16 - INFO - __main__ - Step 130 Global step 130 Train loss 1.60 on epoch=4
05/22/2022 05:29:19 - INFO - __main__ - Step 140 Global step 140 Train loss 1.44 on epoch=4
05/22/2022 05:29:21 - INFO - __main__ - Step 150 Global step 150 Train loss 1.42 on epoch=5
05/22/2022 05:29:32 - INFO - __main__ - Global step 150 Train loss 1.59 Classification-F1 0.14796646089121454 on epoch=5
05/22/2022 05:29:32 - INFO - __main__ - Saving model with best Classification-F1: 0.06697796110919278 -> 0.14796646089121454 on epoch=5, global_step=150
05/22/2022 05:29:35 - INFO - __main__ - Step 160 Global step 160 Train loss 1.29 on epoch=5
05/22/2022 05:29:37 - INFO - __main__ - Step 170 Global step 170 Train loss 1.24 on epoch=6
05/22/2022 05:29:40 - INFO - __main__ - Step 180 Global step 180 Train loss 1.12 on epoch=6
05/22/2022 05:29:43 - INFO - __main__ - Step 190 Global step 190 Train loss 0.98 on epoch=6
05/22/2022 05:29:45 - INFO - __main__ - Step 200 Global step 200 Train loss 0.94 on epoch=7
05/22/2022 05:29:56 - INFO - __main__ - Global step 200 Train loss 1.11 Classification-F1 0.23378794484661622 on epoch=7
05/22/2022 05:29:56 - INFO - __main__ - Saving model with best Classification-F1: 0.14796646089121454 -> 0.23378794484661622 on epoch=7, global_step=200
05/22/2022 05:29:59 - INFO - __main__ - Step 210 Global step 210 Train loss 0.92 on epoch=7
05/22/2022 05:30:01 - INFO - __main__ - Step 220 Global step 220 Train loss 0.77 on epoch=7
05/22/2022 05:30:04 - INFO - __main__ - Step 230 Global step 230 Train loss 0.78 on epoch=8
05/22/2022 05:30:07 - INFO - __main__ - Step 240 Global step 240 Train loss 0.64 on epoch=8
05/22/2022 05:30:09 - INFO - __main__ - Step 250 Global step 250 Train loss 0.72 on epoch=8
05/22/2022 05:30:21 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.3366095564368877 on epoch=8
05/22/2022 05:30:21 - INFO - __main__ - Saving model with best Classification-F1: 0.23378794484661622 -> 0.3366095564368877 on epoch=8, global_step=250
05/22/2022 05:30:24 - INFO - __main__ - Step 260 Global step 260 Train loss 0.54 on epoch=9
05/22/2022 05:30:26 - INFO - __main__ - Step 270 Global step 270 Train loss 0.53 on epoch=9
05/22/2022 05:30:29 - INFO - __main__ - Step 280 Global step 280 Train loss 0.55 on epoch=9
05/22/2022 05:30:32 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=10
05/22/2022 05:30:34 - INFO - __main__ - Step 300 Global step 300 Train loss 0.47 on epoch=10
05/22/2022 05:30:47 - INFO - __main__ - Global step 300 Train loss 0.52 Classification-F1 0.4230144250175787 on epoch=10
05/22/2022 05:30:47 - INFO - __main__ - Saving model with best Classification-F1: 0.3366095564368877 -> 0.4230144250175787 on epoch=10, global_step=300
05/22/2022 05:30:49 - INFO - __main__ - Step 310 Global step 310 Train loss 0.46 on epoch=11
05/22/2022 05:30:52 - INFO - __main__ - Step 320 Global step 320 Train loss 0.45 on epoch=11
05/22/2022 05:30:55 - INFO - __main__ - Step 330 Global step 330 Train loss 0.46 on epoch=11
05/22/2022 05:30:57 - INFO - __main__ - Step 340 Global step 340 Train loss 0.41 on epoch=12
05/22/2022 05:31:00 - INFO - __main__ - Step 350 Global step 350 Train loss 0.45 on epoch=12
05/22/2022 05:31:12 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.4414552243921415 on epoch=12
05/22/2022 05:31:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4230144250175787 -> 0.4414552243921415 on epoch=12, global_step=350
05/22/2022 05:31:15 - INFO - __main__ - Step 360 Global step 360 Train loss 0.37 on epoch=12
05/22/2022 05:31:18 - INFO - __main__ - Step 370 Global step 370 Train loss 0.35 on epoch=13
05/22/2022 05:31:20 - INFO - __main__ - Step 380 Global step 380 Train loss 0.30 on epoch=13
05/22/2022 05:31:23 - INFO - __main__ - Step 390 Global step 390 Train loss 0.33 on epoch=13
05/22/2022 05:31:25 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=14
05/22/2022 05:31:38 - INFO - __main__ - Global step 400 Train loss 0.32 Classification-F1 0.5423427168033474 on epoch=14
05/22/2022 05:31:38 - INFO - __main__ - Saving model with best Classification-F1: 0.4414552243921415 -> 0.5423427168033474 on epoch=14, global_step=400
05/22/2022 05:31:41 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=14
05/22/2022 05:31:43 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=14
05/22/2022 05:31:46 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=15
05/22/2022 05:31:49 - INFO - __main__ - Step 440 Global step 440 Train loss 0.24 on epoch=15
05/22/2022 05:31:51 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=16
05/22/2022 05:32:04 - INFO - __main__ - Global step 450 Train loss 0.30 Classification-F1 0.591477406537391 on epoch=16
05/22/2022 05:32:04 - INFO - __main__ - Saving model with best Classification-F1: 0.5423427168033474 -> 0.591477406537391 on epoch=16, global_step=450
05/22/2022 05:32:07 - INFO - __main__ - Step 460 Global step 460 Train loss 0.21 on epoch=16
05/22/2022 05:32:09 - INFO - __main__ - Step 470 Global step 470 Train loss 0.31 on epoch=16
05/22/2022 05:32:12 - INFO - __main__ - Step 480 Global step 480 Train loss 0.36 on epoch=17
05/22/2022 05:32:15 - INFO - __main__ - Step 490 Global step 490 Train loss 0.31 on epoch=17
05/22/2022 05:32:17 - INFO - __main__ - Step 500 Global step 500 Train loss 0.23 on epoch=17
05/22/2022 05:32:30 - INFO - __main__ - Global step 500 Train loss 0.28 Classification-F1 0.7128565668264357 on epoch=17
05/22/2022 05:32:30 - INFO - __main__ - Saving model with best Classification-F1: 0.591477406537391 -> 0.7128565668264357 on epoch=17, global_step=500
05/22/2022 05:32:33 - INFO - __main__ - Step 510 Global step 510 Train loss 0.17 on epoch=18
05/22/2022 05:32:36 - INFO - __main__ - Step 520 Global step 520 Train loss 0.33 on epoch=18
05/22/2022 05:32:38 - INFO - __main__ - Step 530 Global step 530 Train loss 0.23 on epoch=18
05/22/2022 05:32:41 - INFO - __main__ - Step 540 Global step 540 Train loss 0.22 on epoch=19
05/22/2022 05:32:43 - INFO - __main__ - Step 550 Global step 550 Train loss 0.18 on epoch=19
05/22/2022 05:32:56 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.5331607830191107 on epoch=19
05/22/2022 05:32:59 - INFO - __main__ - Step 560 Global step 560 Train loss 0.27 on epoch=19
05/22/2022 05:33:01 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=20
05/22/2022 05:33:04 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=20
05/22/2022 05:33:07 - INFO - __main__ - Step 590 Global step 590 Train loss 0.22 on epoch=21
05/22/2022 05:33:09 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=21
05/22/2022 05:33:22 - INFO - __main__ - Global step 600 Train loss 0.22 Classification-F1 0.7318516294697337 on epoch=21
05/22/2022 05:33:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7128565668264357 -> 0.7318516294697337 on epoch=21, global_step=600
05/22/2022 05:33:25 - INFO - __main__ - Step 610 Global step 610 Train loss 0.26 on epoch=21
05/22/2022 05:33:27 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=22
05/22/2022 05:33:30 - INFO - __main__ - Step 630 Global step 630 Train loss 0.20 on epoch=22
05/22/2022 05:33:33 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=22
05/22/2022 05:33:35 - INFO - __main__ - Step 650 Global step 650 Train loss 0.22 on epoch=23
05/22/2022 05:33:48 - INFO - __main__ - Global step 650 Train loss 0.22 Classification-F1 0.6359955522634276 on epoch=23
05/22/2022 05:33:51 - INFO - __main__ - Step 660 Global step 660 Train loss 0.13 on epoch=23
05/22/2022 05:33:53 - INFO - __main__ - Step 670 Global step 670 Train loss 0.23 on epoch=23
05/22/2022 05:33:56 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=24
05/22/2022 05:33:59 - INFO - __main__ - Step 690 Global step 690 Train loss 0.14 on epoch=24
05/22/2022 05:34:01 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=24
05/22/2022 05:34:14 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6168943574530058 on epoch=24
05/22/2022 05:34:17 - INFO - __main__ - Step 710 Global step 710 Train loss 0.18 on epoch=25
05/22/2022 05:34:19 - INFO - __main__ - Step 720 Global step 720 Train loss 0.19 on epoch=25
05/22/2022 05:34:22 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=26
05/22/2022 05:34:25 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=26
05/22/2022 05:34:27 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=26
05/22/2022 05:34:40 - INFO - __main__ - Global step 750 Train loss 0.16 Classification-F1 0.5624162766474807 on epoch=26
05/22/2022 05:34:43 - INFO - __main__ - Step 760 Global step 760 Train loss 0.10 on epoch=27
05/22/2022 05:34:45 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=27
05/22/2022 05:34:48 - INFO - __main__ - Step 780 Global step 780 Train loss 0.13 on epoch=27
05/22/2022 05:34:51 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=28
05/22/2022 05:34:53 - INFO - __main__ - Step 800 Global step 800 Train loss 0.11 on epoch=28
05/22/2022 05:35:06 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.5873911831482518 on epoch=28
05/22/2022 05:35:08 - INFO - __main__ - Step 810 Global step 810 Train loss 0.15 on epoch=28
05/22/2022 05:35:11 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=29
05/22/2022 05:35:14 - INFO - __main__ - Step 830 Global step 830 Train loss 0.14 on epoch=29
05/22/2022 05:35:16 - INFO - __main__ - Step 840 Global step 840 Train loss 0.19 on epoch=29
05/22/2022 05:35:19 - INFO - __main__ - Step 850 Global step 850 Train loss 0.13 on epoch=30
05/22/2022 05:35:32 - INFO - __main__ - Global step 850 Train loss 0.14 Classification-F1 0.5257680648948903 on epoch=30
05/22/2022 05:35:34 - INFO - __main__ - Step 860 Global step 860 Train loss 0.14 on epoch=30
05/22/2022 05:35:37 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=31
05/22/2022 05:35:39 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=31
05/22/2022 05:35:42 - INFO - __main__ - Step 890 Global step 890 Train loss 0.13 on epoch=31
05/22/2022 05:35:45 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=32
05/22/2022 05:35:57 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.5265550411051195 on epoch=32
05/22/2022 05:36:00 - INFO - __main__ - Step 910 Global step 910 Train loss 0.11 on epoch=32
05/22/2022 05:36:03 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=32
05/22/2022 05:36:05 - INFO - __main__ - Step 930 Global step 930 Train loss 0.10 on epoch=33
05/22/2022 05:36:08 - INFO - __main__ - Step 940 Global step 940 Train loss 0.09 on epoch=33
05/22/2022 05:36:11 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=33
05/22/2022 05:36:23 - INFO - __main__ - Global step 950 Train loss 0.11 Classification-F1 0.5504477677343663 on epoch=33
05/22/2022 05:36:26 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=34
05/22/2022 05:36:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.11 on epoch=34
05/22/2022 05:36:31 - INFO - __main__ - Step 980 Global step 980 Train loss 0.13 on epoch=34
05/22/2022 05:36:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.09 on epoch=35
05/22/2022 05:36:36 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=35
05/22/2022 05:36:49 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5382913851576194 on epoch=35
05/22/2022 05:36:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.09 on epoch=36
05/22/2022 05:36:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.06 on epoch=36
05/22/2022 05:36:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=36
05/22/2022 05:37:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.11 on epoch=37
05/22/2022 05:37:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=37
05/22/2022 05:37:15 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.5673792000385041 on epoch=37
05/22/2022 05:37:18 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.15 on epoch=37
05/22/2022 05:37:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.08 on epoch=38
05/22/2022 05:37:23 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=38
05/22/2022 05:37:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.08 on epoch=38
05/22/2022 05:37:28 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.08 on epoch=39
05/22/2022 05:37:41 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.5523078360480996 on epoch=39
05/22/2022 05:37:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=39
05/22/2022 05:37:46 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=39
05/22/2022 05:37:49 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=40
05/22/2022 05:37:51 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=40
05/22/2022 05:37:54 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.12 on epoch=41
05/22/2022 05:38:06 - INFO - __main__ - Global step 1150 Train loss 0.08 Classification-F1 0.5901760438990413 on epoch=41
05/22/2022 05:38:09 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=41
05/22/2022 05:38:12 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.07 on epoch=41
05/22/2022 05:38:14 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=42
05/22/2022 05:38:17 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.09 on epoch=42
05/22/2022 05:38:19 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=42
05/22/2022 05:38:32 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.5751668150976315 on epoch=42
05/22/2022 05:38:34 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.08 on epoch=43
05/22/2022 05:38:37 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=43
05/22/2022 05:38:39 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=43
05/22/2022 05:38:42 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=44
05/22/2022 05:38:45 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=44
05/22/2022 05:38:57 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.5688788004831855 on epoch=44
05/22/2022 05:39:00 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=44
05/22/2022 05:39:03 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.09 on epoch=45
05/22/2022 05:39:05 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=45
05/22/2022 05:39:08 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.07 on epoch=46
05/22/2022 05:39:10 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=46
05/22/2022 05:39:23 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6140189836475102 on epoch=46
05/22/2022 05:39:26 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=46
05/22/2022 05:39:28 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=47
05/22/2022 05:39:31 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.06 on epoch=47
05/22/2022 05:39:34 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.09 on epoch=47
05/22/2022 05:39:36 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=48
05/22/2022 05:39:49 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.4959158293170688 on epoch=48
05/22/2022 05:39:52 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=48
05/22/2022 05:39:55 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=48
05/22/2022 05:39:57 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.09 on epoch=49
05/22/2022 05:40:00 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=49
05/22/2022 05:40:02 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.08 on epoch=49
05/22/2022 05:40:15 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.5590878527203894 on epoch=49
05/22/2022 05:40:18 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.03 on epoch=50
05/22/2022 05:40:20 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=50
05/22/2022 05:40:23 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.09 on epoch=51
05/22/2022 05:40:25 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=51
05/22/2022 05:40:28 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.05 on epoch=51
05/22/2022 05:40:40 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.563665329562463 on epoch=51
05/22/2022 05:40:43 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.08 on epoch=52
05/22/2022 05:40:46 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.13 on epoch=52
05/22/2022 05:40:48 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=52
05/22/2022 05:40:51 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=53
05/22/2022 05:40:53 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.07 on epoch=53
05/22/2022 05:41:06 - INFO - __main__ - Global step 1500 Train loss 0.08 Classification-F1 0.6199722179979448 on epoch=53
05/22/2022 05:41:08 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=53
05/22/2022 05:41:11 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.07 on epoch=54
05/22/2022 05:41:13 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=54
05/22/2022 05:41:16 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.06 on epoch=54
05/22/2022 05:41:19 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=55
05/22/2022 05:41:31 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.5752139075448134 on epoch=55
05/22/2022 05:41:34 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=55
05/22/2022 05:41:36 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=56
05/22/2022 05:41:39 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=56
05/22/2022 05:41:42 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=56
05/22/2022 05:41:44 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.05 on epoch=57
05/22/2022 05:41:57 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.6163157412438895 on epoch=57
05/22/2022 05:41:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=57
05/22/2022 05:42:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.05 on epoch=57
05/22/2022 05:42:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.03 on epoch=58
05/22/2022 05:42:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.05 on epoch=58
05/22/2022 05:42:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=58
05/22/2022 05:42:22 - INFO - __main__ - Global step 1650 Train loss 0.05 Classification-F1 0.6388763314804807 on epoch=58
05/22/2022 05:42:24 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=59
05/22/2022 05:42:27 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=59
05/22/2022 05:42:29 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=59
05/22/2022 05:42:32 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=60
05/22/2022 05:42:34 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.06 on epoch=60
05/22/2022 05:42:46 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.623945196312329 on epoch=60
05/22/2022 05:42:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=61
05/22/2022 05:42:52 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=61
05/22/2022 05:42:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=61
05/22/2022 05:42:57 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.03 on epoch=62
05/22/2022 05:42:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.03 on epoch=62
05/22/2022 05:43:12 - INFO - __main__ - Global step 1750 Train loss 0.03 Classification-F1 0.5965359941132862 on epoch=62
05/22/2022 05:43:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=62
05/22/2022 05:43:17 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=63
05/22/2022 05:43:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=63
05/22/2022 05:43:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.05 on epoch=63
05/22/2022 05:43:25 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=64
05/22/2022 05:43:37 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.5736139560151229 on epoch=64
05/22/2022 05:43:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=64
05/22/2022 05:43:42 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=64
05/22/2022 05:43:45 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=65
05/22/2022 05:43:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 05:43:50 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=66
05/22/2022 05:44:02 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.639003006582341 on epoch=66
05/22/2022 05:44:05 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=66
05/22/2022 05:44:07 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=66
05/22/2022 05:44:10 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=67
05/22/2022 05:44:13 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=67
05/22/2022 05:44:15 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=67
05/22/2022 05:44:28 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.6470628678016596 on epoch=67
05/22/2022 05:44:30 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=68
05/22/2022 05:44:33 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=68
05/22/2022 05:44:36 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=68
05/22/2022 05:44:38 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=69
05/22/2022 05:44:41 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=69
05/22/2022 05:44:53 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6497277240336954 on epoch=69
05/22/2022 05:44:56 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.02 on epoch=69
05/22/2022 05:44:58 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=70
05/22/2022 05:45:01 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=70
05/22/2022 05:45:03 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=71
05/22/2022 05:45:06 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=71
05/22/2022 05:45:18 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.5782231756091492 on epoch=71
05/22/2022 05:45:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=71
05/22/2022 05:45:23 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=72
05/22/2022 05:45:26 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=72
05/22/2022 05:45:28 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=72
05/22/2022 05:45:31 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=73
05/22/2022 05:45:43 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.6130172786291033 on epoch=73
05/22/2022 05:45:46 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=73
05/22/2022 05:45:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=73
05/22/2022 05:45:51 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=74
05/22/2022 05:45:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=74
05/22/2022 05:45:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=74
05/22/2022 05:46:08 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.643790109122556 on epoch=74
05/22/2022 05:46:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=75
05/22/2022 05:46:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.10 on epoch=75
05/22/2022 05:46:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=76
05/22/2022 05:46:19 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=76
05/22/2022 05:46:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=76
05/22/2022 05:46:33 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.7027256454272943 on epoch=76
05/22/2022 05:46:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=77
05/22/2022 05:46:38 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=77
05/22/2022 05:46:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=77
05/22/2022 05:46:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 05:46:46 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=78
05/22/2022 05:46:59 - INFO - __main__ - Global step 2200 Train loss 0.04 Classification-F1 0.7729424055070491 on epoch=78
05/22/2022 05:46:59 - INFO - __main__ - Saving model with best Classification-F1: 0.7318516294697337 -> 0.7729424055070491 on epoch=78, global_step=2200
05/22/2022 05:47:01 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=78
05/22/2022 05:47:04 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=79
05/22/2022 05:47:06 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.01 on epoch=79
05/22/2022 05:47:09 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.06 on epoch=79
05/22/2022 05:47:11 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.03 on epoch=80
05/22/2022 05:47:24 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6897777931839901 on epoch=80
05/22/2022 05:47:26 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 05:47:29 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 05:47:31 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=81
05/22/2022 05:47:34 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=81
05/22/2022 05:47:36 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=82
05/22/2022 05:47:49 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6567091720489394 on epoch=82
05/22/2022 05:47:51 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.01 on epoch=82
05/22/2022 05:47:54 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=82
05/22/2022 05:47:57 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=83
05/22/2022 05:47:59 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=83
05/22/2022 05:48:02 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=83
05/22/2022 05:48:14 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.6692579751723393 on epoch=83
05/22/2022 05:48:16 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=84
05/22/2022 05:48:19 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.05 on epoch=84
05/22/2022 05:48:22 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.04 on epoch=84
05/22/2022 05:48:24 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=85
05/22/2022 05:48:27 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 05:48:39 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.6165953424881996 on epoch=85
05/22/2022 05:48:42 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=86
05/22/2022 05:48:44 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=86
05/22/2022 05:48:47 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=86
05/22/2022 05:48:49 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=87
05/22/2022 05:48:52 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.03 on epoch=87
05/22/2022 05:49:04 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7506961353063504 on epoch=87
05/22/2022 05:49:07 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=87
05/22/2022 05:49:09 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=88
05/22/2022 05:49:12 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.05 on epoch=88
05/22/2022 05:49:14 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 05:49:17 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=89
05/22/2022 05:49:29 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7449944963273816 on epoch=89
05/22/2022 05:49:32 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=89
05/22/2022 05:49:34 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=89
05/22/2022 05:49:37 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=90
05/22/2022 05:49:39 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 05:49:42 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.05 on epoch=91
05/22/2022 05:49:54 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7940394961197836 on epoch=91
05/22/2022 05:49:54 - INFO - __main__ - Saving model with best Classification-F1: 0.7729424055070491 -> 0.7940394961197836 on epoch=91, global_step=2550
05/22/2022 05:49:57 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=91
05/22/2022 05:49:59 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 05:50:02 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=92
05/22/2022 05:50:05 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=92
05/22/2022 05:50:07 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=92
05/22/2022 05:50:20 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.7051916945062107 on epoch=92
05/22/2022 05:50:22 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=93
05/22/2022 05:50:25 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 05:50:27 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.08 on epoch=93
05/22/2022 05:50:30 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=94
05/22/2022 05:50:33 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=94
05/22/2022 05:50:45 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6338811227780908 on epoch=94
05/22/2022 05:50:47 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=94
05/22/2022 05:50:50 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=95
05/22/2022 05:50:52 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=95
05/22/2022 05:50:55 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 05:50:58 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=96
05/22/2022 05:51:10 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7394312009246921 on epoch=96
05/22/2022 05:51:12 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=96
05/22/2022 05:51:15 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=97
05/22/2022 05:51:18 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=97
05/22/2022 05:51:20 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=97
05/22/2022 05:51:23 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=98
05/22/2022 05:51:35 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6301536440162476 on epoch=98
05/22/2022 05:51:38 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=98
05/22/2022 05:51:40 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=98
05/22/2022 05:51:43 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=99
05/22/2022 05:51:45 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=99
05/22/2022 05:51:48 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=99
05/22/2022 05:52:00 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.708621107662968 on epoch=99
05/22/2022 05:52:03 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=100
05/22/2022 05:52:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=100
05/22/2022 05:52:08 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=101
05/22/2022 05:52:11 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=101
05/22/2022 05:52:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=101
05/22/2022 05:52:26 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.7456629964451155 on epoch=101
05/22/2022 05:52:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=102
05/22/2022 05:52:31 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=102
05/22/2022 05:52:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=102
05/22/2022 05:52:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=103
05/22/2022 05:52:39 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=103
05/22/2022 05:52:51 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7880592651371042 on epoch=103
05/22/2022 05:52:54 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=103
05/22/2022 05:52:57 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=104
05/22/2022 05:52:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=104
05/22/2022 05:53:02 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=104
05/22/2022 05:53:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.03 on epoch=105
05/22/2022 05:53:17 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7948542826033339 on epoch=105
05/22/2022 05:53:17 - INFO - __main__ - Saving model with best Classification-F1: 0.7940394961197836 -> 0.7948542826033339 on epoch=105, global_step=2950
05/22/2022 05:53:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 05:53:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=106
05/22/2022 05:53:25 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 05:53:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=106
05/22/2022 05:53:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=107
05/22/2022 05:53:31 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:53:31 - INFO - __main__ - Printing 3 examples
05/22/2022 05:53:31 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 05:53:31 - INFO - __main__ - ['Animal']
05/22/2022 05:53:31 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 05:53:31 - INFO - __main__ - ['Animal']
05/22/2022 05:53:31 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 05:53:31 - INFO - __main__ - ['Animal']
05/22/2022 05:53:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:53:32 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:53:32 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 05:53:32 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:53:32 - INFO - __main__ - Printing 3 examples
05/22/2022 05:53:32 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 05:53:32 - INFO - __main__ - ['Animal']
05/22/2022 05:53:32 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 05:53:32 - INFO - __main__ - ['Animal']
05/22/2022 05:53:32 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 05:53:32 - INFO - __main__ - ['Animal']
05/22/2022 05:53:32 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:53:32 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:53:33 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 05:53:42 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9073001043162333 on epoch=107
05/22/2022 05:53:42 - INFO - __main__ - Saving model with best Classification-F1: 0.7948542826033339 -> 0.9073001043162333 on epoch=107, global_step=3000
05/22/2022 05:53:42 - INFO - __main__ - save last model!
05/22/2022 05:53:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 05:53:42 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 05:53:42 - INFO - __main__ - Printing 3 examples
05/22/2022 05:53:42 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 05:53:42 - INFO - __main__ - ['Animal']
05/22/2022 05:53:42 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 05:53:42 - INFO - __main__ - ['Animal']
05/22/2022 05:53:42 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 05:53:42 - INFO - __main__ - ['Village']
05/22/2022 05:53:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:53:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:53:48 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 05:53:49 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 05:53:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 05:53:50 - INFO - __main__ - Starting training!
05/22/2022 05:56:04 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_13_0.4_8_predictions.txt
05/22/2022 05:56:04 - INFO - __main__ - Classification-F1 on test data: 0.6505
05/22/2022 05:56:05 - INFO - __main__ - prefix=dbpedia_14_32_13, lr=0.4, bsz=8, dev_performance=0.9073001043162333, test_performance=0.6505481368654062
05/22/2022 05:56:05 - INFO - __main__ - Running ... prefix=dbpedia_14_32_13, lr=0.3, bsz=8 ...
05/22/2022 05:56:06 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:56:06 - INFO - __main__ - Printing 3 examples
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:56:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:56:06 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 05:56:06 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 05:56:06 - INFO - __main__ - Printing 3 examples
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 05:56:06 - INFO - __main__ - ['Animal']
05/22/2022 05:56:06 - INFO - __main__ - Tokenizing Input ...
05/22/2022 05:56:07 - INFO - __main__ - Tokenizing Output ...
05/22/2022 05:56:07 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 05:56:23 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 05:56:24 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 05:56:24 - INFO - __main__ - Starting training!
05/22/2022 05:56:27 - INFO - __main__ - Step 10 Global step 10 Train loss 7.19 on epoch=0
05/22/2022 05:56:30 - INFO - __main__ - Step 20 Global step 20 Train loss 5.42 on epoch=0
05/22/2022 05:56:33 - INFO - __main__ - Step 30 Global step 30 Train loss 4.69 on epoch=1
05/22/2022 05:56:35 - INFO - __main__ - Step 40 Global step 40 Train loss 4.28 on epoch=1
05/22/2022 05:56:38 - INFO - __main__ - Step 50 Global step 50 Train loss 3.46 on epoch=1
05/22/2022 05:56:52 - INFO - __main__ - Global step 50 Train loss 5.01 Classification-F1 0.016312001322594544 on epoch=1
05/22/2022 05:56:52 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.016312001322594544 on epoch=1, global_step=50
05/22/2022 05:56:55 - INFO - __main__ - Step 60 Global step 60 Train loss 3.35 on epoch=2
05/22/2022 05:56:58 - INFO - __main__ - Step 70 Global step 70 Train loss 3.13 on epoch=2
05/22/2022 05:57:00 - INFO - __main__ - Step 80 Global step 80 Train loss 2.76 on epoch=2
05/22/2022 05:57:03 - INFO - __main__ - Step 90 Global step 90 Train loss 2.56 on epoch=3
05/22/2022 05:57:05 - INFO - __main__ - Step 100 Global step 100 Train loss 2.45 on epoch=3
05/22/2022 05:57:18 - INFO - __main__ - Global step 100 Train loss 2.85 Classification-F1 0.0482202687696305 on epoch=3
05/22/2022 05:57:18 - INFO - __main__ - Saving model with best Classification-F1: 0.016312001322594544 -> 0.0482202687696305 on epoch=3, global_step=100
05/22/2022 05:57:20 - INFO - __main__ - Step 110 Global step 110 Train loss 2.04 on epoch=3
05/22/2022 05:57:23 - INFO - __main__ - Step 120 Global step 120 Train loss 2.11 on epoch=4
05/22/2022 05:57:26 - INFO - __main__ - Step 130 Global step 130 Train loss 1.97 on epoch=4
05/22/2022 05:57:28 - INFO - __main__ - Step 140 Global step 140 Train loss 1.95 on epoch=4
05/22/2022 05:57:31 - INFO - __main__ - Step 150 Global step 150 Train loss 1.83 on epoch=5
05/22/2022 05:57:42 - INFO - __main__ - Global step 150 Train loss 1.98 Classification-F1 0.09373078947908572 on epoch=5
05/22/2022 05:57:42 - INFO - __main__ - Saving model with best Classification-F1: 0.0482202687696305 -> 0.09373078947908572 on epoch=5, global_step=150
05/22/2022 05:57:45 - INFO - __main__ - Step 160 Global step 160 Train loss 1.69 on epoch=5
05/22/2022 05:57:47 - INFO - __main__ - Step 170 Global step 170 Train loss 1.61 on epoch=6
05/22/2022 05:57:50 - INFO - __main__ - Step 180 Global step 180 Train loss 1.57 on epoch=6
05/22/2022 05:57:52 - INFO - __main__ - Step 190 Global step 190 Train loss 1.45 on epoch=6
05/22/2022 05:57:55 - INFO - __main__ - Step 200 Global step 200 Train loss 1.38 on epoch=7
05/22/2022 05:58:06 - INFO - __main__ - Global step 200 Train loss 1.54 Classification-F1 0.14670292474624227 on epoch=7
05/22/2022 05:58:06 - INFO - __main__ - Saving model with best Classification-F1: 0.09373078947908572 -> 0.14670292474624227 on epoch=7, global_step=200
05/22/2022 05:58:08 - INFO - __main__ - Step 210 Global step 210 Train loss 1.33 on epoch=7
05/22/2022 05:58:11 - INFO - __main__ - Step 220 Global step 220 Train loss 1.25 on epoch=7
05/22/2022 05:58:14 - INFO - __main__ - Step 230 Global step 230 Train loss 1.22 on epoch=8
05/22/2022 05:58:16 - INFO - __main__ - Step 240 Global step 240 Train loss 1.06 on epoch=8
05/22/2022 05:58:19 - INFO - __main__ - Step 250 Global step 250 Train loss 1.02 on epoch=8
05/22/2022 05:58:30 - INFO - __main__ - Global step 250 Train loss 1.18 Classification-F1 0.21636512690235027 on epoch=8
05/22/2022 05:58:30 - INFO - __main__ - Saving model with best Classification-F1: 0.14670292474624227 -> 0.21636512690235027 on epoch=8, global_step=250
05/22/2022 05:58:32 - INFO - __main__ - Step 260 Global step 260 Train loss 0.99 on epoch=9
05/22/2022 05:58:35 - INFO - __main__ - Step 270 Global step 270 Train loss 0.83 on epoch=9
05/22/2022 05:58:37 - INFO - __main__ - Step 280 Global step 280 Train loss 0.95 on epoch=9
05/22/2022 05:58:40 - INFO - __main__ - Step 290 Global step 290 Train loss 0.79 on epoch=10
05/22/2022 05:58:42 - INFO - __main__ - Step 300 Global step 300 Train loss 0.72 on epoch=10
05/22/2022 05:58:54 - INFO - __main__ - Global step 300 Train loss 0.86 Classification-F1 0.25177818740535113 on epoch=10
05/22/2022 05:58:54 - INFO - __main__ - Saving model with best Classification-F1: 0.21636512690235027 -> 0.25177818740535113 on epoch=10, global_step=300
05/22/2022 05:58:57 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=11
05/22/2022 05:58:59 - INFO - __main__ - Step 320 Global step 320 Train loss 0.67 on epoch=11
05/22/2022 05:59:02 - INFO - __main__ - Step 330 Global step 330 Train loss 0.58 on epoch=11
05/22/2022 05:59:04 - INFO - __main__ - Step 340 Global step 340 Train loss 0.53 on epoch=12
05/22/2022 05:59:07 - INFO - __main__ - Step 350 Global step 350 Train loss 0.56 on epoch=12
05/22/2022 05:59:18 - INFO - __main__ - Global step 350 Train loss 0.61 Classification-F1 0.33782511605161514 on epoch=12
05/22/2022 05:59:18 - INFO - __main__ - Saving model with best Classification-F1: 0.25177818740535113 -> 0.33782511605161514 on epoch=12, global_step=350
05/22/2022 05:59:21 - INFO - __main__ - Step 360 Global step 360 Train loss 0.58 on epoch=12
05/22/2022 05:59:24 - INFO - __main__ - Step 370 Global step 370 Train loss 0.50 on epoch=13
05/22/2022 05:59:26 - INFO - __main__ - Step 380 Global step 380 Train loss 0.58 on epoch=13
05/22/2022 05:59:29 - INFO - __main__ - Step 390 Global step 390 Train loss 0.55 on epoch=13
05/22/2022 05:59:31 - INFO - __main__ - Step 400 Global step 400 Train loss 0.50 on epoch=14
05/22/2022 05:59:44 - INFO - __main__ - Global step 400 Train loss 0.54 Classification-F1 0.4287806612330708 on epoch=14
05/22/2022 05:59:44 - INFO - __main__ - Saving model with best Classification-F1: 0.33782511605161514 -> 0.4287806612330708 on epoch=14, global_step=400
05/22/2022 05:59:47 - INFO - __main__ - Step 410 Global step 410 Train loss 0.50 on epoch=14
05/22/2022 05:59:49 - INFO - __main__ - Step 420 Global step 420 Train loss 0.46 on epoch=14
05/22/2022 05:59:52 - INFO - __main__ - Step 430 Global step 430 Train loss 0.48 on epoch=15
05/22/2022 05:59:54 - INFO - __main__ - Step 440 Global step 440 Train loss 0.40 on epoch=15
05/22/2022 05:59:57 - INFO - __main__ - Step 450 Global step 450 Train loss 0.49 on epoch=16
05/22/2022 06:00:10 - INFO - __main__ - Global step 450 Train loss 0.47 Classification-F1 0.4180775950772839 on epoch=16
05/22/2022 06:00:12 - INFO - __main__ - Step 460 Global step 460 Train loss 0.34 on epoch=16
05/22/2022 06:00:15 - INFO - __main__ - Step 470 Global step 470 Train loss 0.39 on epoch=16
05/22/2022 06:00:17 - INFO - __main__ - Step 480 Global step 480 Train loss 0.47 on epoch=17
05/22/2022 06:00:20 - INFO - __main__ - Step 490 Global step 490 Train loss 0.36 on epoch=17
05/22/2022 06:00:23 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=17
05/22/2022 06:00:35 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.43404226459817147 on epoch=17
05/22/2022 06:00:35 - INFO - __main__ - Saving model with best Classification-F1: 0.4287806612330708 -> 0.43404226459817147 on epoch=17, global_step=500
05/22/2022 06:00:38 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=18
05/22/2022 06:00:41 - INFO - __main__ - Step 520 Global step 520 Train loss 0.37 on epoch=18
05/22/2022 06:00:43 - INFO - __main__ - Step 530 Global step 530 Train loss 0.35 on epoch=18
05/22/2022 06:00:46 - INFO - __main__ - Step 540 Global step 540 Train loss 0.36 on epoch=19
05/22/2022 06:00:48 - INFO - __main__ - Step 550 Global step 550 Train loss 0.24 on epoch=19
05/22/2022 06:01:01 - INFO - __main__ - Global step 550 Train loss 0.32 Classification-F1 0.484969301057675 on epoch=19
05/22/2022 06:01:01 - INFO - __main__ - Saving model with best Classification-F1: 0.43404226459817147 -> 0.484969301057675 on epoch=19, global_step=550
05/22/2022 06:01:04 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=19
05/22/2022 06:01:06 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=20
05/22/2022 06:01:09 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=20
05/22/2022 06:01:11 - INFO - __main__ - Step 590 Global step 590 Train loss 0.33 on epoch=21
05/22/2022 06:01:14 - INFO - __main__ - Step 600 Global step 600 Train loss 0.25 on epoch=21
05/22/2022 06:01:26 - INFO - __main__ - Global step 600 Train loss 0.25 Classification-F1 0.4859002946214321 on epoch=21
05/22/2022 06:01:26 - INFO - __main__ - Saving model with best Classification-F1: 0.484969301057675 -> 0.4859002946214321 on epoch=21, global_step=600
05/22/2022 06:01:29 - INFO - __main__ - Step 610 Global step 610 Train loss 0.29 on epoch=21
05/22/2022 06:01:32 - INFO - __main__ - Step 620 Global step 620 Train loss 0.23 on epoch=22
05/22/2022 06:01:34 - INFO - __main__ - Step 630 Global step 630 Train loss 0.22 on epoch=22
05/22/2022 06:01:37 - INFO - __main__ - Step 640 Global step 640 Train loss 0.25 on epoch=22
05/22/2022 06:01:39 - INFO - __main__ - Step 650 Global step 650 Train loss 0.26 on epoch=23
05/22/2022 06:01:52 - INFO - __main__ - Global step 650 Train loss 0.25 Classification-F1 0.540417857317341 on epoch=23
05/22/2022 06:01:52 - INFO - __main__ - Saving model with best Classification-F1: 0.4859002946214321 -> 0.540417857317341 on epoch=23, global_step=650
05/22/2022 06:01:55 - INFO - __main__ - Step 660 Global step 660 Train loss 0.32 on epoch=23
05/22/2022 06:01:58 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=23
05/22/2022 06:02:00 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=24
05/22/2022 06:02:03 - INFO - __main__ - Step 690 Global step 690 Train loss 0.21 on epoch=24
05/22/2022 06:02:05 - INFO - __main__ - Step 700 Global step 700 Train loss 0.24 on epoch=24
05/22/2022 06:02:18 - INFO - __main__ - Global step 700 Train loss 0.25 Classification-F1 0.5493738117452202 on epoch=24
05/22/2022 06:02:18 - INFO - __main__ - Saving model with best Classification-F1: 0.540417857317341 -> 0.5493738117452202 on epoch=24, global_step=700
05/22/2022 06:02:21 - INFO - __main__ - Step 710 Global step 710 Train loss 0.14 on epoch=25
05/22/2022 06:02:23 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=25
05/22/2022 06:02:26 - INFO - __main__ - Step 730 Global step 730 Train loss 0.25 on epoch=26
05/22/2022 06:02:28 - INFO - __main__ - Step 740 Global step 740 Train loss 0.17 on epoch=26
05/22/2022 06:02:31 - INFO - __main__ - Step 750 Global step 750 Train loss 0.20 on epoch=26
05/22/2022 06:02:44 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.6453115625598604 on epoch=26
05/22/2022 06:02:44 - INFO - __main__ - Saving model with best Classification-F1: 0.5493738117452202 -> 0.6453115625598604 on epoch=26, global_step=750
05/22/2022 06:02:46 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=27
05/22/2022 06:02:49 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=27
05/22/2022 06:02:51 - INFO - __main__ - Step 780 Global step 780 Train loss 0.15 on epoch=27
05/22/2022 06:02:54 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=28
05/22/2022 06:02:56 - INFO - __main__ - Step 800 Global step 800 Train loss 0.24 on epoch=28
05/22/2022 06:03:09 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.5806070427393957 on epoch=28
05/22/2022 06:03:11 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=28
05/22/2022 06:03:14 - INFO - __main__ - Step 820 Global step 820 Train loss 0.22 on epoch=29
05/22/2022 06:03:16 - INFO - __main__ - Step 830 Global step 830 Train loss 0.21 on epoch=29
05/22/2022 06:03:19 - INFO - __main__ - Step 840 Global step 840 Train loss 0.21 on epoch=29
05/22/2022 06:03:21 - INFO - __main__ - Step 850 Global step 850 Train loss 0.15 on epoch=30
05/22/2022 06:03:34 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6067108405645492 on epoch=30
05/22/2022 06:03:37 - INFO - __main__ - Step 860 Global step 860 Train loss 0.16 on epoch=30
05/22/2022 06:03:39 - INFO - __main__ - Step 870 Global step 870 Train loss 0.17 on epoch=31
05/22/2022 06:03:42 - INFO - __main__ - Step 880 Global step 880 Train loss 0.22 on epoch=31
05/22/2022 06:03:44 - INFO - __main__ - Step 890 Global step 890 Train loss 0.24 on epoch=31
05/22/2022 06:03:47 - INFO - __main__ - Step 900 Global step 900 Train loss 0.18 on epoch=32
05/22/2022 06:03:59 - INFO - __main__ - Global step 900 Train loss 0.19 Classification-F1 0.4972648728449145 on epoch=32
05/22/2022 06:04:02 - INFO - __main__ - Step 910 Global step 910 Train loss 0.12 on epoch=32
05/22/2022 06:04:04 - INFO - __main__ - Step 920 Global step 920 Train loss 0.20 on epoch=32
05/22/2022 06:04:07 - INFO - __main__ - Step 930 Global step 930 Train loss 0.14 on epoch=33
05/22/2022 06:04:10 - INFO - __main__ - Step 940 Global step 940 Train loss 0.19 on epoch=33
05/22/2022 06:04:12 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=33
05/22/2022 06:04:24 - INFO - __main__ - Global step 950 Train loss 0.17 Classification-F1 0.5444968643110015 on epoch=33
05/22/2022 06:04:27 - INFO - __main__ - Step 960 Global step 960 Train loss 0.15 on epoch=34
05/22/2022 06:04:29 - INFO - __main__ - Step 970 Global step 970 Train loss 0.10 on epoch=34
05/22/2022 06:04:32 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=34
05/22/2022 06:04:34 - INFO - __main__ - Step 990 Global step 990 Train loss 0.13 on epoch=35
05/22/2022 06:04:37 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.14 on epoch=35
05/22/2022 06:04:49 - INFO - __main__ - Global step 1000 Train loss 0.13 Classification-F1 0.5789413389865206 on epoch=35
05/22/2022 06:04:52 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.17 on epoch=36
05/22/2022 06:04:54 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.18 on epoch=36
05/22/2022 06:04:57 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=36
05/22/2022 06:05:00 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=37
05/22/2022 06:05:02 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.13 on epoch=37
05/22/2022 06:05:14 - INFO - __main__ - Global step 1050 Train loss 0.15 Classification-F1 0.6365331442193382 on epoch=37
05/22/2022 06:05:17 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.16 on epoch=37
05/22/2022 06:05:20 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=38
05/22/2022 06:05:22 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.14 on epoch=38
05/22/2022 06:05:25 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=38
05/22/2022 06:05:27 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=39
05/22/2022 06:05:40 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.6529857842169957 on epoch=39
05/22/2022 06:05:40 - INFO - __main__ - Saving model with best Classification-F1: 0.6453115625598604 -> 0.6529857842169957 on epoch=39, global_step=1100
05/22/2022 06:05:43 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=39
05/22/2022 06:05:45 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.14 on epoch=39
05/22/2022 06:05:48 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=40
05/22/2022 06:05:50 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=40
05/22/2022 06:05:53 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.13 on epoch=41
05/22/2022 06:06:05 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.6108787617611147 on epoch=41
05/22/2022 06:06:08 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=41
05/22/2022 06:06:10 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.10 on epoch=41
05/22/2022 06:06:13 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.10 on epoch=42
05/22/2022 06:06:16 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=42
05/22/2022 06:06:18 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.13 on epoch=42
05/22/2022 06:06:31 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.6590767677454984 on epoch=42
05/22/2022 06:06:31 - INFO - __main__ - Saving model with best Classification-F1: 0.6529857842169957 -> 0.6590767677454984 on epoch=42, global_step=1200
05/22/2022 06:06:33 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=43
05/22/2022 06:06:36 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.11 on epoch=43
05/22/2022 06:06:38 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=43
05/22/2022 06:06:41 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.06 on epoch=44
05/22/2022 06:06:44 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=44
05/22/2022 06:06:56 - INFO - __main__ - Global step 1250 Train loss 0.09 Classification-F1 0.648063426801327 on epoch=44
05/22/2022 06:06:59 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.13 on epoch=44
05/22/2022 06:07:01 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=45
05/22/2022 06:07:04 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=45
05/22/2022 06:07:06 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.10 on epoch=46
05/22/2022 06:07:09 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.12 on epoch=46
05/22/2022 06:07:22 - INFO - __main__ - Global step 1300 Train loss 0.11 Classification-F1 0.6548514437305076 on epoch=46
05/22/2022 06:07:25 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.09 on epoch=46
05/22/2022 06:07:27 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=47
05/22/2022 06:07:30 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.08 on epoch=47
05/22/2022 06:07:32 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.13 on epoch=47
05/22/2022 06:07:35 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.09 on epoch=48
05/22/2022 06:07:47 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6454255928035026 on epoch=48
05/22/2022 06:07:50 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=48
05/22/2022 06:07:52 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.12 on epoch=48
05/22/2022 06:07:55 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=49
05/22/2022 06:07:57 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.09 on epoch=49
05/22/2022 06:08:00 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.12 on epoch=49
05/22/2022 06:08:12 - INFO - __main__ - Global step 1400 Train loss 0.11 Classification-F1 0.6464914813068464 on epoch=49
05/22/2022 06:08:15 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.10 on epoch=50
05/22/2022 06:08:18 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=50
05/22/2022 06:08:20 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.14 on epoch=51
05/22/2022 06:08:23 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=51
05/22/2022 06:08:25 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.11 on epoch=51
05/22/2022 06:08:38 - INFO - __main__ - Global step 1450 Train loss 0.10 Classification-F1 0.7091886838952567 on epoch=51
05/22/2022 06:08:38 - INFO - __main__ - Saving model with best Classification-F1: 0.6590767677454984 -> 0.7091886838952567 on epoch=51, global_step=1450
05/22/2022 06:08:40 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=52
05/22/2022 06:08:43 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.09 on epoch=52
05/22/2022 06:08:46 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.06 on epoch=52
05/22/2022 06:08:48 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=53
05/22/2022 06:08:51 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=53
05/22/2022 06:09:03 - INFO - __main__ - Global step 1500 Train loss 0.09 Classification-F1 0.6536836611386339 on epoch=53
05/22/2022 06:09:06 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.09 on epoch=53
05/22/2022 06:09:09 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.12 on epoch=54
05/22/2022 06:09:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=54
05/22/2022 06:09:14 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=54
05/22/2022 06:09:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=55
05/22/2022 06:09:29 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.6480785319695997 on epoch=55
05/22/2022 06:09:31 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=55
05/22/2022 06:09:34 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=56
05/22/2022 06:09:36 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.07 on epoch=56
05/22/2022 06:09:39 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=56
05/22/2022 06:09:42 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=57
05/22/2022 06:09:54 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.6532339661438454 on epoch=57
05/22/2022 06:09:57 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=57
05/22/2022 06:09:59 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=57
05/22/2022 06:10:02 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=58
05/22/2022 06:10:04 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=58
05/22/2022 06:10:07 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=58
05/22/2022 06:10:20 - INFO - __main__ - Global step 1650 Train loss 0.09 Classification-F1 0.6465502202974739 on epoch=58
05/22/2022 06:10:22 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=59
05/22/2022 06:10:25 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=59
05/22/2022 06:10:28 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=59
05/22/2022 06:10:30 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=60
05/22/2022 06:10:33 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=60
05/22/2022 06:10:46 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.5996422260040803 on epoch=60
05/22/2022 06:10:49 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.08 on epoch=61
05/22/2022 06:10:51 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=61
05/22/2022 06:10:54 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=61
05/22/2022 06:10:56 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=62
05/22/2022 06:10:59 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=62
05/22/2022 06:11:11 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.5925958941387887 on epoch=62
05/22/2022 06:11:14 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=62
05/22/2022 06:11:16 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=63
05/22/2022 06:11:19 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=63
05/22/2022 06:11:22 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=63
05/22/2022 06:11:24 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.08 on epoch=64
05/22/2022 06:11:36 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.590049131040791 on epoch=64
05/22/2022 06:11:39 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=64
05/22/2022 06:11:41 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=64
05/22/2022 06:11:44 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=65
05/22/2022 06:11:47 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 06:11:49 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=66
05/22/2022 06:12:01 - INFO - __main__ - Global step 1850 Train loss 0.07 Classification-F1 0.5869158152649968 on epoch=66
05/22/2022 06:12:04 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=66
05/22/2022 06:12:06 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=66
05/22/2022 06:12:09 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.13 on epoch=67
05/22/2022 06:12:12 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.06 on epoch=67
05/22/2022 06:12:14 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=67
05/22/2022 06:12:26 - INFO - __main__ - Global step 1900 Train loss 0.08 Classification-F1 0.5719917986247292 on epoch=67
05/22/2022 06:12:28 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=68
05/22/2022 06:12:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.06 on epoch=68
05/22/2022 06:12:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=68
05/22/2022 06:12:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=69
05/22/2022 06:12:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.08 on epoch=69
05/22/2022 06:12:51 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.5842082109536814 on epoch=69
05/22/2022 06:12:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.10 on epoch=69
05/22/2022 06:12:56 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=70
05/22/2022 06:12:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=70
05/22/2022 06:13:01 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.08 on epoch=71
05/22/2022 06:13:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=71
05/22/2022 06:13:16 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6440781651562953 on epoch=71
05/22/2022 06:13:18 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=71
05/22/2022 06:13:21 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=72
05/22/2022 06:13:23 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=72
05/22/2022 06:13:26 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.09 on epoch=72
05/22/2022 06:13:28 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.04 on epoch=73
05/22/2022 06:13:40 - INFO - __main__ - Global step 2050 Train loss 0.06 Classification-F1 0.5630221910664562 on epoch=73
05/22/2022 06:13:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=73
05/22/2022 06:13:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.04 on epoch=73
05/22/2022 06:13:48 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.03 on epoch=74
05/22/2022 06:13:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=74
05/22/2022 06:13:53 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=74
05/22/2022 06:14:05 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6922274930235963 on epoch=74
05/22/2022 06:14:08 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=75
05/22/2022 06:14:10 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=75
05/22/2022 06:14:13 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.05 on epoch=76
05/22/2022 06:14:16 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=76
05/22/2022 06:14:18 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=76
05/22/2022 06:14:30 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6403976566463326 on epoch=76
05/22/2022 06:14:33 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=77
05/22/2022 06:14:35 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=77
05/22/2022 06:14:38 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.08 on epoch=77
05/22/2022 06:14:40 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.04 on epoch=78
05/22/2022 06:14:43 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.04 on epoch=78
05/22/2022 06:14:55 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.6196181920750501 on epoch=78
05/22/2022 06:14:57 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=78
05/22/2022 06:15:00 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.04 on epoch=79
05/22/2022 06:15:03 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=79
05/22/2022 06:15:05 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=79
05/22/2022 06:15:08 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=80
05/22/2022 06:15:20 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6140630865817434 on epoch=80
05/22/2022 06:15:22 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=80
05/22/2022 06:15:25 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.04 on epoch=81
05/22/2022 06:15:27 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=81
05/22/2022 06:15:30 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=81
05/22/2022 06:15:33 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=82
05/22/2022 06:15:45 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7528981032284014 on epoch=82
05/22/2022 06:15:45 - INFO - __main__ - Saving model with best Classification-F1: 0.7091886838952567 -> 0.7528981032284014 on epoch=82, global_step=2300
05/22/2022 06:15:47 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=82
05/22/2022 06:15:50 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.05 on epoch=82
05/22/2022 06:15:53 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=83
05/22/2022 06:15:55 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=83
05/22/2022 06:15:58 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.09 on epoch=83
05/22/2022 06:16:10 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.673343292781955 on epoch=83
05/22/2022 06:16:12 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.13 on epoch=84
05/22/2022 06:16:15 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=84
05/22/2022 06:16:17 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=84
05/22/2022 06:16:20 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=85
05/22/2022 06:16:23 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=85
05/22/2022 06:16:34 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6347010876935347 on epoch=85
05/22/2022 06:16:37 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=86
05/22/2022 06:16:40 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 06:16:42 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=86
05/22/2022 06:16:45 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=87
05/22/2022 06:16:47 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=87
05/22/2022 06:16:59 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.5755208988411996 on epoch=87
05/22/2022 06:17:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=87
05/22/2022 06:17:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=88
05/22/2022 06:17:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 06:17:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=88
05/22/2022 06:17:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=89
05/22/2022 06:17:24 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.6024205928397561 on epoch=89
05/22/2022 06:17:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=89
05/22/2022 06:17:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 06:17:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=90
05/22/2022 06:17:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=90
05/22/2022 06:17:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=91
05/22/2022 06:17:49 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.5785122676566331 on epoch=91
05/22/2022 06:17:51 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=91
05/22/2022 06:17:54 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 06:17:57 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=92
05/22/2022 06:17:59 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=92
05/22/2022 06:18:02 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=92
05/22/2022 06:18:14 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7343487344792312 on epoch=92
05/22/2022 06:18:16 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.07 on epoch=93
05/22/2022 06:18:19 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=93
05/22/2022 06:18:21 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=93
05/22/2022 06:18:24 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 06:18:27 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=94
05/22/2022 06:18:39 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.6463412993337464 on epoch=94
05/22/2022 06:18:41 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=94
05/22/2022 06:18:44 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=95
05/22/2022 06:18:46 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.06 on epoch=95
05/22/2022 06:18:49 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=96
05/22/2022 06:18:52 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=96
05/22/2022 06:19:04 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.5956538182046969 on epoch=96
05/22/2022 06:19:06 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=96
05/22/2022 06:19:09 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=97
05/22/2022 06:19:11 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=97
05/22/2022 06:19:14 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=97
05/22/2022 06:19:17 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=98
05/22/2022 06:19:28 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.6118654893806991 on epoch=98
05/22/2022 06:19:31 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=98
05/22/2022 06:19:34 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=98
05/22/2022 06:19:36 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=99
05/22/2022 06:19:39 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.03 on epoch=99
05/22/2022 06:19:41 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=99
05/22/2022 06:19:53 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6368418982718453 on epoch=99
05/22/2022 06:19:56 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=100
05/22/2022 06:19:58 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=100
05/22/2022 06:20:01 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.06 on epoch=101
05/22/2022 06:20:04 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=101
05/22/2022 06:20:06 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=101
05/22/2022 06:20:18 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.6491294224237762 on epoch=101
05/22/2022 06:20:21 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=102
05/22/2022 06:20:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=102
05/22/2022 06:20:26 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.04 on epoch=102
05/22/2022 06:20:29 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=103
05/22/2022 06:20:31 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=103
05/22/2022 06:20:43 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.6333495224098146 on epoch=103
05/22/2022 06:20:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=103
05/22/2022 06:20:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=104
05/22/2022 06:20:51 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=104
05/22/2022 06:20:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=104
05/22/2022 06:20:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=105
05/22/2022 06:21:08 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.5261782154746767 on epoch=105
05/22/2022 06:21:11 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=105
05/22/2022 06:21:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=106
05/22/2022 06:21:16 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 06:21:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=106
05/22/2022 06:21:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=107
05/22/2022 06:21:22 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:21:22 - INFO - __main__ - Printing 3 examples
05/22/2022 06:21:22 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 06:21:22 - INFO - __main__ - ['Animal']
05/22/2022 06:21:22 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 06:21:22 - INFO - __main__ - ['Animal']
05/22/2022 06:21:22 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 06:21:22 - INFO - __main__ - ['Animal']
05/22/2022 06:21:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:21:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:21:23 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 06:21:23 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:21:23 - INFO - __main__ - Printing 3 examples
05/22/2022 06:21:23 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 06:21:23 - INFO - __main__ - ['Animal']
05/22/2022 06:21:23 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 06:21:23 - INFO - __main__ - ['Animal']
05/22/2022 06:21:23 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 06:21:23 - INFO - __main__ - ['Animal']
05/22/2022 06:21:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:21:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:21:24 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 06:21:33 - INFO - __main__ - Global step 3000 Train loss 0.03 Classification-F1 0.6511966322042934 on epoch=107
05/22/2022 06:21:33 - INFO - __main__ - save last model!
05/22/2022 06:21:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 06:21:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 06:21:33 - INFO - __main__ - Printing 3 examples
05/22/2022 06:21:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 06:21:33 - INFO - __main__ - ['Animal']
05/22/2022 06:21:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 06:21:33 - INFO - __main__ - ['Animal']
05/22/2022 06:21:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 06:21:33 - INFO - __main__ - ['Village']
05/22/2022 06:21:33 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:21:35 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:21:38 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 06:21:42 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 06:21:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 06:21:43 - INFO - __main__ - Starting training!
05/22/2022 06:23:39 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_13_0.3_8_predictions.txt
05/22/2022 06:23:39 - INFO - __main__ - Classification-F1 on test data: 0.4889
05/22/2022 06:23:40 - INFO - __main__ - prefix=dbpedia_14_32_13, lr=0.3, bsz=8, dev_performance=0.7528981032284014, test_performance=0.48890628028274424
05/22/2022 06:23:40 - INFO - __main__ - Running ... prefix=dbpedia_14_32_13, lr=0.2, bsz=8 ...
05/22/2022 06:23:41 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:23:41 - INFO - __main__ - Printing 3 examples
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] Malkaridae is a small spider family with ten species in four genera.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] The Dahl's toad-headed turtle (Mesoclemmys dahli) is a species of turtle in the Chelidae family.It is endemic to Colombia.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] The Tersa Sphinx (Xylophanes tersa) is a moth of the Sphingidae family. It is found from the United States (Massachusetts south to southern Florida west to Nebraska New Mexico and southern Arizona) through Mexico the West Indies and Central America and into parts of South America (including Bolivia Paraguay Argentina and Brazil). An occasional stray can be found as far north as Canada.The wingspan is 60–80 mm.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:23:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:23:41 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 06:23:41 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:23:41 - INFO - __main__ - Printing 3 examples
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] The pygmy rabbit (Brachylagus idahoensis) is a North American rabbit and is one of only two rabbit species in America to dig its own burrow. The pygmy rabbit differs significantly from species within either the Lepus (hare) or Sylvilagus (cottontail) genera and is generally considered to be within the monotypic genus Brachylagus. One isolated population the Columbia Basin Pygmy Rabbit is listed as an endangered species by the U.S.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] Holoterpna is a genus of moth in the family Geometridae.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ -  [dbpedia_14] The Malabar gliding frog or Malabar flying frog (Rhacophorus malabaricus) is a moss frog species found in the Western Ghats of India.
05/22/2022 06:23:41 - INFO - __main__ - ['Animal']
05/22/2022 06:23:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:23:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:23:42 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 06:24:00 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 06:24:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 06:24:01 - INFO - __main__ - Starting training!
05/22/2022 06:24:04 - INFO - __main__ - Step 10 Global step 10 Train loss 7.80 on epoch=0
05/22/2022 06:24:07 - INFO - __main__ - Step 20 Global step 20 Train loss 5.67 on epoch=0
05/22/2022 06:24:10 - INFO - __main__ - Step 30 Global step 30 Train loss 5.19 on epoch=1
05/22/2022 06:24:12 - INFO - __main__ - Step 40 Global step 40 Train loss 4.70 on epoch=1
05/22/2022 06:24:15 - INFO - __main__ - Step 50 Global step 50 Train loss 4.13 on epoch=1
05/22/2022 06:24:26 - INFO - __main__ - Global step 50 Train loss 5.50 Classification-F1 0.02344788360821562 on epoch=1
05/22/2022 06:24:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02344788360821562 on epoch=1, global_step=50
05/22/2022 06:24:29 - INFO - __main__ - Step 60 Global step 60 Train loss 3.98 on epoch=2
05/22/2022 06:24:31 - INFO - __main__ - Step 70 Global step 70 Train loss 3.78 on epoch=2
05/22/2022 06:24:34 - INFO - __main__ - Step 80 Global step 80 Train loss 3.45 on epoch=2
05/22/2022 06:24:36 - INFO - __main__ - Step 90 Global step 90 Train loss 3.30 on epoch=3
05/22/2022 06:24:39 - INFO - __main__ - Step 100 Global step 100 Train loss 2.97 on epoch=3
05/22/2022 06:24:52 - INFO - __main__ - Global step 100 Train loss 3.50 Classification-F1 0.028303552603837236 on epoch=3
05/22/2022 06:24:52 - INFO - __main__ - Saving model with best Classification-F1: 0.02344788360821562 -> 0.028303552603837236 on epoch=3, global_step=100
05/22/2022 06:24:55 - INFO - __main__ - Step 110 Global step 110 Train loss 2.76 on epoch=3
05/22/2022 06:24:57 - INFO - __main__ - Step 120 Global step 120 Train loss 2.71 on epoch=4
05/22/2022 06:25:00 - INFO - __main__ - Step 130 Global step 130 Train loss 2.42 on epoch=4
05/22/2022 06:25:02 - INFO - __main__ - Step 140 Global step 140 Train loss 2.42 on epoch=4
05/22/2022 06:25:05 - INFO - __main__ - Step 150 Global step 150 Train loss 2.41 on epoch=5
05/22/2022 06:25:17 - INFO - __main__ - Global step 150 Train loss 2.54 Classification-F1 0.04680933460298569 on epoch=5
05/22/2022 06:25:17 - INFO - __main__ - Saving model with best Classification-F1: 0.028303552603837236 -> 0.04680933460298569 on epoch=5, global_step=150
05/22/2022 06:25:20 - INFO - __main__ - Step 160 Global step 160 Train loss 2.13 on epoch=5
05/22/2022 06:25:23 - INFO - __main__ - Step 170 Global step 170 Train loss 2.20 on epoch=6
05/22/2022 06:25:25 - INFO - __main__ - Step 180 Global step 180 Train loss 2.15 on epoch=6
05/22/2022 06:25:28 - INFO - __main__ - Step 190 Global step 190 Train loss 1.99 on epoch=6
05/22/2022 06:25:30 - INFO - __main__ - Step 200 Global step 200 Train loss 1.97 on epoch=7
05/22/2022 06:25:42 - INFO - __main__ - Global step 200 Train loss 2.09 Classification-F1 0.06762038812141272 on epoch=7
05/22/2022 06:25:42 - INFO - __main__ - Saving model with best Classification-F1: 0.04680933460298569 -> 0.06762038812141272 on epoch=7, global_step=200
05/22/2022 06:25:44 - INFO - __main__ - Step 210 Global step 210 Train loss 2.08 on epoch=7
05/22/2022 06:25:47 - INFO - __main__ - Step 220 Global step 220 Train loss 1.72 on epoch=7
05/22/2022 06:25:49 - INFO - __main__ - Step 230 Global step 230 Train loss 1.70 on epoch=8
05/22/2022 06:25:52 - INFO - __main__ - Step 240 Global step 240 Train loss 1.77 on epoch=8
05/22/2022 06:25:55 - INFO - __main__ - Step 250 Global step 250 Train loss 1.52 on epoch=8
05/22/2022 06:26:05 - INFO - __main__ - Global step 250 Train loss 1.76 Classification-F1 0.10560010170250134 on epoch=8
05/22/2022 06:26:05 - INFO - __main__ - Saving model with best Classification-F1: 0.06762038812141272 -> 0.10560010170250134 on epoch=8, global_step=250
05/22/2022 06:26:08 - INFO - __main__ - Step 260 Global step 260 Train loss 1.62 on epoch=9
05/22/2022 06:26:10 - INFO - __main__ - Step 270 Global step 270 Train loss 1.61 on epoch=9
05/22/2022 06:26:13 - INFO - __main__ - Step 280 Global step 280 Train loss 1.49 on epoch=9
05/22/2022 06:26:16 - INFO - __main__ - Step 290 Global step 290 Train loss 1.32 on epoch=10
05/22/2022 06:26:18 - INFO - __main__ - Step 300 Global step 300 Train loss 1.31 on epoch=10
05/22/2022 06:26:29 - INFO - __main__ - Global step 300 Train loss 1.47 Classification-F1 0.15274778060039534 on epoch=10
05/22/2022 06:26:29 - INFO - __main__ - Saving model with best Classification-F1: 0.10560010170250134 -> 0.15274778060039534 on epoch=10, global_step=300
05/22/2022 06:26:32 - INFO - __main__ - Step 310 Global step 310 Train loss 1.36 on epoch=11
05/22/2022 06:26:34 - INFO - __main__ - Step 320 Global step 320 Train loss 1.23 on epoch=11
05/22/2022 06:26:37 - INFO - __main__ - Step 330 Global step 330 Train loss 1.15 on epoch=11
05/22/2022 06:26:39 - INFO - __main__ - Step 340 Global step 340 Train loss 1.15 on epoch=12
05/22/2022 06:26:42 - INFO - __main__ - Step 350 Global step 350 Train loss 1.19 on epoch=12
05/22/2022 06:26:53 - INFO - __main__ - Global step 350 Train loss 1.22 Classification-F1 0.22192871037529532 on epoch=12
05/22/2022 06:26:53 - INFO - __main__ - Saving model with best Classification-F1: 0.15274778060039534 -> 0.22192871037529532 on epoch=12, global_step=350
05/22/2022 06:26:56 - INFO - __main__ - Step 360 Global step 360 Train loss 1.06 on epoch=12
05/22/2022 06:26:58 - INFO - __main__ - Step 370 Global step 370 Train loss 0.96 on epoch=13
05/22/2022 06:27:01 - INFO - __main__ - Step 380 Global step 380 Train loss 1.05 on epoch=13
05/22/2022 06:27:03 - INFO - __main__ - Step 390 Global step 390 Train loss 0.83 on epoch=13
05/22/2022 06:27:06 - INFO - __main__ - Step 400 Global step 400 Train loss 1.02 on epoch=14
05/22/2022 06:27:17 - INFO - __main__ - Global step 400 Train loss 0.98 Classification-F1 0.2820868965049436 on epoch=14
05/22/2022 06:27:17 - INFO - __main__ - Saving model with best Classification-F1: 0.22192871037529532 -> 0.2820868965049436 on epoch=14, global_step=400
05/22/2022 06:27:20 - INFO - __main__ - Step 410 Global step 410 Train loss 0.95 on epoch=14
05/22/2022 06:27:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.89 on epoch=14
05/22/2022 06:27:25 - INFO - __main__ - Step 430 Global step 430 Train loss 0.80 on epoch=15
05/22/2022 06:27:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.77 on epoch=15
05/22/2022 06:27:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=16
05/22/2022 06:27:41 - INFO - __main__ - Global step 450 Train loss 0.83 Classification-F1 0.28047770091238505 on epoch=16
05/22/2022 06:27:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.76 on epoch=16
05/22/2022 06:27:47 - INFO - __main__ - Step 470 Global step 470 Train loss 0.65 on epoch=16
05/22/2022 06:27:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.57 on epoch=17
05/22/2022 06:27:52 - INFO - __main__ - Step 490 Global step 490 Train loss 0.65 on epoch=17
05/22/2022 06:27:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.61 on epoch=17
05/22/2022 06:28:06 - INFO - __main__ - Global step 500 Train loss 0.65 Classification-F1 0.37640303693223337 on epoch=17
05/22/2022 06:28:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2820868965049436 -> 0.37640303693223337 on epoch=17, global_step=500
05/22/2022 06:28:09 - INFO - __main__ - Step 510 Global step 510 Train loss 0.58 on epoch=18
05/22/2022 06:28:12 - INFO - __main__ - Step 520 Global step 520 Train loss 0.56 on epoch=18
05/22/2022 06:28:14 - INFO - __main__ - Step 530 Global step 530 Train loss 0.57 on epoch=18
05/22/2022 06:28:17 - INFO - __main__ - Step 540 Global step 540 Train loss 0.52 on epoch=19
05/22/2022 06:28:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=19
05/22/2022 06:28:32 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.4409349901183517 on epoch=19
05/22/2022 06:28:32 - INFO - __main__ - Saving model with best Classification-F1: 0.37640303693223337 -> 0.4409349901183517 on epoch=19, global_step=550
05/22/2022 06:28:34 - INFO - __main__ - Step 560 Global step 560 Train loss 0.52 on epoch=19
05/22/2022 06:28:37 - INFO - __main__ - Step 570 Global step 570 Train loss 0.54 on epoch=20
05/22/2022 06:28:40 - INFO - __main__ - Step 580 Global step 580 Train loss 0.47 on epoch=20
05/22/2022 06:28:42 - INFO - __main__ - Step 590 Global step 590 Train loss 0.50 on epoch=21
05/22/2022 06:28:45 - INFO - __main__ - Step 600 Global step 600 Train loss 0.40 on epoch=21
05/22/2022 06:28:57 - INFO - __main__ - Global step 600 Train loss 0.49 Classification-F1 0.4686468173260127 on epoch=21
05/22/2022 06:28:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4409349901183517 -> 0.4686468173260127 on epoch=21, global_step=600
05/22/2022 06:29:00 - INFO - __main__ - Step 610 Global step 610 Train loss 0.44 on epoch=21
05/22/2022 06:29:03 - INFO - __main__ - Step 620 Global step 620 Train loss 0.55 on epoch=22
05/22/2022 06:29:05 - INFO - __main__ - Step 630 Global step 630 Train loss 0.45 on epoch=22
05/22/2022 06:29:08 - INFO - __main__ - Step 640 Global step 640 Train loss 0.41 on epoch=22
05/22/2022 06:29:11 - INFO - __main__ - Step 650 Global step 650 Train loss 0.50 on epoch=23
05/22/2022 06:29:23 - INFO - __main__ - Global step 650 Train loss 0.47 Classification-F1 0.4925290485494542 on epoch=23
05/22/2022 06:29:23 - INFO - __main__ - Saving model with best Classification-F1: 0.4686468173260127 -> 0.4925290485494542 on epoch=23, global_step=650
05/22/2022 06:29:26 - INFO - __main__ - Step 660 Global step 660 Train loss 0.43 on epoch=23
05/22/2022 06:29:29 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=23
05/22/2022 06:29:31 - INFO - __main__ - Step 680 Global step 680 Train loss 0.40 on epoch=24
05/22/2022 06:29:34 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=24
05/22/2022 06:29:36 - INFO - __main__ - Step 700 Global step 700 Train loss 0.35 on epoch=24
05/22/2022 06:29:49 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.45912119277038066 on epoch=24
05/22/2022 06:29:52 - INFO - __main__ - Step 710 Global step 710 Train loss 0.33 on epoch=25
05/22/2022 06:29:54 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=25
05/22/2022 06:29:57 - INFO - __main__ - Step 730 Global step 730 Train loss 0.29 on epoch=26
05/22/2022 06:29:59 - INFO - __main__ - Step 740 Global step 740 Train loss 0.36 on epoch=26
05/22/2022 06:30:02 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=26
05/22/2022 06:30:15 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.4261341945461648 on epoch=26
05/22/2022 06:30:17 - INFO - __main__ - Step 760 Global step 760 Train loss 0.35 on epoch=27
05/22/2022 06:30:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.37 on epoch=27
05/22/2022 06:30:22 - INFO - __main__ - Step 780 Global step 780 Train loss 0.31 on epoch=27
05/22/2022 06:30:25 - INFO - __main__ - Step 790 Global step 790 Train loss 0.29 on epoch=28
05/22/2022 06:30:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.36 on epoch=28
05/22/2022 06:30:40 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.4484534851433412 on epoch=28
05/22/2022 06:30:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.32 on epoch=28
05/22/2022 06:30:45 - INFO - __main__ - Step 820 Global step 820 Train loss 0.24 on epoch=29
05/22/2022 06:30:48 - INFO - __main__ - Step 830 Global step 830 Train loss 0.25 on epoch=29
05/22/2022 06:30:50 - INFO - __main__ - Step 840 Global step 840 Train loss 0.34 on epoch=29
05/22/2022 06:30:53 - INFO - __main__ - Step 850 Global step 850 Train loss 0.29 on epoch=30
05/22/2022 06:31:06 - INFO - __main__ - Global step 850 Train loss 0.29 Classification-F1 0.39237604961133044 on epoch=30
05/22/2022 06:31:08 - INFO - __main__ - Step 860 Global step 860 Train loss 0.24 on epoch=30
05/22/2022 06:31:11 - INFO - __main__ - Step 870 Global step 870 Train loss 0.44 on epoch=31
05/22/2022 06:31:13 - INFO - __main__ - Step 880 Global step 880 Train loss 0.32 on epoch=31
05/22/2022 06:31:16 - INFO - __main__ - Step 890 Global step 890 Train loss 0.22 on epoch=31
05/22/2022 06:31:18 - INFO - __main__ - Step 900 Global step 900 Train loss 0.35 on epoch=32
05/22/2022 06:31:31 - INFO - __main__ - Global step 900 Train loss 0.32 Classification-F1 0.4287789195477343 on epoch=32
05/22/2022 06:31:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.27 on epoch=32
05/22/2022 06:31:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.27 on epoch=32
05/22/2022 06:31:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.27 on epoch=33
05/22/2022 06:31:42 - INFO - __main__ - Step 940 Global step 940 Train loss 0.22 on epoch=33
05/22/2022 06:31:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.30 on epoch=33
05/22/2022 06:31:57 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.5457327659575492 on epoch=33
05/22/2022 06:31:57 - INFO - __main__ - Saving model with best Classification-F1: 0.4925290485494542 -> 0.5457327659575492 on epoch=33, global_step=950
05/22/2022 06:31:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=34
05/22/2022 06:32:02 - INFO - __main__ - Step 970 Global step 970 Train loss 0.19 on epoch=34
05/22/2022 06:32:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.27 on epoch=34
05/22/2022 06:32:07 - INFO - __main__ - Step 990 Global step 990 Train loss 0.22 on epoch=35
05/22/2022 06:32:10 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=35
05/22/2022 06:32:22 - INFO - __main__ - Global step 1000 Train loss 0.22 Classification-F1 0.5310851894467895 on epoch=35
05/22/2022 06:32:25 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.39 on epoch=36
05/22/2022 06:32:27 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=36
05/22/2022 06:32:30 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.18 on epoch=36
05/22/2022 06:32:33 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=37
05/22/2022 06:32:35 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.19 on epoch=37
05/22/2022 06:32:48 - INFO - __main__ - Global step 1050 Train loss 0.24 Classification-F1 0.5315727494766652 on epoch=37
05/22/2022 06:32:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=37
05/22/2022 06:32:53 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.17 on epoch=38
05/22/2022 06:32:56 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=38
05/22/2022 06:32:58 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=38
05/22/2022 06:33:01 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=39
05/22/2022 06:33:14 - INFO - __main__ - Global step 1100 Train loss 0.20 Classification-F1 0.5811845975817969 on epoch=39
05/22/2022 06:33:14 - INFO - __main__ - Saving model with best Classification-F1: 0.5457327659575492 -> 0.5811845975817969 on epoch=39, global_step=1100
05/22/2022 06:33:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.20 on epoch=39
05/22/2022 06:33:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.32 on epoch=39
05/22/2022 06:33:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.15 on epoch=40
05/22/2022 06:33:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.16 on epoch=40
05/22/2022 06:33:27 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=41
05/22/2022 06:33:39 - INFO - __main__ - Global step 1150 Train loss 0.22 Classification-F1 0.6444917687194575 on epoch=41
05/22/2022 06:33:39 - INFO - __main__ - Saving model with best Classification-F1: 0.5811845975817969 -> 0.6444917687194575 on epoch=41, global_step=1150
05/22/2022 06:33:41 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.18 on epoch=41
05/22/2022 06:33:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.22 on epoch=41
05/22/2022 06:33:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.15 on epoch=42
05/22/2022 06:33:49 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.19 on epoch=42
05/22/2022 06:33:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.19 on epoch=42
05/22/2022 06:34:04 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.5779872798305978 on epoch=42
05/22/2022 06:34:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.17 on epoch=43
05/22/2022 06:34:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.19 on epoch=43
05/22/2022 06:34:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.32 on epoch=43
05/22/2022 06:34:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.22 on epoch=44
05/22/2022 06:34:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=44
05/22/2022 06:34:29 - INFO - __main__ - Global step 1250 Train loss 0.20 Classification-F1 0.640122618469443 on epoch=44
05/22/2022 06:34:32 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.24 on epoch=44
05/22/2022 06:34:34 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.19 on epoch=45
05/22/2022 06:34:37 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=45
05/22/2022 06:34:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=46
05/22/2022 06:34:42 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.19 on epoch=46
05/22/2022 06:34:55 - INFO - __main__ - Global step 1300 Train loss 0.20 Classification-F1 0.5508223139144159 on epoch=46
05/22/2022 06:34:57 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=46
05/22/2022 06:35:00 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.16 on epoch=47
05/22/2022 06:35:02 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=47
05/22/2022 06:35:05 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.14 on epoch=47
05/22/2022 06:35:08 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.16 on epoch=48
05/22/2022 06:35:20 - INFO - __main__ - Global step 1350 Train loss 0.15 Classification-F1 0.5800059320255206 on epoch=48
05/22/2022 06:35:23 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.15 on epoch=48
05/22/2022 06:35:25 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.19 on epoch=48
05/22/2022 06:35:28 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.18 on epoch=49
05/22/2022 06:35:31 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.15 on epoch=49
05/22/2022 06:35:33 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.18 on epoch=49
05/22/2022 06:35:46 - INFO - __main__ - Global step 1400 Train loss 0.17 Classification-F1 0.6096716936787878 on epoch=49
05/22/2022 06:35:48 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.20 on epoch=50
05/22/2022 06:35:51 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.12 on epoch=50
05/22/2022 06:35:54 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.18 on epoch=51
05/22/2022 06:35:56 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=51
05/22/2022 06:35:59 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.17 on epoch=51
05/22/2022 06:36:11 - INFO - __main__ - Global step 1450 Train loss 0.16 Classification-F1 0.6414593598707162 on epoch=51
05/22/2022 06:36:14 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.12 on epoch=52
05/22/2022 06:36:17 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=52
05/22/2022 06:36:19 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.14 on epoch=52
05/22/2022 06:36:22 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.17 on epoch=53
05/22/2022 06:36:24 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=53
05/22/2022 06:36:37 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.6449236994515634 on epoch=53
05/22/2022 06:36:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6444917687194575 -> 0.6449236994515634 on epoch=53, global_step=1500
05/22/2022 06:36:40 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=53
05/22/2022 06:36:42 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.10 on epoch=54
05/22/2022 06:36:45 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.16 on epoch=54
05/22/2022 06:36:47 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.10 on epoch=54
05/22/2022 06:36:50 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.13 on epoch=55
05/22/2022 06:37:03 - INFO - __main__ - Global step 1550 Train loss 0.12 Classification-F1 0.5819215685433484 on epoch=55
05/22/2022 06:37:05 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.16 on epoch=55
05/22/2022 06:37:08 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.16 on epoch=56
05/22/2022 06:37:10 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.17 on epoch=56
05/22/2022 06:37:13 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=56
05/22/2022 06:37:16 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.18 on epoch=57
05/22/2022 06:37:28 - INFO - __main__ - Global step 1600 Train loss 0.16 Classification-F1 0.6416051899239004 on epoch=57
05/22/2022 06:37:31 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.14 on epoch=57
05/22/2022 06:37:34 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=57
05/22/2022 06:37:36 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=58
05/22/2022 06:37:39 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.14 on epoch=58
05/22/2022 06:37:41 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.16 on epoch=58
05/22/2022 06:37:54 - INFO - __main__ - Global step 1650 Train loss 0.14 Classification-F1 0.5256327372943814 on epoch=58
05/22/2022 06:37:57 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.09 on epoch=59
05/22/2022 06:37:59 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=59
05/22/2022 06:38:02 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=59
05/22/2022 06:38:04 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.14 on epoch=60
05/22/2022 06:38:07 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.11 on epoch=60
05/22/2022 06:38:20 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.5275078732360116 on epoch=60
05/22/2022 06:38:22 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=61
05/22/2022 06:38:25 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.17 on epoch=61
05/22/2022 06:38:27 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.13 on epoch=61
05/22/2022 06:38:30 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=62
05/22/2022 06:38:33 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.14 on epoch=62
05/22/2022 06:38:45 - INFO - __main__ - Global step 1750 Train loss 0.14 Classification-F1 0.5631267041703645 on epoch=62
05/22/2022 06:38:48 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=62
05/22/2022 06:38:50 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=63
05/22/2022 06:38:53 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.13 on epoch=63
05/22/2022 06:38:55 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.12 on epoch=63
05/22/2022 06:38:58 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=64
05/22/2022 06:39:11 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.6196425000561169 on epoch=64
05/22/2022 06:39:13 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.09 on epoch=64
05/22/2022 06:39:16 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.14 on epoch=64
05/22/2022 06:39:19 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.10 on epoch=65
05/22/2022 06:39:21 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 06:39:24 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.10 on epoch=66
05/22/2022 06:39:37 - INFO - __main__ - Global step 1850 Train loss 0.10 Classification-F1 0.6089072956357227 on epoch=66
05/22/2022 06:39:39 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.13 on epoch=66
05/22/2022 06:39:42 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=66
05/22/2022 06:39:45 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.12 on epoch=67
05/22/2022 06:39:47 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.10 on epoch=67
05/22/2022 06:39:50 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.13 on epoch=67
05/22/2022 06:40:03 - INFO - __main__ - Global step 1900 Train loss 0.12 Classification-F1 0.6397670097360499 on epoch=67
05/22/2022 06:40:05 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=68
05/22/2022 06:40:08 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 06:40:10 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.07 on epoch=68
05/22/2022 06:40:13 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.12 on epoch=69
05/22/2022 06:40:16 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.11 on epoch=69
05/22/2022 06:40:29 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.6235172832389388 on epoch=69
05/22/2022 06:40:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.12 on epoch=69
05/22/2022 06:40:34 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.07 on epoch=70
05/22/2022 06:40:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=70
05/22/2022 06:40:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.12 on epoch=71
05/22/2022 06:40:42 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.14 on epoch=71
05/22/2022 06:40:55 - INFO - __main__ - Global step 2000 Train loss 0.10 Classification-F1 0.6516223735844479 on epoch=71
05/22/2022 06:40:55 - INFO - __main__ - Saving model with best Classification-F1: 0.6449236994515634 -> 0.6516223735844479 on epoch=71, global_step=2000
05/22/2022 06:40:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.12 on epoch=71
05/22/2022 06:41:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.12 on epoch=72
05/22/2022 06:41:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.15 on epoch=72
05/22/2022 06:41:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=72
05/22/2022 06:41:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=73
05/22/2022 06:41:20 - INFO - __main__ - Global step 2050 Train loss 0.12 Classification-F1 0.6854761206476893 on epoch=73
05/22/2022 06:41:20 - INFO - __main__ - Saving model with best Classification-F1: 0.6516223735844479 -> 0.6854761206476893 on epoch=73, global_step=2050
05/22/2022 06:41:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=73
05/22/2022 06:41:25 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.12 on epoch=73
05/22/2022 06:41:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.10 on epoch=74
05/22/2022 06:41:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.10 on epoch=74
05/22/2022 06:41:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=74
05/22/2022 06:41:46 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.6025727301658153 on epoch=74
05/22/2022 06:41:48 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.09 on epoch=75
05/22/2022 06:41:51 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=75
05/22/2022 06:41:53 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.14 on epoch=76
05/22/2022 06:41:56 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=76
05/22/2022 06:41:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.10 on epoch=76
05/22/2022 06:42:11 - INFO - __main__ - Global step 2150 Train loss 0.10 Classification-F1 0.6461560815028143 on epoch=76
05/22/2022 06:42:14 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.06 on epoch=77
05/22/2022 06:42:16 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.10 on epoch=77
05/22/2022 06:42:19 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.11 on epoch=77
05/22/2022 06:42:22 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.10 on epoch=78
05/22/2022 06:42:24 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.08 on epoch=78
05/22/2022 06:42:37 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.6796825721331129 on epoch=78
05/22/2022 06:42:39 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.11 on epoch=78
05/22/2022 06:42:42 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.09 on epoch=79
05/22/2022 06:42:45 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=79
05/22/2022 06:42:47 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=79
05/22/2022 06:42:50 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 06:43:02 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.6429866371272164 on epoch=80
05/22/2022 06:43:05 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=80
05/22/2022 06:43:08 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.08 on epoch=81
05/22/2022 06:43:10 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.13 on epoch=81
05/22/2022 06:43:13 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=81
05/22/2022 06:43:15 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.09 on epoch=82
05/22/2022 06:43:28 - INFO - __main__ - Global step 2300 Train loss 0.08 Classification-F1 0.619095539508933 on epoch=82
05/22/2022 06:43:31 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=82
05/22/2022 06:43:33 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.14 on epoch=82
05/22/2022 06:43:36 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.04 on epoch=83
05/22/2022 06:43:38 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.10 on epoch=83
05/22/2022 06:43:41 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=83
05/22/2022 06:43:54 - INFO - __main__ - Global step 2350 Train loss 0.09 Classification-F1 0.684204631856995 on epoch=83
05/22/2022 06:43:56 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=84
05/22/2022 06:43:59 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=84
05/22/2022 06:44:02 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=84
05/22/2022 06:44:04 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.09 on epoch=85
05/22/2022 06:44:07 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=85
05/22/2022 06:44:20 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.6470897161935018 on epoch=85
05/22/2022 06:44:22 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.13 on epoch=86
05/22/2022 06:44:25 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.08 on epoch=86
05/22/2022 06:44:28 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=86
05/22/2022 06:44:30 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.07 on epoch=87
05/22/2022 06:44:33 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=87
05/22/2022 06:44:46 - INFO - __main__ - Global step 2450 Train loss 0.08 Classification-F1 0.6155971436717405 on epoch=87
05/22/2022 06:44:48 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.09 on epoch=87
05/22/2022 06:44:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.10 on epoch=88
05/22/2022 06:44:53 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=88
05/22/2022 06:44:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=88
05/22/2022 06:44:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.07 on epoch=89
05/22/2022 06:45:12 - INFO - __main__ - Global step 2500 Train loss 0.08 Classification-F1 0.6414339946570093 on epoch=89
05/22/2022 06:45:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.07 on epoch=89
05/22/2022 06:45:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=89
05/22/2022 06:45:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.09 on epoch=90
05/22/2022 06:45:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.06 on epoch=90
05/22/2022 06:45:25 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.07 on epoch=91
05/22/2022 06:45:38 - INFO - __main__ - Global step 2550 Train loss 0.07 Classification-F1 0.6570564872389785 on epoch=91
05/22/2022 06:45:40 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.05 on epoch=91
05/22/2022 06:45:43 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.02 on epoch=91
05/22/2022 06:45:46 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.11 on epoch=92
05/22/2022 06:45:48 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.08 on epoch=92
05/22/2022 06:45:51 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.09 on epoch=92
05/22/2022 06:46:04 - INFO - __main__ - Global step 2600 Train loss 0.07 Classification-F1 0.6892908949689812 on epoch=92
05/22/2022 06:46:04 - INFO - __main__ - Saving model with best Classification-F1: 0.6854761206476893 -> 0.6892908949689812 on epoch=92, global_step=2600
05/22/2022 06:46:07 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=93
05/22/2022 06:46:09 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 06:46:12 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=93
05/22/2022 06:46:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=94
05/22/2022 06:46:17 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=94
05/22/2022 06:46:30 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.6612699188187504 on epoch=94
05/22/2022 06:46:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=94
05/22/2022 06:46:35 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.08 on epoch=95
05/22/2022 06:46:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.05 on epoch=95
05/22/2022 06:46:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.07 on epoch=96
05/22/2022 06:46:43 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=96
05/22/2022 06:46:56 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7426922855633479 on epoch=96
05/22/2022 06:46:56 - INFO - __main__ - Saving model with best Classification-F1: 0.6892908949689812 -> 0.7426922855633479 on epoch=96, global_step=2700
05/22/2022 06:46:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.10 on epoch=96
05/22/2022 06:47:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.06 on epoch=97
05/22/2022 06:47:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.06 on epoch=97
05/22/2022 06:47:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=97
05/22/2022 06:47:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=98
05/22/2022 06:47:21 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6860442628421983 on epoch=98
05/22/2022 06:47:24 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.06 on epoch=98
05/22/2022 06:47:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.10 on epoch=98
05/22/2022 06:47:29 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.05 on epoch=99
05/22/2022 06:47:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=99
05/22/2022 06:47:34 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=99
05/22/2022 06:47:46 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.672821010938474 on epoch=99
05/22/2022 06:47:49 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=100
05/22/2022 06:47:52 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.02 on epoch=100
05/22/2022 06:47:54 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=101
05/22/2022 06:47:57 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=101
05/22/2022 06:48:00 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=101
05/22/2022 06:48:12 - INFO - __main__ - Global step 2850 Train loss 0.05 Classification-F1 0.7317358739375298 on epoch=101
05/22/2022 06:48:14 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.08 on epoch=102
05/22/2022 06:48:17 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=102
05/22/2022 06:48:20 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=102
05/22/2022 06:48:22 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 06:48:25 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.05 on epoch=103
05/22/2022 06:48:37 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.8378741034823983 on epoch=103
05/22/2022 06:48:37 - INFO - __main__ - Saving model with best Classification-F1: 0.7426922855633479 -> 0.8378741034823983 on epoch=103, global_step=2900
05/22/2022 06:48:40 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=103
05/22/2022 06:48:42 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=104
05/22/2022 06:48:45 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.06 on epoch=104
05/22/2022 06:48:48 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=104
05/22/2022 06:48:50 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.06 on epoch=105
05/22/2022 06:49:02 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.7839926955126703 on epoch=105
05/22/2022 06:49:05 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=105
05/22/2022 06:49:07 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.08 on epoch=106
05/22/2022 06:49:10 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=106
05/22/2022 06:49:13 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.04 on epoch=106
05/22/2022 06:49:15 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=107
05/22/2022 06:49:17 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:49:17 - INFO - __main__ - Printing 3 examples
05/22/2022 06:49:17 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 06:49:17 - INFO - __main__ - ['Plant']
05/22/2022 06:49:17 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 06:49:17 - INFO - __main__ - ['Plant']
05/22/2022 06:49:17 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 06:49:17 - INFO - __main__ - ['Plant']
05/22/2022 06:49:17 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:49:17 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:49:18 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 06:49:18 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:49:18 - INFO - __main__ - Printing 3 examples
05/22/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 06:49:18 - INFO - __main__ - ['Plant']
05/22/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 06:49:18 - INFO - __main__ - ['Plant']
05/22/2022 06:49:18 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 06:49:18 - INFO - __main__ - ['Plant']
05/22/2022 06:49:18 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:49:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:49:19 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 06:49:27 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7405793144329293 on epoch=107
05/22/2022 06:49:27 - INFO - __main__ - save last model!
05/22/2022 06:49:28 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 06:49:28 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 06:49:28 - INFO - __main__ - Printing 3 examples
05/22/2022 06:49:28 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 06:49:28 - INFO - __main__ - ['Animal']
05/22/2022 06:49:28 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 06:49:28 - INFO - __main__ - ['Animal']
05/22/2022 06:49:28 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 06:49:28 - INFO - __main__ - ['Village']
05/22/2022 06:49:28 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:49:29 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:49:33 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 06:49:34 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 06:49:35 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 06:49:35 - INFO - __main__ - Starting training!
05/22/2022 06:51:38 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_13_0.2_8_predictions.txt
05/22/2022 06:51:38 - INFO - __main__ - Classification-F1 on test data: 0.5813
05/22/2022 06:51:38 - INFO - __main__ - prefix=dbpedia_14_32_13, lr=0.2, bsz=8, dev_performance=0.8378741034823983, test_performance=0.581337965224086
05/22/2022 06:51:38 - INFO - __main__ - Running ... prefix=dbpedia_14_32_21, lr=0.5, bsz=8 ...
05/22/2022 06:51:39 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:51:39 - INFO - __main__ - Printing 3 examples
05/22/2022 06:51:39 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 06:51:39 - INFO - __main__ - ['Plant']
05/22/2022 06:51:39 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 06:51:39 - INFO - __main__ - ['Plant']
05/22/2022 06:51:39 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 06:51:39 - INFO - __main__ - ['Plant']
05/22/2022 06:51:39 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:51:39 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:51:40 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 06:51:40 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 06:51:40 - INFO - __main__ - Printing 3 examples
05/22/2022 06:51:40 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 06:51:40 - INFO - __main__ - ['Plant']
05/22/2022 06:51:40 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 06:51:40 - INFO - __main__ - ['Plant']
05/22/2022 06:51:40 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 06:51:40 - INFO - __main__ - ['Plant']
05/22/2022 06:51:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 06:51:40 - INFO - __main__ - Tokenizing Output ...
05/22/2022 06:51:40 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 06:51:58 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 06:51:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 06:51:59 - INFO - __main__ - Starting training!
05/22/2022 06:52:03 - INFO - __main__ - Step 10 Global step 10 Train loss 6.25 on epoch=0
05/22/2022 06:52:06 - INFO - __main__ - Step 20 Global step 20 Train loss 4.51 on epoch=0
05/22/2022 06:52:08 - INFO - __main__ - Step 30 Global step 30 Train loss 3.91 on epoch=1
05/22/2022 06:52:11 - INFO - __main__ - Step 40 Global step 40 Train loss 3.37 on epoch=1
05/22/2022 06:52:14 - INFO - __main__ - Step 50 Global step 50 Train loss 2.78 on epoch=1
05/22/2022 06:52:26 - INFO - __main__ - Global step 50 Train loss 4.17 Classification-F1 0.034735745492304064 on epoch=1
05/22/2022 06:52:26 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.034735745492304064 on epoch=1, global_step=50
05/22/2022 06:52:29 - INFO - __main__ - Step 60 Global step 60 Train loss 2.68 on epoch=2
05/22/2022 06:52:32 - INFO - __main__ - Step 70 Global step 70 Train loss 2.45 on epoch=2
05/22/2022 06:52:34 - INFO - __main__ - Step 80 Global step 80 Train loss 1.82 on epoch=2
05/22/2022 06:52:37 - INFO - __main__ - Step 90 Global step 90 Train loss 2.11 on epoch=3
05/22/2022 06:52:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.76 on epoch=3
05/22/2022 06:52:50 - INFO - __main__ - Global step 100 Train loss 2.17 Classification-F1 0.09783326059077452 on epoch=3
05/22/2022 06:52:50 - INFO - __main__ - Saving model with best Classification-F1: 0.034735745492304064 -> 0.09783326059077452 on epoch=3, global_step=100
05/22/2022 06:52:53 - INFO - __main__ - Step 110 Global step 110 Train loss 1.44 on epoch=3
05/22/2022 06:52:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.44 on epoch=4
05/22/2022 06:52:58 - INFO - __main__ - Step 130 Global step 130 Train loss 1.16 on epoch=4
05/22/2022 06:53:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.16 on epoch=4
05/22/2022 06:53:03 - INFO - __main__ - Step 150 Global step 150 Train loss 1.07 on epoch=5
05/22/2022 06:53:14 - INFO - __main__ - Global step 150 Train loss 1.26 Classification-F1 0.19917015830522167 on epoch=5
05/22/2022 06:53:14 - INFO - __main__ - Saving model with best Classification-F1: 0.09783326059077452 -> 0.19917015830522167 on epoch=5, global_step=150
05/22/2022 06:53:17 - INFO - __main__ - Step 160 Global step 160 Train loss 0.97 on epoch=5
05/22/2022 06:53:19 - INFO - __main__ - Step 170 Global step 170 Train loss 0.87 on epoch=6
05/22/2022 06:53:22 - INFO - __main__ - Step 180 Global step 180 Train loss 0.73 on epoch=6
05/22/2022 06:53:24 - INFO - __main__ - Step 190 Global step 190 Train loss 0.68 on epoch=6
05/22/2022 06:53:27 - INFO - __main__ - Step 200 Global step 200 Train loss 0.64 on epoch=7
05/22/2022 06:53:39 - INFO - __main__ - Global step 200 Train loss 0.78 Classification-F1 0.3208744460989086 on epoch=7
05/22/2022 06:53:39 - INFO - __main__ - Saving model with best Classification-F1: 0.19917015830522167 -> 0.3208744460989086 on epoch=7, global_step=200
05/22/2022 06:53:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.60 on epoch=7
05/22/2022 06:53:44 - INFO - __main__ - Step 220 Global step 220 Train loss 0.45 on epoch=7
05/22/2022 06:53:47 - INFO - __main__ - Step 230 Global step 230 Train loss 0.55 on epoch=8
05/22/2022 06:53:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.51 on epoch=8
05/22/2022 06:53:52 - INFO - __main__ - Step 250 Global step 250 Train loss 0.41 on epoch=8
05/22/2022 06:54:05 - INFO - __main__ - Global step 250 Train loss 0.50 Classification-F1 0.3555225675920919 on epoch=8
05/22/2022 06:54:05 - INFO - __main__ - Saving model with best Classification-F1: 0.3208744460989086 -> 0.3555225675920919 on epoch=8, global_step=250
05/22/2022 06:54:08 - INFO - __main__ - Step 260 Global step 260 Train loss 0.45 on epoch=9
05/22/2022 06:54:10 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=9
05/22/2022 06:54:13 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=9
05/22/2022 06:54:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.34 on epoch=10
05/22/2022 06:54:18 - INFO - __main__ - Step 300 Global step 300 Train loss 0.30 on epoch=10
05/22/2022 06:54:31 - INFO - __main__ - Global step 300 Train loss 0.38 Classification-F1 0.3797832377351291 on epoch=10
05/22/2022 06:54:31 - INFO - __main__ - Saving model with best Classification-F1: 0.3555225675920919 -> 0.3797832377351291 on epoch=10, global_step=300
05/22/2022 06:54:34 - INFO - __main__ - Step 310 Global step 310 Train loss 0.30 on epoch=11
05/22/2022 06:54:36 - INFO - __main__ - Step 320 Global step 320 Train loss 0.31 on epoch=11
05/22/2022 06:54:39 - INFO - __main__ - Step 330 Global step 330 Train loss 0.34 on epoch=11
05/22/2022 06:54:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.31 on epoch=12
05/22/2022 06:54:44 - INFO - __main__ - Step 350 Global step 350 Train loss 0.33 on epoch=12
05/22/2022 06:54:57 - INFO - __main__ - Global step 350 Train loss 0.32 Classification-F1 0.4862245775498979 on epoch=12
05/22/2022 06:54:57 - INFO - __main__ - Saving model with best Classification-F1: 0.3797832377351291 -> 0.4862245775498979 on epoch=12, global_step=350
05/22/2022 06:55:00 - INFO - __main__ - Step 360 Global step 360 Train loss 0.29 on epoch=12
05/22/2022 06:55:02 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=13
05/22/2022 06:55:05 - INFO - __main__ - Step 380 Global step 380 Train loss 0.24 on epoch=13
05/22/2022 06:55:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.35 on epoch=13
05/22/2022 06:55:10 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=14
05/22/2022 06:55:23 - INFO - __main__ - Global step 400 Train loss 0.30 Classification-F1 0.4422443979422656 on epoch=14
05/22/2022 06:55:26 - INFO - __main__ - Step 410 Global step 410 Train loss 0.18 on epoch=14
05/22/2022 06:55:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.22 on epoch=14
05/22/2022 06:55:31 - INFO - __main__ - Step 430 Global step 430 Train loss 0.24 on epoch=15
05/22/2022 06:55:34 - INFO - __main__ - Step 440 Global step 440 Train loss 0.17 on epoch=15
05/22/2022 06:55:36 - INFO - __main__ - Step 450 Global step 450 Train loss 0.22 on epoch=16
05/22/2022 06:55:50 - INFO - __main__ - Global step 450 Train loss 0.21 Classification-F1 0.4707216126458428 on epoch=16
05/22/2022 06:55:52 - INFO - __main__ - Step 460 Global step 460 Train loss 0.23 on epoch=16
05/22/2022 06:55:55 - INFO - __main__ - Step 470 Global step 470 Train loss 0.22 on epoch=16
05/22/2022 06:55:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=17
05/22/2022 06:56:00 - INFO - __main__ - Step 490 Global step 490 Train loss 0.19 on epoch=17
05/22/2022 06:56:03 - INFO - __main__ - Step 500 Global step 500 Train loss 0.18 on epoch=17
05/22/2022 06:56:15 - INFO - __main__ - Global step 500 Train loss 0.21 Classification-F1 0.4957583254632435 on epoch=17
05/22/2022 06:56:15 - INFO - __main__ - Saving model with best Classification-F1: 0.4862245775498979 -> 0.4957583254632435 on epoch=17, global_step=500
05/22/2022 06:56:18 - INFO - __main__ - Step 510 Global step 510 Train loss 0.23 on epoch=18
05/22/2022 06:56:21 - INFO - __main__ - Step 520 Global step 520 Train loss 0.12 on epoch=18
05/22/2022 06:56:23 - INFO - __main__ - Step 530 Global step 530 Train loss 0.16 on epoch=18
05/22/2022 06:56:26 - INFO - __main__ - Step 540 Global step 540 Train loss 0.19 on epoch=19
05/22/2022 06:56:29 - INFO - __main__ - Step 550 Global step 550 Train loss 0.15 on epoch=19
05/22/2022 06:56:41 - INFO - __main__ - Global step 550 Train loss 0.17 Classification-F1 0.5729010247957971 on epoch=19
05/22/2022 06:56:41 - INFO - __main__ - Saving model with best Classification-F1: 0.4957583254632435 -> 0.5729010247957971 on epoch=19, global_step=550
05/22/2022 06:56:44 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=19
05/22/2022 06:56:46 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=20
05/22/2022 06:56:49 - INFO - __main__ - Step 580 Global step 580 Train loss 0.14 on epoch=20
05/22/2022 06:56:52 - INFO - __main__ - Step 590 Global step 590 Train loss 0.09 on epoch=21
05/22/2022 06:56:54 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=21
05/22/2022 06:57:07 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.6395357934741661 on epoch=21
05/22/2022 06:57:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5729010247957971 -> 0.6395357934741661 on epoch=21, global_step=600
05/22/2022 06:57:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.09 on epoch=21
05/22/2022 06:57:12 - INFO - __main__ - Step 620 Global step 620 Train loss 0.19 on epoch=22
05/22/2022 06:57:15 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=22
05/22/2022 06:57:17 - INFO - __main__ - Step 640 Global step 640 Train loss 0.17 on epoch=22
05/22/2022 06:57:20 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=23
05/22/2022 06:57:33 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7237291323945341 on epoch=23
05/22/2022 06:57:33 - INFO - __main__ - Saving model with best Classification-F1: 0.6395357934741661 -> 0.7237291323945341 on epoch=23, global_step=650
05/22/2022 06:57:36 - INFO - __main__ - Step 660 Global step 660 Train loss 0.16 on epoch=23
05/22/2022 06:57:38 - INFO - __main__ - Step 670 Global step 670 Train loss 0.17 on epoch=23
05/22/2022 06:57:41 - INFO - __main__ - Step 680 Global step 680 Train loss 0.11 on epoch=24
05/22/2022 06:57:44 - INFO - __main__ - Step 690 Global step 690 Train loss 0.07 on epoch=24
05/22/2022 06:57:46 - INFO - __main__ - Step 700 Global step 700 Train loss 0.12 on epoch=24
05/22/2022 06:57:59 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.6616365105582854 on epoch=24
05/22/2022 06:58:01 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=25
05/22/2022 06:58:04 - INFO - __main__ - Step 720 Global step 720 Train loss 0.10 on epoch=25
05/22/2022 06:58:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.12 on epoch=26
05/22/2022 06:58:09 - INFO - __main__ - Step 740 Global step 740 Train loss 0.12 on epoch=26
05/22/2022 06:58:12 - INFO - __main__ - Step 750 Global step 750 Train loss 0.09 on epoch=26
05/22/2022 06:58:24 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6030521465672107 on epoch=26
05/22/2022 06:58:26 - INFO - __main__ - Step 760 Global step 760 Train loss 0.05 on epoch=27
05/22/2022 06:58:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.07 on epoch=27
05/22/2022 06:58:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.08 on epoch=27
05/22/2022 06:58:34 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=28
05/22/2022 06:58:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.05 on epoch=28
05/22/2022 06:58:50 - INFO - __main__ - Global step 800 Train loss 0.08 Classification-F1 0.668440599869742 on epoch=28
05/22/2022 06:58:52 - INFO - __main__ - Step 810 Global step 810 Train loss 0.09 on epoch=28
05/22/2022 06:58:55 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=29
05/22/2022 06:58:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.04 on epoch=29
05/22/2022 06:59:00 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=29
05/22/2022 06:59:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.08 on epoch=30
05/22/2022 06:59:16 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.5811700626750437 on epoch=30
05/22/2022 06:59:18 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=30
05/22/2022 06:59:21 - INFO - __main__ - Step 870 Global step 870 Train loss 0.05 on epoch=31
05/22/2022 06:59:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.08 on epoch=31
05/22/2022 06:59:26 - INFO - __main__ - Step 890 Global step 890 Train loss 0.12 on epoch=31
05/22/2022 06:59:29 - INFO - __main__ - Step 900 Global step 900 Train loss 0.07 on epoch=32
05/22/2022 06:59:42 - INFO - __main__ - Global step 900 Train loss 0.09 Classification-F1 0.6101590848134627 on epoch=32
05/22/2022 06:59:44 - INFO - __main__ - Step 910 Global step 910 Train loss 0.09 on epoch=32
05/22/2022 06:59:47 - INFO - __main__ - Step 920 Global step 920 Train loss 0.05 on epoch=32
05/22/2022 06:59:49 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=33
05/22/2022 06:59:52 - INFO - __main__ - Step 940 Global step 940 Train loss 0.05 on epoch=33
05/22/2022 06:59:55 - INFO - __main__ - Step 950 Global step 950 Train loss 0.16 on epoch=33
05/22/2022 07:00:07 - INFO - __main__ - Global step 950 Train loss 0.09 Classification-F1 0.7097828217626228 on epoch=33
05/22/2022 07:00:10 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=34
05/22/2022 07:00:12 - INFO - __main__ - Step 970 Global step 970 Train loss 0.04 on epoch=34
05/22/2022 07:00:15 - INFO - __main__ - Step 980 Global step 980 Train loss 0.11 on epoch=34
05/22/2022 07:00:18 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=35
05/22/2022 07:00:20 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=35
05/22/2022 07:00:33 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.7247944259899133 on epoch=35
05/22/2022 07:00:33 - INFO - __main__ - Saving model with best Classification-F1: 0.7237291323945341 -> 0.7247944259899133 on epoch=35, global_step=1000
05/22/2022 07:00:35 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.06 on epoch=36
05/22/2022 07:00:38 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=36
05/22/2022 07:00:41 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=36
05/22/2022 07:00:43 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=37
05/22/2022 07:00:46 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=37
05/22/2022 07:00:58 - INFO - __main__ - Global step 1050 Train loss 0.07 Classification-F1 0.7438943443612166 on epoch=37
05/22/2022 07:00:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7247944259899133 -> 0.7438943443612166 on epoch=37, global_step=1050
05/22/2022 07:01:01 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=37
05/22/2022 07:01:04 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.05 on epoch=38
05/22/2022 07:01:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=38
05/22/2022 07:01:09 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=38
05/22/2022 07:01:12 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.10 on epoch=39
05/22/2022 07:01:24 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7799806604344863 on epoch=39
05/22/2022 07:01:24 - INFO - __main__ - Saving model with best Classification-F1: 0.7438943443612166 -> 0.7799806604344863 on epoch=39, global_step=1100
05/22/2022 07:01:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.03 on epoch=39
05/22/2022 07:01:30 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.07 on epoch=39
05/22/2022 07:01:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.06 on epoch=40
05/22/2022 07:01:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=40
05/22/2022 07:01:38 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=41
05/22/2022 07:01:50 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.7921906986737652 on epoch=41
05/22/2022 07:01:50 - INFO - __main__ - Saving model with best Classification-F1: 0.7799806604344863 -> 0.7921906986737652 on epoch=41, global_step=1150
05/22/2022 07:01:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.04 on epoch=41
05/22/2022 07:01:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.06 on epoch=41
05/22/2022 07:01:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=42
05/22/2022 07:02:00 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=42
05/22/2022 07:02:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.12 on epoch=42
05/22/2022 07:02:15 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6940767054511869 on epoch=42
05/22/2022 07:02:18 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.02 on epoch=43
05/22/2022 07:02:21 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=43
05/22/2022 07:02:23 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=43
05/22/2022 07:02:26 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=44
05/22/2022 07:02:29 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.03 on epoch=44
05/22/2022 07:02:41 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6475444915106007 on epoch=44
05/22/2022 07:02:43 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=44
05/22/2022 07:02:46 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.03 on epoch=45
05/22/2022 07:02:49 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=45
05/22/2022 07:02:51 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.05 on epoch=46
05/22/2022 07:02:54 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.04 on epoch=46
05/22/2022 07:03:06 - INFO - __main__ - Global step 1300 Train loss 0.05 Classification-F1 0.6486283460594399 on epoch=46
05/22/2022 07:03:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.06 on epoch=46
05/22/2022 07:03:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.05 on epoch=47
05/22/2022 07:03:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.04 on epoch=47
05/22/2022 07:03:16 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=47
05/22/2022 07:03:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.03 on epoch=48
05/22/2022 07:03:32 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8354519634151901 on epoch=48
05/22/2022 07:03:32 - INFO - __main__ - Saving model with best Classification-F1: 0.7921906986737652 -> 0.8354519634151901 on epoch=48, global_step=1350
05/22/2022 07:03:34 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=48
05/22/2022 07:03:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.14 on epoch=48
05/22/2022 07:03:39 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=49
05/22/2022 07:03:42 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=49
05/22/2022 07:03:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.10 on epoch=49
05/22/2022 07:03:58 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.6458524002143367 on epoch=49
05/22/2022 07:04:00 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.04 on epoch=50
05/22/2022 07:04:03 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.03 on epoch=50
05/22/2022 07:04:05 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=51
05/22/2022 07:04:08 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.03 on epoch=51
05/22/2022 07:04:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.06 on epoch=51
05/22/2022 07:04:23 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.6076606645520752 on epoch=51
05/22/2022 07:04:25 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=52
05/22/2022 07:04:28 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.04 on epoch=52
05/22/2022 07:04:31 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.04 on epoch=52
05/22/2022 07:04:33 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=53
05/22/2022 07:04:36 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=53
05/22/2022 07:04:48 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.6014401211662475 on epoch=53
05/22/2022 07:04:51 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=53
05/22/2022 07:04:53 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=54
05/22/2022 07:04:56 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=54
05/22/2022 07:04:58 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=54
05/22/2022 07:05:01 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.04 on epoch=55
05/22/2022 07:05:13 - INFO - __main__ - Global step 1550 Train loss 0.05 Classification-F1 0.7027094566179523 on epoch=55
05/22/2022 07:05:15 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.04 on epoch=55
05/22/2022 07:05:18 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 07:05:21 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=56
05/22/2022 07:05:23 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=56
05/22/2022 07:05:26 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=57
05/22/2022 07:05:38 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.638518046233904 on epoch=57
05/22/2022 07:05:41 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.03 on epoch=57
05/22/2022 07:05:43 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.12 on epoch=57
05/22/2022 07:05:46 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=58
05/22/2022 07:05:48 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=58
05/22/2022 07:05:51 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=58
05/22/2022 07:06:03 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.6839452550359519 on epoch=58
05/22/2022 07:06:06 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=59
05/22/2022 07:06:08 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.01 on epoch=59
05/22/2022 07:06:11 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.06 on epoch=59
05/22/2022 07:06:14 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=60
05/22/2022 07:06:16 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=60
05/22/2022 07:06:29 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.7630869660706862 on epoch=60
05/22/2022 07:06:31 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.02 on epoch=61
05/22/2022 07:06:34 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=61
05/22/2022 07:06:36 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.06 on epoch=61
05/22/2022 07:06:39 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=62
05/22/2022 07:06:41 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 07:06:54 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.7497149865609702 on epoch=62
05/22/2022 07:06:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=62
05/22/2022 07:06:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=63
05/22/2022 07:07:01 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=63
05/22/2022 07:07:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.02 on epoch=63
05/22/2022 07:07:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=64
05/22/2022 07:07:19 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.636432976795964 on epoch=64
05/22/2022 07:07:21 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=64
05/22/2022 07:07:24 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=64
05/22/2022 07:07:26 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=65
05/22/2022 07:07:29 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 07:07:32 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=66
05/22/2022 07:07:44 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.6982578225481751 on epoch=66
05/22/2022 07:07:46 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.02 on epoch=66
05/22/2022 07:07:49 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=66
05/22/2022 07:07:52 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=67
05/22/2022 07:07:54 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=67
05/22/2022 07:07:57 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=67
05/22/2022 07:08:09 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7340761033023298 on epoch=67
05/22/2022 07:08:12 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=68
05/22/2022 07:08:14 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=68
05/22/2022 07:08:17 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.02 on epoch=68
05/22/2022 07:08:19 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=69
05/22/2022 07:08:22 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=69
05/22/2022 07:08:34 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7773736181090615 on epoch=69
05/22/2022 07:08:37 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=69
05/22/2022 07:08:40 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.01 on epoch=70
05/22/2022 07:08:42 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=70
05/22/2022 07:08:45 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=71
05/22/2022 07:08:47 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=71
05/22/2022 07:09:00 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.8400857388441767 on epoch=71
05/22/2022 07:09:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8354519634151901 -> 0.8400857388441767 on epoch=71, global_step=2000
05/22/2022 07:09:02 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=71
05/22/2022 07:09:05 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=72
05/22/2022 07:09:08 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=72
05/22/2022 07:09:10 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.07 on epoch=72
05/22/2022 07:09:13 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=73
05/22/2022 07:09:25 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.9063839216386824 on epoch=73
05/22/2022 07:09:25 - INFO - __main__ - Saving model with best Classification-F1: 0.8400857388441767 -> 0.9063839216386824 on epoch=73, global_step=2050
05/22/2022 07:09:28 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=73
05/22/2022 07:09:30 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=73
05/22/2022 07:09:33 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=74
05/22/2022 07:09:36 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=74
05/22/2022 07:09:38 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=74
05/22/2022 07:09:50 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.727565157024418 on epoch=74
05/22/2022 07:09:53 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.08 on epoch=75
05/22/2022 07:09:55 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=75
05/22/2022 07:09:58 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=76
05/22/2022 07:10:00 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=76
05/22/2022 07:10:03 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=76
05/22/2022 07:10:15 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7936304820909212 on epoch=76
05/22/2022 07:10:18 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=77
05/22/2022 07:10:20 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.01 on epoch=77
05/22/2022 07:10:23 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.05 on epoch=77
05/22/2022 07:10:26 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=78
05/22/2022 07:10:28 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=78
05/22/2022 07:10:40 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.8488465314284986 on epoch=78
05/22/2022 07:10:43 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 07:10:45 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=79
05/22/2022 07:10:48 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=79
05/22/2022 07:10:50 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=79
05/22/2022 07:10:53 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=80
05/22/2022 07:11:05 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9095041318697231 on epoch=80
05/22/2022 07:11:06 - INFO - __main__ - Saving model with best Classification-F1: 0.9063839216386824 -> 0.9095041318697231 on epoch=80, global_step=2250
05/22/2022 07:11:08 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=80
05/22/2022 07:11:11 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=81
05/22/2022 07:11:14 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=81
05/22/2022 07:11:16 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=81
05/22/2022 07:11:19 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=82
05/22/2022 07:11:31 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.8104130320449107 on epoch=82
05/22/2022 07:11:34 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=82
05/22/2022 07:11:36 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=82
05/22/2022 07:11:39 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=83
05/22/2022 07:11:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=83
05/22/2022 07:11:44 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.04 on epoch=83
05/22/2022 07:11:56 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8539177397150608 on epoch=83
05/22/2022 07:11:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=84
05/22/2022 07:12:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=84
05/22/2022 07:12:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=84
05/22/2022 07:12:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=85
05/22/2022 07:12:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.03 on epoch=85
05/22/2022 07:12:21 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.7428741215877862 on epoch=85
05/22/2022 07:12:23 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=86
05/22/2022 07:12:26 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.00 on epoch=86
05/22/2022 07:12:29 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.04 on epoch=86
05/22/2022 07:12:31 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 07:12:34 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=87
05/22/2022 07:12:46 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.8550476832178857 on epoch=87
05/22/2022 07:12:49 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=87
05/22/2022 07:12:51 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=88
05/22/2022 07:12:54 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 07:12:56 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=88
05/22/2022 07:12:59 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=89
05/22/2022 07:13:11 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.8466758728299464 on epoch=89
05/22/2022 07:13:14 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.00 on epoch=89
05/22/2022 07:13:17 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.07 on epoch=89
05/22/2022 07:13:19 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.05 on epoch=90
05/22/2022 07:13:22 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=90
05/22/2022 07:13:24 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=91
05/22/2022 07:13:36 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.8024145017705848 on epoch=91
05/22/2022 07:13:39 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=91
05/22/2022 07:13:42 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=91
05/22/2022 07:13:44 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=92
05/22/2022 07:13:47 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=92
05/22/2022 07:13:49 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=92
05/22/2022 07:14:01 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7435083479344419 on epoch=92
05/22/2022 07:14:04 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=93
05/22/2022 07:14:06 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=93
05/22/2022 07:14:09 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=93
05/22/2022 07:14:11 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 07:14:14 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=94
05/22/2022 07:14:26 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.7925295178661791 on epoch=94
05/22/2022 07:14:29 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=94
05/22/2022 07:14:32 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=95
05/22/2022 07:14:34 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=95
05/22/2022 07:14:37 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=96
05/22/2022 07:14:39 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=96
05/22/2022 07:14:51 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7915144558924879 on epoch=96
05/22/2022 07:14:54 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=96
05/22/2022 07:14:57 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=97
05/22/2022 07:14:59 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=97
05/22/2022 07:15:02 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.04 on epoch=97
05/22/2022 07:15:04 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.00 on epoch=98
05/22/2022 07:15:16 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.8490931345928898 on epoch=98
05/22/2022 07:15:19 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=98
05/22/2022 07:15:22 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=98
05/22/2022 07:15:24 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=99
05/22/2022 07:15:27 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.01 on epoch=99
05/22/2022 07:15:29 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.09 on epoch=99
05/22/2022 07:15:42 - INFO - __main__ - Global step 2800 Train loss 0.04 Classification-F1 0.8548170996070757 on epoch=99
05/22/2022 07:15:44 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=100
05/22/2022 07:15:47 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=100
05/22/2022 07:15:49 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 07:15:52 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=101
05/22/2022 07:15:55 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=101
05/22/2022 07:16:07 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7574634445602187 on epoch=101
05/22/2022 07:16:09 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=102
05/22/2022 07:16:12 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=102
05/22/2022 07:16:15 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.03 on epoch=102
05/22/2022 07:16:17 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=103
05/22/2022 07:16:20 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 07:16:32 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.8419355165682454 on epoch=103
05/22/2022 07:16:34 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=103
05/22/2022 07:16:37 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.00 on epoch=104
05/22/2022 07:16:40 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=104
05/22/2022 07:16:42 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 07:16:45 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=105
05/22/2022 07:16:57 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.7553808428963654 on epoch=105
05/22/2022 07:17:00 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=105
05/22/2022 07:17:02 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 07:17:05 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 07:17:07 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=106
05/22/2022 07:17:10 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=107
05/22/2022 07:17:12 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:17:12 - INFO - __main__ - Printing 3 examples
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:17:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:17:12 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 07:17:12 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:17:12 - INFO - __main__ - Printing 3 examples
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:17:12 - INFO - __main__ - ['Plant']
05/22/2022 07:17:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:17:12 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:17:13 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 07:17:22 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.7512634481834889 on epoch=107
05/22/2022 07:17:22 - INFO - __main__ - save last model!
05/22/2022 07:17:22 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 07:17:22 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 07:17:22 - INFO - __main__ - Printing 3 examples
05/22/2022 07:17:22 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 07:17:22 - INFO - __main__ - ['Animal']
05/22/2022 07:17:22 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 07:17:22 - INFO - __main__ - ['Animal']
05/22/2022 07:17:22 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 07:17:22 - INFO - __main__ - ['Village']
05/22/2022 07:17:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:17:24 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:17:28 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 07:17:31 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 07:17:32 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 07:17:32 - INFO - __main__ - Starting training!
05/22/2022 07:19:34 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_21_0.5_8_predictions.txt
05/22/2022 07:19:34 - INFO - __main__ - Classification-F1 on test data: 0.5039
05/22/2022 07:19:35 - INFO - __main__ - prefix=dbpedia_14_32_21, lr=0.5, bsz=8, dev_performance=0.9095041318697231, test_performance=0.5038522027255007
05/22/2022 07:19:35 - INFO - __main__ - Running ... prefix=dbpedia_14_32_21, lr=0.4, bsz=8 ...
05/22/2022 07:19:36 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:19:36 - INFO - __main__ - Printing 3 examples
05/22/2022 07:19:36 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 07:19:36 - INFO - __main__ - ['Plant']
05/22/2022 07:19:36 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 07:19:36 - INFO - __main__ - ['Plant']
05/22/2022 07:19:36 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 07:19:36 - INFO - __main__ - ['Plant']
05/22/2022 07:19:36 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:19:36 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:19:37 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 07:19:37 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:19:37 - INFO - __main__ - Printing 3 examples
05/22/2022 07:19:37 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 07:19:37 - INFO - __main__ - ['Plant']
05/22/2022 07:19:37 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:19:37 - INFO - __main__ - ['Plant']
05/22/2022 07:19:37 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:19:37 - INFO - __main__ - ['Plant']
05/22/2022 07:19:37 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:19:37 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:19:37 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 07:19:54 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 07:19:54 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 07:19:54 - INFO - __main__ - Starting training!
05/22/2022 07:19:58 - INFO - __main__ - Step 10 Global step 10 Train loss 6.90 on epoch=0
05/22/2022 07:20:00 - INFO - __main__ - Step 20 Global step 20 Train loss 4.74 on epoch=0
05/22/2022 07:20:03 - INFO - __main__ - Step 30 Global step 30 Train loss 4.20 on epoch=1
05/22/2022 07:20:05 - INFO - __main__ - Step 40 Global step 40 Train loss 3.70 on epoch=1
05/22/2022 07:20:08 - INFO - __main__ - Step 50 Global step 50 Train loss 3.05 on epoch=1
05/22/2022 07:20:22 - INFO - __main__ - Global step 50 Train loss 4.52 Classification-F1 0.02579877733202124 on epoch=1
05/22/2022 07:20:22 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.02579877733202124 on epoch=1, global_step=50
05/22/2022 07:20:25 - INFO - __main__ - Step 60 Global step 60 Train loss 2.90 on epoch=2
05/22/2022 07:20:27 - INFO - __main__ - Step 70 Global step 70 Train loss 2.64 on epoch=2
05/22/2022 07:20:30 - INFO - __main__ - Step 80 Global step 80 Train loss 2.11 on epoch=2
05/22/2022 07:20:33 - INFO - __main__ - Step 90 Global step 90 Train loss 2.44 on epoch=3
05/22/2022 07:20:35 - INFO - __main__ - Step 100 Global step 100 Train loss 1.98 on epoch=3
05/22/2022 07:20:47 - INFO - __main__ - Global step 100 Train loss 2.41 Classification-F1 0.0669250876371902 on epoch=3
05/22/2022 07:20:47 - INFO - __main__ - Saving model with best Classification-F1: 0.02579877733202124 -> 0.0669250876371902 on epoch=3, global_step=100
05/22/2022 07:20:50 - INFO - __main__ - Step 110 Global step 110 Train loss 1.76 on epoch=3
05/22/2022 07:20:52 - INFO - __main__ - Step 120 Global step 120 Train loss 1.88 on epoch=4
05/22/2022 07:20:55 - INFO - __main__ - Step 130 Global step 130 Train loss 1.56 on epoch=4
05/22/2022 07:20:57 - INFO - __main__ - Step 140 Global step 140 Train loss 1.75 on epoch=4
05/22/2022 07:21:00 - INFO - __main__ - Step 150 Global step 150 Train loss 1.55 on epoch=5
05/22/2022 07:21:11 - INFO - __main__ - Global step 150 Train loss 1.70 Classification-F1 0.11877049301895512 on epoch=5
05/22/2022 07:21:11 - INFO - __main__ - Saving model with best Classification-F1: 0.0669250876371902 -> 0.11877049301895512 on epoch=5, global_step=150
05/22/2022 07:21:14 - INFO - __main__ - Step 160 Global step 160 Train loss 1.19 on epoch=5
05/22/2022 07:21:16 - INFO - __main__ - Step 170 Global step 170 Train loss 1.38 on epoch=6
05/22/2022 07:21:19 - INFO - __main__ - Step 180 Global step 180 Train loss 1.18 on epoch=6
05/22/2022 07:21:21 - INFO - __main__ - Step 190 Global step 190 Train loss 1.03 on epoch=6
05/22/2022 07:21:24 - INFO - __main__ - Step 200 Global step 200 Train loss 0.98 on epoch=7
05/22/2022 07:21:35 - INFO - __main__ - Global step 200 Train loss 1.15 Classification-F1 0.18963136185815974 on epoch=7
05/22/2022 07:21:35 - INFO - __main__ - Saving model with best Classification-F1: 0.11877049301895512 -> 0.18963136185815974 on epoch=7, global_step=200
05/22/2022 07:21:37 - INFO - __main__ - Step 210 Global step 210 Train loss 0.99 on epoch=7
05/22/2022 07:21:40 - INFO - __main__ - Step 220 Global step 220 Train loss 0.66 on epoch=7
05/22/2022 07:21:43 - INFO - __main__ - Step 230 Global step 230 Train loss 0.82 on epoch=8
05/22/2022 07:21:45 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=8
05/22/2022 07:21:48 - INFO - __main__ - Step 250 Global step 250 Train loss 0.70 on epoch=8
05/22/2022 07:22:00 - INFO - __main__ - Global step 250 Train loss 0.79 Classification-F1 0.3088402443282905 on epoch=8
05/22/2022 07:22:00 - INFO - __main__ - Saving model with best Classification-F1: 0.18963136185815974 -> 0.3088402443282905 on epoch=8, global_step=250
05/22/2022 07:22:02 - INFO - __main__ - Step 260 Global step 260 Train loss 0.64 on epoch=9
05/22/2022 07:22:05 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=9
05/22/2022 07:22:07 - INFO - __main__ - Step 280 Global step 280 Train loss 0.57 on epoch=9
05/22/2022 07:22:10 - INFO - __main__ - Step 290 Global step 290 Train loss 0.48 on epoch=10
05/22/2022 07:22:12 - INFO - __main__ - Step 300 Global step 300 Train loss 0.49 on epoch=10
05/22/2022 07:22:25 - INFO - __main__ - Global step 300 Train loss 0.54 Classification-F1 0.38248274719665093 on epoch=10
05/22/2022 07:22:25 - INFO - __main__ - Saving model with best Classification-F1: 0.3088402443282905 -> 0.38248274719665093 on epoch=10, global_step=300
05/22/2022 07:22:28 - INFO - __main__ - Step 310 Global step 310 Train loss 0.44 on epoch=11
05/22/2022 07:22:30 - INFO - __main__ - Step 320 Global step 320 Train loss 0.44 on epoch=11
05/22/2022 07:22:33 - INFO - __main__ - Step 330 Global step 330 Train loss 0.38 on epoch=11
05/22/2022 07:22:35 - INFO - __main__ - Step 340 Global step 340 Train loss 0.45 on epoch=12
05/22/2022 07:22:38 - INFO - __main__ - Step 350 Global step 350 Train loss 0.38 on epoch=12
05/22/2022 07:22:51 - INFO - __main__ - Global step 350 Train loss 0.42 Classification-F1 0.45207254288359616 on epoch=12
05/22/2022 07:22:51 - INFO - __main__ - Saving model with best Classification-F1: 0.38248274719665093 -> 0.45207254288359616 on epoch=12, global_step=350
05/22/2022 07:22:53 - INFO - __main__ - Step 360 Global step 360 Train loss 0.42 on epoch=12
05/22/2022 07:22:56 - INFO - __main__ - Step 370 Global step 370 Train loss 0.36 on epoch=13
05/22/2022 07:22:58 - INFO - __main__ - Step 380 Global step 380 Train loss 0.37 on epoch=13
05/22/2022 07:23:01 - INFO - __main__ - Step 390 Global step 390 Train loss 0.32 on epoch=13
05/22/2022 07:23:03 - INFO - __main__ - Step 400 Global step 400 Train loss 0.35 on epoch=14
05/22/2022 07:23:17 - INFO - __main__ - Global step 400 Train loss 0.37 Classification-F1 0.4640550838076943 on epoch=14
05/22/2022 07:23:17 - INFO - __main__ - Saving model with best Classification-F1: 0.45207254288359616 -> 0.4640550838076943 on epoch=14, global_step=400
05/22/2022 07:23:19 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=14
05/22/2022 07:23:22 - INFO - __main__ - Step 420 Global step 420 Train loss 0.31 on epoch=14
05/22/2022 07:23:24 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=15
05/22/2022 07:23:27 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=15
05/22/2022 07:23:30 - INFO - __main__ - Step 450 Global step 450 Train loss 0.26 on epoch=16
05/22/2022 07:23:42 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.5469636872491422 on epoch=16
05/22/2022 07:23:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4640550838076943 -> 0.5469636872491422 on epoch=16, global_step=450
05/22/2022 07:23:45 - INFO - __main__ - Step 460 Global step 460 Train loss 0.27 on epoch=16
05/22/2022 07:23:48 - INFO - __main__ - Step 470 Global step 470 Train loss 0.26 on epoch=16
05/22/2022 07:23:50 - INFO - __main__ - Step 480 Global step 480 Train loss 0.23 on epoch=17
05/22/2022 07:23:53 - INFO - __main__ - Step 490 Global step 490 Train loss 0.18 on epoch=17
05/22/2022 07:23:55 - INFO - __main__ - Step 500 Global step 500 Train loss 0.22 on epoch=17
05/22/2022 07:24:08 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.5436102091966376 on epoch=17
05/22/2022 07:24:11 - INFO - __main__ - Step 510 Global step 510 Train loss 0.25 on epoch=18
05/22/2022 07:24:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.23 on epoch=18
05/22/2022 07:24:16 - INFO - __main__ - Step 530 Global step 530 Train loss 0.20 on epoch=18
05/22/2022 07:24:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.25 on epoch=19
05/22/2022 07:24:21 - INFO - __main__ - Step 550 Global step 550 Train loss 0.20 on epoch=19
05/22/2022 07:24:33 - INFO - __main__ - Global step 550 Train loss 0.23 Classification-F1 0.5787922129537317 on epoch=19
05/22/2022 07:24:33 - INFO - __main__ - Saving model with best Classification-F1: 0.5469636872491422 -> 0.5787922129537317 on epoch=19, global_step=550
05/22/2022 07:24:36 - INFO - __main__ - Step 560 Global step 560 Train loss 0.24 on epoch=19
05/22/2022 07:24:38 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=20
05/22/2022 07:24:41 - INFO - __main__ - Step 580 Global step 580 Train loss 0.19 on epoch=20
05/22/2022 07:24:44 - INFO - __main__ - Step 590 Global step 590 Train loss 0.17 on epoch=21
05/22/2022 07:24:46 - INFO - __main__ - Step 600 Global step 600 Train loss 0.19 on epoch=21
05/22/2022 07:24:59 - INFO - __main__ - Global step 600 Train loss 0.20 Classification-F1 0.5792981298991863 on epoch=21
05/22/2022 07:24:59 - INFO - __main__ - Saving model with best Classification-F1: 0.5787922129537317 -> 0.5792981298991863 on epoch=21, global_step=600
05/22/2022 07:25:01 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=21
05/22/2022 07:25:04 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=22
05/22/2022 07:25:06 - INFO - __main__ - Step 630 Global step 630 Train loss 0.16 on epoch=22
05/22/2022 07:25:09 - INFO - __main__ - Step 640 Global step 640 Train loss 0.21 on epoch=22
05/22/2022 07:25:12 - INFO - __main__ - Step 650 Global step 650 Train loss 0.11 on epoch=23
05/22/2022 07:25:24 - INFO - __main__ - Global step 650 Train loss 0.18 Classification-F1 0.6583677719943214 on epoch=23
05/22/2022 07:25:24 - INFO - __main__ - Saving model with best Classification-F1: 0.5792981298991863 -> 0.6583677719943214 on epoch=23, global_step=650
05/22/2022 07:25:27 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=23
05/22/2022 07:25:30 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=23
05/22/2022 07:25:32 - INFO - __main__ - Step 680 Global step 680 Train loss 0.20 on epoch=24
05/22/2022 07:25:35 - INFO - __main__ - Step 690 Global step 690 Train loss 0.13 on epoch=24
05/22/2022 07:25:37 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=24
05/22/2022 07:25:50 - INFO - __main__ - Global step 700 Train loss 0.17 Classification-F1 0.6659161565114973 on epoch=24
05/22/2022 07:25:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6583677719943214 -> 0.6659161565114973 on epoch=24, global_step=700
05/22/2022 07:25:53 - INFO - __main__ - Step 710 Global step 710 Train loss 0.15 on epoch=25
05/22/2022 07:25:55 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=25
05/22/2022 07:25:58 - INFO - __main__ - Step 730 Global step 730 Train loss 0.15 on epoch=26
05/22/2022 07:26:00 - INFO - __main__ - Step 740 Global step 740 Train loss 0.18 on epoch=26
05/22/2022 07:26:03 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=26
05/22/2022 07:26:15 - INFO - __main__ - Global step 750 Train loss 0.17 Classification-F1 0.6087171405143755 on epoch=26
05/22/2022 07:26:18 - INFO - __main__ - Step 760 Global step 760 Train loss 0.11 on epoch=27
05/22/2022 07:26:20 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=27
05/22/2022 07:26:23 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=27
05/22/2022 07:26:26 - INFO - __main__ - Step 790 Global step 790 Train loss 0.13 on epoch=28
05/22/2022 07:26:28 - INFO - __main__ - Step 800 Global step 800 Train loss 0.12 on epoch=28
05/22/2022 07:26:41 - INFO - __main__ - Global step 800 Train loss 0.14 Classification-F1 0.6505135667954004 on epoch=28
05/22/2022 07:26:43 - INFO - __main__ - Step 810 Global step 810 Train loss 0.16 on epoch=28
05/22/2022 07:26:46 - INFO - __main__ - Step 820 Global step 820 Train loss 0.12 on epoch=29
05/22/2022 07:26:49 - INFO - __main__ - Step 830 Global step 830 Train loss 0.08 on epoch=29
05/22/2022 07:26:51 - INFO - __main__ - Step 840 Global step 840 Train loss 0.11 on epoch=29
05/22/2022 07:26:54 - INFO - __main__ - Step 850 Global step 850 Train loss 0.10 on epoch=30
05/22/2022 07:27:06 - INFO - __main__ - Global step 850 Train loss 0.12 Classification-F1 0.641026831748159 on epoch=30
05/22/2022 07:27:09 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=30
05/22/2022 07:27:12 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=31
05/22/2022 07:27:14 - INFO - __main__ - Step 880 Global step 880 Train loss 0.11 on epoch=31
05/22/2022 07:27:17 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=31
05/22/2022 07:27:19 - INFO - __main__ - Step 900 Global step 900 Train loss 0.10 on epoch=32
05/22/2022 07:27:31 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.5677263542057512 on epoch=32
05/22/2022 07:27:34 - INFO - __main__ - Step 910 Global step 910 Train loss 0.08 on epoch=32
05/22/2022 07:27:36 - INFO - __main__ - Step 920 Global step 920 Train loss 0.07 on epoch=32
05/22/2022 07:27:39 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=33
05/22/2022 07:27:41 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=33
05/22/2022 07:27:44 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=33
05/22/2022 07:27:56 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.5495406009870302 on epoch=33
05/22/2022 07:27:59 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=34
05/22/2022 07:28:01 - INFO - __main__ - Step 970 Global step 970 Train loss 0.08 on epoch=34
05/22/2022 07:28:04 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=34
05/22/2022 07:28:06 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=35
05/22/2022 07:28:09 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=35
05/22/2022 07:28:21 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.5820411260293958 on epoch=35
05/22/2022 07:28:24 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.08 on epoch=36
05/22/2022 07:28:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=36
05/22/2022 07:28:29 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.10 on epoch=36
05/22/2022 07:28:32 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=37
05/22/2022 07:28:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=37
05/22/2022 07:28:46 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6053059669168666 on epoch=37
05/22/2022 07:28:49 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.07 on epoch=37
05/22/2022 07:28:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.13 on epoch=38
05/22/2022 07:28:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.10 on epoch=38
05/22/2022 07:28:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.09 on epoch=38
05/22/2022 07:28:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.07 on epoch=39
05/22/2022 07:29:11 - INFO - __main__ - Global step 1100 Train loss 0.09 Classification-F1 0.6028167591814407 on epoch=39
05/22/2022 07:29:13 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=39
05/22/2022 07:29:16 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=39
05/22/2022 07:29:18 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.10 on epoch=40
05/22/2022 07:29:21 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.12 on epoch=40
05/22/2022 07:29:23 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=41
05/22/2022 07:29:35 - INFO - __main__ - Global step 1150 Train loss 0.10 Classification-F1 0.5606256287883216 on epoch=41
05/22/2022 07:29:38 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=41
05/22/2022 07:29:40 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=41
05/22/2022 07:29:43 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.04 on epoch=42
05/22/2022 07:29:46 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.06 on epoch=42
05/22/2022 07:29:48 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.06 on epoch=42
05/22/2022 07:30:00 - INFO - __main__ - Global step 1200 Train loss 0.07 Classification-F1 0.6423596459641341 on epoch=42
05/22/2022 07:30:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.06 on epoch=43
05/22/2022 07:30:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.05 on epoch=43
05/22/2022 07:30:08 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.09 on epoch=43
05/22/2022 07:30:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.07 on epoch=44
05/22/2022 07:30:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.05 on epoch=44
05/22/2022 07:30:25 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.6374540513526422 on epoch=44
05/22/2022 07:30:27 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.10 on epoch=44
05/22/2022 07:30:30 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.07 on epoch=45
05/22/2022 07:30:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.08 on epoch=45
05/22/2022 07:30:35 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=46
05/22/2022 07:30:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=46
05/22/2022 07:30:50 - INFO - __main__ - Global step 1300 Train loss 0.08 Classification-F1 0.7328472504604566 on epoch=46
05/22/2022 07:30:50 - INFO - __main__ - Saving model with best Classification-F1: 0.6659161565114973 -> 0.7328472504604566 on epoch=46, global_step=1300
05/22/2022 07:30:53 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.08 on epoch=46
05/22/2022 07:30:55 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=47
05/22/2022 07:30:58 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=47
05/22/2022 07:31:01 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=47
05/22/2022 07:31:03 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.08 on epoch=48
05/22/2022 07:31:15 - INFO - __main__ - Global step 1350 Train loss 0.07 Classification-F1 0.7625140971642979 on epoch=48
05/22/2022 07:31:15 - INFO - __main__ - Saving model with best Classification-F1: 0.7328472504604566 -> 0.7625140971642979 on epoch=48, global_step=1350
05/22/2022 07:31:18 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=48
05/22/2022 07:31:21 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.08 on epoch=48
05/22/2022 07:31:23 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=49
05/22/2022 07:31:26 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.03 on epoch=49
05/22/2022 07:31:28 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=49
05/22/2022 07:31:41 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.7611080445471725 on epoch=49
05/22/2022 07:31:43 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=50
05/22/2022 07:31:46 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=50
05/22/2022 07:31:49 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=51
05/22/2022 07:31:51 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=51
05/22/2022 07:31:54 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.08 on epoch=51
05/22/2022 07:32:06 - INFO - __main__ - Global step 1450 Train loss 0.06 Classification-F1 0.7178685648505952 on epoch=51
05/22/2022 07:32:08 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.05 on epoch=52
05/22/2022 07:32:11 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.07 on epoch=52
05/22/2022 07:32:14 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=52
05/22/2022 07:32:16 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=53
05/22/2022 07:32:19 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.04 on epoch=53
05/22/2022 07:32:31 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.6044346811030167 on epoch=53
05/22/2022 07:32:34 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.10 on epoch=53
05/22/2022 07:32:36 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=54
05/22/2022 07:32:39 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.03 on epoch=54
05/22/2022 07:32:41 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.05 on epoch=54
05/22/2022 07:32:44 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.09 on epoch=55
05/22/2022 07:32:56 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.6749888796759013 on epoch=55
05/22/2022 07:32:59 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.10 on epoch=55
05/22/2022 07:33:01 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=56
05/22/2022 07:33:04 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.06 on epoch=56
05/22/2022 07:33:06 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.06 on epoch=56
05/22/2022 07:33:09 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=57
05/22/2022 07:33:21 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7117584905621115 on epoch=57
05/22/2022 07:33:24 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=57
05/22/2022 07:33:26 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.10 on epoch=57
05/22/2022 07:33:29 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.08 on epoch=58
05/22/2022 07:33:31 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=58
05/22/2022 07:33:34 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=58
05/22/2022 07:33:46 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.6184217179004518 on epoch=58
05/22/2022 07:33:49 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=59
05/22/2022 07:33:51 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=59
05/22/2022 07:33:54 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.10 on epoch=59
05/22/2022 07:33:57 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=60
05/22/2022 07:33:59 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.05 on epoch=60
05/22/2022 07:34:11 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.6451635819377755 on epoch=60
05/22/2022 07:34:14 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=61
05/22/2022 07:34:17 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=61
05/22/2022 07:34:19 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.07 on epoch=61
05/22/2022 07:34:22 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=62
05/22/2022 07:34:24 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 07:34:37 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.6526074495974336 on epoch=62
05/22/2022 07:34:39 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.06 on epoch=62
05/22/2022 07:34:42 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.02 on epoch=63
05/22/2022 07:34:44 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=63
05/22/2022 07:34:47 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=63
05/22/2022 07:34:50 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=64
05/22/2022 07:35:02 - INFO - __main__ - Global step 1800 Train loss 0.04 Classification-F1 0.6539274938770906 on epoch=64
05/22/2022 07:35:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=64
05/22/2022 07:35:07 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.05 on epoch=64
05/22/2022 07:35:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.03 on epoch=65
05/22/2022 07:35:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.06 on epoch=65
05/22/2022 07:35:15 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=66
05/22/2022 07:35:27 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.5870729991888903 on epoch=66
05/22/2022 07:35:29 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=66
05/22/2022 07:35:32 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=66
05/22/2022 07:35:34 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=67
05/22/2022 07:35:37 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=67
05/22/2022 07:35:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=67
05/22/2022 07:35:52 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5688542832126282 on epoch=67
05/22/2022 07:35:54 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=68
05/22/2022 07:35:57 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=68
05/22/2022 07:36:00 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 07:36:02 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=69
05/22/2022 07:36:05 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.02 on epoch=69
05/22/2022 07:36:17 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.6214052769640327 on epoch=69
05/22/2022 07:36:19 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=69
05/22/2022 07:36:22 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=70
05/22/2022 07:36:24 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.07 on epoch=70
05/22/2022 07:36:27 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=71
05/22/2022 07:36:29 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=71
05/22/2022 07:36:42 - INFO - __main__ - Global step 2000 Train loss 0.04 Classification-F1 0.6725261349495899 on epoch=71
05/22/2022 07:36:44 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.05 on epoch=71
05/22/2022 07:36:47 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=72
05/22/2022 07:36:49 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=72
05/22/2022 07:36:52 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=72
05/22/2022 07:36:54 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=73
05/22/2022 07:37:06 - INFO - __main__ - Global step 2050 Train loss 0.03 Classification-F1 0.6485809520676055 on epoch=73
05/22/2022 07:37:09 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=73
05/22/2022 07:37:11 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.08 on epoch=73
05/22/2022 07:37:14 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=74
05/22/2022 07:37:17 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=74
05/22/2022 07:37:19 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=74
05/22/2022 07:37:31 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6141476862488069 on epoch=74
05/22/2022 07:37:34 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.03 on epoch=75
05/22/2022 07:37:36 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=75
05/22/2022 07:37:39 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.02 on epoch=76
05/22/2022 07:37:41 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=76
05/22/2022 07:37:44 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=76
05/22/2022 07:37:56 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6767417111943818 on epoch=76
05/22/2022 07:37:58 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=77
05/22/2022 07:38:01 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.05 on epoch=77
05/22/2022 07:38:04 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=77
05/22/2022 07:38:06 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=78
05/22/2022 07:38:09 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=78
05/22/2022 07:38:21 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7038970327638274 on epoch=78
05/22/2022 07:38:23 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=78
05/22/2022 07:38:26 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=79
05/22/2022 07:38:29 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=79
05/22/2022 07:38:31 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=79
05/22/2022 07:38:34 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 07:38:46 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.6829154630484544 on epoch=80
05/22/2022 07:38:48 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=80
05/22/2022 07:38:51 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.01 on epoch=81
05/22/2022 07:38:53 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=81
05/22/2022 07:38:56 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=81
05/22/2022 07:38:59 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=82
05/22/2022 07:39:11 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6901936280226671 on epoch=82
05/22/2022 07:39:13 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.05 on epoch=82
05/22/2022 07:39:16 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=82
05/22/2022 07:39:19 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=83
05/22/2022 07:39:21 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.05 on epoch=83
05/22/2022 07:39:24 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=83
05/22/2022 07:39:36 - INFO - __main__ - Global step 2350 Train loss 0.04 Classification-F1 0.689395043894195 on epoch=83
05/22/2022 07:39:39 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=84
05/22/2022 07:39:41 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.02 on epoch=84
05/22/2022 07:39:44 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=84
05/22/2022 07:39:46 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=85
05/22/2022 07:39:49 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.08 on epoch=85
05/22/2022 07:40:01 - INFO - __main__ - Global step 2400 Train loss 0.04 Classification-F1 0.6236440400172929 on epoch=85
05/22/2022 07:40:04 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=86
05/22/2022 07:40:06 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=86
05/22/2022 07:40:09 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=86
05/22/2022 07:40:11 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=87
05/22/2022 07:40:14 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=87
05/22/2022 07:40:27 - INFO - __main__ - Global step 2450 Train loss 0.03 Classification-F1 0.7413711783098248 on epoch=87
05/22/2022 07:40:29 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=87
05/22/2022 07:40:32 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=88
05/22/2022 07:40:34 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=88
05/22/2022 07:40:37 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=88
05/22/2022 07:40:40 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.03 on epoch=89
05/22/2022 07:40:52 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.7037757749632211 on epoch=89
05/22/2022 07:40:55 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=89
05/22/2022 07:40:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=89
05/22/2022 07:41:00 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=90
05/22/2022 07:41:03 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=90
05/22/2022 07:41:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=91
05/22/2022 07:41:18 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.7931540761670289 on epoch=91
05/22/2022 07:41:18 - INFO - __main__ - Saving model with best Classification-F1: 0.7625140971642979 -> 0.7931540761670289 on epoch=91, global_step=2550
05/22/2022 07:41:21 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=91
05/22/2022 07:41:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 07:41:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=92
05/22/2022 07:41:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=92
05/22/2022 07:41:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=92
05/22/2022 07:41:44 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7931540761670289 on epoch=92
05/22/2022 07:41:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.02 on epoch=93
05/22/2022 07:41:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.03 on epoch=93
05/22/2022 07:41:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.02 on epoch=93
05/22/2022 07:41:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 07:41:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.01 on epoch=94
05/22/2022 07:42:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.7984313884079484 on epoch=94
05/22/2022 07:42:10 - INFO - __main__ - Saving model with best Classification-F1: 0.7931540761670289 -> 0.7984313884079484 on epoch=94, global_step=2650
05/22/2022 07:42:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=94
05/22/2022 07:42:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=95
05/22/2022 07:42:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=95
05/22/2022 07:42:20 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=96
05/22/2022 07:42:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=96
05/22/2022 07:42:36 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.7267959252582187 on epoch=96
05/22/2022 07:42:38 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=96
05/22/2022 07:42:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.03 on epoch=97
05/22/2022 07:42:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=97
05/22/2022 07:42:46 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=97
05/22/2022 07:42:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=98
05/22/2022 07:43:02 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.6985325874301354 on epoch=98
05/22/2022 07:43:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.00 on epoch=98
05/22/2022 07:43:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=98
05/22/2022 07:43:09 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=99
05/22/2022 07:43:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=99
05/22/2022 07:43:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=99
05/22/2022 07:43:27 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6982768396822808 on epoch=99
05/22/2022 07:43:30 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=100
05/22/2022 07:43:33 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.09 on epoch=100
05/22/2022 07:43:35 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=101
05/22/2022 07:43:38 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.00 on epoch=101
05/22/2022 07:43:41 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=101
05/22/2022 07:43:53 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.756704910772673 on epoch=101
05/22/2022 07:43:56 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=102
05/22/2022 07:43:59 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=102
05/22/2022 07:44:01 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=102
05/22/2022 07:44:04 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=103
05/22/2022 07:44:07 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.04 on epoch=103
05/22/2022 07:44:19 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7410009267697217 on epoch=103
05/22/2022 07:44:22 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=103
05/22/2022 07:44:25 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=104
05/22/2022 07:44:27 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=104
05/22/2022 07:44:30 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 07:44:33 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=105
05/22/2022 07:44:45 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7850371161527318 on epoch=105
05/22/2022 07:44:48 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 07:44:51 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 07:44:53 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 07:44:56 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=106
05/22/2022 07:44:58 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=107
05/22/2022 07:45:00 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:45:00 - INFO - __main__ - Printing 3 examples
05/22/2022 07:45:00 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 07:45:00 - INFO - __main__ - ['Plant']
05/22/2022 07:45:00 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 07:45:00 - INFO - __main__ - ['Plant']
05/22/2022 07:45:00 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 07:45:00 - INFO - __main__ - ['Plant']
05/22/2022 07:45:00 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:45:00 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:45:01 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 07:45:01 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:45:01 - INFO - __main__ - Printing 3 examples
05/22/2022 07:45:01 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 07:45:01 - INFO - __main__ - ['Plant']
05/22/2022 07:45:01 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:45:01 - INFO - __main__ - ['Plant']
05/22/2022 07:45:01 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:45:01 - INFO - __main__ - ['Plant']
05/22/2022 07:45:01 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:45:01 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:45:01 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 07:45:11 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.7899743818044497 on epoch=107
05/22/2022 07:45:11 - INFO - __main__ - save last model!
05/22/2022 07:45:12 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 07:45:12 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 07:45:12 - INFO - __main__ - Printing 3 examples
05/22/2022 07:45:12 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 07:45:12 - INFO - __main__ - ['Animal']
05/22/2022 07:45:12 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 07:45:12 - INFO - __main__ - ['Animal']
05/22/2022 07:45:12 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 07:45:12 - INFO - __main__ - ['Village']
05/22/2022 07:45:12 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:45:14 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:45:17 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 07:45:17 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 07:45:18 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 07:45:18 - INFO - __main__ - Starting training!
05/22/2022 07:47:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_21_0.4_8_predictions.txt
05/22/2022 07:47:29 - INFO - __main__ - Classification-F1 on test data: 0.4990
05/22/2022 07:47:30 - INFO - __main__ - prefix=dbpedia_14_32_21, lr=0.4, bsz=8, dev_performance=0.7984313884079484, test_performance=0.49899207802143697
05/22/2022 07:47:30 - INFO - __main__ - Running ... prefix=dbpedia_14_32_21, lr=0.3, bsz=8 ...
05/22/2022 07:47:31 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:47:31 - INFO - __main__ - Printing 3 examples
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:47:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:47:31 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 07:47:31 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 07:47:31 - INFO - __main__ - Printing 3 examples
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 07:47:31 - INFO - __main__ - ['Plant']
05/22/2022 07:47:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 07:47:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 07:47:32 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 07:47:48 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 07:47:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 07:47:49 - INFO - __main__ - Starting training!
05/22/2022 07:47:52 - INFO - __main__ - Step 10 Global step 10 Train loss 7.29 on epoch=0
05/22/2022 07:47:55 - INFO - __main__ - Step 20 Global step 20 Train loss 5.11 on epoch=0
05/22/2022 07:47:57 - INFO - __main__ - Step 30 Global step 30 Train loss 4.76 on epoch=1
05/22/2022 07:48:00 - INFO - __main__ - Step 40 Global step 40 Train loss 4.37 on epoch=1
05/22/2022 07:48:03 - INFO - __main__ - Step 50 Global step 50 Train loss 3.52 on epoch=1
05/22/2022 07:48:18 - INFO - __main__ - Global step 50 Train loss 5.01 Classification-F1 0.015523314731717247 on epoch=1
05/22/2022 07:48:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.015523314731717247 on epoch=1, global_step=50
05/22/2022 07:48:20 - INFO - __main__ - Step 60 Global step 60 Train loss 3.40 on epoch=2
05/22/2022 07:48:23 - INFO - __main__ - Step 70 Global step 70 Train loss 3.14 on epoch=2
05/22/2022 07:48:25 - INFO - __main__ - Step 80 Global step 80 Train loss 2.49 on epoch=2
05/22/2022 07:48:28 - INFO - __main__ - Step 90 Global step 90 Train loss 2.76 on epoch=3
05/22/2022 07:48:30 - INFO - __main__ - Step 100 Global step 100 Train loss 2.36 on epoch=3
05/22/2022 07:48:43 - INFO - __main__ - Global step 100 Train loss 2.83 Classification-F1 0.04744872613725073 on epoch=3
05/22/2022 07:48:43 - INFO - __main__ - Saving model with best Classification-F1: 0.015523314731717247 -> 0.04744872613725073 on epoch=3, global_step=100
05/22/2022 07:48:46 - INFO - __main__ - Step 110 Global step 110 Train loss 2.14 on epoch=3
05/22/2022 07:48:48 - INFO - __main__ - Step 120 Global step 120 Train loss 2.28 on epoch=4
05/22/2022 07:48:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.79 on epoch=4
05/22/2022 07:48:53 - INFO - __main__ - Step 140 Global step 140 Train loss 1.96 on epoch=4
05/22/2022 07:48:56 - INFO - __main__ - Step 150 Global step 150 Train loss 2.01 on epoch=5
05/22/2022 07:49:07 - INFO - __main__ - Global step 150 Train loss 2.04 Classification-F1 0.08029230155288769 on epoch=5
05/22/2022 07:49:07 - INFO - __main__ - Saving model with best Classification-F1: 0.04744872613725073 -> 0.08029230155288769 on epoch=5, global_step=150
05/22/2022 07:49:10 - INFO - __main__ - Step 160 Global step 160 Train loss 1.56 on epoch=5
05/22/2022 07:49:12 - INFO - __main__ - Step 170 Global step 170 Train loss 1.65 on epoch=6
05/22/2022 07:49:15 - INFO - __main__ - Step 180 Global step 180 Train loss 1.58 on epoch=6
05/22/2022 07:49:17 - INFO - __main__ - Step 190 Global step 190 Train loss 1.34 on epoch=6
05/22/2022 07:49:20 - INFO - __main__ - Step 200 Global step 200 Train loss 1.49 on epoch=7
05/22/2022 07:49:31 - INFO - __main__ - Global step 200 Train loss 1.52 Classification-F1 0.14617333181280745 on epoch=7
05/22/2022 07:49:31 - INFO - __main__ - Saving model with best Classification-F1: 0.08029230155288769 -> 0.14617333181280745 on epoch=7, global_step=200
05/22/2022 07:49:34 - INFO - __main__ - Step 210 Global step 210 Train loss 1.29 on epoch=7
05/22/2022 07:49:36 - INFO - __main__ - Step 220 Global step 220 Train loss 1.10 on epoch=7
05/22/2022 07:49:39 - INFO - __main__ - Step 230 Global step 230 Train loss 1.24 on epoch=8
05/22/2022 07:49:41 - INFO - __main__ - Step 240 Global step 240 Train loss 1.12 on epoch=8
05/22/2022 07:49:44 - INFO - __main__ - Step 250 Global step 250 Train loss 1.06 on epoch=8
05/22/2022 07:49:55 - INFO - __main__ - Global step 250 Train loss 1.16 Classification-F1 0.209404997199585 on epoch=8
05/22/2022 07:49:55 - INFO - __main__ - Saving model with best Classification-F1: 0.14617333181280745 -> 0.209404997199585 on epoch=8, global_step=250
05/22/2022 07:49:57 - INFO - __main__ - Step 260 Global step 260 Train loss 1.03 on epoch=9
05/22/2022 07:50:00 - INFO - __main__ - Step 270 Global step 270 Train loss 0.75 on epoch=9
05/22/2022 07:50:03 - INFO - __main__ - Step 280 Global step 280 Train loss 0.81 on epoch=9
05/22/2022 07:50:05 - INFO - __main__ - Step 290 Global step 290 Train loss 0.69 on epoch=10
05/22/2022 07:50:08 - INFO - __main__ - Step 300 Global step 300 Train loss 0.66 on epoch=10
05/22/2022 07:50:19 - INFO - __main__ - Global step 300 Train loss 0.79 Classification-F1 0.29748391284339 on epoch=10
05/22/2022 07:50:19 - INFO - __main__ - Saving model with best Classification-F1: 0.209404997199585 -> 0.29748391284339 on epoch=10, global_step=300
05/22/2022 07:50:22 - INFO - __main__ - Step 310 Global step 310 Train loss 0.66 on epoch=11
05/22/2022 07:50:24 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=11
05/22/2022 07:50:27 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=11
05/22/2022 07:50:30 - INFO - __main__ - Step 340 Global step 340 Train loss 0.56 on epoch=12
05/22/2022 07:50:32 - INFO - __main__ - Step 350 Global step 350 Train loss 0.47 on epoch=12
05/22/2022 07:50:45 - INFO - __main__ - Global step 350 Train loss 0.58 Classification-F1 0.2936948550121759 on epoch=12
05/22/2022 07:50:47 - INFO - __main__ - Step 360 Global step 360 Train loss 0.47 on epoch=12
05/22/2022 07:50:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.59 on epoch=13
05/22/2022 07:50:52 - INFO - __main__ - Step 380 Global step 380 Train loss 0.50 on epoch=13
05/22/2022 07:50:55 - INFO - __main__ - Step 390 Global step 390 Train loss 0.48 on epoch=13
05/22/2022 07:50:57 - INFO - __main__ - Step 400 Global step 400 Train loss 0.49 on epoch=14
05/22/2022 07:51:10 - INFO - __main__ - Global step 400 Train loss 0.51 Classification-F1 0.34117581757676857 on epoch=14
05/22/2022 07:51:10 - INFO - __main__ - Saving model with best Classification-F1: 0.29748391284339 -> 0.34117581757676857 on epoch=14, global_step=400
05/22/2022 07:51:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.30 on epoch=14
05/22/2022 07:51:15 - INFO - __main__ - Step 420 Global step 420 Train loss 0.49 on epoch=14
05/22/2022 07:51:18 - INFO - __main__ - Step 430 Global step 430 Train loss 0.43 on epoch=15
05/22/2022 07:51:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=15
05/22/2022 07:51:23 - INFO - __main__ - Step 450 Global step 450 Train loss 0.39 on epoch=16
05/22/2022 07:51:36 - INFO - __main__ - Global step 450 Train loss 0.40 Classification-F1 0.4363371330360229 on epoch=16
05/22/2022 07:51:36 - INFO - __main__ - Saving model with best Classification-F1: 0.34117581757676857 -> 0.4363371330360229 on epoch=16, global_step=450
05/22/2022 07:51:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.37 on epoch=16
05/22/2022 07:51:41 - INFO - __main__ - Step 470 Global step 470 Train loss 0.33 on epoch=16
05/22/2022 07:51:44 - INFO - __main__ - Step 480 Global step 480 Train loss 0.34 on epoch=17
05/22/2022 07:51:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.29 on epoch=17
05/22/2022 07:51:49 - INFO - __main__ - Step 500 Global step 500 Train loss 0.29 on epoch=17
05/22/2022 07:52:01 - INFO - __main__ - Global step 500 Train loss 0.33 Classification-F1 0.4721665522163568 on epoch=17
05/22/2022 07:52:01 - INFO - __main__ - Saving model with best Classification-F1: 0.4363371330360229 -> 0.4721665522163568 on epoch=17, global_step=500
05/22/2022 07:52:04 - INFO - __main__ - Step 510 Global step 510 Train loss 0.31 on epoch=18
05/22/2022 07:52:07 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=18
05/22/2022 07:52:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.41 on epoch=18
05/22/2022 07:52:12 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=19
05/22/2022 07:52:15 - INFO - __main__ - Step 550 Global step 550 Train loss 0.28 on epoch=19
05/22/2022 07:52:27 - INFO - __main__ - Global step 550 Train loss 0.33 Classification-F1 0.4442510566846221 on epoch=19
05/22/2022 07:52:30 - INFO - __main__ - Step 560 Global step 560 Train loss 0.32 on epoch=19
05/22/2022 07:52:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.33 on epoch=20
05/22/2022 07:52:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=20
05/22/2022 07:52:38 - INFO - __main__ - Step 590 Global step 590 Train loss 0.27 on epoch=21
05/22/2022 07:52:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.21 on epoch=21
05/22/2022 07:52:53 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.5145123439116818 on epoch=21
05/22/2022 07:52:53 - INFO - __main__ - Saving model with best Classification-F1: 0.4721665522163568 -> 0.5145123439116818 on epoch=21, global_step=600
05/22/2022 07:52:56 - INFO - __main__ - Step 610 Global step 610 Train loss 0.35 on epoch=21
05/22/2022 07:52:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.29 on epoch=22
05/22/2022 07:53:01 - INFO - __main__ - Step 630 Global step 630 Train loss 0.28 on epoch=22
05/22/2022 07:53:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=22
05/22/2022 07:53:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=23
05/22/2022 07:53:19 - INFO - __main__ - Global step 650 Train loss 0.28 Classification-F1 0.5384887459248854 on epoch=23
05/22/2022 07:53:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5145123439116818 -> 0.5384887459248854 on epoch=23, global_step=650
05/22/2022 07:53:22 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=23
05/22/2022 07:53:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.20 on epoch=23
05/22/2022 07:53:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.23 on epoch=24
05/22/2022 07:53:30 - INFO - __main__ - Step 690 Global step 690 Train loss 0.22 on epoch=24
05/22/2022 07:53:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.16 on epoch=24
05/22/2022 07:53:45 - INFO - __main__ - Global step 700 Train loss 0.21 Classification-F1 0.5440784207198368 on epoch=24
05/22/2022 07:53:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5384887459248854 -> 0.5440784207198368 on epoch=24, global_step=700
05/22/2022 07:53:47 - INFO - __main__ - Step 710 Global step 710 Train loss 0.26 on epoch=25
05/22/2022 07:53:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.20 on epoch=25
05/22/2022 07:53:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.21 on epoch=26
05/22/2022 07:53:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.23 on epoch=26
05/22/2022 07:53:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.22 on epoch=26
05/22/2022 07:54:10 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.5572275045235728 on epoch=26
05/22/2022 07:54:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5440784207198368 -> 0.5572275045235728 on epoch=26, global_step=750
05/22/2022 07:54:13 - INFO - __main__ - Step 760 Global step 760 Train loss 0.21 on epoch=27
05/22/2022 07:54:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.18 on epoch=27
05/22/2022 07:54:18 - INFO - __main__ - Step 780 Global step 780 Train loss 0.19 on epoch=27
05/22/2022 07:54:21 - INFO - __main__ - Step 790 Global step 790 Train loss 0.19 on epoch=28
05/22/2022 07:54:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.19 on epoch=28
05/22/2022 07:54:37 - INFO - __main__ - Global step 800 Train loss 0.19 Classification-F1 0.5187069226835562 on epoch=28
05/22/2022 07:54:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.19 on epoch=28
05/22/2022 07:54:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=29
05/22/2022 07:54:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.13 on epoch=29
05/22/2022 07:54:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.15 on epoch=29
05/22/2022 07:54:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.18 on epoch=30
05/22/2022 07:55:02 - INFO - __main__ - Global step 850 Train loss 0.18 Classification-F1 0.6064902486342546 on epoch=30
05/22/2022 07:55:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5572275045235728 -> 0.6064902486342546 on epoch=30, global_step=850
05/22/2022 07:55:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.15 on epoch=30
05/22/2022 07:55:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=31
05/22/2022 07:55:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=31
05/22/2022 07:55:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=31
05/22/2022 07:55:15 - INFO - __main__ - Step 900 Global step 900 Train loss 0.13 on epoch=32
05/22/2022 07:55:28 - INFO - __main__ - Global step 900 Train loss 0.14 Classification-F1 0.5155890735525612 on epoch=32
05/22/2022 07:55:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=32
05/22/2022 07:55:33 - INFO - __main__ - Step 920 Global step 920 Train loss 0.11 on epoch=32
05/22/2022 07:55:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.17 on epoch=33
05/22/2022 07:55:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=33
05/22/2022 07:55:41 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=33
05/22/2022 07:55:54 - INFO - __main__ - Global step 950 Train loss 0.14 Classification-F1 0.4869116665026999 on epoch=33
05/22/2022 07:55:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=34
05/22/2022 07:55:59 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=34
05/22/2022 07:56:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=34
05/22/2022 07:56:04 - INFO - __main__ - Step 990 Global step 990 Train loss 0.14 on epoch=35
05/22/2022 07:56:07 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.12 on epoch=35
05/22/2022 07:56:20 - INFO - __main__ - Global step 1000 Train loss 0.12 Classification-F1 0.5284886294611052 on epoch=35
05/22/2022 07:56:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=36
05/22/2022 07:56:25 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=36
05/22/2022 07:56:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.16 on epoch=36
05/22/2022 07:56:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.10 on epoch=37
05/22/2022 07:56:33 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=37
05/22/2022 07:56:46 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.513565912591977 on epoch=37
05/22/2022 07:56:48 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.10 on epoch=37
05/22/2022 07:56:51 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.10 on epoch=38
05/22/2022 07:56:54 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.18 on epoch=38
05/22/2022 07:56:56 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.12 on epoch=38
05/22/2022 07:56:59 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.15 on epoch=39
05/22/2022 07:57:12 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.540788042614684 on epoch=39
05/22/2022 07:57:14 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.12 on epoch=39
05/22/2022 07:57:17 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=39
05/22/2022 07:57:20 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=40
05/22/2022 07:57:22 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.14 on epoch=40
05/22/2022 07:57:25 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=41
05/22/2022 07:57:38 - INFO - __main__ - Global step 1150 Train loss 0.12 Classification-F1 0.5562157582300102 on epoch=41
05/22/2022 07:57:40 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.13 on epoch=41
05/22/2022 07:57:43 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.08 on epoch=41
05/22/2022 07:57:46 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.14 on epoch=42
05/22/2022 07:57:48 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=42
05/22/2022 07:57:51 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=42
05/22/2022 07:58:03 - INFO - __main__ - Global step 1200 Train loss 0.10 Classification-F1 0.5707233409862262 on epoch=42
05/22/2022 07:58:06 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=43
05/22/2022 07:58:09 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.09 on epoch=43
05/22/2022 07:58:11 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=43
05/22/2022 07:58:14 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=44
05/22/2022 07:58:17 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=44
05/22/2022 07:58:30 - INFO - __main__ - Global step 1250 Train loss 0.12 Classification-F1 0.673375025970862 on epoch=44
05/22/2022 07:58:30 - INFO - __main__ - Saving model with best Classification-F1: 0.6064902486342546 -> 0.673375025970862 on epoch=44, global_step=1250
05/22/2022 07:58:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.09 on epoch=44
05/22/2022 07:58:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.08 on epoch=45
05/22/2022 07:58:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.12 on epoch=45
05/22/2022 07:58:41 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.11 on epoch=46
05/22/2022 07:58:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.08 on epoch=46
05/22/2022 07:58:56 - INFO - __main__ - Global step 1300 Train loss 0.10 Classification-F1 0.6616867458285479 on epoch=46
05/22/2022 07:58:59 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.12 on epoch=46
05/22/2022 07:59:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=47
05/22/2022 07:59:04 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.09 on epoch=47
05/22/2022 07:59:07 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.10 on epoch=47
05/22/2022 07:59:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=48
05/22/2022 07:59:23 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6772599745095501 on epoch=48
05/22/2022 07:59:23 - INFO - __main__ - Saving model with best Classification-F1: 0.673375025970862 -> 0.6772599745095501 on epoch=48, global_step=1350
05/22/2022 07:59:25 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.06 on epoch=48
05/22/2022 07:59:28 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=48
05/22/2022 07:59:30 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=49
05/22/2022 07:59:33 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.05 on epoch=49
05/22/2022 07:59:36 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=49
05/22/2022 07:59:48 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6297256811556282 on epoch=49
05/22/2022 07:59:51 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=50
05/22/2022 07:59:54 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=50
05/22/2022 07:59:56 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=51
05/22/2022 07:59:59 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=51
05/22/2022 08:00:02 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.09 on epoch=51
05/22/2022 08:00:14 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.7617771182981187 on epoch=51
05/22/2022 08:00:14 - INFO - __main__ - Saving model with best Classification-F1: 0.6772599745095501 -> 0.7617771182981187 on epoch=51, global_step=1450
05/22/2022 08:00:17 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=52
05/22/2022 08:00:20 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=52
05/22/2022 08:00:22 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=52
05/22/2022 08:00:25 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=53
05/22/2022 08:00:28 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.09 on epoch=53
05/22/2022 08:00:40 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7865462924150194 on epoch=53
05/22/2022 08:00:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7617771182981187 -> 0.7865462924150194 on epoch=53, global_step=1500
05/22/2022 08:00:43 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=53
05/22/2022 08:00:46 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.09 on epoch=54
05/22/2022 08:00:48 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=54
05/22/2022 08:00:51 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.09 on epoch=54
05/22/2022 08:00:54 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.08 on epoch=55
05/22/2022 08:01:07 - INFO - __main__ - Global step 1550 Train loss 0.07 Classification-F1 0.7382870430127926 on epoch=55
05/22/2022 08:01:10 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=55
05/22/2022 08:01:12 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 08:01:15 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=56
05/22/2022 08:01:18 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=56
05/22/2022 08:01:20 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.08 on epoch=57
05/22/2022 08:01:34 - INFO - __main__ - Global step 1600 Train loss 0.06 Classification-F1 0.7785610326175884 on epoch=57
05/22/2022 08:01:36 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=57
05/22/2022 08:01:39 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=57
05/22/2022 08:01:42 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=58
05/22/2022 08:01:44 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=58
05/22/2022 08:01:47 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=58
05/22/2022 08:02:01 - INFO - __main__ - Global step 1650 Train loss 0.08 Classification-F1 0.8072790458781722 on epoch=58
05/22/2022 08:02:01 - INFO - __main__ - Saving model with best Classification-F1: 0.7865462924150194 -> 0.8072790458781722 on epoch=58, global_step=1650
05/22/2022 08:02:03 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=59
05/22/2022 08:02:06 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=59
05/22/2022 08:02:09 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.08 on epoch=59
05/22/2022 08:02:11 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.09 on epoch=60
05/22/2022 08:02:14 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=60
05/22/2022 08:02:27 - INFO - __main__ - Global step 1700 Train loss 0.07 Classification-F1 0.6945742516344309 on epoch=60
05/22/2022 08:02:30 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.10 on epoch=61
05/22/2022 08:02:32 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=61
05/22/2022 08:02:35 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.05 on epoch=61
05/22/2022 08:02:38 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=62
05/22/2022 08:02:40 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=62
05/22/2022 08:02:54 - INFO - __main__ - Global step 1750 Train loss 0.07 Classification-F1 0.7411459928973044 on epoch=62
05/22/2022 08:02:56 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=62
05/22/2022 08:02:59 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.06 on epoch=63
05/22/2022 08:03:02 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.05 on epoch=63
05/22/2022 08:03:04 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=63
05/22/2022 08:03:07 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=64
05/22/2022 08:03:20 - INFO - __main__ - Global step 1800 Train loss 0.07 Classification-F1 0.7829255076492377 on epoch=64
05/22/2022 08:03:23 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.05 on epoch=64
05/22/2022 08:03:25 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.06 on epoch=64
05/22/2022 08:03:28 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=65
05/22/2022 08:03:31 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=65
05/22/2022 08:03:33 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.03 on epoch=66
05/22/2022 08:03:46 - INFO - __main__ - Global step 1850 Train loss 0.06 Classification-F1 0.6636429957665057 on epoch=66
05/22/2022 08:03:49 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=66
05/22/2022 08:03:52 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=66
05/22/2022 08:03:54 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=67
05/22/2022 08:03:57 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.07 on epoch=67
05/22/2022 08:04:00 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=67
05/22/2022 08:04:12 - INFO - __main__ - Global step 1900 Train loss 0.06 Classification-F1 0.5908684393563426 on epoch=67
05/22/2022 08:04:15 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=68
05/22/2022 08:04:17 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 08:04:20 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=68
05/22/2022 08:04:23 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=69
05/22/2022 08:04:25 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=69
05/22/2022 08:04:38 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.7461807945495139 on epoch=69
05/22/2022 08:04:40 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.05 on epoch=69
05/22/2022 08:04:43 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=70
05/22/2022 08:04:46 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=70
05/22/2022 08:04:48 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.05 on epoch=71
05/22/2022 08:04:51 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=71
05/22/2022 08:05:04 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.7416702929935367 on epoch=71
05/22/2022 08:05:06 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.07 on epoch=71
05/22/2022 08:05:09 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=72
05/22/2022 08:05:12 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.06 on epoch=72
05/22/2022 08:05:14 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.05 on epoch=72
05/22/2022 08:05:17 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.06 on epoch=73
05/22/2022 08:05:29 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.682098741031052 on epoch=73
05/22/2022 08:05:32 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=73
05/22/2022 08:05:35 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.06 on epoch=73
05/22/2022 08:05:37 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=74
05/22/2022 08:05:40 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.02 on epoch=74
05/22/2022 08:05:43 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.07 on epoch=74
05/22/2022 08:05:55 - INFO - __main__ - Global step 2100 Train loss 0.06 Classification-F1 0.6546641159436546 on epoch=74
05/22/2022 08:05:58 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=75
05/22/2022 08:06:01 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=75
05/22/2022 08:06:03 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=76
05/22/2022 08:06:06 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=76
05/22/2022 08:06:08 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=76
05/22/2022 08:06:21 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.6335286015112865 on epoch=76
05/22/2022 08:06:23 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.08 on epoch=77
05/22/2022 08:06:26 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=77
05/22/2022 08:06:29 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=77
05/22/2022 08:06:31 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 08:06:34 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.03 on epoch=78
05/22/2022 08:06:46 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.6166697748138406 on epoch=78
05/22/2022 08:06:49 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.07 on epoch=78
05/22/2022 08:06:52 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=79
05/22/2022 08:06:54 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=79
05/22/2022 08:06:57 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=79
05/22/2022 08:07:00 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 08:07:12 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.6339664442976273 on epoch=80
05/22/2022 08:07:15 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.06 on epoch=80
05/22/2022 08:07:17 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=81
05/22/2022 08:07:20 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.04 on epoch=81
05/22/2022 08:07:23 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=81
05/22/2022 08:07:25 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=82
05/22/2022 08:07:37 - INFO - __main__ - Global step 2300 Train loss 0.04 Classification-F1 0.6454403537770472 on epoch=82
05/22/2022 08:07:40 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=82
05/22/2022 08:07:43 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.09 on epoch=82
05/22/2022 08:07:45 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=83
05/22/2022 08:07:48 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=83
05/22/2022 08:07:50 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.08 on epoch=83
05/22/2022 08:08:03 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.6851203958176079 on epoch=83
05/22/2022 08:08:05 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=84
05/22/2022 08:08:08 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=84
05/22/2022 08:08:10 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.10 on epoch=84
05/22/2022 08:08:13 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.05 on epoch=85
05/22/2022 08:08:16 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=85
05/22/2022 08:08:28 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.732161930313812 on epoch=85
05/22/2022 08:08:30 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=86
05/22/2022 08:08:33 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.03 on epoch=86
05/22/2022 08:08:35 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=86
05/22/2022 08:08:38 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.03 on epoch=87
05/22/2022 08:08:41 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=87
05/22/2022 08:08:53 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.6989480866709221 on epoch=87
05/22/2022 08:08:56 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=87
05/22/2022 08:08:58 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=88
05/22/2022 08:09:01 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.03 on epoch=88
05/22/2022 08:09:03 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=88
05/22/2022 08:09:06 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.05 on epoch=89
05/22/2022 08:09:18 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.6514995029611965 on epoch=89
05/22/2022 08:09:21 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.05 on epoch=89
05/22/2022 08:09:24 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=89
05/22/2022 08:09:26 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=90
05/22/2022 08:09:29 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=90
05/22/2022 08:09:31 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=91
05/22/2022 08:09:43 - INFO - __main__ - Global step 2550 Train loss 0.04 Classification-F1 0.5994860725167126 on epoch=91
05/22/2022 08:09:46 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=91
05/22/2022 08:09:49 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=91
05/22/2022 08:09:51 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.07 on epoch=92
05/22/2022 08:09:54 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.05 on epoch=92
05/22/2022 08:09:56 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.07 on epoch=92
05/22/2022 08:10:09 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.6973421046999826 on epoch=92
05/22/2022 08:10:11 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=93
05/22/2022 08:10:14 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.04 on epoch=93
05/22/2022 08:10:17 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=93
05/22/2022 08:10:19 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.02 on epoch=94
05/22/2022 08:10:22 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.03 on epoch=94
05/22/2022 08:10:35 - INFO - __main__ - Global step 2650 Train loss 0.04 Classification-F1 0.7945539079894198 on epoch=94
05/22/2022 08:10:37 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=94
05/22/2022 08:10:40 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=95
05/22/2022 08:10:43 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.07 on epoch=95
05/22/2022 08:10:45 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 08:10:48 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=96
05/22/2022 08:11:00 - INFO - __main__ - Global step 2700 Train loss 0.04 Classification-F1 0.8402318917241873 on epoch=96
05/22/2022 08:11:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8072790458781722 -> 0.8402318917241873 on epoch=96, global_step=2700
05/22/2022 08:11:03 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.08 on epoch=96
05/22/2022 08:11:05 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=97
05/22/2022 08:11:08 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=97
05/22/2022 08:11:11 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.03 on epoch=97
05/22/2022 08:11:13 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=98
05/22/2022 08:11:26 - INFO - __main__ - Global step 2750 Train loss 0.03 Classification-F1 0.8394922729600149 on epoch=98
05/22/2022 08:11:29 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.03 on epoch=98
05/22/2022 08:11:31 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.05 on epoch=98
05/22/2022 08:11:34 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=99
05/22/2022 08:11:36 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=99
05/22/2022 08:11:39 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=99
05/22/2022 08:11:52 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7965653649100463 on epoch=99
05/22/2022 08:11:54 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=100
05/22/2022 08:11:57 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.06 on epoch=100
05/22/2022 08:12:00 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 08:12:02 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=101
05/22/2022 08:12:05 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.07 on epoch=101
05/22/2022 08:12:17 - INFO - __main__ - Global step 2850 Train loss 0.04 Classification-F1 0.7831257297202595 on epoch=101
05/22/2022 08:12:20 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=102
05/22/2022 08:12:23 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=102
05/22/2022 08:12:25 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=102
05/22/2022 08:12:28 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=103
05/22/2022 08:12:30 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 08:12:43 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7385467490272801 on epoch=103
05/22/2022 08:12:45 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=103
05/22/2022 08:12:48 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.12 on epoch=104
05/22/2022 08:12:50 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=104
05/22/2022 08:12:53 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.06 on epoch=104
05/22/2022 08:12:56 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=105
05/22/2022 08:13:08 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.6266948617179031 on epoch=105
05/22/2022 08:13:10 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=105
05/22/2022 08:13:13 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=106
05/22/2022 08:13:15 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=106
05/22/2022 08:13:18 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.05 on epoch=106
05/22/2022 08:13:21 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=107
05/22/2022 08:13:22 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:13:22 - INFO - __main__ - Printing 3 examples
05/22/2022 08:13:22 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 08:13:22 - INFO - __main__ - ['Plant']
05/22/2022 08:13:22 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 08:13:22 - INFO - __main__ - ['Plant']
05/22/2022 08:13:22 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 08:13:22 - INFO - __main__ - ['Plant']
05/22/2022 08:13:22 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:13:22 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:13:23 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 08:13:23 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:13:23 - INFO - __main__ - Printing 3 examples
05/22/2022 08:13:23 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 08:13:23 - INFO - __main__ - ['Plant']
05/22/2022 08:13:23 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 08:13:23 - INFO - __main__ - ['Plant']
05/22/2022 08:13:23 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 08:13:23 - INFO - __main__ - ['Plant']
05/22/2022 08:13:23 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:13:23 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:13:23 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 08:13:33 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7517211467345876 on epoch=107
05/22/2022 08:13:33 - INFO - __main__ - save last model!
05/22/2022 08:13:33 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 08:13:33 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 08:13:33 - INFO - __main__ - Printing 3 examples
05/22/2022 08:13:33 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 08:13:33 - INFO - __main__ - ['Animal']
05/22/2022 08:13:33 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 08:13:33 - INFO - __main__ - ['Animal']
05/22/2022 08:13:33 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 08:13:33 - INFO - __main__ - ['Village']
05/22/2022 08:13:33 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:13:35 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:13:38 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 08:13:39 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 08:13:40 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 08:13:40 - INFO - __main__ - Starting training!
05/22/2022 08:15:44 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_21_0.3_8_predictions.txt
05/22/2022 08:15:44 - INFO - __main__ - Classification-F1 on test data: 0.5158
05/22/2022 08:15:45 - INFO - __main__ - prefix=dbpedia_14_32_21, lr=0.3, bsz=8, dev_performance=0.8402318917241873, test_performance=0.5157811910121048
05/22/2022 08:15:45 - INFO - __main__ - Running ... prefix=dbpedia_14_32_21, lr=0.2, bsz=8 ...
05/22/2022 08:15:45 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:15:45 - INFO - __main__ - Printing 3 examples
05/22/2022 08:15:45 - INFO - __main__ -  [dbpedia_14] Symplocos octopetala is a species of plant in the Symplocaceae family. It is endemic to Jamaica.
05/22/2022 08:15:45 - INFO - __main__ - ['Plant']
05/22/2022 08:15:45 - INFO - __main__ -  [dbpedia_14] Walsura is a genus of plant in family Meliaceae. It contains the following species (but this list may be incomplete): Walsura gardneri Thwaites Walsura pinnata Hassk. Walsura trifoliate Walsura
05/22/2022 08:15:45 - INFO - __main__ - ['Plant']
05/22/2022 08:15:45 - INFO - __main__ -  [dbpedia_14] Cystopteris is a genus of ferns in the family Cystopteridaceae. These are known generally as bladderferns or fragile ferns. They are found in temperate areas worldwide. This is a very diverse genus and within a species individuals can look quite different especially in harsh environments where they experience stress and remain small and stunted. Also they hybridize easily with each other. Identifying an individual can be challenging.
05/22/2022 08:15:45 - INFO - __main__ - ['Plant']
05/22/2022 08:15:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:15:46 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:15:46 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 08:15:46 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:15:46 - INFO - __main__ - Printing 3 examples
05/22/2022 08:15:46 - INFO - __main__ -  [dbpedia_14] Carex nigra (L.) Reichard (syn. C. acuta auct. non L.) is a perennial species of plants in the family Cyperaceae native to wetlands of Europe western Asia NW Africa and E North America. Common names include common sedge black sedge or smooth black sedge. The eastern limit of its range reaches central Siberia Turkey and probably Caucasus.
05/22/2022 08:15:46 - INFO - __main__ - ['Plant']
05/22/2022 08:15:46 - INFO - __main__ -  [dbpedia_14] Bulbophyllum calophyllum is a species of orchid in the genus Bulbophyllum.
05/22/2022 08:15:46 - INFO - __main__ - ['Plant']
05/22/2022 08:15:46 - INFO - __main__ -  [dbpedia_14] Bulbophyllum gymnopus is a species of orchid in the genus Bulbophyllum.
05/22/2022 08:15:46 - INFO - __main__ - ['Plant']
05/22/2022 08:15:46 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:15:46 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:15:47 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 08:16:03 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 08:16:03 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 08:16:03 - INFO - __main__ - Starting training!
05/22/2022 08:16:07 - INFO - __main__ - Step 10 Global step 10 Train loss 7.42 on epoch=0
05/22/2022 08:16:10 - INFO - __main__ - Step 20 Global step 20 Train loss 5.66 on epoch=0
05/22/2022 08:16:12 - INFO - __main__ - Step 30 Global step 30 Train loss 5.17 on epoch=1
05/22/2022 08:16:15 - INFO - __main__ - Step 40 Global step 40 Train loss 5.05 on epoch=1
05/22/2022 08:16:17 - INFO - __main__ - Step 50 Global step 50 Train loss 4.20 on epoch=1
05/22/2022 08:16:29 - INFO - __main__ - Global step 50 Train loss 5.50 Classification-F1 0.01821025713776459 on epoch=1
05/22/2022 08:16:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.01821025713776459 on epoch=1, global_step=50
05/22/2022 08:16:32 - INFO - __main__ - Step 60 Global step 60 Train loss 4.07 on epoch=2
05/22/2022 08:16:34 - INFO - __main__ - Step 70 Global step 70 Train loss 3.91 on epoch=2
05/22/2022 08:16:37 - INFO - __main__ - Step 80 Global step 80 Train loss 3.08 on epoch=2
05/22/2022 08:16:40 - INFO - __main__ - Step 90 Global step 90 Train loss 3.59 on epoch=3
05/22/2022 08:16:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.96 on epoch=3
05/22/2022 08:16:56 - INFO - __main__ - Global step 100 Train loss 3.52 Classification-F1 0.027023959795061062 on epoch=3
05/22/2022 08:16:56 - INFO - __main__ - Saving model with best Classification-F1: 0.01821025713776459 -> 0.027023959795061062 on epoch=3, global_step=100
05/22/2022 08:16:59 - INFO - __main__ - Step 110 Global step 110 Train loss 2.68 on epoch=3
05/22/2022 08:17:01 - INFO - __main__ - Step 120 Global step 120 Train loss 2.89 on epoch=4
05/22/2022 08:17:04 - INFO - __main__ - Step 130 Global step 130 Train loss 2.32 on epoch=4
05/22/2022 08:17:06 - INFO - __main__ - Step 140 Global step 140 Train loss 2.66 on epoch=4
05/22/2022 08:17:09 - INFO - __main__ - Step 150 Global step 150 Train loss 2.37 on epoch=5
05/22/2022 08:17:22 - INFO - __main__ - Global step 150 Train loss 2.58 Classification-F1 0.04734149841587858 on epoch=5
05/22/2022 08:17:22 - INFO - __main__ - Saving model with best Classification-F1: 0.027023959795061062 -> 0.04734149841587858 on epoch=5, global_step=150
05/22/2022 08:17:24 - INFO - __main__ - Step 160 Global step 160 Train loss 2.18 on epoch=5
05/22/2022 08:17:27 - INFO - __main__ - Step 170 Global step 170 Train loss 2.10 on epoch=6
05/22/2022 08:17:30 - INFO - __main__ - Step 180 Global step 180 Train loss 2.13 on epoch=6
05/22/2022 08:17:32 - INFO - __main__ - Step 190 Global step 190 Train loss 1.90 on epoch=6
05/22/2022 08:17:35 - INFO - __main__ - Step 200 Global step 200 Train loss 1.88 on epoch=7
05/22/2022 08:17:46 - INFO - __main__ - Global step 200 Train loss 2.04 Classification-F1 0.07177347956195039 on epoch=7
05/22/2022 08:17:46 - INFO - __main__ - Saving model with best Classification-F1: 0.04734149841587858 -> 0.07177347956195039 on epoch=7, global_step=200
05/22/2022 08:17:49 - INFO - __main__ - Step 210 Global step 210 Train loss 1.98 on epoch=7
05/22/2022 08:17:51 - INFO - __main__ - Step 220 Global step 220 Train loss 1.58 on epoch=7
05/22/2022 08:17:54 - INFO - __main__ - Step 230 Global step 230 Train loss 1.82 on epoch=8
05/22/2022 08:17:57 - INFO - __main__ - Step 240 Global step 240 Train loss 1.57 on epoch=8
05/22/2022 08:17:59 - INFO - __main__ - Step 250 Global step 250 Train loss 1.54 on epoch=8
05/22/2022 08:18:10 - INFO - __main__ - Global step 250 Train loss 1.70 Classification-F1 0.10814624305020287 on epoch=8
05/22/2022 08:18:10 - INFO - __main__ - Saving model with best Classification-F1: 0.07177347956195039 -> 0.10814624305020287 on epoch=8, global_step=250
05/22/2022 08:18:13 - INFO - __main__ - Step 260 Global step 260 Train loss 1.62 on epoch=9
05/22/2022 08:18:16 - INFO - __main__ - Step 270 Global step 270 Train loss 1.35 on epoch=9
05/22/2022 08:18:18 - INFO - __main__ - Step 280 Global step 280 Train loss 1.51 on epoch=9
05/22/2022 08:18:21 - INFO - __main__ - Step 290 Global step 290 Train loss 1.43 on epoch=10
05/22/2022 08:18:23 - INFO - __main__ - Step 300 Global step 300 Train loss 1.15 on epoch=10
05/22/2022 08:18:34 - INFO - __main__ - Global step 300 Train loss 1.41 Classification-F1 0.1357990509325572 on epoch=10
05/22/2022 08:18:34 - INFO - __main__ - Saving model with best Classification-F1: 0.10814624305020287 -> 0.1357990509325572 on epoch=10, global_step=300
05/22/2022 08:18:37 - INFO - __main__ - Step 310 Global step 310 Train loss 1.33 on epoch=11
05/22/2022 08:18:40 - INFO - __main__ - Step 320 Global step 320 Train loss 1.27 on epoch=11
05/22/2022 08:18:42 - INFO - __main__ - Step 330 Global step 330 Train loss 1.10 on epoch=11
05/22/2022 08:18:45 - INFO - __main__ - Step 340 Global step 340 Train loss 1.17 on epoch=12
05/22/2022 08:18:47 - INFO - __main__ - Step 350 Global step 350 Train loss 1.16 on epoch=12
05/22/2022 08:18:58 - INFO - __main__ - Global step 350 Train loss 1.21 Classification-F1 0.18995157280138353 on epoch=12
05/22/2022 08:18:58 - INFO - __main__ - Saving model with best Classification-F1: 0.1357990509325572 -> 0.18995157280138353 on epoch=12, global_step=350
05/22/2022 08:19:01 - INFO - __main__ - Step 360 Global step 360 Train loss 0.86 on epoch=12
05/22/2022 08:19:03 - INFO - __main__ - Step 370 Global step 370 Train loss 1.07 on epoch=13
05/22/2022 08:19:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.84 on epoch=13
05/22/2022 08:19:09 - INFO - __main__ - Step 390 Global step 390 Train loss 0.88 on epoch=13
05/22/2022 08:19:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.90 on epoch=14
05/22/2022 08:19:22 - INFO - __main__ - Global step 400 Train loss 0.91 Classification-F1 0.22968362303421766 on epoch=14
05/22/2022 08:19:22 - INFO - __main__ - Saving model with best Classification-F1: 0.18995157280138353 -> 0.22968362303421766 on epoch=14, global_step=400
05/22/2022 08:19:25 - INFO - __main__ - Step 410 Global step 410 Train loss 0.76 on epoch=14
05/22/2022 08:19:27 - INFO - __main__ - Step 420 Global step 420 Train loss 0.81 on epoch=14
05/22/2022 08:19:30 - INFO - __main__ - Step 430 Global step 430 Train loss 0.74 on epoch=15
05/22/2022 08:19:33 - INFO - __main__ - Step 440 Global step 440 Train loss 0.69 on epoch=15
05/22/2022 08:19:35 - INFO - __main__ - Step 450 Global step 450 Train loss 0.69 on epoch=16
05/22/2022 08:19:47 - INFO - __main__ - Global step 450 Train loss 0.74 Classification-F1 0.2650370712269323 on epoch=16
05/22/2022 08:19:47 - INFO - __main__ - Saving model with best Classification-F1: 0.22968362303421766 -> 0.2650370712269323 on epoch=16, global_step=450
05/22/2022 08:19:49 - INFO - __main__ - Step 460 Global step 460 Train loss 0.59 on epoch=16
05/22/2022 08:19:52 - INFO - __main__ - Step 470 Global step 470 Train loss 0.67 on epoch=16
05/22/2022 08:19:55 - INFO - __main__ - Step 480 Global step 480 Train loss 0.66 on epoch=17
05/22/2022 08:19:57 - INFO - __main__ - Step 490 Global step 490 Train loss 0.61 on epoch=17
05/22/2022 08:20:00 - INFO - __main__ - Step 500 Global step 500 Train loss 0.59 on epoch=17
05/22/2022 08:20:12 - INFO - __main__ - Global step 500 Train loss 0.62 Classification-F1 0.26326831320608424 on epoch=17
05/22/2022 08:20:14 - INFO - __main__ - Step 510 Global step 510 Train loss 0.55 on epoch=18
05/22/2022 08:20:17 - INFO - __main__ - Step 520 Global step 520 Train loss 0.57 on epoch=18
05/22/2022 08:20:19 - INFO - __main__ - Step 530 Global step 530 Train loss 0.53 on epoch=18
05/22/2022 08:20:22 - INFO - __main__ - Step 540 Global step 540 Train loss 0.50 on epoch=19
05/22/2022 08:20:25 - INFO - __main__ - Step 550 Global step 550 Train loss 0.45 on epoch=19
05/22/2022 08:20:37 - INFO - __main__ - Global step 550 Train loss 0.52 Classification-F1 0.3210856678741224 on epoch=19
05/22/2022 08:20:37 - INFO - __main__ - Saving model with best Classification-F1: 0.2650370712269323 -> 0.3210856678741224 on epoch=19, global_step=550
05/22/2022 08:20:40 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=19
05/22/2022 08:20:42 - INFO - __main__ - Step 570 Global step 570 Train loss 0.52 on epoch=20
05/22/2022 08:20:45 - INFO - __main__ - Step 580 Global step 580 Train loss 0.35 on epoch=20
05/22/2022 08:20:47 - INFO - __main__ - Step 590 Global step 590 Train loss 0.42 on epoch=21
05/22/2022 08:20:50 - INFO - __main__ - Step 600 Global step 600 Train loss 0.51 on epoch=21
05/22/2022 08:21:03 - INFO - __main__ - Global step 600 Train loss 0.47 Classification-F1 0.40658133844425365 on epoch=21
05/22/2022 08:21:03 - INFO - __main__ - Saving model with best Classification-F1: 0.3210856678741224 -> 0.40658133844425365 on epoch=21, global_step=600
05/22/2022 08:21:05 - INFO - __main__ - Step 610 Global step 610 Train loss 0.37 on epoch=21
05/22/2022 08:21:08 - INFO - __main__ - Step 620 Global step 620 Train loss 0.43 on epoch=22
05/22/2022 08:21:11 - INFO - __main__ - Step 630 Global step 630 Train loss 0.47 on epoch=22
05/22/2022 08:21:13 - INFO - __main__ - Step 640 Global step 640 Train loss 0.52 on epoch=22
05/22/2022 08:21:16 - INFO - __main__ - Step 650 Global step 650 Train loss 0.34 on epoch=23
05/22/2022 08:21:29 - INFO - __main__ - Global step 650 Train loss 0.43 Classification-F1 0.3991087404331331 on epoch=23
05/22/2022 08:21:31 - INFO - __main__ - Step 660 Global step 660 Train loss 0.35 on epoch=23
05/22/2022 08:21:34 - INFO - __main__ - Step 670 Global step 670 Train loss 0.33 on epoch=23
05/22/2022 08:21:36 - INFO - __main__ - Step 680 Global step 680 Train loss 0.42 on epoch=24
05/22/2022 08:21:39 - INFO - __main__ - Step 690 Global step 690 Train loss 0.37 on epoch=24
05/22/2022 08:21:41 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=24
05/22/2022 08:21:55 - INFO - __main__ - Global step 700 Train loss 0.37 Classification-F1 0.4851703703995524 on epoch=24
05/22/2022 08:21:55 - INFO - __main__ - Saving model with best Classification-F1: 0.40658133844425365 -> 0.4851703703995524 on epoch=24, global_step=700
05/22/2022 08:21:57 - INFO - __main__ - Step 710 Global step 710 Train loss 0.36 on epoch=25
05/22/2022 08:22:00 - INFO - __main__ - Step 720 Global step 720 Train loss 0.35 on epoch=25
05/22/2022 08:22:02 - INFO - __main__ - Step 730 Global step 730 Train loss 0.28 on epoch=26
05/22/2022 08:22:05 - INFO - __main__ - Step 740 Global step 740 Train loss 0.32 on epoch=26
05/22/2022 08:22:08 - INFO - __main__ - Step 750 Global step 750 Train loss 0.30 on epoch=26
05/22/2022 08:22:20 - INFO - __main__ - Global step 750 Train loss 0.32 Classification-F1 0.4336345909918896 on epoch=26
05/22/2022 08:22:23 - INFO - __main__ - Step 760 Global step 760 Train loss 0.43 on epoch=27
05/22/2022 08:22:26 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=27
05/22/2022 08:22:28 - INFO - __main__ - Step 780 Global step 780 Train loss 0.29 on epoch=27
05/22/2022 08:22:31 - INFO - __main__ - Step 790 Global step 790 Train loss 0.32 on epoch=28
05/22/2022 08:22:33 - INFO - __main__ - Step 800 Global step 800 Train loss 0.20 on epoch=28
05/22/2022 08:22:47 - INFO - __main__ - Global step 800 Train loss 0.31 Classification-F1 0.4583223649697592 on epoch=28
05/22/2022 08:22:49 - INFO - __main__ - Step 810 Global step 810 Train loss 0.27 on epoch=28
05/22/2022 08:22:52 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=29
05/22/2022 08:22:55 - INFO - __main__ - Step 830 Global step 830 Train loss 0.28 on epoch=29
05/22/2022 08:22:57 - INFO - __main__ - Step 840 Global step 840 Train loss 0.26 on epoch=29
05/22/2022 08:23:00 - INFO - __main__ - Step 850 Global step 850 Train loss 0.26 on epoch=30
05/22/2022 08:23:13 - INFO - __main__ - Global step 850 Train loss 0.27 Classification-F1 0.49562284439781923 on epoch=30
05/22/2022 08:23:13 - INFO - __main__ - Saving model with best Classification-F1: 0.4851703703995524 -> 0.49562284439781923 on epoch=30, global_step=850
05/22/2022 08:23:16 - INFO - __main__ - Step 860 Global step 860 Train loss 0.18 on epoch=30
05/22/2022 08:23:18 - INFO - __main__ - Step 870 Global step 870 Train loss 0.28 on epoch=31
05/22/2022 08:23:21 - INFO - __main__ - Step 880 Global step 880 Train loss 0.23 on epoch=31
05/22/2022 08:23:23 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=31
05/22/2022 08:23:26 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=32
05/22/2022 08:23:39 - INFO - __main__ - Global step 900 Train loss 0.21 Classification-F1 0.5534966555397843 on epoch=32
05/22/2022 08:23:39 - INFO - __main__ - Saving model with best Classification-F1: 0.49562284439781923 -> 0.5534966555397843 on epoch=32, global_step=900
05/22/2022 08:23:42 - INFO - __main__ - Step 910 Global step 910 Train loss 0.25 on epoch=32
05/22/2022 08:23:44 - INFO - __main__ - Step 920 Global step 920 Train loss 0.30 on epoch=32
05/22/2022 08:23:47 - INFO - __main__ - Step 930 Global step 930 Train loss 0.20 on epoch=33
05/22/2022 08:23:50 - INFO - __main__ - Step 940 Global step 940 Train loss 0.28 on epoch=33
05/22/2022 08:23:52 - INFO - __main__ - Step 950 Global step 950 Train loss 0.22 on epoch=33
05/22/2022 08:24:06 - INFO - __main__ - Global step 950 Train loss 0.25 Classification-F1 0.5790275723778916 on epoch=33
05/22/2022 08:24:06 - INFO - __main__ - Saving model with best Classification-F1: 0.5534966555397843 -> 0.5790275723778916 on epoch=33, global_step=950
05/22/2022 08:24:08 - INFO - __main__ - Step 960 Global step 960 Train loss 0.27 on epoch=34
05/22/2022 08:24:11 - INFO - __main__ - Step 970 Global step 970 Train loss 0.16 on epoch=34
05/22/2022 08:24:13 - INFO - __main__ - Step 980 Global step 980 Train loss 0.28 on epoch=34
05/22/2022 08:24:16 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=35
05/22/2022 08:24:19 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.17 on epoch=35
05/22/2022 08:24:32 - INFO - __main__ - Global step 1000 Train loss 0.23 Classification-F1 0.49026131361573677 on epoch=35
05/22/2022 08:24:34 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.27 on epoch=36
05/22/2022 08:24:37 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.22 on epoch=36
05/22/2022 08:24:39 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.17 on epoch=36
05/22/2022 08:24:42 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.14 on epoch=37
05/22/2022 08:24:45 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.28 on epoch=37
05/22/2022 08:24:58 - INFO - __main__ - Global step 1050 Train loss 0.21 Classification-F1 0.533052957465974 on epoch=37
05/22/2022 08:25:00 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.12 on epoch=37
05/22/2022 08:25:03 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=38
05/22/2022 08:25:06 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.19 on epoch=38
05/22/2022 08:25:08 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.22 on epoch=38
05/22/2022 08:25:11 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.26 on epoch=39
05/22/2022 08:25:24 - INFO - __main__ - Global step 1100 Train loss 0.21 Classification-F1 0.5517250920606124 on epoch=39
05/22/2022 08:25:27 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=39
05/22/2022 08:25:29 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=39
05/22/2022 08:25:32 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.19 on epoch=40
05/22/2022 08:25:35 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=40
05/22/2022 08:25:37 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.15 on epoch=41
05/22/2022 08:25:50 - INFO - __main__ - Global step 1150 Train loss 0.17 Classification-F1 0.5574570321217117 on epoch=41
05/22/2022 08:25:53 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.17 on epoch=41
05/22/2022 08:25:55 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.23 on epoch=41
05/22/2022 08:25:58 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.16 on epoch=42
05/22/2022 08:26:01 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.18 on epoch=42
05/22/2022 08:26:03 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.15 on epoch=42
05/22/2022 08:26:17 - INFO - __main__ - Global step 1200 Train loss 0.18 Classification-F1 0.6513624325820815 on epoch=42
05/22/2022 08:26:17 - INFO - __main__ - Saving model with best Classification-F1: 0.5790275723778916 -> 0.6513624325820815 on epoch=42, global_step=1200
05/22/2022 08:26:19 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.21 on epoch=43
05/22/2022 08:26:22 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.15 on epoch=43
05/22/2022 08:26:24 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.16 on epoch=43
05/22/2022 08:26:27 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.17 on epoch=44
05/22/2022 08:26:30 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.20 on epoch=44
05/22/2022 08:26:43 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.5629259884419929 on epoch=44
05/22/2022 08:26:45 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=44
05/22/2022 08:26:48 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.13 on epoch=45
05/22/2022 08:26:50 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=45
05/22/2022 08:26:53 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.20 on epoch=46
05/22/2022 08:26:56 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=46
05/22/2022 08:27:09 - INFO - __main__ - Global step 1300 Train loss 0.16 Classification-F1 0.5863860088669826 on epoch=46
05/22/2022 08:27:11 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.13 on epoch=46
05/22/2022 08:27:14 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.15 on epoch=47
05/22/2022 08:27:17 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.12 on epoch=47
05/22/2022 08:27:19 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.23 on epoch=47
05/22/2022 08:27:22 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=48
05/22/2022 08:27:35 - INFO - __main__ - Global step 1350 Train loss 0.16 Classification-F1 0.6231805976693894 on epoch=48
05/22/2022 08:27:37 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=48
05/22/2022 08:27:40 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.15 on epoch=48
05/22/2022 08:27:42 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.15 on epoch=49
05/22/2022 08:27:45 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.10 on epoch=49
05/22/2022 08:27:48 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.21 on epoch=49
05/22/2022 08:28:01 - INFO - __main__ - Global step 1400 Train loss 0.14 Classification-F1 0.5688004546993564 on epoch=49
05/22/2022 08:28:03 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=50
05/22/2022 08:28:06 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.11 on epoch=50
05/22/2022 08:28:08 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.07 on epoch=51
05/22/2022 08:28:11 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.14 on epoch=51
05/22/2022 08:28:14 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.15 on epoch=51
05/22/2022 08:28:27 - INFO - __main__ - Global step 1450 Train loss 0.12 Classification-F1 0.6281125625652331 on epoch=51
05/22/2022 08:28:29 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.14 on epoch=52
05/22/2022 08:28:32 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.17 on epoch=52
05/22/2022 08:28:35 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=52
05/22/2022 08:28:37 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.14 on epoch=53
05/22/2022 08:28:40 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.14 on epoch=53
05/22/2022 08:28:53 - INFO - __main__ - Global step 1500 Train loss 0.14 Classification-F1 0.7029066543153926 on epoch=53
05/22/2022 08:28:53 - INFO - __main__ - Saving model with best Classification-F1: 0.6513624325820815 -> 0.7029066543153926 on epoch=53, global_step=1500
05/22/2022 08:28:56 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=53
05/22/2022 08:28:58 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.14 on epoch=54
05/22/2022 08:29:01 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=54
05/22/2022 08:29:04 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.13 on epoch=54
05/22/2022 08:29:06 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=55
05/22/2022 08:29:19 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.5971446332261983 on epoch=55
05/22/2022 08:29:22 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.11 on epoch=55
05/22/2022 08:29:24 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.09 on epoch=56
05/22/2022 08:29:27 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.11 on epoch=56
05/22/2022 08:29:29 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.12 on epoch=56
05/22/2022 08:29:32 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.11 on epoch=57
05/22/2022 08:29:45 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.6605890716337527 on epoch=57
05/22/2022 08:29:47 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=57
05/22/2022 08:29:50 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.18 on epoch=57
05/22/2022 08:29:52 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.12 on epoch=58
05/22/2022 08:29:55 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=58
05/22/2022 08:29:58 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.09 on epoch=58
05/22/2022 08:30:11 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.7415288891270764 on epoch=58
05/22/2022 08:30:11 - INFO - __main__ - Saving model with best Classification-F1: 0.7029066543153926 -> 0.7415288891270764 on epoch=58, global_step=1650
05/22/2022 08:30:13 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.12 on epoch=59
05/22/2022 08:30:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=59
05/22/2022 08:30:18 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.09 on epoch=59
05/22/2022 08:30:21 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.10 on epoch=60
05/22/2022 08:30:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.12 on epoch=60
05/22/2022 08:30:36 - INFO - __main__ - Global step 1700 Train loss 0.10 Classification-F1 0.6592089970981102 on epoch=60
05/22/2022 08:30:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.14 on epoch=61
05/22/2022 08:30:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=61
05/22/2022 08:30:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.15 on epoch=61
05/22/2022 08:30:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.12 on epoch=62
05/22/2022 08:30:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.11 on epoch=62
05/22/2022 08:31:02 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.6094825127083192 on epoch=62
05/22/2022 08:31:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.14 on epoch=62
05/22/2022 08:31:08 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.12 on epoch=63
05/22/2022 08:31:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.11 on epoch=63
05/22/2022 08:31:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=63
05/22/2022 08:31:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=64
05/22/2022 08:31:29 - INFO - __main__ - Global step 1800 Train loss 0.11 Classification-F1 0.6659762872707732 on epoch=64
05/22/2022 08:31:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.06 on epoch=64
05/22/2022 08:31:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=64
05/22/2022 08:31:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.12 on epoch=65
05/22/2022 08:31:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=65
05/22/2022 08:31:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.07 on epoch=66
05/22/2022 08:31:55 - INFO - __main__ - Global step 1850 Train loss 0.09 Classification-F1 0.6733095577206741 on epoch=66
05/22/2022 08:31:58 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=66
05/22/2022 08:32:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.09 on epoch=66
05/22/2022 08:32:03 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.08 on epoch=67
05/22/2022 08:32:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.14 on epoch=67
05/22/2022 08:32:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.11 on epoch=67
05/22/2022 08:32:20 - INFO - __main__ - Global step 1900 Train loss 0.10 Classification-F1 0.664117010815968 on epoch=67
05/22/2022 08:32:23 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.09 on epoch=68
05/22/2022 08:32:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.09 on epoch=68
05/22/2022 08:32:28 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.11 on epoch=68
05/22/2022 08:32:31 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=69
05/22/2022 08:32:33 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.05 on epoch=69
05/22/2022 08:32:46 - INFO - __main__ - Global step 1950 Train loss 0.09 Classification-F1 0.6417754374967648 on epoch=69
05/22/2022 08:32:49 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.13 on epoch=69
05/22/2022 08:32:51 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=70
05/22/2022 08:32:54 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.08 on epoch=70
05/22/2022 08:32:57 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.06 on epoch=71
05/22/2022 08:32:59 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.10 on epoch=71
05/22/2022 08:33:12 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.5084365123083262 on epoch=71
05/22/2022 08:33:14 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.09 on epoch=71
05/22/2022 08:33:17 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.04 on epoch=72
05/22/2022 08:33:20 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=72
05/22/2022 08:33:22 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=72
05/22/2022 08:33:25 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=73
05/22/2022 08:33:37 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.5130801138145169 on epoch=73
05/22/2022 08:33:40 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.12 on epoch=73
05/22/2022 08:33:42 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.07 on epoch=73
05/22/2022 08:33:45 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.08 on epoch=74
05/22/2022 08:33:48 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=74
05/22/2022 08:33:50 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.12 on epoch=74
05/22/2022 08:34:02 - INFO - __main__ - Global step 2100 Train loss 0.09 Classification-F1 0.507013764547732 on epoch=74
05/22/2022 08:34:05 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.06 on epoch=75
05/22/2022 08:34:08 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.08 on epoch=75
05/22/2022 08:34:10 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=76
05/22/2022 08:34:13 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.11 on epoch=76
05/22/2022 08:34:15 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=76
05/22/2022 08:34:28 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.5348363771923483 on epoch=76
05/22/2022 08:34:30 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.10 on epoch=77
05/22/2022 08:34:33 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=77
05/22/2022 08:34:35 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=77
05/22/2022 08:34:38 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.08 on epoch=78
05/22/2022 08:34:40 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.10 on epoch=78
05/22/2022 08:34:53 - INFO - __main__ - Global step 2200 Train loss 0.09 Classification-F1 0.6148053725648326 on epoch=78
05/22/2022 08:34:55 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=78
05/22/2022 08:34:58 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=79
05/22/2022 08:35:01 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=79
05/22/2022 08:35:03 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.11 on epoch=79
05/22/2022 08:35:06 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=80
05/22/2022 08:35:18 - INFO - __main__ - Global step 2250 Train loss 0.08 Classification-F1 0.6431279954118228 on epoch=80
05/22/2022 08:35:21 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=80
05/22/2022 08:35:23 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.03 on epoch=81
05/22/2022 08:35:26 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=81
05/22/2022 08:35:28 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=81
05/22/2022 08:35:31 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=82
05/22/2022 08:35:43 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.6107703215697606 on epoch=82
05/22/2022 08:35:46 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=82
05/22/2022 08:35:48 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=82
05/22/2022 08:35:51 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=83
05/22/2022 08:35:53 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.04 on epoch=83
05/22/2022 08:35:56 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.06 on epoch=83
05/22/2022 08:36:08 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.6473401398906302 on epoch=83
05/22/2022 08:36:11 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=84
05/22/2022 08:36:13 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.06 on epoch=84
05/22/2022 08:36:16 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.08 on epoch=84
05/22/2022 08:36:19 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.06 on epoch=85
05/22/2022 08:36:21 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.06 on epoch=85
05/22/2022 08:36:34 - INFO - __main__ - Global step 2400 Train loss 0.06 Classification-F1 0.6546456592510095 on epoch=85
05/22/2022 08:36:36 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.05 on epoch=86
05/22/2022 08:36:39 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.07 on epoch=86
05/22/2022 08:36:41 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=86
05/22/2022 08:36:44 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.06 on epoch=87
05/22/2022 08:36:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=87
05/22/2022 08:36:59 - INFO - __main__ - Global step 2450 Train loss 0.06 Classification-F1 0.7322945874116432 on epoch=87
05/22/2022 08:37:02 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.05 on epoch=87
05/22/2022 08:37:04 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.04 on epoch=88
05/22/2022 08:37:07 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.07 on epoch=88
05/22/2022 08:37:10 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.08 on epoch=88
05/22/2022 08:37:12 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=89
05/22/2022 08:37:25 - INFO - __main__ - Global step 2500 Train loss 0.06 Classification-F1 0.721534982497276 on epoch=89
05/22/2022 08:37:27 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=89
05/22/2022 08:37:30 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=89
05/22/2022 08:37:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.08 on epoch=90
05/22/2022 08:37:35 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=90
05/22/2022 08:37:38 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.06 on epoch=91
05/22/2022 08:37:50 - INFO - __main__ - Global step 2550 Train loss 0.06 Classification-F1 0.65173229324439 on epoch=91
05/22/2022 08:37:53 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=91
05/22/2022 08:37:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.09 on epoch=91
05/22/2022 08:37:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.04 on epoch=92
05/22/2022 08:38:01 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=92
05/22/2022 08:38:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=92
05/22/2022 08:38:16 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.6743669836789071 on epoch=92
05/22/2022 08:38:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=93
05/22/2022 08:38:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.07 on epoch=93
05/22/2022 08:38:24 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.06 on epoch=93
05/22/2022 08:38:27 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.04 on epoch=94
05/22/2022 08:38:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.06 on epoch=94
05/22/2022 08:38:41 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7733917578469355 on epoch=94
05/22/2022 08:38:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7415288891270764 -> 0.7733917578469355 on epoch=94, global_step=2650
05/22/2022 08:38:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.07 on epoch=94
05/22/2022 08:38:47 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.07 on epoch=95
05/22/2022 08:38:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.08 on epoch=95
05/22/2022 08:38:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 08:38:55 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=96
05/22/2022 08:39:07 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.6960236141640606 on epoch=96
05/22/2022 08:39:10 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.06 on epoch=96
05/22/2022 08:39:13 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.09 on epoch=97
05/22/2022 08:39:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.03 on epoch=97
05/22/2022 08:39:18 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.08 on epoch=97
05/22/2022 08:39:21 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.06 on epoch=98
05/22/2022 08:39:33 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.6531641574286761 on epoch=98
05/22/2022 08:39:36 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=98
05/22/2022 08:39:39 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=98
05/22/2022 08:39:41 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.06 on epoch=99
05/22/2022 08:39:44 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.10 on epoch=99
05/22/2022 08:39:47 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.06 on epoch=99
05/22/2022 08:39:59 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.5805031155333198 on epoch=99
05/22/2022 08:40:02 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.05 on epoch=100
05/22/2022 08:40:05 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.12 on epoch=100
05/22/2022 08:40:07 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.11 on epoch=101
05/22/2022 08:40:10 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.04 on epoch=101
05/22/2022 08:40:13 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.05 on epoch=101
05/22/2022 08:40:25 - INFO - __main__ - Global step 2850 Train loss 0.08 Classification-F1 0.5833506315538961 on epoch=101
05/22/2022 08:40:28 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.09 on epoch=102
05/22/2022 08:40:30 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.05 on epoch=102
05/22/2022 08:40:33 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.09 on epoch=102
05/22/2022 08:40:36 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.06 on epoch=103
05/22/2022 08:40:38 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.06 on epoch=103
05/22/2022 08:40:51 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.6428050027169039 on epoch=103
05/22/2022 08:40:53 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.07 on epoch=103
05/22/2022 08:40:56 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=104
05/22/2022 08:40:59 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=104
05/22/2022 08:41:01 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 08:41:04 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=105
05/22/2022 08:41:16 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.5259383058413715 on epoch=105
05/22/2022 08:41:19 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.07 on epoch=105
05/22/2022 08:41:22 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.05 on epoch=106
05/22/2022 08:41:24 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.07 on epoch=106
05/22/2022 08:41:27 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.08 on epoch=106
05/22/2022 08:41:30 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.04 on epoch=107
05/22/2022 08:41:31 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:41:31 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:31 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 08:41:31 - INFO - __main__ - ['Company']
05/22/2022 08:41:31 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 08:41:31 - INFO - __main__ - ['Company']
05/22/2022 08:41:31 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 08:41:31 - INFO - __main__ - ['Company']
05/22/2022 08:41:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:32 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 08:41:32 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:41:32 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:32 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 08:41:32 - INFO - __main__ - ['Company']
05/22/2022 08:41:32 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 08:41:32 - INFO - __main__ - ['Company']
05/22/2022 08:41:32 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 08:41:32 - INFO - __main__ - ['Company']
05/22/2022 08:41:32 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:32 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:33 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 08:41:42 - INFO - __main__ - Global step 3000 Train loss 0.06 Classification-F1 0.5482910087833017 on epoch=107
05/22/2022 08:41:42 - INFO - __main__ - save last model!
05/22/2022 08:41:42 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 08:41:42 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 08:41:42 - INFO - __main__ - Printing 3 examples
05/22/2022 08:41:42 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 08:41:42 - INFO - __main__ - ['Animal']
05/22/2022 08:41:42 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 08:41:42 - INFO - __main__ - ['Animal']
05/22/2022 08:41:42 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 08:41:42 - INFO - __main__ - ['Village']
05/22/2022 08:41:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:41:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:41:47 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 08:41:48 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 08:41:49 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 08:41:49 - INFO - __main__ - Starting training!
05/22/2022 08:43:43 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_21_0.2_8_predictions.txt
05/22/2022 08:43:43 - INFO - __main__ - Classification-F1 on test data: 0.4311
05/22/2022 08:43:43 - INFO - __main__ - prefix=dbpedia_14_32_21, lr=0.2, bsz=8, dev_performance=0.7733917578469355, test_performance=0.43107637004889054
05/22/2022 08:43:43 - INFO - __main__ - Running ... prefix=dbpedia_14_32_42, lr=0.5, bsz=8 ...
05/22/2022 08:43:44 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:43:44 - INFO - __main__ - Printing 3 examples
05/22/2022 08:43:44 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 08:43:44 - INFO - __main__ - ['Company']
05/22/2022 08:43:44 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 08:43:44 - INFO - __main__ - ['Company']
05/22/2022 08:43:44 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 08:43:44 - INFO - __main__ - ['Company']
05/22/2022 08:43:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:43:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:43:45 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 08:43:45 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 08:43:45 - INFO - __main__ - Printing 3 examples
05/22/2022 08:43:45 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 08:43:45 - INFO - __main__ - ['Company']
05/22/2022 08:43:45 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 08:43:45 - INFO - __main__ - ['Company']
05/22/2022 08:43:45 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 08:43:45 - INFO - __main__ - ['Company']
05/22/2022 08:43:45 - INFO - __main__ - Tokenizing Input ...
05/22/2022 08:43:45 - INFO - __main__ - Tokenizing Output ...
05/22/2022 08:43:46 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 08:44:01 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 08:44:02 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 08:44:02 - INFO - __main__ - Starting training!
05/22/2022 08:44:06 - INFO - __main__ - Step 10 Global step 10 Train loss 6.38 on epoch=0
05/22/2022 08:44:09 - INFO - __main__ - Step 20 Global step 20 Train loss 4.69 on epoch=0
05/22/2022 08:44:11 - INFO - __main__ - Step 30 Global step 30 Train loss 3.89 on epoch=1
05/22/2022 08:44:14 - INFO - __main__ - Step 40 Global step 40 Train loss 3.03 on epoch=1
05/22/2022 08:44:17 - INFO - __main__ - Step 50 Global step 50 Train loss 3.05 on epoch=1
05/22/2022 08:44:30 - INFO - __main__ - Global step 50 Train loss 4.21 Classification-F1 0.03399604390858035 on epoch=1
05/22/2022 08:44:30 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.03399604390858035 on epoch=1, global_step=50
05/22/2022 08:44:32 - INFO - __main__ - Step 60 Global step 60 Train loss 2.52 on epoch=2
05/22/2022 08:44:35 - INFO - __main__ - Step 70 Global step 70 Train loss 2.02 on epoch=2
05/22/2022 08:44:37 - INFO - __main__ - Step 80 Global step 80 Train loss 2.07 on epoch=2
05/22/2022 08:44:40 - INFO - __main__ - Step 90 Global step 90 Train loss 1.76 on epoch=3
05/22/2022 08:44:43 - INFO - __main__ - Step 100 Global step 100 Train loss 1.88 on epoch=3
05/22/2022 08:44:54 - INFO - __main__ - Global step 100 Train loss 2.05 Classification-F1 0.08553653044895325 on epoch=3
05/22/2022 08:44:54 - INFO - __main__ - Saving model with best Classification-F1: 0.03399604390858035 -> 0.08553653044895325 on epoch=3, global_step=100
05/22/2022 08:44:57 - INFO - __main__ - Step 110 Global step 110 Train loss 1.69 on epoch=3
05/22/2022 08:44:59 - INFO - __main__ - Step 120 Global step 120 Train loss 1.35 on epoch=4
05/22/2022 08:45:02 - INFO - __main__ - Step 130 Global step 130 Train loss 1.40 on epoch=4
05/22/2022 08:45:04 - INFO - __main__ - Step 140 Global step 140 Train loss 1.24 on epoch=4
05/22/2022 08:45:07 - INFO - __main__ - Step 150 Global step 150 Train loss 0.87 on epoch=5
05/22/2022 08:45:18 - INFO - __main__ - Global step 150 Train loss 1.31 Classification-F1 0.17441880303637408 on epoch=5
05/22/2022 08:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.08553653044895325 -> 0.17441880303637408 on epoch=5, global_step=150
05/22/2022 08:45:21 - INFO - __main__ - Step 160 Global step 160 Train loss 1.16 on epoch=5
05/22/2022 08:45:23 - INFO - __main__ - Step 170 Global step 170 Train loss 0.82 on epoch=6
05/22/2022 08:45:26 - INFO - __main__ - Step 180 Global step 180 Train loss 0.71 on epoch=6
05/22/2022 08:45:28 - INFO - __main__ - Step 190 Global step 190 Train loss 0.83 on epoch=6
05/22/2022 08:45:31 - INFO - __main__ - Step 200 Global step 200 Train loss 0.75 on epoch=7
05/22/2022 08:45:43 - INFO - __main__ - Global step 200 Train loss 0.85 Classification-F1 0.2978815794952401 on epoch=7
05/22/2022 08:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.17441880303637408 -> 0.2978815794952401 on epoch=7, global_step=200
05/22/2022 08:45:46 - INFO - __main__ - Step 210 Global step 210 Train loss 0.62 on epoch=7
05/22/2022 08:45:49 - INFO - __main__ - Step 220 Global step 220 Train loss 0.52 on epoch=7
05/22/2022 08:45:51 - INFO - __main__ - Step 230 Global step 230 Train loss 0.41 on epoch=8
05/22/2022 08:45:54 - INFO - __main__ - Step 240 Global step 240 Train loss 0.53 on epoch=8
05/22/2022 08:45:56 - INFO - __main__ - Step 250 Global step 250 Train loss 0.48 on epoch=8
05/22/2022 08:46:10 - INFO - __main__ - Global step 250 Train loss 0.51 Classification-F1 0.47730604927505144 on epoch=8
05/22/2022 08:46:10 - INFO - __main__ - Saving model with best Classification-F1: 0.2978815794952401 -> 0.47730604927505144 on epoch=8, global_step=250
05/22/2022 08:46:13 - INFO - __main__ - Step 260 Global step 260 Train loss 0.42 on epoch=9
05/22/2022 08:46:15 - INFO - __main__ - Step 270 Global step 270 Train loss 0.56 on epoch=9
05/22/2022 08:46:18 - INFO - __main__ - Step 280 Global step 280 Train loss 0.39 on epoch=9
05/22/2022 08:46:20 - INFO - __main__ - Step 290 Global step 290 Train loss 0.33 on epoch=10
05/22/2022 08:46:23 - INFO - __main__ - Step 300 Global step 300 Train loss 0.42 on epoch=10
05/22/2022 08:46:36 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.5175651100547651 on epoch=10
05/22/2022 08:46:36 - INFO - __main__ - Saving model with best Classification-F1: 0.47730604927505144 -> 0.5175651100547651 on epoch=10, global_step=300
05/22/2022 08:46:38 - INFO - __main__ - Step 310 Global step 310 Train loss 0.37 on epoch=11
05/22/2022 08:46:41 - INFO - __main__ - Step 320 Global step 320 Train loss 0.35 on epoch=11
05/22/2022 08:46:44 - INFO - __main__ - Step 330 Global step 330 Train loss 0.39 on epoch=11
05/22/2022 08:46:46 - INFO - __main__ - Step 340 Global step 340 Train loss 0.28 on epoch=12
05/22/2022 08:46:49 - INFO - __main__ - Step 350 Global step 350 Train loss 0.27 on epoch=12
05/22/2022 08:47:02 - INFO - __main__ - Global step 350 Train loss 0.33 Classification-F1 0.6249101961416399 on epoch=12
05/22/2022 08:47:02 - INFO - __main__ - Saving model with best Classification-F1: 0.5175651100547651 -> 0.6249101961416399 on epoch=12, global_step=350
05/22/2022 08:47:05 - INFO - __main__ - Step 360 Global step 360 Train loss 0.33 on epoch=12
05/22/2022 08:47:07 - INFO - __main__ - Step 370 Global step 370 Train loss 0.23 on epoch=13
05/22/2022 08:47:10 - INFO - __main__ - Step 380 Global step 380 Train loss 0.41 on epoch=13
05/22/2022 08:47:13 - INFO - __main__ - Step 390 Global step 390 Train loss 0.24 on epoch=13
05/22/2022 08:47:15 - INFO - __main__ - Step 400 Global step 400 Train loss 0.26 on epoch=14
05/22/2022 08:47:29 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.714454529413431 on epoch=14
05/22/2022 08:47:29 - INFO - __main__ - Saving model with best Classification-F1: 0.6249101961416399 -> 0.714454529413431 on epoch=14, global_step=400
05/22/2022 08:47:31 - INFO - __main__ - Step 410 Global step 410 Train loss 0.28 on epoch=14
05/22/2022 08:47:34 - INFO - __main__ - Step 420 Global step 420 Train loss 0.23 on epoch=14
05/22/2022 08:47:36 - INFO - __main__ - Step 430 Global step 430 Train loss 0.31 on epoch=15
05/22/2022 08:47:39 - INFO - __main__ - Step 440 Global step 440 Train loss 0.20 on epoch=15
05/22/2022 08:47:42 - INFO - __main__ - Step 450 Global step 450 Train loss 0.25 on epoch=16
05/22/2022 08:47:55 - INFO - __main__ - Global step 450 Train loss 0.25 Classification-F1 0.6923164313285282 on epoch=16
05/22/2022 08:47:57 - INFO - __main__ - Step 460 Global step 460 Train loss 0.24 on epoch=16
05/22/2022 08:48:00 - INFO - __main__ - Step 470 Global step 470 Train loss 0.19 on epoch=16
05/22/2022 08:48:03 - INFO - __main__ - Step 480 Global step 480 Train loss 0.21 on epoch=17
05/22/2022 08:48:05 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=17
05/22/2022 08:48:08 - INFO - __main__ - Step 500 Global step 500 Train loss 0.25 on epoch=17
05/22/2022 08:48:21 - INFO - __main__ - Global step 500 Train loss 0.23 Classification-F1 0.6545572230473007 on epoch=17
05/22/2022 08:48:23 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=18
05/22/2022 08:48:26 - INFO - __main__ - Step 520 Global step 520 Train loss 0.24 on epoch=18
05/22/2022 08:48:29 - INFO - __main__ - Step 530 Global step 530 Train loss 0.19 on epoch=18
05/22/2022 08:48:31 - INFO - __main__ - Step 540 Global step 540 Train loss 0.13 on epoch=19
05/22/2022 08:48:34 - INFO - __main__ - Step 550 Global step 550 Train loss 0.26 on epoch=19
05/22/2022 08:48:46 - INFO - __main__ - Global step 550 Train loss 0.20 Classification-F1 0.6005292395574892 on epoch=19
05/22/2022 08:48:49 - INFO - __main__ - Step 560 Global step 560 Train loss 0.15 on epoch=19
05/22/2022 08:48:52 - INFO - __main__ - Step 570 Global step 570 Train loss 0.14 on epoch=20
05/22/2022 08:48:54 - INFO - __main__ - Step 580 Global step 580 Train loss 0.18 on epoch=20
05/22/2022 08:48:57 - INFO - __main__ - Step 590 Global step 590 Train loss 0.15 on epoch=21
05/22/2022 08:48:59 - INFO - __main__ - Step 600 Global step 600 Train loss 0.11 on epoch=21
05/22/2022 08:49:12 - INFO - __main__ - Global step 600 Train loss 0.15 Classification-F1 0.6940237812275313 on epoch=21
05/22/2022 08:49:15 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=21
05/22/2022 08:49:17 - INFO - __main__ - Step 620 Global step 620 Train loss 0.10 on epoch=22
05/22/2022 08:49:20 - INFO - __main__ - Step 630 Global step 630 Train loss 0.13 on epoch=22
05/22/2022 08:49:23 - INFO - __main__ - Step 640 Global step 640 Train loss 0.14 on epoch=22
05/22/2022 08:49:25 - INFO - __main__ - Step 650 Global step 650 Train loss 0.06 on epoch=23
05/22/2022 08:49:38 - INFO - __main__ - Global step 650 Train loss 0.12 Classification-F1 0.635750917530234 on epoch=23
05/22/2022 08:49:41 - INFO - __main__ - Step 660 Global step 660 Train loss 0.24 on epoch=23
05/22/2022 08:49:43 - INFO - __main__ - Step 670 Global step 670 Train loss 0.10 on epoch=23
05/22/2022 08:49:46 - INFO - __main__ - Step 680 Global step 680 Train loss 0.12 on epoch=24
05/22/2022 08:49:48 - INFO - __main__ - Step 690 Global step 690 Train loss 0.20 on epoch=24
05/22/2022 08:49:51 - INFO - __main__ - Step 700 Global step 700 Train loss 0.08 on epoch=24
05/22/2022 08:50:04 - INFO - __main__ - Global step 700 Train loss 0.15 Classification-F1 0.6613922037033785 on epoch=24
05/22/2022 08:50:07 - INFO - __main__ - Step 710 Global step 710 Train loss 0.12 on epoch=25
05/22/2022 08:50:10 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=25
05/22/2022 08:50:12 - INFO - __main__ - Step 730 Global step 730 Train loss 0.08 on epoch=26
05/22/2022 08:50:15 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=26
05/22/2022 08:50:18 - INFO - __main__ - Step 750 Global step 750 Train loss 0.10 on epoch=26
05/22/2022 08:50:31 - INFO - __main__ - Global step 750 Train loss 0.10 Classification-F1 0.6061381946099027 on epoch=26
05/22/2022 08:50:33 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=27
05/22/2022 08:50:36 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=27
05/22/2022 08:50:39 - INFO - __main__ - Step 780 Global step 780 Train loss 0.17 on epoch=27
05/22/2022 08:50:41 - INFO - __main__ - Step 790 Global step 790 Train loss 0.08 on epoch=28
05/22/2022 08:50:44 - INFO - __main__ - Step 800 Global step 800 Train loss 0.15 on epoch=28
05/22/2022 08:50:57 - INFO - __main__ - Global step 800 Train loss 0.13 Classification-F1 0.7161404305911239 on epoch=28
05/22/2022 08:50:57 - INFO - __main__ - Saving model with best Classification-F1: 0.714454529413431 -> 0.7161404305911239 on epoch=28, global_step=800
05/22/2022 08:51:00 - INFO - __main__ - Step 810 Global step 810 Train loss 0.11 on epoch=28
05/22/2022 08:51:02 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=29
05/22/2022 08:51:05 - INFO - __main__ - Step 830 Global step 830 Train loss 0.12 on epoch=29
05/22/2022 08:51:08 - INFO - __main__ - Step 840 Global step 840 Train loss 0.09 on epoch=29
05/22/2022 08:51:10 - INFO - __main__ - Step 850 Global step 850 Train loss 0.07 on epoch=30
05/22/2022 08:51:23 - INFO - __main__ - Global step 850 Train loss 0.10 Classification-F1 0.8045583228150106 on epoch=30
05/22/2022 08:51:23 - INFO - __main__ - Saving model with best Classification-F1: 0.7161404305911239 -> 0.8045583228150106 on epoch=30, global_step=850
05/22/2022 08:51:26 - INFO - __main__ - Step 860 Global step 860 Train loss 0.11 on epoch=30
05/22/2022 08:51:29 - INFO - __main__ - Step 870 Global step 870 Train loss 0.12 on epoch=31
05/22/2022 08:51:31 - INFO - __main__ - Step 880 Global step 880 Train loss 0.10 on epoch=31
05/22/2022 08:51:34 - INFO - __main__ - Step 890 Global step 890 Train loss 0.11 on epoch=31
05/22/2022 08:51:36 - INFO - __main__ - Step 900 Global step 900 Train loss 0.09 on epoch=32
05/22/2022 08:51:49 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.7667334852291644 on epoch=32
05/22/2022 08:51:52 - INFO - __main__ - Step 910 Global step 910 Train loss 0.10 on epoch=32
05/22/2022 08:51:54 - INFO - __main__ - Step 920 Global step 920 Train loss 0.09 on epoch=32
05/22/2022 08:51:57 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=33
05/22/2022 08:52:00 - INFO - __main__ - Step 940 Global step 940 Train loss 0.11 on epoch=33
05/22/2022 08:52:02 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=33
05/22/2022 08:52:15 - INFO - __main__ - Global step 950 Train loss 0.10 Classification-F1 0.7524973403336657 on epoch=33
05/22/2022 08:52:18 - INFO - __main__ - Step 960 Global step 960 Train loss 0.06 on epoch=34
05/22/2022 08:52:20 - INFO - __main__ - Step 970 Global step 970 Train loss 0.09 on epoch=34
05/22/2022 08:52:23 - INFO - __main__ - Step 980 Global step 980 Train loss 0.14 on epoch=34
05/22/2022 08:52:26 - INFO - __main__ - Step 990 Global step 990 Train loss 0.07 on epoch=35
05/22/2022 08:52:28 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.05 on epoch=35
05/22/2022 08:52:41 - INFO - __main__ - Global step 1000 Train loss 0.08 Classification-F1 0.76053153075141 on epoch=35
05/22/2022 08:52:44 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.07 on epoch=36
05/22/2022 08:52:46 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.07 on epoch=36
05/22/2022 08:52:49 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.07 on epoch=36
05/22/2022 08:52:51 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=37
05/22/2022 08:52:54 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.07 on epoch=37
05/22/2022 08:53:07 - INFO - __main__ - Global step 1050 Train loss 0.08 Classification-F1 0.6592393199923938 on epoch=37
05/22/2022 08:53:10 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=37
05/22/2022 08:53:12 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.07 on epoch=38
05/22/2022 08:53:15 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.11 on epoch=38
05/22/2022 08:53:18 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.05 on epoch=38
05/22/2022 08:53:20 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=39
05/22/2022 08:53:33 - INFO - __main__ - Global step 1100 Train loss 0.07 Classification-F1 0.8503270477675056 on epoch=39
05/22/2022 08:53:33 - INFO - __main__ - Saving model with best Classification-F1: 0.8045583228150106 -> 0.8503270477675056 on epoch=39, global_step=1100
05/22/2022 08:53:36 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.09 on epoch=39
05/22/2022 08:53:39 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.04 on epoch=39
05/22/2022 08:53:41 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=40
05/22/2022 08:53:44 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.06 on epoch=40
05/22/2022 08:53:46 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.04 on epoch=41
05/22/2022 08:54:00 - INFO - __main__ - Global step 1150 Train loss 0.06 Classification-F1 0.9196344631385617 on epoch=41
05/22/2022 08:54:00 - INFO - __main__ - Saving model with best Classification-F1: 0.8503270477675056 -> 0.9196344631385617 on epoch=41, global_step=1150
05/22/2022 08:54:02 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.08 on epoch=41
05/22/2022 08:54:05 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=41
05/22/2022 08:54:07 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=42
05/22/2022 08:54:10 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=42
05/22/2022 08:54:12 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.08 on epoch=42
05/22/2022 08:54:26 - INFO - __main__ - Global step 1200 Train loss 0.08 Classification-F1 0.9163769798810782 on epoch=42
05/22/2022 08:54:29 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.07 on epoch=43
05/22/2022 08:54:31 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.06 on epoch=43
05/22/2022 08:54:34 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=43
05/22/2022 08:54:36 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=44
05/22/2022 08:54:39 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=44
05/22/2022 08:54:52 - INFO - __main__ - Global step 1250 Train loss 0.06 Classification-F1 0.913922000956722 on epoch=44
05/22/2022 08:54:55 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.05 on epoch=44
05/22/2022 08:54:57 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.05 on epoch=45
05/22/2022 08:55:00 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.06 on epoch=45
05/22/2022 08:55:02 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=46
05/22/2022 08:55:05 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.06 on epoch=46
05/22/2022 08:55:18 - INFO - __main__ - Global step 1300 Train loss 0.06 Classification-F1 0.988835519639091 on epoch=46
05/22/2022 08:55:18 - INFO - __main__ - Saving model with best Classification-F1: 0.9196344631385617 -> 0.988835519639091 on epoch=46, global_step=1300
05/22/2022 08:55:20 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=46
05/22/2022 08:55:23 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.07 on epoch=47
05/22/2022 08:55:25 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=47
05/22/2022 08:55:28 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=47
05/22/2022 08:55:31 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.04 on epoch=48
05/22/2022 08:55:44 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.863239442043005 on epoch=48
05/22/2022 08:55:46 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=48
05/22/2022 08:55:49 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.06 on epoch=48
05/22/2022 08:55:51 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.02 on epoch=49
05/22/2022 08:55:54 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=49
05/22/2022 08:55:57 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.04 on epoch=49
05/22/2022 08:56:10 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9865890733338265 on epoch=49
05/22/2022 08:56:13 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.09 on epoch=50
05/22/2022 08:56:15 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.08 on epoch=50
05/22/2022 08:56:18 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.05 on epoch=51
05/22/2022 08:56:20 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.05 on epoch=51
05/22/2022 08:56:23 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=51
05/22/2022 08:56:36 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.9184687072187072 on epoch=51
05/22/2022 08:56:38 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.03 on epoch=52
05/22/2022 08:56:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.03 on epoch=52
05/22/2022 08:56:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.07 on epoch=52
05/22/2022 08:56:46 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.02 on epoch=53
05/22/2022 08:56:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=53
05/22/2022 08:57:02 - INFO - __main__ - Global step 1500 Train loss 0.04 Classification-F1 0.8095702246758333 on epoch=53
05/22/2022 08:57:04 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=53
05/22/2022 08:57:07 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.06 on epoch=54
05/22/2022 08:57:09 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.05 on epoch=54
05/22/2022 08:57:12 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.07 on epoch=54
05/22/2022 08:57:14 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=55
05/22/2022 08:57:27 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.8498111207788628 on epoch=55
05/22/2022 08:57:30 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=55
05/22/2022 08:57:32 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.03 on epoch=56
05/22/2022 08:57:35 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.05 on epoch=56
05/22/2022 08:57:38 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.02 on epoch=56
05/22/2022 08:57:40 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.03 on epoch=57
05/22/2022 08:57:53 - INFO - __main__ - Global step 1600 Train loss 0.04 Classification-F1 0.8612026400458861 on epoch=57
05/22/2022 08:57:55 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=57
05/22/2022 08:57:58 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.03 on epoch=57
05/22/2022 08:58:00 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.02 on epoch=58
05/22/2022 08:58:03 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.07 on epoch=58
05/22/2022 08:58:05 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=58
05/22/2022 08:58:18 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9865909743480413 on epoch=58
05/22/2022 08:58:21 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.03 on epoch=59
05/22/2022 08:58:23 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.05 on epoch=59
05/22/2022 08:58:26 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=59
05/22/2022 08:58:28 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=60
05/22/2022 08:58:31 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=60
05/22/2022 08:58:44 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9865909743480413 on epoch=60
05/22/2022 08:58:46 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.05 on epoch=61
05/22/2022 08:58:49 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.03 on epoch=61
05/22/2022 08:58:51 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=61
05/22/2022 08:58:54 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=62
05/22/2022 08:58:56 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 08:59:09 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.921844193706501 on epoch=62
05/22/2022 08:59:12 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=62
05/22/2022 08:59:14 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.01 on epoch=63
05/22/2022 08:59:17 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.02 on epoch=63
05/22/2022 08:59:19 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=63
05/22/2022 08:59:22 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=64
05/22/2022 08:59:34 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8621524907021998 on epoch=64
05/22/2022 08:59:37 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=64
05/22/2022 08:59:39 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=64
05/22/2022 08:59:42 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.02 on epoch=65
05/22/2022 08:59:45 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.02 on epoch=65
05/22/2022 08:59:47 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.04 on epoch=66
05/22/2022 09:00:00 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.9218406294690656 on epoch=66
05/22/2022 09:00:03 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=66
05/22/2022 09:00:05 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.02 on epoch=66
05/22/2022 09:00:08 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.02 on epoch=67
05/22/2022 09:00:10 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.04 on epoch=67
05/22/2022 09:00:13 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=67
05/22/2022 09:00:26 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8651926852746525 on epoch=67
05/22/2022 09:00:29 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=68
05/22/2022 09:00:31 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.02 on epoch=68
05/22/2022 09:00:34 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 09:00:36 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.02 on epoch=69
05/22/2022 09:00:39 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=69
05/22/2022 09:00:51 - INFO - __main__ - Global step 1950 Train loss 0.03 Classification-F1 0.8620180821000494 on epoch=69
05/22/2022 09:00:54 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=69
05/22/2022 09:00:57 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.02 on epoch=70
05/22/2022 09:00:59 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=70
05/22/2022 09:01:02 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=71
05/22/2022 09:01:04 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=71
05/22/2022 09:01:17 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9184543860828224 on epoch=71
05/22/2022 09:01:20 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=71
05/22/2022 09:01:22 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=72
05/22/2022 09:01:25 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.01 on epoch=72
05/22/2022 09:01:27 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=72
05/22/2022 09:01:30 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=73
05/22/2022 09:01:43 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.9218406294690656 on epoch=73
05/22/2022 09:01:45 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.01 on epoch=73
05/22/2022 09:01:48 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=73
05/22/2022 09:01:50 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=74
05/22/2022 09:01:53 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.04 on epoch=74
05/22/2022 09:01:56 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.02 on epoch=74
05/22/2022 09:02:08 - INFO - __main__ - Global step 2100 Train loss 0.02 Classification-F1 0.9888239943907521 on epoch=74
05/22/2022 09:02:11 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=75
05/22/2022 09:02:13 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=75
05/22/2022 09:02:16 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=76
05/22/2022 09:02:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.06 on epoch=76
05/22/2022 09:02:21 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.03 on epoch=76
05/22/2022 09:02:34 - INFO - __main__ - Global step 2150 Train loss 0.03 Classification-F1 0.9218406294690656 on epoch=76
05/22/2022 09:02:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=77
05/22/2022 09:02:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=77
05/22/2022 09:02:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=77
05/22/2022 09:02:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.01 on epoch=78
05/22/2022 09:02:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=78
05/22/2022 09:02:59 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9176772969475243 on epoch=78
05/22/2022 09:03:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 09:03:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=79
05/22/2022 09:03:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=79
05/22/2022 09:03:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.03 on epoch=79
05/22/2022 09:03:12 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.02 on epoch=80
05/22/2022 09:03:25 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9207557000259273 on epoch=80
05/22/2022 09:03:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 09:03:30 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 09:03:33 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=81
05/22/2022 09:03:35 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=81
05/22/2022 09:03:38 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=82
05/22/2022 09:03:51 - INFO - __main__ - Global step 2300 Train loss 0.01 Classification-F1 0.9888201755649286 on epoch=82
05/22/2022 09:03:53 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=82
05/22/2022 09:03:56 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=82
05/22/2022 09:03:58 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=83
05/22/2022 09:04:01 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=83
05/22/2022 09:04:03 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=83
05/22/2022 09:04:16 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.8151807290327214 on epoch=83
05/22/2022 09:04:19 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.01 on epoch=84
05/22/2022 09:04:21 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=84
05/22/2022 09:04:24 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=84
05/22/2022 09:04:26 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=85
05/22/2022 09:04:29 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=85
05/22/2022 09:04:42 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.986587487617955 on epoch=85
05/22/2022 09:04:44 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=86
05/22/2022 09:04:47 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=86
05/22/2022 09:04:50 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.01 on epoch=86
05/22/2022 09:04:52 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 09:04:55 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=87
05/22/2022 09:05:07 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9301571546732837 on epoch=87
05/22/2022 09:05:10 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.02 on epoch=87
05/22/2022 09:05:12 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=88
05/22/2022 09:05:15 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.01 on epoch=88
05/22/2022 09:05:18 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 09:05:20 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.00 on epoch=89
05/22/2022 09:05:33 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9888201755649286 on epoch=89
05/22/2022 09:05:36 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=89
05/22/2022 09:05:38 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 09:05:41 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=90
05/22/2022 09:05:43 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=90
05/22/2022 09:05:46 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.02 on epoch=91
05/22/2022 09:05:59 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9260113691236763 on epoch=91
05/22/2022 09:06:01 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.03 on epoch=91
05/22/2022 09:06:04 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 09:06:06 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=92
05/22/2022 09:06:09 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=92
05/22/2022 09:06:11 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=92
05/22/2022 09:06:24 - INFO - __main__ - Global step 2600 Train loss 0.04 Classification-F1 0.9239275270398343 on epoch=92
05/22/2022 09:06:27 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=93
05/22/2022 09:06:29 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.00 on epoch=93
05/22/2022 09:06:32 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=93
05/22/2022 09:06:34 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 09:06:37 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.07 on epoch=94
05/22/2022 09:06:50 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9932986624230864 on epoch=94
05/22/2022 09:06:50 - INFO - __main__ - Saving model with best Classification-F1: 0.988835519639091 -> 0.9932986624230864 on epoch=94, global_step=2650
05/22/2022 09:06:52 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=94
05/22/2022 09:06:55 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=95
05/22/2022 09:06:57 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.01 on epoch=95
05/22/2022 09:07:00 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.01 on epoch=96
05/22/2022 09:07:02 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=96
05/22/2022 09:07:15 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.8141758946462526 on epoch=96
05/22/2022 09:07:18 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=96
05/22/2022 09:07:20 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=97
05/22/2022 09:07:23 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.01 on epoch=97
05/22/2022 09:07:25 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=97
05/22/2022 09:07:28 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=98
05/22/2022 09:07:40 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9239275270398343 on epoch=98
05/22/2022 09:07:43 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.01 on epoch=98
05/22/2022 09:07:46 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.00 on epoch=98
05/22/2022 09:07:48 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=99
05/22/2022 09:07:51 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.08 on epoch=99
05/22/2022 09:07:53 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=99
05/22/2022 09:08:06 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.926014240768339 on epoch=99
05/22/2022 09:08:09 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.00 on epoch=100
05/22/2022 09:08:11 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=100
05/22/2022 09:08:14 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=101
05/22/2022 09:08:16 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=101
05/22/2022 09:08:19 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.01 on epoch=101
05/22/2022 09:08:32 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9260113691236763 on epoch=101
05/22/2022 09:08:35 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=102
05/22/2022 09:08:37 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.03 on epoch=102
05/22/2022 09:08:40 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=102
05/22/2022 09:08:43 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=103
05/22/2022 09:08:45 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 09:08:58 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9932888251948686 on epoch=103
05/22/2022 09:09:00 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=103
05/22/2022 09:09:03 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=104
05/22/2022 09:09:06 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.01 on epoch=104
05/22/2022 09:09:08 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=104
05/22/2022 09:09:11 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.05 on epoch=105
05/22/2022 09:09:23 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9260113691236763 on epoch=105
05/22/2022 09:09:26 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 09:09:28 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.03 on epoch=106
05/22/2022 09:09:31 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 09:09:34 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 09:09:36 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=107
05/22/2022 09:09:38 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:09:38 - INFO - __main__ - Printing 3 examples
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:09:38 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:09:38 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 09:09:38 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:09:38 - INFO - __main__ - Printing 3 examples
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 09:09:38 - INFO - __main__ - ['Company']
05/22/2022 09:09:38 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:09:39 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:09:39 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 09:09:49 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9260113691236763 on epoch=107
05/22/2022 09:09:49 - INFO - __main__ - save last model!
05/22/2022 09:09:49 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 09:09:49 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 09:09:49 - INFO - __main__ - Printing 3 examples
05/22/2022 09:09:49 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 09:09:49 - INFO - __main__ - ['Animal']
05/22/2022 09:09:49 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 09:09:49 - INFO - __main__ - ['Animal']
05/22/2022 09:09:49 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 09:09:49 - INFO - __main__ - ['Village']
05/22/2022 09:09:49 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:09:51 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:09:54 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 09:09:55 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 09:09:56 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 09:09:56 - INFO - __main__ - Starting training!
05/22/2022 09:12:06 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_42_0.5_8_predictions.txt
05/22/2022 09:12:06 - INFO - __main__ - Classification-F1 on test data: 0.5955
05/22/2022 09:12:06 - INFO - __main__ - prefix=dbpedia_14_32_42, lr=0.5, bsz=8, dev_performance=0.9932986624230864, test_performance=0.5954915324172786
05/22/2022 09:12:06 - INFO - __main__ - Running ... prefix=dbpedia_14_32_42, lr=0.4, bsz=8 ...
05/22/2022 09:12:07 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:12:07 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:07 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 09:12:07 - INFO - __main__ - ['Company']
05/22/2022 09:12:07 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 09:12:07 - INFO - __main__ - ['Company']
05/22/2022 09:12:07 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 09:12:07 - INFO - __main__ - ['Company']
05/22/2022 09:12:07 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:07 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:08 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 09:12:08 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:12:08 - INFO - __main__ - Printing 3 examples
05/22/2022 09:12:08 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 09:12:08 - INFO - __main__ - ['Company']
05/22/2022 09:12:08 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 09:12:08 - INFO - __main__ - ['Company']
05/22/2022 09:12:08 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 09:12:08 - INFO - __main__ - ['Company']
05/22/2022 09:12:08 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:12:08 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:12:09 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 09:12:25 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 09:12:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 09:12:25 - INFO - __main__ - Starting training!
05/22/2022 09:12:29 - INFO - __main__ - Step 10 Global step 10 Train loss 7.11 on epoch=0
05/22/2022 09:12:32 - INFO - __main__ - Step 20 Global step 20 Train loss 5.26 on epoch=0
05/22/2022 09:12:34 - INFO - __main__ - Step 30 Global step 30 Train loss 4.27 on epoch=1
05/22/2022 09:12:37 - INFO - __main__ - Step 40 Global step 40 Train loss 3.56 on epoch=1
05/22/2022 09:12:39 - INFO - __main__ - Step 50 Global step 50 Train loss 3.54 on epoch=1
05/22/2022 09:12:53 - INFO - __main__ - Global step 50 Train loss 4.75 Classification-F1 0.023233835597166127 on epoch=1
05/22/2022 09:12:53 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.023233835597166127 on epoch=1, global_step=50
05/22/2022 09:12:55 - INFO - __main__ - Step 60 Global step 60 Train loss 2.96 on epoch=2
05/22/2022 09:12:58 - INFO - __main__ - Step 70 Global step 70 Train loss 2.59 on epoch=2
05/22/2022 09:13:01 - INFO - __main__ - Step 80 Global step 80 Train loss 2.52 on epoch=2
05/22/2022 09:13:03 - INFO - __main__ - Step 90 Global step 90 Train loss 1.94 on epoch=3
05/22/2022 09:13:06 - INFO - __main__ - Step 100 Global step 100 Train loss 2.14 on epoch=3
05/22/2022 09:13:18 - INFO - __main__ - Global step 100 Train loss 2.43 Classification-F1 0.06673781105115764 on epoch=3
05/22/2022 09:13:18 - INFO - __main__ - Saving model with best Classification-F1: 0.023233835597166127 -> 0.06673781105115764 on epoch=3, global_step=100
05/22/2022 09:13:20 - INFO - __main__ - Step 110 Global step 110 Train loss 1.99 on epoch=3
05/22/2022 09:13:23 - INFO - __main__ - Step 120 Global step 120 Train loss 1.67 on epoch=4
05/22/2022 09:13:25 - INFO - __main__ - Step 130 Global step 130 Train loss 1.83 on epoch=4
05/22/2022 09:13:28 - INFO - __main__ - Step 140 Global step 140 Train loss 1.53 on epoch=4
05/22/2022 09:13:31 - INFO - __main__ - Step 150 Global step 150 Train loss 1.27 on epoch=5
05/22/2022 09:13:42 - INFO - __main__ - Global step 150 Train loss 1.66 Classification-F1 0.11719758187403924 on epoch=5
05/22/2022 09:13:42 - INFO - __main__ - Saving model with best Classification-F1: 0.06673781105115764 -> 0.11719758187403924 on epoch=5, global_step=150
05/22/2022 09:13:45 - INFO - __main__ - Step 160 Global step 160 Train loss 1.51 on epoch=5
05/22/2022 09:13:47 - INFO - __main__ - Step 170 Global step 170 Train loss 1.23 on epoch=6
05/22/2022 09:13:50 - INFO - __main__ - Step 180 Global step 180 Train loss 1.06 on epoch=6
05/22/2022 09:13:53 - INFO - __main__ - Step 190 Global step 190 Train loss 1.12 on epoch=6
05/22/2022 09:13:55 - INFO - __main__ - Step 200 Global step 200 Train loss 1.00 on epoch=7
05/22/2022 09:14:07 - INFO - __main__ - Global step 200 Train loss 1.19 Classification-F1 0.1932510763776871 on epoch=7
05/22/2022 09:14:07 - INFO - __main__ - Saving model with best Classification-F1: 0.11719758187403924 -> 0.1932510763776871 on epoch=7, global_step=200
05/22/2022 09:14:09 - INFO - __main__ - Step 210 Global step 210 Train loss 0.86 on epoch=7
05/22/2022 09:14:12 - INFO - __main__ - Step 220 Global step 220 Train loss 0.84 on epoch=7
05/22/2022 09:14:15 - INFO - __main__ - Step 230 Global step 230 Train loss 0.67 on epoch=8
05/22/2022 09:14:17 - INFO - __main__ - Step 240 Global step 240 Train loss 0.76 on epoch=8
05/22/2022 09:14:20 - INFO - __main__ - Step 250 Global step 250 Train loss 0.68 on epoch=8
05/22/2022 09:14:32 - INFO - __main__ - Global step 250 Train loss 0.76 Classification-F1 0.2806559396654772 on epoch=8
05/22/2022 09:14:32 - INFO - __main__ - Saving model with best Classification-F1: 0.1932510763776871 -> 0.2806559396654772 on epoch=8, global_step=250
05/22/2022 09:14:35 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=9
05/22/2022 09:14:38 - INFO - __main__ - Step 270 Global step 270 Train loss 0.77 on epoch=9
05/22/2022 09:14:40 - INFO - __main__ - Step 280 Global step 280 Train loss 0.58 on epoch=9
05/22/2022 09:14:43 - INFO - __main__ - Step 290 Global step 290 Train loss 0.52 on epoch=10
05/22/2022 09:14:45 - INFO - __main__ - Step 300 Global step 300 Train loss 0.43 on epoch=10
05/22/2022 09:14:58 - INFO - __main__ - Global step 300 Train loss 0.58 Classification-F1 0.41820471426823225 on epoch=10
05/22/2022 09:14:58 - INFO - __main__ - Saving model with best Classification-F1: 0.2806559396654772 -> 0.41820471426823225 on epoch=10, global_step=300
05/22/2022 09:15:01 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=11
05/22/2022 09:15:04 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=11
05/22/2022 09:15:06 - INFO - __main__ - Step 330 Global step 330 Train loss 0.61 on epoch=11
05/22/2022 09:15:09 - INFO - __main__ - Step 340 Global step 340 Train loss 0.39 on epoch=12
05/22/2022 09:15:12 - INFO - __main__ - Step 350 Global step 350 Train loss 0.32 on epoch=12
05/22/2022 09:15:25 - INFO - __main__ - Global step 350 Train loss 0.43 Classification-F1 0.567607030299772 on epoch=12
05/22/2022 09:15:25 - INFO - __main__ - Saving model with best Classification-F1: 0.41820471426823225 -> 0.567607030299772 on epoch=12, global_step=350
05/22/2022 09:15:27 - INFO - __main__ - Step 360 Global step 360 Train loss 0.50 on epoch=12
05/22/2022 09:15:30 - INFO - __main__ - Step 370 Global step 370 Train loss 0.30 on epoch=13
05/22/2022 09:15:33 - INFO - __main__ - Step 380 Global step 380 Train loss 0.52 on epoch=13
05/22/2022 09:15:35 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=13
05/22/2022 09:15:38 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=14
05/22/2022 09:15:50 - INFO - __main__ - Global step 400 Train loss 0.40 Classification-F1 0.587187190154182 on epoch=14
05/22/2022 09:15:50 - INFO - __main__ - Saving model with best Classification-F1: 0.567607030299772 -> 0.587187190154182 on epoch=14, global_step=400
05/22/2022 09:15:53 - INFO - __main__ - Step 410 Global step 410 Train loss 0.33 on epoch=14
05/22/2022 09:15:55 - INFO - __main__ - Step 420 Global step 420 Train loss 0.40 on epoch=14
05/22/2022 09:15:58 - INFO - __main__ - Step 430 Global step 430 Train loss 0.30 on epoch=15
05/22/2022 09:16:01 - INFO - __main__ - Step 440 Global step 440 Train loss 0.34 on epoch=15
05/22/2022 09:16:03 - INFO - __main__ - Step 450 Global step 450 Train loss 0.32 on epoch=16
05/22/2022 09:16:16 - INFO - __main__ - Global step 450 Train loss 0.34 Classification-F1 0.548135474882177 on epoch=16
05/22/2022 09:16:18 - INFO - __main__ - Step 460 Global step 460 Train loss 0.29 on epoch=16
05/22/2022 09:16:21 - INFO - __main__ - Step 470 Global step 470 Train loss 0.36 on epoch=16
05/22/2022 09:16:24 - INFO - __main__ - Step 480 Global step 480 Train loss 0.22 on epoch=17
05/22/2022 09:16:26 - INFO - __main__ - Step 490 Global step 490 Train loss 0.28 on epoch=17
05/22/2022 09:16:29 - INFO - __main__ - Step 500 Global step 500 Train loss 0.36 on epoch=17
05/22/2022 09:16:41 - INFO - __main__ - Global step 500 Train loss 0.30 Classification-F1 0.6018054982638316 on epoch=17
05/22/2022 09:16:41 - INFO - __main__ - Saving model with best Classification-F1: 0.587187190154182 -> 0.6018054982638316 on epoch=17, global_step=500
05/22/2022 09:16:44 - INFO - __main__ - Step 510 Global step 510 Train loss 0.28 on epoch=18
05/22/2022 09:16:46 - INFO - __main__ - Step 520 Global step 520 Train loss 0.38 on epoch=18
05/22/2022 09:16:49 - INFO - __main__ - Step 530 Global step 530 Train loss 0.17 on epoch=18
05/22/2022 09:16:51 - INFO - __main__ - Step 540 Global step 540 Train loss 0.14 on epoch=19
05/22/2022 09:16:54 - INFO - __main__ - Step 550 Global step 550 Train loss 0.27 on epoch=19
05/22/2022 09:17:07 - INFO - __main__ - Global step 550 Train loss 0.25 Classification-F1 0.6127825445102842 on epoch=19
05/22/2022 09:17:07 - INFO - __main__ - Saving model with best Classification-F1: 0.6018054982638316 -> 0.6127825445102842 on epoch=19, global_step=550
05/22/2022 09:17:09 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=19
05/22/2022 09:17:12 - INFO - __main__ - Step 570 Global step 570 Train loss 0.21 on epoch=20
05/22/2022 09:17:15 - INFO - __main__ - Step 580 Global step 580 Train loss 0.27 on epoch=20
05/22/2022 09:17:17 - INFO - __main__ - Step 590 Global step 590 Train loss 0.18 on epoch=21
05/22/2022 09:17:20 - INFO - __main__ - Step 600 Global step 600 Train loss 0.27 on epoch=21
05/22/2022 09:17:32 - INFO - __main__ - Global step 600 Train loss 0.23 Classification-F1 0.7006693537943538 on epoch=21
05/22/2022 09:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.6127825445102842 -> 0.7006693537943538 on epoch=21, global_step=600
05/22/2022 09:17:35 - INFO - __main__ - Step 610 Global step 610 Train loss 0.20 on epoch=21
05/22/2022 09:17:38 - INFO - __main__ - Step 620 Global step 620 Train loss 0.18 on epoch=22
05/22/2022 09:17:40 - INFO - __main__ - Step 630 Global step 630 Train loss 0.11 on epoch=22
05/22/2022 09:17:43 - INFO - __main__ - Step 640 Global step 640 Train loss 0.20 on epoch=22
05/22/2022 09:17:46 - INFO - __main__ - Step 650 Global step 650 Train loss 0.13 on epoch=23
05/22/2022 09:17:58 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.663707761531738 on epoch=23
05/22/2022 09:18:00 - INFO - __main__ - Step 660 Global step 660 Train loss 0.19 on epoch=23
05/22/2022 09:18:03 - INFO - __main__ - Step 670 Global step 670 Train loss 0.25 on epoch=23
05/22/2022 09:18:06 - INFO - __main__ - Step 680 Global step 680 Train loss 0.14 on epoch=24
05/22/2022 09:18:08 - INFO - __main__ - Step 690 Global step 690 Train loss 0.23 on epoch=24
05/22/2022 09:18:11 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=24
05/22/2022 09:18:24 - INFO - __main__ - Global step 700 Train loss 0.19 Classification-F1 0.6237570539883409 on epoch=24
05/22/2022 09:18:26 - INFO - __main__ - Step 710 Global step 710 Train loss 0.19 on epoch=25
05/22/2022 09:18:29 - INFO - __main__ - Step 720 Global step 720 Train loss 0.17 on epoch=25
05/22/2022 09:18:32 - INFO - __main__ - Step 730 Global step 730 Train loss 0.19 on epoch=26
05/22/2022 09:18:34 - INFO - __main__ - Step 740 Global step 740 Train loss 0.14 on epoch=26
05/22/2022 09:18:37 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=26
05/22/2022 09:18:50 - INFO - __main__ - Global step 750 Train loss 0.19 Classification-F1 0.622761634141178 on epoch=26
05/22/2022 09:18:52 - INFO - __main__ - Step 760 Global step 760 Train loss 0.12 on epoch=27
05/22/2022 09:18:55 - INFO - __main__ - Step 770 Global step 770 Train loss 0.13 on epoch=27
05/22/2022 09:18:58 - INFO - __main__ - Step 780 Global step 780 Train loss 0.14 on epoch=27
05/22/2022 09:19:00 - INFO - __main__ - Step 790 Global step 790 Train loss 0.14 on epoch=28
05/22/2022 09:19:03 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=28
05/22/2022 09:19:16 - INFO - __main__ - Global step 800 Train loss 0.15 Classification-F1 0.6979384271075486 on epoch=28
05/22/2022 09:19:19 - INFO - __main__ - Step 810 Global step 810 Train loss 0.13 on epoch=28
05/22/2022 09:19:22 - INFO - __main__ - Step 820 Global step 820 Train loss 0.11 on epoch=29
05/22/2022 09:19:24 - INFO - __main__ - Step 830 Global step 830 Train loss 0.24 on epoch=29
05/22/2022 09:19:27 - INFO - __main__ - Step 840 Global step 840 Train loss 0.13 on epoch=29
05/22/2022 09:19:30 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=30
05/22/2022 09:19:42 - INFO - __main__ - Global step 850 Train loss 0.15 Classification-F1 0.6268018307071893 on epoch=30
05/22/2022 09:19:44 - INFO - __main__ - Step 860 Global step 860 Train loss 0.12 on epoch=30
05/22/2022 09:19:47 - INFO - __main__ - Step 870 Global step 870 Train loss 0.16 on epoch=31
05/22/2022 09:19:50 - INFO - __main__ - Step 880 Global step 880 Train loss 0.19 on epoch=31
05/22/2022 09:19:52 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=31
05/22/2022 09:19:55 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=32
05/22/2022 09:20:08 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.662702673211676 on epoch=32
05/22/2022 09:20:10 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=32
05/22/2022 09:20:13 - INFO - __main__ - Step 920 Global step 920 Train loss 0.15 on epoch=32
05/22/2022 09:20:16 - INFO - __main__ - Step 930 Global step 930 Train loss 0.08 on epoch=33
05/22/2022 09:20:18 - INFO - __main__ - Step 940 Global step 940 Train loss 0.12 on epoch=33
05/22/2022 09:20:21 - INFO - __main__ - Step 950 Global step 950 Train loss 0.13 on epoch=33
05/22/2022 09:20:33 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.6614337561175422 on epoch=33
05/22/2022 09:20:36 - INFO - __main__ - Step 960 Global step 960 Train loss 0.07 on epoch=34
05/22/2022 09:20:39 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=34
05/22/2022 09:20:41 - INFO - __main__ - Step 980 Global step 980 Train loss 0.09 on epoch=34
05/22/2022 09:20:44 - INFO - __main__ - Step 990 Global step 990 Train loss 0.11 on epoch=35
05/22/2022 09:20:47 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.10 on epoch=35
05/22/2022 09:20:59 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6305421685543496 on epoch=35
05/22/2022 09:21:01 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.12 on epoch=36
05/22/2022 09:21:04 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.15 on epoch=36
05/22/2022 09:21:06 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.15 on epoch=36
05/22/2022 09:21:09 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.09 on epoch=37
05/22/2022 09:21:12 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.10 on epoch=37
05/22/2022 09:21:24 - INFO - __main__ - Global step 1050 Train loss 0.12 Classification-F1 0.6846787032982479 on epoch=37
05/22/2022 09:21:27 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.06 on epoch=37
05/22/2022 09:21:29 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=38
05/22/2022 09:21:32 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.16 on epoch=38
05/22/2022 09:21:35 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=38
05/22/2022 09:21:37 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.09 on epoch=39
05/22/2022 09:21:50 - INFO - __main__ - Global step 1100 Train loss 0.10 Classification-F1 0.6625623407435801 on epoch=39
05/22/2022 09:21:52 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.10 on epoch=39
05/22/2022 09:21:55 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.11 on epoch=39
05/22/2022 09:21:58 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.08 on epoch=40
05/22/2022 09:22:00 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.19 on epoch=40
05/22/2022 09:22:03 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.08 on epoch=41
05/22/2022 09:22:16 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.665603298382457 on epoch=41
05/22/2022 09:22:18 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.06 on epoch=41
05/22/2022 09:22:21 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=41
05/22/2022 09:22:24 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=42
05/22/2022 09:22:26 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.08 on epoch=42
05/22/2022 09:22:29 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=42
05/22/2022 09:22:41 - INFO - __main__ - Global step 1200 Train loss 0.09 Classification-F1 0.7642481177686438 on epoch=42
05/22/2022 09:22:41 - INFO - __main__ - Saving model with best Classification-F1: 0.7006693537943538 -> 0.7642481177686438 on epoch=42, global_step=1200
05/22/2022 09:22:44 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=43
05/22/2022 09:22:46 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=43
05/22/2022 09:22:49 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.11 on epoch=43
05/22/2022 09:22:52 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.05 on epoch=44
05/22/2022 09:22:54 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.11 on epoch=44
05/22/2022 09:23:07 - INFO - __main__ - Global step 1250 Train loss 0.08 Classification-F1 0.6895516595113369 on epoch=44
05/22/2022 09:23:09 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.07 on epoch=44
05/22/2022 09:23:12 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.10 on epoch=45
05/22/2022 09:23:15 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.10 on epoch=45
05/22/2022 09:23:17 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=46
05/22/2022 09:23:20 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.09 on epoch=46
05/22/2022 09:23:32 - INFO - __main__ - Global step 1300 Train loss 0.09 Classification-F1 0.6738290382831756 on epoch=46
05/22/2022 09:23:35 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=46
05/22/2022 09:23:37 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.06 on epoch=47
05/22/2022 09:23:40 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.05 on epoch=47
05/22/2022 09:23:43 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.08 on epoch=47
05/22/2022 09:23:45 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.06 on epoch=48
05/22/2022 09:23:57 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.8008823057530945 on epoch=48
05/22/2022 09:23:58 - INFO - __main__ - Saving model with best Classification-F1: 0.7642481177686438 -> 0.8008823057530945 on epoch=48, global_step=1350
05/22/2022 09:24:00 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=48
05/22/2022 09:24:03 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.05 on epoch=48
05/22/2022 09:24:05 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=49
05/22/2022 09:24:08 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.08 on epoch=49
05/22/2022 09:24:11 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=49
05/22/2022 09:24:23 - INFO - __main__ - Global step 1400 Train loss 0.07 Classification-F1 0.9105531515149212 on epoch=49
05/22/2022 09:24:23 - INFO - __main__ - Saving model with best Classification-F1: 0.8008823057530945 -> 0.9105531515149212 on epoch=49, global_step=1400
05/22/2022 09:24:26 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.05 on epoch=50
05/22/2022 09:24:28 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.04 on epoch=50
05/22/2022 09:24:31 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=51
05/22/2022 09:24:34 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.09 on epoch=51
05/22/2022 09:24:36 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.13 on epoch=51
05/22/2022 09:24:49 - INFO - __main__ - Global step 1450 Train loss 0.07 Classification-F1 0.8485675768793167 on epoch=51
05/22/2022 09:24:51 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.06 on epoch=52
05/22/2022 09:24:54 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.06 on epoch=52
05/22/2022 09:24:56 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=52
05/22/2022 09:24:59 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.03 on epoch=53
05/22/2022 09:25:02 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=53
05/22/2022 09:25:14 - INFO - __main__ - Global step 1500 Train loss 0.06 Classification-F1 0.7907005989924611 on epoch=53
05/22/2022 09:25:17 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=53
05/22/2022 09:25:19 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=54
05/22/2022 09:25:22 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.10 on epoch=54
05/22/2022 09:25:24 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=54
05/22/2022 09:25:27 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=55
05/22/2022 09:25:39 - INFO - __main__ - Global step 1550 Train loss 0.06 Classification-F1 0.7376515669018185 on epoch=55
05/22/2022 09:25:42 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.06 on epoch=55
05/22/2022 09:25:45 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.07 on epoch=56
05/22/2022 09:25:47 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=56
05/22/2022 09:25:50 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.03 on epoch=56
05/22/2022 09:25:53 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.04 on epoch=57
05/22/2022 09:26:05 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8001653348155355 on epoch=57
05/22/2022 09:26:08 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.09 on epoch=57
05/22/2022 09:26:10 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.09 on epoch=57
05/22/2022 09:26:13 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.04 on epoch=58
05/22/2022 09:26:16 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=58
05/22/2022 09:26:18 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.05 on epoch=58
05/22/2022 09:26:31 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7716841744303279 on epoch=58
05/22/2022 09:26:33 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.05 on epoch=59
05/22/2022 09:26:36 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.11 on epoch=59
05/22/2022 09:26:38 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=59
05/22/2022 09:26:41 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=60
05/22/2022 09:26:44 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.03 on epoch=60
05/22/2022 09:26:56 - INFO - __main__ - Global step 1700 Train loss 0.05 Classification-F1 0.9167985935951113 on epoch=60
05/22/2022 09:26:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9105531515149212 -> 0.9167985935951113 on epoch=60, global_step=1700
05/22/2022 09:26:58 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.06 on epoch=61
05/22/2022 09:27:01 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.06 on epoch=61
05/22/2022 09:27:04 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.08 on epoch=61
05/22/2022 09:27:06 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.04 on epoch=62
05/22/2022 09:27:09 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=62
05/22/2022 09:27:21 - INFO - __main__ - Global step 1750 Train loss 0.06 Classification-F1 0.8000314399099464 on epoch=62
05/22/2022 09:27:24 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.05 on epoch=62
05/22/2022 09:27:27 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.03 on epoch=63
05/22/2022 09:27:29 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.09 on epoch=63
05/22/2022 09:27:32 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.06 on epoch=63
05/22/2022 09:27:34 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=64
05/22/2022 09:27:47 - INFO - __main__ - Global step 1800 Train loss 0.06 Classification-F1 0.9168018478765255 on epoch=64
05/22/2022 09:27:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9167985935951113 -> 0.9168018478765255 on epoch=64, global_step=1800
05/22/2022 09:27:49 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=64
05/22/2022 09:27:52 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=64
05/22/2022 09:27:55 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.05 on epoch=65
05/22/2022 09:27:57 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=65
05/22/2022 09:28:00 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=66
05/22/2022 09:28:12 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8632335266351857 on epoch=66
05/22/2022 09:28:15 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=66
05/22/2022 09:28:17 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.05 on epoch=66
05/22/2022 09:28:20 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.06 on epoch=67
05/22/2022 09:28:23 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.02 on epoch=67
05/22/2022 09:28:25 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.05 on epoch=67
05/22/2022 09:28:38 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.8576121345269028 on epoch=67
05/22/2022 09:28:40 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.04 on epoch=68
05/22/2022 09:28:43 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 09:28:46 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.05 on epoch=68
05/22/2022 09:28:48 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=69
05/22/2022 09:28:51 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.04 on epoch=69
05/22/2022 09:29:04 - INFO - __main__ - Global step 1950 Train loss 0.05 Classification-F1 0.8013490629187459 on epoch=69
05/22/2022 09:29:06 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.04 on epoch=69
05/22/2022 09:29:09 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.06 on epoch=70
05/22/2022 09:29:11 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.04 on epoch=70
05/22/2022 09:29:14 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=71
05/22/2022 09:29:17 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.06 on epoch=71
05/22/2022 09:29:29 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.6698586144366305 on epoch=71
05/22/2022 09:29:32 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.02 on epoch=71
05/22/2022 09:29:34 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.02 on epoch=72
05/22/2022 09:29:37 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.04 on epoch=72
05/22/2022 09:29:40 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.11 on epoch=72
05/22/2022 09:29:42 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=73
05/22/2022 09:29:55 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8460878650770818 on epoch=73
05/22/2022 09:29:57 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.03 on epoch=73
05/22/2022 09:30:00 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.03 on epoch=73
05/22/2022 09:30:03 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.01 on epoch=74
05/22/2022 09:30:05 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=74
05/22/2022 09:30:08 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.03 on epoch=74
05/22/2022 09:30:21 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.8388346801382429 on epoch=74
05/22/2022 09:30:23 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=75
05/22/2022 09:30:26 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.01 on epoch=75
05/22/2022 09:30:29 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=76
05/22/2022 09:30:31 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=76
05/22/2022 09:30:34 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=76
05/22/2022 09:30:47 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.8387650291828173 on epoch=76
05/22/2022 09:30:49 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=77
05/22/2022 09:30:52 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.04 on epoch=77
05/22/2022 09:30:55 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=77
05/22/2022 09:30:57 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 09:31:00 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=78
05/22/2022 09:31:12 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7301888286511221 on epoch=78
05/22/2022 09:31:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 09:31:18 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.01 on epoch=79
05/22/2022 09:31:21 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.04 on epoch=79
05/22/2022 09:31:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=79
05/22/2022 09:31:26 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 09:31:39 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7980466893377345 on epoch=80
05/22/2022 09:31:41 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=80
05/22/2022 09:31:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 09:31:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=81
05/22/2022 09:31:49 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.06 on epoch=81
05/22/2022 09:31:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.02 on epoch=82
05/22/2022 09:32:04 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7931640528983983 on epoch=82
05/22/2022 09:32:07 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=82
05/22/2022 09:32:10 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.04 on epoch=82
05/22/2022 09:32:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=83
05/22/2022 09:32:15 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.03 on epoch=83
05/22/2022 09:32:18 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.02 on epoch=83
05/22/2022 09:32:30 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.8020878070537164 on epoch=83
05/22/2022 09:32:33 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.04 on epoch=84
05/22/2022 09:32:36 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=84
05/22/2022 09:32:38 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.02 on epoch=84
05/22/2022 09:32:41 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=85
05/22/2022 09:32:44 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.02 on epoch=85
05/22/2022 09:32:56 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.8445677371131848 on epoch=85
05/22/2022 09:32:59 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.02 on epoch=86
05/22/2022 09:33:01 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.02 on epoch=86
05/22/2022 09:33:04 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.07 on epoch=86
05/22/2022 09:33:06 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 09:33:09 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.07 on epoch=87
05/22/2022 09:33:22 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9239275270398343 on epoch=87
05/22/2022 09:33:22 - INFO - __main__ - Saving model with best Classification-F1: 0.9168018478765255 -> 0.9239275270398343 on epoch=87, global_step=2450
05/22/2022 09:33:24 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.04 on epoch=87
05/22/2022 09:33:27 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=88
05/22/2022 09:33:30 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 09:33:32 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.05 on epoch=88
05/22/2022 09:33:35 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=89
05/22/2022 09:33:47 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.8903437464793096 on epoch=89
05/22/2022 09:33:50 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=89
05/22/2022 09:33:52 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.01 on epoch=89
05/22/2022 09:33:55 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=90
05/22/2022 09:33:58 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 09:34:00 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=91
05/22/2022 09:34:13 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.8507945766962357 on epoch=91
05/22/2022 09:34:15 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=91
05/22/2022 09:34:18 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 09:34:21 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=92
05/22/2022 09:34:23 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.01 on epoch=92
05/22/2022 09:34:26 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.03 on epoch=92
05/22/2022 09:34:38 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.9239275270398343 on epoch=92
05/22/2022 09:34:41 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=93
05/22/2022 09:34:44 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=93
05/22/2022 09:34:46 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.05 on epoch=93
05/22/2022 09:34:49 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 09:34:51 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.04 on epoch=94
05/22/2022 09:35:04 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9228351904636267 on epoch=94
05/22/2022 09:35:07 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=94
05/22/2022 09:35:09 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.06 on epoch=95
05/22/2022 09:35:12 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=95
05/22/2022 09:35:14 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=96
05/22/2022 09:35:17 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.03 on epoch=96
05/22/2022 09:35:30 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9079625756578503 on epoch=96
05/22/2022 09:35:32 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=96
05/22/2022 09:35:35 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=97
05/22/2022 09:35:38 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=97
05/22/2022 09:35:40 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.02 on epoch=97
05/22/2022 09:35:43 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=98
05/22/2022 09:35:56 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9888239943907521 on epoch=98
05/22/2022 09:35:56 - INFO - __main__ - Saving model with best Classification-F1: 0.9239275270398343 -> 0.9888239943907521 on epoch=98, global_step=2750
05/22/2022 09:35:58 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.02 on epoch=98
05/22/2022 09:36:01 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=98
05/22/2022 09:36:03 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=99
05/22/2022 09:36:06 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=99
05/22/2022 09:36:09 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.04 on epoch=99
05/22/2022 09:36:21 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9865890733338265 on epoch=99
05/22/2022 09:36:24 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=100
05/22/2022 09:36:26 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=100
05/22/2022 09:36:29 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 09:36:32 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=101
05/22/2022 09:36:34 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=101
05/22/2022 09:36:46 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.991056137247895 on epoch=101
05/22/2022 09:36:46 - INFO - __main__ - Saving model with best Classification-F1: 0.9888239943907521 -> 0.991056137247895 on epoch=101, global_step=2850
05/22/2022 09:36:49 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=102
05/22/2022 09:36:52 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=102
05/22/2022 09:36:54 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=102
05/22/2022 09:36:57 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 09:36:59 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=103
05/22/2022 09:37:12 - INFO - __main__ - Global step 2900 Train loss 0.03 Classification-F1 0.8606807699868751 on epoch=103
05/22/2022 09:37:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=103
05/22/2022 09:37:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.01 on epoch=104
05/22/2022 09:37:20 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.04 on epoch=104
05/22/2022 09:37:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=104
05/22/2022 09:37:25 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.02 on epoch=105
05/22/2022 09:37:38 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9888201755649286 on epoch=105
05/22/2022 09:37:41 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=105
05/22/2022 09:37:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 09:37:46 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 09:37:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=106
05/22/2022 09:37:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.02 on epoch=107
05/22/2022 09:37:52 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:37:52 - INFO - __main__ - Printing 3 examples
05/22/2022 09:37:52 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 09:37:52 - INFO - __main__ - ['Company']
05/22/2022 09:37:52 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 09:37:52 - INFO - __main__ - ['Company']
05/22/2022 09:37:52 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 09:37:52 - INFO - __main__ - ['Company']
05/22/2022 09:37:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:37:53 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:37:53 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 09:37:53 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:37:53 - INFO - __main__ - Printing 3 examples
05/22/2022 09:37:53 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 09:37:53 - INFO - __main__ - ['Company']
05/22/2022 09:37:53 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 09:37:53 - INFO - __main__ - ['Company']
05/22/2022 09:37:53 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 09:37:53 - INFO - __main__ - ['Company']
05/22/2022 09:37:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:37:53 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:37:54 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 09:38:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.8641394822053203 on epoch=107
05/22/2022 09:38:04 - INFO - __main__ - save last model!
05/22/2022 09:38:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 09:38:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 09:38:04 - INFO - __main__ - Printing 3 examples
05/22/2022 09:38:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 09:38:04 - INFO - __main__ - ['Animal']
05/22/2022 09:38:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 09:38:04 - INFO - __main__ - ['Animal']
05/22/2022 09:38:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 09:38:04 - INFO - __main__ - ['Village']
05/22/2022 09:38:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:38:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:38:09 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 09:38:12 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 09:38:13 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 09:38:13 - INFO - __main__ - Starting training!
05/22/2022 09:40:17 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_42_0.4_8_predictions.txt
05/22/2022 09:40:17 - INFO - __main__ - Classification-F1 on test data: 0.5479
05/22/2022 09:40:18 - INFO - __main__ - prefix=dbpedia_14_32_42, lr=0.4, bsz=8, dev_performance=0.991056137247895, test_performance=0.5478563163167703
05/22/2022 09:40:18 - INFO - __main__ - Running ... prefix=dbpedia_14_32_42, lr=0.3, bsz=8 ...
05/22/2022 09:40:19 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:40:19 - INFO - __main__ - Printing 3 examples
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:40:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:40:19 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 09:40:19 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 09:40:19 - INFO - __main__ - Printing 3 examples
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 09:40:19 - INFO - __main__ - ['Company']
05/22/2022 09:40:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 09:40:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 09:40:20 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 09:40:38 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 09:40:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 09:40:39 - INFO - __main__ - Starting training!
05/22/2022 09:40:43 - INFO - __main__ - Step 10 Global step 10 Train loss 7.08 on epoch=0
05/22/2022 09:40:45 - INFO - __main__ - Step 20 Global step 20 Train loss 5.48 on epoch=0
05/22/2022 09:40:48 - INFO - __main__ - Step 30 Global step 30 Train loss 4.63 on epoch=1
05/22/2022 09:40:51 - INFO - __main__ - Step 40 Global step 40 Train loss 3.81 on epoch=1
05/22/2022 09:40:53 - INFO - __main__ - Step 50 Global step 50 Train loss 3.93 on epoch=1
05/22/2022 09:41:07 - INFO - __main__ - Global step 50 Train loss 4.99 Classification-F1 0.019002817600170457 on epoch=1
05/22/2022 09:41:08 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.019002817600170457 on epoch=1, global_step=50
05/22/2022 09:41:10 - INFO - __main__ - Step 60 Global step 60 Train loss 3.23 on epoch=2
05/22/2022 09:41:13 - INFO - __main__ - Step 70 Global step 70 Train loss 3.07 on epoch=2
05/22/2022 09:41:15 - INFO - __main__ - Step 80 Global step 80 Train loss 2.83 on epoch=2
05/22/2022 09:41:18 - INFO - __main__ - Step 90 Global step 90 Train loss 2.26 on epoch=3
05/22/2022 09:41:21 - INFO - __main__ - Step 100 Global step 100 Train loss 2.52 on epoch=3
05/22/2022 09:41:34 - INFO - __main__ - Global step 100 Train loss 2.78 Classification-F1 0.04295577132491195 on epoch=3
05/22/2022 09:41:34 - INFO - __main__ - Saving model with best Classification-F1: 0.019002817600170457 -> 0.04295577132491195 on epoch=3, global_step=100
05/22/2022 09:41:36 - INFO - __main__ - Step 110 Global step 110 Train loss 2.39 on epoch=3
05/22/2022 09:41:39 - INFO - __main__ - Step 120 Global step 120 Train loss 1.96 on epoch=4
05/22/2022 09:41:41 - INFO - __main__ - Step 130 Global step 130 Train loss 2.12 on epoch=4
05/22/2022 09:41:44 - INFO - __main__ - Step 140 Global step 140 Train loss 1.92 on epoch=4
05/22/2022 09:41:47 - INFO - __main__ - Step 150 Global step 150 Train loss 1.50 on epoch=5
05/22/2022 09:41:58 - INFO - __main__ - Global step 150 Train loss 1.98 Classification-F1 0.08034683887598536 on epoch=5
05/22/2022 09:41:58 - INFO - __main__ - Saving model with best Classification-F1: 0.04295577132491195 -> 0.08034683887598536 on epoch=5, global_step=150
05/22/2022 09:42:00 - INFO - __main__ - Step 160 Global step 160 Train loss 1.87 on epoch=5
05/22/2022 09:42:03 - INFO - __main__ - Step 170 Global step 170 Train loss 1.65 on epoch=6
05/22/2022 09:42:06 - INFO - __main__ - Step 180 Global step 180 Train loss 1.38 on epoch=6
05/22/2022 09:42:08 - INFO - __main__ - Step 190 Global step 190 Train loss 1.52 on epoch=6
05/22/2022 09:42:11 - INFO - __main__ - Step 200 Global step 200 Train loss 1.43 on epoch=7
05/22/2022 09:42:22 - INFO - __main__ - Global step 200 Train loss 1.57 Classification-F1 0.1265424621875251 on epoch=7
05/22/2022 09:42:22 - INFO - __main__ - Saving model with best Classification-F1: 0.08034683887598536 -> 0.1265424621875251 on epoch=7, global_step=200
05/22/2022 09:42:24 - INFO - __main__ - Step 210 Global step 210 Train loss 1.36 on epoch=7
05/22/2022 09:42:27 - INFO - __main__ - Step 220 Global step 220 Train loss 1.25 on epoch=7
05/22/2022 09:42:29 - INFO - __main__ - Step 230 Global step 230 Train loss 1.00 on epoch=8
05/22/2022 09:42:32 - INFO - __main__ - Step 240 Global step 240 Train loss 1.23 on epoch=8
05/22/2022 09:42:35 - INFO - __main__ - Step 250 Global step 250 Train loss 1.10 on epoch=8
05/22/2022 09:42:46 - INFO - __main__ - Global step 250 Train loss 1.19 Classification-F1 0.1850507143839065 on epoch=8
05/22/2022 09:42:46 - INFO - __main__ - Saving model with best Classification-F1: 0.1265424621875251 -> 0.1850507143839065 on epoch=8, global_step=250
05/22/2022 09:42:48 - INFO - __main__ - Step 260 Global step 260 Train loss 0.84 on epoch=9
05/22/2022 09:42:51 - INFO - __main__ - Step 270 Global step 270 Train loss 0.98 on epoch=9
05/22/2022 09:42:53 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=9
05/22/2022 09:42:56 - INFO - __main__ - Step 290 Global step 290 Train loss 0.76 on epoch=10
05/22/2022 09:42:59 - INFO - __main__ - Step 300 Global step 300 Train loss 0.76 on epoch=10
05/22/2022 09:43:10 - INFO - __main__ - Global step 300 Train loss 0.84 Classification-F1 0.23249692361075083 on epoch=10
05/22/2022 09:43:10 - INFO - __main__ - Saving model with best Classification-F1: 0.1850507143839065 -> 0.23249692361075083 on epoch=10, global_step=300
05/22/2022 09:43:13 - INFO - __main__ - Step 310 Global step 310 Train loss 0.80 on epoch=11
05/22/2022 09:43:16 - INFO - __main__ - Step 320 Global step 320 Train loss 0.62 on epoch=11
05/22/2022 09:43:18 - INFO - __main__ - Step 330 Global step 330 Train loss 0.74 on epoch=11
05/22/2022 09:43:21 - INFO - __main__ - Step 340 Global step 340 Train loss 0.65 on epoch=12
05/22/2022 09:43:23 - INFO - __main__ - Step 350 Global step 350 Train loss 0.65 on epoch=12
05/22/2022 09:43:36 - INFO - __main__ - Global step 350 Train loss 0.69 Classification-F1 0.33518698164247807 on epoch=12
05/22/2022 09:43:36 - INFO - __main__ - Saving model with best Classification-F1: 0.23249692361075083 -> 0.33518698164247807 on epoch=12, global_step=350
05/22/2022 09:43:39 - INFO - __main__ - Step 360 Global step 360 Train loss 0.67 on epoch=12
05/22/2022 09:43:41 - INFO - __main__ - Step 370 Global step 370 Train loss 0.47 on epoch=13
05/22/2022 09:43:44 - INFO - __main__ - Step 380 Global step 380 Train loss 0.57 on epoch=13
05/22/2022 09:43:47 - INFO - __main__ - Step 390 Global step 390 Train loss 0.50 on epoch=13
05/22/2022 09:43:49 - INFO - __main__ - Step 400 Global step 400 Train loss 0.45 on epoch=14
05/22/2022 09:44:01 - INFO - __main__ - Global step 400 Train loss 0.53 Classification-F1 0.43992437480938484 on epoch=14
05/22/2022 09:44:02 - INFO - __main__ - Saving model with best Classification-F1: 0.33518698164247807 -> 0.43992437480938484 on epoch=14, global_step=400
05/22/2022 09:44:04 - INFO - __main__ - Step 410 Global step 410 Train loss 0.56 on epoch=14
05/22/2022 09:44:07 - INFO - __main__ - Step 420 Global step 420 Train loss 0.41 on epoch=14
05/22/2022 09:44:09 - INFO - __main__ - Step 430 Global step 430 Train loss 0.37 on epoch=15
05/22/2022 09:44:12 - INFO - __main__ - Step 440 Global step 440 Train loss 0.51 on epoch=15
05/22/2022 09:44:14 - INFO - __main__ - Step 450 Global step 450 Train loss 0.44 on epoch=16
05/22/2022 09:44:27 - INFO - __main__ - Global step 450 Train loss 0.46 Classification-F1 0.5011733499058569 on epoch=16
05/22/2022 09:44:27 - INFO - __main__ - Saving model with best Classification-F1: 0.43992437480938484 -> 0.5011733499058569 on epoch=16, global_step=450
05/22/2022 09:44:30 - INFO - __main__ - Step 460 Global step 460 Train loss 0.40 on epoch=16
05/22/2022 09:44:33 - INFO - __main__ - Step 470 Global step 470 Train loss 0.38 on epoch=16
05/22/2022 09:44:35 - INFO - __main__ - Step 480 Global step 480 Train loss 0.35 on epoch=17
05/22/2022 09:44:38 - INFO - __main__ - Step 490 Global step 490 Train loss 0.27 on epoch=17
05/22/2022 09:44:40 - INFO - __main__ - Step 500 Global step 500 Train loss 0.37 on epoch=17
05/22/2022 09:44:53 - INFO - __main__ - Global step 500 Train loss 0.36 Classification-F1 0.5006407734635455 on epoch=17
05/22/2022 09:44:56 - INFO - __main__ - Step 510 Global step 510 Train loss 0.33 on epoch=18
05/22/2022 09:44:58 - INFO - __main__ - Step 520 Global step 520 Train loss 0.39 on epoch=18
05/22/2022 09:45:01 - INFO - __main__ - Step 530 Global step 530 Train loss 0.40 on epoch=18
05/22/2022 09:45:03 - INFO - __main__ - Step 540 Global step 540 Train loss 0.30 on epoch=19
05/22/2022 09:45:06 - INFO - __main__ - Step 550 Global step 550 Train loss 0.41 on epoch=19
05/22/2022 09:45:18 - INFO - __main__ - Global step 550 Train loss 0.37 Classification-F1 0.5480973571882664 on epoch=19
05/22/2022 09:45:18 - INFO - __main__ - Saving model with best Classification-F1: 0.5011733499058569 -> 0.5480973571882664 on epoch=19, global_step=550
05/22/2022 09:45:21 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=19
05/22/2022 09:45:23 - INFO - __main__ - Step 570 Global step 570 Train loss 0.26 on epoch=20
05/22/2022 09:45:26 - INFO - __main__ - Step 580 Global step 580 Train loss 0.33 on epoch=20
05/22/2022 09:45:29 - INFO - __main__ - Step 590 Global step 590 Train loss 0.38 on epoch=21
05/22/2022 09:45:31 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=21
05/22/2022 09:45:43 - INFO - __main__ - Global step 600 Train loss 0.29 Classification-F1 0.5703174493546749 on epoch=21
05/22/2022 09:45:43 - INFO - __main__ - Saving model with best Classification-F1: 0.5480973571882664 -> 0.5703174493546749 on epoch=21, global_step=600
05/22/2022 09:45:46 - INFO - __main__ - Step 610 Global step 610 Train loss 0.30 on epoch=21
05/22/2022 09:45:49 - INFO - __main__ - Step 620 Global step 620 Train loss 0.22 on epoch=22
05/22/2022 09:45:51 - INFO - __main__ - Step 630 Global step 630 Train loss 0.24 on epoch=22
05/22/2022 09:45:54 - INFO - __main__ - Step 640 Global step 640 Train loss 0.31 on epoch=22
05/22/2022 09:45:57 - INFO - __main__ - Step 650 Global step 650 Train loss 0.23 on epoch=23
05/22/2022 09:46:09 - INFO - __main__ - Global step 650 Train loss 0.26 Classification-F1 0.5794977351920291 on epoch=23
05/22/2022 09:46:09 - INFO - __main__ - Saving model with best Classification-F1: 0.5703174493546749 -> 0.5794977351920291 on epoch=23, global_step=650
05/22/2022 09:46:12 - INFO - __main__ - Step 660 Global step 660 Train loss 0.25 on epoch=23
05/22/2022 09:46:14 - INFO - __main__ - Step 670 Global step 670 Train loss 0.22 on epoch=23
05/22/2022 09:46:17 - INFO - __main__ - Step 680 Global step 680 Train loss 0.19 on epoch=24
05/22/2022 09:46:19 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=24
05/22/2022 09:46:22 - INFO - __main__ - Step 700 Global step 700 Train loss 0.17 on epoch=24
05/22/2022 09:46:35 - INFO - __main__ - Global step 700 Train loss 0.22 Classification-F1 0.6193320215740659 on epoch=24
05/22/2022 09:46:35 - INFO - __main__ - Saving model with best Classification-F1: 0.5794977351920291 -> 0.6193320215740659 on epoch=24, global_step=700
05/22/2022 09:46:37 - INFO - __main__ - Step 710 Global step 710 Train loss 0.22 on epoch=25
05/22/2022 09:46:40 - INFO - __main__ - Step 720 Global step 720 Train loss 0.24 on epoch=25
05/22/2022 09:46:43 - INFO - __main__ - Step 730 Global step 730 Train loss 0.17 on epoch=26
05/22/2022 09:46:45 - INFO - __main__ - Step 740 Global step 740 Train loss 0.22 on epoch=26
05/22/2022 09:46:48 - INFO - __main__ - Step 750 Global step 750 Train loss 0.23 on epoch=26
05/22/2022 09:47:00 - INFO - __main__ - Global step 750 Train loss 0.22 Classification-F1 0.6980873190166795 on epoch=26
05/22/2022 09:47:00 - INFO - __main__ - Saving model with best Classification-F1: 0.6193320215740659 -> 0.6980873190166795 on epoch=26, global_step=750
05/22/2022 09:47:03 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=27
05/22/2022 09:47:05 - INFO - __main__ - Step 770 Global step 770 Train loss 0.17 on epoch=27
05/22/2022 09:47:08 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=27
05/22/2022 09:47:11 - INFO - __main__ - Step 790 Global step 790 Train loss 0.18 on epoch=28
05/22/2022 09:47:13 - INFO - __main__ - Step 800 Global step 800 Train loss 0.23 on epoch=28
05/22/2022 09:47:26 - INFO - __main__ - Global step 800 Train loss 0.20 Classification-F1 0.6553597694514502 on epoch=28
05/22/2022 09:47:28 - INFO - __main__ - Step 810 Global step 810 Train loss 0.14 on epoch=28
05/22/2022 09:47:31 - INFO - __main__ - Step 820 Global step 820 Train loss 0.18 on epoch=29
05/22/2022 09:47:33 - INFO - __main__ - Step 830 Global step 830 Train loss 0.26 on epoch=29
05/22/2022 09:47:36 - INFO - __main__ - Step 840 Global step 840 Train loss 0.18 on epoch=29
05/22/2022 09:47:39 - INFO - __main__ - Step 850 Global step 850 Train loss 0.21 on epoch=30
05/22/2022 09:47:51 - INFO - __main__ - Global step 850 Train loss 0.19 Classification-F1 0.7394127894347386 on epoch=30
05/22/2022 09:47:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6980873190166795 -> 0.7394127894347386 on epoch=30, global_step=850
05/22/2022 09:47:54 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=30
05/22/2022 09:47:56 - INFO - __main__ - Step 870 Global step 870 Train loss 0.18 on epoch=31
05/22/2022 09:47:59 - INFO - __main__ - Step 880 Global step 880 Train loss 0.16 on epoch=31
05/22/2022 09:48:02 - INFO - __main__ - Step 890 Global step 890 Train loss 0.14 on epoch=31
05/22/2022 09:48:04 - INFO - __main__ - Step 900 Global step 900 Train loss 0.16 on epoch=32
05/22/2022 09:48:17 - INFO - __main__ - Global step 900 Train loss 0.17 Classification-F1 0.6298856945822676 on epoch=32
05/22/2022 09:48:20 - INFO - __main__ - Step 910 Global step 910 Train loss 0.15 on epoch=32
05/22/2022 09:48:22 - INFO - __main__ - Step 920 Global step 920 Train loss 0.19 on epoch=32
05/22/2022 09:48:25 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=33
05/22/2022 09:48:28 - INFO - __main__ - Step 940 Global step 940 Train loss 0.15 on epoch=33
05/22/2022 09:48:30 - INFO - __main__ - Step 950 Global step 950 Train loss 0.18 on epoch=33
05/22/2022 09:48:43 - INFO - __main__ - Global step 950 Train loss 0.16 Classification-F1 0.6635094334356935 on epoch=33
05/22/2022 09:48:45 - INFO - __main__ - Step 960 Global step 960 Train loss 0.11 on epoch=34
05/22/2022 09:48:48 - INFO - __main__ - Step 970 Global step 970 Train loss 0.17 on epoch=34
05/22/2022 09:48:51 - INFO - __main__ - Step 980 Global step 980 Train loss 0.15 on epoch=34
05/22/2022 09:48:53 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=35
05/22/2022 09:48:56 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.15 on epoch=35
05/22/2022 09:49:09 - INFO - __main__ - Global step 1000 Train loss 0.14 Classification-F1 0.6548373227168686 on epoch=35
05/22/2022 09:49:11 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.18 on epoch=36
05/22/2022 09:49:14 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.19 on epoch=36
05/22/2022 09:49:17 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.12 on epoch=36
05/22/2022 09:49:19 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.18 on epoch=37
05/22/2022 09:49:22 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.14 on epoch=37
05/22/2022 09:49:35 - INFO - __main__ - Global step 1050 Train loss 0.16 Classification-F1 0.624706882749733 on epoch=37
05/22/2022 09:49:37 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.17 on epoch=37
05/22/2022 09:49:40 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.12 on epoch=38
05/22/2022 09:49:43 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.15 on epoch=38
05/22/2022 09:49:45 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.13 on epoch=38
05/22/2022 09:49:48 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.17 on epoch=39
05/22/2022 09:50:01 - INFO - __main__ - Global step 1100 Train loss 0.15 Classification-F1 0.6644244431973174 on epoch=39
05/22/2022 09:50:03 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.16 on epoch=39
05/22/2022 09:50:06 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.16 on epoch=39
05/22/2022 09:50:09 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.13 on epoch=40
05/22/2022 09:50:11 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.17 on epoch=40
05/22/2022 09:50:14 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.11 on epoch=41
05/22/2022 09:50:26 - INFO - __main__ - Global step 1150 Train loss 0.14 Classification-F1 0.6567356846696989 on epoch=41
05/22/2022 09:50:29 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.12 on epoch=41
05/22/2022 09:50:31 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.20 on epoch=41
05/22/2022 09:50:34 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.08 on epoch=42
05/22/2022 09:50:37 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.16 on epoch=42
05/22/2022 09:50:39 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.14 on epoch=42
05/22/2022 09:50:52 - INFO - __main__ - Global step 1200 Train loss 0.14 Classification-F1 0.6278899001737275 on epoch=42
05/22/2022 09:50:54 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.14 on epoch=43
05/22/2022 09:50:57 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=43
05/22/2022 09:50:59 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.14 on epoch=43
05/22/2022 09:51:02 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.12 on epoch=44
05/22/2022 09:51:05 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.09 on epoch=44
05/22/2022 09:51:17 - INFO - __main__ - Global step 1250 Train loss 0.13 Classification-F1 0.7037913743506404 on epoch=44
05/22/2022 09:51:20 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.11 on epoch=44
05/22/2022 09:51:23 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.18 on epoch=45
05/22/2022 09:51:25 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.14 on epoch=45
05/22/2022 09:51:28 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.08 on epoch=46
05/22/2022 09:51:30 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.15 on epoch=46
05/22/2022 09:51:43 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6713634106626006 on epoch=46
05/22/2022 09:51:46 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.11 on epoch=46
05/22/2022 09:51:48 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.09 on epoch=47
05/22/2022 09:51:51 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.10 on epoch=47
05/22/2022 09:51:53 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.11 on epoch=47
05/22/2022 09:51:56 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=48
05/22/2022 09:52:09 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.7773021638937959 on epoch=48
05/22/2022 09:52:09 - INFO - __main__ - Saving model with best Classification-F1: 0.7394127894347386 -> 0.7773021638937959 on epoch=48, global_step=1350
05/22/2022 09:52:12 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.10 on epoch=48
05/22/2022 09:52:14 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=48
05/22/2022 09:52:17 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.06 on epoch=49
05/22/2022 09:52:19 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.11 on epoch=49
05/22/2022 09:52:22 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.13 on epoch=49
05/22/2022 09:52:35 - INFO - __main__ - Global step 1400 Train loss 0.10 Classification-F1 0.7030059686567685 on epoch=49
05/22/2022 09:52:37 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=50
05/22/2022 09:52:40 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=50
05/22/2022 09:52:42 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.11 on epoch=51
05/22/2022 09:52:45 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=51
05/22/2022 09:52:48 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.10 on epoch=51
05/22/2022 09:53:00 - INFO - __main__ - Global step 1450 Train loss 0.11 Classification-F1 0.6652338834287107 on epoch=51
05/22/2022 09:53:03 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.11 on epoch=52
05/22/2022 09:53:05 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.08 on epoch=52
05/22/2022 09:53:08 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.11 on epoch=52
05/22/2022 09:53:10 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.10 on epoch=53
05/22/2022 09:53:13 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.11 on epoch=53
05/22/2022 09:53:26 - INFO - __main__ - Global step 1500 Train loss 0.10 Classification-F1 0.8108575295287423 on epoch=53
05/22/2022 09:53:26 - INFO - __main__ - Saving model with best Classification-F1: 0.7773021638937959 -> 0.8108575295287423 on epoch=53, global_step=1500
05/22/2022 09:53:29 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.08 on epoch=53
05/22/2022 09:53:31 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.08 on epoch=54
05/22/2022 09:53:34 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.14 on epoch=54
05/22/2022 09:53:36 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.08 on epoch=54
05/22/2022 09:53:39 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.11 on epoch=55
05/22/2022 09:53:52 - INFO - __main__ - Global step 1550 Train loss 0.10 Classification-F1 0.7624225282525918 on epoch=55
05/22/2022 09:53:54 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=55
05/22/2022 09:53:57 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.11 on epoch=56
05/22/2022 09:53:59 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=56
05/22/2022 09:54:02 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.04 on epoch=56
05/22/2022 09:54:05 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.12 on epoch=57
05/22/2022 09:54:17 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.8488270588684192 on epoch=57
05/22/2022 09:54:17 - INFO - __main__ - Saving model with best Classification-F1: 0.8108575295287423 -> 0.8488270588684192 on epoch=57, global_step=1600
05/22/2022 09:54:20 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.07 on epoch=57
05/22/2022 09:54:23 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.07 on epoch=57
05/22/2022 09:54:25 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=58
05/22/2022 09:54:28 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.06 on epoch=58
05/22/2022 09:54:30 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.10 on epoch=58
05/22/2022 09:54:43 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.911472386051162 on epoch=58
05/22/2022 09:54:43 - INFO - __main__ - Saving model with best Classification-F1: 0.8488270588684192 -> 0.911472386051162 on epoch=58, global_step=1650
05/22/2022 09:54:46 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.06 on epoch=59
05/22/2022 09:54:49 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.07 on epoch=59
05/22/2022 09:54:51 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.04 on epoch=59
05/22/2022 09:54:54 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.06 on epoch=60
05/22/2022 09:54:56 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.08 on epoch=60
05/22/2022 09:55:09 - INFO - __main__ - Global step 1700 Train loss 0.06 Classification-F1 0.9167985935951113 on epoch=60
05/22/2022 09:55:09 - INFO - __main__ - Saving model with best Classification-F1: 0.911472386051162 -> 0.9167985935951113 on epoch=60, global_step=1700
05/22/2022 09:55:12 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.04 on epoch=61
05/22/2022 09:55:15 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.12 on epoch=61
05/22/2022 09:55:17 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=61
05/22/2022 09:55:20 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.08 on epoch=62
05/22/2022 09:55:23 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.05 on epoch=62
05/22/2022 09:55:35 - INFO - __main__ - Global step 1750 Train loss 0.08 Classification-F1 0.7999953590440336 on epoch=62
05/22/2022 09:55:38 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=62
05/22/2022 09:55:41 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=63
05/22/2022 09:55:43 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.10 on epoch=63
05/22/2022 09:55:46 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.09 on epoch=63
05/22/2022 09:55:49 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.06 on epoch=64
05/22/2022 09:56:01 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.8621497985353286 on epoch=64
05/22/2022 09:56:04 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.07 on epoch=64
05/22/2022 09:56:06 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=64
05/22/2022 09:56:09 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=65
05/22/2022 09:56:12 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.07 on epoch=65
05/22/2022 09:56:14 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.06 on epoch=66
05/22/2022 09:56:27 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.8581437159165328 on epoch=66
05/22/2022 09:56:30 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.08 on epoch=66
05/22/2022 09:56:33 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.07 on epoch=66
05/22/2022 09:56:35 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.03 on epoch=67
05/22/2022 09:56:38 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.09 on epoch=67
05/22/2022 09:56:40 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.06 on epoch=67
05/22/2022 09:56:53 - INFO - __main__ - Global step 1900 Train loss 0.07 Classification-F1 0.9165874272440232 on epoch=67
05/22/2022 09:56:56 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.03 on epoch=68
05/22/2022 09:56:58 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 09:57:01 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.09 on epoch=68
05/22/2022 09:57:03 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.05 on epoch=69
05/22/2022 09:57:06 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=69
05/22/2022 09:57:19 - INFO - __main__ - Global step 1950 Train loss 0.06 Classification-F1 0.8557482853902114 on epoch=69
05/22/2022 09:57:21 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=69
05/22/2022 09:57:24 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.05 on epoch=70
05/22/2022 09:57:27 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.11 on epoch=70
05/22/2022 09:57:29 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.04 on epoch=71
05/22/2022 09:57:32 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.05 on epoch=71
05/22/2022 09:57:45 - INFO - __main__ - Global step 2000 Train loss 0.06 Classification-F1 0.7892673476639321 on epoch=71
05/22/2022 09:57:47 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.06 on epoch=71
05/22/2022 09:57:50 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.06 on epoch=72
05/22/2022 09:57:53 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.10 on epoch=72
05/22/2022 09:57:55 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.12 on epoch=72
05/22/2022 09:57:58 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.05 on epoch=73
05/22/2022 09:58:11 - INFO - __main__ - Global step 2050 Train loss 0.08 Classification-F1 0.8498724327082536 on epoch=73
05/22/2022 09:58:13 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.09 on epoch=73
05/22/2022 09:58:16 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.09 on epoch=73
05/22/2022 09:58:19 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=74
05/22/2022 09:58:21 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.06 on epoch=74
05/22/2022 09:58:24 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.06 on epoch=74
05/22/2022 09:58:37 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.798167719716825 on epoch=74
05/22/2022 09:58:39 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=75
05/22/2022 09:58:42 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.06 on epoch=75
05/22/2022 09:58:44 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=76
05/22/2022 09:58:47 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=76
05/22/2022 09:58:49 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.05 on epoch=76
05/22/2022 09:59:02 - INFO - __main__ - Global step 2150 Train loss 0.05 Classification-F1 0.8059247036221745 on epoch=76
05/22/2022 09:59:05 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=77
05/22/2022 09:59:07 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.07 on epoch=77
05/22/2022 09:59:10 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.04 on epoch=77
05/22/2022 09:59:12 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 09:59:15 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.06 on epoch=78
05/22/2022 09:59:28 - INFO - __main__ - Global step 2200 Train loss 0.05 Classification-F1 0.8104712781130674 on epoch=78
05/22/2022 09:59:30 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=78
05/22/2022 09:59:33 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=79
05/22/2022 09:59:35 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.09 on epoch=79
05/22/2022 09:59:38 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.07 on epoch=79
05/22/2022 09:59:41 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.05 on epoch=80
05/22/2022 09:59:53 - INFO - __main__ - Global step 2250 Train loss 0.05 Classification-F1 0.8064825051845411 on epoch=80
05/22/2022 09:59:56 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.03 on epoch=80
05/22/2022 09:59:58 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.07 on epoch=81
05/22/2022 10:00:01 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.07 on epoch=81
05/22/2022 10:00:03 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.07 on epoch=81
05/22/2022 10:00:06 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.03 on epoch=82
05/22/2022 10:00:18 - INFO - __main__ - Global step 2300 Train loss 0.05 Classification-F1 0.8612553150588779 on epoch=82
05/22/2022 10:00:21 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.09 on epoch=82
05/22/2022 10:00:23 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.06 on epoch=82
05/22/2022 10:00:26 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.05 on epoch=83
05/22/2022 10:00:29 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.07 on epoch=83
05/22/2022 10:00:31 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=83
05/22/2022 10:00:44 - INFO - __main__ - Global step 2350 Train loss 0.06 Classification-F1 0.867111593013252 on epoch=83
05/22/2022 10:00:47 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=84
05/22/2022 10:00:49 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.07 on epoch=84
05/22/2022 10:00:52 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=84
05/22/2022 10:00:54 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.04 on epoch=85
05/22/2022 10:00:57 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.05 on epoch=85
05/22/2022 10:01:10 - INFO - __main__ - Global step 2400 Train loss 0.05 Classification-F1 0.9865160280994909 on epoch=85
05/22/2022 10:01:10 - INFO - __main__ - Saving model with best Classification-F1: 0.9167985935951113 -> 0.9865160280994909 on epoch=85, global_step=2400
05/22/2022 10:01:12 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.03 on epoch=86
05/22/2022 10:01:15 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 10:01:17 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.03 on epoch=86
05/22/2022 10:01:20 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.02 on epoch=87
05/22/2022 10:01:23 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=87
05/22/2022 10:01:35 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.9843598721169392 on epoch=87
05/22/2022 10:01:38 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.08 on epoch=87
05/22/2022 10:01:40 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=88
05/22/2022 10:01:43 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.04 on epoch=88
05/22/2022 10:01:45 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.03 on epoch=88
05/22/2022 10:01:48 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.04 on epoch=89
05/22/2022 10:02:00 - INFO - __main__ - Global step 2500 Train loss 0.04 Classification-F1 0.9218469392374063 on epoch=89
05/22/2022 10:02:03 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.04 on epoch=89
05/22/2022 10:02:06 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 10:02:08 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.01 on epoch=90
05/22/2022 10:02:11 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.05 on epoch=90
05/22/2022 10:02:13 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.04 on epoch=91
05/22/2022 10:02:26 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.9196897091979058 on epoch=91
05/22/2022 10:02:29 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=91
05/22/2022 10:02:31 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.04 on epoch=91
05/22/2022 10:02:34 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.05 on epoch=92
05/22/2022 10:02:36 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.07 on epoch=92
05/22/2022 10:02:39 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.04 on epoch=92
05/22/2022 10:02:51 - INFO - __main__ - Global step 2600 Train loss 0.05 Classification-F1 0.9865576743147414 on epoch=92
05/22/2022 10:02:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9865160280994909 -> 0.9865576743147414 on epoch=92, global_step=2600
05/22/2022 10:02:54 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=93
05/22/2022 10:02:57 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.06 on epoch=93
05/22/2022 10:02:59 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.03 on epoch=93
05/22/2022 10:03:02 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 10:03:05 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.15 on epoch=94
05/22/2022 10:03:17 - INFO - __main__ - Global step 2650 Train loss 0.06 Classification-F1 0.8590612541883729 on epoch=94
05/22/2022 10:03:19 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.03 on epoch=94
05/22/2022 10:03:22 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.03 on epoch=95
05/22/2022 10:03:25 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=95
05/22/2022 10:03:27 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=96
05/22/2022 10:03:30 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.04 on epoch=96
05/22/2022 10:03:42 - INFO - __main__ - Global step 2700 Train loss 0.03 Classification-F1 0.9197294703860663 on epoch=96
05/22/2022 10:03:45 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=96
05/22/2022 10:03:47 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=97
05/22/2022 10:03:50 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=97
05/22/2022 10:03:53 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.05 on epoch=97
05/22/2022 10:03:55 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=98
05/22/2022 10:04:08 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.8016819718652113 on epoch=98
05/22/2022 10:04:11 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=98
05/22/2022 10:04:13 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.04 on epoch=98
05/22/2022 10:04:16 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.02 on epoch=99
05/22/2022 10:04:18 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.06 on epoch=99
05/22/2022 10:04:21 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=99
05/22/2022 10:04:33 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.8560153165602233 on epoch=99
05/22/2022 10:04:36 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.04 on epoch=100
05/22/2022 10:04:38 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=100
05/22/2022 10:04:41 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.02 on epoch=101
05/22/2022 10:04:44 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=101
05/22/2022 10:04:46 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=101
05/22/2022 10:04:59 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.9196948261175512 on epoch=101
05/22/2022 10:05:01 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.03 on epoch=102
05/22/2022 10:05:04 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.07 on epoch=102
05/22/2022 10:05:06 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.05 on epoch=102
05/22/2022 10:05:09 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.02 on epoch=103
05/22/2022 10:05:12 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.03 on epoch=103
05/22/2022 10:05:24 - INFO - __main__ - Global step 2900 Train loss 0.04 Classification-F1 0.9888269360310079 on epoch=103
05/22/2022 10:05:24 - INFO - __main__ - Saving model with best Classification-F1: 0.9865576743147414 -> 0.9888269360310079 on epoch=103, global_step=2900
05/22/2022 10:05:27 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.05 on epoch=103
05/22/2022 10:05:30 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.08 on epoch=104
05/22/2022 10:05:32 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.07 on epoch=104
05/22/2022 10:05:35 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.03 on epoch=104
05/22/2022 10:05:37 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=105
05/22/2022 10:05:50 - INFO - __main__ - Global step 2950 Train loss 0.05 Classification-F1 0.9239275270398343 on epoch=105
05/22/2022 10:05:52 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=105
05/22/2022 10:05:55 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=106
05/22/2022 10:05:58 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.10 on epoch=106
05/22/2022 10:06:00 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.02 on epoch=106
05/22/2022 10:06:03 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.03 on epoch=107
05/22/2022 10:06:04 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:06:04 - INFO - __main__ - Printing 3 examples
05/22/2022 10:06:04 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 10:06:04 - INFO - __main__ - ['Company']
05/22/2022 10:06:04 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 10:06:04 - INFO - __main__ - ['Company']
05/22/2022 10:06:04 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 10:06:04 - INFO - __main__ - ['Company']
05/22/2022 10:06:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:06:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:06:05 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 10:06:05 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:06:05 - INFO - __main__ - Printing 3 examples
05/22/2022 10:06:05 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 10:06:05 - INFO - __main__ - ['Company']
05/22/2022 10:06:05 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 10:06:05 - INFO - __main__ - ['Company']
05/22/2022 10:06:05 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 10:06:05 - INFO - __main__ - ['Company']
05/22/2022 10:06:05 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:06:05 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:06:06 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 10:06:16 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.9218095494379858 on epoch=107
05/22/2022 10:06:16 - INFO - __main__ - save last model!
05/22/2022 10:06:16 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 10:06:16 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 10:06:16 - INFO - __main__ - Printing 3 examples
05/22/2022 10:06:16 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 10:06:16 - INFO - __main__ - ['Animal']
05/22/2022 10:06:16 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 10:06:16 - INFO - __main__ - ['Animal']
05/22/2022 10:06:16 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 10:06:16 - INFO - __main__ - ['Village']
05/22/2022 10:06:16 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:06:18 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:06:21 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 10:06:24 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 10:06:25 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 10:06:25 - INFO - __main__ - Starting training!
05/22/2022 10:08:29 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_42_0.3_8_predictions.txt
05/22/2022 10:08:29 - INFO - __main__ - Classification-F1 on test data: 0.7599
05/22/2022 10:08:29 - INFO - __main__ - prefix=dbpedia_14_32_42, lr=0.3, bsz=8, dev_performance=0.9888269360310079, test_performance=0.7598861798838317
05/22/2022 10:08:29 - INFO - __main__ - Running ... prefix=dbpedia_14_32_42, lr=0.2, bsz=8 ...
05/22/2022 10:08:30 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:08:30 - INFO - __main__ - Printing 3 examples
05/22/2022 10:08:30 - INFO - __main__ -  [dbpedia_14] The Sterling Piano Company was a piano manufacturer in Derby Connecticut. The company was founded in 1873 by Charles A. Sterling as the Sterling Organ Company. Sterling had purchased the Birmingham Organ Company in 1871 and had $30000 to fund the company. The Sterling Organ Company began making pianos in 1885.
05/22/2022 10:08:30 - INFO - __main__ - ['Company']
05/22/2022 10:08:30 - INFO - __main__ -  [dbpedia_14] UltraVision CLPL is a contact lens manufacturer with headquarters based in Leighton Buzzard Bedfordshire England. UltraVision CLPL also has a Research and Development office based in Cambridge England.
05/22/2022 10:08:30 - INFO - __main__ - ['Company']
05/22/2022 10:08:30 - INFO - __main__ -  [dbpedia_14] Databank is a financial services provider and a brokerage ffirm with its headquarters in Accra Ghana. It provides corporate and public finance advisory services.
05/22/2022 10:08:30 - INFO - __main__ - ['Company']
05/22/2022 10:08:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:08:30 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:08:31 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 10:08:31 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:08:31 - INFO - __main__ - Printing 3 examples
05/22/2022 10:08:31 - INFO - __main__ -  [dbpedia_14] Annata is a multinational management consulting and technology services company headquartered in Reykjavík Iceland.
05/22/2022 10:08:31 - INFO - __main__ - ['Company']
05/22/2022 10:08:31 - INFO - __main__ -  [dbpedia_14] Wind Jet S.p.A. was an Italian low-cost airline based in Catania Italy. It was founded in 2003 following the disbandment of Air Sicilia by current CEO Antonino Pulvirenti also owner of football team Calcio Catania. It was currently the fourth Italian airline by number of passengers and operated several national and continental flights most of them from the main hub of Catania-Fontanarossa.On 11 August 2012 the airline has ceased operations until further notice due to financial troubles.
05/22/2022 10:08:31 - INFO - __main__ - ['Company']
05/22/2022 10:08:31 - INFO - __main__ -  [dbpedia_14] Kranti Road Transport is a transportation company in the Indian state of Andhra Pradesh. Kranti operates a network of 403 branches and 270 vehicles with direct and indirect staff of above 1000 employees. It offers transportation of any type of goods across its branches.Kranti covers the state of Andhra Pradesh and some areas in Chennai City and one area in Yanam. Its head office is situated in Vijayawada at 5th ROAD Jawahar Autonagar combined with transshipment.
05/22/2022 10:08:31 - INFO - __main__ - ['Company']
05/22/2022 10:08:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:08:31 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:08:31 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 10:08:49 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 10:08:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 10:08:50 - INFO - __main__ - Starting training!
05/22/2022 10:08:54 - INFO - __main__ - Step 10 Global step 10 Train loss 7.21 on epoch=0
05/22/2022 10:08:56 - INFO - __main__ - Step 20 Global step 20 Train loss 6.74 on epoch=0
05/22/2022 10:08:59 - INFO - __main__ - Step 30 Global step 30 Train loss 5.09 on epoch=1
05/22/2022 10:09:01 - INFO - __main__ - Step 40 Global step 40 Train loss 4.65 on epoch=1
05/22/2022 10:09:04 - INFO - __main__ - Step 50 Global step 50 Train loss 4.61 on epoch=1
05/22/2022 10:09:16 - INFO - __main__ - Global step 50 Train loss 5.66 Classification-F1 0.014220627856991493 on epoch=1
05/22/2022 10:09:16 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.014220627856991493 on epoch=1, global_step=50
05/22/2022 10:09:18 - INFO - __main__ - Step 60 Global step 60 Train loss 4.07 on epoch=2
05/22/2022 10:09:21 - INFO - __main__ - Step 70 Global step 70 Train loss 3.57 on epoch=2
05/22/2022 10:09:23 - INFO - __main__ - Step 80 Global step 80 Train loss 3.55 on epoch=2
05/22/2022 10:09:26 - INFO - __main__ - Step 90 Global step 90 Train loss 3.00 on epoch=3
05/22/2022 10:09:29 - INFO - __main__ - Step 100 Global step 100 Train loss 3.20 on epoch=3
05/22/2022 10:09:42 - INFO - __main__ - Global step 100 Train loss 3.48 Classification-F1 0.026034585696455587 on epoch=3
05/22/2022 10:09:42 - INFO - __main__ - Saving model with best Classification-F1: 0.014220627856991493 -> 0.026034585696455587 on epoch=3, global_step=100
05/22/2022 10:09:45 - INFO - __main__ - Step 110 Global step 110 Train loss 3.04 on epoch=3
05/22/2022 10:09:47 - INFO - __main__ - Step 120 Global step 120 Train loss 2.54 on epoch=4
05/22/2022 10:09:50 - INFO - __main__ - Step 130 Global step 130 Train loss 2.80 on epoch=4
05/22/2022 10:09:53 - INFO - __main__ - Step 140 Global step 140 Train loss 2.37 on epoch=4
05/22/2022 10:09:55 - INFO - __main__ - Step 150 Global step 150 Train loss 2.07 on epoch=5
05/22/2022 10:10:08 - INFO - __main__ - Global step 150 Train loss 2.56 Classification-F1 0.04161816817319209 on epoch=5
05/22/2022 10:10:08 - INFO - __main__ - Saving model with best Classification-F1: 0.026034585696455587 -> 0.04161816817319209 on epoch=5, global_step=150
05/22/2022 10:10:10 - INFO - __main__ - Step 160 Global step 160 Train loss 2.34 on epoch=5
05/22/2022 10:10:13 - INFO - __main__ - Step 170 Global step 170 Train loss 2.27 on epoch=6
05/22/2022 10:10:16 - INFO - __main__ - Step 180 Global step 180 Train loss 1.95 on epoch=6
05/22/2022 10:10:18 - INFO - __main__ - Step 190 Global step 190 Train loss 2.21 on epoch=6
05/22/2022 10:10:21 - INFO - __main__ - Step 200 Global step 200 Train loss 1.89 on epoch=7
05/22/2022 10:10:32 - INFO - __main__ - Global step 200 Train loss 2.13 Classification-F1 0.07044909486000978 on epoch=7
05/22/2022 10:10:32 - INFO - __main__ - Saving model with best Classification-F1: 0.04161816817319209 -> 0.07044909486000978 on epoch=7, global_step=200
05/22/2022 10:10:35 - INFO - __main__ - Step 210 Global step 210 Train loss 1.77 on epoch=7
05/22/2022 10:10:38 - INFO - __main__ - Step 220 Global step 220 Train loss 1.95 on epoch=7
05/22/2022 10:10:40 - INFO - __main__ - Step 230 Global step 230 Train loss 1.48 on epoch=8
05/22/2022 10:10:43 - INFO - __main__ - Step 240 Global step 240 Train loss 1.85 on epoch=8
05/22/2022 10:10:45 - INFO - __main__ - Step 250 Global step 250 Train loss 1.74 on epoch=8
05/22/2022 10:10:57 - INFO - __main__ - Global step 250 Train loss 1.76 Classification-F1 0.09336711041357128 on epoch=8
05/22/2022 10:10:57 - INFO - __main__ - Saving model with best Classification-F1: 0.07044909486000978 -> 0.09336711041357128 on epoch=8, global_step=250
05/22/2022 10:10:59 - INFO - __main__ - Step 260 Global step 260 Train loss 1.39 on epoch=9
05/22/2022 10:11:02 - INFO - __main__ - Step 270 Global step 270 Train loss 1.58 on epoch=9
05/22/2022 10:11:05 - INFO - __main__ - Step 280 Global step 280 Train loss 1.39 on epoch=9
05/22/2022 10:11:07 - INFO - __main__ - Step 290 Global step 290 Train loss 1.13 on epoch=10
05/22/2022 10:11:10 - INFO - __main__ - Step 300 Global step 300 Train loss 1.57 on epoch=10
05/22/2022 10:11:21 - INFO - __main__ - Global step 300 Train loss 1.41 Classification-F1 0.12707032839983393 on epoch=10
05/22/2022 10:11:21 - INFO - __main__ - Saving model with best Classification-F1: 0.09336711041357128 -> 0.12707032839983393 on epoch=10, global_step=300
05/22/2022 10:11:23 - INFO - __main__ - Step 310 Global step 310 Train loss 1.31 on epoch=11
05/22/2022 10:11:26 - INFO - __main__ - Step 320 Global step 320 Train loss 1.13 on epoch=11
05/22/2022 10:11:29 - INFO - __main__ - Step 330 Global step 330 Train loss 1.25 on epoch=11
05/22/2022 10:11:31 - INFO - __main__ - Step 340 Global step 340 Train loss 1.18 on epoch=12
05/22/2022 10:11:34 - INFO - __main__ - Step 350 Global step 350 Train loss 1.12 on epoch=12
05/22/2022 10:11:45 - INFO - __main__ - Global step 350 Train loss 1.20 Classification-F1 0.15786753524151262 on epoch=12
05/22/2022 10:11:45 - INFO - __main__ - Saving model with best Classification-F1: 0.12707032839983393 -> 0.15786753524151262 on epoch=12, global_step=350
05/22/2022 10:11:47 - INFO - __main__ - Step 360 Global step 360 Train loss 1.19 on epoch=12
05/22/2022 10:11:50 - INFO - __main__ - Step 370 Global step 370 Train loss 0.92 on epoch=13
05/22/2022 10:11:53 - INFO - __main__ - Step 380 Global step 380 Train loss 1.04 on epoch=13
05/22/2022 10:11:55 - INFO - __main__ - Step 390 Global step 390 Train loss 1.09 on epoch=13
05/22/2022 10:11:58 - INFO - __main__ - Step 400 Global step 400 Train loss 0.78 on epoch=14
05/22/2022 10:12:09 - INFO - __main__ - Global step 400 Train loss 1.01 Classification-F1 0.212797704493543 on epoch=14
05/22/2022 10:12:09 - INFO - __main__ - Saving model with best Classification-F1: 0.15786753524151262 -> 0.212797704493543 on epoch=14, global_step=400
05/22/2022 10:12:11 - INFO - __main__ - Step 410 Global step 410 Train loss 1.05 on epoch=14
05/22/2022 10:12:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.83 on epoch=14
05/22/2022 10:12:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.70 on epoch=15
05/22/2022 10:12:19 - INFO - __main__ - Step 440 Global step 440 Train loss 0.84 on epoch=15
05/22/2022 10:12:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=16
05/22/2022 10:12:33 - INFO - __main__ - Global step 450 Train loss 0.84 Classification-F1 0.2661693235087405 on epoch=16
05/22/2022 10:12:33 - INFO - __main__ - Saving model with best Classification-F1: 0.212797704493543 -> 0.2661693235087405 on epoch=16, global_step=450
05/22/2022 10:12:36 - INFO - __main__ - Step 460 Global step 460 Train loss 0.68 on epoch=16
05/22/2022 10:12:39 - INFO - __main__ - Step 470 Global step 470 Train loss 0.74 on epoch=16
05/22/2022 10:12:41 - INFO - __main__ - Step 480 Global step 480 Train loss 0.66 on epoch=17
05/22/2022 10:12:44 - INFO - __main__ - Step 490 Global step 490 Train loss 0.55 on epoch=17
05/22/2022 10:12:46 - INFO - __main__ - Step 500 Global step 500 Train loss 0.66 on epoch=17
05/22/2022 10:12:59 - INFO - __main__ - Global step 500 Train loss 0.66 Classification-F1 0.3073642005502954 on epoch=17
05/22/2022 10:12:59 - INFO - __main__ - Saving model with best Classification-F1: 0.2661693235087405 -> 0.3073642005502954 on epoch=17, global_step=500
05/22/2022 10:13:01 - INFO - __main__ - Step 510 Global step 510 Train loss 0.47 on epoch=18
05/22/2022 10:13:04 - INFO - __main__ - Step 520 Global step 520 Train loss 0.63 on epoch=18
05/22/2022 10:13:06 - INFO - __main__ - Step 530 Global step 530 Train loss 0.65 on epoch=18
05/22/2022 10:13:09 - INFO - __main__ - Step 540 Global step 540 Train loss 0.46 on epoch=19
05/22/2022 10:13:12 - INFO - __main__ - Step 550 Global step 550 Train loss 0.59 on epoch=19
05/22/2022 10:13:24 - INFO - __main__ - Global step 550 Train loss 0.56 Classification-F1 0.40161412254132745 on epoch=19
05/22/2022 10:13:24 - INFO - __main__ - Saving model with best Classification-F1: 0.3073642005502954 -> 0.40161412254132745 on epoch=19, global_step=550
05/22/2022 10:13:27 - INFO - __main__ - Step 560 Global step 560 Train loss 0.53 on epoch=19
05/22/2022 10:13:30 - INFO - __main__ - Step 570 Global step 570 Train loss 0.45 on epoch=20
05/22/2022 10:13:32 - INFO - __main__ - Step 580 Global step 580 Train loss 0.45 on epoch=20
05/22/2022 10:13:35 - INFO - __main__ - Step 590 Global step 590 Train loss 0.43 on epoch=21
05/22/2022 10:13:37 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=21
05/22/2022 10:13:50 - INFO - __main__ - Global step 600 Train loss 0.46 Classification-F1 0.456390946866964 on epoch=21
05/22/2022 10:13:50 - INFO - __main__ - Saving model with best Classification-F1: 0.40161412254132745 -> 0.456390946866964 on epoch=21, global_step=600
05/22/2022 10:13:53 - INFO - __main__ - Step 610 Global step 610 Train loss 0.53 on epoch=21
05/22/2022 10:13:55 - INFO - __main__ - Step 620 Global step 620 Train loss 0.44 on epoch=22
05/22/2022 10:13:58 - INFO - __main__ - Step 630 Global step 630 Train loss 0.40 on epoch=22
05/22/2022 10:14:00 - INFO - __main__ - Step 640 Global step 640 Train loss 0.52 on epoch=22
05/22/2022 10:14:03 - INFO - __main__ - Step 650 Global step 650 Train loss 0.43 on epoch=23
05/22/2022 10:14:16 - INFO - __main__ - Global step 650 Train loss 0.46 Classification-F1 0.4876878568931408 on epoch=23
05/22/2022 10:14:16 - INFO - __main__ - Saving model with best Classification-F1: 0.456390946866964 -> 0.4876878568931408 on epoch=23, global_step=650
05/22/2022 10:14:18 - INFO - __main__ - Step 660 Global step 660 Train loss 0.44 on epoch=23
05/22/2022 10:14:21 - INFO - __main__ - Step 670 Global step 670 Train loss 0.46 on epoch=23
05/22/2022 10:14:24 - INFO - __main__ - Step 680 Global step 680 Train loss 0.28 on epoch=24
05/22/2022 10:14:26 - INFO - __main__ - Step 690 Global step 690 Train loss 0.38 on epoch=24
05/22/2022 10:14:29 - INFO - __main__ - Step 700 Global step 700 Train loss 0.32 on epoch=24
05/22/2022 10:14:42 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.5406056631626939 on epoch=24
05/22/2022 10:14:42 - INFO - __main__ - Saving model with best Classification-F1: 0.4876878568931408 -> 0.5406056631626939 on epoch=24, global_step=700
05/22/2022 10:14:44 - INFO - __main__ - Step 710 Global step 710 Train loss 0.31 on epoch=25
05/22/2022 10:14:47 - INFO - __main__ - Step 720 Global step 720 Train loss 0.33 on epoch=25
05/22/2022 10:14:50 - INFO - __main__ - Step 730 Global step 730 Train loss 0.34 on epoch=26
05/22/2022 10:14:52 - INFO - __main__ - Step 740 Global step 740 Train loss 0.28 on epoch=26
05/22/2022 10:14:55 - INFO - __main__ - Step 750 Global step 750 Train loss 0.42 on epoch=26
05/22/2022 10:15:08 - INFO - __main__ - Global step 750 Train loss 0.34 Classification-F1 0.4953725040642924 on epoch=26
05/22/2022 10:15:10 - INFO - __main__ - Step 760 Global step 760 Train loss 0.42 on epoch=27
05/22/2022 10:15:13 - INFO - __main__ - Step 770 Global step 770 Train loss 0.31 on epoch=27
05/22/2022 10:15:15 - INFO - __main__ - Step 780 Global step 780 Train loss 0.34 on epoch=27
05/22/2022 10:15:18 - INFO - __main__ - Step 790 Global step 790 Train loss 0.31 on epoch=28
05/22/2022 10:15:20 - INFO - __main__ - Step 800 Global step 800 Train loss 0.33 on epoch=28
05/22/2022 10:15:33 - INFO - __main__ - Global step 800 Train loss 0.34 Classification-F1 0.47425807437349027 on epoch=28
05/22/2022 10:15:36 - INFO - __main__ - Step 810 Global step 810 Train loss 0.36 on epoch=28
05/22/2022 10:15:39 - INFO - __main__ - Step 820 Global step 820 Train loss 0.25 on epoch=29
05/22/2022 10:15:41 - INFO - __main__ - Step 830 Global step 830 Train loss 0.33 on epoch=29
05/22/2022 10:15:44 - INFO - __main__ - Step 840 Global step 840 Train loss 0.29 on epoch=29
05/22/2022 10:15:46 - INFO - __main__ - Step 850 Global step 850 Train loss 0.33 on epoch=30
05/22/2022 10:15:59 - INFO - __main__ - Global step 850 Train loss 0.31 Classification-F1 0.5375436718649814 on epoch=30
05/22/2022 10:16:02 - INFO - __main__ - Step 860 Global step 860 Train loss 0.30 on epoch=30
05/22/2022 10:16:04 - INFO - __main__ - Step 870 Global step 870 Train loss 0.22 on epoch=31
05/22/2022 10:16:07 - INFO - __main__ - Step 880 Global step 880 Train loss 0.29 on epoch=31
05/22/2022 10:16:09 - INFO - __main__ - Step 890 Global step 890 Train loss 0.35 on epoch=31
05/22/2022 10:16:12 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=32
05/22/2022 10:16:25 - INFO - __main__ - Global step 900 Train loss 0.27 Classification-F1 0.5599364541332741 on epoch=32
05/22/2022 10:16:25 - INFO - __main__ - Saving model with best Classification-F1: 0.5406056631626939 -> 0.5599364541332741 on epoch=32, global_step=900
05/22/2022 10:16:27 - INFO - __main__ - Step 910 Global step 910 Train loss 0.24 on epoch=32
05/22/2022 10:16:30 - INFO - __main__ - Step 920 Global step 920 Train loss 0.33 on epoch=32
05/22/2022 10:16:33 - INFO - __main__ - Step 930 Global step 930 Train loss 0.26 on epoch=33
05/22/2022 10:16:35 - INFO - __main__ - Step 940 Global step 940 Train loss 0.30 on epoch=33
05/22/2022 10:16:38 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=33
05/22/2022 10:16:50 - INFO - __main__ - Global step 950 Train loss 0.28 Classification-F1 0.5946404432926662 on epoch=33
05/22/2022 10:16:50 - INFO - __main__ - Saving model with best Classification-F1: 0.5599364541332741 -> 0.5946404432926662 on epoch=33, global_step=950
05/22/2022 10:16:53 - INFO - __main__ - Step 960 Global step 960 Train loss 0.22 on epoch=34
05/22/2022 10:16:55 - INFO - __main__ - Step 970 Global step 970 Train loss 0.36 on epoch=34
05/22/2022 10:16:58 - INFO - __main__ - Step 980 Global step 980 Train loss 0.24 on epoch=34
05/22/2022 10:17:01 - INFO - __main__ - Step 990 Global step 990 Train loss 0.27 on epoch=35
05/22/2022 10:17:03 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.26 on epoch=35
05/22/2022 10:17:16 - INFO - __main__ - Global step 1000 Train loss 0.27 Classification-F1 0.5917234500265487 on epoch=35
05/22/2022 10:17:19 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=36
05/22/2022 10:17:22 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.23 on epoch=36
05/22/2022 10:17:24 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.28 on epoch=36
05/22/2022 10:17:27 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.33 on epoch=37
05/22/2022 10:17:29 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.25 on epoch=37
05/22/2022 10:17:42 - INFO - __main__ - Global step 1050 Train loss 0.26 Classification-F1 0.5623523809698201 on epoch=37
05/22/2022 10:17:45 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.21 on epoch=37
05/22/2022 10:17:47 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.24 on epoch=38
05/22/2022 10:17:50 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=38
05/22/2022 10:17:52 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.20 on epoch=38
05/22/2022 10:17:55 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.20 on epoch=39
05/22/2022 10:18:08 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.5733484257456667 on epoch=39
05/22/2022 10:18:11 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.31 on epoch=39
05/22/2022 10:18:13 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.24 on epoch=39
05/22/2022 10:18:16 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.21 on epoch=40
05/22/2022 10:18:18 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.21 on epoch=40
05/22/2022 10:18:21 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.28 on epoch=41
05/22/2022 10:18:34 - INFO - __main__ - Global step 1150 Train loss 0.25 Classification-F1 0.6143926623236968 on epoch=41
05/22/2022 10:18:34 - INFO - __main__ - Saving model with best Classification-F1: 0.5946404432926662 -> 0.6143926623236968 on epoch=41, global_step=1150
05/22/2022 10:18:37 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.16 on epoch=41
05/22/2022 10:18:39 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.29 on epoch=41
05/22/2022 10:18:42 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.18 on epoch=42
05/22/2022 10:18:44 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.20 on epoch=42
05/22/2022 10:18:47 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.23 on epoch=42
05/22/2022 10:18:59 - INFO - __main__ - Global step 1200 Train loss 0.21 Classification-F1 0.5805549045325906 on epoch=42
05/22/2022 10:19:02 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.16 on epoch=43
05/22/2022 10:19:05 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.22 on epoch=43
05/22/2022 10:19:07 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.19 on epoch=43
05/22/2022 10:19:10 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.18 on epoch=44
05/22/2022 10:19:13 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.16 on epoch=44
05/22/2022 10:19:25 - INFO - __main__ - Global step 1250 Train loss 0.18 Classification-F1 0.5988754378985471 on epoch=44
05/22/2022 10:19:28 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.18 on epoch=44
05/22/2022 10:19:31 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.21 on epoch=45
05/22/2022 10:19:33 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.20 on epoch=45
05/22/2022 10:19:36 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.18 on epoch=46
05/22/2022 10:19:38 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.21 on epoch=46
05/22/2022 10:19:51 - INFO - __main__ - Global step 1300 Train loss 0.19 Classification-F1 0.6289015954805428 on epoch=46
05/22/2022 10:19:51 - INFO - __main__ - Saving model with best Classification-F1: 0.6143926623236968 -> 0.6289015954805428 on epoch=46, global_step=1300
05/22/2022 10:19:54 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.26 on epoch=46
05/22/2022 10:19:57 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.20 on epoch=47
05/22/2022 10:19:59 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.15 on epoch=47
05/22/2022 10:20:02 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.15 on epoch=47
05/22/2022 10:20:05 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=48
05/22/2022 10:20:18 - INFO - __main__ - Global step 1350 Train loss 0.18 Classification-F1 0.6340066115292128 on epoch=48
05/22/2022 10:20:18 - INFO - __main__ - Saving model with best Classification-F1: 0.6289015954805428 -> 0.6340066115292128 on epoch=48, global_step=1350
05/22/2022 10:20:20 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.21 on epoch=48
05/22/2022 10:20:23 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.17 on epoch=48
05/22/2022 10:20:25 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.16 on epoch=49
05/22/2022 10:20:28 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.17 on epoch=49
05/22/2022 10:20:31 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.23 on epoch=49
05/22/2022 10:20:44 - INFO - __main__ - Global step 1400 Train loss 0.19 Classification-F1 0.5944373718360926 on epoch=49
05/22/2022 10:20:46 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.16 on epoch=50
05/22/2022 10:20:49 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=50
05/22/2022 10:20:51 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.21 on epoch=51
05/22/2022 10:20:54 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.12 on epoch=51
05/22/2022 10:20:57 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.14 on epoch=51
05/22/2022 10:21:09 - INFO - __main__ - Global step 1450 Train loss 0.15 Classification-F1 0.5882685667054551 on epoch=51
05/22/2022 10:21:12 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.16 on epoch=52
05/22/2022 10:21:14 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.16 on epoch=52
05/22/2022 10:21:17 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.20 on epoch=52
05/22/2022 10:21:20 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.18 on epoch=53
05/22/2022 10:21:22 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.16 on epoch=53
05/22/2022 10:21:35 - INFO - __main__ - Global step 1500 Train loss 0.17 Classification-F1 0.6582329459260987 on epoch=53
05/22/2022 10:21:35 - INFO - __main__ - Saving model with best Classification-F1: 0.6340066115292128 -> 0.6582329459260987 on epoch=53, global_step=1500
05/22/2022 10:21:37 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.13 on epoch=53
05/22/2022 10:21:40 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=54
05/22/2022 10:21:42 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.20 on epoch=54
05/22/2022 10:21:45 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.18 on epoch=54
05/22/2022 10:21:48 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.14 on epoch=55
05/22/2022 10:22:00 - INFO - __main__ - Global step 1550 Train loss 0.16 Classification-F1 0.5876499471257536 on epoch=55
05/22/2022 10:22:03 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=55
05/22/2022 10:22:05 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.15 on epoch=56
05/22/2022 10:22:08 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.14 on epoch=56
05/22/2022 10:22:10 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.14 on epoch=56
05/22/2022 10:22:13 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.15 on epoch=57
05/22/2022 10:22:26 - INFO - __main__ - Global step 1600 Train loss 0.14 Classification-F1 0.5763311636292346 on epoch=57
05/22/2022 10:22:29 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.13 on epoch=57
05/22/2022 10:22:31 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.16 on epoch=57
05/22/2022 10:22:34 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=58
05/22/2022 10:22:37 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.18 on epoch=58
05/22/2022 10:22:39 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=58
05/22/2022 10:22:52 - INFO - __main__ - Global step 1650 Train loss 0.13 Classification-F1 0.5712733900776242 on epoch=58
05/22/2022 10:22:54 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.08 on epoch=59
05/22/2022 10:22:57 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.16 on epoch=59
05/22/2022 10:22:59 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.11 on epoch=59
05/22/2022 10:23:02 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.15 on epoch=60
05/22/2022 10:23:05 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.14 on epoch=60
05/22/2022 10:23:17 - INFO - __main__ - Global step 1700 Train loss 0.13 Classification-F1 0.5711869735793181 on epoch=60
05/22/2022 10:23:20 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.09 on epoch=61
05/22/2022 10:23:23 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.13 on epoch=61
05/22/2022 10:23:25 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.12 on epoch=61
05/22/2022 10:23:28 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.17 on epoch=62
05/22/2022 10:23:30 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.13 on epoch=62
05/22/2022 10:23:43 - INFO - __main__ - Global step 1750 Train loss 0.13 Classification-F1 0.6532484765293934 on epoch=62
05/22/2022 10:23:46 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.10 on epoch=62
05/22/2022 10:23:48 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.09 on epoch=63
05/22/2022 10:23:51 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.18 on epoch=63
05/22/2022 10:23:54 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.10 on epoch=63
05/22/2022 10:23:56 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.11 on epoch=64
05/22/2022 10:24:09 - INFO - __main__ - Global step 1800 Train loss 0.12 Classification-F1 0.6823877569297777 on epoch=64
05/22/2022 10:24:09 - INFO - __main__ - Saving model with best Classification-F1: 0.6582329459260987 -> 0.6823877569297777 on epoch=64, global_step=1800
05/22/2022 10:24:12 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.19 on epoch=64
05/22/2022 10:24:15 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.09 on epoch=64
05/22/2022 10:24:17 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.11 on epoch=65
05/22/2022 10:24:20 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.11 on epoch=65
05/22/2022 10:24:23 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.14 on epoch=66
05/22/2022 10:24:35 - INFO - __main__ - Global step 1850 Train loss 0.13 Classification-F1 0.6206517534729935 on epoch=66
05/22/2022 10:24:38 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.10 on epoch=66
05/22/2022 10:24:41 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.11 on epoch=66
05/22/2022 10:24:43 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.13 on epoch=67
05/22/2022 10:24:46 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.20 on epoch=67
05/22/2022 10:24:49 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.08 on epoch=67
05/22/2022 10:25:02 - INFO - __main__ - Global step 1900 Train loss 0.13 Classification-F1 0.6617198148001682 on epoch=67
05/22/2022 10:25:04 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.07 on epoch=68
05/22/2022 10:25:07 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.15 on epoch=68
05/22/2022 10:25:09 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.13 on epoch=68
05/22/2022 10:25:12 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.08 on epoch=69
05/22/2022 10:25:15 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.10 on epoch=69
05/22/2022 10:25:28 - INFO - __main__ - Global step 1950 Train loss 0.10 Classification-F1 0.6975066155268972 on epoch=69
05/22/2022 10:25:28 - INFO - __main__ - Saving model with best Classification-F1: 0.6823877569297777 -> 0.6975066155268972 on epoch=69, global_step=1950
05/22/2022 10:25:31 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=69
05/22/2022 10:25:33 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.09 on epoch=70
05/22/2022 10:25:36 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.10 on epoch=70
05/22/2022 10:25:39 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=71
05/22/2022 10:25:41 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.12 on epoch=71
05/22/2022 10:25:54 - INFO - __main__ - Global step 2000 Train loss 0.09 Classification-F1 0.6999480808715883 on epoch=71
05/22/2022 10:25:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6975066155268972 -> 0.6999480808715883 on epoch=71, global_step=2000
05/22/2022 10:25:57 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.08 on epoch=71
05/22/2022 10:25:59 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.09 on epoch=72
05/22/2022 10:26:02 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=72
05/22/2022 10:26:04 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=72
05/22/2022 10:26:07 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.08 on epoch=73
05/22/2022 10:26:20 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.6058183729264004 on epoch=73
05/22/2022 10:26:23 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.10 on epoch=73
05/22/2022 10:26:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.11 on epoch=73
05/22/2022 10:26:28 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.07 on epoch=74
05/22/2022 10:26:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.12 on epoch=74
05/22/2022 10:26:33 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.09 on epoch=74
05/22/2022 10:26:46 - INFO - __main__ - Global step 2100 Train loss 0.10 Classification-F1 0.6318097599465524 on epoch=74
05/22/2022 10:26:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.05 on epoch=75
05/22/2022 10:26:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.13 on epoch=75
05/22/2022 10:26:54 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.07 on epoch=76
05/22/2022 10:26:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.12 on epoch=76
05/22/2022 10:26:59 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=76
05/22/2022 10:27:12 - INFO - __main__ - Global step 2150 Train loss 0.09 Classification-F1 0.7073293765896326 on epoch=76
05/22/2022 10:27:12 - INFO - __main__ - Saving model with best Classification-F1: 0.6999480808715883 -> 0.7073293765896326 on epoch=76, global_step=2150
05/22/2022 10:27:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.13 on epoch=77
05/22/2022 10:27:17 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.11 on epoch=77
05/22/2022 10:27:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.09 on epoch=77
05/22/2022 10:27:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.07 on epoch=78
05/22/2022 10:27:25 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.14 on epoch=78
05/22/2022 10:27:38 - INFO - __main__ - Global step 2200 Train loss 0.11 Classification-F1 0.7055932654785215 on epoch=78
05/22/2022 10:27:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.15 on epoch=78
05/22/2022 10:27:43 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.07 on epoch=79
05/22/2022 10:27:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.17 on epoch=79
05/22/2022 10:27:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.08 on epoch=79
05/22/2022 10:27:51 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=80
05/22/2022 10:28:04 - INFO - __main__ - Global step 2250 Train loss 0.11 Classification-F1 0.6614332646696823 on epoch=80
05/22/2022 10:28:06 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.07 on epoch=80
05/22/2022 10:28:09 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.10 on epoch=81
05/22/2022 10:28:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.11 on epoch=81
05/22/2022 10:28:14 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.08 on epoch=81
05/22/2022 10:28:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.08 on epoch=82
05/22/2022 10:28:30 - INFO - __main__ - Global step 2300 Train loss 0.09 Classification-F1 0.6768951438954119 on epoch=82
05/22/2022 10:28:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.07 on epoch=82
05/22/2022 10:28:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.07 on epoch=82
05/22/2022 10:28:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.07 on epoch=83
05/22/2022 10:28:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.09 on epoch=83
05/22/2022 10:28:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.07 on epoch=83
05/22/2022 10:28:56 - INFO - __main__ - Global step 2350 Train loss 0.07 Classification-F1 0.684648754120162 on epoch=83
05/22/2022 10:28:59 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.06 on epoch=84
05/22/2022 10:29:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.08 on epoch=84
05/22/2022 10:29:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.06 on epoch=84
05/22/2022 10:29:07 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.10 on epoch=85
05/22/2022 10:29:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.09 on epoch=85
05/22/2022 10:29:22 - INFO - __main__ - Global step 2400 Train loss 0.08 Classification-F1 0.7131370644906796 on epoch=85
05/22/2022 10:29:22 - INFO - __main__ - Saving model with best Classification-F1: 0.7073293765896326 -> 0.7131370644906796 on epoch=85, global_step=2400
05/22/2022 10:29:24 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.08 on epoch=86
05/22/2022 10:29:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.06 on epoch=86
05/22/2022 10:29:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.08 on epoch=86
05/22/2022 10:29:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.16 on epoch=87
05/22/2022 10:29:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.05 on epoch=87
05/22/2022 10:29:48 - INFO - __main__ - Global step 2450 Train loss 0.09 Classification-F1 0.7144390812933666 on epoch=87
05/22/2022 10:29:48 - INFO - __main__ - Saving model with best Classification-F1: 0.7131370644906796 -> 0.7144390812933666 on epoch=87, global_step=2450
05/22/2022 10:29:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.10 on epoch=87
05/22/2022 10:29:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.07 on epoch=88
05/22/2022 10:29:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.09 on epoch=88
05/22/2022 10:29:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.04 on epoch=88
05/22/2022 10:30:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=89
05/22/2022 10:30:13 - INFO - __main__ - Global step 2500 Train loss 0.07 Classification-F1 0.7271381287269588 on epoch=89
05/22/2022 10:30:13 - INFO - __main__ - Saving model with best Classification-F1: 0.7144390812933666 -> 0.7271381287269588 on epoch=89, global_step=2500
05/22/2022 10:30:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.09 on epoch=89
05/22/2022 10:30:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.04 on epoch=89
05/22/2022 10:30:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.10 on epoch=90
05/22/2022 10:30:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.08 on epoch=90
05/22/2022 10:30:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=91
05/22/2022 10:30:39 - INFO - __main__ - Global step 2550 Train loss 0.08 Classification-F1 0.7295515988118549 on epoch=91
05/22/2022 10:30:39 - INFO - __main__ - Saving model with best Classification-F1: 0.7271381287269588 -> 0.7295515988118549 on epoch=91, global_step=2550
05/22/2022 10:30:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.07 on epoch=91
05/22/2022 10:30:45 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.08 on epoch=91
05/22/2022 10:30:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=92
05/22/2022 10:30:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.10 on epoch=92
05/22/2022 10:30:53 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.06 on epoch=92
05/22/2022 10:31:05 - INFO - __main__ - Global step 2600 Train loss 0.08 Classification-F1 0.7188013599600824 on epoch=92
05/22/2022 10:31:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.05 on epoch=93
05/22/2022 10:31:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.09 on epoch=93
05/22/2022 10:31:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.09 on epoch=93
05/22/2022 10:31:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.11 on epoch=94
05/22/2022 10:31:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.11 on epoch=94
05/22/2022 10:31:31 - INFO - __main__ - Global step 2650 Train loss 0.09 Classification-F1 0.6979942835034962 on epoch=94
05/22/2022 10:31:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.05 on epoch=94
05/22/2022 10:31:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.04 on epoch=95
05/22/2022 10:31:39 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.11 on epoch=95
05/22/2022 10:31:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.04 on epoch=96
05/22/2022 10:31:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.08 on epoch=96
05/22/2022 10:31:56 - INFO - __main__ - Global step 2700 Train loss 0.07 Classification-F1 0.7118209443889807 on epoch=96
05/22/2022 10:31:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.05 on epoch=96
05/22/2022 10:32:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.05 on epoch=97
05/22/2022 10:32:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.04 on epoch=97
05/22/2022 10:32:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.07 on epoch=97
05/22/2022 10:32:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.03 on epoch=98
05/22/2022 10:32:22 - INFO - __main__ - Global step 2750 Train loss 0.05 Classification-F1 0.7100567322845875 on epoch=98
05/22/2022 10:32:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.09 on epoch=98
05/22/2022 10:32:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.09 on epoch=98
05/22/2022 10:32:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.07 on epoch=99
05/22/2022 10:32:32 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.07 on epoch=99
05/22/2022 10:32:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.05 on epoch=99
05/22/2022 10:32:48 - INFO - __main__ - Global step 2800 Train loss 0.07 Classification-F1 0.7266828544148713 on epoch=99
05/22/2022 10:32:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=100
05/22/2022 10:32:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.07 on epoch=100
05/22/2022 10:32:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.07 on epoch=101
05/22/2022 10:32:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.06 on epoch=101
05/22/2022 10:33:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.06 on epoch=101
05/22/2022 10:33:13 - INFO - __main__ - Global step 2850 Train loss 0.06 Classification-F1 0.7220112365032924 on epoch=101
05/22/2022 10:33:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.04 on epoch=102
05/22/2022 10:33:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.08 on epoch=102
05/22/2022 10:33:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=102
05/22/2022 10:33:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.04 on epoch=103
05/22/2022 10:33:27 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.11 on epoch=103
05/22/2022 10:33:39 - INFO - __main__ - Global step 2900 Train loss 0.07 Classification-F1 0.7174121319041878 on epoch=103
05/22/2022 10:33:42 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.06 on epoch=103
05/22/2022 10:33:45 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=104
05/22/2022 10:33:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.10 on epoch=104
05/22/2022 10:33:50 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.04 on epoch=104
05/22/2022 10:33:53 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.08 on epoch=105
05/22/2022 10:34:05 - INFO - __main__ - Global step 2950 Train loss 0.06 Classification-F1 0.8209975166752828 on epoch=105
05/22/2022 10:34:05 - INFO - __main__ - Saving model with best Classification-F1: 0.7295515988118549 -> 0.8209975166752828 on epoch=105, global_step=2950
05/22/2022 10:34:08 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=105
05/22/2022 10:34:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.07 on epoch=106
05/22/2022 10:34:13 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.04 on epoch=106
05/22/2022 10:34:16 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.06 on epoch=106
05/22/2022 10:34:18 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.06 on epoch=107
05/22/2022 10:34:20 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:34:20 - INFO - __main__ - Printing 3 examples
05/22/2022 10:34:20 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 10:34:20 - INFO - __main__ - ['Film']
05/22/2022 10:34:20 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 10:34:20 - INFO - __main__ - ['Film']
05/22/2022 10:34:20 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 10:34:20 - INFO - __main__ - ['Film']
05/22/2022 10:34:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:34:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:34:21 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 10:34:21 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:34:21 - INFO - __main__ - Printing 3 examples
05/22/2022 10:34:21 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 10:34:21 - INFO - __main__ - ['Film']
05/22/2022 10:34:21 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 10:34:21 - INFO - __main__ - ['Film']
05/22/2022 10:34:21 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 10:34:21 - INFO - __main__ - ['Film']
05/22/2022 10:34:21 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:34:21 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:34:21 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 10:34:31 - INFO - __main__ - Global step 3000 Train loss 0.05 Classification-F1 0.7843860730870041 on epoch=107
05/22/2022 10:34:31 - INFO - __main__ - save last model!
05/22/2022 10:34:31 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 10:34:31 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 10:34:31 - INFO - __main__ - Printing 3 examples
05/22/2022 10:34:31 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 10:34:31 - INFO - __main__ - ['Animal']
05/22/2022 10:34:31 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 10:34:31 - INFO - __main__ - ['Animal']
05/22/2022 10:34:31 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 10:34:31 - INFO - __main__ - ['Village']
05/22/2022 10:34:31 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:34:33 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:34:37 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 10:34:37 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 10:34:38 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 10:34:38 - INFO - __main__ - Starting training!
05/22/2022 10:36:40 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_42_0.2_8_predictions.txt
05/22/2022 10:36:40 - INFO - __main__ - Classification-F1 on test data: 0.6263
05/22/2022 10:36:40 - INFO - __main__ - prefix=dbpedia_14_32_42, lr=0.2, bsz=8, dev_performance=0.8209975166752828, test_performance=0.6263408415081972
05/22/2022 10:36:40 - INFO - __main__ - Running ... prefix=dbpedia_14_32_87, lr=0.5, bsz=8 ...
05/22/2022 10:36:41 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:36:41 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:41 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 10:36:41 - INFO - __main__ - ['Film']
05/22/2022 10:36:41 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 10:36:41 - INFO - __main__ - ['Film']
05/22/2022 10:36:41 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 10:36:41 - INFO - __main__ - ['Film']
05/22/2022 10:36:41 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:41 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:42 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 10:36:42 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 10:36:42 - INFO - __main__ - Printing 3 examples
05/22/2022 10:36:42 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 10:36:42 - INFO - __main__ - ['Film']
05/22/2022 10:36:42 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 10:36:42 - INFO - __main__ - ['Film']
05/22/2022 10:36:42 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 10:36:42 - INFO - __main__ - ['Film']
05/22/2022 10:36:42 - INFO - __main__ - Tokenizing Input ...
05/22/2022 10:36:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 10:36:43 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 10:36:59 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 10:36:59 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 10:36:59 - INFO - __main__ - Starting training!
05/22/2022 10:37:03 - INFO - __main__ - Step 10 Global step 10 Train loss 7.14 on epoch=0
05/22/2022 10:37:06 - INFO - __main__ - Step 20 Global step 20 Train loss 4.74 on epoch=0
05/22/2022 10:37:08 - INFO - __main__ - Step 30 Global step 30 Train loss 4.01 on epoch=1
05/22/2022 10:37:11 - INFO - __main__ - Step 40 Global step 40 Train loss 3.37 on epoch=1
05/22/2022 10:37:13 - INFO - __main__ - Step 50 Global step 50 Train loss 2.82 on epoch=1
05/22/2022 10:37:27 - INFO - __main__ - Global step 50 Train loss 4.42 Classification-F1 0.0319816313504777 on epoch=1
05/22/2022 10:37:27 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.0319816313504777 on epoch=1, global_step=50
05/22/2022 10:37:29 - INFO - __main__ - Step 60 Global step 60 Train loss 2.56 on epoch=2
05/22/2022 10:37:32 - INFO - __main__ - Step 70 Global step 70 Train loss 2.17 on epoch=2
05/22/2022 10:37:34 - INFO - __main__ - Step 80 Global step 80 Train loss 2.30 on epoch=2
05/22/2022 10:37:37 - INFO - __main__ - Step 90 Global step 90 Train loss 1.92 on epoch=3
05/22/2022 10:37:40 - INFO - __main__ - Step 100 Global step 100 Train loss 1.76 on epoch=3
05/22/2022 10:37:51 - INFO - __main__ - Global step 100 Train loss 2.14 Classification-F1 0.08880721789959656 on epoch=3
05/22/2022 10:37:51 - INFO - __main__ - Saving model with best Classification-F1: 0.0319816313504777 -> 0.08880721789959656 on epoch=3, global_step=100
05/22/2022 10:37:53 - INFO - __main__ - Step 110 Global step 110 Train loss 1.70 on epoch=3
05/22/2022 10:37:56 - INFO - __main__ - Step 120 Global step 120 Train loss 1.50 on epoch=4
05/22/2022 10:37:59 - INFO - __main__ - Step 130 Global step 130 Train loss 1.41 on epoch=4
05/22/2022 10:38:01 - INFO - __main__ - Step 140 Global step 140 Train loss 1.16 on epoch=4
05/22/2022 10:38:04 - INFO - __main__ - Step 150 Global step 150 Train loss 1.33 on epoch=5
05/22/2022 10:38:15 - INFO - __main__ - Global step 150 Train loss 1.42 Classification-F1 0.1851726266877854 on epoch=5
05/22/2022 10:38:15 - INFO - __main__ - Saving model with best Classification-F1: 0.08880721789959656 -> 0.1851726266877854 on epoch=5, global_step=150
05/22/2022 10:38:18 - INFO - __main__ - Step 160 Global step 160 Train loss 1.08 on epoch=5
05/22/2022 10:38:20 - INFO - __main__ - Step 170 Global step 170 Train loss 0.86 on epoch=6
05/22/2022 10:38:23 - INFO - __main__ - Step 180 Global step 180 Train loss 0.89 on epoch=6
05/22/2022 10:38:25 - INFO - __main__ - Step 190 Global step 190 Train loss 0.69 on epoch=6
05/22/2022 10:38:28 - INFO - __main__ - Step 200 Global step 200 Train loss 0.61 on epoch=7
05/22/2022 10:38:40 - INFO - __main__ - Global step 200 Train loss 0.83 Classification-F1 0.2985775766421674 on epoch=7
05/22/2022 10:38:40 - INFO - __main__ - Saving model with best Classification-F1: 0.1851726266877854 -> 0.2985775766421674 on epoch=7, global_step=200
05/22/2022 10:38:42 - INFO - __main__ - Step 210 Global step 210 Train loss 0.66 on epoch=7
05/22/2022 10:38:45 - INFO - __main__ - Step 220 Global step 220 Train loss 0.60 on epoch=7
05/22/2022 10:38:48 - INFO - __main__ - Step 230 Global step 230 Train loss 0.57 on epoch=8
05/22/2022 10:38:50 - INFO - __main__ - Step 240 Global step 240 Train loss 0.52 on epoch=8
05/22/2022 10:38:53 - INFO - __main__ - Step 250 Global step 250 Train loss 0.57 on epoch=8
05/22/2022 10:39:06 - INFO - __main__ - Global step 250 Train loss 0.58 Classification-F1 0.44190345408363996 on epoch=8
05/22/2022 10:39:06 - INFO - __main__ - Saving model with best Classification-F1: 0.2985775766421674 -> 0.44190345408363996 on epoch=8, global_step=250
05/22/2022 10:39:09 - INFO - __main__ - Step 260 Global step 260 Train loss 0.47 on epoch=9
05/22/2022 10:39:11 - INFO - __main__ - Step 270 Global step 270 Train loss 0.34 on epoch=9
05/22/2022 10:39:14 - INFO - __main__ - Step 280 Global step 280 Train loss 0.46 on epoch=9
05/22/2022 10:39:16 - INFO - __main__ - Step 290 Global step 290 Train loss 0.43 on epoch=10
05/22/2022 10:39:19 - INFO - __main__ - Step 300 Global step 300 Train loss 0.38 on epoch=10
05/22/2022 10:39:32 - INFO - __main__ - Global step 300 Train loss 0.42 Classification-F1 0.480431260018543 on epoch=10
05/22/2022 10:39:32 - INFO - __main__ - Saving model with best Classification-F1: 0.44190345408363996 -> 0.480431260018543 on epoch=10, global_step=300
05/22/2022 10:39:35 - INFO - __main__ - Step 310 Global step 310 Train loss 0.38 on epoch=11
05/22/2022 10:39:37 - INFO - __main__ - Step 320 Global step 320 Train loss 0.39 on epoch=11
05/22/2022 10:39:40 - INFO - __main__ - Step 330 Global step 330 Train loss 0.32 on epoch=11
05/22/2022 10:39:42 - INFO - __main__ - Step 340 Global step 340 Train loss 0.37 on epoch=12
05/22/2022 10:39:45 - INFO - __main__ - Step 350 Global step 350 Train loss 0.24 on epoch=12
05/22/2022 10:39:58 - INFO - __main__ - Global step 350 Train loss 0.34 Classification-F1 0.6887265193601974 on epoch=12
05/22/2022 10:39:58 - INFO - __main__ - Saving model with best Classification-F1: 0.480431260018543 -> 0.6887265193601974 on epoch=12, global_step=350
05/22/2022 10:40:00 - INFO - __main__ - Step 360 Global step 360 Train loss 0.30 on epoch=12
05/22/2022 10:40:03 - INFO - __main__ - Step 370 Global step 370 Train loss 0.29 on epoch=13
05/22/2022 10:40:06 - INFO - __main__ - Step 380 Global step 380 Train loss 0.36 on epoch=13
05/22/2022 10:40:08 - INFO - __main__ - Step 390 Global step 390 Train loss 0.21 on epoch=13
05/22/2022 10:40:11 - INFO - __main__ - Step 400 Global step 400 Train loss 0.30 on epoch=14
05/22/2022 10:40:24 - INFO - __main__ - Global step 400 Train loss 0.29 Classification-F1 0.766980979287101 on epoch=14
05/22/2022 10:40:24 - INFO - __main__ - Saving model with best Classification-F1: 0.6887265193601974 -> 0.766980979287101 on epoch=14, global_step=400
05/22/2022 10:40:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.24 on epoch=14
05/22/2022 10:40:29 - INFO - __main__ - Step 420 Global step 420 Train loss 0.24 on epoch=14
05/22/2022 10:40:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.28 on epoch=15
05/22/2022 10:40:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.33 on epoch=15
05/22/2022 10:40:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.21 on epoch=16
05/22/2022 10:40:51 - INFO - __main__ - Global step 450 Train loss 0.26 Classification-F1 0.6459883405253262 on epoch=16
05/22/2022 10:40:53 - INFO - __main__ - Step 460 Global step 460 Train loss 0.22 on epoch=16
05/22/2022 10:40:56 - INFO - __main__ - Step 470 Global step 470 Train loss 0.24 on epoch=16
05/22/2022 10:40:59 - INFO - __main__ - Step 480 Global step 480 Train loss 0.15 on epoch=17
05/22/2022 10:41:01 - INFO - __main__ - Step 490 Global step 490 Train loss 0.20 on epoch=17
05/22/2022 10:41:04 - INFO - __main__ - Step 500 Global step 500 Train loss 0.15 on epoch=17
05/22/2022 10:41:17 - INFO - __main__ - Global step 500 Train loss 0.19 Classification-F1 0.65504896914065 on epoch=17
05/22/2022 10:41:20 - INFO - __main__ - Step 510 Global step 510 Train loss 0.18 on epoch=18
05/22/2022 10:41:22 - INFO - __main__ - Step 520 Global step 520 Train loss 0.16 on epoch=18
05/22/2022 10:41:25 - INFO - __main__ - Step 530 Global step 530 Train loss 0.18 on epoch=18
05/22/2022 10:41:28 - INFO - __main__ - Step 540 Global step 540 Train loss 0.17 on epoch=19
05/22/2022 10:41:31 - INFO - __main__ - Step 550 Global step 550 Train loss 0.11 on epoch=19
05/22/2022 10:41:44 - INFO - __main__ - Global step 550 Train loss 0.16 Classification-F1 0.6328604188755895 on epoch=19
05/22/2022 10:41:46 - INFO - __main__ - Step 560 Global step 560 Train loss 0.12 on epoch=19
05/22/2022 10:41:49 - INFO - __main__ - Step 570 Global step 570 Train loss 0.13 on epoch=20
05/22/2022 10:41:51 - INFO - __main__ - Step 580 Global step 580 Train loss 0.17 on epoch=20
05/22/2022 10:41:54 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=21
05/22/2022 10:41:57 - INFO - __main__ - Step 600 Global step 600 Train loss 0.14 on epoch=21
05/22/2022 10:42:09 - INFO - __main__ - Global step 600 Train loss 0.14 Classification-F1 0.6897604272861009 on epoch=21
05/22/2022 10:42:12 - INFO - __main__ - Step 610 Global step 610 Train loss 0.14 on epoch=21
05/22/2022 10:42:15 - INFO - __main__ - Step 620 Global step 620 Train loss 0.12 on epoch=22
05/22/2022 10:42:17 - INFO - __main__ - Step 630 Global step 630 Train loss 0.19 on epoch=22
05/22/2022 10:42:20 - INFO - __main__ - Step 640 Global step 640 Train loss 0.11 on epoch=22
05/22/2022 10:42:23 - INFO - __main__ - Step 650 Global step 650 Train loss 0.15 on epoch=23
05/22/2022 10:42:36 - INFO - __main__ - Global step 650 Train loss 0.14 Classification-F1 0.7179164278220171 on epoch=23
05/22/2022 10:42:38 - INFO - __main__ - Step 660 Global step 660 Train loss 0.09 on epoch=23
05/22/2022 10:42:41 - INFO - __main__ - Step 670 Global step 670 Train loss 0.15 on epoch=23
05/22/2022 10:42:44 - INFO - __main__ - Step 680 Global step 680 Train loss 0.22 on epoch=24
05/22/2022 10:42:46 - INFO - __main__ - Step 690 Global step 690 Train loss 0.12 on epoch=24
05/22/2022 10:42:49 - INFO - __main__ - Step 700 Global step 700 Train loss 0.09 on epoch=24
05/22/2022 10:43:02 - INFO - __main__ - Global step 700 Train loss 0.13 Classification-F1 0.7020532504107563 on epoch=24
05/22/2022 10:43:05 - INFO - __main__ - Step 710 Global step 710 Train loss 0.09 on epoch=25
05/22/2022 10:43:07 - INFO - __main__ - Step 720 Global step 720 Train loss 0.09 on epoch=25
05/22/2022 10:43:10 - INFO - __main__ - Step 730 Global step 730 Train loss 0.13 on epoch=26
05/22/2022 10:43:13 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=26
05/22/2022 10:43:15 - INFO - __main__ - Step 750 Global step 750 Train loss 0.15 on epoch=26
05/22/2022 10:43:28 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.7052779952948515 on epoch=26
05/22/2022 10:43:31 - INFO - __main__ - Step 760 Global step 760 Train loss 0.16 on epoch=27
05/22/2022 10:43:33 - INFO - __main__ - Step 770 Global step 770 Train loss 0.08 on epoch=27
05/22/2022 10:43:36 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=27
05/22/2022 10:43:39 - INFO - __main__ - Step 790 Global step 790 Train loss 0.09 on epoch=28
05/22/2022 10:43:41 - INFO - __main__ - Step 800 Global step 800 Train loss 0.06 on epoch=28
05/22/2022 10:43:54 - INFO - __main__ - Global step 800 Train loss 0.10 Classification-F1 0.797581910326872 on epoch=28
05/22/2022 10:43:54 - INFO - __main__ - Saving model with best Classification-F1: 0.766980979287101 -> 0.797581910326872 on epoch=28, global_step=800
05/22/2022 10:43:57 - INFO - __main__ - Step 810 Global step 810 Train loss 0.08 on epoch=28
05/22/2022 10:44:00 - INFO - __main__ - Step 820 Global step 820 Train loss 0.08 on epoch=29
05/22/2022 10:44:02 - INFO - __main__ - Step 830 Global step 830 Train loss 0.09 on epoch=29
05/22/2022 10:44:05 - INFO - __main__ - Step 840 Global step 840 Train loss 0.04 on epoch=29
05/22/2022 10:44:07 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=30
05/22/2022 10:44:21 - INFO - __main__ - Global step 850 Train loss 0.08 Classification-F1 0.8572586156003494 on epoch=30
05/22/2022 10:44:21 - INFO - __main__ - Saving model with best Classification-F1: 0.797581910326872 -> 0.8572586156003494 on epoch=30, global_step=850
05/22/2022 10:44:23 - INFO - __main__ - Step 860 Global step 860 Train loss 0.07 on epoch=30
05/22/2022 10:44:26 - INFO - __main__ - Step 870 Global step 870 Train loss 0.08 on epoch=31
05/22/2022 10:44:29 - INFO - __main__ - Step 880 Global step 880 Train loss 0.06 on epoch=31
05/22/2022 10:44:31 - INFO - __main__ - Step 890 Global step 890 Train loss 0.07 on epoch=31
05/22/2022 10:44:34 - INFO - __main__ - Step 900 Global step 900 Train loss 0.11 on epoch=32
05/22/2022 10:44:47 - INFO - __main__ - Global step 900 Train loss 0.08 Classification-F1 0.8357111647289452 on epoch=32
05/22/2022 10:44:49 - INFO - __main__ - Step 910 Global step 910 Train loss 0.06 on epoch=32
05/22/2022 10:44:52 - INFO - __main__ - Step 920 Global step 920 Train loss 0.06 on epoch=32
05/22/2022 10:44:54 - INFO - __main__ - Step 930 Global step 930 Train loss 0.07 on epoch=33
05/22/2022 10:44:57 - INFO - __main__ - Step 940 Global step 940 Train loss 0.06 on epoch=33
05/22/2022 10:45:00 - INFO - __main__ - Step 950 Global step 950 Train loss 0.07 on epoch=33
05/22/2022 10:45:12 - INFO - __main__ - Global step 950 Train loss 0.06 Classification-F1 0.804028587575847 on epoch=33
05/22/2022 10:45:15 - INFO - __main__ - Step 960 Global step 960 Train loss 0.12 on epoch=34
05/22/2022 10:45:18 - INFO - __main__ - Step 970 Global step 970 Train loss 0.05 on epoch=34
05/22/2022 10:45:20 - INFO - __main__ - Step 980 Global step 980 Train loss 0.06 on epoch=34
05/22/2022 10:45:23 - INFO - __main__ - Step 990 Global step 990 Train loss 0.04 on epoch=35
05/22/2022 10:45:25 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.08 on epoch=35
05/22/2022 10:45:38 - INFO - __main__ - Global step 1000 Train loss 0.07 Classification-F1 0.8049020552424837 on epoch=35
05/22/2022 10:45:41 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.04 on epoch=36
05/22/2022 10:45:44 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.03 on epoch=36
05/22/2022 10:45:46 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.03 on epoch=36
05/22/2022 10:45:49 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.07 on epoch=37
05/22/2022 10:45:52 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.05 on epoch=37
05/22/2022 10:46:04 - INFO - __main__ - Global step 1050 Train loss 0.04 Classification-F1 0.7575566334302893 on epoch=37
05/22/2022 10:46:07 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.05 on epoch=37
05/22/2022 10:46:10 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=38
05/22/2022 10:46:12 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.04 on epoch=38
05/22/2022 10:46:15 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.04 on epoch=38
05/22/2022 10:46:18 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.04 on epoch=39
05/22/2022 10:46:30 - INFO - __main__ - Global step 1100 Train loss 0.05 Classification-F1 0.8461777742849728 on epoch=39
05/22/2022 10:46:33 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.07 on epoch=39
05/22/2022 10:46:36 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.06 on epoch=39
05/22/2022 10:46:38 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.05 on epoch=40
05/22/2022 10:46:41 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.09 on epoch=40
05/22/2022 10:46:44 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.07 on epoch=41
05/22/2022 10:46:57 - INFO - __main__ - Global step 1150 Train loss 0.07 Classification-F1 0.848118025008146 on epoch=41
05/22/2022 10:46:59 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.07 on epoch=41
05/22/2022 10:47:02 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.11 on epoch=41
05/22/2022 10:47:04 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.05 on epoch=42
05/22/2022 10:47:07 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.04 on epoch=42
05/22/2022 10:47:10 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=42
05/22/2022 10:47:22 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.8596974402648241 on epoch=42
05/22/2022 10:47:22 - INFO - __main__ - Saving model with best Classification-F1: 0.8572586156003494 -> 0.8596974402648241 on epoch=42, global_step=1200
05/22/2022 10:47:25 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.03 on epoch=43
05/22/2022 10:47:28 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.02 on epoch=43
05/22/2022 10:47:30 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.07 on epoch=43
05/22/2022 10:47:33 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.04 on epoch=44
05/22/2022 10:47:36 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.07 on epoch=44
05/22/2022 10:47:48 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.848691141128137 on epoch=44
05/22/2022 10:47:51 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.02 on epoch=44
05/22/2022 10:47:54 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.04 on epoch=45
05/22/2022 10:47:56 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.04 on epoch=45
05/22/2022 10:47:59 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.04 on epoch=46
05/22/2022 10:48:02 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.02 on epoch=46
05/22/2022 10:48:15 - INFO - __main__ - Global step 1300 Train loss 0.03 Classification-F1 0.9163843071504362 on epoch=46
05/22/2022 10:48:15 - INFO - __main__ - Saving model with best Classification-F1: 0.8596974402648241 -> 0.9163843071504362 on epoch=46, global_step=1300
05/22/2022 10:48:18 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.02 on epoch=46
05/22/2022 10:48:20 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.12 on epoch=47
05/22/2022 10:48:23 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=47
05/22/2022 10:48:25 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.02 on epoch=47
05/22/2022 10:48:28 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.05 on epoch=48
05/22/2022 10:48:42 - INFO - __main__ - Global step 1350 Train loss 0.05 Classification-F1 0.8631798977149899 on epoch=48
05/22/2022 10:48:44 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.04 on epoch=48
05/22/2022 10:48:47 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.10 on epoch=48
05/22/2022 10:48:50 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.07 on epoch=49
05/22/2022 10:48:52 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.02 on epoch=49
05/22/2022 10:48:55 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.06 on epoch=49
05/22/2022 10:49:08 - INFO - __main__ - Global step 1400 Train loss 0.06 Classification-F1 0.9177352840777888 on epoch=49
05/22/2022 10:49:08 - INFO - __main__ - Saving model with best Classification-F1: 0.9163843071504362 -> 0.9177352840777888 on epoch=49, global_step=1400
05/22/2022 10:49:11 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=50
05/22/2022 10:49:13 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.02 on epoch=50
05/22/2022 10:49:16 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.06 on epoch=51
05/22/2022 10:49:19 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.02 on epoch=51
05/22/2022 10:49:21 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.03 on epoch=51
05/22/2022 10:49:36 - INFO - __main__ - Global step 1450 Train loss 0.04 Classification-F1 0.8580562204932165 on epoch=51
05/22/2022 10:49:39 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.02 on epoch=52
05/22/2022 10:49:41 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.02 on epoch=52
05/22/2022 10:49:44 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=52
05/22/2022 10:49:47 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.04 on epoch=53
05/22/2022 10:49:49 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=53
05/22/2022 10:50:03 - INFO - __main__ - Global step 1500 Train loss 0.03 Classification-F1 0.8612517410596501 on epoch=53
05/22/2022 10:50:05 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.02 on epoch=53
05/22/2022 10:50:08 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.04 on epoch=54
05/22/2022 10:50:11 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.02 on epoch=54
05/22/2022 10:50:13 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=54
05/22/2022 10:50:16 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.03 on epoch=55
05/22/2022 10:50:29 - INFO - __main__ - Global step 1550 Train loss 0.03 Classification-F1 0.9207625185447768 on epoch=55
05/22/2022 10:50:29 - INFO - __main__ - Saving model with best Classification-F1: 0.9177352840777888 -> 0.9207625185447768 on epoch=55, global_step=1550
05/22/2022 10:50:32 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.02 on epoch=55
05/22/2022 10:50:35 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 10:50:37 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.02 on epoch=56
05/22/2022 10:50:40 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.01 on epoch=56
05/22/2022 10:50:43 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.02 on epoch=57
05/22/2022 10:50:56 - INFO - __main__ - Global step 1600 Train loss 0.02 Classification-F1 0.764449150702566 on epoch=57
05/22/2022 10:50:59 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=57
05/22/2022 10:51:02 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=57
05/22/2022 10:51:04 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.07 on epoch=58
05/22/2022 10:51:07 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.01 on epoch=58
05/22/2022 10:51:10 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.02 on epoch=58
05/22/2022 10:51:22 - INFO - __main__ - Global step 1650 Train loss 0.04 Classification-F1 0.9197044129705421 on epoch=58
05/22/2022 10:51:25 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.01 on epoch=59
05/22/2022 10:51:28 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.03 on epoch=59
05/22/2022 10:51:30 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=59
05/22/2022 10:51:33 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.03 on epoch=60
05/22/2022 10:51:36 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.01 on epoch=60
05/22/2022 10:51:49 - INFO - __main__ - Global step 1700 Train loss 0.02 Classification-F1 0.8651334996685919 on epoch=60
05/22/2022 10:51:51 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.01 on epoch=61
05/22/2022 10:51:54 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.02 on epoch=61
05/22/2022 10:51:56 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.02 on epoch=61
05/22/2022 10:51:59 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.02 on epoch=62
05/22/2022 10:52:02 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 10:52:14 - INFO - __main__ - Global step 1750 Train loss 0.02 Classification-F1 0.9216763791763791 on epoch=62
05/22/2022 10:52:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9207625185447768 -> 0.9216763791763791 on epoch=62, global_step=1750
05/22/2022 10:52:17 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.02 on epoch=62
05/22/2022 10:52:20 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=63
05/22/2022 10:52:22 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.01 on epoch=63
05/22/2022 10:52:25 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=63
05/22/2022 10:52:28 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.05 on epoch=64
05/22/2022 10:52:40 - INFO - __main__ - Global step 1800 Train loss 0.03 Classification-F1 0.8632172920605381 on epoch=64
05/22/2022 10:52:43 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=64
05/22/2022 10:52:45 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.03 on epoch=64
05/22/2022 10:52:48 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.01 on epoch=65
05/22/2022 10:52:51 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.01 on epoch=65
05/22/2022 10:52:53 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.01 on epoch=66
05/22/2022 10:53:06 - INFO - __main__ - Global step 1850 Train loss 0.02 Classification-F1 0.8652005546536796 on epoch=66
05/22/2022 10:53:08 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.03 on epoch=66
05/22/2022 10:53:11 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.01 on epoch=66
05/22/2022 10:53:14 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.04 on epoch=67
05/22/2022 10:53:16 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.01 on epoch=67
05/22/2022 10:53:19 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=67
05/22/2022 10:53:32 - INFO - __main__ - Global step 1900 Train loss 0.02 Classification-F1 0.9195981416883057 on epoch=67
05/22/2022 10:53:35 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.02 on epoch=68
05/22/2022 10:53:38 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=68
05/22/2022 10:53:41 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 10:53:43 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=69
05/22/2022 10:53:46 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.01 on epoch=69
05/22/2022 10:53:59 - INFO - __main__ - Global step 1950 Train loss 0.02 Classification-F1 0.9156525087288846 on epoch=69
05/22/2022 10:54:01 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=69
05/22/2022 10:54:04 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=70
05/22/2022 10:54:06 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.03 on epoch=70
05/22/2022 10:54:09 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.02 on epoch=71
05/22/2022 10:54:12 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.02 on epoch=71
05/22/2022 10:54:24 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.8086109333346634 on epoch=71
05/22/2022 10:54:27 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.11 on epoch=71
05/22/2022 10:54:30 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.01 on epoch=72
05/22/2022 10:54:32 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.03 on epoch=72
05/22/2022 10:54:35 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.02 on epoch=72
05/22/2022 10:54:38 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.03 on epoch=73
05/22/2022 10:54:51 - INFO - __main__ - Global step 2050 Train loss 0.04 Classification-F1 0.8095125918122621 on epoch=73
05/22/2022 10:54:53 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.05 on epoch=73
05/22/2022 10:54:56 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=73
05/22/2022 10:54:58 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.04 on epoch=74
05/22/2022 10:55:01 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=74
05/22/2022 10:55:04 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.04 on epoch=74
05/22/2022 10:55:18 - INFO - __main__ - Global step 2100 Train loss 0.03 Classification-F1 0.8532618367295787 on epoch=74
05/22/2022 10:55:21 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.02 on epoch=75
05/22/2022 10:55:23 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.02 on epoch=75
05/22/2022 10:55:26 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.03 on epoch=76
05/22/2022 10:55:28 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.02 on epoch=76
05/22/2022 10:55:31 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.01 on epoch=76
05/22/2022 10:55:45 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9196697687020269 on epoch=76
05/22/2022 10:55:48 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.01 on epoch=77
05/22/2022 10:55:50 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=77
05/22/2022 10:55:53 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=77
05/22/2022 10:55:56 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.05 on epoch=78
05/22/2022 10:55:58 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=78
05/22/2022 10:56:12 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9196527967610056 on epoch=78
05/22/2022 10:56:15 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.03 on epoch=78
05/22/2022 10:56:17 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=79
05/22/2022 10:56:20 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=79
05/22/2022 10:56:23 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.01 on epoch=79
05/22/2022 10:56:25 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.01 on epoch=80
05/22/2022 10:56:39 - INFO - __main__ - Global step 2250 Train loss 0.02 Classification-F1 0.9175875021036312 on epoch=80
05/22/2022 10:56:42 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.01 on epoch=80
05/22/2022 10:56:44 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 10:56:47 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.01 on epoch=81
05/22/2022 10:56:50 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.03 on epoch=81
05/22/2022 10:56:52 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=82
05/22/2022 10:57:05 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.8612308236678197 on epoch=82
05/22/2022 10:57:08 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.02 on epoch=82
05/22/2022 10:57:11 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.01 on epoch=82
05/22/2022 10:57:13 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.01 on epoch=83
05/22/2022 10:57:16 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.01 on epoch=83
05/22/2022 10:57:19 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.00 on epoch=83
05/22/2022 10:57:32 - INFO - __main__ - Global step 2350 Train loss 0.01 Classification-F1 0.809606360590706 on epoch=83
05/22/2022 10:57:34 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=84
05/22/2022 10:57:37 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.01 on epoch=84
05/22/2022 10:57:39 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=84
05/22/2022 10:57:42 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.03 on epoch=85
05/22/2022 10:57:45 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 10:57:58 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.8505017523918734 on epoch=85
05/22/2022 10:58:01 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=86
05/22/2022 10:58:04 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.01 on epoch=86
05/22/2022 10:58:06 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=86
05/22/2022 10:58:09 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 10:58:11 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.02 on epoch=87
05/22/2022 10:58:25 - INFO - __main__ - Global step 2450 Train loss 0.01 Classification-F1 0.9218217863379154 on epoch=87
05/22/2022 10:58:25 - INFO - __main__ - Saving model with best Classification-F1: 0.9216763791763791 -> 0.9218217863379154 on epoch=87, global_step=2450
05/22/2022 10:58:28 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=87
05/22/2022 10:58:31 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.03 on epoch=88
05/22/2022 10:58:33 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.00 on epoch=88
05/22/2022 10:58:36 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 10:58:39 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.01 on epoch=89
05/22/2022 10:58:51 - INFO - __main__ - Global step 2500 Train loss 0.02 Classification-F1 0.9866005985821654 on epoch=89
05/22/2022 10:58:51 - INFO - __main__ - Saving model with best Classification-F1: 0.9218217863379154 -> 0.9866005985821654 on epoch=89, global_step=2500
05/22/2022 10:58:54 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=89
05/22/2022 10:58:57 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.03 on epoch=89
05/22/2022 10:58:59 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.00 on epoch=90
05/22/2022 10:59:02 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 10:59:05 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=91
05/22/2022 10:59:18 - INFO - __main__ - Global step 2550 Train loss 0.01 Classification-F1 0.8582221541898961 on epoch=91
05/22/2022 10:59:20 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.02 on epoch=91
05/22/2022 10:59:23 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=91
05/22/2022 10:59:26 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.01 on epoch=92
05/22/2022 10:59:28 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.00 on epoch=92
05/22/2022 10:59:31 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=92
05/22/2022 10:59:44 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9197044129705421 on epoch=92
05/22/2022 10:59:46 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.01 on epoch=93
05/22/2022 10:59:49 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 10:59:52 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.00 on epoch=93
05/22/2022 10:59:54 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 10:59:57 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.00 on epoch=94
05/22/2022 11:00:10 - INFO - __main__ - Global step 2650 Train loss 0.01 Classification-F1 0.9156525087288846 on epoch=94
05/22/2022 11:00:12 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.01 on epoch=94
05/22/2022 11:00:15 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=95
05/22/2022 11:00:18 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.00 on epoch=95
05/22/2022 11:00:21 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 11:00:23 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=96
05/22/2022 11:00:36 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9176813393056773 on epoch=96
05/22/2022 11:00:39 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.03 on epoch=96
05/22/2022 11:00:41 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.02 on epoch=97
05/22/2022 11:00:44 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.00 on epoch=97
05/22/2022 11:00:47 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.00 on epoch=97
05/22/2022 11:00:49 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.02 on epoch=98
05/22/2022 11:01:02 - INFO - __main__ - Global step 2750 Train loss 0.02 Classification-F1 0.9218543926205217 on epoch=98
05/22/2022 11:01:04 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=98
05/22/2022 11:01:07 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.01 on epoch=98
05/22/2022 11:01:10 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.01 on epoch=99
05/22/2022 11:01:12 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=99
05/22/2022 11:01:15 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.01 on epoch=99
05/22/2022 11:01:29 - INFO - __main__ - Global step 2800 Train loss 0.02 Classification-F1 0.8651394150764111 on epoch=99
05/22/2022 11:01:31 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.01 on epoch=100
05/22/2022 11:01:34 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.01 on epoch=100
05/22/2022 11:01:37 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 11:01:39 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.02 on epoch=101
05/22/2022 11:01:42 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.00 on epoch=101
05/22/2022 11:01:55 - INFO - __main__ - Global step 2850 Train loss 0.01 Classification-F1 0.9196527967610056 on epoch=101
05/22/2022 11:01:57 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=102
05/22/2022 11:02:00 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.02 on epoch=102
05/22/2022 11:02:03 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.01 on epoch=102
05/22/2022 11:02:05 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.01 on epoch=103
05/22/2022 11:02:08 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 11:02:21 - INFO - __main__ - Global step 2900 Train loss 0.01 Classification-F1 0.9238672673713657 on epoch=103
05/22/2022 11:02:24 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.03 on epoch=103
05/22/2022 11:02:26 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.02 on epoch=104
05/22/2022 11:02:29 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=104
05/22/2022 11:02:32 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.00 on epoch=104
05/22/2022 11:02:34 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.00 on epoch=105
05/22/2022 11:02:47 - INFO - __main__ - Global step 2950 Train loss 0.01 Classification-F1 0.8651334996685919 on epoch=105
05/22/2022 11:02:50 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.03 on epoch=105
05/22/2022 11:02:52 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 11:02:55 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.01 on epoch=106
05/22/2022 11:02:58 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 11:03:00 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.00 on epoch=107
05/22/2022 11:03:02 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:03:02 - INFO - __main__ - Printing 3 examples
05/22/2022 11:03:02 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 11:03:02 - INFO - __main__ - ['Film']
05/22/2022 11:03:02 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 11:03:02 - INFO - __main__ - ['Film']
05/22/2022 11:03:02 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 11:03:02 - INFO - __main__ - ['Film']
05/22/2022 11:03:02 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:03:02 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:03:03 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 11:03:03 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:03:03 - INFO - __main__ - Printing 3 examples
05/22/2022 11:03:03 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 11:03:03 - INFO - __main__ - ['Film']
05/22/2022 11:03:03 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 11:03:03 - INFO - __main__ - ['Film']
05/22/2022 11:03:03 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 11:03:03 - INFO - __main__ - ['Film']
05/22/2022 11:03:03 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:03:03 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:03:03 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 11:03:14 - INFO - __main__ - Global step 3000 Train loss 0.01 Classification-F1 0.9238672673713657 on epoch=107
05/22/2022 11:03:14 - INFO - __main__ - save last model!
05/22/2022 11:03:14 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 11:03:14 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 11:03:14 - INFO - __main__ - Printing 3 examples
05/22/2022 11:03:14 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 11:03:14 - INFO - __main__ - ['Animal']
05/22/2022 11:03:14 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 11:03:14 - INFO - __main__ - ['Animal']
05/22/2022 11:03:14 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 11:03:14 - INFO - __main__ - ['Village']
05/22/2022 11:03:14 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:03:16 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:03:19 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 11:03:22 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 11:03:22 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 11:03:22 - INFO - __main__ - Starting training!
05/22/2022 11:05:32 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_87_0.5_8_predictions.txt
05/22/2022 11:05:32 - INFO - __main__ - Classification-F1 on test data: 0.6855
05/22/2022 11:05:32 - INFO - __main__ - prefix=dbpedia_14_32_87, lr=0.5, bsz=8, dev_performance=0.9866005985821654, test_performance=0.685495371477395
05/22/2022 11:05:32 - INFO - __main__ - Running ... prefix=dbpedia_14_32_87, lr=0.4, bsz=8 ...
05/22/2022 11:05:33 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:05:33 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:33 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 11:05:33 - INFO - __main__ - ['Film']
05/22/2022 11:05:33 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 11:05:33 - INFO - __main__ - ['Film']
05/22/2022 11:05:33 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 11:05:33 - INFO - __main__ - ['Film']
05/22/2022 11:05:33 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:33 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:34 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 11:05:34 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:05:34 - INFO - __main__ - Printing 3 examples
05/22/2022 11:05:34 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 11:05:34 - INFO - __main__ - ['Film']
05/22/2022 11:05:34 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 11:05:34 - INFO - __main__ - ['Film']
05/22/2022 11:05:34 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 11:05:34 - INFO - __main__ - ['Film']
05/22/2022 11:05:34 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:05:34 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:05:35 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 11:05:51 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 11:05:51 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 11:05:51 - INFO - __main__ - Starting training!
05/22/2022 11:05:55 - INFO - __main__ - Step 10 Global step 10 Train loss 7.57 on epoch=0
05/22/2022 11:05:57 - INFO - __main__ - Step 20 Global step 20 Train loss 4.76 on epoch=0
05/22/2022 11:06:00 - INFO - __main__ - Step 30 Global step 30 Train loss 4.25 on epoch=1
05/22/2022 11:06:02 - INFO - __main__ - Step 40 Global step 40 Train loss 3.56 on epoch=1
05/22/2022 11:06:05 - INFO - __main__ - Step 50 Global step 50 Train loss 3.22 on epoch=1
05/22/2022 11:06:18 - INFO - __main__ - Global step 50 Train loss 4.67 Classification-F1 0.026240848878057995 on epoch=1
05/22/2022 11:06:18 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.026240848878057995 on epoch=1, global_step=50
05/22/2022 11:06:21 - INFO - __main__ - Step 60 Global step 60 Train loss 2.90 on epoch=2
05/22/2022 11:06:23 - INFO - __main__ - Step 70 Global step 70 Train loss 2.67 on epoch=2
05/22/2022 11:06:26 - INFO - __main__ - Step 80 Global step 80 Train loss 2.67 on epoch=2
05/22/2022 11:06:29 - INFO - __main__ - Step 90 Global step 90 Train loss 2.14 on epoch=3
05/22/2022 11:06:31 - INFO - __main__ - Step 100 Global step 100 Train loss 1.93 on epoch=3
05/22/2022 11:06:43 - INFO - __main__ - Global step 100 Train loss 2.46 Classification-F1 0.06624970112365071 on epoch=3
05/22/2022 11:06:43 - INFO - __main__ - Saving model with best Classification-F1: 0.026240848878057995 -> 0.06624970112365071 on epoch=3, global_step=100
05/22/2022 11:06:45 - INFO - __main__ - Step 110 Global step 110 Train loss 1.92 on epoch=3
05/22/2022 11:06:48 - INFO - __main__ - Step 120 Global step 120 Train loss 1.90 on epoch=4
05/22/2022 11:06:51 - INFO - __main__ - Step 130 Global step 130 Train loss 1.58 on epoch=4
05/22/2022 11:06:53 - INFO - __main__ - Step 140 Global step 140 Train loss 1.43 on epoch=4
05/22/2022 11:06:56 - INFO - __main__ - Step 150 Global step 150 Train loss 1.58 on epoch=5
05/22/2022 11:07:07 - INFO - __main__ - Global step 150 Train loss 1.68 Classification-F1 0.13439944242693344 on epoch=5
05/22/2022 11:07:07 - INFO - __main__ - Saving model with best Classification-F1: 0.06624970112365071 -> 0.13439944242693344 on epoch=5, global_step=150
05/22/2022 11:07:09 - INFO - __main__ - Step 160 Global step 160 Train loss 1.22 on epoch=5
05/22/2022 11:07:12 - INFO - __main__ - Step 170 Global step 170 Train loss 1.13 on epoch=6
05/22/2022 11:07:15 - INFO - __main__ - Step 180 Global step 180 Train loss 1.23 on epoch=6
05/22/2022 11:07:17 - INFO - __main__ - Step 190 Global step 190 Train loss 1.03 on epoch=6
05/22/2022 11:07:20 - INFO - __main__ - Step 200 Global step 200 Train loss 0.88 on epoch=7
05/22/2022 11:07:31 - INFO - __main__ - Global step 200 Train loss 1.10 Classification-F1 0.20777802796647432 on epoch=7
05/22/2022 11:07:31 - INFO - __main__ - Saving model with best Classification-F1: 0.13439944242693344 -> 0.20777802796647432 on epoch=7, global_step=200
05/22/2022 11:07:33 - INFO - __main__ - Step 210 Global step 210 Train loss 0.94 on epoch=7
05/22/2022 11:07:36 - INFO - __main__ - Step 220 Global step 220 Train loss 0.88 on epoch=7
05/22/2022 11:07:39 - INFO - __main__ - Step 230 Global step 230 Train loss 0.77 on epoch=8
05/22/2022 11:07:41 - INFO - __main__ - Step 240 Global step 240 Train loss 0.69 on epoch=8
05/22/2022 11:07:44 - INFO - __main__ - Step 250 Global step 250 Train loss 0.64 on epoch=8
05/22/2022 11:07:56 - INFO - __main__ - Global step 250 Train loss 0.78 Classification-F1 0.30702542093418306 on epoch=8
05/22/2022 11:07:56 - INFO - __main__ - Saving model with best Classification-F1: 0.20777802796647432 -> 0.30702542093418306 on epoch=8, global_step=250
05/22/2022 11:07:59 - INFO - __main__ - Step 260 Global step 260 Train loss 0.60 on epoch=9
05/22/2022 11:08:01 - INFO - __main__ - Step 270 Global step 270 Train loss 0.50 on epoch=9
05/22/2022 11:08:04 - INFO - __main__ - Step 280 Global step 280 Train loss 0.47 on epoch=9
05/22/2022 11:08:06 - INFO - __main__ - Step 290 Global step 290 Train loss 0.59 on epoch=10
05/22/2022 11:08:09 - INFO - __main__ - Step 300 Global step 300 Train loss 0.48 on epoch=10
05/22/2022 11:08:22 - INFO - __main__ - Global step 300 Train loss 0.53 Classification-F1 0.39750050001091686 on epoch=10
05/22/2022 11:08:22 - INFO - __main__ - Saving model with best Classification-F1: 0.30702542093418306 -> 0.39750050001091686 on epoch=10, global_step=300
05/22/2022 11:08:25 - INFO - __main__ - Step 310 Global step 310 Train loss 0.45 on epoch=11
05/22/2022 11:08:28 - INFO - __main__ - Step 320 Global step 320 Train loss 0.51 on epoch=11
05/22/2022 11:08:30 - INFO - __main__ - Step 330 Global step 330 Train loss 0.40 on epoch=11
05/22/2022 11:08:33 - INFO - __main__ - Step 340 Global step 340 Train loss 0.48 on epoch=12
05/22/2022 11:08:35 - INFO - __main__ - Step 350 Global step 350 Train loss 0.39 on epoch=12
05/22/2022 11:08:49 - INFO - __main__ - Global step 350 Train loss 0.45 Classification-F1 0.48281086527702893 on epoch=12
05/22/2022 11:08:49 - INFO - __main__ - Saving model with best Classification-F1: 0.39750050001091686 -> 0.48281086527702893 on epoch=12, global_step=350
05/22/2022 11:08:51 - INFO - __main__ - Step 360 Global step 360 Train loss 0.41 on epoch=12
05/22/2022 11:08:54 - INFO - __main__ - Step 370 Global step 370 Train loss 0.44 on epoch=13
05/22/2022 11:08:56 - INFO - __main__ - Step 380 Global step 380 Train loss 0.32 on epoch=13
05/22/2022 11:08:59 - INFO - __main__ - Step 390 Global step 390 Train loss 0.39 on epoch=13
05/22/2022 11:09:02 - INFO - __main__ - Step 400 Global step 400 Train loss 0.39 on epoch=14
05/22/2022 11:09:15 - INFO - __main__ - Global step 400 Train loss 0.39 Classification-F1 0.5637627551957106 on epoch=14
05/22/2022 11:09:15 - INFO - __main__ - Saving model with best Classification-F1: 0.48281086527702893 -> 0.5637627551957106 on epoch=14, global_step=400
05/22/2022 11:09:18 - INFO - __main__ - Step 410 Global step 410 Train loss 0.32 on epoch=14
05/22/2022 11:09:20 - INFO - __main__ - Step 420 Global step 420 Train loss 0.33 on epoch=14
05/22/2022 11:09:23 - INFO - __main__ - Step 430 Global step 430 Train loss 0.29 on epoch=15
05/22/2022 11:09:26 - INFO - __main__ - Step 440 Global step 440 Train loss 0.30 on epoch=15
05/22/2022 11:09:28 - INFO - __main__ - Step 450 Global step 450 Train loss 0.34 on epoch=16
05/22/2022 11:09:41 - INFO - __main__ - Global step 450 Train loss 0.32 Classification-F1 0.5581022403222803 on epoch=16
05/22/2022 11:09:44 - INFO - __main__ - Step 460 Global step 460 Train loss 0.30 on epoch=16
05/22/2022 11:09:46 - INFO - __main__ - Step 470 Global step 470 Train loss 0.20 on epoch=16
05/22/2022 11:09:49 - INFO - __main__ - Step 480 Global step 480 Train loss 0.25 on epoch=17
05/22/2022 11:09:51 - INFO - __main__ - Step 490 Global step 490 Train loss 0.24 on epoch=17
05/22/2022 11:09:54 - INFO - __main__ - Step 500 Global step 500 Train loss 0.21 on epoch=17
05/22/2022 11:10:07 - INFO - __main__ - Global step 500 Train loss 0.24 Classification-F1 0.6670066684815947 on epoch=17
05/22/2022 11:10:07 - INFO - __main__ - Saving model with best Classification-F1: 0.5637627551957106 -> 0.6670066684815947 on epoch=17, global_step=500
05/22/2022 11:10:10 - INFO - __main__ - Step 510 Global step 510 Train loss 0.26 on epoch=18
05/22/2022 11:10:13 - INFO - __main__ - Step 520 Global step 520 Train loss 0.25 on epoch=18
05/22/2022 11:10:15 - INFO - __main__ - Step 530 Global step 530 Train loss 0.26 on epoch=18
05/22/2022 11:10:18 - INFO - __main__ - Step 540 Global step 540 Train loss 0.21 on epoch=19
05/22/2022 11:10:20 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=19
05/22/2022 11:10:34 - INFO - __main__ - Global step 550 Train loss 0.24 Classification-F1 0.7835823325529716 on epoch=19
05/22/2022 11:10:34 - INFO - __main__ - Saving model with best Classification-F1: 0.6670066684815947 -> 0.7835823325529716 on epoch=19, global_step=550
05/22/2022 11:10:37 - INFO - __main__ - Step 560 Global step 560 Train loss 0.19 on epoch=19
05/22/2022 11:10:39 - INFO - __main__ - Step 570 Global step 570 Train loss 0.20 on epoch=20
05/22/2022 11:10:42 - INFO - __main__ - Step 580 Global step 580 Train loss 0.15 on epoch=20
05/22/2022 11:10:45 - INFO - __main__ - Step 590 Global step 590 Train loss 0.13 on epoch=21
05/22/2022 11:10:47 - INFO - __main__ - Step 600 Global step 600 Train loss 0.26 on epoch=21
05/22/2022 11:11:01 - INFO - __main__ - Global step 600 Train loss 0.19 Classification-F1 0.7325016520093193 on epoch=21
05/22/2022 11:11:03 - INFO - __main__ - Step 610 Global step 610 Train loss 0.17 on epoch=21
05/22/2022 11:11:06 - INFO - __main__ - Step 620 Global step 620 Train loss 0.14 on epoch=22
05/22/2022 11:11:08 - INFO - __main__ - Step 630 Global step 630 Train loss 0.15 on epoch=22
05/22/2022 11:11:11 - INFO - __main__ - Step 640 Global step 640 Train loss 0.19 on epoch=22
05/22/2022 11:11:14 - INFO - __main__ - Step 650 Global step 650 Train loss 0.17 on epoch=23
05/22/2022 11:11:27 - INFO - __main__ - Global step 650 Train loss 0.16 Classification-F1 0.7779299630069041 on epoch=23
05/22/2022 11:11:29 - INFO - __main__ - Step 660 Global step 660 Train loss 0.15 on epoch=23
05/22/2022 11:11:32 - INFO - __main__ - Step 670 Global step 670 Train loss 0.12 on epoch=23
05/22/2022 11:11:35 - INFO - __main__ - Step 680 Global step 680 Train loss 0.21 on epoch=24
05/22/2022 11:11:37 - INFO - __main__ - Step 690 Global step 690 Train loss 0.16 on epoch=24
05/22/2022 11:11:40 - INFO - __main__ - Step 700 Global step 700 Train loss 0.14 on epoch=24
05/22/2022 11:11:53 - INFO - __main__ - Global step 700 Train loss 0.16 Classification-F1 0.6504812415466066 on epoch=24
05/22/2022 11:11:56 - INFO - __main__ - Step 710 Global step 710 Train loss 0.11 on epoch=25
05/22/2022 11:11:58 - INFO - __main__ - Step 720 Global step 720 Train loss 0.12 on epoch=25
05/22/2022 11:12:01 - INFO - __main__ - Step 730 Global step 730 Train loss 0.10 on epoch=26
05/22/2022 11:12:04 - INFO - __main__ - Step 740 Global step 740 Train loss 0.10 on epoch=26
05/22/2022 11:12:06 - INFO - __main__ - Step 750 Global step 750 Train loss 0.12 on epoch=26
05/22/2022 11:12:19 - INFO - __main__ - Global step 750 Train loss 0.11 Classification-F1 0.6526736880675641 on epoch=26
05/22/2022 11:12:22 - INFO - __main__ - Step 760 Global step 760 Train loss 0.13 on epoch=27
05/22/2022 11:12:24 - INFO - __main__ - Step 770 Global step 770 Train loss 0.14 on epoch=27
05/22/2022 11:12:27 - INFO - __main__ - Step 780 Global step 780 Train loss 0.10 on epoch=27
05/22/2022 11:12:30 - INFO - __main__ - Step 790 Global step 790 Train loss 0.11 on epoch=28
05/22/2022 11:12:32 - INFO - __main__ - Step 800 Global step 800 Train loss 0.14 on epoch=28
05/22/2022 11:12:45 - INFO - __main__ - Global step 800 Train loss 0.12 Classification-F1 0.7141414569980351 on epoch=28
05/22/2022 11:12:47 - INFO - __main__ - Step 810 Global step 810 Train loss 0.12 on epoch=28
05/22/2022 11:12:50 - INFO - __main__ - Step 820 Global step 820 Train loss 0.14 on epoch=29
05/22/2022 11:12:53 - INFO - __main__ - Step 830 Global step 830 Train loss 0.11 on epoch=29
05/22/2022 11:12:56 - INFO - __main__ - Step 840 Global step 840 Train loss 0.16 on epoch=29
05/22/2022 11:12:58 - INFO - __main__ - Step 850 Global step 850 Train loss 0.12 on epoch=30
05/22/2022 11:13:11 - INFO - __main__ - Global step 850 Train loss 0.13 Classification-F1 0.6631798348892443 on epoch=30
05/22/2022 11:13:14 - INFO - __main__ - Step 860 Global step 860 Train loss 0.13 on epoch=30
05/22/2022 11:13:16 - INFO - __main__ - Step 870 Global step 870 Train loss 0.11 on epoch=31
05/22/2022 11:13:19 - INFO - __main__ - Step 880 Global step 880 Train loss 0.07 on epoch=31
05/22/2022 11:13:22 - INFO - __main__ - Step 890 Global step 890 Train loss 0.08 on epoch=31
05/22/2022 11:13:24 - INFO - __main__ - Step 900 Global step 900 Train loss 0.14 on epoch=32
05/22/2022 11:13:37 - INFO - __main__ - Global step 900 Train loss 0.11 Classification-F1 0.6624591028665732 on epoch=32
05/22/2022 11:13:39 - INFO - __main__ - Step 910 Global step 910 Train loss 0.14 on epoch=32
05/22/2022 11:13:42 - INFO - __main__ - Step 920 Global step 920 Train loss 0.16 on epoch=32
05/22/2022 11:13:45 - INFO - __main__ - Step 930 Global step 930 Train loss 0.13 on epoch=33
05/22/2022 11:13:47 - INFO - __main__ - Step 940 Global step 940 Train loss 0.08 on epoch=33
05/22/2022 11:13:50 - INFO - __main__ - Step 950 Global step 950 Train loss 0.12 on epoch=33
05/22/2022 11:14:03 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7367048764015359 on epoch=33
05/22/2022 11:14:05 - INFO - __main__ - Step 960 Global step 960 Train loss 0.10 on epoch=34
05/22/2022 11:14:08 - INFO - __main__ - Step 970 Global step 970 Train loss 0.12 on epoch=34
05/22/2022 11:14:11 - INFO - __main__ - Step 980 Global step 980 Train loss 0.12 on epoch=34
05/22/2022 11:14:13 - INFO - __main__ - Step 990 Global step 990 Train loss 0.12 on epoch=35
05/22/2022 11:14:16 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.11 on epoch=35
05/22/2022 11:14:29 - INFO - __main__ - Global step 1000 Train loss 0.11 Classification-F1 0.6872120522375192 on epoch=35
05/22/2022 11:14:32 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.11 on epoch=36
05/22/2022 11:14:35 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.09 on epoch=36
05/22/2022 11:14:37 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.08 on epoch=36
05/22/2022 11:14:40 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.08 on epoch=37
05/22/2022 11:14:43 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.08 on epoch=37
05/22/2022 11:14:55 - INFO - __main__ - Global step 1050 Train loss 0.09 Classification-F1 0.6963266760333364 on epoch=37
05/22/2022 11:14:58 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=37
05/22/2022 11:15:01 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.06 on epoch=38
05/22/2022 11:15:03 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.08 on epoch=38
05/22/2022 11:15:06 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.10 on epoch=38
05/22/2022 11:15:09 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.06 on epoch=39
05/22/2022 11:15:22 - INFO - __main__ - Global step 1100 Train loss 0.08 Classification-F1 0.7358443425278653 on epoch=39
05/22/2022 11:15:25 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.11 on epoch=39
05/22/2022 11:15:27 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.10 on epoch=39
05/22/2022 11:15:30 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.07 on epoch=40
05/22/2022 11:15:32 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.08 on epoch=40
05/22/2022 11:15:35 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.06 on epoch=41
05/22/2022 11:15:48 - INFO - __main__ - Global step 1150 Train loss 0.09 Classification-F1 0.7340900143713484 on epoch=41
05/22/2022 11:15:50 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.10 on epoch=41
05/22/2022 11:15:53 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.05 on epoch=41
05/22/2022 11:15:55 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.07 on epoch=42
05/22/2022 11:15:58 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.07 on epoch=42
05/22/2022 11:16:01 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.03 on epoch=42
05/22/2022 11:16:13 - INFO - __main__ - Global step 1200 Train loss 0.06 Classification-F1 0.7426625408144224 on epoch=42
05/22/2022 11:16:16 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.05 on epoch=43
05/22/2022 11:16:19 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.04 on epoch=43
05/22/2022 11:16:21 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.04 on epoch=43
05/22/2022 11:16:24 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.10 on epoch=44
05/22/2022 11:16:27 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.04 on epoch=44
05/22/2022 11:16:40 - INFO - __main__ - Global step 1250 Train loss 0.05 Classification-F1 0.8030869549199205 on epoch=44
05/22/2022 11:16:40 - INFO - __main__ - Saving model with best Classification-F1: 0.7835823325529716 -> 0.8030869549199205 on epoch=44, global_step=1250
05/22/2022 11:16:42 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.06 on epoch=44
05/22/2022 11:16:45 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.11 on epoch=45
05/22/2022 11:16:48 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.05 on epoch=45
05/22/2022 11:16:50 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.03 on epoch=46
05/22/2022 11:16:53 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.11 on epoch=46
05/22/2022 11:17:06 - INFO - __main__ - Global step 1300 Train loss 0.07 Classification-F1 0.7994199757126703 on epoch=46
05/22/2022 11:17:09 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.05 on epoch=46
05/22/2022 11:17:11 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=47
05/22/2022 11:17:14 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.03 on epoch=47
05/22/2022 11:17:17 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.06 on epoch=47
05/22/2022 11:17:19 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.07 on epoch=48
05/22/2022 11:17:32 - INFO - __main__ - Global step 1350 Train loss 0.06 Classification-F1 0.808701832112648 on epoch=48
05/22/2022 11:17:32 - INFO - __main__ - Saving model with best Classification-F1: 0.8030869549199205 -> 0.808701832112648 on epoch=48, global_step=1350
05/22/2022 11:17:35 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.05 on epoch=48
05/22/2022 11:17:37 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.03 on epoch=48
05/22/2022 11:17:40 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.05 on epoch=49
05/22/2022 11:17:43 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.04 on epoch=49
05/22/2022 11:17:45 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.07 on epoch=49
05/22/2022 11:17:58 - INFO - __main__ - Global step 1400 Train loss 0.05 Classification-F1 0.8096647172667097 on epoch=49
05/22/2022 11:17:58 - INFO - __main__ - Saving model with best Classification-F1: 0.808701832112648 -> 0.8096647172667097 on epoch=49, global_step=1400
05/22/2022 11:18:01 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.06 on epoch=50
05/22/2022 11:18:04 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.05 on epoch=50
05/22/2022 11:18:06 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.03 on epoch=51
05/22/2022 11:18:09 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.06 on epoch=51
05/22/2022 11:18:11 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.04 on epoch=51
05/22/2022 11:18:24 - INFO - __main__ - Global step 1450 Train loss 0.05 Classification-F1 0.8612608255879426 on epoch=51
05/22/2022 11:18:24 - INFO - __main__ - Saving model with best Classification-F1: 0.8096647172667097 -> 0.8612608255879426 on epoch=51, global_step=1450
05/22/2022 11:18:27 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=52
05/22/2022 11:18:30 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.05 on epoch=52
05/22/2022 11:18:32 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.02 on epoch=52
05/22/2022 11:18:35 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.09 on epoch=53
05/22/2022 11:18:38 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.03 on epoch=53
05/22/2022 11:18:50 - INFO - __main__ - Global step 1500 Train loss 0.05 Classification-F1 0.9197705505366796 on epoch=53
05/22/2022 11:18:50 - INFO - __main__ - Saving model with best Classification-F1: 0.8612608255879426 -> 0.9197705505366796 on epoch=53, global_step=1500
05/22/2022 11:18:53 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.05 on epoch=53
05/22/2022 11:18:56 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=54
05/22/2022 11:18:58 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.06 on epoch=54
05/22/2022 11:19:01 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.04 on epoch=54
05/22/2022 11:19:04 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.02 on epoch=55
05/22/2022 11:19:17 - INFO - __main__ - Global step 1550 Train loss 0.04 Classification-F1 0.8632464295896756 on epoch=55
05/22/2022 11:19:19 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.05 on epoch=55
05/22/2022 11:19:22 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 11:19:25 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.04 on epoch=56
05/22/2022 11:19:27 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.05 on epoch=56
05/22/2022 11:19:30 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.06 on epoch=57
05/22/2022 11:19:43 - INFO - __main__ - Global step 1600 Train loss 0.05 Classification-F1 0.8561951475383935 on epoch=57
05/22/2022 11:19:46 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.05 on epoch=57
05/22/2022 11:19:48 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.01 on epoch=57
05/22/2022 11:19:51 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.15 on epoch=58
05/22/2022 11:19:54 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.04 on epoch=58
05/22/2022 11:19:56 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.04 on epoch=58
05/22/2022 11:20:09 - INFO - __main__ - Global step 1650 Train loss 0.06 Classification-F1 0.813372697563874 on epoch=58
05/22/2022 11:20:12 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=59
05/22/2022 11:20:14 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=59
05/22/2022 11:20:17 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.02 on epoch=59
05/22/2022 11:20:20 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.02 on epoch=60
05/22/2022 11:20:22 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=60
05/22/2022 11:20:36 - INFO - __main__ - Global step 1700 Train loss 0.03 Classification-F1 0.9197705505366796 on epoch=60
05/22/2022 11:20:38 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.03 on epoch=61
05/22/2022 11:20:41 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.05 on epoch=61
05/22/2022 11:20:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.03 on epoch=61
05/22/2022 11:20:46 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.06 on epoch=62
05/22/2022 11:20:49 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.02 on epoch=62
05/22/2022 11:21:02 - INFO - __main__ - Global step 1750 Train loss 0.04 Classification-F1 0.8085461515608574 on epoch=62
05/22/2022 11:21:04 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.09 on epoch=62
05/22/2022 11:21:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.04 on epoch=63
05/22/2022 11:21:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.03 on epoch=63
05/22/2022 11:21:12 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.04 on epoch=63
05/22/2022 11:21:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.03 on epoch=64
05/22/2022 11:21:28 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.8632464295896756 on epoch=64
05/22/2022 11:21:31 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.02 on epoch=64
05/22/2022 11:21:34 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.02 on epoch=64
05/22/2022 11:21:36 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.08 on epoch=65
05/22/2022 11:21:39 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.05 on epoch=65
05/22/2022 11:21:42 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=66
05/22/2022 11:21:55 - INFO - __main__ - Global step 1850 Train loss 0.04 Classification-F1 0.8572579956363338 on epoch=66
05/22/2022 11:21:57 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=66
05/22/2022 11:22:00 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.03 on epoch=66
05/22/2022 11:22:02 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.01 on epoch=67
05/22/2022 11:22:05 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.03 on epoch=67
05/22/2022 11:22:08 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.02 on epoch=67
05/22/2022 11:22:21 - INFO - __main__ - Global step 1900 Train loss 0.03 Classification-F1 0.8574321634412656 on epoch=67
05/22/2022 11:22:24 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.06 on epoch=68
05/22/2022 11:22:26 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.03 on epoch=68
05/22/2022 11:22:29 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=68
05/22/2022 11:22:32 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.04 on epoch=69
05/22/2022 11:22:34 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.03 on epoch=69
05/22/2022 11:22:47 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.9218543926205217 on epoch=69
05/22/2022 11:22:47 - INFO - __main__ - Saving model with best Classification-F1: 0.9197705505366796 -> 0.9218543926205217 on epoch=69, global_step=1950
05/22/2022 11:22:50 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.01 on epoch=69
05/22/2022 11:22:53 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.03 on epoch=70
05/22/2022 11:22:55 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.02 on epoch=70
05/22/2022 11:22:58 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=71
05/22/2022 11:23:01 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.03 on epoch=71
05/22/2022 11:23:14 - INFO - __main__ - Global step 2000 Train loss 0.02 Classification-F1 0.9218548551209842 on epoch=71
05/22/2022 11:23:14 - INFO - __main__ - Saving model with best Classification-F1: 0.9218543926205217 -> 0.9218548551209842 on epoch=71, global_step=2000
05/22/2022 11:23:17 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.03 on epoch=71
05/22/2022 11:23:19 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.03 on epoch=72
05/22/2022 11:23:22 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.02 on epoch=72
05/22/2022 11:23:25 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.03 on epoch=72
05/22/2022 11:23:27 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.02 on epoch=73
05/22/2022 11:23:41 - INFO - __main__ - Global step 2050 Train loss 0.02 Classification-F1 0.8671526795896756 on epoch=73
05/22/2022 11:23:43 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.02 on epoch=73
05/22/2022 11:23:46 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.02 on epoch=73
05/22/2022 11:23:49 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.02 on epoch=74
05/22/2022 11:23:51 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.01 on epoch=74
05/22/2022 11:23:54 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.01 on epoch=74
05/22/2022 11:24:07 - INFO - __main__ - Global step 2100 Train loss 0.01 Classification-F1 0.8671526795896756 on epoch=74
05/22/2022 11:24:10 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.01 on epoch=75
05/22/2022 11:24:12 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.03 on epoch=75
05/22/2022 11:24:15 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.01 on epoch=76
05/22/2022 11:24:18 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=76
05/22/2022 11:24:20 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.02 on epoch=76
05/22/2022 11:24:33 - INFO - __main__ - Global step 2150 Train loss 0.02 Classification-F1 0.9218503196325777 on epoch=76
05/22/2022 11:24:36 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.03 on epoch=77
05/22/2022 11:24:39 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.02 on epoch=77
05/22/2022 11:24:41 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.01 on epoch=77
05/22/2022 11:24:44 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.02 on epoch=78
05/22/2022 11:24:47 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.01 on epoch=78
05/22/2022 11:24:59 - INFO - __main__ - Global step 2200 Train loss 0.02 Classification-F1 0.9218218818218818 on epoch=78
05/22/2022 11:25:02 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.04 on epoch=78
05/22/2022 11:25:05 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.02 on epoch=79
05/22/2022 11:25:07 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.02 on epoch=79
05/22/2022 11:25:10 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=79
05/22/2022 11:25:13 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 11:25:26 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.9176477924018908 on epoch=80
05/22/2022 11:25:28 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.02 on epoch=80
05/22/2022 11:25:31 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 11:25:34 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.02 on epoch=81
05/22/2022 11:25:36 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.02 on epoch=81
05/22/2022 11:25:39 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.01 on epoch=82
05/22/2022 11:25:52 - INFO - __main__ - Global step 2300 Train loss 0.02 Classification-F1 0.9239041484202775 on epoch=82
05/22/2022 11:25:52 - INFO - __main__ - Saving model with best Classification-F1: 0.9218548551209842 -> 0.9239041484202775 on epoch=82, global_step=2300
05/22/2022 11:25:55 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.04 on epoch=82
05/22/2022 11:25:58 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=82
05/22/2022 11:26:00 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.03 on epoch=83
05/22/2022 11:26:03 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=83
05/22/2022 11:26:06 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.05 on epoch=83
05/22/2022 11:26:19 - INFO - __main__ - Global step 2350 Train loss 0.03 Classification-F1 0.9865558756047763 on epoch=83
05/22/2022 11:26:19 - INFO - __main__ - Saving model with best Classification-F1: 0.9239041484202775 -> 0.9865558756047763 on epoch=83, global_step=2350
05/22/2022 11:26:21 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.02 on epoch=84
05/22/2022 11:26:24 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.04 on epoch=84
05/22/2022 11:26:27 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.01 on epoch=84
05/22/2022 11:26:29 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=85
05/22/2022 11:26:32 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 11:26:45 - INFO - __main__ - Global step 2400 Train loss 0.02 Classification-F1 0.9239077126577127 on epoch=85
05/22/2022 11:26:48 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.01 on epoch=86
05/22/2022 11:26:51 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 11:26:53 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.00 on epoch=86
05/22/2022 11:26:56 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.01 on epoch=87
05/22/2022 11:26:59 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.01 on epoch=87
05/22/2022 11:27:13 - INFO - __main__ - Global step 2450 Train loss 0.02 Classification-F1 0.9218217863379154 on epoch=87
05/22/2022 11:27:15 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.01 on epoch=87
05/22/2022 11:27:18 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.01 on epoch=88
05/22/2022 11:27:21 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 11:27:23 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 11:27:26 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.02 on epoch=89
05/22/2022 11:27:39 - INFO - __main__ - Global step 2500 Train loss 0.01 Classification-F1 0.9197301544842529 on epoch=89
05/22/2022 11:27:42 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.01 on epoch=89
05/22/2022 11:27:45 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.06 on epoch=89
05/22/2022 11:27:47 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=90
05/22/2022 11:27:50 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.01 on epoch=90
05/22/2022 11:27:52 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.01 on epoch=91
05/22/2022 11:28:06 - INFO - __main__ - Global step 2550 Train loss 0.02 Classification-F1 0.9197374817536108 on epoch=91
05/22/2022 11:28:08 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.01 on epoch=91
05/22/2022 11:28:11 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.01 on epoch=91
05/22/2022 11:28:14 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.02 on epoch=92
05/22/2022 11:28:16 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=92
05/22/2022 11:28:19 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.01 on epoch=92
05/22/2022 11:28:32 - INFO - __main__ - Global step 2600 Train loss 0.01 Classification-F1 0.9239372172033462 on epoch=92
05/22/2022 11:28:35 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.04 on epoch=93
05/22/2022 11:28:37 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.01 on epoch=93
05/22/2022 11:28:40 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.01 on epoch=93
05/22/2022 11:28:42 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 11:28:45 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=94
05/22/2022 11:28:58 - INFO - __main__ - Global step 2650 Train loss 0.02 Classification-F1 0.9239041484202775 on epoch=94
05/22/2022 11:29:01 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=94
05/22/2022 11:29:04 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.01 on epoch=95
05/22/2022 11:29:06 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.02 on epoch=95
05/22/2022 11:29:09 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.03 on epoch=96
05/22/2022 11:29:12 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.02 on epoch=96
05/22/2022 11:29:25 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.9260210592871884 on epoch=96
05/22/2022 11:29:28 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.01 on epoch=96
05/22/2022 11:29:31 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.01 on epoch=97
05/22/2022 11:29:33 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.02 on epoch=97
05/22/2022 11:29:36 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=97
05/22/2022 11:29:39 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.01 on epoch=98
05/22/2022 11:29:52 - INFO - __main__ - Global step 2750 Train loss 0.01 Classification-F1 0.9239041484202775 on epoch=98
05/22/2022 11:29:55 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.07 on epoch=98
05/22/2022 11:29:58 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.07 on epoch=98
05/22/2022 11:30:00 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.00 on epoch=99
05/22/2022 11:30:03 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.00 on epoch=99
05/22/2022 11:30:06 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.02 on epoch=99
05/22/2022 11:30:19 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.9238672673713657 on epoch=99
05/22/2022 11:30:22 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.02 on epoch=100
05/22/2022 11:30:24 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.05 on epoch=100
05/22/2022 11:30:27 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=101
05/22/2022 11:30:30 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=101
05/22/2022 11:30:32 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.02 on epoch=101
05/22/2022 11:30:45 - INFO - __main__ - Global step 2850 Train loss 0.02 Classification-F1 0.9218543926205217 on epoch=101
05/22/2022 11:30:48 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.01 on epoch=102
05/22/2022 11:30:50 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=102
05/22/2022 11:30:53 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=102
05/22/2022 11:30:56 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.05 on epoch=103
05/22/2022 11:30:58 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.01 on epoch=103
05/22/2022 11:31:11 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.9238672673713657 on epoch=103
05/22/2022 11:31:14 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.01 on epoch=103
05/22/2022 11:31:17 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.03 on epoch=104
05/22/2022 11:31:19 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=104
05/22/2022 11:31:22 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.01 on epoch=104
05/22/2022 11:31:24 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=105
05/22/2022 11:31:37 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.9197647032688017 on epoch=105
05/22/2022 11:31:40 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.02 on epoch=105
05/22/2022 11:31:43 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.02 on epoch=106
05/22/2022 11:31:45 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=106
05/22/2022 11:31:48 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 11:31:51 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=107
05/22/2022 11:31:52 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:31:52 - INFO - __main__ - Printing 3 examples
05/22/2022 11:31:52 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 11:31:52 - INFO - __main__ - ['Film']
05/22/2022 11:31:52 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 11:31:52 - INFO - __main__ - ['Film']
05/22/2022 11:31:52 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 11:31:52 - INFO - __main__ - ['Film']
05/22/2022 11:31:52 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:31:52 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:31:53 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 11:31:53 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:31:53 - INFO - __main__ - Printing 3 examples
05/22/2022 11:31:53 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 11:31:53 - INFO - __main__ - ['Film']
05/22/2022 11:31:53 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 11:31:53 - INFO - __main__ - ['Film']
05/22/2022 11:31:53 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 11:31:53 - INFO - __main__ - ['Film']
05/22/2022 11:31:53 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:31:53 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:31:53 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 11:32:04 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.9217866795689377 on epoch=107
05/22/2022 11:32:04 - INFO - __main__ - save last model!
05/22/2022 11:32:04 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 11:32:04 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 11:32:04 - INFO - __main__ - Printing 3 examples
05/22/2022 11:32:04 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 11:32:04 - INFO - __main__ - ['Animal']
05/22/2022 11:32:04 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 11:32:04 - INFO - __main__ - ['Animal']
05/22/2022 11:32:04 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 11:32:04 - INFO - __main__ - ['Village']
05/22/2022 11:32:04 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:32:06 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:32:09 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 11:32:09 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 11:32:10 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 11:32:10 - INFO - __main__ - Starting training!
05/22/2022 11:34:23 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_87_0.4_8_predictions.txt
05/22/2022 11:34:23 - INFO - __main__ - Classification-F1 on test data: 0.7620
05/22/2022 11:34:24 - INFO - __main__ - prefix=dbpedia_14_32_87, lr=0.4, bsz=8, dev_performance=0.9865558756047763, test_performance=0.7619948670600036
05/22/2022 11:34:24 - INFO - __main__ - Running ... prefix=dbpedia_14_32_87, lr=0.3, bsz=8 ...
05/22/2022 11:34:25 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:34:25 - INFO - __main__ - Printing 3 examples
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:34:25 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:34:25 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 11:34:25 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 11:34:25 - INFO - __main__ - Printing 3 examples
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 11:34:25 - INFO - __main__ - ['Film']
05/22/2022 11:34:25 - INFO - __main__ - Tokenizing Input ...
05/22/2022 11:34:26 - INFO - __main__ - Tokenizing Output ...
05/22/2022 11:34:26 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 11:34:42 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 11:34:43 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 11:34:43 - INFO - __main__ - Starting training!
05/22/2022 11:34:46 - INFO - __main__ - Step 10 Global step 10 Train loss 7.60 on epoch=0
05/22/2022 11:34:49 - INFO - __main__ - Step 20 Global step 20 Train loss 5.42 on epoch=0
05/22/2022 11:34:52 - INFO - __main__ - Step 30 Global step 30 Train loss 4.67 on epoch=1
05/22/2022 11:34:54 - INFO - __main__ - Step 40 Global step 40 Train loss 4.12 on epoch=1
05/22/2022 11:34:57 - INFO - __main__ - Step 50 Global step 50 Train loss 3.75 on epoch=1
05/22/2022 11:35:12 - INFO - __main__ - Global step 50 Train loss 5.11 Classification-F1 0.015200044170286657 on epoch=1
05/22/2022 11:35:12 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.015200044170286657 on epoch=1, global_step=50
05/22/2022 11:35:15 - INFO - __main__ - Step 60 Global step 60 Train loss 3.31 on epoch=2
05/22/2022 11:35:18 - INFO - __main__ - Step 70 Global step 70 Train loss 2.96 on epoch=2
05/22/2022 11:35:20 - INFO - __main__ - Step 80 Global step 80 Train loss 3.00 on epoch=2
05/22/2022 11:35:23 - INFO - __main__ - Step 90 Global step 90 Train loss 2.56 on epoch=3
05/22/2022 11:35:26 - INFO - __main__ - Step 100 Global step 100 Train loss 2.35 on epoch=3
05/22/2022 11:35:38 - INFO - __main__ - Global step 100 Train loss 2.84 Classification-F1 0.04411785018100807 on epoch=3
05/22/2022 11:35:38 - INFO - __main__ - Saving model with best Classification-F1: 0.015200044170286657 -> 0.04411785018100807 on epoch=3, global_step=100
05/22/2022 11:35:41 - INFO - __main__ - Step 110 Global step 110 Train loss 2.36 on epoch=3
05/22/2022 11:35:44 - INFO - __main__ - Step 120 Global step 120 Train loss 2.30 on epoch=4
05/22/2022 11:35:46 - INFO - __main__ - Step 130 Global step 130 Train loss 2.03 on epoch=4
05/22/2022 11:35:49 - INFO - __main__ - Step 140 Global step 140 Train loss 1.97 on epoch=4
05/22/2022 11:35:52 - INFO - __main__ - Step 150 Global step 150 Train loss 2.00 on epoch=5
05/22/2022 11:36:03 - INFO - __main__ - Global step 150 Train loss 2.13 Classification-F1 0.08725109835600905 on epoch=5
05/22/2022 11:36:03 - INFO - __main__ - Saving model with best Classification-F1: 0.04411785018100807 -> 0.08725109835600905 on epoch=5, global_step=150
05/22/2022 11:36:06 - INFO - __main__ - Step 160 Global step 160 Train loss 1.67 on epoch=5
05/22/2022 11:36:09 - INFO - __main__ - Step 170 Global step 170 Train loss 1.69 on epoch=6
05/22/2022 11:36:11 - INFO - __main__ - Step 180 Global step 180 Train loss 1.61 on epoch=6
05/22/2022 11:36:14 - INFO - __main__ - Step 190 Global step 190 Train loss 1.38 on epoch=6
05/22/2022 11:36:16 - INFO - __main__ - Step 200 Global step 200 Train loss 1.38 on epoch=7
05/22/2022 11:36:28 - INFO - __main__ - Global step 200 Train loss 1.54 Classification-F1 0.1460526997502027 on epoch=7
05/22/2022 11:36:28 - INFO - __main__ - Saving model with best Classification-F1: 0.08725109835600905 -> 0.1460526997502027 on epoch=7, global_step=200
05/22/2022 11:36:30 - INFO - __main__ - Step 210 Global step 210 Train loss 1.33 on epoch=7
05/22/2022 11:36:33 - INFO - __main__ - Step 220 Global step 220 Train loss 1.33 on epoch=7
05/22/2022 11:36:35 - INFO - __main__ - Step 230 Global step 230 Train loss 1.24 on epoch=8
05/22/2022 11:36:38 - INFO - __main__ - Step 240 Global step 240 Train loss 1.16 on epoch=8
05/22/2022 11:36:41 - INFO - __main__ - Step 250 Global step 250 Train loss 1.04 on epoch=8
05/22/2022 11:36:52 - INFO - __main__ - Global step 250 Train loss 1.22 Classification-F1 0.21202766183237914 on epoch=8
05/22/2022 11:36:52 - INFO - __main__ - Saving model with best Classification-F1: 0.1460526997502027 -> 0.21202766183237914 on epoch=8, global_step=250
05/22/2022 11:36:55 - INFO - __main__ - Step 260 Global step 260 Train loss 1.04 on epoch=9
05/22/2022 11:36:57 - INFO - __main__ - Step 270 Global step 270 Train loss 0.90 on epoch=9
05/22/2022 11:37:00 - INFO - __main__ - Step 280 Global step 280 Train loss 0.83 on epoch=9
05/22/2022 11:37:03 - INFO - __main__ - Step 290 Global step 290 Train loss 0.87 on epoch=10
05/22/2022 11:37:05 - INFO - __main__ - Step 300 Global step 300 Train loss 0.79 on epoch=10
05/22/2022 11:37:17 - INFO - __main__ - Global step 300 Train loss 0.88 Classification-F1 0.2594366736695283 on epoch=10
05/22/2022 11:37:17 - INFO - __main__ - Saving model with best Classification-F1: 0.21202766183237914 -> 0.2594366736695283 on epoch=10, global_step=300
05/22/2022 11:37:20 - INFO - __main__ - Step 310 Global step 310 Train loss 0.72 on epoch=11
05/22/2022 11:37:22 - INFO - __main__ - Step 320 Global step 320 Train loss 0.75 on epoch=11
05/22/2022 11:37:25 - INFO - __main__ - Step 330 Global step 330 Train loss 0.59 on epoch=11
05/22/2022 11:37:27 - INFO - __main__ - Step 340 Global step 340 Train loss 0.61 on epoch=12
05/22/2022 11:37:30 - INFO - __main__ - Step 350 Global step 350 Train loss 0.60 on epoch=12
05/22/2022 11:37:43 - INFO - __main__ - Global step 350 Train loss 0.65 Classification-F1 0.3323362819799876 on epoch=12
05/22/2022 11:37:43 - INFO - __main__ - Saving model with best Classification-F1: 0.2594366736695283 -> 0.3323362819799876 on epoch=12, global_step=350
05/22/2022 11:37:45 - INFO - __main__ - Step 360 Global step 360 Train loss 0.56 on epoch=12
05/22/2022 11:37:48 - INFO - __main__ - Step 370 Global step 370 Train loss 0.56 on epoch=13
05/22/2022 11:37:51 - INFO - __main__ - Step 380 Global step 380 Train loss 0.51 on epoch=13
05/22/2022 11:37:53 - INFO - __main__ - Step 390 Global step 390 Train loss 0.49 on epoch=13
05/22/2022 11:37:56 - INFO - __main__ - Step 400 Global step 400 Train loss 0.48 on epoch=14
05/22/2022 11:38:09 - INFO - __main__ - Global step 400 Train loss 0.52 Classification-F1 0.43690852625151705 on epoch=14
05/22/2022 11:38:09 - INFO - __main__ - Saving model with best Classification-F1: 0.3323362819799876 -> 0.43690852625151705 on epoch=14, global_step=400
05/22/2022 11:38:12 - INFO - __main__ - Step 410 Global step 410 Train loss 0.49 on epoch=14
05/22/2022 11:38:14 - INFO - __main__ - Step 420 Global step 420 Train loss 0.45 on epoch=14
05/22/2022 11:38:17 - INFO - __main__ - Step 430 Global step 430 Train loss 0.38 on epoch=15
05/22/2022 11:38:20 - INFO - __main__ - Step 440 Global step 440 Train loss 0.37 on epoch=15
05/22/2022 11:38:22 - INFO - __main__ - Step 450 Global step 450 Train loss 0.37 on epoch=16
05/22/2022 11:38:35 - INFO - __main__ - Global step 450 Train loss 0.41 Classification-F1 0.38489267929880067 on epoch=16
05/22/2022 11:38:38 - INFO - __main__ - Step 460 Global step 460 Train loss 0.43 on epoch=16
05/22/2022 11:38:40 - INFO - __main__ - Step 470 Global step 470 Train loss 0.35 on epoch=16
05/22/2022 11:38:43 - INFO - __main__ - Step 480 Global step 480 Train loss 0.37 on epoch=17
05/22/2022 11:38:46 - INFO - __main__ - Step 490 Global step 490 Train loss 0.46 on epoch=17
05/22/2022 11:38:48 - INFO - __main__ - Step 500 Global step 500 Train loss 0.32 on epoch=17
05/22/2022 11:39:01 - INFO - __main__ - Global step 500 Train loss 0.39 Classification-F1 0.49192621653545093 on epoch=17
05/22/2022 11:39:01 - INFO - __main__ - Saving model with best Classification-F1: 0.43690852625151705 -> 0.49192621653545093 on epoch=17, global_step=500
05/22/2022 11:39:03 - INFO - __main__ - Step 510 Global step 510 Train loss 0.37 on epoch=18
05/22/2022 11:39:06 - INFO - __main__ - Step 520 Global step 520 Train loss 0.31 on epoch=18
05/22/2022 11:39:09 - INFO - __main__ - Step 530 Global step 530 Train loss 0.31 on epoch=18
05/22/2022 11:39:11 - INFO - __main__ - Step 540 Global step 540 Train loss 0.32 on epoch=19
05/22/2022 11:39:14 - INFO - __main__ - Step 550 Global step 550 Train loss 0.23 on epoch=19
05/22/2022 11:39:27 - INFO - __main__ - Global step 550 Train loss 0.31 Classification-F1 0.5518815116537774 on epoch=19
05/22/2022 11:39:27 - INFO - __main__ - Saving model with best Classification-F1: 0.49192621653545093 -> 0.5518815116537774 on epoch=19, global_step=550
05/22/2022 11:39:29 - INFO - __main__ - Step 560 Global step 560 Train loss 0.23 on epoch=19
05/22/2022 11:39:32 - INFO - __main__ - Step 570 Global step 570 Train loss 0.32 on epoch=20
05/22/2022 11:39:35 - INFO - __main__ - Step 580 Global step 580 Train loss 0.24 on epoch=20
05/22/2022 11:39:37 - INFO - __main__ - Step 590 Global step 590 Train loss 0.24 on epoch=21
05/22/2022 11:39:40 - INFO - __main__ - Step 600 Global step 600 Train loss 0.34 on epoch=21
05/22/2022 11:39:52 - INFO - __main__ - Global step 600 Train loss 0.27 Classification-F1 0.5392930274051205 on epoch=21
05/22/2022 11:39:55 - INFO - __main__ - Step 610 Global step 610 Train loss 0.25 on epoch=21
05/22/2022 11:39:58 - INFO - __main__ - Step 620 Global step 620 Train loss 0.26 on epoch=22
05/22/2022 11:40:00 - INFO - __main__ - Step 630 Global step 630 Train loss 0.26 on epoch=22
05/22/2022 11:40:03 - INFO - __main__ - Step 640 Global step 640 Train loss 0.27 on epoch=22
05/22/2022 11:40:06 - INFO - __main__ - Step 650 Global step 650 Train loss 0.29 on epoch=23
05/22/2022 11:40:19 - INFO - __main__ - Global step 650 Train loss 0.27 Classification-F1 0.5620686995390418 on epoch=23
05/22/2022 11:40:19 - INFO - __main__ - Saving model with best Classification-F1: 0.5518815116537774 -> 0.5620686995390418 on epoch=23, global_step=650
05/22/2022 11:40:21 - INFO - __main__ - Step 660 Global step 660 Train loss 0.26 on epoch=23
05/22/2022 11:40:24 - INFO - __main__ - Step 670 Global step 670 Train loss 0.24 on epoch=23
05/22/2022 11:40:27 - INFO - __main__ - Step 680 Global step 680 Train loss 0.24 on epoch=24
05/22/2022 11:40:29 - INFO - __main__ - Step 690 Global step 690 Train loss 0.26 on epoch=24
05/22/2022 11:40:32 - INFO - __main__ - Step 700 Global step 700 Train loss 0.20 on epoch=24
05/22/2022 11:40:45 - INFO - __main__ - Global step 700 Train loss 0.24 Classification-F1 0.5975300291883234 on epoch=24
05/22/2022 11:40:45 - INFO - __main__ - Saving model with best Classification-F1: 0.5620686995390418 -> 0.5975300291883234 on epoch=24, global_step=700
05/22/2022 11:40:48 - INFO - __main__ - Step 710 Global step 710 Train loss 0.25 on epoch=25
05/22/2022 11:40:50 - INFO - __main__ - Step 720 Global step 720 Train loss 0.22 on epoch=25
05/22/2022 11:40:53 - INFO - __main__ - Step 730 Global step 730 Train loss 0.16 on epoch=26
05/22/2022 11:40:55 - INFO - __main__ - Step 740 Global step 740 Train loss 0.19 on epoch=26
05/22/2022 11:40:58 - INFO - __main__ - Step 750 Global step 750 Train loss 0.18 on epoch=26
05/22/2022 11:41:11 - INFO - __main__ - Global step 750 Train loss 0.20 Classification-F1 0.6620220375738203 on epoch=26
05/22/2022 11:41:11 - INFO - __main__ - Saving model with best Classification-F1: 0.5975300291883234 -> 0.6620220375738203 on epoch=26, global_step=750
05/22/2022 11:41:14 - INFO - __main__ - Step 760 Global step 760 Train loss 0.20 on epoch=27
05/22/2022 11:41:16 - INFO - __main__ - Step 770 Global step 770 Train loss 0.15 on epoch=27
05/22/2022 11:41:19 - INFO - __main__ - Step 780 Global step 780 Train loss 0.18 on epoch=27
05/22/2022 11:41:22 - INFO - __main__ - Step 790 Global step 790 Train loss 0.17 on epoch=28
05/22/2022 11:41:24 - INFO - __main__ - Step 800 Global step 800 Train loss 0.18 on epoch=28
05/22/2022 11:41:37 - INFO - __main__ - Global step 800 Train loss 0.18 Classification-F1 0.7099381763530829 on epoch=28
05/22/2022 11:41:37 - INFO - __main__ - Saving model with best Classification-F1: 0.6620220375738203 -> 0.7099381763530829 on epoch=28, global_step=800
05/22/2022 11:41:39 - INFO - __main__ - Step 810 Global step 810 Train loss 0.22 on epoch=28
05/22/2022 11:41:42 - INFO - __main__ - Step 820 Global step 820 Train loss 0.19 on epoch=29
05/22/2022 11:41:44 - INFO - __main__ - Step 830 Global step 830 Train loss 0.18 on epoch=29
05/22/2022 11:41:47 - INFO - __main__ - Step 840 Global step 840 Train loss 0.23 on epoch=29
05/22/2022 11:41:50 - INFO - __main__ - Step 850 Global step 850 Train loss 0.20 on epoch=30
05/22/2022 11:42:02 - INFO - __main__ - Global step 850 Train loss 0.20 Classification-F1 0.6542681002852476 on epoch=30
05/22/2022 11:42:05 - INFO - __main__ - Step 860 Global step 860 Train loss 0.20 on epoch=30
05/22/2022 11:42:08 - INFO - __main__ - Step 870 Global step 870 Train loss 0.14 on epoch=31
05/22/2022 11:42:10 - INFO - __main__ - Step 880 Global step 880 Train loss 0.18 on epoch=31
05/22/2022 11:42:13 - INFO - __main__ - Step 890 Global step 890 Train loss 0.15 on epoch=31
05/22/2022 11:42:16 - INFO - __main__ - Step 900 Global step 900 Train loss 0.15 on epoch=32
05/22/2022 11:42:28 - INFO - __main__ - Global step 900 Train loss 0.16 Classification-F1 0.6193063482597029 on epoch=32
05/22/2022 11:42:31 - INFO - __main__ - Step 910 Global step 910 Train loss 0.16 on epoch=32
05/22/2022 11:42:34 - INFO - __main__ - Step 920 Global step 920 Train loss 0.12 on epoch=32
05/22/2022 11:42:36 - INFO - __main__ - Step 930 Global step 930 Train loss 0.16 on epoch=33
05/22/2022 11:42:39 - INFO - __main__ - Step 940 Global step 940 Train loss 0.10 on epoch=33
05/22/2022 11:42:42 - INFO - __main__ - Step 950 Global step 950 Train loss 0.11 on epoch=33
05/22/2022 11:42:54 - INFO - __main__ - Global step 950 Train loss 0.13 Classification-F1 0.7671417080776238 on epoch=33
05/22/2022 11:42:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7099381763530829 -> 0.7671417080776238 on epoch=33, global_step=950
05/22/2022 11:42:57 - INFO - __main__ - Step 960 Global step 960 Train loss 0.13 on epoch=34
05/22/2022 11:43:00 - INFO - __main__ - Step 970 Global step 970 Train loss 0.18 on epoch=34
05/22/2022 11:43:02 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=34
05/22/2022 11:43:05 - INFO - __main__ - Step 990 Global step 990 Train loss 0.16 on epoch=35
05/22/2022 11:43:08 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.09 on epoch=35
05/22/2022 11:43:21 - INFO - __main__ - Global step 1000 Train loss 0.16 Classification-F1 0.7396367495039222 on epoch=35
05/22/2022 11:43:23 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.13 on epoch=36
05/22/2022 11:43:26 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.12 on epoch=36
05/22/2022 11:43:28 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.11 on epoch=36
05/22/2022 11:43:31 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.16 on epoch=37
05/22/2022 11:43:34 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.11 on epoch=37
05/22/2022 11:43:47 - INFO - __main__ - Global step 1050 Train loss 0.13 Classification-F1 0.6707004777318248 on epoch=37
05/22/2022 11:43:50 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.09 on epoch=37
05/22/2022 11:43:52 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.15 on epoch=38
05/22/2022 11:43:55 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.07 on epoch=38
05/22/2022 11:43:57 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.16 on epoch=38
05/22/2022 11:44:00 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.16 on epoch=39
05/22/2022 11:44:13 - INFO - __main__ - Global step 1100 Train loss 0.13 Classification-F1 0.7073285100502843 on epoch=39
05/22/2022 11:44:16 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.08 on epoch=39
05/22/2022 11:44:19 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.09 on epoch=39
05/22/2022 11:44:21 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.11 on epoch=40
05/22/2022 11:44:24 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.15 on epoch=40
05/22/2022 11:44:26 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.14 on epoch=41
05/22/2022 11:44:39 - INFO - __main__ - Global step 1150 Train loss 0.11 Classification-F1 0.7639928002533256 on epoch=41
05/22/2022 11:44:42 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.11 on epoch=41
05/22/2022 11:44:44 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.13 on epoch=41
05/22/2022 11:44:47 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.09 on epoch=42
05/22/2022 11:44:50 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.10 on epoch=42
05/22/2022 11:44:52 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.11 on epoch=42
05/22/2022 11:45:05 - INFO - __main__ - Global step 1200 Train loss 0.11 Classification-F1 0.6809212413023293 on epoch=42
05/22/2022 11:45:07 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.13 on epoch=43
05/22/2022 11:45:10 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.10 on epoch=43
05/22/2022 11:45:12 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.10 on epoch=43
05/22/2022 11:45:15 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.09 on epoch=44
05/22/2022 11:45:18 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.08 on epoch=44
05/22/2022 11:45:30 - INFO - __main__ - Global step 1250 Train loss 0.10 Classification-F1 0.6674009815551304 on epoch=44
05/22/2022 11:45:33 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.15 on epoch=44
05/22/2022 11:45:35 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.16 on epoch=45
05/22/2022 11:45:38 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.17 on epoch=45
05/22/2022 11:45:40 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.09 on epoch=46
05/22/2022 11:45:43 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.07 on epoch=46
05/22/2022 11:45:55 - INFO - __main__ - Global step 1300 Train loss 0.13 Classification-F1 0.6728407425089722 on epoch=46
05/22/2022 11:45:58 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.07 on epoch=46
05/22/2022 11:46:01 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.11 on epoch=47
05/22/2022 11:46:03 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.11 on epoch=47
05/22/2022 11:46:06 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.05 on epoch=47
05/22/2022 11:46:09 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.11 on epoch=48
05/22/2022 11:46:21 - INFO - __main__ - Global step 1350 Train loss 0.09 Classification-F1 0.6779975776035746 on epoch=48
05/22/2022 11:46:24 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.07 on epoch=48
05/22/2022 11:46:26 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.07 on epoch=48
05/22/2022 11:46:29 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.11 on epoch=49
05/22/2022 11:46:32 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.07 on epoch=49
05/22/2022 11:46:34 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.09 on epoch=49
05/22/2022 11:46:47 - INFO - __main__ - Global step 1400 Train loss 0.08 Classification-F1 0.6698853011973667 on epoch=49
05/22/2022 11:46:50 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.11 on epoch=50
05/22/2022 11:46:52 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.09 on epoch=50
05/22/2022 11:46:55 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.08 on epoch=51
05/22/2022 11:46:57 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.08 on epoch=51
05/22/2022 11:47:00 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.07 on epoch=51
05/22/2022 11:47:13 - INFO - __main__ - Global step 1450 Train loss 0.08 Classification-F1 0.6770584852811873 on epoch=51
05/22/2022 11:47:15 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.07 on epoch=52
05/22/2022 11:47:18 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.10 on epoch=52
05/22/2022 11:47:20 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.05 on epoch=52
05/22/2022 11:47:23 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.05 on epoch=53
05/22/2022 11:47:26 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.06 on epoch=53
05/22/2022 11:47:38 - INFO - __main__ - Global step 1500 Train loss 0.07 Classification-F1 0.7094737907562145 on epoch=53
05/22/2022 11:47:41 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.07 on epoch=53
05/22/2022 11:47:44 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.05 on epoch=54
05/22/2022 11:47:46 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.04 on epoch=54
05/22/2022 11:47:49 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.16 on epoch=54
05/22/2022 11:47:51 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.05 on epoch=55
05/22/2022 11:48:04 - INFO - __main__ - Global step 1550 Train loss 0.08 Classification-F1 0.7282746549547625 on epoch=55
05/22/2022 11:48:07 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.07 on epoch=55
05/22/2022 11:48:09 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.04 on epoch=56
05/22/2022 11:48:12 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.08 on epoch=56
05/22/2022 11:48:15 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=56
05/22/2022 11:48:17 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.10 on epoch=57
05/22/2022 11:48:30 - INFO - __main__ - Global step 1600 Train loss 0.07 Classification-F1 0.719052704066145 on epoch=57
05/22/2022 11:48:32 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.06 on epoch=57
05/22/2022 11:48:35 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.06 on epoch=57
05/22/2022 11:48:38 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.05 on epoch=58
05/22/2022 11:48:40 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.12 on epoch=58
05/22/2022 11:48:43 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.06 on epoch=58
05/22/2022 11:48:55 - INFO - __main__ - Global step 1650 Train loss 0.07 Classification-F1 0.7892502556986521 on epoch=58
05/22/2022 11:48:55 - INFO - __main__ - Saving model with best Classification-F1: 0.7671417080776238 -> 0.7892502556986521 on epoch=58, global_step=1650
05/22/2022 11:48:58 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.04 on epoch=59
05/22/2022 11:49:00 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.04 on epoch=59
05/22/2022 11:49:03 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.05 on epoch=59
05/22/2022 11:49:06 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.04 on epoch=60
05/22/2022 11:49:08 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.04 on epoch=60
05/22/2022 11:49:21 - INFO - __main__ - Global step 1700 Train loss 0.04 Classification-F1 0.7803735892233856 on epoch=60
05/22/2022 11:49:23 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.07 on epoch=61
05/22/2022 11:49:26 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.04 on epoch=61
05/22/2022 11:49:29 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.04 on epoch=61
05/22/2022 11:49:31 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.05 on epoch=62
05/22/2022 11:49:34 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.04 on epoch=62
05/22/2022 11:49:46 - INFO - __main__ - Global step 1750 Train loss 0.05 Classification-F1 0.729367736050988 on epoch=62
05/22/2022 11:49:49 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.04 on epoch=62
05/22/2022 11:49:52 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.05 on epoch=63
05/22/2022 11:49:54 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.04 on epoch=63
05/22/2022 11:49:57 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.03 on epoch=63
05/22/2022 11:50:00 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=64
05/22/2022 11:50:12 - INFO - __main__ - Global step 1800 Train loss 0.05 Classification-F1 0.7116712835391845 on epoch=64
05/22/2022 11:50:15 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.04 on epoch=64
05/22/2022 11:50:17 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.04 on epoch=64
05/22/2022 11:50:20 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.07 on epoch=65
05/22/2022 11:50:23 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.04 on epoch=65
05/22/2022 11:50:25 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.05 on epoch=66
05/22/2022 11:50:38 - INFO - __main__ - Global step 1850 Train loss 0.05 Classification-F1 0.7006705968628996 on epoch=66
05/22/2022 11:50:41 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.04 on epoch=66
05/22/2022 11:50:43 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.04 on epoch=66
05/22/2022 11:50:46 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.05 on epoch=67
05/22/2022 11:50:49 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.05 on epoch=67
05/22/2022 11:50:51 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.03 on epoch=67
05/22/2022 11:51:04 - INFO - __main__ - Global step 1900 Train loss 0.04 Classification-F1 0.7333123824187768 on epoch=67
05/22/2022 11:51:07 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.05 on epoch=68
05/22/2022 11:51:09 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.04 on epoch=68
05/22/2022 11:51:12 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.03 on epoch=68
05/22/2022 11:51:14 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.03 on epoch=69
05/22/2022 11:51:17 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.06 on epoch=69
05/22/2022 11:51:30 - INFO - __main__ - Global step 1950 Train loss 0.04 Classification-F1 0.6620966835583771 on epoch=69
05/22/2022 11:51:32 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.07 on epoch=69
05/22/2022 11:51:35 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.04 on epoch=70
05/22/2022 11:51:37 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.05 on epoch=70
05/22/2022 11:51:40 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.03 on epoch=71
05/22/2022 11:51:43 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.04 on epoch=71
05/22/2022 11:51:55 - INFO - __main__ - Global step 2000 Train loss 0.05 Classification-F1 0.6769348045379215 on epoch=71
05/22/2022 11:51:58 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.04 on epoch=71
05/22/2022 11:52:00 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=72
05/22/2022 11:52:03 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.05 on epoch=72
05/22/2022 11:52:05 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.04 on epoch=72
05/22/2022 11:52:08 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.07 on epoch=73
05/22/2022 11:52:21 - INFO - __main__ - Global step 2050 Train loss 0.05 Classification-F1 0.6937818810662041 on epoch=73
05/22/2022 11:52:24 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.04 on epoch=73
05/22/2022 11:52:26 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=73
05/22/2022 11:52:29 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.05 on epoch=74
05/22/2022 11:52:31 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.03 on epoch=74
05/22/2022 11:52:34 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.05 on epoch=74
05/22/2022 11:52:47 - INFO - __main__ - Global step 2100 Train loss 0.04 Classification-F1 0.6836365175988468 on epoch=74
05/22/2022 11:52:49 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.04 on epoch=75
05/22/2022 11:52:52 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.04 on epoch=75
05/22/2022 11:52:55 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.04 on epoch=76
05/22/2022 11:52:57 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.03 on epoch=76
05/22/2022 11:53:00 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.04 on epoch=76
05/22/2022 11:53:13 - INFO - __main__ - Global step 2150 Train loss 0.04 Classification-F1 0.7405532631609907 on epoch=76
05/22/2022 11:53:15 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.04 on epoch=77
05/22/2022 11:53:18 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.03 on epoch=77
05/22/2022 11:53:20 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.02 on epoch=77
05/22/2022 11:53:23 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.03 on epoch=78
05/22/2022 11:53:26 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.02 on epoch=78
05/22/2022 11:53:39 - INFO - __main__ - Global step 2200 Train loss 0.03 Classification-F1 0.7349095241839183 on epoch=78
05/22/2022 11:53:41 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.02 on epoch=78
05/22/2022 11:53:44 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.03 on epoch=79
05/22/2022 11:53:46 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.05 on epoch=79
05/22/2022 11:53:49 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.02 on epoch=79
05/22/2022 11:53:52 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.04 on epoch=80
05/22/2022 11:54:04 - INFO - __main__ - Global step 2250 Train loss 0.03 Classification-F1 0.7301896323672524 on epoch=80
05/22/2022 11:54:07 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=80
05/22/2022 11:54:10 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.02 on epoch=81
05/22/2022 11:54:12 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.05 on epoch=81
05/22/2022 11:54:15 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.01 on epoch=81
05/22/2022 11:54:17 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.04 on epoch=82
05/22/2022 11:54:30 - INFO - __main__ - Global step 2300 Train loss 0.03 Classification-F1 0.7896177432189312 on epoch=82
05/22/2022 11:54:30 - INFO - __main__ - Saving model with best Classification-F1: 0.7892502556986521 -> 0.7896177432189312 on epoch=82, global_step=2300
05/22/2022 11:54:33 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.03 on epoch=82
05/22/2022 11:54:35 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.02 on epoch=82
05/22/2022 11:54:38 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.02 on epoch=83
05/22/2022 11:54:41 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.02 on epoch=83
05/22/2022 11:54:43 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=83
05/22/2022 11:54:56 - INFO - __main__ - Global step 2350 Train loss 0.02 Classification-F1 0.6305901066845768 on epoch=83
05/22/2022 11:54:58 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.03 on epoch=84
05/22/2022 11:55:01 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.03 on epoch=84
05/22/2022 11:55:04 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.05 on epoch=84
05/22/2022 11:55:06 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.02 on epoch=85
05/22/2022 11:55:09 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.01 on epoch=85
05/22/2022 11:55:22 - INFO - __main__ - Global step 2400 Train loss 0.03 Classification-F1 0.7805437953483676 on epoch=85
05/22/2022 11:55:25 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.04 on epoch=86
05/22/2022 11:55:27 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.05 on epoch=86
05/22/2022 11:55:30 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.02 on epoch=86
05/22/2022 11:55:32 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=87
05/22/2022 11:55:35 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.04 on epoch=87
05/22/2022 11:55:48 - INFO - __main__ - Global step 2450 Train loss 0.04 Classification-F1 0.738388692152133 on epoch=87
05/22/2022 11:55:50 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.03 on epoch=87
05/22/2022 11:55:53 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.02 on epoch=88
05/22/2022 11:55:56 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.02 on epoch=88
05/22/2022 11:55:58 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.01 on epoch=88
05/22/2022 11:56:01 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.06 on epoch=89
05/22/2022 11:56:13 - INFO - __main__ - Global step 2500 Train loss 0.03 Classification-F1 0.7412879064015728 on epoch=89
05/22/2022 11:56:16 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.02 on epoch=89
05/22/2022 11:56:19 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.05 on epoch=89
05/22/2022 11:56:21 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.02 on epoch=90
05/22/2022 11:56:24 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.02 on epoch=90
05/22/2022 11:56:27 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.03 on epoch=91
05/22/2022 11:56:39 - INFO - __main__ - Global step 2550 Train loss 0.03 Classification-F1 0.705658084605453 on epoch=91
05/22/2022 11:56:42 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.04 on epoch=91
05/22/2022 11:56:44 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.03 on epoch=91
05/22/2022 11:56:47 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.03 on epoch=92
05/22/2022 11:56:50 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.02 on epoch=92
05/22/2022 11:56:52 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.02 on epoch=92
05/22/2022 11:57:05 - INFO - __main__ - Global step 2600 Train loss 0.03 Classification-F1 0.7543934383517716 on epoch=92
05/22/2022 11:57:08 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=93
05/22/2022 11:57:10 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.02 on epoch=93
05/22/2022 11:57:13 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=93
05/22/2022 11:57:15 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.01 on epoch=94
05/22/2022 11:57:18 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.02 on epoch=94
05/22/2022 11:57:31 - INFO - __main__ - Global step 2650 Train loss 0.03 Classification-F1 0.7553350534869352 on epoch=94
05/22/2022 11:57:33 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.02 on epoch=94
05/22/2022 11:57:36 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.02 on epoch=95
05/22/2022 11:57:38 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.03 on epoch=95
05/22/2022 11:57:41 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.02 on epoch=96
05/22/2022 11:57:44 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.01 on epoch=96
05/22/2022 11:57:56 - INFO - __main__ - Global step 2700 Train loss 0.02 Classification-F1 0.7171842958325363 on epoch=96
05/22/2022 11:57:59 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.02 on epoch=96
05/22/2022 11:58:01 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.04 on epoch=97
05/22/2022 11:58:04 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=97
05/22/2022 11:58:07 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.01 on epoch=97
05/22/2022 11:58:09 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.09 on epoch=98
05/22/2022 11:58:22 - INFO - __main__ - Global step 2750 Train loss 0.04 Classification-F1 0.763679450776225 on epoch=98
05/22/2022 11:58:25 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.04 on epoch=98
05/22/2022 11:58:27 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.02 on epoch=98
05/22/2022 11:58:30 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.03 on epoch=99
05/22/2022 11:58:33 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.02 on epoch=99
05/22/2022 11:58:35 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=99
05/22/2022 11:58:48 - INFO - __main__ - Global step 2800 Train loss 0.03 Classification-F1 0.6767716266708202 on epoch=99
05/22/2022 11:58:50 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.06 on epoch=100
05/22/2022 11:58:53 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.03 on epoch=100
05/22/2022 11:58:56 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.01 on epoch=101
05/22/2022 11:58:58 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.01 on epoch=101
05/22/2022 11:59:01 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.04 on epoch=101
05/22/2022 11:59:13 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7122403183260048 on epoch=101
05/22/2022 11:59:16 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.02 on epoch=102
05/22/2022 11:59:19 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.01 on epoch=102
05/22/2022 11:59:21 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.02 on epoch=102
05/22/2022 11:59:24 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 11:59:26 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.02 on epoch=103
05/22/2022 11:59:39 - INFO - __main__ - Global step 2900 Train loss 0.02 Classification-F1 0.7206116782605279 on epoch=103
05/22/2022 11:59:41 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.02 on epoch=103
05/22/2022 11:59:44 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.04 on epoch=104
05/22/2022 11:59:47 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.02 on epoch=104
05/22/2022 11:59:49 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.02 on epoch=104
05/22/2022 11:59:52 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.01 on epoch=105
05/22/2022 12:00:04 - INFO - __main__ - Global step 2950 Train loss 0.02 Classification-F1 0.6749550686487161 on epoch=105
05/22/2022 12:00:07 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.01 on epoch=105
05/22/2022 12:00:10 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.01 on epoch=106
05/22/2022 12:00:12 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.03 on epoch=106
05/22/2022 12:00:15 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.01 on epoch=106
05/22/2022 12:00:17 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.01 on epoch=107
05/22/2022 12:00:19 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 12:00:19 - INFO - __main__ - Printing 3 examples
05/22/2022 12:00:19 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 12:00:19 - INFO - __main__ - ['Film']
05/22/2022 12:00:19 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 12:00:19 - INFO - __main__ - ['Film']
05/22/2022 12:00:19 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 12:00:19 - INFO - __main__ - ['Film']
05/22/2022 12:00:19 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:00:19 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:00:20 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 12:00:20 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 12:00:20 - INFO - __main__ - Printing 3 examples
05/22/2022 12:00:20 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 12:00:20 - INFO - __main__ - ['Film']
05/22/2022 12:00:20 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 12:00:20 - INFO - __main__ - ['Film']
05/22/2022 12:00:20 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 12:00:20 - INFO - __main__ - ['Film']
05/22/2022 12:00:20 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:00:20 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:00:20 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 12:00:30 - INFO - __main__ - Global step 3000 Train loss 0.02 Classification-F1 0.723239915740851 on epoch=107
05/22/2022 12:00:30 - INFO - __main__ - save last model!
05/22/2022 12:00:30 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 12:00:30 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 12:00:30 - INFO - __main__ - Printing 3 examples
05/22/2022 12:00:30 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 12:00:30 - INFO - __main__ - ['Animal']
05/22/2022 12:00:30 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 12:00:30 - INFO - __main__ - ['Animal']
05/22/2022 12:00:30 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 12:00:30 - INFO - __main__ - ['Village']
05/22/2022 12:00:30 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:00:32 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:00:35 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 12:00:39 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 12:00:39 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 12:00:39 - INFO - __main__ - Starting training!
05/22/2022 12:02:42 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_87_0.3_8_predictions.txt
05/22/2022 12:02:42 - INFO - __main__ - Classification-F1 on test data: 0.5020
05/22/2022 12:02:42 - INFO - __main__ - prefix=dbpedia_14_32_87, lr=0.3, bsz=8, dev_performance=0.7896177432189312, test_performance=0.5019654705870729
05/22/2022 12:02:42 - INFO - __main__ - Running ... prefix=dbpedia_14_32_87, lr=0.2, bsz=8 ...
05/22/2022 12:02:43 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 12:02:43 - INFO - __main__ - Printing 3 examples
05/22/2022 12:02:43 - INFO - __main__ -  [dbpedia_14] Aibō The Movie (相棒 -劇場版- 絶体絶命! 42.195km 東京ビッグシティマラソン) is a 2008 Japanese film directed by Seiji Izumi and based on the television series Aibō.
05/22/2022 12:02:43 - INFO - __main__ - ['Film']
05/22/2022 12:02:43 - INFO - __main__ -  [dbpedia_14] Time Traveller: The Girl Who Leapt Through Time originally released as Toki o Kakeru Shōjo (時をかける少女 lit. The Girl Who Runs Through Time) is a 2010 Japanese science fiction film directed by Masaaki Taniguchi and written by Tomoe Kanno. It is the fourth film based on the novel The Girl Who Leapt Through Time and is a sequel to the original 1983 film adaptation. The film stars Riisa Naka as the protagonist Akari Yoshiyama daughter of the original story's protagonist Kazuko Yoshiyama.
05/22/2022 12:02:43 - INFO - __main__ - ['Film']
05/22/2022 12:02:43 - INFO - __main__ -  [dbpedia_14] Judy of Rogue's Harbor was a 1920 silent drama film directed by William Desmond Taylor and starring Mary Miles Minter. The film is based on the novel of the same name by Grace Miller White. It was produced by Famous Players-Lasky and distributed through Realart and Paramount Pictures.As with many of Minter's films Judy of Rogue's Harbor is considered lost.
05/22/2022 12:02:43 - INFO - __main__ - ['Film']
05/22/2022 12:02:43 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:02:43 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:02:44 - INFO - __main__ - Loaded 448 examples from train data
05/22/2022 12:02:44 - INFO - __main__ - Start tokenizing ... 448 instances
05/22/2022 12:02:44 - INFO - __main__ - Printing 3 examples
05/22/2022 12:02:44 - INFO - __main__ -  [dbpedia_14] Bawyrym (Kazakh/Russian: Бауырым) is a 2008 Kazakh film released in 2008.
05/22/2022 12:02:44 - INFO - __main__ - ['Film']
05/22/2022 12:02:44 - INFO - __main__ -  [dbpedia_14] Monisha En Monalisa is a Tamil film released in 1999 directed and produced by T. Rajendar. His son Silambarasan starred in a cameo role in the film whilst debutants Ramanakanth and Mumtaj played the lead roles. The film received primarily poor reviews upon release with one reviewer labelling it the low point of Tamil cinema.
05/22/2022 12:02:44 - INFO - __main__ - ['Film']
05/22/2022 12:02:44 - INFO - __main__ -  [dbpedia_14] Hollywood or Bust is a 1956 film comedy starring the team of Dean Martin and Jerry Lewis. The picture was filmed from April 16 to June 19 1956 and released on December 6 1956 by Paramount Pictures almost five months after the Martin and Lewis partnership split up.
05/22/2022 12:02:44 - INFO - __main__ - ['Film']
05/22/2022 12:02:44 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:02:44 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:02:45 - INFO - __main__ - Loaded 448 examples from dev data
05/22/2022 12:03:00 - INFO - __main__ - load prompt embedding from ckpt
05/22/2022 12:03:01 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 746.97M parameters
05/22/2022 12:03:01 - INFO - __main__ - Starting training!
05/22/2022 12:03:05 - INFO - __main__ - Step 10 Global step 10 Train loss 7.55 on epoch=0
05/22/2022 12:03:07 - INFO - __main__ - Step 20 Global step 20 Train loss 6.15 on epoch=0
05/22/2022 12:03:10 - INFO - __main__ - Step 30 Global step 30 Train loss 5.26 on epoch=1
05/22/2022 12:03:13 - INFO - __main__ - Step 40 Global step 40 Train loss 4.72 on epoch=1
05/22/2022 12:03:15 - INFO - __main__ - Step 50 Global step 50 Train loss 4.49 on epoch=1
05/22/2022 12:03:29 - INFO - __main__ - Global step 50 Train loss 5.63 Classification-F1 0.012835952685576746 on epoch=1
05/22/2022 12:03:29 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.012835952685576746 on epoch=1, global_step=50
05/22/2022 12:03:32 - INFO - __main__ - Step 60 Global step 60 Train loss 3.89 on epoch=2
05/22/2022 12:03:35 - INFO - __main__ - Step 70 Global step 70 Train loss 3.68 on epoch=2
05/22/2022 12:03:37 - INFO - __main__ - Step 80 Global step 80 Train loss 3.77 on epoch=2
05/22/2022 12:03:40 - INFO - __main__ - Step 90 Global step 90 Train loss 3.37 on epoch=3
05/22/2022 12:03:42 - INFO - __main__ - Step 100 Global step 100 Train loss 2.99 on epoch=3
05/22/2022 12:03:56 - INFO - __main__ - Global step 100 Train loss 3.54 Classification-F1 0.025796300256102394 on epoch=3
05/22/2022 12:03:56 - INFO - __main__ - Saving model with best Classification-F1: 0.012835952685576746 -> 0.025796300256102394 on epoch=3, global_step=100
05/22/2022 12:03:58 - INFO - __main__ - Step 110 Global step 110 Train loss 3.10 on epoch=3
05/22/2022 12:04:01 - INFO - __main__ - Step 120 Global step 120 Train loss 2.87 on epoch=4
05/22/2022 12:04:04 - INFO - __main__ - Step 130 Global step 130 Train loss 2.65 on epoch=4
05/22/2022 12:04:06 - INFO - __main__ - Step 140 Global step 140 Train loss 2.49 on epoch=4
05/22/2022 12:04:09 - INFO - __main__ - Step 150 Global step 150 Train loss 2.67 on epoch=5
05/22/2022 12:04:22 - INFO - __main__ - Global step 150 Train loss 2.76 Classification-F1 0.0442732234837498 on epoch=5
05/22/2022 12:04:22 - INFO - __main__ - Saving model with best Classification-F1: 0.025796300256102394 -> 0.0442732234837498 on epoch=5, global_step=150
05/22/2022 12:04:25 - INFO - __main__ - Step 160 Global step 160 Train loss 2.26 on epoch=5
05/22/2022 12:04:27 - INFO - __main__ - Step 170 Global step 170 Train loss 2.35 on epoch=6
05/22/2022 12:04:30 - INFO - __main__ - Step 180 Global step 180 Train loss 2.15 on epoch=6
05/22/2022 12:04:32 - INFO - __main__ - Step 190 Global step 190 Train loss 2.01 on epoch=6
05/22/2022 12:04:35 - INFO - __main__ - Step 200 Global step 200 Train loss 1.83 on epoch=7
05/22/2022 12:04:47 - INFO - __main__ - Global step 200 Train loss 2.12 Classification-F1 0.06982827351015863 on epoch=7
05/22/2022 12:04:47 - INFO - __main__ - Saving model with best Classification-F1: 0.0442732234837498 -> 0.06982827351015863 on epoch=7, global_step=200
05/22/2022 12:04:50 - INFO - __main__ - Step 210 Global step 210 Train loss 2.00 on epoch=7
05/22/2022 12:04:52 - INFO - __main__ - Step 220 Global step 220 Train loss 1.89 on epoch=7
05/22/2022 12:04:55 - INFO - __main__ - Step 230 Global step 230 Train loss 1.74 on epoch=8
05/22/2022 12:04:57 - INFO - __main__ - Step 240 Global step 240 Train loss 1.66 on epoch=8
05/22/2022 12:05:00 - INFO - __main__ - Step 250 Global step 250 Train loss 1.76 on epoch=8
05/22/2022 12:05:11 - INFO - __main__ - Global step 250 Train loss 1.81 Classification-F1 0.11251922396525053 on epoch=8
05/22/2022 12:05:11 - INFO - __main__ - Saving model with best Classification-F1: 0.06982827351015863 -> 0.11251922396525053 on epoch=8, global_step=250
05/22/2022 12:05:14 - INFO - __main__ - Step 260 Global step 260 Train loss 1.78 on epoch=9
05/22/2022 12:05:17 - INFO - __main__ - Step 270 Global step 270 Train loss 1.50 on epoch=9
05/22/2022 12:05:19 - INFO - __main__ - Step 280 Global step 280 Train loss 1.57 on epoch=9
05/22/2022 12:05:22 - INFO - __main__ - Step 290 Global step 290 Train loss 1.62 on epoch=10
05/22/2022 12:05:25 - INFO - __main__ - Step 300 Global step 300 Train loss 1.34 on epoch=10
05/22/2022 12:05:36 - INFO - __main__ - Global step 300 Train loss 1.56 Classification-F1 0.1437313825809711 on epoch=10
05/22/2022 12:05:36 - INFO - __main__ - Saving model with best Classification-F1: 0.11251922396525053 -> 0.1437313825809711 on epoch=10, global_step=300
05/22/2022 12:05:38 - INFO - __main__ - Step 310 Global step 310 Train loss 1.27 on epoch=11
05/22/2022 12:05:41 - INFO - __main__ - Step 320 Global step 320 Train loss 1.34 on epoch=11
05/22/2022 12:05:43 - INFO - __main__ - Step 330 Global step 330 Train loss 1.22 on epoch=11
05/22/2022 12:05:46 - INFO - __main__ - Step 340 Global step 340 Train loss 1.10 on epoch=12
05/22/2022 12:05:49 - INFO - __main__ - Step 350 Global step 350 Train loss 1.28 on epoch=12
05/22/2022 12:06:00 - INFO - __main__ - Global step 350 Train loss 1.24 Classification-F1 0.17199186587096438 on epoch=12
05/22/2022 12:06:00 - INFO - __main__ - Saving model with best Classification-F1: 0.1437313825809711 -> 0.17199186587096438 on epoch=12, global_step=350
05/22/2022 12:06:02 - INFO - __main__ - Step 360 Global step 360 Train loss 1.16 on epoch=12
05/22/2022 12:06:05 - INFO - __main__ - Step 370 Global step 370 Train loss 1.03 on epoch=13
05/22/2022 12:06:08 - INFO - __main__ - Step 380 Global step 380 Train loss 1.01 on epoch=13
05/22/2022 12:06:10 - INFO - __main__ - Step 390 Global step 390 Train loss 0.96 on epoch=13
05/22/2022 12:06:13 - INFO - __main__ - Step 400 Global step 400 Train loss 0.95 on epoch=14
05/22/2022 12:06:24 - INFO - __main__ - Global step 400 Train loss 1.02 Classification-F1 0.21645247310460441 on epoch=14
05/22/2022 12:06:24 - INFO - __main__ - Saving model with best Classification-F1: 0.17199186587096438 -> 0.21645247310460441 on epoch=14, global_step=400
05/22/2022 12:06:27 - INFO - __main__ - Step 410 Global step 410 Train loss 0.87 on epoch=14
05/22/2022 12:06:30 - INFO - __main__ - Step 420 Global step 420 Train loss 0.80 on epoch=14
05/22/2022 12:06:32 - INFO - __main__ - Step 430 Global step 430 Train loss 0.86 on epoch=15
05/22/2022 12:06:35 - INFO - __main__ - Step 440 Global step 440 Train loss 0.73 on epoch=15
05/22/2022 12:06:37 - INFO - __main__ - Step 450 Global step 450 Train loss 0.76 on epoch=16
05/22/2022 12:06:49 - INFO - __main__ - Global step 450 Train loss 0.80 Classification-F1 0.2708499950988261 on epoch=16
05/22/2022 12:06:49 - INFO - __main__ - Saving model with best Classification-F1: 0.21645247310460441 -> 0.2708499950988261 on epoch=16, global_step=450
05/22/2022 12:06:51 - INFO - __main__ - Step 460 Global step 460 Train loss 0.83 on epoch=16
05/22/2022 12:06:54 - INFO - __main__ - Step 470 Global step 470 Train loss 0.69 on epoch=16
05/22/2022 12:06:57 - INFO - __main__ - Step 480 Global step 480 Train loss 0.63 on epoch=17
05/22/2022 12:06:59 - INFO - __main__ - Step 490 Global step 490 Train loss 0.63 on epoch=17
05/22/2022 12:07:02 - INFO - __main__ - Step 500 Global step 500 Train loss 0.63 on epoch=17
05/22/2022 12:07:14 - INFO - __main__ - Global step 500 Train loss 0.68 Classification-F1 0.3010022086565041 on epoch=17
05/22/2022 12:07:14 - INFO - __main__ - Saving model with best Classification-F1: 0.2708499950988261 -> 0.3010022086565041 on epoch=17, global_step=500
05/22/2022 12:07:17 - INFO - __main__ - Step 510 Global step 510 Train loss 0.65 on epoch=18
05/22/2022 12:07:19 - INFO - __main__ - Step 520 Global step 520 Train loss 0.60 on epoch=18
05/22/2022 12:07:22 - INFO - __main__ - Step 530 Global step 530 Train loss 0.67 on epoch=18
05/22/2022 12:07:25 - INFO - __main__ - Step 540 Global step 540 Train loss 0.58 on epoch=19
05/22/2022 12:07:27 - INFO - __main__ - Step 550 Global step 550 Train loss 0.58 on epoch=19
05/22/2022 12:07:40 - INFO - __main__ - Global step 550 Train loss 0.61 Classification-F1 0.36878365289895493 on epoch=19
05/22/2022 12:07:40 - INFO - __main__ - Saving model with best Classification-F1: 0.3010022086565041 -> 0.36878365289895493 on epoch=19, global_step=550
05/22/2022 12:07:43 - INFO - __main__ - Step 560 Global step 560 Train loss 0.43 on epoch=19
05/22/2022 12:07:45 - INFO - __main__ - Step 570 Global step 570 Train loss 0.60 on epoch=20
05/22/2022 12:07:48 - INFO - __main__ - Step 580 Global step 580 Train loss 0.46 on epoch=20
05/22/2022 12:07:51 - INFO - __main__ - Step 590 Global step 590 Train loss 0.45 on epoch=21
05/22/2022 12:07:53 - INFO - __main__ - Step 600 Global step 600 Train loss 0.45 on epoch=21
05/22/2022 12:08:06 - INFO - __main__ - Global step 600 Train loss 0.48 Classification-F1 0.36288877139197706 on epoch=21
05/22/2022 12:08:09 - INFO - __main__ - Step 610 Global step 610 Train loss 0.52 on epoch=21
05/22/2022 12:08:11 - INFO - __main__ - Step 620 Global step 620 Train loss 0.41 on epoch=22
05/22/2022 12:08:14 - INFO - __main__ - Step 630 Global step 630 Train loss 0.48 on epoch=22
05/22/2022 12:08:16 - INFO - __main__ - Step 640 Global step 640 Train loss 0.36 on epoch=22
05/22/2022 12:08:19 - INFO - __main__ - Step 650 Global step 650 Train loss 0.45 on epoch=23
05/22/2022 12:08:32 - INFO - __main__ - Global step 650 Train loss 0.44 Classification-F1 0.47039971547639525 on epoch=23
05/22/2022 12:08:32 - INFO - __main__ - Saving model with best Classification-F1: 0.36878365289895493 -> 0.47039971547639525 on epoch=23, global_step=650
05/22/2022 12:08:34 - INFO - __main__ - Step 660 Global step 660 Train loss 0.42 on epoch=23
05/22/2022 12:08:37 - INFO - __main__ - Step 670 Global step 670 Train loss 0.35 on epoch=23
05/22/2022 12:08:40 - INFO - __main__ - Step 680 Global step 680 Train loss 0.43 on epoch=24
05/22/2022 12:08:42 - INFO - __main__ - Step 690 Global step 690 Train loss 0.33 on epoch=24
05/22/2022 12:08:45 - INFO - __main__ - Step 700 Global step 700 Train loss 0.37 on epoch=24
05/22/2022 12:08:58 - INFO - __main__ - Global step 700 Train loss 0.38 Classification-F1 0.40805466672941626 on epoch=24
05/22/2022 12:09:00 - INFO - __main__ - Step 710 Global step 710 Train loss 0.37 on epoch=25
05/22/2022 12:09:03 - INFO - __main__ - Step 720 Global step 720 Train loss 0.32 on epoch=25
05/22/2022 12:09:06 - INFO - __main__ - Step 730 Global step 730 Train loss 0.32 on epoch=26
05/22/2022 12:09:08 - INFO - __main__ - Step 740 Global step 740 Train loss 0.38 on epoch=26
05/22/2022 12:09:11 - INFO - __main__ - Step 750 Global step 750 Train loss 0.36 on epoch=26
05/22/2022 12:09:24 - INFO - __main__ - Global step 750 Train loss 0.35 Classification-F1 0.46934308060792085 on epoch=26
05/22/2022 12:09:27 - INFO - __main__ - Step 760 Global step 760 Train loss 0.31 on epoch=27
05/22/2022 12:09:29 - INFO - __main__ - Step 770 Global step 770 Train loss 0.26 on epoch=27
05/22/2022 12:09:32 - INFO - __main__ - Step 780 Global step 780 Train loss 0.23 on epoch=27
05/22/2022 12:09:35 - INFO - __main__ - Step 790 Global step 790 Train loss 0.34 on epoch=28
05/22/2022 12:09:37 - INFO - __main__ - Step 800 Global step 800 Train loss 0.32 on epoch=28
05/22/2022 12:09:50 - INFO - __main__ - Global step 800 Train loss 0.29 Classification-F1 0.4873998596137582 on epoch=28
05/22/2022 12:09:50 - INFO - __main__ - Saving model with best Classification-F1: 0.47039971547639525 -> 0.4873998596137582 on epoch=28, global_step=800
05/22/2022 12:09:53 - INFO - __main__ - Step 810 Global step 810 Train loss 0.26 on epoch=28
05/22/2022 12:09:56 - INFO - __main__ - Step 820 Global step 820 Train loss 0.33 on epoch=29
05/22/2022 12:09:58 - INFO - __main__ - Step 830 Global step 830 Train loss 0.36 on epoch=29
05/22/2022 12:10:01 - INFO - __main__ - Step 840 Global step 840 Train loss 0.38 on epoch=29
05/22/2022 12:10:03 - INFO - __main__ - Step 850 Global step 850 Train loss 0.30 on epoch=30
05/22/2022 12:10:17 - INFO - __main__ - Global step 850 Train loss 0.33 Classification-F1 0.47529078862241525 on epoch=30
05/22/2022 12:10:19 - INFO - __main__ - Step 860 Global step 860 Train loss 0.29 on epoch=30
05/22/2022 12:10:22 - INFO - __main__ - Step 870 Global step 870 Train loss 0.25 on epoch=31
05/22/2022 12:10:24 - INFO - __main__ - Step 880 Global step 880 Train loss 0.30 on epoch=31
05/22/2022 12:10:27 - INFO - __main__ - Step 890 Global step 890 Train loss 0.25 on epoch=31
05/22/2022 12:10:30 - INFO - __main__ - Step 900 Global step 900 Train loss 0.22 on epoch=32
05/22/2022 12:10:42 - INFO - __main__ - Global step 900 Train loss 0.26 Classification-F1 0.44161465073038914 on epoch=32
05/22/2022 12:10:45 - INFO - __main__ - Step 910 Global step 910 Train loss 0.28 on epoch=32
05/22/2022 12:10:48 - INFO - __main__ - Step 920 Global step 920 Train loss 0.26 on epoch=32
05/22/2022 12:10:50 - INFO - __main__ - Step 930 Global step 930 Train loss 0.29 on epoch=33
05/22/2022 12:10:53 - INFO - __main__ - Step 940 Global step 940 Train loss 0.23 on epoch=33
05/22/2022 12:10:56 - INFO - __main__ - Step 950 Global step 950 Train loss 0.26 on epoch=33
05/22/2022 12:11:09 - INFO - __main__ - Global step 950 Train loss 0.26 Classification-F1 0.5290487931956283 on epoch=33
05/22/2022 12:11:09 - INFO - __main__ - Saving model with best Classification-F1: 0.4873998596137582 -> 0.5290487931956283 on epoch=33, global_step=950
05/22/2022 12:11:11 - INFO - __main__ - Step 960 Global step 960 Train loss 0.24 on epoch=34
05/22/2022 12:11:14 - INFO - __main__ - Step 970 Global step 970 Train loss 0.26 on epoch=34
05/22/2022 12:11:17 - INFO - __main__ - Step 980 Global step 980 Train loss 0.21 on epoch=34
05/22/2022 12:11:19 - INFO - __main__ - Step 990 Global step 990 Train loss 0.26 on epoch=35
05/22/2022 12:11:22 - INFO - __main__ - Step 1000 Global step 1000 Train loss 0.22 on epoch=35
05/22/2022 12:11:34 - INFO - __main__ - Global step 1000 Train loss 0.24 Classification-F1 0.5208817601917094 on epoch=35
05/22/2022 12:11:37 - INFO - __main__ - Step 1010 Global step 1010 Train loss 0.23 on epoch=36
05/22/2022 12:11:40 - INFO - __main__ - Step 1020 Global step 1020 Train loss 0.24 on epoch=36
05/22/2022 12:11:42 - INFO - __main__ - Step 1030 Global step 1030 Train loss 0.23 on epoch=36
05/22/2022 12:11:45 - INFO - __main__ - Step 1040 Global step 1040 Train loss 0.21 on epoch=37
05/22/2022 12:11:48 - INFO - __main__ - Step 1050 Global step 1050 Train loss 0.23 on epoch=37
05/22/2022 12:12:01 - INFO - __main__ - Global step 1050 Train loss 0.23 Classification-F1 0.6116140162802945 on epoch=37
05/22/2022 12:12:01 - INFO - __main__ - Saving model with best Classification-F1: 0.5290487931956283 -> 0.6116140162802945 on epoch=37, global_step=1050
05/22/2022 12:12:04 - INFO - __main__ - Step 1060 Global step 1060 Train loss 0.19 on epoch=37
05/22/2022 12:12:06 - INFO - __main__ - Step 1070 Global step 1070 Train loss 0.20 on epoch=38
05/22/2022 12:12:09 - INFO - __main__ - Step 1080 Global step 1080 Train loss 0.23 on epoch=38
05/22/2022 12:12:11 - INFO - __main__ - Step 1090 Global step 1090 Train loss 0.23 on epoch=38
05/22/2022 12:12:14 - INFO - __main__ - Step 1100 Global step 1100 Train loss 0.23 on epoch=39
05/22/2022 12:12:27 - INFO - __main__ - Global step 1100 Train loss 0.22 Classification-F1 0.6181603588816862 on epoch=39
05/22/2022 12:12:27 - INFO - __main__ - Saving model with best Classification-F1: 0.6116140162802945 -> 0.6181603588816862 on epoch=39, global_step=1100
05/22/2022 12:12:30 - INFO - __main__ - Step 1110 Global step 1110 Train loss 0.17 on epoch=39
05/22/2022 12:12:33 - INFO - __main__ - Step 1120 Global step 1120 Train loss 0.17 on epoch=39
05/22/2022 12:12:35 - INFO - __main__ - Step 1130 Global step 1130 Train loss 0.20 on epoch=40
05/22/2022 12:12:38 - INFO - __main__ - Step 1140 Global step 1140 Train loss 0.13 on epoch=40
05/22/2022 12:12:40 - INFO - __main__ - Step 1150 Global step 1150 Train loss 0.26 on epoch=41
05/22/2022 12:12:53 - INFO - __main__ - Global step 1150 Train loss 0.19 Classification-F1 0.6089767008835345 on epoch=41
05/22/2022 12:12:56 - INFO - __main__ - Step 1160 Global step 1160 Train loss 0.20 on epoch=41
05/22/2022 12:12:59 - INFO - __main__ - Step 1170 Global step 1170 Train loss 0.09 on epoch=41
05/22/2022 12:13:01 - INFO - __main__ - Step 1180 Global step 1180 Train loss 0.24 on epoch=42
05/22/2022 12:13:04 - INFO - __main__ - Step 1190 Global step 1190 Train loss 0.21 on epoch=42
05/22/2022 12:13:07 - INFO - __main__ - Step 1200 Global step 1200 Train loss 0.21 on epoch=42
05/22/2022 12:13:19 - INFO - __main__ - Global step 1200 Train loss 0.19 Classification-F1 0.651743019305319 on epoch=42
05/22/2022 12:13:19 - INFO - __main__ - Saving model with best Classification-F1: 0.6181603588816862 -> 0.651743019305319 on epoch=42, global_step=1200
05/22/2022 12:13:22 - INFO - __main__ - Step 1210 Global step 1210 Train loss 0.15 on epoch=43
05/22/2022 12:13:25 - INFO - __main__ - Step 1220 Global step 1220 Train loss 0.16 on epoch=43
05/22/2022 12:13:27 - INFO - __main__ - Step 1230 Global step 1230 Train loss 0.17 on epoch=43
05/22/2022 12:13:30 - INFO - __main__ - Step 1240 Global step 1240 Train loss 0.14 on epoch=44
05/22/2022 12:13:33 - INFO - __main__ - Step 1250 Global step 1250 Train loss 0.17 on epoch=44
05/22/2022 12:13:46 - INFO - __main__ - Global step 1250 Train loss 0.16 Classification-F1 0.6647301136034534 on epoch=44
05/22/2022 12:13:46 - INFO - __main__ - Saving model with best Classification-F1: 0.651743019305319 -> 0.6647301136034534 on epoch=44, global_step=1250
05/22/2022 12:13:48 - INFO - __main__ - Step 1260 Global step 1260 Train loss 0.20 on epoch=44
05/22/2022 12:13:51 - INFO - __main__ - Step 1270 Global step 1270 Train loss 0.17 on epoch=45
05/22/2022 12:13:54 - INFO - __main__ - Step 1280 Global step 1280 Train loss 0.09 on epoch=45
05/22/2022 12:13:56 - INFO - __main__ - Step 1290 Global step 1290 Train loss 0.13 on epoch=46
05/22/2022 12:13:59 - INFO - __main__ - Step 1300 Global step 1300 Train loss 0.14 on epoch=46
05/22/2022 12:14:12 - INFO - __main__ - Global step 1300 Train loss 0.15 Classification-F1 0.6546384432162439 on epoch=46
05/22/2022 12:14:14 - INFO - __main__ - Step 1310 Global step 1310 Train loss 0.19 on epoch=46
05/22/2022 12:14:17 - INFO - __main__ - Step 1320 Global step 1320 Train loss 0.13 on epoch=47
05/22/2022 12:14:20 - INFO - __main__ - Step 1330 Global step 1330 Train loss 0.18 on epoch=47
05/22/2022 12:14:22 - INFO - __main__ - Step 1340 Global step 1340 Train loss 0.19 on epoch=47
05/22/2022 12:14:25 - INFO - __main__ - Step 1350 Global step 1350 Train loss 0.14 on epoch=48
05/22/2022 12:14:37 - INFO - __main__ - Global step 1350 Train loss 0.17 Classification-F1 0.6226700159503004 on epoch=48
05/22/2022 12:14:40 - INFO - __main__ - Step 1360 Global step 1360 Train loss 0.17 on epoch=48
05/22/2022 12:14:43 - INFO - __main__ - Step 1370 Global step 1370 Train loss 0.11 on epoch=48
05/22/2022 12:14:45 - INFO - __main__ - Step 1380 Global step 1380 Train loss 0.17 on epoch=49
05/22/2022 12:14:48 - INFO - __main__ - Step 1390 Global step 1390 Train loss 0.16 on epoch=49
05/22/2022 12:14:50 - INFO - __main__ - Step 1400 Global step 1400 Train loss 0.17 on epoch=49
05/22/2022 12:15:03 - INFO - __main__ - Global step 1400 Train loss 0.16 Classification-F1 0.6543618614925917 on epoch=49
05/22/2022 12:15:06 - INFO - __main__ - Step 1410 Global step 1410 Train loss 0.13 on epoch=50
05/22/2022 12:15:08 - INFO - __main__ - Step 1420 Global step 1420 Train loss 0.13 on epoch=50
05/22/2022 12:15:11 - INFO - __main__ - Step 1430 Global step 1430 Train loss 0.12 on epoch=51
05/22/2022 12:15:13 - INFO - __main__ - Step 1440 Global step 1440 Train loss 0.15 on epoch=51
05/22/2022 12:15:16 - INFO - __main__ - Step 1450 Global step 1450 Train loss 0.12 on epoch=51
05/22/2022 12:15:29 - INFO - __main__ - Global step 1450 Train loss 0.13 Classification-F1 0.652772008103843 on epoch=51
05/22/2022 12:15:31 - INFO - __main__ - Step 1460 Global step 1460 Train loss 0.10 on epoch=52
05/22/2022 12:15:34 - INFO - __main__ - Step 1470 Global step 1470 Train loss 0.14 on epoch=52
05/22/2022 12:15:36 - INFO - __main__ - Step 1480 Global step 1480 Train loss 0.12 on epoch=52
05/22/2022 12:15:39 - INFO - __main__ - Step 1490 Global step 1490 Train loss 0.13 on epoch=53
05/22/2022 12:15:42 - INFO - __main__ - Step 1500 Global step 1500 Train loss 0.13 on epoch=53
05/22/2022 12:15:54 - INFO - __main__ - Global step 1500 Train loss 0.12 Classification-F1 0.8328386590459647 on epoch=53
05/22/2022 12:15:54 - INFO - __main__ - Saving model with best Classification-F1: 0.6647301136034534 -> 0.8328386590459647 on epoch=53, global_step=1500
05/22/2022 12:15:57 - INFO - __main__ - Step 1510 Global step 1510 Train loss 0.11 on epoch=53
05/22/2022 12:16:00 - INFO - __main__ - Step 1520 Global step 1520 Train loss 0.15 on epoch=54
05/22/2022 12:16:02 - INFO - __main__ - Step 1530 Global step 1530 Train loss 0.09 on epoch=54
05/22/2022 12:16:05 - INFO - __main__ - Step 1540 Global step 1540 Train loss 0.17 on epoch=54
05/22/2022 12:16:07 - INFO - __main__ - Step 1550 Global step 1550 Train loss 0.10 on epoch=55
05/22/2022 12:16:20 - INFO - __main__ - Global step 1550 Train loss 0.13 Classification-F1 0.6983888000689077 on epoch=55
05/22/2022 12:16:23 - INFO - __main__ - Step 1560 Global step 1560 Train loss 0.12 on epoch=55
05/22/2022 12:16:25 - INFO - __main__ - Step 1570 Global step 1570 Train loss 0.08 on epoch=56
05/22/2022 12:16:28 - INFO - __main__ - Step 1580 Global step 1580 Train loss 0.16 on epoch=56
05/22/2022 12:16:30 - INFO - __main__ - Step 1590 Global step 1590 Train loss 0.08 on epoch=56
05/22/2022 12:16:33 - INFO - __main__ - Step 1600 Global step 1600 Train loss 0.09 on epoch=57
05/22/2022 12:16:45 - INFO - __main__ - Global step 1600 Train loss 0.11 Classification-F1 0.7003310716260693 on epoch=57
05/22/2022 12:16:48 - INFO - __main__ - Step 1610 Global step 1610 Train loss 0.10 on epoch=57
05/22/2022 12:16:51 - INFO - __main__ - Step 1620 Global step 1620 Train loss 0.14 on epoch=57
05/22/2022 12:16:54 - INFO - __main__ - Step 1630 Global step 1630 Train loss 0.13 on epoch=58
05/22/2022 12:16:56 - INFO - __main__ - Step 1640 Global step 1640 Train loss 0.10 on epoch=58
05/22/2022 12:16:59 - INFO - __main__ - Step 1650 Global step 1650 Train loss 0.14 on epoch=58
05/22/2022 12:17:11 - INFO - __main__ - Global step 1650 Train loss 0.12 Classification-F1 0.6958327596524767 on epoch=58
05/22/2022 12:17:14 - INFO - __main__ - Step 1660 Global step 1660 Train loss 0.13 on epoch=59
05/22/2022 12:17:16 - INFO - __main__ - Step 1670 Global step 1670 Train loss 0.09 on epoch=59
05/22/2022 12:17:19 - INFO - __main__ - Step 1680 Global step 1680 Train loss 0.17 on epoch=59
05/22/2022 12:17:22 - INFO - __main__ - Step 1690 Global step 1690 Train loss 0.07 on epoch=60
05/22/2022 12:17:24 - INFO - __main__ - Step 1700 Global step 1700 Train loss 0.09 on epoch=60
05/22/2022 12:17:36 - INFO - __main__ - Global step 1700 Train loss 0.11 Classification-F1 0.6957475068306432 on epoch=60
05/22/2022 12:17:39 - INFO - __main__ - Step 1710 Global step 1710 Train loss 0.13 on epoch=61
05/22/2022 12:17:42 - INFO - __main__ - Step 1720 Global step 1720 Train loss 0.14 on epoch=61
05/22/2022 12:17:44 - INFO - __main__ - Step 1730 Global step 1730 Train loss 0.09 on epoch=61
05/22/2022 12:17:47 - INFO - __main__ - Step 1740 Global step 1740 Train loss 0.09 on epoch=62
05/22/2022 12:17:50 - INFO - __main__ - Step 1750 Global step 1750 Train loss 0.10 on epoch=62
05/22/2022 12:18:02 - INFO - __main__ - Global step 1750 Train loss 0.11 Classification-F1 0.7337794331355162 on epoch=62
05/22/2022 12:18:05 - INFO - __main__ - Step 1760 Global step 1760 Train loss 0.08 on epoch=62
05/22/2022 12:18:07 - INFO - __main__ - Step 1770 Global step 1770 Train loss 0.11 on epoch=63
05/22/2022 12:18:10 - INFO - __main__ - Step 1780 Global step 1780 Train loss 0.07 on epoch=63
05/22/2022 12:18:13 - INFO - __main__ - Step 1790 Global step 1790 Train loss 0.08 on epoch=63
05/22/2022 12:18:15 - INFO - __main__ - Step 1800 Global step 1800 Train loss 0.10 on epoch=64
05/22/2022 12:18:27 - INFO - __main__ - Global step 1800 Train loss 0.09 Classification-F1 0.7387242282410071 on epoch=64
05/22/2022 12:18:30 - INFO - __main__ - Step 1810 Global step 1810 Train loss 0.08 on epoch=64
05/22/2022 12:18:33 - INFO - __main__ - Step 1820 Global step 1820 Train loss 0.07 on epoch=64
05/22/2022 12:18:35 - INFO - __main__ - Step 1830 Global step 1830 Train loss 0.06 on epoch=65
05/22/2022 12:18:38 - INFO - __main__ - Step 1840 Global step 1840 Train loss 0.10 on epoch=65
05/22/2022 12:18:40 - INFO - __main__ - Step 1850 Global step 1850 Train loss 0.12 on epoch=66
05/22/2022 12:18:53 - INFO - __main__ - Global step 1850 Train loss 0.08 Classification-F1 0.7001013749834272 on epoch=66
05/22/2022 12:18:55 - INFO - __main__ - Step 1860 Global step 1860 Train loss 0.07 on epoch=66
05/22/2022 12:18:58 - INFO - __main__ - Step 1870 Global step 1870 Train loss 0.06 on epoch=66
05/22/2022 12:19:00 - INFO - __main__ - Step 1880 Global step 1880 Train loss 0.09 on epoch=67
05/22/2022 12:19:03 - INFO - __main__ - Step 1890 Global step 1890 Train loss 0.17 on epoch=67
05/22/2022 12:19:06 - INFO - __main__ - Step 1900 Global step 1900 Train loss 0.07 on epoch=67
05/22/2022 12:19:18 - INFO - __main__ - Global step 1900 Train loss 0.09 Classification-F1 0.7326648088075468 on epoch=67
05/22/2022 12:19:20 - INFO - __main__ - Step 1910 Global step 1910 Train loss 0.11 on epoch=68
05/22/2022 12:19:23 - INFO - __main__ - Step 1920 Global step 1920 Train loss 0.07 on epoch=68
05/22/2022 12:19:26 - INFO - __main__ - Step 1930 Global step 1930 Train loss 0.06 on epoch=68
05/22/2022 12:19:28 - INFO - __main__ - Step 1940 Global step 1940 Train loss 0.09 on epoch=69
05/22/2022 12:19:31 - INFO - __main__ - Step 1950 Global step 1950 Train loss 0.07 on epoch=69
05/22/2022 12:19:43 - INFO - __main__ - Global step 1950 Train loss 0.08 Classification-F1 0.7274116934710251 on epoch=69
05/22/2022 12:19:46 - INFO - __main__ - Step 1960 Global step 1960 Train loss 0.06 on epoch=69
05/22/2022 12:19:48 - INFO - __main__ - Step 1970 Global step 1970 Train loss 0.11 on epoch=70
05/22/2022 12:19:51 - INFO - __main__ - Step 1980 Global step 1980 Train loss 0.06 on epoch=70
05/22/2022 12:19:53 - INFO - __main__ - Step 1990 Global step 1990 Train loss 0.07 on epoch=71
05/22/2022 12:19:56 - INFO - __main__ - Step 2000 Global step 2000 Train loss 0.08 on epoch=71
05/22/2022 12:20:08 - INFO - __main__ - Global step 2000 Train loss 0.08 Classification-F1 0.7349207580162257 on epoch=71
05/22/2022 12:20:11 - INFO - __main__ - Step 2010 Global step 2010 Train loss 0.13 on epoch=71
05/22/2022 12:20:14 - INFO - __main__ - Step 2020 Global step 2020 Train loss 0.05 on epoch=72
05/22/2022 12:20:16 - INFO - __main__ - Step 2030 Global step 2030 Train loss 0.09 on epoch=72
05/22/2022 12:20:19 - INFO - __main__ - Step 2040 Global step 2040 Train loss 0.08 on epoch=72
05/22/2022 12:20:22 - INFO - __main__ - Step 2050 Global step 2050 Train loss 0.09 on epoch=73
05/22/2022 12:20:34 - INFO - __main__ - Global step 2050 Train loss 0.09 Classification-F1 0.7030620424404578 on epoch=73
05/22/2022 12:20:36 - INFO - __main__ - Step 2060 Global step 2060 Train loss 0.07 on epoch=73
05/22/2022 12:20:39 - INFO - __main__ - Step 2070 Global step 2070 Train loss 0.05 on epoch=73
05/22/2022 12:20:42 - INFO - __main__ - Step 2080 Global step 2080 Train loss 0.06 on epoch=74
05/22/2022 12:20:44 - INFO - __main__ - Step 2090 Global step 2090 Train loss 0.08 on epoch=74
05/22/2022 12:20:47 - INFO - __main__ - Step 2100 Global step 2100 Train loss 0.10 on epoch=74
05/22/2022 12:20:59 - INFO - __main__ - Global step 2100 Train loss 0.07 Classification-F1 0.737543102476631 on epoch=74
05/22/2022 12:21:02 - INFO - __main__ - Step 2110 Global step 2110 Train loss 0.10 on epoch=75
05/22/2022 12:21:04 - INFO - __main__ - Step 2120 Global step 2120 Train loss 0.05 on epoch=75
05/22/2022 12:21:07 - INFO - __main__ - Step 2130 Global step 2130 Train loss 0.08 on epoch=76
05/22/2022 12:21:10 - INFO - __main__ - Step 2140 Global step 2140 Train loss 0.04 on epoch=76
05/22/2022 12:21:12 - INFO - __main__ - Step 2150 Global step 2150 Train loss 0.07 on epoch=76
05/22/2022 12:21:25 - INFO - __main__ - Global step 2150 Train loss 0.07 Classification-F1 0.7452333387070689 on epoch=76
05/22/2022 12:21:27 - INFO - __main__ - Step 2160 Global step 2160 Train loss 0.07 on epoch=77
05/22/2022 12:21:30 - INFO - __main__ - Step 2170 Global step 2170 Train loss 0.08 on epoch=77
05/22/2022 12:21:33 - INFO - __main__ - Step 2180 Global step 2180 Train loss 0.03 on epoch=77
05/22/2022 12:21:35 - INFO - __main__ - Step 2190 Global step 2190 Train loss 0.06 on epoch=78
05/22/2022 12:21:38 - INFO - __main__ - Step 2200 Global step 2200 Train loss 0.07 on epoch=78
05/22/2022 12:21:50 - INFO - __main__ - Global step 2200 Train loss 0.06 Classification-F1 0.7073863807365702 on epoch=78
05/22/2022 12:21:53 - INFO - __main__ - Step 2210 Global step 2210 Train loss 0.08 on epoch=78
05/22/2022 12:21:55 - INFO - __main__ - Step 2220 Global step 2220 Train loss 0.06 on epoch=79
05/22/2022 12:21:58 - INFO - __main__ - Step 2230 Global step 2230 Train loss 0.06 on epoch=79
05/22/2022 12:22:01 - INFO - __main__ - Step 2240 Global step 2240 Train loss 0.04 on epoch=79
05/22/2022 12:22:03 - INFO - __main__ - Step 2250 Global step 2250 Train loss 0.08 on epoch=80
05/22/2022 12:22:16 - INFO - __main__ - Global step 2250 Train loss 0.07 Classification-F1 0.7140868751419827 on epoch=80
05/22/2022 12:22:18 - INFO - __main__ - Step 2260 Global step 2260 Train loss 0.04 on epoch=80
05/22/2022 12:22:21 - INFO - __main__ - Step 2270 Global step 2270 Train loss 0.06 on epoch=81
05/22/2022 12:22:24 - INFO - __main__ - Step 2280 Global step 2280 Train loss 0.08 on epoch=81
05/22/2022 12:22:26 - INFO - __main__ - Step 2290 Global step 2290 Train loss 0.04 on epoch=81
05/22/2022 12:22:29 - INFO - __main__ - Step 2300 Global step 2300 Train loss 0.05 on epoch=82
05/22/2022 12:22:41 - INFO - __main__ - Global step 2300 Train loss 0.06 Classification-F1 0.6996041494935181 on epoch=82
05/22/2022 12:22:44 - INFO - __main__ - Step 2310 Global step 2310 Train loss 0.06 on epoch=82
05/22/2022 12:22:47 - INFO - __main__ - Step 2320 Global step 2320 Train loss 0.03 on epoch=82
05/22/2022 12:22:49 - INFO - __main__ - Step 2330 Global step 2330 Train loss 0.06 on epoch=83
05/22/2022 12:22:52 - INFO - __main__ - Step 2340 Global step 2340 Train loss 0.06 on epoch=83
05/22/2022 12:22:54 - INFO - __main__ - Step 2350 Global step 2350 Train loss 0.03 on epoch=83
05/22/2022 12:23:07 - INFO - __main__ - Global step 2350 Train loss 0.05 Classification-F1 0.705191896210239 on epoch=83
05/22/2022 12:23:09 - INFO - __main__ - Step 2360 Global step 2360 Train loss 0.07 on epoch=84
05/22/2022 12:23:12 - INFO - __main__ - Step 2370 Global step 2370 Train loss 0.11 on epoch=84
05/22/2022 12:23:15 - INFO - __main__ - Step 2380 Global step 2380 Train loss 0.03 on epoch=84
05/22/2022 12:23:17 - INFO - __main__ - Step 2390 Global step 2390 Train loss 0.07 on epoch=85
05/22/2022 12:23:20 - INFO - __main__ - Step 2400 Global step 2400 Train loss 0.04 on epoch=85
05/22/2022 12:23:32 - INFO - __main__ - Global step 2400 Train loss 0.07 Classification-F1 0.7872827725496456 on epoch=85
05/22/2022 12:23:35 - INFO - __main__ - Step 2410 Global step 2410 Train loss 0.06 on epoch=86
05/22/2022 12:23:38 - INFO - __main__ - Step 2420 Global step 2420 Train loss 0.04 on epoch=86
05/22/2022 12:23:40 - INFO - __main__ - Step 2430 Global step 2430 Train loss 0.05 on epoch=86
05/22/2022 12:23:43 - INFO - __main__ - Step 2440 Global step 2440 Train loss 0.04 on epoch=87
05/22/2022 12:23:46 - INFO - __main__ - Step 2450 Global step 2450 Train loss 0.06 on epoch=87
05/22/2022 12:23:58 - INFO - __main__ - Global step 2450 Train loss 0.05 Classification-F1 0.766498284026747 on epoch=87
05/22/2022 12:24:01 - INFO - __main__ - Step 2460 Global step 2460 Train loss 0.06 on epoch=87
05/22/2022 12:24:03 - INFO - __main__ - Step 2470 Global step 2470 Train loss 0.06 on epoch=88
05/22/2022 12:24:06 - INFO - __main__ - Step 2480 Global step 2480 Train loss 0.06 on epoch=88
05/22/2022 12:24:09 - INFO - __main__ - Step 2490 Global step 2490 Train loss 0.02 on epoch=88
05/22/2022 12:24:11 - INFO - __main__ - Step 2500 Global step 2500 Train loss 0.08 on epoch=89
05/22/2022 12:24:24 - INFO - __main__ - Global step 2500 Train loss 0.05 Classification-F1 0.7683379094550821 on epoch=89
05/22/2022 12:24:26 - INFO - __main__ - Step 2510 Global step 2510 Train loss 0.03 on epoch=89
05/22/2022 12:24:29 - INFO - __main__ - Step 2520 Global step 2520 Train loss 0.09 on epoch=89
05/22/2022 12:24:32 - INFO - __main__ - Step 2530 Global step 2530 Train loss 0.03 on epoch=90
05/22/2022 12:24:34 - INFO - __main__ - Step 2540 Global step 2540 Train loss 0.03 on epoch=90
05/22/2022 12:24:37 - INFO - __main__ - Step 2550 Global step 2550 Train loss 0.08 on epoch=91
05/22/2022 12:24:49 - INFO - __main__ - Global step 2550 Train loss 0.05 Classification-F1 0.7256231348301241 on epoch=91
05/22/2022 12:24:52 - INFO - __main__ - Step 2560 Global step 2560 Train loss 0.06 on epoch=91
05/22/2022 12:24:55 - INFO - __main__ - Step 2570 Global step 2570 Train loss 0.06 on epoch=91
05/22/2022 12:24:58 - INFO - __main__ - Step 2580 Global step 2580 Train loss 0.08 on epoch=92
05/22/2022 12:25:00 - INFO - __main__ - Step 2590 Global step 2590 Train loss 0.04 on epoch=92
05/22/2022 12:25:03 - INFO - __main__ - Step 2600 Global step 2600 Train loss 0.05 on epoch=92
05/22/2022 12:25:16 - INFO - __main__ - Global step 2600 Train loss 0.06 Classification-F1 0.7220802158655866 on epoch=92
05/22/2022 12:25:18 - INFO - __main__ - Step 2610 Global step 2610 Train loss 0.03 on epoch=93
05/22/2022 12:25:21 - INFO - __main__ - Step 2620 Global step 2620 Train loss 0.05 on epoch=93
05/22/2022 12:25:23 - INFO - __main__ - Step 2630 Global step 2630 Train loss 0.07 on epoch=93
05/22/2022 12:25:26 - INFO - __main__ - Step 2640 Global step 2640 Train loss 0.03 on epoch=94
05/22/2022 12:25:29 - INFO - __main__ - Step 2650 Global step 2650 Train loss 0.05 on epoch=94
05/22/2022 12:25:41 - INFO - __main__ - Global step 2650 Train loss 0.05 Classification-F1 0.7172757754041907 on epoch=94
05/22/2022 12:25:44 - INFO - __main__ - Step 2660 Global step 2660 Train loss 0.04 on epoch=94
05/22/2022 12:25:46 - INFO - __main__ - Step 2670 Global step 2670 Train loss 0.11 on epoch=95
05/22/2022 12:25:49 - INFO - __main__ - Step 2680 Global step 2680 Train loss 0.04 on epoch=95
05/22/2022 12:25:52 - INFO - __main__ - Step 2690 Global step 2690 Train loss 0.08 on epoch=96
05/22/2022 12:25:54 - INFO - __main__ - Step 2700 Global step 2700 Train loss 0.05 on epoch=96
05/22/2022 12:26:07 - INFO - __main__ - Global step 2700 Train loss 0.06 Classification-F1 0.7554168401347945 on epoch=96
05/22/2022 12:26:09 - INFO - __main__ - Step 2710 Global step 2710 Train loss 0.04 on epoch=96
05/22/2022 12:26:12 - INFO - __main__ - Step 2720 Global step 2720 Train loss 0.10 on epoch=97
05/22/2022 12:26:15 - INFO - __main__ - Step 2730 Global step 2730 Train loss 0.05 on epoch=97
05/22/2022 12:26:17 - INFO - __main__ - Step 2740 Global step 2740 Train loss 0.06 on epoch=97
05/22/2022 12:26:20 - INFO - __main__ - Step 2750 Global step 2750 Train loss 0.04 on epoch=98
05/22/2022 12:26:32 - INFO - __main__ - Global step 2750 Train loss 0.06 Classification-F1 0.8166490165860125 on epoch=98
05/22/2022 12:26:35 - INFO - __main__ - Step 2760 Global step 2760 Train loss 0.05 on epoch=98
05/22/2022 12:26:38 - INFO - __main__ - Step 2770 Global step 2770 Train loss 0.06 on epoch=98
05/22/2022 12:26:40 - INFO - __main__ - Step 2780 Global step 2780 Train loss 0.04 on epoch=99
05/22/2022 12:26:43 - INFO - __main__ - Step 2790 Global step 2790 Train loss 0.04 on epoch=99
05/22/2022 12:26:46 - INFO - __main__ - Step 2800 Global step 2800 Train loss 0.03 on epoch=99
05/22/2022 12:26:58 - INFO - __main__ - Global step 2800 Train loss 0.05 Classification-F1 0.7356399721311262 on epoch=99
05/22/2022 12:27:01 - INFO - __main__ - Step 2810 Global step 2810 Train loss 0.03 on epoch=100
05/22/2022 12:27:04 - INFO - __main__ - Step 2820 Global step 2820 Train loss 0.04 on epoch=100
05/22/2022 12:27:06 - INFO - __main__ - Step 2830 Global step 2830 Train loss 0.03 on epoch=101
05/22/2022 12:27:09 - INFO - __main__ - Step 2840 Global step 2840 Train loss 0.03 on epoch=101
05/22/2022 12:27:12 - INFO - __main__ - Step 2850 Global step 2850 Train loss 0.03 on epoch=101
05/22/2022 12:27:24 - INFO - __main__ - Global step 2850 Train loss 0.03 Classification-F1 0.7169125167445061 on epoch=101
05/22/2022 12:27:27 - INFO - __main__ - Step 2860 Global step 2860 Train loss 0.05 on epoch=102
05/22/2022 12:27:29 - INFO - __main__ - Step 2870 Global step 2870 Train loss 0.04 on epoch=102
05/22/2022 12:27:32 - INFO - __main__ - Step 2880 Global step 2880 Train loss 0.07 on epoch=102
05/22/2022 12:27:35 - INFO - __main__ - Step 2890 Global step 2890 Train loss 0.03 on epoch=103
05/22/2022 12:27:37 - INFO - __main__ - Step 2900 Global step 2900 Train loss 0.07 on epoch=103
05/22/2022 12:27:50 - INFO - __main__ - Global step 2900 Train loss 0.05 Classification-F1 0.7366114353976714 on epoch=103
05/22/2022 12:27:52 - INFO - __main__ - Step 2910 Global step 2910 Train loss 0.04 on epoch=103
05/22/2022 12:27:55 - INFO - __main__ - Step 2920 Global step 2920 Train loss 0.05 on epoch=104
05/22/2022 12:27:57 - INFO - __main__ - Step 2930 Global step 2930 Train loss 0.03 on epoch=104
05/22/2022 12:28:00 - INFO - __main__ - Step 2940 Global step 2940 Train loss 0.05 on epoch=104
05/22/2022 12:28:03 - INFO - __main__ - Step 2950 Global step 2950 Train loss 0.04 on epoch=105
05/22/2022 12:28:15 - INFO - __main__ - Global step 2950 Train loss 0.04 Classification-F1 0.7224631199765609 on epoch=105
05/22/2022 12:28:18 - INFO - __main__ - Step 2960 Global step 2960 Train loss 0.04 on epoch=105
05/22/2022 12:28:20 - INFO - __main__ - Step 2970 Global step 2970 Train loss 0.04 on epoch=106
05/22/2022 12:28:23 - INFO - __main__ - Step 2980 Global step 2980 Train loss 0.02 on epoch=106
05/22/2022 12:28:26 - INFO - __main__ - Step 2990 Global step 2990 Train loss 0.03 on epoch=106
05/22/2022 12:28:28 - INFO - __main__ - Step 3000 Global step 3000 Train loss 0.05 on epoch=107
05/22/2022 12:28:40 - INFO - __main__ - Global step 3000 Train loss 0.04 Classification-F1 0.7239632975039554 on epoch=107
05/22/2022 12:28:40 - INFO - __main__ - save last model!
05/22/2022 12:28:40 - INFO - __main__ - Loading checkpoint from best ckpt on the fly
05/22/2022 12:28:40 - INFO - __main__ - Start tokenizing ... 3500 instances
05/22/2022 12:28:40 - INFO - __main__ - Printing 3 examples
05/22/2022 12:28:40 - INFO - __main__ -  [dbpedia_14] Platymetopus is a genus of beetles in the family Carabidae containing the following species: Platymetopus brevilabris Laferte-Senectere 1853 Platymetopus colpophilus Alluaud 1918 Platymetopus congestulus Basilewsky 1948 Platymetopus crenulatus Chaudoir 1878 Platymetopus cribricollis Facchini 2004 Platymetopus curtulus (Peringuey 1908) Platymetopus cyaneus Facchini 2004 Platymetopus diversepunctatus Facchini 2004 Platymetopus figuratus Boheman 1848 Platymetopus flavilabris (Fabricius 1798) Platymetopus guineensis Dejean 1831 Platymetopus indicus Jedlicka 1969 Platymetopus interpunctatus Dejean 1829 Platymetopus keiseri Louwerens 1956 Platymetopus laevigatus Kuntzen 1919 Platymetopus laticeps Dejean 1829 Platymetopus lepidus Dejean 1829 Platymetopus ludificus (H.Kolbe 1883) Platymetopus majusculus Lorenz 1998 Platymetopus obscuripes Chaudoir 1878 Platymetopus pictus Andrewes 1923 Platymetopus platythorax Basilewsky 1948 Platymetopus quadrimaculatus Dejean 1829 Platymetopus quadrinotatus Burgeon 1936 Platymetopus rectangularis Burgeon 1936 Platymetopus rugosus (Nietner 1857) Platymetopus sakalava Jeannel 1948 Platymetopus schoenherri Dejean 1831 Platymetopus seriatus Chaudoir 1878 Platymetopus straeleni Basilewsky 1947 Platymetopus subrugosus Schauberger 1938 Platymetopus sudanicus Basilewsky 1967 Platymetopus tessellatus Dejean 1829 Platymetopus tibialis (H.Kolbe 1883) Platymetopus tritus Bates 1889 Platymetopus vestitus Dejean 1829 Platymetopus xanthographus (Alluaud 1916)↑
05/22/2022 12:28:40 - INFO - __main__ - ['Animal']
05/22/2022 12:28:40 - INFO - __main__ -  [dbpedia_14] Sicera is a genus of moth in the family Gelechiidae.
05/22/2022 12:28:40 - INFO - __main__ - ['Animal']
05/22/2022 12:28:40 - INFO - __main__ -  [dbpedia_14] Strzeczonka [stʂɛˈt͡ʂɔnka] is a village in the administrative district of Gmina Debrzno within Człuchów County Pomeranian Voivodeship in northern Poland. It lies approximately 7 kilometres (4 mi) north-west of Debrzno 16 km (10 mi) south-west of Człuchów and 130 km (81 mi) south-west of the regional capital Gdańsk.For details of the history of the region see History of Pomerania.
05/22/2022 12:28:40 - INFO - __main__ - ['Village']
05/22/2022 12:28:40 - INFO - __main__ - Tokenizing Input ...
05/22/2022 12:28:42 - INFO - __main__ - Tokenizing Output ...
05/22/2022 12:28:46 - INFO - __main__ - Loaded 3500 examples from test data
05/22/2022 12:30:40 - INFO - __main__ - Saved prediction in models/T5-large-multitask-cls2cls-5e-1-4-20-down32shot/singletask-dbpedia_14/dbpedia_14_32_87_0.2_8_predictions.txt
05/22/2022 12:30:40 - INFO - __main__ - Classification-F1 on test data: 0.5139
05/22/2022 12:30:40 - INFO - __main__ - prefix=dbpedia_14_32_87, lr=0.2, bsz=8, dev_performance=0.8328386590459647, test_performance=0.5138708512443594
