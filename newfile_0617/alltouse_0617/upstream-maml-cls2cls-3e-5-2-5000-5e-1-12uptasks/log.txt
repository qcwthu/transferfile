05/27/2022 15:06:14 - INFO - __main__ - Namespace(train_dir='data', predict_dir='data', identifier='large', output_dir='models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks', do_train=True, do_predict=False, inner_bsz=2, inner_lr=3e-05, checkpoint=None, do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=64, num_beams=4, append_another_bos=False, train_batch_size=1, predict_batch_size=1, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=2, num_train_epochs=120.0, warmup_steps=360, total_steps=5000, wait_step=10000000000, verbose=False, eval_period=10, prefix='', debug=False, seed=42, custom_tasks_splits='./dataloader/custom_tasks_splits/train_classification_test_classification_12uptasks.json', cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=-1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=100, cuda='0')
05/27/2022 15:06:14 - INFO - __main__ - models/upstream-maml-cls2cls-3e-5-2-5000-5e-1-12uptasks
05/27/2022 15:06:14 - INFO - __main__ - args.device: cuda
05/27/2022 15:06:14 - INFO - __main__ - Using 1 gpus
05/27/2022 15:06:15 - INFO - __main__ - Training on the following tasks: ['superglue-rte', 'tweet_eval-sentiment', 'discovery', 'glue-rte', 'hatexplain', 'glue-cola', 'health_fact', 'glue-mnli', 'imdb', 'ethos-disability', 'glue-wnli', 'scitail']
05/27/2022 15:06:15 - INFO - __main__ - Start tokenizing ... 60 instances
05/27/2022 15:06:15 - INFO - __main__ - Printing 3 examples
05/27/2022 15:06:15 - INFO - __main__ -  [discovery] sentence 1: That doesn't even happen in mainstream publishing. [SEP] sentence 2: While self-publishing is a good alternative for some writers, going outside of the system lets publishing off the hook.
05/27/2022 15:06:15 - INFO - __main__ -  finally,
05/27/2022 15:06:15 - INFO - __main__ -  [discovery] sentence 1: She modulates her tone and pace to keep listeners engaged, creating believable and distinguished character voices. [SEP] sentence 2: Campbell invokes Maine accents sparingly-using them only when the text demands it and successfully avoiding the trap of caricature.
05/27/2022 15:06:15 - INFO - __main__ -  finally,
05/27/2022 15:06:15 - INFO - __main__ -  [discovery] sentence 1: I will keep you informed. [SEP] sentence 2: I will never forget I am a servant of the people who have placed their trust in me.
05/27/2022 15:06:15 - INFO - __main__ -  finally,
05/27/2022 15:06:15 - INFO - __main__ - Tokenizing Train Input ...
05/27/2022 15:06:23 - INFO - __main__ - Tokenizing Train Output ...
05/27/2022 15:06:28 - INFO - __main__ - Tokenizing Dev Input ...
05/27/2022 15:06:36 - INFO - __main__ - Tokenizing Dev Output ...
05/27/2022 15:07:00 - INFO - __main__ - Loaded 60 examples from train data
05/27/2022 15:07:19 - INFO - __main__ - try to initialize prompt embeddings
05/27/2022 15:07:24 - INFO - __main__ - Starting training!
05/27/2022 15:07:47 - INFO - __main__ - global step: 10; train loss: 7.211672782897949; dev loss: 7.082781791687012
05/27/2022 15:08:09 - INFO - __main__ - global step: 20; train loss: 5.351564884185791; dev loss: 5.0403947830200195
05/27/2022 15:08:31 - INFO - __main__ - global step: 30; train loss: 3.4712061882019043; dev loss: 3.6050899028778076
05/27/2022 15:08:53 - INFO - __main__ - global step: 40; train loss: 2.9668352603912354; dev loss: 2.8230323791503906
05/27/2022 15:09:14 - INFO - __main__ - global step: 50; train loss: 2.8711676597595215; dev loss: 2.4213242530822754
05/27/2022 15:09:36 - INFO - __main__ - global step: 60; train loss: 2.6367766857147217; dev loss: 3.0821075439453125
05/27/2022 15:09:58 - INFO - __main__ - global step: 70; train loss: 2.1009552478790283; dev loss: 2.2470879554748535
05/27/2022 15:10:20 - INFO - __main__ - global step: 80; train loss: 2.2553138732910156; dev loss: 2.110147476196289
05/27/2022 15:10:42 - INFO - __main__ - global step: 90; train loss: 2.2554125785827637; dev loss: 1.9666677713394165
05/27/2022 15:11:04 - INFO - __main__ - global step: 100; train loss: 1.7775777578353882; dev loss: 1.798284888267517
05/27/2022 15:11:26 - INFO - __main__ - global step: 110; train loss: 1.8087173700332642; dev loss: 2.1882107257843018
05/27/2022 15:11:48 - INFO - __main__ - global step: 120; train loss: 2.340221881866455; dev loss: 1.9104845523834229
05/27/2022 15:12:10 - INFO - __main__ - global step: 130; train loss: 1.7089732885360718; dev loss: 1.7348829507827759
05/27/2022 15:12:32 - INFO - __main__ - global step: 140; train loss: 1.9874846935272217; dev loss: 1.9408245086669922
05/27/2022 15:12:54 - INFO - __main__ - global step: 150; train loss: 2.2547695636749268; dev loss: 2.097534656524658
05/27/2022 15:13:16 - INFO - __main__ - global step: 160; train loss: 1.3514864444732666; dev loss: 1.4487169981002808
05/27/2022 15:13:38 - INFO - __main__ - global step: 170; train loss: 1.9216350317001343; dev loss: 1.7744216918945312
05/27/2022 15:13:59 - INFO - __main__ - global step: 180; train loss: 2.764444589614868; dev loss: 2.4691643714904785
05/27/2022 15:14:21 - INFO - __main__ - global step: 190; train loss: 4.119754314422607; dev loss: 3.9340057373046875
05/27/2022 15:14:43 - INFO - __main__ - global step: 200; train loss: 2.5832369327545166; dev loss: 2.5848007202148438
05/27/2022 15:15:05 - INFO - __main__ - global step: 210; train loss: 1.724663496017456; dev loss: 1.4836370944976807
05/27/2022 15:15:27 - INFO - __main__ - global step: 220; train loss: 2.070673942565918; dev loss: 2.0274295806884766
05/27/2022 15:15:49 - INFO - __main__ - global step: 230; train loss: 1.7379915714263916; dev loss: 1.8337287902832031
05/27/2022 15:16:11 - INFO - __main__ - global step: 240; train loss: 1.489215612411499; dev loss: 1.7687504291534424
05/27/2022 15:16:33 - INFO - __main__ - global step: 250; train loss: 1.6489368677139282; dev loss: 1.7502256631851196
05/27/2022 15:16:55 - INFO - __main__ - global step: 260; train loss: 1.8879106044769287; dev loss: 1.645308256149292
05/27/2022 15:17:17 - INFO - __main__ - global step: 270; train loss: 2.195431709289551; dev loss: 2.015728235244751
05/27/2022 15:17:39 - INFO - __main__ - global step: 280; train loss: 1.7823301553726196; dev loss: 1.6709234714508057
05/27/2022 15:18:01 - INFO - __main__ - global step: 290; train loss: 1.6582117080688477; dev loss: 1.4461033344268799
05/27/2022 15:18:23 - INFO - __main__ - global step: 300; train loss: 2.0389199256896973; dev loss: 1.8773151636123657
05/27/2022 15:18:45 - INFO - __main__ - global step: 310; train loss: 2.031287670135498; dev loss: 2.436591625213623
05/27/2022 15:19:07 - INFO - __main__ - global step: 320; train loss: 1.4877688884735107; dev loss: 1.7412645816802979
05/27/2022 15:19:29 - INFO - __main__ - global step: 330; train loss: 1.6568212509155273; dev loss: 1.4682137966156006
05/27/2022 15:19:51 - INFO - __main__ - global step: 340; train loss: 1.5579906702041626; dev loss: 1.4927464723587036
05/27/2022 15:20:13 - INFO - __main__ - global step: 350; train loss: 2.0005908012390137; dev loss: 1.959580421447754
05/27/2022 15:20:34 - INFO - __main__ - global step: 360; train loss: 1.870967149734497; dev loss: 1.9393961429595947
05/27/2022 15:20:56 - INFO - __main__ - global step: 370; train loss: 1.5722142457962036; dev loss: 1.5140107870101929
05/27/2022 15:21:18 - INFO - __main__ - global step: 380; train loss: 1.4321715831756592; dev loss: 1.5770548582077026
05/27/2022 15:21:40 - INFO - __main__ - global step: 390; train loss: 2.0371203422546387; dev loss: 1.789208173751831
05/27/2022 15:22:02 - INFO - __main__ - global step: 400; train loss: 2.0363352298736572; dev loss: 1.875006079673767
05/27/2022 15:22:24 - INFO - __main__ - global step: 410; train loss: 1.5270600318908691; dev loss: 1.5856353044509888
05/27/2022 15:22:46 - INFO - __main__ - global step: 420; train loss: 1.6545794010162354; dev loss: 1.5161982774734497
05/27/2022 15:23:08 - INFO - __main__ - global step: 430; train loss: 1.467372179031372; dev loss: 1.5205096006393433
05/27/2022 15:23:30 - INFO - __main__ - global step: 440; train loss: 1.767727255821228; dev loss: 1.6472793817520142
05/27/2022 15:23:52 - INFO - __main__ - global step: 450; train loss: 1.739771842956543; dev loss: 2.130502223968506
05/27/2022 15:24:14 - INFO - __main__ - global step: 460; train loss: 1.5925017595291138; dev loss: 1.5357271432876587
05/27/2022 15:24:36 - INFO - __main__ - global step: 470; train loss: 2.0165445804595947; dev loss: 1.92521071434021
05/27/2022 15:24:57 - INFO - __main__ - global step: 480; train loss: 1.7087700366973877; dev loss: 1.6124576330184937
05/27/2022 15:25:19 - INFO - __main__ - global step: 490; train loss: 1.7763664722442627; dev loss: 1.6750967502593994
05/27/2022 15:25:41 - INFO - __main__ - global step: 500; train loss: 1.6636463403701782; dev loss: 1.7720048427581787
05/27/2022 15:26:03 - INFO - __main__ - global step: 510; train loss: 1.6527831554412842; dev loss: 1.6423813104629517
05/27/2022 15:26:25 - INFO - __main__ - global step: 520; train loss: 1.78224778175354; dev loss: 1.6446123123168945
05/27/2022 15:26:47 - INFO - __main__ - global step: 530; train loss: 1.668466567993164; dev loss: 1.5792254209518433
05/27/2022 15:27:09 - INFO - __main__ - global step: 540; train loss: 1.681031584739685; dev loss: 1.7602484226226807
05/27/2022 15:27:31 - INFO - __main__ - global step: 550; train loss: 1.7063812017440796; dev loss: 1.756303071975708
05/27/2022 15:27:53 - INFO - __main__ - global step: 560; train loss: 1.4677940607070923; dev loss: 1.4546743631362915
05/27/2022 15:28:15 - INFO - __main__ - global step: 570; train loss: 1.6405216455459595; dev loss: 1.698259949684143
05/27/2022 15:28:37 - INFO - __main__ - global step: 580; train loss: 1.9173457622528076; dev loss: 1.8529605865478516
05/27/2022 15:28:59 - INFO - __main__ - global step: 590; train loss: 1.528868556022644; dev loss: 1.3771904706954956
05/27/2022 15:29:21 - INFO - __main__ - global step: 600; train loss: 1.3742808103561401; dev loss: 1.590097427368164
05/27/2022 15:29:42 - INFO - __main__ - global step: 610; train loss: 1.4632880687713623; dev loss: 1.6109657287597656
05/27/2022 15:30:04 - INFO - __main__ - global step: 620; train loss: 1.445406436920166; dev loss: 1.4540094137191772
05/27/2022 15:30:26 - INFO - __main__ - global step: 630; train loss: 1.689518928527832; dev loss: 1.7574456930160522
05/27/2022 15:30:48 - INFO - __main__ - global step: 640; train loss: 1.6639779806137085; dev loss: 1.8769785165786743
05/27/2022 15:31:10 - INFO - __main__ - global step: 650; train loss: 1.5082964897155762; dev loss: 1.3299142122268677
05/27/2022 15:31:32 - INFO - __main__ - global step: 660; train loss: 1.5910398960113525; dev loss: 1.7627990245819092
05/27/2022 15:31:54 - INFO - __main__ - global step: 670; train loss: 1.6628433465957642; dev loss: 1.6078729629516602
05/27/2022 15:32:16 - INFO - __main__ - global step: 680; train loss: 1.390211820602417; dev loss: 1.4042245149612427
05/27/2022 15:32:38 - INFO - __main__ - global step: 690; train loss: 1.5646626949310303; dev loss: 1.5004651546478271
05/27/2022 15:33:00 - INFO - __main__ - global step: 700; train loss: 1.6212186813354492; dev loss: 1.586963415145874
05/27/2022 15:33:22 - INFO - __main__ - global step: 710; train loss: 1.450490117073059; dev loss: 1.5030285120010376
05/27/2022 15:33:44 - INFO - __main__ - global step: 720; train loss: 1.533942461013794; dev loss: 1.3317114114761353
05/27/2022 15:34:05 - INFO - __main__ - global step: 730; train loss: 1.637028455734253; dev loss: 1.5480371713638306
05/27/2022 15:34:27 - INFO - __main__ - global step: 740; train loss: 1.3828359842300415; dev loss: 1.4265615940093994
05/27/2022 15:34:49 - INFO - __main__ - global step: 750; train loss: 1.5267258882522583; dev loss: 1.504225730895996
05/27/2022 15:35:12 - INFO - __main__ - global step: 760; train loss: 1.5101807117462158; dev loss: 1.259975552558899
05/27/2022 15:35:34 - INFO - __main__ - global step: 770; train loss: 1.7957055568695068; dev loss: 1.7008177042007446
05/27/2022 15:35:56 - INFO - __main__ - global step: 780; train loss: 1.446616291999817; dev loss: 1.4416601657867432
05/27/2022 15:36:17 - INFO - __main__ - global step: 790; train loss: 1.5741908550262451; dev loss: 1.514484167098999
05/27/2022 15:36:39 - INFO - __main__ - global step: 800; train loss: 1.4450187683105469; dev loss: 1.4502168893814087
05/27/2022 15:37:01 - INFO - __main__ - global step: 810; train loss: 1.569680094718933; dev loss: 1.461135745048523
05/27/2022 15:37:23 - INFO - __main__ - global step: 820; train loss: 1.727269172668457; dev loss: 1.5870907306671143
05/27/2022 15:37:45 - INFO - __main__ - global step: 830; train loss: 1.542565107345581; dev loss: 1.6451466083526611
05/27/2022 15:38:07 - INFO - __main__ - global step: 840; train loss: 1.236541986465454; dev loss: 1.2444067001342773
05/27/2022 15:38:29 - INFO - __main__ - global step: 850; train loss: 1.4200127124786377; dev loss: 1.5522148609161377
05/27/2022 15:38:51 - INFO - __main__ - global step: 860; train loss: 1.572487235069275; dev loss: 1.580283522605896
05/27/2022 15:39:13 - INFO - __main__ - global step: 870; train loss: 1.545549750328064; dev loss: 1.434478998184204
05/27/2022 15:39:35 - INFO - __main__ - global step: 880; train loss: 1.3048465251922607; dev loss: 1.3872249126434326
05/27/2022 15:39:58 - INFO - __main__ - global step: 890; train loss: 1.9002892971038818; dev loss: 1.756742238998413
05/27/2022 15:40:19 - INFO - __main__ - global step: 900; train loss: 1.3083415031433105; dev loss: 1.4286690950393677
05/27/2022 15:40:41 - INFO - __main__ - global step: 910; train loss: 1.415065884590149; dev loss: 1.306863784790039
05/27/2022 15:41:03 - INFO - __main__ - global step: 920; train loss: 1.7840921878814697; dev loss: 1.683924913406372
05/27/2022 15:41:25 - INFO - __main__ - global step: 930; train loss: 1.5076572895050049; dev loss: 1.6573734283447266
05/27/2022 15:41:47 - INFO - __main__ - global step: 940; train loss: 1.5679417848587036; dev loss: 1.4870277643203735
05/27/2022 15:42:09 - INFO - __main__ - global step: 950; train loss: 1.5465679168701172; dev loss: 1.5798524618148804
05/27/2022 15:42:31 - INFO - __main__ - global step: 960; train loss: 1.2684128284454346; dev loss: 1.3226757049560547
05/27/2022 15:42:53 - INFO - __main__ - global step: 970; train loss: 1.3246415853500366; dev loss: 1.4465811252593994
05/27/2022 15:43:15 - INFO - __main__ - global step: 980; train loss: 1.5533933639526367; dev loss: 1.6383882761001587
05/27/2022 15:43:37 - INFO - __main__ - global step: 990; train loss: 1.653800368309021; dev loss: 1.4367437362670898
05/27/2022 15:43:59 - INFO - __main__ - global step: 1000; train loss: 1.759265661239624; dev loss: 1.496016263961792
05/27/2022 15:44:21 - INFO - __main__ - global step: 1010; train loss: 1.0947635173797607; dev loss: 1.052379846572876
05/27/2022 15:44:43 - INFO - __main__ - global step: 1020; train loss: 1.562187910079956; dev loss: 1.677006721496582
05/27/2022 15:45:05 - INFO - __main__ - global step: 1030; train loss: 1.5529627799987793; dev loss: 1.3715784549713135
05/27/2022 15:45:27 - INFO - __main__ - global step: 1040; train loss: 1.3584400415420532; dev loss: 1.3812930583953857
05/27/2022 15:45:49 - INFO - __main__ - global step: 1050; train loss: 1.535496711730957; dev loss: 1.6219332218170166
05/27/2022 15:46:11 - INFO - __main__ - global step: 1060; train loss: 1.2736788988113403; dev loss: 1.3640334606170654
05/27/2022 15:46:33 - INFO - __main__ - global step: 1070; train loss: 1.5784608125686646; dev loss: 1.6046546697616577
05/27/2022 15:46:55 - INFO - __main__ - global step: 1080; train loss: 1.6327407360076904; dev loss: 1.6106462478637695
05/27/2022 15:47:17 - INFO - __main__ - global step: 1090; train loss: 1.0907175540924072; dev loss: 1.0741095542907715
05/27/2022 15:47:39 - INFO - __main__ - global step: 1100; train loss: 1.5404263734817505; dev loss: 1.3650891780853271
05/27/2022 15:48:01 - INFO - __main__ - global step: 1110; train loss: 1.708788275718689; dev loss: 1.6037088632583618
05/27/2022 15:48:23 - INFO - __main__ - global step: 1120; train loss: 1.430754542350769; dev loss: 1.461430311203003
05/27/2022 15:48:44 - INFO - __main__ - global step: 1130; train loss: 1.2619829177856445; dev loss: 1.2174617052078247
05/27/2022 15:49:06 - INFO - __main__ - global step: 1140; train loss: 1.6351678371429443; dev loss: 1.512941837310791
05/27/2022 15:49:28 - INFO - __main__ - global step: 1150; train loss: 1.4468495845794678; dev loss: 1.6293636560440063
05/27/2022 15:49:50 - INFO - __main__ - global step: 1160; train loss: 1.2567980289459229; dev loss: 1.3715492486953735
05/27/2022 15:50:12 - INFO - __main__ - global step: 1170; train loss: 1.6497160196304321; dev loss: 1.6158874034881592
05/27/2022 15:50:34 - INFO - __main__ - global step: 1180; train loss: 1.7260119915008545; dev loss: 1.362898826599121
05/27/2022 15:50:56 - INFO - __main__ - global step: 1190; train loss: 1.6563701629638672; dev loss: 1.481673240661621
05/27/2022 15:51:19 - INFO - __main__ - global step: 1200; train loss: 1.1716667413711548; dev loss: 1.251291275024414
05/27/2022 15:51:40 - INFO - __main__ - global step: 1210; train loss: 1.8018369674682617; dev loss: 1.802147626876831
05/27/2022 15:52:03 - INFO - __main__ - global step: 1220; train loss: 1.1596190929412842; dev loss: 1.2677243947982788
05/27/2022 15:52:24 - INFO - __main__ - global step: 1230; train loss: 1.35858952999115; dev loss: 1.3274089097976685
05/27/2022 15:52:46 - INFO - __main__ - global step: 1240; train loss: 1.373389720916748; dev loss: 1.457440972328186
05/27/2022 15:53:08 - INFO - __main__ - global step: 1250; train loss: 1.407867431640625; dev loss: 1.4877692461013794
05/27/2022 15:53:30 - INFO - __main__ - global step: 1260; train loss: 1.328960657119751; dev loss: 1.3063145875930786
05/27/2022 15:53:52 - INFO - __main__ - global step: 1270; train loss: 1.313639521598816; dev loss: 1.3537938594818115
05/27/2022 15:54:14 - INFO - __main__ - global step: 1280; train loss: 1.4888453483581543; dev loss: 1.4320247173309326
05/27/2022 15:54:36 - INFO - __main__ - global step: 1290; train loss: 1.525665283203125; dev loss: 1.3641984462738037
05/27/2022 15:54:58 - INFO - __main__ - global step: 1300; train loss: 1.3466191291809082; dev loss: 1.5191924571990967
05/27/2022 15:55:20 - INFO - __main__ - global step: 1310; train loss: 1.1997449398040771; dev loss: 1.2156503200531006
05/27/2022 15:55:42 - INFO - __main__ - global step: 1320; train loss: 1.6958096027374268; dev loss: 1.6654958724975586
05/27/2022 15:56:04 - INFO - __main__ - global step: 1330; train loss: 1.417897343635559; dev loss: 1.5023809671401978
05/27/2022 15:56:26 - INFO - __main__ - global step: 1340; train loss: 1.2678778171539307; dev loss: 1.355322241783142
05/27/2022 15:56:48 - INFO - __main__ - global step: 1350; train loss: 1.310964584350586; dev loss: 1.3660991191864014
05/27/2022 15:57:10 - INFO - __main__ - global step: 1360; train loss: 1.2172294855117798; dev loss: 1.2895513772964478
05/27/2022 15:57:32 - INFO - __main__ - global step: 1370; train loss: 1.5169503688812256; dev loss: 1.601989984512329
05/27/2022 15:57:54 - INFO - __main__ - global step: 1380; train loss: 1.5566399097442627; dev loss: 1.3331358432769775
05/27/2022 15:58:16 - INFO - __main__ - global step: 1390; train loss: 1.2328084707260132; dev loss: 1.2255988121032715
05/27/2022 15:58:38 - INFO - __main__ - global step: 1400; train loss: 1.4028432369232178; dev loss: 1.3379679918289185
05/27/2022 15:59:00 - INFO - __main__ - global step: 1410; train loss: 1.517204999923706; dev loss: 1.5016478300094604
05/27/2022 15:59:22 - INFO - __main__ - global step: 1420; train loss: 1.2538502216339111; dev loss: 1.2439074516296387
05/27/2022 15:59:44 - INFO - __main__ - global step: 1430; train loss: 1.4078083038330078; dev loss: 1.5133904218673706
05/27/2022 16:00:06 - INFO - __main__ - global step: 1440; train loss: 1.5208299160003662; dev loss: 1.623621940612793
05/27/2022 16:00:28 - INFO - __main__ - global step: 1450; train loss: 1.3610165119171143; dev loss: 1.2578473091125488
05/27/2022 16:00:50 - INFO - __main__ - global step: 1460; train loss: 1.3195018768310547; dev loss: 1.3711742162704468
05/27/2022 16:01:11 - INFO - __main__ - global step: 1470; train loss: 1.444234848022461; dev loss: 1.530037522315979
05/27/2022 16:01:33 - INFO - __main__ - global step: 1480; train loss: 1.3092812299728394; dev loss: 1.4687285423278809
05/27/2022 16:01:55 - INFO - __main__ - global step: 1490; train loss: 1.396673321723938; dev loss: 1.321225881576538
05/27/2022 16:02:18 - INFO - __main__ - global step: 1500; train loss: 1.44483482837677; dev loss: 1.4358961582183838
05/27/2022 16:02:40 - INFO - __main__ - global step: 1510; train loss: 1.413753867149353; dev loss: 1.528113603591919
05/27/2022 16:03:02 - INFO - __main__ - global step: 1520; train loss: 1.397812008857727; dev loss: 1.535156488418579
05/27/2022 16:03:24 - INFO - __main__ - global step: 1530; train loss: 1.3035287857055664; dev loss: 1.5271399021148682
05/27/2022 16:03:46 - INFO - __main__ - global step: 1540; train loss: 1.3739941120147705; dev loss: 1.6108415126800537
05/27/2022 16:04:08 - INFO - __main__ - global step: 1550; train loss: 1.2926712036132812; dev loss: 1.4472217559814453
05/27/2022 16:04:30 - INFO - __main__ - global step: 1560; train loss: 1.2753288745880127; dev loss: 1.2053494453430176
05/27/2022 16:04:52 - INFO - __main__ - global step: 1570; train loss: 1.38865065574646; dev loss: 1.6507850885391235
05/27/2022 16:05:13 - INFO - __main__ - global step: 1580; train loss: 1.5171244144439697; dev loss: 1.2372578382492065
05/27/2022 16:05:35 - INFO - __main__ - global step: 1590; train loss: 1.1414662599563599; dev loss: 1.2492268085479736
05/27/2022 16:05:57 - INFO - __main__ - global step: 1600; train loss: 1.5793259143829346; dev loss: 1.449622631072998
05/27/2022 16:06:19 - INFO - __main__ - global step: 1610; train loss: 1.0642688274383545; dev loss: 1.0939512252807617
05/27/2022 16:06:41 - INFO - __main__ - global step: 1620; train loss: 1.5107405185699463; dev loss: 1.6457483768463135
05/27/2022 16:07:03 - INFO - __main__ - global step: 1630; train loss: 1.2599709033966064; dev loss: 1.1284117698669434
05/27/2022 16:07:25 - INFO - __main__ - global step: 1640; train loss: 1.5415436029434204; dev loss: 1.478785514831543
05/27/2022 16:07:47 - INFO - __main__ - global step: 1650; train loss: 1.5268641710281372; dev loss: 1.4566819667816162
05/27/2022 16:08:09 - INFO - __main__ - global step: 1660; train loss: 1.3740874528884888; dev loss: 1.2236459255218506
05/27/2022 16:08:31 - INFO - __main__ - global step: 1670; train loss: 1.2341880798339844; dev loss: 1.3290234804153442
05/27/2022 16:08:53 - INFO - __main__ - global step: 1680; train loss: 1.5546187162399292; dev loss: 1.473462462425232
05/27/2022 16:09:15 - INFO - __main__ - global step: 1690; train loss: 1.539734125137329; dev loss: 1.4093583822250366
05/27/2022 16:09:37 - INFO - __main__ - global step: 1700; train loss: 1.3645373582839966; dev loss: 1.510309100151062
05/27/2022 16:09:58 - INFO - __main__ - global step: 1710; train loss: 1.1575658321380615; dev loss: 1.2660473585128784
05/27/2022 16:10:20 - INFO - __main__ - global step: 1720; train loss: 1.5452771186828613; dev loss: 1.4648081064224243
05/27/2022 16:10:42 - INFO - __main__ - global step: 1730; train loss: 1.12337327003479; dev loss: 1.260296106338501
05/27/2022 16:11:04 - INFO - __main__ - global step: 1740; train loss: 1.245481252670288; dev loss: 1.076111912727356
05/27/2022 16:11:26 - INFO - __main__ - global step: 1750; train loss: 1.5681356191635132; dev loss: 1.7544724941253662
05/27/2022 16:11:48 - INFO - __main__ - global step: 1760; train loss: 1.4986684322357178; dev loss: 1.4316835403442383
05/27/2022 16:12:10 - INFO - __main__ - global step: 1770; train loss: 1.1617085933685303; dev loss: 1.2029998302459717
05/27/2022 16:12:32 - INFO - __main__ - global step: 1780; train loss: 1.167866826057434; dev loss: 1.0158027410507202
05/27/2022 16:12:54 - INFO - __main__ - global step: 1790; train loss: 1.2922496795654297; dev loss: 1.3290207386016846
05/27/2022 16:13:16 - INFO - __main__ - global step: 1800; train loss: 1.655521035194397; dev loss: 1.7763502597808838
05/27/2022 16:13:38 - INFO - __main__ - global step: 1810; train loss: 1.5358469486236572; dev loss: 1.5592927932739258
05/27/2022 16:14:00 - INFO - __main__ - global step: 1820; train loss: 1.2772117853164673; dev loss: 1.2730491161346436
05/27/2022 16:14:22 - INFO - __main__ - global step: 1830; train loss: 1.1165603399276733; dev loss: 1.1467386484146118
05/27/2022 16:14:44 - INFO - __main__ - global step: 1840; train loss: 1.3306639194488525; dev loss: 1.1690623760223389
05/27/2022 16:15:06 - INFO - __main__ - global step: 1850; train loss: 1.5404912233352661; dev loss: 1.3920623064041138
05/27/2022 16:15:28 - INFO - __main__ - global step: 1860; train loss: 1.2650158405303955; dev loss: 1.3012748956680298
05/27/2022 16:15:50 - INFO - __main__ - global step: 1870; train loss: 1.4539930820465088; dev loss: 1.316481351852417
05/27/2022 16:16:12 - INFO - __main__ - global step: 1880; train loss: 1.4171876907348633; dev loss: 1.4049996137619019
05/27/2022 16:16:34 - INFO - __main__ - global step: 1890; train loss: 1.3716630935668945; dev loss: 1.1729955673217773
05/27/2022 16:16:56 - INFO - __main__ - global step: 1900; train loss: 1.1889235973358154; dev loss: 1.3045599460601807
05/27/2022 16:17:18 - INFO - __main__ - global step: 1910; train loss: 1.5206191539764404; dev loss: 1.56834876537323
05/27/2022 16:17:40 - INFO - __main__ - global step: 1920; train loss: 1.267886996269226; dev loss: 1.2603453397750854
05/27/2022 16:18:02 - INFO - __main__ - global step: 1930; train loss: 1.4392597675323486; dev loss: 1.3471087217330933
05/27/2022 16:18:24 - INFO - __main__ - global step: 1940; train loss: 1.1801118850708008; dev loss: 1.1916444301605225
05/27/2022 16:18:46 - INFO - __main__ - global step: 1950; train loss: 1.562842845916748; dev loss: 1.4262572526931763
05/27/2022 16:19:08 - INFO - __main__ - global step: 1960; train loss: 1.152288556098938; dev loss: 1.1151431798934937
05/27/2022 16:19:30 - INFO - __main__ - global step: 1970; train loss: 1.141412615776062; dev loss: 1.1028515100479126
05/27/2022 16:19:52 - INFO - __main__ - global step: 1980; train loss: 1.4992167949676514; dev loss: 1.6502565145492554
05/27/2022 16:20:14 - INFO - __main__ - global step: 1990; train loss: 0.9133390188217163; dev loss: 0.9968976974487305
05/27/2022 16:20:36 - INFO - __main__ - global step: 2000; train loss: 1.171090841293335; dev loss: 1.1657207012176514
05/27/2022 16:20:58 - INFO - __main__ - global step: 2010; train loss: 1.9291818141937256; dev loss: 1.6940215826034546
05/27/2022 16:21:20 - INFO - __main__ - global step: 2020; train loss: 1.1535407304763794; dev loss: 1.190580129623413
05/27/2022 16:21:42 - INFO - __main__ - global step: 2030; train loss: 1.1153501272201538; dev loss: 1.1508848667144775
05/27/2022 16:22:04 - INFO - __main__ - global step: 2040; train loss: 1.3401124477386475; dev loss: 1.444991946220398
05/27/2022 16:22:26 - INFO - __main__ - global step: 2050; train loss: 1.2283962965011597; dev loss: 1.1965866088867188
05/27/2022 16:22:48 - INFO - __main__ - global step: 2060; train loss: 1.3787959814071655; dev loss: 1.384262204170227
05/27/2022 16:23:10 - INFO - __main__ - global step: 2070; train loss: 1.2889888286590576; dev loss: 1.2709625959396362
05/27/2022 16:23:32 - INFO - __main__ - global step: 2080; train loss: 1.229209303855896; dev loss: 1.312121868133545
05/27/2022 16:23:54 - INFO - __main__ - global step: 2090; train loss: 1.53278648853302; dev loss: 1.5443412065505981
05/27/2022 16:24:16 - INFO - __main__ - global step: 2100; train loss: 1.1399164199829102; dev loss: 1.049494981765747
05/27/2022 16:24:38 - INFO - __main__ - global step: 2110; train loss: 0.8736376762390137; dev loss: 0.8387231826782227
05/27/2022 16:25:00 - INFO - __main__ - global step: 2120; train loss: 1.5488197803497314; dev loss: 1.8718969821929932
05/27/2022 16:25:22 - INFO - __main__ - global step: 2130; train loss: 1.2321621179580688; dev loss: 1.324401617050171
05/27/2022 16:25:44 - INFO - __main__ - global step: 2140; train loss: 1.5555617809295654; dev loss: 1.419703483581543
05/27/2022 16:26:06 - INFO - __main__ - global step: 2150; train loss: 1.0708072185516357; dev loss: 1.283339023590088
05/27/2022 16:26:28 - INFO - __main__ - global step: 2160; train loss: 1.0686674118041992; dev loss: 0.9978517293930054
05/27/2022 16:26:50 - INFO - __main__ - global step: 2170; train loss: 1.1835401058197021; dev loss: 1.1665542125701904
05/27/2022 16:27:12 - INFO - __main__ - global step: 2180; train loss: 0.9057682752609253; dev loss: 1.1831371784210205
05/27/2022 16:27:34 - INFO - __main__ - global step: 2190; train loss: 1.457959771156311; dev loss: 1.3262710571289062
05/27/2022 16:27:56 - INFO - __main__ - global step: 2200; train loss: 1.3102819919586182; dev loss: 1.329256296157837
05/27/2022 16:28:18 - INFO - __main__ - global step: 2210; train loss: 1.0687850713729858; dev loss: 1.0510658025741577
05/27/2022 16:28:40 - INFO - __main__ - global step: 2220; train loss: 1.2454626560211182; dev loss: 1.4095152616500854
05/27/2022 16:29:02 - INFO - __main__ - global step: 2230; train loss: 1.1567412614822388; dev loss: 1.1507329940795898
05/27/2022 16:29:24 - INFO - __main__ - global step: 2240; train loss: 1.221566081047058; dev loss: 1.055765151977539
05/27/2022 16:29:46 - INFO - __main__ - global step: 2250; train loss: 1.1525371074676514; dev loss: 1.4615256786346436
05/27/2022 16:30:08 - INFO - __main__ - global step: 2260; train loss: 1.469206690788269; dev loss: 1.6060978174209595
05/27/2022 16:30:30 - INFO - __main__ - global step: 2270; train loss: 1.0367398262023926; dev loss: 1.055387020111084
05/27/2022 16:30:52 - INFO - __main__ - global step: 2280; train loss: 1.1611942052841187; dev loss: 1.160045862197876
05/27/2022 16:31:14 - INFO - __main__ - global step: 2290; train loss: 1.1734756231307983; dev loss: 1.1607916355133057
05/27/2022 16:31:35 - INFO - __main__ - global step: 2300; train loss: 1.1639912128448486; dev loss: 1.1399497985839844
05/27/2022 16:31:58 - INFO - __main__ - global step: 2310; train loss: 1.4154709577560425; dev loss: 1.273020625114441
05/27/2022 16:32:19 - INFO - __main__ - global step: 2320; train loss: 1.104910969734192; dev loss: 1.020073652267456
05/27/2022 16:32:42 - INFO - __main__ - global step: 2330; train loss: 1.3488696813583374; dev loss: 1.3124380111694336
05/27/2022 16:33:04 - INFO - __main__ - global step: 2340; train loss: 1.1533317565917969; dev loss: 0.9975947141647339
05/27/2022 16:33:26 - INFO - __main__ - global step: 2350; train loss: 1.2816741466522217; dev loss: 1.1639020442962646
05/27/2022 16:33:48 - INFO - __main__ - global step: 2360; train loss: 1.125932216644287; dev loss: 1.1339079141616821
05/27/2022 16:34:11 - INFO - __main__ - global step: 2370; train loss: 1.2101515531539917; dev loss: 1.1862471103668213
05/27/2022 16:34:33 - INFO - __main__ - global step: 2380; train loss: 1.286034345626831; dev loss: 1.2353585958480835
05/27/2022 16:34:55 - INFO - __main__ - global step: 2390; train loss: 1.0781071186065674; dev loss: 1.1348016262054443
05/27/2022 16:35:17 - INFO - __main__ - global step: 2400; train loss: 1.091228723526001; dev loss: 0.9774936437606812
05/27/2022 16:35:39 - INFO - __main__ - global step: 2410; train loss: 1.0496211051940918; dev loss: 0.8285902142524719
05/27/2022 16:36:01 - INFO - __main__ - global step: 2420; train loss: 1.0259798765182495; dev loss: 0.9935781359672546
05/27/2022 16:36:23 - INFO - __main__ - global step: 2430; train loss: 1.4459728002548218; dev loss: 1.384941577911377
05/27/2022 16:36:46 - INFO - __main__ - global step: 2440; train loss: 0.9729436039924622; dev loss: 1.0354053974151611
05/27/2022 16:37:08 - INFO - __main__ - global step: 2450; train loss: 1.1816025972366333; dev loss: 1.1544710397720337
05/27/2022 16:37:30 - INFO - __main__ - global step: 2460; train loss: 1.3467246294021606; dev loss: 1.170975923538208
05/27/2022 16:37:52 - INFO - __main__ - global step: 2470; train loss: 1.0356829166412354; dev loss: 0.9036257863044739
05/27/2022 16:38:14 - INFO - __main__ - global step: 2480; train loss: 1.202185869216919; dev loss: 1.0937769412994385
05/27/2022 16:38:36 - INFO - __main__ - global step: 2490; train loss: 1.306451439857483; dev loss: 1.255281686782837
05/27/2022 16:38:57 - INFO - __main__ - global step: 2500; train loss: 1.2699545621871948; dev loss: 1.4155957698822021
05/27/2022 16:39:19 - INFO - __main__ - global step: 2510; train loss: 1.3075194358825684; dev loss: 1.1693426370620728
05/27/2022 16:39:42 - INFO - __main__ - global step: 2520; train loss: 0.7246733903884888; dev loss: 0.9141210317611694
05/27/2022 16:40:04 - INFO - __main__ - global step: 2530; train loss: 1.1153961420059204; dev loss: 1.1003435850143433
05/27/2022 16:40:26 - INFO - __main__ - global step: 2540; train loss: 1.4586718082427979; dev loss: 1.456305980682373
05/27/2022 16:40:48 - INFO - __main__ - global step: 2550; train loss: 0.8741170763969421; dev loss: 0.7160812616348267
05/27/2022 16:41:10 - INFO - __main__ - global step: 2560; train loss: 1.3525996208190918; dev loss: 1.1064332723617554
05/27/2022 16:41:32 - INFO - __main__ - global step: 2570; train loss: 1.1908892393112183; dev loss: 1.1212271451950073
05/27/2022 16:41:54 - INFO - __main__ - global step: 2580; train loss: 0.9857984781265259; dev loss: 1.0544933080673218
05/27/2022 16:42:16 - INFO - __main__ - global step: 2590; train loss: 1.2331287860870361; dev loss: 1.118117094039917
05/27/2022 16:42:38 - INFO - __main__ - global step: 2600; train loss: 1.0610990524291992; dev loss: 0.9131231307983398
05/27/2022 16:43:00 - INFO - __main__ - global step: 2610; train loss: 1.0800849199295044; dev loss: 1.4095098972320557
05/27/2022 16:43:22 - INFO - __main__ - global step: 2620; train loss: 1.354982852935791; dev loss: 1.4656862020492554
05/27/2022 16:43:44 - INFO - __main__ - global step: 2630; train loss: 1.164019227027893; dev loss: 1.2013989686965942
05/27/2022 16:44:06 - INFO - __main__ - global step: 2640; train loss: 0.8563572764396667; dev loss: 0.8722742199897766
05/27/2022 16:44:28 - INFO - __main__ - global step: 2650; train loss: 1.0618174076080322; dev loss: 1.1652483940124512
05/27/2022 16:44:50 - INFO - __main__ - global step: 2660; train loss: 1.3737503290176392; dev loss: 1.1391327381134033
05/27/2022 16:45:12 - INFO - __main__ - global step: 2670; train loss: 1.0413764715194702; dev loss: 1.023037314414978
05/27/2022 16:45:33 - INFO - __main__ - global step: 2680; train loss: 0.9676743745803833; dev loss: 0.9707938432693481
05/27/2022 16:45:55 - INFO - __main__ - global step: 2690; train loss: 0.9487062692642212; dev loss: 1.0996007919311523
05/27/2022 16:46:17 - INFO - __main__ - global step: 2700; train loss: 1.2011572122573853; dev loss: 1.4019895792007446
05/27/2022 16:46:39 - INFO - __main__ - global step: 2710; train loss: 0.877174973487854; dev loss: 0.8128234148025513
05/27/2022 16:47:01 - INFO - __main__ - global step: 2720; train loss: 1.0993306636810303; dev loss: 1.0221798419952393
05/27/2022 16:47:23 - INFO - __main__ - global step: 2730; train loss: 1.2486865520477295; dev loss: 1.4606493711471558
05/27/2022 16:47:45 - INFO - __main__ - global step: 2740; train loss: 0.9461267590522766; dev loss: 0.9760537147521973
05/27/2022 16:48:07 - INFO - __main__ - global step: 2750; train loss: 0.9538514018058777; dev loss: 1.049096703529358
05/27/2022 16:48:29 - INFO - __main__ - global step: 2760; train loss: 1.0895496606826782; dev loss: 1.0264904499053955
05/27/2022 16:48:51 - INFO - __main__ - global step: 2770; train loss: 0.9644120931625366; dev loss: 1.1513359546661377
05/27/2022 16:49:13 - INFO - __main__ - global step: 2780; train loss: 0.8493698835372925; dev loss: 1.0486527681350708
05/27/2022 16:49:35 - INFO - __main__ - global step: 2790; train loss: 1.27889084815979; dev loss: 1.1563024520874023
05/27/2022 16:49:57 - INFO - __main__ - global step: 2800; train loss: 1.0096924304962158; dev loss: 0.8987576365470886
05/27/2022 16:50:19 - INFO - __main__ - global step: 2810; train loss: 0.9743319749832153; dev loss: 1.0330601930618286
05/27/2022 16:50:41 - INFO - __main__ - global step: 2820; train loss: 1.215986967086792; dev loss: 1.1429558992385864
05/27/2022 16:51:03 - INFO - __main__ - global step: 2830; train loss: 0.9223830103874207; dev loss: 0.9009672999382019
05/27/2022 16:51:24 - INFO - __main__ - global step: 2840; train loss: 1.2058870792388916; dev loss: 1.180654764175415
05/27/2022 16:51:47 - INFO - __main__ - global step: 2850; train loss: 0.8825565576553345; dev loss: 1.0935297012329102
05/27/2022 16:52:08 - INFO - __main__ - global step: 2860; train loss: 1.1176837682724; dev loss: 1.1593290567398071
05/27/2022 16:52:30 - INFO - __main__ - global step: 2870; train loss: 0.775270938873291; dev loss: 0.8905584216117859
05/27/2022 16:52:52 - INFO - __main__ - global step: 2880; train loss: 1.1689283847808838; dev loss: 1.1296778917312622
05/27/2022 16:53:14 - INFO - __main__ - global step: 2890; train loss: 1.091369867324829; dev loss: 1.0207189321517944
05/27/2022 16:53:36 - INFO - __main__ - global step: 2900; train loss: 0.9815500378608704; dev loss: 1.083068609237671
05/27/2022 16:53:58 - INFO - __main__ - global step: 2910; train loss: 1.1154391765594482; dev loss: 1.170272946357727
05/27/2022 16:54:20 - INFO - __main__ - global step: 2920; train loss: 1.0120112895965576; dev loss: 0.8325406908988953
05/27/2022 16:54:42 - INFO - __main__ - global step: 2930; train loss: 0.9413335919380188; dev loss: 0.984277606010437
05/27/2022 16:55:04 - INFO - __main__ - global step: 2940; train loss: 1.1914101839065552; dev loss: 1.1346476078033447
05/27/2022 16:55:26 - INFO - __main__ - global step: 2950; train loss: 1.154565453529358; dev loss: 1.210216760635376
05/27/2022 16:55:48 - INFO - __main__ - global step: 2960; train loss: 0.9097062945365906; dev loss: 1.0932879447937012
05/27/2022 16:56:10 - INFO - __main__ - global step: 2970; train loss: 1.086982250213623; dev loss: 1.0499197244644165
05/27/2022 16:56:31 - INFO - __main__ - global step: 2980; train loss: 1.206710934638977; dev loss: 1.0011920928955078
05/27/2022 16:56:54 - INFO - __main__ - global step: 2990; train loss: 0.5612421631813049; dev loss: 0.6488972902297974
05/27/2022 16:57:16 - INFO - __main__ - global step: 3000; train loss: 1.2540900707244873; dev loss: 1.173412799835205
05/27/2022 16:57:38 - INFO - __main__ - global step: 3010; train loss: 0.8928509950637817; dev loss: 0.7681635022163391
05/27/2022 16:58:00 - INFO - __main__ - global step: 3020; train loss: 1.0759625434875488; dev loss: 1.1352479457855225
05/27/2022 16:58:22 - INFO - __main__ - global step: 3030; train loss: 1.3723009824752808; dev loss: 1.1587483882904053
05/27/2022 16:58:44 - INFO - __main__ - global step: 3040; train loss: 0.9379064440727234; dev loss: 0.9044912457466125
05/27/2022 16:59:05 - INFO - __main__ - global step: 3050; train loss: 0.9807652235031128; dev loss: 0.9534170031547546
05/27/2022 16:59:27 - INFO - __main__ - global step: 3060; train loss: 1.0365582704544067; dev loss: 1.0104278326034546
05/27/2022 16:59:50 - INFO - __main__ - global step: 3070; train loss: 0.9921731948852539; dev loss: 0.9459640383720398
05/27/2022 17:00:11 - INFO - __main__ - global step: 3080; train loss: 1.1427382230758667; dev loss: 1.1029062271118164
05/27/2022 17:00:33 - INFO - __main__ - global step: 3090; train loss: 1.0818827152252197; dev loss: 1.1889026165008545
05/27/2022 17:00:55 - INFO - __main__ - global step: 3100; train loss: 1.064310073852539; dev loss: 1.1901780366897583
05/27/2022 17:01:17 - INFO - __main__ - global step: 3110; train loss: 0.7120367288589478; dev loss: 0.6470652222633362
05/27/2022 17:01:39 - INFO - __main__ - global step: 3120; train loss: 1.274921178817749; dev loss: 1.1293989419937134
05/27/2022 17:02:01 - INFO - __main__ - global step: 3130; train loss: 0.9010673761367798; dev loss: 0.9784196019172668
05/27/2022 17:02:22 - INFO - __main__ - global step: 3140; train loss: 1.2964112758636475; dev loss: 1.1244549751281738
05/27/2022 17:02:45 - INFO - __main__ - global step: 3150; train loss: 1.0915205478668213; dev loss: 0.8284207582473755
05/27/2022 17:03:07 - INFO - __main__ - global step: 3160; train loss: 1.367570400238037; dev loss: 1.3260085582733154
05/27/2022 17:03:29 - INFO - __main__ - global step: 3170; train loss: 0.9721305966377258; dev loss: 0.8959289789199829
05/27/2022 17:03:51 - INFO - __main__ - global step: 3180; train loss: 0.8253675699234009; dev loss: 0.9065837860107422
05/27/2022 17:04:12 - INFO - __main__ - global step: 3190; train loss: 1.2811052799224854; dev loss: 1.127676248550415
05/27/2022 17:04:35 - INFO - __main__ - global step: 3200; train loss: 0.8684757947921753; dev loss: 0.9199366569519043
05/27/2022 17:04:56 - INFO - __main__ - global step: 3210; train loss: 1.0852450132369995; dev loss: 0.9890602231025696
05/27/2022 17:05:18 - INFO - __main__ - global step: 3220; train loss: 0.8269318342208862; dev loss: 0.9032630920410156
05/27/2022 17:05:40 - INFO - __main__ - global step: 3230; train loss: 0.8309186100959778; dev loss: 0.8431843519210815
05/27/2022 17:06:02 - INFO - __main__ - global step: 3240; train loss: 1.411106824874878; dev loss: 1.3046319484710693
05/27/2022 17:06:24 - INFO - __main__ - global step: 3250; train loss: 0.9483399391174316; dev loss: 1.1444368362426758
05/27/2022 17:06:46 - INFO - __main__ - global step: 3260; train loss: 0.9143749475479126; dev loss: 0.8640238046646118
05/27/2022 17:07:08 - INFO - __main__ - global step: 3270; train loss: 1.0897295475006104; dev loss: 1.1846965551376343
05/27/2022 17:07:30 - INFO - __main__ - global step: 3280; train loss: 1.049949049949646; dev loss: 1.084152340888977
05/27/2022 17:07:52 - INFO - __main__ - global step: 3290; train loss: 0.7669745683670044; dev loss: 0.7266539335250854
05/27/2022 17:08:14 - INFO - __main__ - global step: 3300; train loss: 1.0039613246917725; dev loss: 1.0869061946868896
05/27/2022 17:08:35 - INFO - __main__ - global step: 3310; train loss: 0.9002447128295898; dev loss: 1.1117204427719116
05/27/2022 17:08:57 - INFO - __main__ - global step: 3320; train loss: 0.835519015789032; dev loss: 0.7488272786140442
05/27/2022 17:09:19 - INFO - __main__ - global step: 3330; train loss: 1.1579105854034424; dev loss: 0.8872182965278625
05/27/2022 17:09:40 - INFO - __main__ - global step: 3340; train loss: 1.287819266319275; dev loss: 1.481886625289917
05/27/2022 17:10:02 - INFO - __main__ - global step: 3350; train loss: 0.9097398519515991; dev loss: 0.9376686215400696
05/27/2022 17:10:24 - INFO - __main__ - global step: 3360; train loss: 0.6118367910385132; dev loss: 0.7948480844497681
05/27/2022 17:10:46 - INFO - __main__ - global step: 3370; train loss: 1.0497667789459229; dev loss: 0.9880208969116211
05/27/2022 17:11:08 - INFO - __main__ - global step: 3380; train loss: 0.8717063665390015; dev loss: 0.8980979919433594
05/27/2022 17:11:29 - INFO - __main__ - global step: 3390; train loss: 1.0629944801330566; dev loss: 1.046449065208435
05/27/2022 17:11:51 - INFO - __main__ - global step: 3400; train loss: 1.1997429132461548; dev loss: 1.1718833446502686
05/27/2022 17:12:13 - INFO - __main__ - global step: 3410; train loss: 0.9158599972724915; dev loss: 0.7491966485977173
05/27/2022 17:12:35 - INFO - __main__ - global step: 3420; train loss: 0.691480815410614; dev loss: 0.7647072672843933
05/27/2022 17:12:57 - INFO - __main__ - global step: 3430; train loss: 0.8572672009468079; dev loss: 0.9366495013237
05/27/2022 17:13:18 - INFO - __main__ - global step: 3440; train loss: 0.9602965116500854; dev loss: 0.9605175852775574
05/27/2022 17:13:40 - INFO - __main__ - global step: 3450; train loss: 1.1821563243865967; dev loss: 1.0570788383483887
05/27/2022 17:14:02 - INFO - __main__ - global step: 3460; train loss: 0.8847575187683105; dev loss: 0.8324943780899048
05/27/2022 17:14:24 - INFO - __main__ - global step: 3470; train loss: 0.9749830365180969; dev loss: 0.8631571531295776
05/27/2022 17:14:46 - INFO - __main__ - global step: 3480; train loss: 0.9594147801399231; dev loss: 0.9649848937988281
05/27/2022 17:15:07 - INFO - __main__ - global step: 3490; train loss: 1.0013978481292725; dev loss: 0.9969840049743652
05/27/2022 17:15:29 - INFO - __main__ - global step: 3500; train loss: 0.8615344166755676; dev loss: 1.0581852197647095
05/27/2022 17:15:51 - INFO - __main__ - global step: 3510; train loss: 1.1312642097473145; dev loss: 0.9504135847091675
05/27/2022 17:16:12 - INFO - __main__ - global step: 3520; train loss: 0.8010419011116028; dev loss: 0.8242924809455872
05/27/2022 17:16:34 - INFO - __main__ - global step: 3530; train loss: 1.1415513753890991; dev loss: 1.1374385356903076
05/27/2022 17:16:56 - INFO - __main__ - global step: 3540; train loss: 0.7943130731582642; dev loss: 0.9233447909355164
05/27/2022 17:17:18 - INFO - __main__ - global step: 3550; train loss: 1.0800341367721558; dev loss: 1.2135584354400635
05/27/2022 17:17:39 - INFO - __main__ - global step: 3560; train loss: 0.8465719223022461; dev loss: 0.7751142382621765
05/27/2022 17:18:01 - INFO - __main__ - global step: 3570; train loss: 1.0954773426055908; dev loss: 0.9196402430534363
05/27/2022 17:18:23 - INFO - __main__ - global step: 3580; train loss: 1.0347634553909302; dev loss: 0.9556180834770203
05/27/2022 17:18:45 - INFO - __main__ - global step: 3590; train loss: 0.6795929670333862; dev loss: 0.7454149723052979
05/27/2022 17:19:07 - INFO - __main__ - global step: 3600; train loss: 1.0612907409667969; dev loss: 1.2652314901351929
05/27/2022 17:19:07 - INFO - __main__ - save model!
