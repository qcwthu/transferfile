06/17/2022 15:49:25 - INFO - __main__ - Namespace(task_dir='data/ethos-religion/', task_name='ethos-religion', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=1, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/17/2022 15:49:25 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-ethos-religion
06/17/2022 15:49:25 - INFO - __main__ - Namespace(task_dir='data/ethos-religion/', task_name='ethos-religion', identifier='T5-large-multitask-cls2cls-5e-1-4-20-200prompt', train_file='data', dev_file='data', test_file='data', dataset='nlp_forest_single', output_dir='models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-ethos-religion', do_train=True, do_predict=True, predict_checkpoint='best-model.pt', checkpoint='models/upstream-200prompt-multitask-cls2cls-5e-1-4-20/last-model.pt', do_lowercase=False, freeze_embeds=False, max_input_length=512, max_output_length=128, num_beams=4, append_another_bos=False, train_batch_size=4, predict_batch_size=16, learning_rate=0.5, weight_decay=1e-05, adam_epsilon=1e-08, max_grad_norm=1.0, gradient_accumulation_steps=1, num_train_epochs=1000.0, warmup_steps=50, total_steps=3000, wait_step=10000000000, quiet=False, eval_period=50, prefix='', debug=False, seed=42, learning_rate_list=[0.5, 0.4, 0.3, 0.2], bsz_list=[8], cache_dir='/export/share/sjoty/continual-learning/cache/', local_rank=0, log_step=10, lm_adapted_path='/export/share/sjoty/continual-learning/lm_adapted_model/torch_ckpt/large/pytorch_model.bin', model='google/t5-v1_1-large', prompt_number=200, cuda='4,5')
06/17/2022 15:49:25 - INFO - __main__ - models/T5-large-multitask-cls2cls-5e-1-4-20-200prompt/singletask-ethos-religion
06/17/2022 15:49:26 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 1
06/17/2022 15:49:26 - INFO - root - Added key: store_based_barrier_key:1 to store for rank: 0
06/17/2022 15:49:26 - INFO - __main__ - args.device: cuda:0
06/17/2022 15:49:26 - INFO - __main__ - Using 2 gpus
06/17/2022 15:49:26 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_16_100', 'ethos-religion_16_13', 'ethos-religion_16_21', 'ethos-religion_16_42', 'ethos-religion_16_87']
06/17/2022 15:49:26 - INFO - __main__ - args.device: cuda:1
06/17/2022 15:49:26 - INFO - __main__ - Using 2 gpus
06/17/2022 15:49:26 - INFO - __main__ - Fine-tuning the following samples: ['ethos-religion_16_100', 'ethos-religion_16_13', 'ethos-religion_16_21', 'ethos-religion_16_42', 'ethos-religion_16_87']
06/17/2022 15:49:31 - INFO - __main__ - Running ... prefix=ethos-religion_16_100, lr=0.5, bsz=8 ...
06/17/2022 15:49:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/17/2022 15:49:32 - INFO - __main__ - Printing 3 examples
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:49:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/17/2022 15:49:32 - INFO - __main__ - Printing 3 examples
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] If I were your dad, I'd Google "Abortions at 30 years old mentally handicapped”.
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] I liked macklemore,  not anymore , gays should fucking die motherfuckers cocksukers
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] an Asian Moe Howard piece of shit
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:49:32 - INFO - __main__ - Loaded 32 examples from train data
06/17/2022 15:49:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/17/2022 15:49:32 - INFO - __main__ - Printing 3 examples
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] Women!!! Grow a pair and refuse to compete with men!!! This is asinine!
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] Maybe it's because you're autistic?? Wish you death
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] all mental illnesses are awful and must be treated
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:49:32 - INFO - __main__ - Loaded 32 examples from train data
06/17/2022 15:49:32 - INFO - __main__ - Start tokenizing ... 32 instances
06/17/2022 15:49:32 - INFO - __main__ - Printing 3 examples
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] Women!!! Grow a pair and refuse to compete with men!!! This is asinine!
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] Maybe it's because you're autistic?? Wish you death
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ -  [ethos-religion] all mental illnesses are awful and must be treated
06/17/2022 15:49:32 - INFO - __main__ - ['false']
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Input ...
06/17/2022 15:49:32 - INFO - __main__ - Loaded 32 examples from dev data
06/17/2022 15:49:32 - INFO - __main__ - Tokenizing Output ...
06/17/2022 15:49:32 - INFO - __main__ - Loaded 32 examples from dev data
06/17/2022 15:49:49 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:49:50 - INFO - __main__ - load prompt embedding from ckpt
06/17/2022 15:49:50 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:49:50 - INFO - __main__ - Starting training!
06/17/2022 15:49:55 - INFO - root - ShardedDDP bucket size: 8.00M parameters, model size 747.07M parameters
06/17/2022 15:49:55 - INFO - __main__ - Starting training!
06/17/2022 15:49:59 - INFO - __main__ - Step 10 Global step 10 Train loss 0.50 on epoch=4
06/17/2022 15:50:01 - INFO - __main__ - Step 20 Global step 20 Train loss 0.48 on epoch=9
06/17/2022 15:50:04 - INFO - __main__ - Step 30 Global step 30 Train loss 0.45 on epoch=14
06/17/2022 15:50:07 - INFO - __main__ - Step 40 Global step 40 Train loss 0.40 on epoch=19
06/17/2022 15:50:09 - INFO - __main__ - Step 50 Global step 50 Train loss 0.43 on epoch=24
06/17/2022 15:50:10 - INFO - __main__ - Global step 50 Train loss 0.45 Classification-F1 0.3191489361702127 on epoch=24
06/17/2022 15:50:10 - INFO - __main__ - Saving model with best Classification-F1: -1.0 -> 0.3191489361702127 on epoch=24, global_step=50
06/17/2022 15:50:13 - INFO - __main__ - Step 60 Global step 60 Train loss 0.46 on epoch=29
06/17/2022 15:50:16 - INFO - __main__ - Step 70 Global step 70 Train loss 0.47 on epoch=34
06/17/2022 15:50:18 - INFO - __main__ - Step 80 Global step 80 Train loss 0.42 on epoch=39
06/17/2022 15:50:21 - INFO - __main__ - Step 90 Global step 90 Train loss 0.45 on epoch=44
06/17/2022 15:50:24 - INFO - __main__ - Step 100 Global step 100 Train loss 0.37 on epoch=49
06/17/2022 15:50:24 - INFO - __main__ - Global step 100 Train loss 0.44 Classification-F1 0.4682306940371457 on epoch=49
06/17/2022 15:50:24 - INFO - __main__ - Saving model with best Classification-F1: 0.3191489361702127 -> 0.4682306940371457 on epoch=49, global_step=100
06/17/2022 15:50:27 - INFO - __main__ - Step 110 Global step 110 Train loss 0.45 on epoch=54
06/17/2022 15:50:30 - INFO - __main__ - Step 120 Global step 120 Train loss 0.42 on epoch=59
06/17/2022 15:50:33 - INFO - __main__ - Step 130 Global step 130 Train loss 0.42 on epoch=64
06/17/2022 15:50:35 - INFO - __main__ - Step 140 Global step 140 Train loss 0.45 on epoch=69
06/17/2022 15:50:38 - INFO - __main__ - Step 150 Global step 150 Train loss 0.37 on epoch=74
06/17/2022 15:50:39 - INFO - __main__ - Global step 150 Train loss 0.42 Classification-F1 0.5465587044534412 on epoch=74
06/17/2022 15:50:39 - INFO - __main__ - Saving model with best Classification-F1: 0.4682306940371457 -> 0.5465587044534412 on epoch=74, global_step=150
06/17/2022 15:50:42 - INFO - __main__ - Step 160 Global step 160 Train loss 0.37 on epoch=79
06/17/2022 15:50:44 - INFO - __main__ - Step 170 Global step 170 Train loss 0.36 on epoch=84
06/17/2022 15:50:47 - INFO - __main__ - Step 180 Global step 180 Train loss 0.40 on epoch=89
06/17/2022 15:50:49 - INFO - __main__ - Step 190 Global step 190 Train loss 0.35 on epoch=94
06/17/2022 15:50:52 - INFO - __main__ - Step 200 Global step 200 Train loss 0.32 on epoch=99
06/17/2022 15:50:53 - INFO - __main__ - Global step 200 Train loss 0.36 Classification-F1 0.716256157635468 on epoch=99
06/17/2022 15:50:53 - INFO - __main__ - Saving model with best Classification-F1: 0.5465587044534412 -> 0.716256157635468 on epoch=99, global_step=200
06/17/2022 15:50:56 - INFO - __main__ - Step 210 Global step 210 Train loss 0.33 on epoch=104
